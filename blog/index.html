<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/gatsby-jenkins-io/styles.7c3b8f7f67d9c5da9f51.css" data-identity="gatsby-global-css">@import url(https://www.jenkins.io/assets/bower/bootstrap/css/bootstrap.min.css);@import url(https://www.jenkins.io/assets/bower/tether/css/tether.min.css);@import url(https://www.jenkins.io/css/jenkins.css);@import url(https://www.jenkins.io/assets/bower/ionicons/css/ionicons.min.css);@import url(https://www.jenkins.io/css/footer.css);@import url(https://www.jenkins.io/css/font-awesome.min.css);.artifact-list li:before,dt[id]:before,h1[id]:before,h2[id]:before,h3[id]:before,h4[id]:before,h5[id]:before,h6[id]:before{content:" ";display:block;height:55px;margin-top:-55px;visibility:hidden}:hover>.anchorjs-link{opacity:0}img{max-width:100%}.anchorjs-link:hover{opacity:1}.anchorjs-link{padding:.4em .3em .4em .5em!important}.container.page{position:relative}body .no-margin{margin:0;padding:0}#ji-hover-layer{position:relative;z-index:999}#download-menu>.dropdown-menu{padding:2rem;width:50rem}.download-popup-menu .popover-arrow{display:none}#download-menu>.dropdown-menu .btn-group:active>.dropdown-menu{display:block}body .popover.download-options{box-shadow:0 3px 15px rgba(0,0,0,.25);max-width:90%!important;min-width:500px!important;width:620px}.betanotice{background-color:#f7f1da;color:#d24939;font-weight:700;text-align:center;top:0;width:100%;z-index:100}body h1.page-title{font:700 4rem georgia;margin-top:-.2rem}body h1.page-title .in-tag{display:none}.sub-heading{margin:-.5rem 0 1rem}.fixed.top{position:fixed;top:0;width:100%;z-index:10}.carousel-item{background:#fff;min-height:27rem}.carousel-item>.carousel-caption{bottom:auto;top:1.5rem}#ji-download .carousel-caption{display:block;margin-top:1rem;padding:1rem;position:static}.carousel-item video{bottom:0;left:0;opacity:.67;position:absolute;right:0;top:0;width:100%}.carousel-item .mask{background:hsla(0,0%,100%,.5);bottom:0;box-shadow:0 0 100px 10px #fff;left:20%;position:absolute;right:20%;top:0}.carousel{z-index:9}.dropdown-menu p{font-size:.875rem!important}@media screen and (-webkit-min-device-pixel-ratio:0) and (min-resolution:.001dpcm){.chromeOnly{height:36px}}.carousel-inner{z-index:8}#ji-download{left:0;min-width:620px;position:absolute;right:0;text-align:center;top:18rem;z-index:9}.authors,.authors>.auth{display:inline-block;margin:0;padding-bottom:5px}.authors>.auth>a{border:1px solid;cursor:pointer;display:block;font-size:50px;padding:5px;text-decoration:none}.authors>.auth>a:hover{background:#def}div .authors{display:block;margin-bottom:3rem;padding:0}.row.body{padding-top:3rem}.no-margin .row{margin:0}.container.center{text-align:center}.center>.center{display:inline;display:inline-block;float:none}body .jumbotron{margin:0}body .card-block{display:block}.jumbotron.featured{background-color:#168bb9}.jumbotron.featured a{color:#fff;text-decoration:none!important}.jumbotron.featured .row>div{position:relative}.jumbotron.featured .icon-docker.big{font-size:300px;position:absolute;right:0;text-decoration:none;top:-4rem}.tint{box-shadow:inset 0 0 100px rgba(0,0,0,.25)}img.desaturate{filter:grayscale(100%);filter:gray;filter:url("data:image/svg+xml;utf8,<svg version='1.1' xmlns='http://www.w3.org/2000/svg' height='0'><filter id='greyscale'><feColorMatrix type='matrix' values='0.3333 0.3333 0.3333 0 0 0.3333 0.3333 0.3333 0 0 0.3333 0.3333 0.3333 0 0 0 0 0 1 0' /></filter></svg>#greyscale")}.img-box{background:#fff;border:1px solid #ccc;box-sizing:content-box;display:block;float:left;height:132px;line-height:132px;margin:2px;overflow:hidden;padding:0 10px;width:112px}.img-box>img{position:relative;top:-5px;vertical-align:middle;width:100%}.media-row,.step-by-step{border-bottom:.1rem solid #ccc;overflow-x:auto;overflow:visible;padding:2rem 1rem 3rem;position:relative;text-align:center;white-space:nowrap}.media-row{background-color:#fff;display:flex;flex-wrap:wrap}.media-row>.header,.step-by-step>.container>.header{margin-bottom:1.75rem}.media-row>.media,.step-by-step>.container.step{cursor:pointer;font-size:.9rem;vertical-align:top}.date-time,.step-by-step>.container .step .card-title{background:#168bb9;border-radius:50%;color:#fff;display:inline-block;font-size:1rem;height:4.75em;overflow:hidden;padding:.5em;position:relative;text-align:center;width:4.75em}.date-time>.date,.step-by-step>.container .step .card-title>.tag{background:rgba(180,40,40,.85);border-top-left-radius:.5em;border-top-right-radius:.5em;box-shadow:0 1px 5px rgba(0,0,0,.15);font-size:.75em;font-weight:400;left:0;padding:.5em 0 .25em;position:absolute;right:0;top:0}.date-time>.date .small{font-size:.5em}body .date-time{border-radius:.5em;height:5.3em;width:5.3em}.date-time>.date>*{display:inline}.date-time>.date>.dow{bottom:-1.1em;color:rgba(0,0,0,.15);display:block;font-family:arial narrow;font-size:6em;font-weight:bolder;left:-1em;position:absolute;right:-1.15em;text-align:center}.date-time>.time{font-size:1.1em;line-height:.67em;margin:2em -1em 0;position:relative}.step-by-step>.container .step .card-title>.num{font-size:2em;line-height:1em;margin-top:.67em}.step-by-step>.container .step .title{font-size:1.1rem;white-space:nowrap}.step-by-step>.container .step .short{display:block;font-size:.75rem;line-height:1.5em;margin:0 .5rem .5rem;overflow:hidden}.card-block{padding-bottom:0}.media-row>.media{font-size:85%;height:auto;margin:.25rem;min-height:16rem;text-align:left;width:14rem}.media-row>.media>img{width:100%}.media-row>.media>.card-block{padding:.75rem;white-space:normal;width:100%}.media-row>.media>.card-block p{line-height:1.2em}.media-row>.media .media-title{font-size:1.25rem;margin-bottom:.125rem}.quote-row{background:#f9f9f9;border-radius:0;box-shadow:inset 0 10px 100px rgba(0,0,0,.25);white-space:normal}.quote-row .card.important{background:#fff;box-shadow:0 1px 5px rgba(0,0,0,.25);font-size:1rem;margin-top:-1rem;white-space:normal}.quote-row .card.important p{font-size:1rem}#directory td>a{display:block;margin-bottom:.5rem;padding-bottom:.5rem;padding-right:1rem}#directory td>a>img{height:40px;width:40px}#directory tr{vertical-align:top}#directory tr td .title{font-weight:700}#directory tr td .description{font-size:75%}#welcome,body #sidebar ul.resources{border-top:1px solid #ccc;margin-bottom:2rem;margin-top:.75rem;padding-bottom:3rem;padding-top:1.5rem;position:relative}#welcome>div{bottom:0;height:3rem;left:0;position:absolute}#welcome>div>a{display:block;font-weight:700;margin-left:1rem;padding-left:40px;position:absolute;top:0}#sidebar #welcome>div>img{height:32px;left:4px;position:absolute;top:0;width:32px}#sidebar #welcome>.content{height:auto;position:relative}#sidebar ul.resources,#sidebar ul.resources>li,#sidebar ul.resources>li>a{display:block;list-style:none;margin:0;padding:0}body #sidebar ul.resources>li>a{font-weight:700;margin-left:1rem;padding:0 0 .5rem 40px}body .ji-dated-list>.post{border-top:.1rem solid #ccc;margin-bottom:.5rem}.ji-blog-list,.ji-dated-list,.ji-item-list,.ji-item-list>.post>.body,.ji-item-list>post,.ji-item-list>post>.body{display:block;font-size:1rem;list-style:none;margin:0;padding:0;position:relative}.events .ji-item-list{border-bottom:1px solid #ccc;overflow:visible;overflow-x:auto;overflow-y:visible;text-align:center;vertical-align:top;white-space:nowrap}.events .ji-item-list>.event{display:inline-block;margin:0;vertical-align:top}.events .ji-item-list>.event>a{margin:1rem .25rem .25rem;padding:.75rem;text-decoration:none;white-space:normal;width:16rem}.events .ji-item-list>.event>a .title{height:1.1rem;margin:.75rem 0 .25rem;overflow:hidden;position:relative}.events .ji-item-list>.event>a .title:after{bottom:0;box-shadow:inset -3rem 0 2rem -2rem #fff;content:" ";display:block;height:1.1rem;position:absolute;right:0;width:10%}.events .ji-item-list>.event>a .teaser{color:#4a5568;font-size:.85rem;height:3.3rem;overflow:hidden;position:relative}.events .ji-item-list>.event>a .teaser:after{bottom:0;box-shadow:inset -6rem 0 3rem -3rem #fff;content:" ";display:block;height:1.1rem;position:absolute;right:0;width:25%}.ji-dated-list>.post>.attrs,.ji-dated-list>.post>.body{padding:1.25rem 1rem 1rem 5rem;text-decoration:none}.ji-blog-list>.post>.more{color:#79b1be;position:absolute;right:0}.ji-blog-list>.post>.more:before{border:1px solid;content:"+";display:block;float:right;margin-left:.5rem}.ji-blog-list>.post>.body>.teaser,.ji-dated-list>.post>.body>.teaser{color:#555;margin:0 0 .5rem;max-height:6rem;overflow:hidden;position:relative;text-decoration:none}.ji-blog-list>.event>.body>.teaser{max-height:3.3rem!important}.fff.section{background:#fff;box-shadow:0 2px 3px rgba(0,0,0,.15);position:relative;z-index:2}.ji-blog-list>.post>.body>.teaser:after,.ji-dated-list>.post>.body>.teaser:after{bottom:0;box-shadow:inset -25rem 0 15rem -15rem #fff;content:"";display:block;height:1.5rem;position:absolute;right:0;width:30rem}.f9f9f9.section{background:#f9f9f9}.ji-dated-list>.post>.body>.teaser:after,z.f9f9f9.section .ji-blog-list>.post>.body>.teaser:after{box-shadow:inset -25rem 0 15rem -15rem #f9f9f9}.ji-blog-list>.post>.body:hover,.ji-dated-list>.post>.body:hover{text-decoration:none}.ji-blog-list>.post>.body:hover>.header>.title,.ji-dated-list>.post>.body:hover>.title{text-decoration:underline}.ji-dated-list>.post>.body>.teaser{color:#333;text-decoration:none}.ji-dated-list>.post>.body>.card{left:0;position:absolute;top:1.25rem}.ji-dated-list>.post>.attrs{padding-top:0;text-align:left}.ji-dated-list>.post>.attrs .author{display:inline-block;font-size:125%;margin:0 0 .25rem}.ji-blog-list>.post>.attrs>.tags,.ji-dated-list>.post>.attrs>.tags{font-size:75%;opacity:.75}.ji-blog-list>.post>.attrs>.tags>li,.ji-dated-list>.post>.attrs>.tags>li{display:inline-block;padding:0}.ji-blog-list>.post>.attrs>.tags>li>a{padding-right:.25rem}.ji-dated-list>.post>.attrs>.tags>li>a{border:.1rem solid;display:block;padding:0 .25rem}.ji-item-list .card{border:.1rem solid;text-align:center;width:4rem}.date.card>.month{background:#999;color:#fff}.date.card>.day{font-size:150%;font-weight:600;line-height:3rem}.ji-blog-list .date{border:1px solid;display:inline-block;font-size:.75rem;line-height:1.2em;margin:-.25rem .25rem 0 -2.75rem;position:relative;text-align:center;vertical-align:middle}.ji-blog-list .header{padding-left:2.75rem}.ji-blog-list .title{display:inline-block;vertical-align:middle}.ji-blog-list .date>.month{background:#168bb9;border-bottom:1px solid;color:#fff;padding:0 .2rem}.ji-blog-list .post,.ji-item-list .post{margin:.5rem 0 1.5rem}.blog-posts .ji-blog-list .post{background:#fff;margin:.5rem -1.5rem 1rem;padding:1.5rem}.ji-blog-list .attrs{color:#d55}.ji-blog-list .attrs>a{color:#d53730}.ji-blog-list .header.time{padding:0 0 .33rem 2.15rem;position:relative}.ji-blog-list .header.time .date{left:0;margin:0;position:absolute;top:0}.ji-blog-list .date-time .time{color:#d53730;font-size:.85rem;margin-bottom:-.5rem;position:relative;top:-.33rem}.blog-posts>h4,.events>h5{border-bottom:1px solid #ccc;margin:0 0 1rem;min-height:2rem}.events .event .title{display:block;font-size:1rem;margin:0}.events .event .teaser{font-size:.85rem;line-height:1.1rem}.event .teaser{overflow:hidden;position:relative;text-align:justify}.event .teaser.collapsed{max-height:4rem}.event .teaser:not(.collapsed){max-height:unset}.event .teaser.collapsed:before{background-image:linear-gradient(180deg,transparent,#fff);bottom:0;content:"";left:0;padding:3em 0;position:absolute;width:100%}.events .ji-blog-list>.event>.body>.teaser:after{height:1.1rem}.docker-plugins-list{margin-top:3rem}.ji-item-list.plugins>.post .body{padding:.75rem 0 0 2.5rem}.ji-item-list.plugins>.post .body p{margin:0}.ji-item-list.plugins>.post .body>.title{margin-top:0}.ji-item-list.plugins>.post>.attrs{font-size:80%;text-align:right}.ji-item-list.plugins>.post>.body>.card{top:.75rem}.card.icon{line-height:2rem;padding:0 .25rem;vertical-align:middle}.card.icon,.card.icon div{display:inline}.ji-dated-list>.post>.article{text-decoration:none}.ji-dated-list>.post>.article>.title{margin:.5rem 0 .125rem}.ji-dated-list>.post>.article>.url{color:#999;font-size:75%}.doc-block{margin:2rem 0 6rem}.sub-block{margin:3rem 0}.active-section{margin-bottom:1rem}.toc li a{display:block;line-height:1.2em;padding:.5rem 0}.toc .active-section li a{padding:.125rem 0}.cal{border:1px solid #999;margin-bottom:2rem}.cal>.row{border-bottom:1px solid rgba(0,0,0,.2);margin:0}.cal>.days{background:rgba(0,0,0,.15);border-bottom:1px solid #999;box-shadow:inset 0 3px 3px -3px rgba(0,0,0,.3);text-align:center}.cal>.days>.col-md-2{height:auto;line-height:2em;position:relative}.cal>.row>.col-md-2.weekend{background:rgba(0,0,0,.1);border:none;box-shadow:inset 3px 0 3px -3px rgba(0,0,0,.2)}.cal .col-md-2{border-right:1px solid rgba(0,0,0,.1);height:5.5rem}.cal a.apt{background:rgba(100,255,255,.5);box-shadow:inset 0 0 0 1px rgba(0,100,100,.5);display:block;font-size:75%;left:0;line-height:1.2em;padding:.125rem .5rem;position:absolute}.cal a.apt.span-4{margin:1px;width:400%}.cal a.apt.span-1{width:100%}.segment{padding-top:3rem}.cols-3{-moz-columns:3;column-count:3}.chunks{list-style:none;margin:0;padding:0}.features.uniform-height>div{padding-left:0}.uniform-height .box{border-radius:5px;min-height:10rem;padding:.67rem .75rem 0 4rem;position:relative}.uniform-height .box:before,.uniform-height .box i{background:#168bb9;border-radius:50%;color:#fff;content:" ";display:block;font-size:1.75rem;height:3.25rem;left:0;line-height:3.25rem;position:absolute;text-align:center;top:.75rem;width:3.25rem}.uniform-height .box>p{font-size:.8rem;line-height:1.5em;overflow:hidden}.uniform-height .box>h5{font-size:1.1rem;line-height:1.3em;margin-bottom:.33rem}@media (max-width:768px){.segment{padding-top:1rem}.uniform-height .box{margin-bottom:.5rem;min-height:4rem;padding-bottom:.5rem}}@media (min-width:992px) and (max-width:1200px){.uniform-height .box{min-height:12rem}}#ji-download .btn{border-radius:3px;box-shadow:0 3px 3px -1px rgba(0,0,0,.25);position:relative}#ji-download .btn .brick-tops{background:repeating-linear-gradient(90deg,transparent,transparent 12px,#358 0,#07d 22px,#358 32px);display:none;left:0;position:absolute;right:0;top:0}.brick-tops.footer{background:repeating-linear-gradient(90deg,transparent,transparent 12px,#234 0,#357 22px,#234 32px);border-bottom:2px solid rgba(255,255,255,.1)}#ji-download .btn:hover .brick-tops{background:repeating-linear-gradient(90deg,transparent,transparent 12px,#136 0,#05a 22px,#136 32px)}#ji-download .btn:hover{box-shadow:none}body{background-color:#fff;color:#4a5568;font-family:lato,Roboto,Open Sans,sans-serif;font-size:1rem;line-height:1.5;margin:0}.jumbotron.plugins{background:#81b0c4;background:linear-gradient(90deg,#81b0c4,#335061);border-radius:0;color:#fff;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#81b0c4",endColorstr="#335061",GradientType=1)}.overview{padding-top:1.5rem}.overview p{font-size:1.1rem}.btn-primary{background:#d24939;border:0}.btn-primary:active,.btn-primary:focus,.btn-primary:hover{background:#335061;border:0}nav .nav-item{cursor:pointer}nav .nav-item.active{box-shadow:inset 0 -2px #d33833}a{color:#069}#toc-blog{margin-left:-1rem}.section.blogs .content{padding-top:.5rem}.container.blog-post{min-height:65rem}.container.blog-post h1{font-size:2.25rem;margin-bottom:1rem}.container.blog-post .submitted{display:block}.section.blogs h4.blog-title{font-size:1.25rem;padding-bottom:.25rem}.container.blog-post .main-content{margin-bottom:60px}.quoteblock{padding-bottom:1rem}blockquote{border-left:5px solid #ddd;font-style:italic;margin:1rem 0 2rem;padding:1rem 1rem 1rem 2rem}.quoteblock blockquote{background:#fff;margin:1rem 0 0;padding:1rem 1rem 1rem 3rem;position:relative}.quoteblock .attribution{font-style:italic;margin-left:1.5rem}.quoteblock blockquote:before{color:#ddd;content:"\201C";display:block;font-size:4rem;left:0;line-height:1em;position:absolute;text-align:center;top:.5rem;width:3rem}.toc{background-color:#f9f9f9;border-left:1px solid #c9c9c9;clear:right;float:right;margin-bottom:1rem;margin-left:15px;padding:10px;width:20rem}.toc li li{padding-left:1rem}.toc li,.toc li>a,.toc ul{display:block;font-size:.9rem;line-height:1.35rem;list-style:none;margin:0;padding:0}.toc ul.root>li>a{color:#911;font-size:.85rem}.container.blog-post #sidebar{background:#f9f9f9;border-left:1px solid #ccc;bottom:0;box-shadow:inset 10px 0 10px -15px;overflow-y:auto;padding-top:5rem;position:fixed;right:0;top:0}.vertical.events .ji-item-list>.event{display:block}.container.blog-post .events .ji-item-list{border:none;white-space:normal}.container.blog-post .time .date-time{font-size:.75rem;left:1rem;position:absolute}.container.blog-post .events .ji-item-list>.event>a{background:#fff;border:1px solid #ccc;border-radius:3px;box-shadow:0 2px 2px rgba(0,0,0,.15);margin:.25rem 1rem .25rem .25rem;padding:.25rem 0 .25rem 5.5rem;text-align:left;width:auto}.carousel-caption{text-shadow:none}.admonitionblock td.content>.title,.audioblock>.title,.dlist>.title,.exampleblock>.title,.hdlist>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.olist>.title,.openblock>.title,.paragraph>.title,.qlist>.title,.quoteblock>.title,.stemblock>.title,.ulist>.title,.verseblock>.title,.videoblock>.title,table.tableblock>.title{text-rendering:optimizeLegibility;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic;text-align:left}table.tableblock>caption.title{max-width:0;overflow:visible;white-space:nowrap}#preamble>.sectionbody>.paragraph:first-of-type p,.paragraph.lead>p{color:rgba(0,0,0,.85)}table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}.admonitionblock>table{background:none;border:0;border-collapse:separate;margin:10px;width:100%}.admonitionblock>table td.icon{text-align:center;width:80px}.admonitionblock>table td.icon img{max-width:none}.admonitionblock>table td.icon .title{font-family:Open Sans,DejaVu Sans,sans-serif;font-weight:700;text-transform:uppercase}.admonitionblock>table td.content{border-left:1px solid #ddddd8;color:rgba(0,0,0,.6);padding-left:1.125em;padding-right:1.25em}.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}span.icon>.fa{cursor:default}.admonitionblock td.icon [class^="fa icon-"]{cursor:default;font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5)}.admonitionblock td.icon .icon-note:before{color:#19407c;content:"\f05a"}.admonitionblock td.icon .icon-tip:before{color:#111;content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8)}.admonitionblock td.icon .icon-warning:before{color:#bf6900;content:"\f071"}.admonitionblock td.icon .icon-caution:before{color:#bf3400;content:"\f06d"}.admonitionblock td.icon .icon-important:before{color:#bf0000;content:"\f06a"}.fa{text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-family:FontAwesome!important;font-size:inherit}p.details{margin-top:1rem}.imageblock,.listingblock{background:#fafafa;margin:20px 0;padding:15px}.image.right,.imageblock.right{float:right}.image.left,.imageblock.left{float:left}.image.center,.imageblock.center{margin-left:auto;margin-right:auto;text-align:center}.imageblock.boxshadow img,.paragraph.boxshadow img{box-shadow:0 0 15px 0 rgba(0,0,0,.5);margin:5px}#sponsorsblock{padding:1rem 2rem}#sponsorsblock p,#sponsorsblock ul{list-style-type:none;padding:0;text-align:center}#sponsorsblock li{display:inline;padding:1rem}.sponsors a:hover{text-decoration:none}.supporters{padding-top:1.5rem}.supporters a{font-weight:700}.div-mar{border-top:2px solid #fff;margin-right:2rem}.area,.div-mar{padding:1rem 0}.links{padding:0}.footer-left{padding-left:0}@media screen and (max-width:991px){.footer-left{margin-top:1rem}}li>p{margin:0;padding:0}.image.center>img{max-height:100%;max-width:100%}.current-page,.next-link,.previous-link,.skip{background-color:#fff;border:1px solid #ddd;color:#0275d8;float:left;line-height:1.5;margin-left:-1px;padding:.5rem .75rem;position:relative;text-decoration:none}.next-link:focus,.next-link:hover,.previous-link:focus,.previous-link:hover{background-color:#eceeef;border-color:#ddd;color:#014c8c;text-decoration:underline}.current-page{background-color:#eceeef;border-color:#ddd;color:#014c8c}li.card.step{background:none;border:none}.card.step>.card-block>p{white-space:normal}.conum[data-value]{background-color:rgba(0,0,0,.8);border-radius:100px;display:inline-block;font-family:Open Sans,DejaVu Sans,sans-serif;font-size:.75em;font-style:normal;font-weight:700;height:1.67em;line-height:1.67em;text-align:center;width:1.67em}.conum[data-value],.conum[data-value] *{color:#fff!important}.conum[data-value]+b{display:none}.conum[data-value]:after{content:attr(data-value)}pre .conum[data-value]{position:relative;top:-.125em}b.conum *{color:inherit!important}.conum:not([data-value]):empty{display:none}.colist>table tr>td:first-of-type{line-height:1;padding:0 .75em}.colist>table tr>td:last-of-type{padding:.25em 0}table{margin-bottom:1.25rem}.sidebar-nav h4{margin-bottom:1.5rem}.doc-page-link{margin-left:auto;margin-right:auto}.pipeline-block{margin-bottom:1rem}.pipeline-script-expand{font-size:.7rem}.scripted-pipeline{border-left:2px solid #ddd;border-top:1px solid #ddd;padding:5px}.syntax h2{border-bottom:3px solid #ddd}.syntax h3{border-bottom:2px solid #ddd}.syntax h4{border-bottom:1px solid #ddd}table.syntax{border:1px solid #fafafa;font-size:.8rem;margin:1rem}table.syntax p{margin:0;padding:5px}table.syntax>tbody>tr>td{border:1px solid #fafafa}table.syntax>tbody>tr>th{background-color:#fafafa;border:1px solid #fafafa;font-weight:700}.tour .active{font-weight:700}.navbar.navbar-expand-lg{font-size:.875rem}.navbar.navbar-expand-lg.bg-dark{background-color:#212529!important}.navbar.navbar-expand-lg .navbar-brand{font-family:Georgia,Times,Times New Roman,serif;font-size:20px;font-weight:600;padding:2px 0}.navbar.navbar-expand-lg .btn{font-size:.875rem;margin-left:8px;margin-top:1px}.navbar.navbar-expand-lg .btn.dropdown-toggle:after{margin:0 0 0 8px}.navbar.navbar-expand-lg .btn.btn-outline-secondary.active,.navbar.navbar-expand-lg .btn .btn-outline-secondary.active,.navbar.navbar-expand-lg .btn.btn-outline-secondary.focus,.navbar.navbar-expand-lg .btn.btn-outline-secondary:active,.navbar.navbar-expand-lg .btn .btn-outline-secondary:active,.navbar.navbar-expand-lg .btn.btn-outline-secondary:focus{background-color:hsla(0,0%,100%,.15)}.navbar.navbar-expand-lg .btn.btn-outline-secondary:hover,.navbar.navbar-expand-lg .navbar-toggler:hover{background-color:hsla(0,0%,100%,.1)}.navbar.navbar-expand-lg .show>.btn-outline-secondary.dropdown-toggle{background-color:hsla(0,0%,100%,.15)}.navbar.navbar-expand-lg .nav-link.btn{color:hsla(0,0%,100%,.75)}.navbar.navbar-expand-lg .dropdown-menu{font-size:.875rem}.navbar-toggler-icon{font-size:.8em}.nav-link.dropdown-toggle{background-color:transparent;border:0;font-family:inherit;font-size:inherit;line-height:inherit}.navbar .nav-link:focus,.navbar .navbar-brand:focus{outline-color:rgba(255,255,255,.5);outline-style:auto;outline-width:1px}.no-outline .navbar .nav-link:focus,.no-outline .navbar .navbar-brand:focus{outline-width:0}.banner-container .skew:before{-webkit-backface-visibility:hidden;backface-visibility:visible;-webkit-backface-visibility:initial;backface-visibility:initial;background:#f8f9fb;content:"";height:600px;left:0;overflow:visible;position:absolute;top:-100px;transform:skewY(-14deg);width:100%;z-index:-1}@media (min-width:767px){.header .skew:before{height:900px;top:-350px}}@media (min-width:992px){.header .skew:before{height:1020px;top:-350px}}.jumbotron{background-color:#f8f9fb}.post-attrs>.tags>li{display:inline-block;font-size:.7rem}.post-attrs>.tags>li>a{background-color:#069;border:.1rem solid;color:#fff;display:inline-block;padding:0 .25rem}.author.box td{max-width:600px;padding:5px;vertical-align:top}.author.box p{margin-bottom:3px}.author.about-header{font:1.5em Georgia,Times New Roman;margin-bottom:3px}.author.name{font:1.3em Georgia,Times New Roman}.author.logo{border-radius:6px;height:128px;max-width:none}.author.social-media-buttons{float:left;list-style:none;margin-top:0;padding:0;width:100%}.author.social-media-buttons li{display:block;float:left;margin-right:10px}.author-list{display:flex;flex-wrap:wrap}.author-card{background:#fff;border:.1rem solid #ccc;border-radius:3px;box-sizing:border-box;color:#666;cursor:pointer;font-size:.85rem;height:16.5rem;margin:.25rem;padding:.67rem;text-align:center;text-decoration:none!important;width:13rem}.author-card,.author-card .author.logo{display:block}.author-card .author.logo{margin:16px auto}.author-card .social-media-buttons{display:flex;margin-top:16px;width:100%}.author-card .social-media-buttons li{flex-grow:1;text-align:center}.author-card .social-media-buttons li a{margin:auto}.group-description p{margin-bottom:0}.group-links{margin-bottom:1rem}.logo-thumb{max-height:256px}.btn.btn-xs{border-radius:.2rem;height:1rem;line-height:.5rem;margin:.2rem;padding:.15rem;width:1rem}.grid-container{grid-gap:20px;display:grid;grid-template-columns:repeat(auto-fill,minmax(256px,1fr));margin-bottom:1rem}.grid-container .card{border:1px solid #d3d3d3;border-radius:.25rem}.grid-container .card .content{padding:15px}.grid-all,.grid-all td,.grid-all th{border:1px solid #dee2e6;padding:.75rem}.grid-all thead th{border-bottom-width:2px}.nav-item.searchbox{margin:auto auto auto .75em}.twitter-share-button{background-color:#1b95e0;background-image:url(/images/twitter-logo.svg);background-position:4px;background-repeat:no-repeat;background-size:14px 14px;border-radius:3px;box-sizing:border-box;color:#fff;cursor:pointer;display:inline-block;font-size:.7rem;font-weight:500;height:20px;line-height:20px;padding:1px 8px 1px 24px;position:relative}.twitter-share-button:hover{color:#fff;text-decoration:none}</style><meta name="generator" content="Gatsby 3.14.1"/><title data-react-helmet="true">Jenkins</title><link data-react-helmet="true" href="https://www.jenkins.io/favicon.ico" rel="shortcut icon" type="image/x-icon"/><link data-react-helmet="true" href="https://www.jenkins.io/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/><link data-react-helmet="true" href="https://www.jenkins.io/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/><link data-react-helmet="true" href="https://www.jenkins.io/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/><link data-react-helmet="true" href="/site.webmanifest" rel="manifest"/><link data-react-helmet="true" color="#5bbad5" href="https://www.jenkins.io/safari-pinned-tab.svg" rel="mask-icon"/><meta data-react-helmet="true" content="text/html; charset=UTF-8" http-equiv="Content-Type"/><meta data-react-helmet="true" charSet="utf-8"/><meta data-react-helmet="true" content="width=device-width, initial-scale=1" name="viewport"/><meta data-react-helmet="true" content="ie=edge" http-equiv="x-ua-compatible"/><meta data-react-helmet="true" content="#2b5797" name="msapplication-TileColor"/><meta data-react-helmet="true" content="#ffffff" name="theme-color"/><meta data-react-helmet="true" content="summary_large_image" name="twitter:card"/><meta data-react-helmet="true" content="@JenkinsCI" name="twitter:site"/><meta data-react-helmet="true" content="@JenkinsCI" name="twitter:creator"/><meta data-react-helmet="true" content="article" property="og:type"/><meta data-react-helmet="true" content="https:/www.jenkins.io/template/" property="og:url"/><style data-react-helmet="true">#grid-box { position: relative } </style><style data-react-helmet="true">html { min-height:100%; position: relative; }</style><link rel="sitemap" type="application/xml" href="/gatsby-jenkins-io/sitemap-index.xml"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="icon" href="/gatsby-jenkins-io/favicon-32x32.png?v=4a9773549091c227cd2eb82ccd9c5e3a" type="image/png"/><link rel="manifest" href="/gatsby-jenkins-io/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/gatsby-jenkins-io/icons/icon-48x48.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="72x72" href="/gatsby-jenkins-io/icons/icon-72x72.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="96x96" href="/gatsby-jenkins-io/icons/icon-96x96.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="144x144" href="/gatsby-jenkins-io/icons/icon-144x144.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="192x192" href="/gatsby-jenkins-io/icons/icon-192x192.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="256x256" href="/gatsby-jenkins-io/icons/icon-256x256.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="384x384" href="/gatsby-jenkins-io/icons/icon-384x384.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="512x512" href="/gatsby-jenkins-io/icons/icon-512x512.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link as="script" rel="preload" href="/gatsby-jenkins-io/webpack-runtime-b42e528980e987374b2f.js"/><link as="script" rel="preload" href="/gatsby-jenkins-io/framework-094b0089736b8f621f0d.js"/><link as="script" rel="preload" href="/gatsby-jenkins-io/app-78a498257c1e7f31ccf8.js"/><link as="script" rel="preload" href="/gatsby-jenkins-io/commons-e65a75583f121ad6113a.js"/><link as="script" rel="preload" href="/gatsby-jenkins-io/component---src-pages-blog-js-31fe540eab0531bb5744.js"/><link as="fetch" rel="preload" href="/gatsby-jenkins-io/page-data/blog/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/gatsby-jenkins-io/page-data/sq/d/3649515864.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/gatsby-jenkins-io/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><script src="https://www.jenkins.io/assets/bower/jquery/jquery.min.js"></script><nav class="navbar navbar-expand-lg navbar-dark top bg-dark fixed-top" id="ji-toolbar"><a class="navbar-brand" href="https://www.jenkins.io/">Jenkins</a><button class="navbar-toggler" data-target="#CollapsingNavbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="CollapsingNavbar"><ul class="nav navbar-nav mr-auto"><li class="nav-item dropdown"><button type="button" aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown"><svg width="36" height="18" xmlns="http://www.w3.org/2000/svg" role="img" xlink="http://www.w3.org/1999/xlink" viewBox="-3.23 44.77 362.70 271.95"><defs><linearGradient id="a" x1="359.765" x2="104.082" y1="134.295" y2="124.577" gradientTransform="matrix(1 0 0 -1 0 439.068)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#ed1c24"></stop><stop offset="1" stop-color="#f7941d"></stop></linearGradient><linearGradient id="b" x1="355.202" x2="99.519" y1="254.467" y2="244.749" href="#a"></linearGradient><linearGradient id="c" x1="183.903" x2="10.612" y1="227.598" y2="221.023" href="#a"></linearGradient><linearGradient id="d" x1="367.119" x2="157.995" y1="265.311" y2="257.091" href="#a"></linearGradient></defs><path fill="#c49a6c" d="M231.52 309.278c2.483-.332 4.895-.77 7.255-1.329s4.649-1.206 6.991-1.957c13.494-4.58 25.187-12.952 36.374-24.593l-.14-.175c-14.944 15.486-30.693 25.344-50.48 28.054z"></path><path fill="url(#a)" d="M224.232 309.96h.332c1.084 0 2.15-.14 3.216-.228a93.844 93.844 0 0 1-3.233.227z"></path><path fill="url(#b)" d="M284.692 187.187l-.122.192.122-.192z"></path><path fill="url(#c)" d="M146.145 231.847a150.844 150.844 0 0 1-12.97 15.862c-7.582 7.889-15.507 13.563-24.652 16.667a47.832 47.832 0 0 1-4.738 1.326 56.959 56.959 0 0 1-4.916.9 38.32 38.32 0 0 1-1.682.214l-.912.083c-.723.059-1.445.118-2.18.154h-3.068a42.325 42.325 0 0 1-9.192-1.043 49.977 49.977 0 0 1-6.764-2.002 43.097 43.097 0 0 1-4.525-1.954c-1.493-.77-2.961-1.516-4.407-2.37a59.5 59.5 0 0 1-17.105-15.399 59.714 59.714 0 0 1-2.914-4.311 53.09 53.09 0 0 1-1.291-2.263 51.985 51.985 0 0 1-2.263-4.738 46.72 46.72 0 0 1 0-36.426 51.986 51.986 0 0 1 2.263-4.738 54.14 54.14 0 0 1 1.291-2.263 59.742 59.742 0 0 1 2.914-4.311 59.714 59.714 0 0 1 17.105-15.4 60.828 60.828 0 0 1 4.407-2.369q2.217-1 4.525-1.777a49.976 49.976 0 0 1 6.906-2.073 42.325 42.325 0 0 1 9.192-1.042h3.128c.722 0 1.445.094 2.155.154l1.043.106 1.019.119c1.8.237 3.553.557 5.271.96.853.2 1.694.426 2.523.663a51.186 51.186 0 0 1 11.846 5.176 59.645 59.645 0 0 1 4.395 2.89 74.485 74.485 0 0 1 8.386 7.108q2.038 1.99 4.063 4.193l.083-.13a159.395 159.395 0 0 1 11.064 13.942c5.437-8.576 13.658-21.464 16.584-25.74 1.185-1.718 2.37-3.46 3.66-5.212-13.54-16.513-29.827-30.23-51.587-36.082h-.154a89.397 89.397 0 0 0-3.187-.794l-.45-.107a92.565 92.565 0 0 0-3.151-.627l-.628-.119a80.578 80.578 0 0 0-3.743-.569h-.142a58.29 58.29 0 0 0-2.073-.236h-.391l-1.872-.166h-.568l-1.754-.119h-.675l-1.777-.07h-3.115c-46.447-.25-87.125 40.476-87.125 86.911s40.725 87.173 87.172 87.173h3.14l1.729-.071h.734l1.67-.095h.676l1.706-.154h.568l1.813-.213.414-.06 1.967-.272h.213a125.91 125.91 0 0 0 3.553-.628l.652-.142c.96-.201 1.907-.415 2.855-.64l.58-.142a86.66 86.66 0 0 0 3.009-.817l.237-.071c20.73-6.077 36.425-19.392 49.55-35.277-2.037-3.068-3.4-5.366-4.039-6.48z"></path><path fill="url(#d)" d="M318.05 51.733v94.66a85.514 85.514 0 0 0-52.595-18.729h-3.115l-1.777.072-.7.047-1.752.118h-.569l-1.871.166h-.391c-.7.071-1.386.142-2.073.237h-.154c-1.256.154-2.5.355-3.732.569l-.628.118c-1.066.19-2.108.403-3.15.628l-.45.107c-30.35 6.858-50.333 28.808-66.822 52.82-.7 1.018-1.35 2.049-2.038 3.068-2.25 3.423-5.46 8.422-8.635 13.397-4.17 6.527-8.292 13.03-9.939 15.66l20.624 32.137s21.997 40.465 61.68 51.482l.237.07c.995.297 2.002.558 3.009.818l.58.142c.936.237 1.896.439 2.855.64l.652.142c1.184.225 2.369.439 3.553.628h.214l1.966.273.415.059 1.812.213h.569l1.705.154h.676l1.67.095h.734l1.73.07h3.139c54.703 0 86.355-30.964 87.149-85.063V51.733zm-52.595 215.403h-3.068c-.734 0-1.457-.095-2.18-.154l-.912-.083c-.568-.06-1.125-.13-1.682-.213a49.077 49.077 0 0 1-9.571-2.275 49.612 49.612 0 0 1-6.634-2.83 55.792 55.792 0 0 1-6.254-3.768 63.068 63.068 0 0 1-3.009-2.215 82.399 82.399 0 0 1-8.683-7.925l-.095.119c-1.255-1.303-2.487-2.69-3.731-4.11-.154-.167-.296-.356-.45-.534-.628-.722-1.256-1.445-1.884-2.215s-1.125-1.398-1.682-2.097-.888-1.101-1.338-1.682a184.467 184.467 0 0 1-6.053-8.292c-.7-.995-1.398-2.025-2.109-3.056-.379-.569-.77-1.184-1.185-1.73-.675-1.018-1.362-2.013-2.049-3.056l-.355-.545c-1.185-1.812-2.37-3.684-3.649-5.603q2.95-4.608 5.817-8.86c1.907-2.831 3.79-5.556 5.662-8.138s3.72-5.046 5.591-7.38 3.72-4.525 5.603-6.586q2.026-2.203 4.063-4.194c1.374-1.338 2.748-2.594 4.158-3.778s2.807-2.287 4.252-3.329a57.594 57.594 0 0 1 7.748-4.62c.331-.166.663-.367 1.006-.533l.226-.118c1.41-.652 2.843-1.185 4.3-1.73l.485-.201c.273-.083.557-.142.83-.237a44.943 44.943 0 0 1 3.34-.948l1.374-.343a60.798 60.798 0 0 1 4.738-.841l1.019-.119 1.042-.106c.711 0 1.434-.119 2.156-.154h3.128a42.431 42.431 0 0 1 4.572.26 48.011 48.011 0 0 1 6.93 1.35c1.54.427 3.08.925 4.596 1.505a48.724 48.724 0 0 1 4.525 1.955c1.493.722 2.961 1.516 4.407 2.369s2.866 1.8 4.24 2.784 2.725 2.049 4.028 3.174a58.459 58.459 0 0 1 8.837 9.477 59.73 59.73 0 0 1 2.914 4.312 51.067 51.067 0 0 1 5.318 11.916 47.38 47.38 0 0 1 1.185 5.165 45.567 45.567 0 0 1 .71 8.09c.072 35.964-16.062 52.122-52.227 52.122z"></path></svg></button><div class="dropdown-menu"><a class="dropdown-item feature" href="https://cd.foundation/">What is CDF?</a><a class="dropdown-item feature" href="https://jenkins-x.io/">Jenkins X</a><a class="dropdown-item feature" href="https://cloud.google.com/tekton/">Tekton</a><a class="dropdown-item feature" href="https://www.spinnaker.io/">Spinnaker</a></div></li></ul><ul class="nav navbar-nav ml-auto"><li class="nav-item"><a aria-current="page" class="nav-link active" href="/gatsby-jenkins-io/blog/">Blog</a></li><li class="nav-item dropdown"><button aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown">Documentation</button><div class="dropdown-menu"><a class="dropdown-item feature" href="/gatsby-jenkins-io/doc/book/"><strong>User Guide</strong></a><a class="dropdown-item" href="/gatsby-jenkins-io/doc/book/installing/"> - Installing Jenkins</a><a class="dropdown-item" href="https://www.jenkins.io/doc/book/pipeline/"> - Jenkins Pipeline</a><a class="dropdown-item" href="https://www.jenkins.io/doc/book/managing/"> - Managing Jenkins</a><a class="dropdown-item" href="https://www.jenkins.io/doc/book/security/"> - Securing Jenkins</a><a class="dropdown-item" href="https://www.jenkins.io/doc/book/system-administration/"> - System Administration</a><a class="dropdown-item" href="https://www.jenkins.io/doc/book/glossary/"> - Terms and Definitions</a><a class="dropdown-item" href="https://www.jenkins.io/solutions/"><strong>Solution Pages</strong></a><a class="dropdown-item" href="https://www.jenkins.io/doc/tutorials/"><strong>Tutorials</strong></a><a class="dropdown-item" href="https://www.jenkins.io/doc/pipeline/tour/getting-started/"> - Guided Tour</a><a class="dropdown-item" href="https://www.jenkins.io/doc/tutorials/"> - More Tutorials</a><a class="dropdown-item feature" href="https://www.jenkins.io/doc/developer/"><strong>Developer Guide</strong></a><a class="dropdown-item" href="https://www.jenkins.io/participate/"><strong>Contributor Guide</strong></a></div></li><li class="nav-item"><a class="nav-link" href="https://plugins.jenkins.io">Plugins</a></li><li class="nav-item dropdown"><button aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown">Community</button><div class="dropdown-menu"><a class="dropdown-item feature" href="https://www.jenkins.io/participate/">Overview</a><a class="dropdown-item feature" href="https://www.jenkins.io/chat/" title="Chat with the rest of the Jenkins community on IRC">Chat</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/jam/">Meet</a><a class="dropdown-item feature" href="https://www.jenkins.io/events/">Events</a><a class="dropdown-item feature" href="https://issues.jenkins.io/">Issue Tracker</a><a class="dropdown-item feature" href="https://www.jenkins.io/mailing-lists/" title="Browse Jenkins mailing list archives and/or subscribe to lists">Mailing Lists</a><a class="dropdown-item feature" href="https://www.jenkins.io/project/roadmap/">Roadmap</a><a class="dropdown-item feature" href="https://accounts.jenkins.io/" title="Create/manage your account for accessing wiki, issue tracker, etc">Account Management</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/"><strong>Special Interest Groups</strong></a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/advocacy-and-outreach/"> - Advocacy and Outreach</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/chinese-localization/"> - Chinese Localization</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/cloud-native/"> - Cloud Native</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/docs/"> - Documentation</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/gsoc/"> - Google Summer of Code</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/hw-and-eda/"> - Hardware and EDA</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/pipeline-authoring/"> - Pipeline Authoring</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/platform/"> - Platform</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/ux/"> - User Experience</a></div></li><li class="dropdown nav-item"><button aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown">Subprojects</button><div class="dropdown-menu"><a class="dropdown-item feature" href="https://www.jenkins.io/projects/">Overview</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/evergreen/">Evergreen</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/gsoc/">Google Summer of Code in Jenkins</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/infrastructure/">Infrastructure</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/jam/">CI/CD and Jenkins Area Meetups</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/jcasc/">Jenkins Configuration as Code</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/jenkins-operator/">Jenkins Operator</a><a class="dropdown-item feature" href="https://www.jenkins.io/projects/remoting/">Jenkins Remoting</a><a class="dropdown-item feature" href="https://www.jenkins.io/sigs/docs/gsod/2020/projects/document-jenkins-on-kubernetes/">Document Jenkins on Kubernetes</a></div></li><li class="nav-item dropdown"><button aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown">About</button><div class="dropdown-menu"><a class="dropdown-item" href="https://www.jenkins.io/project/roadmap/">Roadmap</a><a class="dropdown-item" href="https://www.jenkins.io/security/">Security</a><a class="dropdown-item" href="https://www.jenkins.io/press/">Press</a><a class="dropdown-item" href="https://www.jenkins.io/awards/">Awards</a><a class="dropdown-item" href="https://www.jenkins.io/project/conduct/">Conduct</a><a class="dropdown-item" href="https://www.jenkins.io/artwork/">Artwork</a></div></li><li class="nav-item dropdown"><button aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown">English</button><div class="dropdown-menu"><a class="dropdown-item" href="https://www.jenkins.io/zh/">中文 Chinese</a></div></li><li class="nav-item"><a class="nav-link btn btn-outline-secondary" href="https://www.jenkins.io/download/">Download</a></li></ul></div></nav><div class="pt-4"> </div><div id="grid-box"><div class="container"><div id="block-block-15" class="block block-block even blog-posts"><h3 class="title">Recent Blog Posts</h3></div><div class="content blog-posts"><div class="item-list"><ul class="ji-blog-list ji-item-list"><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/02/welcome-to-continuous-blog/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 2</div></div><h5 class="title">Welcome to Continuous Blog!</h5></div><p class="teaser">Hello and welcome to &quot;Continuous Blog&quot;, the official Hudson weblog! If you
don’t mind me saying so, I think its arrival is long overdue. Since Hudson
started in November of 2006, there hasn’t been a central &quot;voice&quot; for the
project. In just a few short years Hudson has grown into a substantial project
with hundreds of plugins and thousands of users around the world.
Kohsuke &#x27;s
nice Java-based extensible continuous integration server has grown up into
fantastic tool with a great community around it.

Goals for this weblog

I think it is important to set out a couple of goals for this weblog, some simple items that should help guide the content and discussion around Continuous Blog and its future.

Continuous Blog should:

Help advocate the use of Hudson to the larger internet community

Be a central source for tutorials and helpful information to Hudson users of all skill-levels

Recognize the numerous contributors to the Hudson project for their efforts

What to expect

As Continuous Blog grows and matures, you can expect to see a variety of Hudson-related content. Overviews of the latest releases of Hudson and its plugins, interviews and discussions with the developers who have contributed to Hudson over the years, guest posts by power-users on how Hudson fits into their workflow and much much more (really).

If you look around the page you’ll already see a good amount of content, in the
sidebar to the right you’ll notice the &quot;Recently Released&quot; section which
aggregates recently released plugins via this RSS
feed, the &quot;Blogs&quot;
section which is an aggregation of Hudson community blogs (from this RSS
feed).

We’re just starting out so make sure you subscribe to the RSS feed, we’ve got a lot to talk about here on Continuous Blog.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/08/hudson-1-344-released/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 8</div></div><h5 class="title">Hudson 1.344 Released</h5></div><p class="teaser">The latest release of Hudson, 1.344, was released on February 5th, 2010. The release contains primarily bug-fixes but has a few enhancements baked into it as well. As mentioned in &quot; [Incoming! More Translations&quot;, 1.344 incorporates a number of community-driven translations (see the other post for more information). Additionally, 1.344 removes the &quot;easter egg&quot; background image I wrote about in a post to my personal blog: Mourning Sun Enough of the small talk, here’s the breakdown.

Bugs fixed

Removed the forced upper casing in parameterized builds. ( issue 5391)

Password parameter on the disk should be encrypted. ( issue 5420)

Duplicate entries on Upstream/Downstream project with &quot;Build modules in parallel&quot;. ( issue 5293)

&quot;Projects tied on&quot; should be &quot;Projects tied to&quot;. ( issue 5451)

Fixed the bug that prevents update center metadata retrieval in Jetty. ( issue 5210)

+

Enhancements

Show which plugins have already been upgraded in Plugin Manager. ( issue 2313)

Show Hudson upgrade status on manage page instead of offering same upgrade again. ( issue 3055)

Make badges in build history line up. ( report)

+

Contributors

This release of Hudson contained 44 commits from 5 different contributors to &quot;core&quot;:

abayer

kohsuke

mindless

sogabe

huybrechts

+
As usual, you can go grab the http://mirrors.jenkins.io/war-stable/latest/jenkins.war[latest .war file] straight from `hudson-ci.org` or if you&#x27;re using a native package, use your package manager to upgrade.

Update: This post was written a day before issue 5536 was discovered. I recommend waiting until 1.345 to update any production Hudson instances.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/08/breaking-hudson-1-345-released/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 8</div></div><h5 class="title">Breaking! Hudson 1.345 Released!</h5></div><p class="teaser">As I mentioned in the footer of the post on the Hudson 1.344 release, there were a couple big regressions in the 1.344 release that were causing a number of users issues (such as issue 5536 and issue 5546).

As a result, Kohsuke and the team have quickly pushed out a hot-fix release: 1.345. Here’s the break down:

Bugs fixed:

Update center retrieval, &quot;build now&quot; link, and real-time console update was broken in 1.344 ( issue 5536)

Fixed the backward incompatibility introduced in HUDSON-5391 fix in 1.344. ( issue 5391)

If you have already updated to 1.344, your &quot;Update Center&quot; is most likely busted and you’ll need to download the hudson.war file manually.

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/09/whats-going-on-with-the-hudsons-infrastructure/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 9</div></div><h5 class="title">What&#x27;s going on with the Hudson&#x27;s infrastructure</h5></div><p class="teaser">A lot has changed in the Hudson development and distribution infrastructure since last summer - we’ve made a distinct effort to get the quality of our infrastructure to match the quality of Hudson itself. We owe a special thanks to the wonderful folks over at Atlassian - we’re taking advantage of their generous open source license for our bug tracking ( JIRA), wiki ( Confluence), and source repository browser ( FishEye). Obviously, there’s a lot more we can improve going forward - I’ll have another post up soon, looking at some of the ideas we’re kicking around. But for now, take a look at what we’ve already done, below the fold.

The Hudson war and plugin downloads have all moved off of the unreliable java.net to our own [hudson-ci.org]( https://hudson-ci.org) with the downloads being powered by the same system used for distributing Java, OpenSolaris, and NetBeans. Downloading Hudson and/or plugins is now easier and more reliable.

We’ve moved issue tracking from java.net’s system to our own JIRA instance, at [issues.hudson-ci.org]( https://issues.hudson-ci.org). As with moving downloads off java.net, we’ve made reporting and browsing Hudson’s issues much faster, easier and more reliable, while still using the same authentication on the back-end as our Subversion and Maven repositories. We’re still working out some kinks in the system but since we’re running our own issue tracker now, rather than using one we didn’t have control over, we’ve got the flexibility we need to adapt our tools to best serve the developer and user communities.

Speaking of tools we now run ourselves, we’ve put up our own FishEye instance at [fisheye.hudson-ci.org]( https://fisheye.hudson-ci.org) - until that was in place, we’d been relying on Atlassian’s public FishEye instance, which has many other open source projects&#x27; repositories available. Getting our own server up means we don’t have to bug the generous folks over at Atlassian every time the java.net SVN server confuses FishEye into failing to update. It also opens the door for us to use Crucible for code review in the future.

Hudson’s moved onto Twitter more and more over the last 6-9 months - we’ve got the always fabulous @hudsonci, tweeting new releases, Hudson-related tweets, and more, as well as the #hudsonci hashtag.

This may not strictly be infrastructure but it’s worth mentioning that we’ve now got native packages and distribution for Hudson for Ubuntu/Debian, Red Hat/Fedora/CentOS, openSUSE, OpenSolaris/Nevada, and FreeBSD.

This is all in addition to key parts of our infrastructure that haven’t changed: our official wiki, our user and developer mailing lists, our Subversion repository (and a Git mirror on GitHub) and our IRC channel over on Freenode.

Oh, and I hear there’s a blog now too.

Editor’s Note: *Andrew Bayer ( abayer) has been a contributor to Hudson since early 2009, contributing to the ClearCase plugin, Hudson’s core and a small number of other plugins. Andrew also helps Kohsuke with a lot of Hudson’s project infrastructure, most notably the migration from Bugzilla on Java.net to JIRA running at issues.hudson-ci.org *<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/08/incoming-more-translations/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 8</div></div><h5 class="title">Incoming! More Translations</h5></div><p class="teaser">As Kohsuke mentioned on the dev@ mailing
list on January 29th,
another series of community translations of Hudson have been committed
( r26764) and have been released with the
Hudson 1.344 release.

The locales included in this update are:

Czech

Spanish

Finnish

French

Hungarian

Japanese

Korean

Lithuanian

Norwegian

Dutch

Polish

Brazilian Portuguese

Russian

Slovenian

Swedish

Chinese (Simplified/Traditional)

If you’re fluent in any of the locales above, check out the latest release of Hudson to verify that the translations are correct, if there’s translations that you feel are incorrect, you can report them in JIRA.

The [internationalization] https://jenkins.io/doc/developer/internationalization/) project could always use some more help whether it be from patches or via the Translation Assistance Plugin.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/10/keeping-your-configuration-and-data-in-subversion/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">10</div></div><h5 class="title">Keeping your configuration and data in Subversion</h5></div><p class="teaser">We all know that keeping important files in version control is critical, as it ensures problematic changes can be reverted and can serve as a backup mechanism as well. Code and resources are often kept in version control, but it can be easy to forget your continuous integration (CI) server itself! If a disk were to die or fall victim to a misplaced rm -rf, you could lose all the history and configuration associated with the jobs your CI server manages.

It’s pretty simple to create a repository, but it isn’t obvious which parts of your $HUDSON_HOME you’ll want to backup. You’ll also want to have some automation so new projects get added to the repository, and deleted ones get removed. Luckily we have a great tool to handle this: Hudson!

We have a Hudson job which runs nightly, performs the appropriate SVN commands, and checks in. The high-level overview of this job is basically:

Add any new jobs, users, plugin configurations, et cetera: svn add -q --parents.xml jobs/ /config.xml users/ /config.xml userContent/

Remove anything from SVN that no longer exists (such as a deleted job): svn status | grep &#x27;!&#x27; | awk &#x27;{print $2;}&#x27; | xargs -r svn rm

Check it in! svn ci --non-interactive --username=mrhudson -m &quot;automated commit of Hudson configuration&quot;
You’ll want to make sure to use the --non-interactive option for any automated svn operations, as this ensures Subversion won’t hang asking a question but instead fail immediately. You may also need to provide your password with the --password option.

To make such a Hudson job, create a new job, tie it to the controller (since this is where the configuration files are), set it to build periodically (we use “@midnight”), and add an “Execute shell” build step. Here’s the full script we use, to put into the build step:

# Change into your HUDSON_HOME.
cd /opt/hudson
# Add any new conf files, jobs, users, and content.
svn add -q --parents *.xml jobs/*/config.xml users/*/config.xml userContent/*
# Ignore things in the root we don&#x27;t care about.
echo -e &quot;warnlogn*.logn*.tmpn*.oldn*.bakn*.jarn*.json&quot; &gt; myignores
svn propset svn:ignore -F myignores . &amp;&amp; rm myignores
# Ignore things in jobs/* we don&#x27;t care about.
echo -e &quot;buildsnlast*nnext*n*.txtn*.lognworkspace*ncoberturanjavadocnhtmlreportsnncoverndoclinks&quot; &gt; myignores
svn propset svn:ignore -F myignores jobs/* &amp;&amp; rm myignores
# Remove anything from SVN that no longer exists in Hudson.
svn status | grep &#x27;!&#x27; | awk &#x27;{print $2;}&#x27; | xargs -r svn rm
# And finally, check in of course, showing status before and after for logging.
svn st &amp;&amp; svn ci --non-interactive --username=mrhudson -m &quot;automated commit of Hudson configuration&quot; &amp;&amp; svn st

You’ll notice this does some extra things like set the svn:ignores property to provide a relatively clean svn st which it shows before and after the commit for logging purposes. One thing this job doesn’t do is put the build results of your jobs in version control. Because historical build logs and artifacts will never change and are also potentially large, a periodic (daily or weekly) cp or rsync of the jobs directory will still give you restorability while keeping your repository lean.

Now you can sleep well at night knowing that your CI server is safe and sound. If you are doing a similar thing with Hudson or another CI system, let us know about your solution!

Editor’s Note: Mike Rooney is a Software Engineer at Genius.com, provider of real-time marketing automation software connecting marketing and sales. You can read more posts from Mike and other Geniuses at eng.genius.com<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jobs">jobs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/11/spotlight-on-ita-software/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">11</div></div><h5 class="title">Spotlight on: ITA Software</h5></div><p class="teaser">For the first &quot;User Spotlight&quot; interview ever on Continuous Blog, I am talking with Matt Girard of
ITA Software, a Boston-based software company that produces travel industry software which is used by many of the major carriers in the U.S. and abroad. When I sent out a message asking for users of Hudson in the corporate space to ping me about doing a &quot;spotlight&quot; on them, ITA Software stuck out in particular; they’re hiring a Hudson expert!

The format for the &quot;spotlight&quot; series isn’t entirely nailed down yet so feel free to ask questions in the comments section and I’ll follow-up with Matt after the fact if need be. That said, without further delay, Matt Girard from ITA Software, on Hudson.
--- Hudson Matt, appreciate you taking the time to answer some questions about Hudson at ITA Software, let’s start with a simple one: How long has ITA been using Hudson?

Matt My pleasure, glad to be a part of the community. We have been using Hudson in some form since early 2008. Predictably our usage has increased over time and now encompasses the majority of our automated build and test infrastructure.

Hudson Was continuous integration a part of ITA’s workflow prior to adopting Hudson? If so: what did ITA switch to Hudson from, and why?

Matt Yes, though not to the degree that we have now. Prior to Hudson we were reliant on BuildBot for our automated builds, but we were not doing continuous integration
 across our components until after the transition to Hudson. The easy to understand UI and flexibility were primary features that compelled our switch. I should mention
 that when we decided to switch we also evaluated CruiseControl but Hudson came out on top for our needs.

Hudson What kind of projects are you typically using Hudson for? What
languages/build system(s)? What platforms is Hudson performing builds? What kinds of jobs primarily run on ITA’s Hudson cluster?

Matt Our Hudson environments (yes, we have more than one) have been optimized for building C++, Java (all maven based), Lisp (a surprise to some to be sure more about that here), and Python on Linux build agents (Fedora and CentOS).

Our jobs are (loosely) grouped into one of three categories: rpm (we are primarily RedHat based), tests, and tools. The rpm jobs are the actual code builds and individual component unit tests. The test jobs (thank you parameterized trigger plugin!) are part of a larger cross-component integration testing and promotion scheme. The (handful of) tools jobs support us in tasks such as cleaning up stale sandbox database connections.

Hudson Given the flexibility of Hudson, it’s safe to say that not everybody is using it in the exact same fashion, is there anything you would consider interesting or noteworthy about the use of Hudson at ITA?

Matt I think that our most interesting usage of Hudson has to be how we have combined parameterized builds with the parameterized trigger plugin in order to do cross-component testing of trunk code. More specifically, we pass a properties file (to us a &quot;scoreboard&quot; that tells the jobs what exact revisions of which projects to
 test together) to several jobs and only build a final promotion job if ALL of downstream jobs (with the same scoreboard) passed. In this way we create a hurdle that all of our code must clear before we even consider deploying it anywhere else.

The next most interesting thing we are doing is using Hudson for continuous deployment of monitoring changes into our staging environment. It’s quite rewarding to watch a check-in makes it’s way through Hudson, into and rpm, and out to a server without a human being involved.

Hudson Are there any additional tools ITA has written to better integrate things &quot;behind the scenes&quot;?

Matt We evolved what became a very large build script (mostly derived from what we had for BuildBot) that handles all of the nitty-gritty details involved in the building, packaging, and testing of our software. Recently we have been working to refactor this into several smaller build tools each with a more focused purpose. The first of these is designed (largely as a wrapper to rpmbuild) to standardize our package building while leaving the .spec files (with the real specifics) living alongside the code where they belong.

Hudson On a scale from 1-10, how important would you rate Hudson for ITA’s
day-to-day workflow?

Matt ITA is a decent size company and there is plenty of work that goes on that does not involve Hudson in any way. Still since we rely on the building and testing that Hudson does in order to promote new code to production, I would say that we are somewhere around an 8.

I’d like to thank Matt again for being a good sport as the very first in what I hope will be a long line of &quot;spotlights&quot; on companies using Hudson to help them work smart, better and faster. If you would like to discuss your company’s use of Hudson for Continuous Blog, you can contact me at tyler at linux.com

Editor’s Note: Matt Girard is the Manager of Build and Integration at ITA Software and a passionate advocate for continuous integration and continuous deployment. He believes that release engineering exists to make developers lives easier — not harder — and can be found posting about such topics on Twitter as @equalize.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/12/this-week-in-plugins/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">12</div></div><h5 class="title">This Week in Plugins</h5></div><p class="teaser">Since this is the first &quot;This Week in Plugins&quot; (TWiP), I’m trying a fairly basic format out. I’m debating how much information I want to include in these, while I would like to include details on &quot;what’s changed&quot; for each plugin over the course of the week, the means of fetching that information would be incredibly tedious (read: no fun) since there’s not particularly any standard meta-data to be scraped from the wiki. Duplicates have been pruned from the list, meaning the latest release of a plugin is what’s being shown; sorting is also by day of release then alphabetical.

Feb 4th, 2010

Codescanner Plug-in 0.9 released

Feb 5th, 2010

Centralized Job(Re)Action 1.1 released

Performance Publisher plugin 7.95 released

Selenium Auto Exec Server(AES) plugin 0.3 released

Feb 6th, 2010

MSTest plugin 0.5 released

TextFinder plugin 1.8 released

Feb 7th, 2010

Configuration Slicing plugin 1.16 released

Feb 8th, 2010

ClearCase UCM Baseline Plug-in 1.2 released

Join plugin 1.8 released

Feb 9th, 2010

Downstream-Ext 1.5 released

Groovy Postbuild 1.1 released

Feb 10th, 2010

Batch task plugin 1.13 released

disk-usage plugin 0.10 released

JBoss Management Plugin 1.0 released

Sidebar Link 1.3 released

slave-status 1.4 released

SLOCCount Plug-in 1.4 released

StarTeam plugin 0.2 released

Template Project plugin 1.1 released

TuxDroid Plugin 1.6 released

Zentimestamp plugin 1.2 released

Feb 11th, 2010

Backup plugin 1.4 released

Promoted Builds (Simple) 1.2 released

Python Plugin 1.1 released

Subversion Plug-in 1.11 released<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/14/thanks-for-the-help/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">14</div></div><h5 class="title">Thanks for the help!</h5></div><p class="teaser">A great community of developers and users is one of the many things that make Hudson a great tool and a fun project to work with, after launching Continuous Blog as an extensions of that community earlier this week there are some thanks in order to those that helped spread the word about CB and in turn, Hudson. Thanks to:

Everybody on Twitter who retweeted the Continuous Blog launch announcement

Julian Simpson, also known as The Build Doctor for helping spread the word

Kevin Farnham for featuring the launch of Continuous Blog on the Java.net home page!

Of course, none of this would be possible without Kohsuke and a large collection of contributors that have made Hudson what it is today.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/15/hudson-1-346-released/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">15</div></div><h5 class="title">Hudson 1.346 Released</h5></div><p class="teaser">After some scrambling earlier in the week to get 1.345 out the door, correcting some regressions in 1.344, the Hudson team still rolled out a 1.346 release last Friday, February 12th, 2010. Similar to the past couple releases, 1.346 had a good number of bug fixes, including a a performance fix when dealing with larger build submissions and a substantial revision of the SCM polling code to fix a long-standing issue with the quiet period blocking the build from running ( issue 2180), there were also some additionally memory improvements made to Jelly, the library with which the majority of Hudson’s web interface is rendered, that Kohsuke will detail in a later post.

Here’s the breakdown:

Bugs fixed

Maven modules should not be buildable when the parent project is disabled. ( issue 1375)

Fixed the broken quiet period implementation when polling interval is shorter than the quiet period. (Changes in SCM impls are needed for this to take effect.) ( issue 2180)

Escape username in URLs in case it contains special characters such as &quot;#&quot;. ( issue 2610)

Fix sidepanel link for People to be visible and show view-specific info when appropriate. ( issue 5443)

Improved HTML rendering, not using closing tags that do not exist in HTML. ( issue 5458)

Show better error message for missing view type selection when creating a view. ( issue 5469)

Hudson wasn’t properly streaming a large external build submission, which can result in OOME and unresponsiveness.
# Enhancements

Use fixed-width font in text area for shell/batch build steps. ( issue 5471)

Use user selected icon size on People page. ( issue 5447)

Speed/footprint improvement in the HTML rendering.

# Contributors This release of Hudson contained 37 commits from 3 different contributors to &quot;core&quot;: * kohsuke * mindless * sogabe
As usual, you can go grab the [latest .war file]( http://mirrors.jenkins.io/war-stable/latest/jenkins.war) straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade. ---- Updated: Added the &quot;official&quot; changelog notes<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/16/performance-improvements-in-1-346/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">16</div></div><h5 class="title">Performance improvements in 1.346</h5></div><p class="teaser">From time to time, we get a report of out of memory problems in Hudson. It’s frequent enough that we have a dedicated Wiki page that talks about how to obtain information to help devs work on the problem.

So the latest thread from David Woon was assumed to be one of those ordinary trouble-shooting sessions, but thanks to Gustaf Lundh, it turned out to be a very interesting exercise.

What we discovered was that the profiler I was using ( Your Kit Profiler), was basically eliminating all the weak/soft references from the picture entirely. If we are looking for leaks, this was the right thing, as those references will be cleared before VM chokes with OutOfMemoryError. But because of this elimination, I was completely blind to the wasteful memory usage in Jelly, which are only reachable via soft references.

So I used Eclipse Memory Analyzer and YJP side by side to look into Jelly’s memory usage, and based on that insight, I was able to substantially improve the memory usage and speed of Jelly.

I monitor my production Hudson deployment with VisualGC, and the result was quite noticable. And I hope you’ll notice that the response from Hudson is also snappier.

All these changes are a part of the latest 1.346 release.

Editor’s Note: Kohsuke Kawaguchi a senior engineer at Oracle (formerly Sun) and is the founder and author of the Hudson project. To learn more about Kohsuke, you can follow him on Twitter or subscribe to his blog.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/17/getting-started-building-android-apps-with-hudson/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">17</div></div><h5 class="title">Getting started: Building Android apps with Hudson</h5></div><p class="teaser">In this post I’ll show a very basic tips on how to compile an Android project using Hudson. Specifically how  I use Hudson to create release versions of my apps.

Debug vs Release

I’m assuming that you are using Eclipse with the ADT plugin. During development you can test your app on the emulator or a device and resources like R.java and aidl files are compiled for you automatically by the plugin. When it’s time to release your app, you’ll need to go through some steps:

You must sign your app using a certificate

You must update your AndroidManifest.xml to remove the android:debuggable attribute

Replace your Google Maps API debug key with the one belonging to your release certificate (if you are using a MapView)

Generate an apk package for the release and test it on a device or emulator

It would be nice to automate a few of these steps, and this is where Hudson comes in.

Automated builds: Ant

For automated builds the Android SDK uses Apache Ant, which Hudson has great support for. To generate a template build.xml you can use the android tool from the SDK using the following command:

android create project -n template -t android-7 -p template -k dummy.pkg -a Dummy

The target is specified as &quot;android-7&quot; meaning that we are building for Android 2.1. For apps that use MapView we would use &quot;Google Inc.:Google APIs:7&quot;. It is a good idea to always target the latest SDK. From this template project we’ll grab the build.properties and the build.xml and copy those to the Android project that we want to build. Edit build.xml and set the project name to your Android project name.

The local.properties file contains the path to the SDK root and shouldn’t be checked in to version control. For our use we’ll set the properties that are in that file on the Hudson job configuration page.

Running the build in Hudson

This part is easy: create a new freestyle job and let it be build with ant. The targets that we want to execute are clean release. Release will compile, package and sign your apk. Now to get this working right, some custom properties should be set (use the Advanced button).

sdk.dir=/Users/hugo/Code/android-sdk-mac
target=Google Inc.:Google APIs:7
key.store=certs/rd-release.keystore
key.alias=rainydays
key.store.password=thisisnotmypassword
key.alias.password=thisisnotmypassword

The sdk.dir should point to the Android SDK root on your Hudson node. In my case I’m running Hudson locally on my machine.  The target property refers to the SDK we want to use as mentioned earlier.  The key. properties are related to signing of the apk. My strategy is to have a separate key store and private key for each application that I develop. I also check that keystore in to SVN. I also archive the -release.apk artifact so that I can download the latest release apk directly from Hudson.  After completing these steps, you should be able to build your Android app with Hudson.

Updating the AndroidManifest for release

…​But we’re not done yet :) Remember what I said about updating the AndroidManifest.xml? For that we need to edit the build.xml, which by default contains nothing more then a tag to pull in the Android SDK ant target definitions. For my Rainy Days application, I adjusted build.xml like this:

...

Removing debug attribute from AndroidManifest.xml

Setting release maps key

What the above snippet does is removing the android:debuggable attribute from the AndroidManifest.xml and replacing the maps API key in res/layout/maplayout.xml with the correct key for release. The -package-resources target is pulled in from the Android android_rules.xml file.

Now when Hudson builds my app I get a ready to release apk that I can install on my device or emulator, which is pretty nice.

There is are some issues with this approach however. As you might have noticed:

Replacements are done in the workspace, we are not really building exactly what’s in svn

Each new build should start out fresh for that reason, for example by using the svn revert option.

Additionally I can not yet tag the release version with the updated files, because the subversion tagging plugin doesn’t support this by design. This could be worked around by adding svn statements in the build.xml however.  For now I don’t really mind as I make minor changes to the resource files, but I’ll be looking at improving this situation.

Things to add: unit testing, coverage…​

One thing that I’d really like to add is unit testing. This is a little bit more complicated though, since unit tests require a running emulator and a running emulator requires a gui. The Hudson Xvnc plugin could be very helpful here.

The Android build scripts for test projects already include EMMA output, it shouldn’t be to hard to use the Hudson plugin for that.

When Hudson is running on a local machine, the Batch task plugin can automate installing the apk on a device to automate things further.

Summary

Building Android applications with Hudson is not that hard, since the builds are based on Ant. By hooking in to the standard Android build targets it’s easy to update files like AndroidManifest.xml which in turn makes sure the release process is controlled and predictable.
Android unit tests depend on the emulator which is a little bit more challenging to set up, but Hudson already has some plugins available to make this easier.

Editor’s Note: Hugo Visser is the developer of Rainy Days and Engine Watch for Android. You can
follow him on Twitter and on his blog.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jobs">jobs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/18/spotlight-on-visfleet/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">18</div></div><h5 class="title">Spotlight on: VisFleet</h5></div><p class="teaser">For this week’s user spotlight, I’m talking to Rasheed Abdul-Aziz of
VisFleet Ltd. out of New Zealand. This being our second &quot;spotlight&quot; on a particular company, the format can still be considered beta; if you have any additional questions for Rasheed, feel free to ask them in the comments and I’ll try to get Rasheed to answer.

Similar to the spotlight on ITA Software from last week, VisFleet builds business software helping their customers operate their businesses more effectively through web applications in tandem with mobile applications. While I could endlessly discuss the power and flexibility of Hudson, particularly for building web software, I’ll let Rasheed do the majority of the talking, so let’s get to it.
introducing VisFleet, would you mind explaining a bit more of what you guys do and some of the challenges it presents?

Rasheed It’s a pleasure. VisFleet has changed it’s direction somewhat, moving from
services into product development. As we move into product, we want to be
responsive to our customers. Agile development is becoming core to how we
operate, and as such, continuous builds and integration became a major
factor. We now plan to offer two products for work planning and and vehicle
tracking. We want to present these systems with a SaaS model. The world of
online, pay as you go software, has a culture of frequent improvements and
responsiveness to user feedback. If we want to do well in this space, it’s
important that we can code, test, release and feed back in
tight iterations.

Hudson How long has VisFleet been using Hudson?

Rasheed About 14 months now.

Hudson Did you guys work with continuous integration prior to starting to use
Hudson? If so, what system was VisFleet using and what compelled the switch
to
Hudson?

Rasheed We didn’t actually, but certainly everyone I knew who was doing continuous
integration recommended Hudson.

Hudson That’s good to hear! How lucky you are to know so many smart people :)
What kinds of projects is VisFleet building with Hudson?

Rasheed We build and test Ruby On Rails service layer applications. We also build Flex applications using the Flex SDK for our web-deployed RIA offering. Lastly, we build our iPhone applications using Hudson.

Hudson I’d say building and testing web applications alone with Hudson would be quite notable, but to add Flex and iPhone applications into the mix as well is certainly interesting! Anything specific that’s interesting about VisFleet’s use of Hudson?

Rasheed It runs multiple agent types, and automates deploys to different cloud
infrastructures. At the moment we have 2 Flex build agents running Ubuntu, A
Mac Mini building our iPhone app, and several Ubuntu Servers testing our web
tier. We currently deploy to Citrix Xen servers, and soon to Rackspace Cloud as well.

In the near future, we will automate integration by first updating an
integration system on the cloud, deploying our system and then running our
tests. All very quickly.

We have very little metric and reporting output from Hudson, and this is
noteworthy in it’s absence. It’s very important  to use to provide clear
development metrics and integrate those into our Scrum / Kanban approach. What
Hudson has done for us is educate us about the possibilities in
visualisation and reporting, and is informing the way we structure our
codebase going forward. Soon, we expect to have a premium test driven
development environment and workflow.

Hudson We all know Hudson isn’t perfect but there’s a lot of room for extending it to meet your demands if need be, what additional tools have you written to glue everything together behind
the scenes?

Rasheed We are using &#x27; Vlad the Deployer &#x27; and in legacy, &#x27; Capistrano &#x27; for a lot of
our deployment and build tasks. These are merely infrastructure specific
scripts to ensure we can bring up live environments in the shortest amount
of time possible.

Hudson So it sounds like you guys are all on board with Hudson, on a 1-10 scale, how important would you rate Hudson’s importance to VisFleet’s workflow?

Rasheed 7, aiming at 10. The missing points are just a matter of time :)

Thanks again to Rasheed for chatting with me about how Hudson helps VisFleet keep cranking on what they do best. If you would like to discuss your company’s use of Hudson for Continuous Blog, you can contact me at tyler at linux.com

Editor’s Note: Rasheed Abdul-Aziz is a Software Architect at VisFleet Ltd. Rasheed specializes in Flex RIA development, but also loves a good build script and manages Hudson for VisFleet. Find out more about VisFleet and Rasheed on the VisFleet devblog and Rasheed’s blog<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/19/this-week-in-plugins/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">19</div></div><h5 class="title">This Week in Plugins</h5></div><p class="teaser">Last week’s TWIP enumerated the release of 26 different plugin, this past week has seen 19 unique releases in comparison. You might be tempted to assume that less plugin development has occurred over the past week, which isn’t the case. Last week a number of the releases were &quot;code updates&quot;, i.e. plugins being rebuilt against the latest Hudson plugin API as opposed to new features or bug-fixes. With the releases of plugins this past week, it seems a large number of the releases contained new features and bug fixes, including three new plugins!

Making their Hudson debut are the following

Agent Monitor for system load average

Tool Environment plugin

Ivy plugin

If you’re interested in contributing to an existing plugin, or building your own, I highly recommend checking out the plugin tutorial and joining the dev@ mailing list. That said, here are this week’s releases, starting with last Friday.

Feb 12th, 2010

File System SCM 1.6 released

JIRA plugin 1.19 released

Job Configuration History Plugin 1.2 released

MSTest plugin 0.6 released

Agent Monitor for system load average 1.1 released

Template Project plugin 1.2 released

Feb 13th, 2010

xUnit plugin 0.5.2 released

Feb 14th, 2010

Amazon EC2 plugin 1.6 released

Dependency Analyzer Plugin 0.5 released

DocLinks plugin 0.3 released

Tool Environment plugin 1.0 released

Feb 15th, 2010

Artifactory Plugin 1.0.6 released

Dimensions SCM plugin 0.6.8 released

Feb 16th, 2010

HTML Publisher plugin 0.2.2 released

Feb 17th, 2010

Ivy plugin 1.0 released

JBoss Management Plugin 1.0.2 released<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/22/hudson-1-347-released/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">22</div></div><h5 class="title">Hudson 1.347 Released</h5></div><p class="teaser">The release of Hudson 1.347 last friday, February 19th, was a relatively &quot;minor&quot; one insofar that it contained an assortment of smaller fixes instead of fixes to major regressions (they weren’t any to be fixed) or major features added. There were however some notable commits in this release cycle that didn’t make the changelog just yet, for example https://twitter.com/ godin [godin] committed an ebuild which will allow for a native package of Hudson for Gentoo Linux, joining the ranks of the existing packages for Debian/Ubuntu, FreeBSD, OpenSolaris, openSUSE and RedHat/Fedora Linux. The bundled Subversion plugin was updated and thanks to sogabe and wyukawa the Japanese translations for Hudson got some updates as well.

For Hudson developers, both plugin and core, this release contains some notable changes from mindless (a.k.a Alan Harder), a number of calls which have been deprecated for over two years have finally been pruned from the code base:

Hudson.addListener(JobListener), Hudson.removeListener(JobListener)

Entire listeners.JobListener class (replaced by ItemListener)

One form of DirectoryBrowser constructor

One form of Descriptor.configure() (with HttpServletRequest param)

Descriptor.convert(Map) and 4 implementations of this method, and code calling it in Descriptor.readResolve() (this code called save() whenever updating data, so there should be no remaining cases out there)

Alan’s quest for removing deprecated code will likely continue for a while, but this is a good step in the right direction, keeping Hudson’s internals in good working order. Worth mentioning, the influx of plugin releases in the This Week in Plugins from a couple weeks ago, was driven largely by Alan, rummaging through the code of older plugins, updating plugins left and right.
Now the breakdown for this release:

Bugs fixed

Fix javascript problem showing test failure detail for test name with a quote character. ( issue 1544)

Hudson can incorrectly configure labels for the controller when bleeding edge EC2 plugin is used.

Fixed the regression wrt the whitespace trimming caused by 1.346. ( issue 5633)

Under some circumstances, Hudson can incorrectly delete the temporary directory itself. ( issue 5642)

Newlines in MAVEN_OPTS environment variable can cause problems in other contexts. ( issue 5651)

Enhancements

Improved the form validation mechanism to support multiple controls. ( issue 5610)

Added message to agent log when it has successfully come online. ( issue 5630)

Contributors

This release of Hudson contained 36 commits from 7 different contributors to &quot;core&quot;:

abayer

https://twitter.com/ godin [godin]

huybrechts

kohsuke

mindless

sogabe

wyukawa

As usual, you can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/23/would-you-run-hudson-in-the-cloud/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">23</div></div><h5 class="title">Would you run Hudson in the cloud?</h5></div><p class="teaser">One of my favorite bloggers on the subject of continuous integration, The Build Doctor, posed this question in a recent post :

Continuous Integration in the cloud: good idea?

The topic of running a CI server in a virtualized environment, such as with Amazon’s EC2 service, is an interesting issue, particularly in the Hudson community. About 10 months ago Kohsuke announced the Hudson EC2 plugin which has seen slow, but steady development since then, including support for the Ubuntu Enterprise Cloud which was added to the plugin in a release last Monday.

As The Build Doctor and his readers point out, continuous integration is a difficult task to offload into the cloud because of the immense hardware demands constant building and testing presents. That said, Hudson does very effectively manage spinning agents up and down on demand if you’ve configured it as such. Implication being: running Hudson in the cloud may be more efficient to meet peak demands without needing to run a large farm of machines.

If you’re interested in trying out the EC2 plugin, check out Sonatype’s post on Nexus Open Source and Hudson on EC2 might be a good start.

Would you run Hudson in the cloud?<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/24/hudson-at-pycon/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">24</div></div><h5 class="title">Hudson at PyCon</h5></div><p class="teaser">This past week PyCon has been going on in Atlanta, where Titus Brown gave a talk titled:

Why not run all your tests all the time? A study of continuous integration systems

Titus has some notable quotes &quot;just use Hudson&quot; but overall a good introduction of CI and a breakdown of some of the challenges behind continuous integration. He also does a good job going over getting started with Hudson, setting up a basic Python project that incorporates JUnit XML reporting and agents.

&quot;Yeah, we used Buildbot until recently, then I switched us to Hudson and my life got a lot better&quot;

If you’re using Python with Hudson, I highly recommend watching the talk (embedded below).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/25/links-for-2010-02-24/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">25</div></div><h5 class="title">Links for 2010-02-24</h5></div><p class="teaser">Via the @hudsonci twitter account I typically share or &quot;retweet&quot; a number of links during the day, I realize a number of people either do not use Twitter or do not constantly pay attention to it. A lot of the links I find quite interesting, so I’d like to try sharing them after the fact here.

Java.net Maven Repository Rescue Mission on March 5th

Fighting Problems with Hudson Matrix Jobs and Perforce Plugin

Working around issues with matrix jobs and the Perforce plugin ( issue 1022)

Oracle ADF Development Essentials - Part 7 — Continuous Integration with Hudson

Learn how to use Hudson in tandem with the Oracle Application Development Framework (with screenshots).

What is the best Version Control for Visual Studio 2008 SP1?

Asked on Stack Overflow, guess what the chosen answer was?

Automatic testing Oracle Service Bus using Hudson, maven and SoapUI<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/25/sonatype-freeing-projects-from-java-nets-maven-repo/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">25</div></div><h5 class="title">Sonatype freeing projects from java.net&#x27;s Maven repo</h5></div><p class="teaser">Are you working on a project which uses java.net’s Maven repository for deploying its artifacts?

Well, if so, there’s a great opportunity opening up for you to get off that problematic repository: Sonatype is helping java.net projects move to Sonatype’s hosted OSS Nexus repository, starting March 5th. We’re looking into moving Hudson over but for most smaller projects, this should be a no-brainer. Problems with the java.net Maven repository are legendary and Sonatype’s OSS Nexus repository is a great alternative.

Take a look and see if this can work for you.

Editor’s Note: Andrew Bayer ( abayer) has been a contributor to Hudson since early 2009, contributing to the ClearCase plugin, Hudson’s core and a small number of other plugins. Andrew also helps Kohsuke with a lot of Hudson’s project infrastructure, most notably the migration from Bugzilla on Java.net to JIRA running at issues.hudson-ci.org.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/25/spotlight-on-springsource/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">25</div></div><h5 class="title">Spotlight on: SpringSource</h5></div><p class="teaser">For this week’s user spotlight segment, I’m talking with Doug MacEachern of Hyperic, part of SpringSource, a division of VMware, hoping I got that dependency chain correct. Hyperic builds enterprise systems monitoring and management software and also contributes to a number of open source projects, many of which are built with Hudson.

To date I must say that Doug’s use of Hudson is one of the largest and more impressive installations I’ve seen. I don’t want to spoil the interview, but they’re testing on platforms that don’t even run Java. Madness! If you think you can out-do him, you can find my email information at the bottom of the interview, I’d love to hear about it!

Without further ado, Doug from SpringSource.

Doug We started using Hudson in early 2008 to automate the build and testing of our SIGAR library.  The SIGAR API implements a portable interface in C for gathering system information related to memory, processors, file systems, network interfaces, network connection tables, the process table and more.  We support dozens of OS + version + architecture combinations, along with several language bindings.  SIGAR is a key component of the Hyperic HQ agent and is used in other projects including Hypertable, Terracotta, GridGain and MySQL enterprise.

Hudson Was SpringSource using continuous integration before Hudson? If so, what caused you guys to switch?

Doug The SIGAR project actually started back in late 2002 and our initial CI system for the project was a good old-fashioned Perl script / ssh for-loop.  It was good enough to get by in the early years, but a proper replacement was long overdue.  We were (and still are) using Bamboo to build and test Hyperic HQ.  We looked at using Bamboo for SIGAR, but at the time the &quot;Remote Agent&quot; feature was new to Bamboo and was not in the version we were running. Rather than disrupt HQ’s CI along with taking on an additional licensing cost, we gave Hudson a shot and haven’t looked back.

Hudson Might be a bit of personal bias, but I think you guys made the right choice there! Checking out the public Hudson server, I see that SpringSource is building/testing products on AIX, the BSDs, various flavors of Linux, Solaris, Windows and Mac OS X, what kinds of languages/build systems are being built by Hudson? How varied are the environments that Hudson executes jobs in?

Doug And HP-UX! The matrix of SIGAR’s supported OS + kernel version + architecture + distribution is north of 100 combinations.  So, Hudson is covering a very heterogeneous collection of systems with most jobs tied to a specific node.  Our primary focus has been the C API and Java JNI bindings, using an Ant based build system and a JUnit test suite.  SIGAR also has language bindings for Perl, Ruby, Python, Erlang, PHP, C# and Lua.  So, Hudson is also driving each language’s extension build system of choice, respectively: MakeMaker, Rake, distutils, emake, phpize, Nant and autotools.

Hudson What do you consider to be noteworthy about your Hudson implementation? Besides, clearly, that you’re running Hudson agents on just about every OS that will run Java :)

Doug The majority of our x86/x64 nodes are virtualized on VMware ESX and VMware Server.  We also have a fine collection of PPC, PA-RISC and Sparc hardware in house, with IA-64 and s390x hosted elsewhere by third parties.  Some of these systems are too old to support Java 1.5 and/or Git.  As a simple work-around, the nodes share an NFS workspace where the agent node takes care of &#x27;SCM&#x27; and &#x27;Post-build Actions&#x27;, but the &#x27;Build&#x27; step in between is invoked via ssh. The SIGAR distribution includes about two dozen native binaries that are compatible with most of the supported platform matrix.  There’s a Hudson job for each Git branch that rolls these binaries into a release bundle. Another job flavor uses the Hudson URL SCM plugin to download and unit test the binary releases on the rest of the platform matrix.  This is key to testing binary compatibility.  Similar for the collectd project, each Git branch has a job that runs automake, autoconf, etc. and &#x27;make dist&#x27; into the collectd release flavor tarball.  So a push to git.verplant.org by octo in Germany triggers an update of the collectd release artifact, which in turn triggers the URL SCM jobs to download the tarball, unpack and build over here at our west coast locations. We have four Hudson servers in different locations, three of which are managing most of the jobs behind firewalls.  Select jobs use the Build Publisher plugin to post the job and its artifacts to our public Hudson server. This makes it easy for us to provide platform specific bug fixes in binary form, share build logs with external projects and host a central repository of artifacts reachable by all of the URL SCM based jobs. Our public Hudson server also provides CI for the HQApi project and jobs to build HQ plugins, again making it easier to distribute patch fixes in binary form between releases.

Hudson I’ve very impressed! I’m glad the fact that Java won’t run on some of the platforms you want to support hasn’t stopped you from testing anyways. Clearly you folks have written some addition tools behind the scenes, mind discussing them a bit?

Doug Other than some Hudson plugin tweaks and additions, the Perl script I mentioned earlier was converted to generate the majority of our Hudson jobs and includes a simple templating system.  The same script generates jobs to build collectd and a few other projects.  We’ve outgrown this flavor of the script and have started working on integrating Opscode Chef to automate our Hudson configration along with the systems we build and test on. And of course, we’re using Hyperic HQ to monitor our Hudson server instances, agent and node machines.

Hudson But of course, I’d say dog-fooding is an important part of any continuous testing set up. It appears that SpringSource has bought in pretty deeply to a Hudson-oriented workflow, given the amount of time and resources you all have invested in getting the massive farm set up that you have. That said, on a scale from 1-10, how important would you rate Hudson to your day-to-day workflow?

Doug I’d say at least an 8, although my daily workflow doesn’t always directly involve Hudson.  Most of those points go to Hudson for automating what otherwise would be interrupting my workflow on a daily basis.

I&#x27;d like to thank Doug again for giving us a peek behind the curtains at SpringSource and how they&#x27;re using Hudson. If you would like to discuss your organization or company&#x27;s use of Hudson for Continuous Blog, you can contact me at `tyler` at `linux.com`

Editor’s note: Doug was the primary author of mod_perl for many years until he was tricked into &quot;helping out&quot; with a new project.  This project turned into Hyperic HQ which shifted his focus to systems and application management for the past ~7 years and counting.  He occasionally rambles on Twitter as @dougmaceachern.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/26/links-for-2010-02-25/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">26</div></div><h5 class="title">Links for 2010-02-25</h5></div><p class="teaser">Justifying Continuous Integration Expenditure

Our friend the Build Doctor, tries to quantify spending on continuous integration. In the comment thread on another related post of his, he strikes gold with:

People are more expensive than Continuous Integration servers; let’s optimise the system for them.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/02/26/this-week-in-plugins/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">26</div></div><h5 class="title">This Week in Plugins</h5></div><p class="teaser">This week we had 18 plugin releases, with the xUnit plugin managing to have a release almost every day. For this edition of TWiP I was actually able to generate the log of releases mostly automatically thanks to rpetti who contributed the script to the contiuous-blog-tools repository on GitHub.

This past week saw two new plugins, the SSH plugin and the Global Build Stats plugin, the latter of which is still in &quot;alpha&quot;.

Feb 19th, 2010

Perforce Plugin 1.0.21

Feb 20th, 2010

Monitoring 1.12.0

Feb 21st, 2010

Hudson global-build-stats plugin 0.1-alpha1

Hudson Gallio plugin 0.70

Hudson cppunit plugin 1.2

Hudson Emma plugin 1.12

Hudson Backup plugin 1.4.1

Feb 23rd, 2010

Hudson Sonar Plugin 1.3

Hudson Gradle plugin 1.3

Hudson Sectioned View Plugin 1.10

Hudson xUnit plugin 0.6.1

Feb 24th, 2010

Hudson Cpptest plugin 0.3

Hudson SSH plugin 1.0

Hudson ClearCase UCM Baseline Plug-in 1.3

Feb 25th, 2010

Hudson NAnt Plugin 1.3.1

Hudson Ivy plugin 1.1

Hudson Bazaar plugin 1.4

Dimensions SCM plugin 0.7.0<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/01/hudson-1-348-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 1</div></div><h5 class="title">Hudson 1.348 Released </h5></div><p class="teaser">The latest release, 1.348 of Hudson was pushed out to the repositories on the 26th of Feb. This release is primarily a bugfix release containing a number of fixes (listed below) and a few localization corrections

Bugs fixed

Fixed a performance problem of the job/build top page when there are too many artifacts.

Improved /etc/shadow permission checks.

Disable auto-refresh in Groovy script console ( issue 5729)

Contributors

This release of Hudson contained 19 commits from 5 different contributors to &quot;core&quot;:

https://twitter.com/ godin [godin]

kohsuke

swiest

manuel_carrasco

rseguy

As usual, you can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/01/learn-about-ci-with-hudson-sf-java-user-group/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 1</div></div><h5 class="title">Learn about CI with Hudson (SF Java User Group)</h5></div><p class="teaser">A few weeks ago our fearless leader Kohsuke Kawaguchi joined the San Francisco Java Users Group to talk about continuous integration with Hudson. Thanks to Marakana for organizing the meetup, and Aleksandar Gargenta for posting the video and slides, embedded below.

+ ----

Learn About Continuous Integration With Hudson Directly From the Source<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jobs">jobs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/02/call-for-testers-the-older-the-better/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 2</div></div><h5 class="title">Call for Testers: The older the better</h5></div><p class="teaser">A couple weeks ago in the post outlining the release of Hudson 1.347 I mentioned that Alan Harder (a.k.a. mindless) had undertaken a deprecation-crusade; that is to say Alan has taken it upon himself to rid Hudson’s code-base, particularly in the plugin area, of older code. One of Alan’s branches old-data-monitor was merged into trunk with r28147 bringing with it some changes to help migrate older plugin datasets to newer formats.

When I reached out to Alan earlier today on IRC ( #hudson on the Freenode) about the subject he agreed that polling the community for beta testers would be a good idea; this is where you come in. Per Alan’s message to the dev@ mailing list:

Visit your &quot;Manage Hudson&quot; screen to see if the notice about old/unreadable data appears. I’ll be curious to see which of the old deprecated data structures are actually out there in people’s XML files.

Instead of waiting for the release candidate to be packaged Wednesday evening, I’ve gone ahead and published the artifact from build #4544 which can be downloaded here: hudson.war

If you have an old Hudson installation with, testing this build would be incredibly useful. Alan went on to say:

If people find issues with OldDataMonitor, they should file them at issues.hudson-ci.org in &quot;core&quot; component and assign them to &quot;mindless&quot;.

This change does not mutate any data (or at least it shouldn’t) so it should be safe, be on the look out for exceptions in Hudson’s log on startup.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/02/what-new-features-do-you-want-to-see/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 2</div></div><h5 class="title">What new features do you want to see?</h5></div><p class="teaser">Michael Donohue, a Hudson developer who has taken on the role of master bug triage guy for Hudson, does something regularly which I’ve really come to appreciate as a Hudson developer myself: he sends out emails to the dev list with the top 10 voted issues at that time. This gives those of us in the Hudson development community a good sense of what’s really important to our users, which in turn helps us decide where to focus our efforts. If you’re interested, you can see the top voted issues over at our JIRA server.

A good number of those issues have been high on the list for a while - I’m actually in the early stages of work on a plugin to answer HUDSON-682, the current #1 most voted-for issue, two and a half years after it was opened. But I’m sure there are some equally useful features Hudson users would like to see added which aren’t on that list. So I’m asking you, dear readers: what are you looking for in Hudson that isn’t already there? Take a look around the existing issues - you may find a request that fits what you want lurking just out of the top 10, needing only your vote to push it into the spotlight. If no one’s yet created an issue requesting your desired feature, well, create one.

Or, better still, write a plugin or contribute a patch yourself!

Editor’s Note: If you’re interested in writing a plugin, you can check out Hudson’s wiki and/or this guide on the subject.

Andrew Bayer ( abayer) has been a contributor to Hudson since early 2009, contributing to the ClearCase plugin, Hudson’s core and a small number of other plugins. Andrew also helps Kohsuke with a lot of Hudson’s project infrastructure, most notably the migration from Bugzilla on Java.net to JIRA running at issues.hudson-ci.org.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/05/links-for-2010-03-04/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 5</div></div><h5 class="title">Links for 2010-03-04</h5></div><p class="teaser">Since I’ve been a bit pre-occupied with non-Hudson related activities lately, I have missed a few days of link rollups, I suppose it’s fitting to get a couple days worth of links in one post.

While The Build Doctor has the time to follow the continuous integration world and post links on a daily basis, I haven’t found the same quantity of Hudson links on a day-to-day basis. Therefore, I will be posting a link-rollup every few days. Do let me know if this is too infrequent. That said, here’s some interesting links!

That feels better — Cocoa, Hudson and running green

Indie iPhone app developer Jeff Schilling writes about working more efficient with Hudson and Cocoa for developing iPhone apps, he covers OCUnit integration and code coverage with gcovr, a good read for iPhone and Mac developers alike.

Add CI Build Stability to your Sonar Dashboard

Hudson contributor https://twitter.com/ godin [godin] (also known as Evgeny Mandrikov) has released a Sonar plugin to report build stability back into Sonar.

How to get logged-in username in Hudson?

Switching from CruiseControl to Hudson

The developers over at Amaxus wax poetic on reducing their &quot; bus factor&quot; by switching from CruiseControl to Hudson

Integrating Selenium tests with Hudson CI

The folks at InfoStretch have written up a nice, short-and-sweet, overview of getting higher level integration tests built with Selenium to play with Hudson<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/05/tag-team-automating-massive-projects-with-hudson-and-artifactory/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 5</div></div><h5 class="title">Tag team: Automating massive projects with Hudson and Artifactory</h5></div><p class="teaser">For those of you living in or around Silicon Valley, next Wednesday (March 10th) you might want to reserve some space around 6pm on your calendar. Frederic Simon and Yoav Landman from JFrog will be presenting at the Silicon Valley JavaFX Users Group meeting at the Googleplex. Frederic and Yoav will be discussing and demonstrating how JFrog’s Artifactory works with Hudson to combine continuous integration with release management.

Join with the Artifactory team to realize the benefits of managing your software development life-cycle through continuous integration.

Frederic Simon (JFrog Chief Architect) and Yoav Landman (JFrog CTO) will demonstrate how to automate large-scale multi-module projects, using a fully-integrated platform with Artifactory and Hudson.

Using Maven, Gradle or Ivy builds, it is now possible to dynamically automate and manage the pyramidal stacks of Unit, Functional, and Integration Tests.

This demo-based session will show you how Artifactory and Hudson together make it much easier to promote certified builds to milestone releases , and finally to general availability, while making sure all builds are fully reproducible.

Staying dynamic all through the development process avoids code freeze and provides very accurate feedback loops. This is crucial for Developers, QA teams, System and Integration testers, Users, Customers, and all the remaining actors of the development process.

If you’re interested in attending, you can RSVP on the meetup page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/07/this-week-in-plugins/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 7</div></div><h5 class="title">This Week in Plugins</h5></div><p class="teaser">A little late, but this past week we released 19 plugins including one new release, the Libvirt Slaves.

Feb 28th

Accurev plugin 0.6.10

Mar 1st

Subversion Release Manager plugin 1.1

Clover plugin 2.6.3

SCTMExecutor 1.5

global-build-stats plugin 0.1-alpha3

Mar 2nd

ClearCase UCM Baseline Plug-in 1.4

Accurev plugin 0.6.11

JIRA plugin 1.20

Mar 3rd

NAnt Plugin 1.4.1

Edgewall Trac plugin 1.10

NCover plugin 0.3

nabaztag 1.7

Mozmill Plugin 1.3

Mantis plugin 0.9

Harvest SCM 0.3

Subversion Plug-in 1.12

Mar 4th

Performance Publisher plugin 7.96

Artifactory Plugin 1.0.7

Mar 5th

Perforce Plugin 1.0.23

Mar 6th

SCTMExecutor 1.5.1

Mar 7th

Libvirt Slaves plugin 1.0

Emma plugin 1.13<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/08/hudson-1-349-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 8</div></div><h5 class="title">Hudson 1.349 Released</h5></div><p class="teaser">Last Friday, March 5th, Hudson 1.349 was pushed out into the wild with an even split of bug fixes and enhancements. Included in this release is Alan Harder’s (a.k.a mindless) old data monitor code, discussed previously in the post &quot; Call for Testers: The older the better.&quot; Included in this release were further updates to the japanese and german localizations of Hudson; if you’re interested in helping localize Hudson into more languages you can join the effort via the Internationalization page on the wiki.

Now for the breakdown of the 1.349 release:

Bug fixes

Fix deserialization problem with fields containing double underscore. ( issue 5768)

Fix deserialization problem for Exception objects where the XML has bad/old data. ( issue 5769)

Fix serialization problem with empty CopyOnWriteMap.Tree. ( issue 5776)

Fixed a bug that can cause 404 in the form validation check.

Enhancements

Remote build result submission shouldn’t hang forever even if Hudson goes down.

Added a monitor for old or unreadable data in XML files and a manage screen to assist in updating files to the current data format and/or removing unreadable data from plugins that are no longer active. &quot;Manage Hudson&quot; page will show a link if any old/unreadable data was detected.

Added a mechanism to bundle init.groovy inside the war for OEM. ( report)

Added an extension point to annotate console output. ( issue 2137)

Contributors

Hudson 1.349 contains 43 commits from 6 contributors, due to the merging in of Alan Harder’s old-data-monitor branch the commit count is a bit off from the amount of code change that actually went out in 1.349.

abayer

kohsuke

mindless

sogabe

swiest

wyukawa

As usual, you can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/08/meet-up-and-hack-alongside-kohsuke-and-co/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 8</div></div><h5 class="title">Meet-up and Hack alongside Kohsuke and Co.</h5></div><p class="teaser">Ever wanted to pick the brains of multiple Hudson developers and users, all at the same time? Feel like finally meeting Kohsuke in person? Now’s your chance!

We’re hosting our second-ever Bay Area Hudson Hackathon/Meetup on March 19th and 20th. That’s nearly two whole days of Hudson!

Day One (Mar. 19)

The first day of the hackathon/meetup is aimed primarily at those working with Hudson’s core, or are building on top of Hudson (plugins, etc).

Start: 10 a.m.

End: 5 p.m.

Location: Oracle Santa Clara campus in the &quot;library&quot; conference room of SCA7 &quot;Mansion&quot; building.

There will a number of community and corporate Hudson hackers joining us on Friday, so bring everything you’ll need to get some grade A hacking done with Kohsuke, Andrew Bayer, Alan Harder and your fellow plugin hackers.

Day Two (Mar. 20)

I’m tentatively calling this the main event, which will be hosted at the delightful Hacker Dojo in Mountain View. The &quot;main event&quot; will carry over the hackathon from the day before at Oracle, into a full blown community hackathon and meet-up. This is for Hudson hackers and users alike!

Start: 10 a.m.

End: 6 p.m.

Location: Hacker Dojo (Savanna room)

As I’ve pointed out before, Hudson’s getting a lot of attention in other developer circles such as the Python, Ruby, Cocoa communities. As such, I’m hoping to get a lot of folks interested in using Hudson to come to Hacker Dojo where we (already being Hudson users) can help get them up to speed with all the great things Hudson can do.

If you’re interested please RSVP:

Via the hackathon page on the wiki

Via Facebook for day one and day two

How you can help

While I casually refer to myself as a &quot;PR intern&quot; for Kohsuke, I’m technically a busy software engineer, meaning I’m grateful for all the help I can get.

Get the word out

The best way to help get the word out is to talk about Hudson and the meetup, this includes:

Link to this post on Twitter

Ping any user groups you are a member of in the area

Blog about it

Let your co-workers know about it

Attend!

Volunteer to help setup/teardown

Hosting the Saturday event at Hacker Dojo does carry some responsibilities with it. We will need some extra hands to make sure everybody has power, refreshments are chilled, lunch is ordered and delivered, and of course, cleaning up after we leave. If you’re in a generous mood, or in a real need for some karma, sign up to help on the bottom of the wiki page

I am hoping Oracle and some other heavy users/contributors will kick in a few bucks for lunch and drinks on Saturday, if you think your company can help us out, feel free to ping me directly at tyler at linux.com.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/09/one-month-of-continuous-blog/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 9</div></div><h5 class="title">One month of Continuous Blog</h5></div><p class="teaser">It’s been a little over a month since I pinged Kohsuke about an &quot;official Hudson blog&quot;; my role has been nothing more than writer and editor of a community resource, while I have invested a lot of time in Continuous Blog it is not &quot;mine&quot; so much as it is &quot;ours.&quot; I feel I have a responsibility as the current maintainer of this resource to be as open as possible about what’s going on with CB. When I sat down to write the inaugural post, Welcome to Continuous Blog, I set forth a few goals:

Help advocate the use of Hudson to the larger internet community

Be a central source for tutorials and helpful information to Hudson users of all skill-levels

Recognize the numerous contributors to the Hudson project for their efforts

Being a community resource, I wanted to review our progress on those goals along with some other interesting details about Continuous Blog and my community efforts. My metrics for achieving these goals are largely based on web traffic to this blog and retweets via the @hudsonci twitter account. First a minor overview of some of Continuous Blog’s traffic, then I’ll get to reviewing the goals.

Visitor trend via Google Analytics

Over the past month Continuous Blog has seen just under 10,000 visits from a number of different sources, the top sources being:

Feedburner links posted to @hudsonci

Direct visits

Feedburner

Referrals from the &quot;blog&quot; link on hudson-ci.org

reddit

Links from the Java.net community portal and associated weblogs

In addition to general web traffic, Continuous Blog has around 350 RSS subscribers.

To put these numbers into perspective, Hudson has seen commits from 173 different developers and the @hudsonci twitter account has about 1,100 followers.

Hudson Advocacy

Looking at the traffic sources and the volume of traffic coming from what I would consider &quot;the wider internet community&quot; I’d say I failed to meet my own expectations. The majority of traffic seems to be coming from &quot;within the community&quot;, which is certainly not a bad thing by a stretch, but I was hoping to start to see more visitors who are less likely to be using Hudson already. There are signs of this (I think) in the low number of search referrals, roughly 370 visits. To me this indicates the early age of this site, small number of external links to Continuous Blog and the content isn’t &quot;interesting&quot; enough to come up in searches for terms like &quot;continuous integration with python&quot;.

The vector for improvement in advocacy, in my opinion, is to focus more on tutorials and user guides in the next month. Mike Rooney’s post on Keeping your configuration and data in Subversion was both discussion provoking, but one of the more visited pages over the past month. I’ll be reaching out to more power-users from differing backgrounds to try to get some more tutorials on using Hudson for Python, Ruby, and Cocoa development while continuing to bug some of you Maven2 pros about guides.

Central information repository

I feel I failed to meet my own expectations here as well, it has only been a month (feels like an eternity!) so the amount of information we’ve been able to aggregate is small, but growing.

I have likely spent too much time covering Hudson community news, which I feel is important, to put a human voice in front of commits and releases, but it is not what I originally intended to spend the majority of my time doing.

Recognition of contributors

In my opinion, this goal I’ve met. When writing up each Hudson release I’ve made certain to give credit where credit is due, to those that contributed, Through the &quot;spotlight&quot; series of posts I’ve also made an effort to highlight power-users of Hudson, trying to glean interesting details about their installations from them for our benefit. Unfortunately I’ve done a poor job highlighting the contributions from individual plugin developers, something I’m still not certain how to correct.

Content

If you’ve been following the blog you have no doubt noticed the regular occurrence of certain types of posts, these regular series are:

&quot;This Week in Plugins&quot;

This post is halfway script generated, pulling all the release details out of SVN history to help me generate a post. The intention of the post being to cite new or notable plugins, while giving an informative listing of &quot;what’s happening&quot; in plugin development for the past week.

&quot;Spotlight On&quot;

The only interview-formatted series I’ve got going right now, I’ve been trying to find companies or organizations who are using Hudson in interesting ways and are willing to let &quot;us&quot; peek behind the curtains a bit. This started more from curiosity, but I think it’s fun to let Hudson users brag about their set ups.

Hudson 1.xxx Released

Pretty straight-forward reporting on a release of Hudson, depending on the contents of the release there may be some calls to action or editorializing on what’s gone into the release.

Links for

Roll-up of links shared or retweeted via the @hudsonci account, uncertain whether this is worth the time spent.

My two questions to the community in general would be:

Do you dislike any of these?

What else would you like to see on a regular basis?

I’m certainly open to suggestion, I’d like Continuous Blog to continue to be interesting to the Hudson community and if certain kinds of posts are boring or uninteresting, I can cut them from the line-up.

Challenges

The largest challenge of Continuous Blog is time. As it stands the majority of content I write or edit in some capacity, which is a larger amount of time than I expected to spend. All said and done it takes me between 6-10 hours a week to write for CB, keep tabs on @hudsonci and peruse the mailing list for interesting things. This probably isn’t maintainable, and if for some reason a bus hits me ( not uncommon around here), this blog would go dark for a while.

This can be easily fixed by simply adding more contributors to the blog, I’ll post more on how to write for Continuous Blog in another post.

All said and done, I am looking forward to another month of writing and following the Hudson community. I’m grateful for all those who’ve asked questions, been interviewed, wrote content and participated in discussion in the comments. For those of you in the Bay Area, I do hope you come out for the meet-up in mid-March, for the rest of you, I’ll catch you on IRC :)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/12/links-for-2010-03-12/"><div class="header"><div class="date"><div class="month">March</div><div class="day">12</div></div><h5 class="title">Links for 2010-03-12</h5></div><p class="teaser">Been a bit pre-occupied this week, so this links roll-up is short and sweet.

The JavaDude details a fairly simple test application embedding Glassfish + Netbeans + Hudson

Thanks to @chrisbingham, discovered a.NET wrapper for Hudson’s remote API

Learned all about getting started with Hudson for .NET projects from Bob Cravens

Robert Fletcher wrote a groovy post about testing Grails plugins on Hudson.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/12/want-some-hudson-stickers/"><div class="header"><div class="date"><div class="month">March</div><div class="day">12</div></div><h5 class="title">Want some Hudson stickers?</h5></div><p class="teaser">Rarely do I ever get mail, let alone mail I like, so I was quite excited when a shipment of stickers from Hudson HQ arrived yesterday.  I’m certain you’re thinking to yourself &quot;what does this guy need hundreds of Hudson stickers for?&quot; Fact is, I don’t! They’re not for me, they’re for you!

I am willing to mail stickers vast distances to you ( with some conditions)

Conferences

If you’re presenting at a conference or otherwise would like some Hudson stickers to go around, email me with a rough estimate of how many you need. The only condition being that you tell me all about the event and how Hudson was received after the fact (this may involve an interview).

User Groups

If you email me requesting some stickers for a user group, I’ll need an estimate of how many folks attend meetings. Depending on supplies, I may send you a little more than requested to be shared.

Companies

If your company wants some Hudson stickers, I’d be happy to oblige, and of course I always appreciate stickers, pens, branded bouncy balls, etc (see: swag) in return!

People who like stickers

If you’re just a fan of Hudson, stickers, or both, I’ll still gladly mail you a few stickers with the condition that you take pictures of where the stickers end up (and maybe of your Hudson install) and either email me some cool pictures or post them to Flickr (tagged: &quot; hudsonstickers&quot;)

I will be stuffing envelopes in my free time, so there may be a slight delay. You can email me at tyler at linux dot com requesting stickers, I’ll need:

How many: (estimate)
What for: (conference|usergroup|company|iwantsomeokay)
Mailing Address:<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/13/this-week-in-plugins/"><div class="header"><div class="date"><div class="month">March</div><div class="day">13</div></div><h5 class="title">This Week in Plugins</h5></div><p class="teaser">Apologies for the slight delay in posting another TWiP, both within the Hudson community and outside of it, it was quite a busy week. This past week we’ve had roughly 15 plugins released, with a few going through a number of iterations over the course of the week such as the Emma plugin and one of Hudson’s newest plugins, the Libvirt Slaves plugin.
One of Hudson’s most active contributors, Alan Harder (a.k.a mindless) was responsible for this week’s only new plugin: Copy Artifact Plugin. The Copy Artifact plugin does exactly what you’d think it does, according to the short-and-sweet wiki page:

Adds a build step to copy artifacts from another project.

If you’re a plugin developer in the Bay Area, this upcoming Friday and Saturday is the Bay Area Hudson Hackathon/Meetup; don’t miss out!

Mar 07, 2010

Copy Artifact Plugin 1.0

Emma plugin 1.15

Mar 08, 2010

CAS protocol version 1 plugin 1.0.1

Copy To Slave Plugin 1.2

Emma plugin 1.16

Libvirt Slaves plugin 1.1

Sidebar Link 1.4

Subversion Plug-in 1.13

Mar 09, 2010

Emma plugin 1.17

Mercurial plugin 1.26

Mar 10, 2010

Libvirt Slaves plugin 1.2

Mar 11, 2010

File System SCM 1.7

Mar 12, 2010

Perforce Plugin 1.0.24

Mar 13, 2010

IRC Plugin 2.2

Jabber notifier plugin 1.6

Sonar Plugin 1.4

global-build-stats plugin 0.1-alpha4

instant-messaging plugin 1.5<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/14/would-you-like-to-ok/"><div class="header"><div class="date"><div class="month">March</div><div class="day">14</div></div><h5 class="title">Would you like to, OK</h5></div><p class="teaser">As Matt Brown pointed out on the dev@ list, Hudson made a cameo on The Daily WTF in their post Nobulation Fail.

Kohsuke went on to mention on the mailing list:

Looks like this one is already fixed back in October last year.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/15/breaking-hudson-1-351-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day">15</div></div><h5 class="title">Breaking! Hudson 1.351 Released</h5></div><p class="teaser">Rush delivery from Hudson HQ! Hudson 1.351 just rolled out with a very important regression fix:

Regression in 1.350 that can delete old build artifacts. ( mailing list thread, issue 5937)

Sorry for the hiccup everybody, we’re working pretty hard on getting a better, more stable, release process in place.

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/15/hudson-1-350-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day">15</div></div><h5 class="title">Hudson 1.350 Released</h5></div><p class="teaser">Finishing off the second week in March, the Hudson team rolled Hudson 1.350 off the assembly line last Friday, bringing a slew of fixes. Of particular interest to users of Hudson’s various native packages for Red Hat, openSuSE, Ubuntu/Debian and Solaris, was a change that suppress the &quot;self-upgrade&quot; functionality in the &quot;Manage Hudson&quot; page. On the enhancements side of the fence, the team added authentication support to the Hudson CLI ( issue 3796) allowing Hudson users with locked down installations to take advantage of everything the CLI has to offer.

Internal to Hudson, some more changes from Alan Harder (a.k.a mindless, a.k.a The Garbage Man), deprecating or otherwise removing deprecated APIs. Alan’s been doing some great work on Hudson’s internals, if you’re coming out to this weekend’s hackathon, but sure to pat him on the back for his tireless efforts.

Bug fixes

Fix handling of relative paths in alternate settings.xml path for Maven projects. ( issue 4693)

Alternate settings, private repository, profiles, etc were not used in embedded Maven for deploy publisher. ( issue 4939)

Make editableComboBox work in repeatable content, such as a build step.

If content is captured using ..content.. , fixed this to use proper HTML rendering when appropriate.

&#x27;&lt;&#x27; and &#x27;&amp;&#x27; in the console output was not escaped since 1.349 ( issue 5852)

Fixed an AbstractMethodError in SCM polling under some circumstances. ( issue 5756)

Fixed a ClassCastException in the Subversion plugin - now using Subversion plugin 1.13. ( issue 5827)

The Maven Integration plugin link in the Update Center was going to a dead location. ( issue 4811)

On RPM/DEB/etc installation, don’t offer the self upgrade. It should be done by the native package manager. ( report)

Fixed a possible lock up of agents.

Enhancements

Added advanced option to LogRotator to allow for removing artifacts from old builds without removing the logs, history, etc. ( issue 834)

Authentication support in Hudson CLI. ( issue 3796)

Added console annotation support to SCM polling logs.

Contributors

The 1.350 release of Hudson contains 54 commits from 6 different contributors,

abayer

jglick

kohsuke

manuel_carrasco

mfriedenhagen

mindless

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/16/slaves-building-robots/"><div class="header"><div class="date"><div class="month">March</div><div class="day">16</div></div><h5 class="title">Agents building robots</h5></div><p class="teaser">A few weeks ago we covered building Android apps with Hudson thanks to a very informative post by Hugo Visser, ever thought about building Android itself with Hudson? Sony Ericsson apparently has, Continuous Blog reader and Hudson user Christopher Orr sent me this screen shot from his recently purchased Sony Ericsson Xperia X10 mini, notice the &quot;Kernel version&quot; field. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/x10-mini-hudson.png

If you’ve got screen shots or photos spotting Hudson out in the big blue room, drop me an email at tyler at linux dot com<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/19/get-excited-and-make-things/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Get excited and make things</h5></div><p class="teaser">The day of hackery is upon us! Today is Day One of the Bay Area Hudson hackathon/meetup, the hacking will start at 10am today and continue until 5pm at the Oracle Santa Clara campus in the &quot;library&quot; conference room of SCA7 &quot;Mansion&quot; building. The focus today will be largely on hacking Hudson itself.

Can’t attend?

Not everybody lives in the Bay Area, fortunately all of you are on the internets! There’s two ways you can participate remotely in the hackathon:

WebEx: Meeting Number: 201 389 367, Password: hudson (audio conference, app sharing, etc)

IRC As always, there’s the #hudson IRC channel on the Freenode where you can participate via text chat

If you’re in the Bay Area, but busy at work today, come by for Day Two of the hackathon/meetup tomorrow (Saturday) from 10am to 6pm at Hacker Dojo in Mountain View!

Friday Agenda

Currently there is only one item on the agenda for Friday:

Improving Client-Side Code Quality with YUI 3: A Proposal (by: Benjamin Shine)

Image courtesy of blackbeltjones

Update : The WebEx link for today has been corrected.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/19/links-for-2010-03-19/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Links for 2010-03-19</h5></div><p class="teaser">It’s been quite a busy week, preparing for the Bay Area Hudson hackathon/meetup which starts today, receiving requests for crazy-awesome Hudson stickers and my day job. Regardless, I’ve stumbled across a few links to share in this links roll-up.

John Ferguson Smart discusses some of the gotchas with migrating Hudson build jobs from one server to another

Learned a bit about how Kim Moir and the Eclipse Foundation are &quot;building better&quot; with Hudson

dbaktiar gave a quick overview of installing Hudson on Ubuntu Karma Koala

Looking forward even more interesting things to read next week after the hackathon and meetup here in California.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/19/recap-of-hackathon-part-one/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Recap of Hackathon Part One</h5></div><p class="teaser">Kohsuke just posted a brief write-up on his personal blog about the first day of the Bay Area Hudson hackathon/meetup. He writes:

Total of 9 people came and we had a great time talking about infrastructure issues, possible enhancements, design dicussions, exchanging tips and plugins that they’ve developed, and otherwise building personal relationships.

A number of folks joined us on the #Hudson IRC channel on Freenode and the WebEx conference, participating remotely. Since day one was primarily intended for hacking on Hudson itself, we’re expecting more people tomorrow when we’ll have a good mix of folks hacking on Hudson, folks hacking with Hudson and plain old folks. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/HackathonDay1.jpeg<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/22/hudson-1-352-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day">22</div></div><h5 class="title">Hudson 1.352 Released</h5></div><p class="teaser">After an exciting week that saw the rushed release of Hudson 1.351 on Monday following a fairly serious regression, Hudson 1.352 was released mid-Friday with a good mix bug fixes and enhancements. Bundled with this release was another localizations drop including translations for ca, es, fi, fr, hi_IN, it, nl, ru, and sv_SE locales. In addition to the nice fancy new community contributed translations, which you can help with by installing the Translation Assistance plugin, the 1.352 release includes the subtle enhancement of hyperlinking URLs in the console output.

In general, 1.352 is looking like a very solid release, that said, here’s the breakdown for this release:

Bugs fixed

Fixed a file handle leak when a copy fails. ( issue 5899)

Replace &#x27;&gt;&#x27; with &#x27;_&#x27; in username, as already done for &#x27;&lt;&#x27;. ( issue 5833)

Fix editableComboBox to select item when mouse click takes more than 100ms. ( issue 2722)

Fixed NPE when configuring a view without &quot;Regular expression&quot;.

Page shouldn’t scroll up when the user opens/closes a stack trace in the test failure report.

Fixed a bug where Hudson can put a wrong help file link. ( report)

Fixed Maven site goal archiving from agents. ( issue 5943)

Fixed a regression with NetBeans Hudson plugin progressive console output. ( issue 5941)

Fixed a situation where a failure in plugin start up can prevent massive number of job loss.

Enhancements

Supported JBoss EAP 5.0.0 GA. ( issue 5922)

CLI commands on protected Hudson now asks a password interactively, if run on Java6.

Added CLI &#x27;login&#x27; and &#x27;logout&#x27; commands so that you don’t have to specify a credential for individual CLI invocation.

URLs in the console output are now hyperlinks.

Improved the URL annotation logic.

Add drag&amp;drop support for f:repeatable lists and use this for the JDK/Ant/Maven installations in global config so these can be reordered.

Integrated a new round of community-contributed localizations (ca, es, fi, fr, hi_IN, it, nl, ru, and sv_SE locales.)

Contributors

This release contains 63 commits, from six different contributors including our very own Subversion-loving Mike Rooney (mcrooney).

abayer

jglick

kohsuke

mcrooney

mindless

sogabe

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/23/links-for-2010-03-23/"><div class="header"><div class="date"><div class="month">March</div><div class="day">23</div></div><h5 class="title">Links for 2010-03-23</h5></div><p class="teaser">While I work on some screencasts and start to get more&quot;Spotlight&quot; interviews lined up, I figured it’s time for a link roll-up for your Tuesday morning reading.

We caught a glimpse of a little Java scoreboard app for Hudson from @davefollett

Matt Patterson of Reprocessed.org wrote a great post on continuous integration with Rails with Hudson, running both Rspec and Selenium tests.

At the hackathon at Hacker Dojo on Saturday, Kohsuke pointed us all to the Hudson Cafe Press store, where he gets all his Hudson threads.

C.J. Adams-Collier seems quite pleased to have builds for IronRuby back online , powered by Hudson.

We got a sneak-peak into the first chapter of John Ferguson Smart’s Continuous Integration with Hudson book.

Ben Shine showed off some of his UI mock-ups for Hudson.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/27/this-week-in-plugins/"><div class="header"><div class="date"><div class="month">March</div><div class="day">27</div></div><h5 class="title">This Week in Plugins</h5></div><p class="teaser">I apologize for the lack of posts this week, I’ve been quite pre-occupied and a quirk in the twipFromSvn.py script prevented the generation of this post’s contents earlier; thanks to rpetti it works again!

This week was an interesting week in plugin development, a slight regression in the release of Jabber notifier plugin 1.7 resulted in the rapid release of a 1.8 release by kutzi. The Fitnesse plugin saw multiple releases again this week, along with the Libvirt Slaves plugin which has seen an amazing number of releases since it burst onto the plugin scene two weeks ago.

There were a few new and notable plugins released this week such as the iPhoneView plugin which adds a fancy view to make checking Hudson all that prettier on an iPhone or iPod Touch, the cross-platform shell plugin was released, aiming to solve the problem of running a job on both Windows and Unix agents. My favorite new plugin release this week has to be the Gerrit plugin which made its debut and shows a lot of potential to enable the &quot;pre-tested commit&quot; workflow with Git and Gerrit

Mar 20, 2010

Fitnesse plugin 1.2

Labeled Test Groups Publisher 1.2.6

Libvirt Slaves plugin 1.3

Monitoring 1.13.0

Perforce Plugin 1.0.25

iPhoneView plugin 0.1

instant-messaging plugin 1.6

Mar 21, 2010

Fitnesse plugin 1.3

Ivy plugin 1.4

Mar 22, 2010

Buckminster 0.9.4

Cobertura plugin 0.8.11

Fitnesse plugin 1.3.1

Gerrit plugin 0.1

JIRA plugin 1.21

Maven Release Plug-in nexus helper 0.0.3

Nested View Plugin 1.1

Performance plugin 1.2

Sonar Plugin 1.5

Subversion Plug-in 1.15

Translation Assitance plugin 1.4

Mar 23, 2010

Subversion Plug-in 1.16

nabaztag 1.9

Mar 24, 2010

Buckminster 0.9.5

Jabber notifier plugin 1.8

Mar 25, 2010

https://www.collab.net/[CollabNet] Plugins 1.1.4

CVS Plug-in 1.1

Dashboard View 1.4

Libvirt Slaves plugin 1.4

Perforce Plugin 1.0.26

Mar 26, 2010

CMake plugin 1.2

GNAT plugin 0.2.2

Groovy Postbuild 1.2

cppunit plugin 1.3

cross-platform shell plugin 0.2<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/30/resurgence-of-releng/"><div class="header"><div class="date"><div class="month">March</div><div class="day">30</div></div><h5 class="title">Resurgence of Releng</h5></div><p class="teaser">A few weeks ago I passed a job listing that I had found through one of my many Google Alerts for Hudson-related queries to Andrew ( abayer), following up on one of those job listings Andrew recently signed an offer to join the nice folks over at Digg to be their resident &quot;build guy.&quot; On its own I thought &quot;great for Andrew!&quot; and nothing more, then I saw this thread on reddit which poses the question:

Anyone here a build engineer, or part of the build team? Could you please share your experience?

It seems, to me at least, the notion of &quot;release engineering&quot; is making a come-back, particularly in the aging &quot;Web 2.0&quot; world where companies like Digg, Facebook, Reddit, Twitter, etc are anywhere from five to ten years old. As these companies have aged a couple of important things have happened, their code-base has aged increasing the possibility of bitrot, but they have also expanded in terms of headcount. Start-ups that might have once slighted larger corporations like Oracle, Cisco VMWare and IBM for their burdensome process and longer release schedules now find themselves ensnared with massive code bases, larger development teams and complicated deployments. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/hudson_vs_buildbot.png

Over the past few months we’ve seen Hudson being used in a number of different contexts, it was pitched at PyCon as part of a larger appeal to the Python community to get on the continuous integration bandwagon, we’ve seen a few posts from developers using Hudson for testing and packaging Android and iPhone apps, .NET developers are jumping on board as well. Across the board it feels like Hudson is being more and more widely used, it is no longer the mainstay of the Java shop’s toolkit, it’s become a must have for all developers.

With the allure of continuous deployment and Hudson’s lowered barrier to entry for testing, packaging and automating releases, is release engineering making a comeback?<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/31/hudson-1-353-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day">31</div></div><h5 class="title">Hudson 1.353 Released</h5></div><p class="teaser">This week’s release comes slightly later than usual and is mostly a clean-up of a few bugs. Due to a problem with the Kohsuke’s GitHub mirror of Hudson’s core, I can’t mine the commits for interesting information as per usual so you’ll just have to trust that Hudson 1.353 is chock full of good, wholesome bug fixes. If the problem persists next week, I’ll find a better way to dig up information on particularly releases that doesn’t depend on the GitHub mirror.

Bugs fixed

Tagging a repository can result in NPE.

Fix possible form submission error when using multiple combobox elements. ( issue 6025)

Better escaping of test case names in test results pages. ( issue 5982)

Make radio buttons work in repeatable content, such as a build step. ( issue 5028)

Fixed the handling of verifying that the POM path entered for Maven projects exists. ( issue 4693)

Enhancements

Added link to builds in buildTimeTrend ( issue 3993)

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/03/31/screencast-python-on-hudson-part-1/"><div class="header"><div class="date"><div class="month">March</div><div class="day">31</div></div><h5 class="title">Screencast: Python on Hudson (Part 1)</h5></div><p class="teaser">After Hudson got some major publicity at PyCon Atlanta 2010 I haven’t been as quick as I would have liked with Python-related posts and tutorials. I use Hudson to build and test a number of pure Python modules and C extensions across numerous Python versions (covering 2.4 - 3.1). For most beginners, or those simply looking to get started with Python on Hudson, starting with my job configurations is too much at once, so instead I wanted to start at the &quot;beginning&quot; so to speak.

The trouble with getting people started with Hudson, given how simple and visual it is to use, is that articles with sample configurations are not particularly useful; a screencast however is a good medium for visually walking somebody through Hudson. The screencast below ( also on YouTube) is the first in a series of screencasts I’ll be doing, not only for Python on Hudson, but for Hudson overall. It is just over four minutes long, and covers setting up a simple continuous integration job for the Eventlet library (which is hosted on Bitbucket)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jobs">jobs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/01/announcing-the-hudson-2-0-roadmap/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 1</div></div><h5 class="title">Announcing the Hudson 2.0 Roadmap</h5></div><p class="teaser">/https://agentdero.cachefly.net/continuousblog/java-evil-edition.png&quot; alt=&quot;java evil edition&quot;&gt; There have been numerous discussions on the mailing lists over the past couple months regarding memory issues, speed regressions and a number of other issues regarding performance of Hudson, particularly under high load. In an effort to address these concerns, the Hudson core team has https://web.archive.org/web/ /https://agentdero.cachefly.net/continuousblog/just-kidding.jpg[announced] a roadmap for Hudson 2.0.

In a message to the dev@ mailing list, Kohsuke said of Hudson 2.0:

As it stands now Hudson 1.0 is a good proof of concept, it’s time to take the lessons learned and build a truly solid enterprise-ready continuous integration server
Some notable points from Kohsuke’s announcement with regards to the Hudson 2.0 roadmap, which is expected to ship late Q4 2011, are:

Implementation of core in portable C for greater speed and code readability

Selection of a better license, namely the WTFPL

Revamped storage architecture around the Oracle 11g Database to provide more optimal synergy over flat XML files.

Embedding the Mono, Python, V8 and Lua engines allowing plugins to be written in C#, Python, JavaScript or Lua.

Adoption of the Hudson Eagle as a mascot instead of the butler

&quot;Social&quot; support will be merged into core, integrating Hudson directly with Facebook so you can share test failures with your friends.

Hudson 2.0 is expected to follow in the intrepid footsteps of other major revamps such as Netscape 5 and Perl 6 in its ambitiousness and innovation.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/01/regarding-the-start-of-april/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 1</div></div><h5 class="title">Regarding the start of April</h5></div><p class="teaser">I had briefly contemplating what sort of silly posts I could write to celebrate April Fool’s Day, when I sat down to write out some of them, I got a few sentences in and decided that they just weren’t funny enough. Either I have very high standards, or I’m terribly unfunny.

The web is awash with April Fool’s articles, comics, headlines and everything else, so instead I’m going to just give you a few useful links.

A couple of Twitter links

Besides the @hudsonci account, you can also follow a couple of Hudson’s more notable (or was it notorious?) hackers, such as our benevolent dictator, Kohsuke Kawaguchi. Ben Shine from Yahoo! who’s been working pretty hard on making Hudson prettier. Then there’s John Ferguson Smart who’s been working on a Hudson book. Of course I’ve tried to collect as many Hudson contributors as possible in the @contributors Twitter list.

Hacking Hudson

When starting to hack Hudson, it’s useful to start by understanding how to build Hudson. If hacking Hudson’s core isn’t your cup of tea, you can always start with the plugin tutorial and try your hand at writing another awesome Hudson plugin. If you find yourself struggling to find out what methods do what while you’re hacking, you can always visit the regularly updated, online Javadocs for Hudson

Communicate
The two primary mediums for communicating with the Hudson community are through the mailing lists and the IRC channel. During &quot;regular business hours&quot; for the pacific standard time zone, you can usually get some decent real-time help or answers to most of your queries.

I’d list more, but I’m too busy reading about Google’s nuclear weapons program. ;)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/07/kohsuke-leaves-sun/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 7</div></div><h5 class="title">Kohsuke leaves Sun</h5></div><p class="teaser">Those of you on the users@ or dev@ mailing lists have likely already read that Kohsuke ( left in the photo), the founder of the Hudson project, is leaving Sun. I say that he is leaving Sun, instead of leaving Oracle as Kohsuke worked at Sun for nine years and Oracle only a few months. In those nine years at Sun, Kohsuke has worked on some great products, the most notable of them being Hudson.

Per Kohsuke’s post:

Where am I heading next? I’m actually starting my own company to take Hudson to the next stage.

What this means for Hudson still isn’t certain yet, fortunately it means that Hudson will continue to have at least one full-time developer. It remains to be seen where KohsukeCorp (the name has not yet been disclosed) will focus within the Hudson code-base. For the greater user-base of Hudson, this means that the schedule for releases may slow down during this transitional period, there are some logistics to work out with Oracle regarding some of the hardware Hudson has traditionally used to host JIRA, this blog, and a number of other machines helping support the Hudson project in one fashion or another.

The next couple of months will be interesting for the Hudson community; as per usual you’ll be able to get the latest updates from this blog or the @hudsonci twitter account. I’ll let Kohsuke finish this post off:

And finally, big thank you to everyone in the Hudson community, and in a broader java.net community. I wouldn’t be here without you guys, and I feel very proud that I’m a part of it.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/12/pre-tested-commits-with-git/"><div class="header"><div class="date"><div class="month">April</div><div class="day">12</div></div><h5 class="title">Pre-tested commits with Git</h5></div><p class="teaser">At the first Bay Area Hackathon in mid-2009, the topic du jour was &quot; pre-tested commits.&quot; As potential implementations of the concept were discussed over burgers from Brickhouse in downtown San Francisco, we realized as a group a few things: first, those burgers were delicious, but more importantly: pre-testing commits is very-SCM dependent and involves a lot of moving parts. One of the positive changes that came out shortly after the meet up was the support for &quot;Concurrent Builds&quot;, allowing a job to be executed concurrently on different agents, a precursor to pre-tested commit support. Fervor for the pre-tested commit feature lowered as time went on, the feature being too dependent on the SCM itself was generally accepted as the reasoning behind the feature languishing.

Chances are the feature is in fact too large for Hudson to support alone. It requires Hudson, the SCM and likely a third tool to work in concert together to perform such a feat.

With Git, and the phenomenal code review tool Gerrit, and the Gerrit plugin by intrepid plugin developer, Jyrki Puttonen, pre-tested commits with Hudson, Git and Gerrit are possible.
For Git users more familiar with the distributed Git workflows, working with Gerrit should seem familiar. Gerrit has JGit, a Java implementation of Git embedded within it, along with an sshd stack, meaning Gerrit can masquerade as a &quot;regular&quot; Git remote repository. Developers can push and pull to the repository just as they can with any other Git repository (provided they have permissions of course). I won’t delve too much into using Gerrit specifically here, but the pre-tested workflow with Gerrit and Hudson would look something like this:

Dev creates a topic branch to work on a change

Code is written (and hopefully tested) and committed locally

Dev pushes commit(s) to Gerrit

Hudson job (set to Poll SCM) picks up the patch, runs the job and marks it as &quot;+1 Verified&quot; or &quot;-1 Fails&quot;

If the job fails or is unstable, the change should be reworked or corrected (typically with git-rebase(1))

If Hudson says the change is good to go, it can be cherry-picked or pulled directly from Gerrit.

For example: image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/gerrit_patch.png

To learn more about Gerrit, check out the project page on Google Code; information on the Gerrit plugin can be found on the wiki.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jobs">jobs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/16/a-new-blog-for-kohsuke/"><div class="header"><div class="date"><div class="month">April</div><div class="day">16</div></div><h5 class="title">A new blog for Kohsuke</h5></div><p class="teaser">Historically, our fearless leader Kohsuke has blogged on Java.net. The setup made a whole lot of sense when Kohsuke was employed by Sun, then Oracle, which sponsors and runs Java.net. In a post earlier this week discussing console markups, Kohsuke casually pointed out that he will be cross-posting to Java.net, and his personal blog located at kohsuke.org. The first post over on Kohsuke.org welcomes us:

For the longest time I haven’t really done anything about kohsuke.org, but as I left Sun/Oracle, I decided to put a bit more effort into it. So this is the new home.

For the time being, I plan to post my blogs both on java.net and here.

If you’re a reader of feeds, I recommend adding the rss feed for the blog to your list of interesting continuous integration/hacker feeds.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/16/hudson-1-354-released/"><div class="header"><div class="date"><div class="month">April</div><div class="day">16</div></div><h5 class="title">Hudson 1.354 Released</h5></div><p class="teaser">Hear ye, hear ye! Behold, the first release of Hudson ever made by a not-employed-by-Sun Kohsuke (as we covered last week). This iteration of Hudson contains only bug fixes, check the listing below for the specifics on which bugs have been fixed (1.355 is looking like it will contain a number of fixes as well). The release of 1.354 comes slightly later than usual given some of the logistics that needed to, or still need to be resolved.

One of the infrastructure issues that’s half-way resolved is the question of Debian/Ubuntu packages. Kohuske has packages uploaded in an experimental apt repository on hudson-labs.org which you can try out. That said, it’s not entirely clear whether this is going to be the preferred means of distributing native Debian/Ubuntu packages in the future (your mileage may vary).

Bugs fixed

POM parsing was still using the module root as the base for relative paths for alternate settings files. ( issue 6080)

Fix dynamic updates of build history table when CSRF protection is turned on. ( issue 6072)

Improved the error reporting mechanism in LDAP setting.

Raw console output contains garbage. ( issue 6034)

Fixed a file handle leak in the agents connection. ( issue 6137)

Quiet period wasn’t taking effect properly when doing parameterized builds.

Contributors

The release of 1.354 contains a total of 51 commits to the &quot;core&quot; part of the tree, from 9 different contributors

abayer

drulli

kohsuke

manuel_carrasco

mindless

sogabe

swiest

vlatombe

wyukawa
+

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/04/24/hudson-1-355-released/"><div class="header"><div class="date"><div class="month">April</div><div class="day">24</div></div><h5 class="title">Hudson 1.355 Released</h5></div><p class="teaser">The release of 1.355 came out earlier this week but I hadn’t had the chance to write anything up about it. Of course, the work never stops on Hudson so we almost have 1.356 ready to roll out the door, but then Kohsuke tweeted this:

Because of the data center migration going on, I won’t be able to release #hudsonci today.

I won’t go into details on some of the infrastructure changes we have lined up just yet, so here’s the breakdown of 1.355

Bugs fixed

Colored ball image at top of build pages was broken for Hudson in some web containers (fixed by removing workaround for a Firefox bug fixed since 3.0.5/Dec2008). (https://issues.jenkins.io/browse/JENKINS-2341[issue 2341])
Console page while build is running did not wrap lines when viewed in IE. (https://issues.jenkins.io/browse/JENKINS-5869[issue 5869])
Fixed build history to indicate test failure for MavenBuild and MavenModuleSetBuild.
Make +++ +++dropdownList+++ +++ work in repeatable content, such as a build step.

Enhancements

Added the agent retention strategy based on a schedule.

Added to configure charset option of Mailer.

You can go grab the latest .war file straight from hudson-ci.org or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/09/welcome-to-hudson-labs/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 9</div></div><h5 class="title">Welcome to Hudson Labs!</h5></div><p class="teaser">Hello again! It’s been a long time since I’ve written for the Hudson community, but now I’m back and ready to tackle some of the latest developments in the Hudson community.

What is Hudson Labs?

As you may have read in April, Kohsuke left Oracle to found InfraDNA, a company specializing around Hudson. The departure meant the Hudson community would no longer have access to some of the hardware and services that Kohsuke had accumulated over the years working on Hudson at Sun Microsystems. While we are still happily part of the Java.net community, we’ve recognized the need for some community-owned resources and Hudson Labs was born.

Over the past couple months, a group within the Hudson community, &quot;infra&quot; (short for &quot;infrastructure&quot;), has been working to get machines set up and build the foundation for a more open Hudson project infrastructure.

What does Hudson Labs provide?
Builds

One of the first tasks we set upon when building out Hudson Labs was to start improving the build and release process of Hudson by moving as much of it into a public Hudson instance. Building Hudson itself, plugins and dependencies of the Hudson project, the Hudson Labs instance will help improve the reliability of the Hudson ecosystem across the board, and should serve as a useful tool for core and plugin developers.

Mirroring

Thanks to the great team over at the Oregon State University Open Source Lab ( OSUOSL), we’ve been able to build out mirroring infrastructure for Hudson to provide fast access to native packages and wars alike. Currently the OSUOSL only has mirrors inside the continental United States, so we’re reaching out to friends in Asia and Europe to extend the mirroring system.

Information

I’m currently working on re-working some of the blog posts you may have read over four months as more structured tutorials. I hope to provide an easily accessible knowledge-base for developing Hudson along with configuring Hudson for various platforms and development environments; this is a more difficult task so all the pieces aren’t entirely in place for this just yet.

To be honest, I’m very enthusiastic about Hudson’s future. Now that InfraDNA is up and running, Kohsuke’s renewed focus combined with the foundation of Hudson Labs and the uncommonly hospitable Hudson developer and user communities, the future is looking bright!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/10/subversion-repository-change-notification-push-vs-pull/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">10</div></div><h5 class="title">Subversion repository change notification: push vs pull</h5></div><p class="teaser">+
People often configure https://en.wikipedia.org/wiki/Hudson%20%28software%29[Hudson] to start a new build whenever a change is made to the repository. In fact, this is often considered central to the practice of continuous integration. +
 +

+
There are two ways to achieve this. One is the &quot;pull&quot; model, where Hudson periodically reaches out to a Subversion repository to see if there is any changes. The other is the &quot;push&quot; model, where you make the Subversion repository reach out to Hudson. +
 +

+
Both approaches have trade-offs. The pull model is easier to configure, since you can do this entirely from Hudson. But this comes at the expense of increased load to the Subversion server. Even though the overhead of Subversion polling is relatively low, as you add more projects to Hudson and increase the polling frequency, the overhead may get non-trivial (imagine the number of Hudson pollings that the poor https://java.net[java.net] Subversion server gets, for example.) A more serious downside, in my opinion, is that this increases the delay from your commit to a build. For example, if your build just takes 5 mins, then even if you poll every minute, you pay on average 30 seconds delay before a build starts — a 10% overhead! +
 +

+
The push approach eliminates those two downsides, but it requires a post-commit hook configuration in the Subversion repository, which has to be done manually by the administrator, because those scripts are not exposed to external systems like Hudson. +
 +

+
With that said, if you do have an access to the Subversion repository post-commit hook, I highly recommend the push approach, and in Hudson we made it as easy as possible to configure the set up. Here&#x27;s the script you&#x27;ll need in your post-commit hook: +
 +
`+ REPOS=&quot;$1&quot; REV=&quot;$2&quot; UUID=\`svnlook uuid $REPOS\` /usr/bin/wget \   --header &quot;Content-Type:text/plain;charset=UTF-8&quot; \   --post-data &quot;\`svnlook changed --revision $REV $REPOS\`&quot; \   --output-document &quot;-&quot; \   https://server/hudson/subversion/${UUID}/notifyCommit?rev=$REV+` +
 +

+
This script basically just tells Hudson that there was a change in a repository. Hudson will then check this information against all the jobs that have a polling configured, and schedule the builds accordingly. The beauty of this approach is two-folds: +
 +

The script doesn’t change when you add/remove/rename jobs.

The overhead is constant regardless of the number of jobs.

+
+

+
If you haven&#x27;t configured a push setup yet, now is the time to do so! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/11/casual-fridays-directing-traffic-with-hudson/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">11</div></div><h5 class="title">Casual Fridays: Directing traffic with Hudson</h5></div><p class="teaser">Intrepid Hudson user Christian Pelster posted a little project of his this week to the &quot;users&quot; mailing list called: hudsontrafficlights .

Christian describes the project as:

This Java based daemon aggregates the status of one or more jobs from a Hudson continous integration server into a single status (red, yellow, green) and invokes a shell script on status change.

You can use hudsontrafficlights to control a USB traffic light (such as this USB Traffic Light from Cleware, GmbH) to give you and your colleagues nearly instant feedback on jobs in Hudson, without ever needing to leave your text editor! image:https://hudsontrafficlights.googlecode.com/files/CIMG1635.JPG<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/14/hudson-1-362-released/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">14</div></div><h5 class="title">Hudson 1.362 Released</h5></div><p class="teaser">The 1.362 release of Hudson has a few bug-fixes and a few minor enhancements, all together a good stabilization release. Not too much interesting to discuss so straight on to the changelog!

Bugs

Restored optional container-based authentication for CLI. ( issue 6587)

Fix javascript error when a plugin uses an empty dropdownList, resulting in LOADING overlay being left up. ( issue 6542)

Enhancements

Add setting so job views may show only enabled or disabled jobs. ( issue 6673)

File parameters can now be downloaded from the build Parameters page. ( issue 6719)

Added an ability to point to different update sites.

Added a new extension point to plug in custom utility to kill processes.

Added a proactive error diagnostics to look for a broken reverse proxy setup. ( report)

You can go grab the latest .war file straight from our OSL mirror or if you’re using a native package, use your package manager to upgrade.

Image courtesy of &quot; class=&quot;bare&quot;&gt;https://hudsonsgrill.com/<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/22/hudson-1-363-released/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">22</div></div><h5 class="title">Hudson 1.363 Released!</h5></div><p class="teaser">Last Friday the Hudson team released release 1.363 which is yet another mixed bag of enhancements and bug fixes. Along with the usual bunch of fixes, this release includes a number of localization updates courtesy of a team of Hudson community volunteers participating in the Hudson Internationalization project.

It is also worth noting that this post is being published on Tuesday, contrary to the schedule that I operated on with Continuous Blog, I will no longer be posting release updates on Monday morning. Traditionally Hudson is released Friday afternoon (PST), meaning any potential regressions are reported early on Monday morning after our European users start to upgrade. Publishing this release announcement on Tuesday gives me more time to test out the release so I can report with greater confidence in the reliability of the update. ( Note : This may change in the future as we push for easier RC testing capabilities within Hudson)

If you’re a regular reader of the Hudson Labs blog, you may also notice that this change log looks eerily similar to the 1.362 announcement from last week. Turns out I had mistakenly taken the upcoming changes from 1.363 and reported them as fixes in 1.362; I’ve since updated the post regarding 1.362’s change log.

Bug Fixes

Fix queue handling to close locking gap between removing job from queue and starting build, to prevent unintended concurrent builds (refactor of change first made in 1.360). ( report)

Allow multiple dependencies between same two projects, as they may trigger under different conditions and with different parameters. ( issue 5708)

Timeline on build trend page should use server timezone instead of always GMT. ( issue 6692)

Don’t mask the cause of the checkout related exception.

&quot;who am I?&quot; page should be visible to everyone.

Reinstall a JDK when a different version is selected. ( issue 5551)

Enhancements

Avoid pointless and harmful redirection when downloading agent.jar. ( issue 5752)

Cache downloaded JDKs.

Integrated community-contributed translations (Germany, Greek, Spanish, Finnish, Hungarian, Italian, Japanese, French, Russian, Slovenian, Dutch, Traditional Chinese, Swedish, Ukrainian, and Portuguese.)

Upgraded bundled Ant to version 1.8.1. ( issue 6562)

You can go grab the latest .war file straight from our OSL mirror or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/23/stickers-starting-to-arrive/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">23</div></div><h5 class="title">Stickers starting to arrive</h5></div><p class="teaser">Way back in March, I asked you all: Want some Hudson stickers?

Turns out, a lot of you do! Thanks to a huge amuont of help by my future wife, the first shipment of Hudson stickers went into the mail last week. This first shipment was only to United States addresses! If you live outside of the U.S., or if you requested more than 50-ish stickers, I’ve not yet been able to send you stickers. I expect to start sending out international shipments later this week and early next week.
To those of you that have received your stickers, I’d like to remind you of the terms of our agreement:

Conferences : The only condition being that you tell me all about the event and how Hudson was received after the fact (this may involve an interview).

Companies : I always appreciate stickers, pens, branded bouncy balls, etc (see: swag) in return!

Nice People : If you’re just a fan of Hudson, stickers, or both, I’ll still gladly mail you a few stickers with the condition that you take pictures of where the stickers end up (and maybe of your Hudson install) and either email me some cool pictures or post them to  Flickr (tagged: &quot;hudsonstickers&quot;)

To be honest, I really just want to see some pictures of Hudson stickers slapped all over cool stuff: laptops, bosses, servers, desks, stop signs, coworkers, cats, you name it.

If you did not request stickers, but want some now: please refer to the original post for directions. I do still have stickers left, but there are some &quot;bulk requests&quot; I’ve not yet filled. I will do my best to send out as many stickers as I can.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/28/digg-technical-talk/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">28</div></div><h5 class="title">Digg Technical Talk</h5></div><p class="teaser">Recently our fearless leader, Kohsuke Kawaguchi, was invited by the nice folks over at Digg to give a tech talk about continuous integration and automated testing. The Digg engineering team is full of believers in continuous integration, including our very own Andrew Bayer ( abayer). Being big users of the Sauce Labs service to drive their vast Selenium test suite, the house was packed with Selenium hackers/users and Hudson users, the stage was set for Kohsuke to give a great presentation.

Digg Technical Talks - Kohsuke Kawaguchi from Digg Development on Vimeo.

You can find slides of the presentation here
---

For those not familiar with Digg’s peripheral involvement in the Hudson community, they’ve graciously donated a build machine to help run Hudson builds on ci.hudson-labs.org.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/06/29/11th-international-free-software-forum-in-brazil/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">29</div></div><h5 class="title">11th International Free Software Forum in Brazil</h5></div><p class="teaser">Last week, friend-of-Hudson Leandro Nunes sent the following message to the users mailing list regarding his upcoming talk on continuous integration and Hudson:

Next month I will present a talk about Hudson in the 11th
International Free Software Forum ( FISL 11), held in Porto Alegre
Brazil (detailed time and date of the talk are not yet scheduled so).

FISL 11 is one of the biggest free software events in Latin America and will quite literally attract thousands of free software users, hackers, and enthusiasts. It will be held from the 21st to the 24th of July in Porto Alegre, if you’re in Central or South America, you should definitely try to attend.

Leandro will have Hudson stickers on hand to give out and will surely do a fantastic job presenting Hudson to all those future Hudson users, I hope you can make it!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/05/links-for-2010-07-05/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 5</div></div><h5 class="title">Links for 2010-07-05</h5></div><p class="teaser">It’s been quite a while since I posted a Hudson links-roundup post, so without further ado, here goes nothing

Max tells us about using Hudson with Symbian’s CodeScanner tool.

Running agents on Mac OS X? Mirko has some handy launchctl foo for keeping his JNLP agents online

Scott threw up a great configuration sample for running Hudson with an Nginx reverse proxy with SSL

Mark walks us through using Xvfb to run headless cucumber/selenium tests with Hudson

Our friends behind Build Doctor wrote an interesting build radiator that works seamlessly with Hudson.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/05/so-youve-found-a-vulnerability-now-what/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 5</div></div><h5 class="title">So you&#x27;ve found a vulnerability, now what?</h5></div><p class="teaser">Hudson, like all web applications, is not immune from vulnerabilities that could open up attack vectors for malicious use. What puts Hudson in a league of its own compared to others is its ability to execute arbitrary commands on agent machines, or in the case of the EC2 plugin, execute arbitrary commands &quot;in the cloud.&quot; In light of all this, Hudson is quite secure and offers a variety of mechanisms to reduce the potential for exploits.

Despite Hudson’s security track record, you’ve managed to find a vulnerability in Hudson, and decide to don your white hat and inform the Hudson team. First off, let me commend you on your brilliant decision to report the vulnerability, you are truly a leader among men.

Generally immediate public disclosure of vulnerabilities is frowned upon as it doesn’t give us much time to react, investigate and patch the hole. For this reason there is the &quot; SECURITY&quot; project in Hudson’s JIRA. The SECURITY project is a more locked down section of JIRA than the other projects and allows you to submit issues and have them reviewed by the Hudson core developers who can assess the vulnerability. When reporting the issue, it will be helpful to include information regarding the environment the Hudson instance is running in (such as the servlet container) as well as any pertinent reproduction steps so the team can reproduce, fix and verify with as little wheel-spinning as possible.

What happens next wholly determines on the severity of the issue, if it’s a highly critical vulnerability, the team will likely make an out-of-schedule release and advise users to upgrade. If it’s a less critical hole, the fix will be included in an upcoming scheduled release. Either way, the Hudson team has a good track record of correct potential security holes in a timely fashion.

After the hole you’ve discovered has been patched and released, you can revel in the fact that you helped make Hudson better, thanks!

Image courtesy of ThinkGeek<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/06/security-fix-hudson-1-365-released/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 6</div></div><h5 class="title">Security Fix! Hudson 1.365 Released</h5></div><p class="teaser">The Hudson team has released Hudson 1.365 which contains a critical security fix! A security advisory released yesterday by InfraDNA goes on to explain the hole with more detail:

This vulnerability allows an attacker to read arbitrary files in the
server file system whose path names are known, by sending malicious
HTTP GET requests. While such access is still subject to the normal
access control enforced by the operating system, Hudson can still leak
&quot;secrets&quot; possessed by Hudson

The vulnerability inside of Hudson affects Hudson instances running inside the embedded Winstone container, instances behind Glasshfish or Jetty (for example) are not subject to this vulnerability. Instances running behind a reverse proxy such as mod_proxy or Nginx.

Hudson system administrators should subscribe to either the security advisories RSS feed or the advisories@ mailing list

You can go grab the latest .war file straight from our OSL mirror or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/07/gee-thanks/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 7</div></div><h5 class="title">Gee Thanks</h5></div><p class="teaser">Squee-D had some nice things to say in the #hudson IRC channel yesterday that I thought I would share:

Just to sing some praise again, make sure you all know how appreciated it is, we absolutely love hudson, and appreciate everyone who develops and maintains it.

Positive feedback (and negative really) is always appreciated; have you thanked your plugin maintainer today?<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/08/a-python-love-story-virtualenv-and-hudson/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 8</div></div><h5 class="title">A Python Love Story: Virtualenv and Hudson</h5></div><p class="teaser">Over the past year Hudson has grown tremendously, both within the Java community and outside of it. Partially thanks to [Titus Brown]( https://twitter.com/ctitusbrown)&#x27;s PyCon 2010 Atlanta coverage of continuous integration for Python (which we’ve [covered before]( https://jenkins.io/content/hudson-pycon)), Hudson has made great strides within the Python community as well. In my experience, the majority of Python developers are not using Hudson to build anything, unless they have C extensions, but rather to test their packages, which presents its own set of specific requirements for jobs. Jobs for testing Python code need to be able to reliaby reproduce an environment with the same set of dependencies from one run to the next in order to provide consistent testing. Unlike their Java counterparts, Python developers cannot rely on a powerful system like Maven2 for enumerating build/test targets or defining their project’s dependencies in their jobs; fortunately, w e can have something close: [virtualenv]( https://pypi.python.org/pypi/virtualenv) and [pip]( https://pypi.python.org/pypi/pip). Virtualenv does exactly what you might expect it to, it creates a &quot;virtual environment&quot; with custom site-packages directory, and modified python executable. Using virtualenv you can create a staged environment to use for running unit and integration tests. Adding pip alongside that and you have a fantastic Python package manager/installer to use with the virtual environment. Below, I’ve outlined the steps required to use virtualenv and pip to automatically manage a custom environment for your Python jobs. # The Recipe For this recipe to work, you should make sure that your agent machines all have virtualenv and pip installed and accessible from your agent agent’s $PATH. For Mac OS X users, sudo easy_install virtualenv should do the trick, Linux users should be able to run sudo [aptitude/yum/zypper] install python-virtualenv with your respective package manager. You will also need the [SetEnv Plugin]( https://wiki.jenkins.io/display/JENKINS/Setenv+Plugin) installed in Hudson. Step 1 Inside of the job’s configuration page ([http;//hudson/job/configure]( https://hudson/job/configure)), we need to define an environment variable for the job. Using the SetEnv plugin, define a new $PATH : +     PATH=.env/bin:$PATH+ What this will do is modify the $PATH environment variable for all of the &quot;Execute shell&quot; build steps in your job. As you might have guessed, we’re going to install the virtualenv in.env in the workspace root directory. Step 2 To set up the virtualenv, you want to add a build step of type &quot;Execute shell&quot; and paste the following commands into the text area: +     if [ -d &quot;.env&quot; ]; then         echo &quot; virtualenv exists&quot;     else         echo &quot; creating virtualenv&quot;         virtualenv .env     fi+ This will create a virtualenv the first time the job runs on a particular agent, a virtualenv that will persist until the workspace is cleared. Since we’re going to install dependencies in the virtualenv, we want to keep it around between jobs to reduce the amount of network hits to download packages. ## Step 3 With our virtualenv and our $PATH properly set up, the job can now properly install dependencies into its virtualenv, this is where pip shines. A little known feature of pip allows you to define a &quot;requirements file&quot; which enumerates the packages to install. In my example project, I defined the following requirements in a file called pip-requires.txt +     eventlet&gt;=0.9.9     nose&gt;=0.11.3     MySQL-python&gt;=1.2.3c1+ In my hypothetical example, I’ll need nose to run my tests, while eventlet and MySQL-python are required for my project to properly run. With the pip-requires.txt file in the root of my source repository, I can add an additional &quot;Execute shell&quot; build step that does the following: +     pip install -r pip-requires.txt+ Assuming the $PATH environment variable was properly defined, this will use the virtualenv’s version of pip and it will install the packages defined in pip-requires.txt into the virtualenv! With the dependencies all properly installed in the virtualenv, I can now configure the remainder of my job to build my project and execute the tests. Pretty snazzy if you ask me!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/12/updated-chrome-extension/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">12</div></div><h5 class="title">Updated Chrome Extension</h5></div><p class="teaser">The developer for the Hudson extension for Google Chrome, Sebastian Sanitz, emailed the users@ list today to inform the community of an update to his fantastic extension .

Sebastian’s extension monitors ci.hudson-labs.org by default, but the URL and polling interval are both trivial to change. When any of the builds in the configured URL fail, you’ll see a red &quot;Fail&quot; indicator, otherwise green &quot;Ok&quot;.

If you’re interested in contributing to the plugin, good news! It’s open source! You can find it on GitHub.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/13/monitor-hudson-from-your-android/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">13</div></div><h5 class="title">Monitor Hudson from your Android</h5></div><p class="teaser">So you’ve got your fancy Android cell phone and you’re thinking to yourself &quot;besides feeling smugly superior to iPhone users, what can I do with this thing?&quot; Perhaps you should be considering using it as a phone but if that’s too boring, check out the new and improved Hudson Mood widget for Android ! The latest release brings support for multiple servers and fancier graphics.

If you’re interested in installing the widget, search for &quot;Hudson Mood&quot; in the Android Market, and be sure to thank Siarhei Dudzin for creating the widget!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/21/hudson-with-selenium-and-sauce-on-demand-videos/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">21</div></div><h5 class="title">Hudson with Selenium and Sauce On-Demand Videos</h5></div><p class="teaser">A few weeks ago, Kohsuke stopped by the San Francisco Selenium Meetup hosted by Sauce Labs to talk about all things Selenium and Hudson related (with a bit of Sauce in there too).

The good folks over at Sauce Labs have gotten around to posting some of the videos taken with Kohsuke.

Instead of embed the videos, I wanted to directly link to the post and make sure that you all went over to check out Sauce Labs, they’re up to some interesting things over there.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/22/continuous-deployment-on-the-new-digg/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">22</div></div><h5 class="title">Continuous Deployment on the new Digg</h5></div><p class="teaser">In my capacity as Build Guy at Digg, I’ve written up a blog post on our new continuous deployment/code review/pre-tested commit workflow. We’re using a combination of Hudson, Git and Gerrit, Selenium and more to make sure that every change going to Digg’s new site has been thoroughly tested.

Read the whole post, with all the juicy details over on Digg’s Technology Blog!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/27/hudson-1-368-released/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">27</div></div><h5 class="title">Hudson 1.368 Released!</h5></div><p class="teaser">Regular readers will recognize that I’ve been slacking off quite a bit lately with my release announcements, my apologies. With the release of 1.368 on Sunday, which fixed a few fairly important bugs, I figured I’d dusty off my blogging fedora and give this a shot.

This release has three bug fixes in it which were causing some issues for some users, particularly those deploying Hudson inside the recently released Tomcat 7.0 (see issue 6738).

Hudson users utilizing the JDK auto-installation feature between different platforms may have been affected by issue 6880 which was also fixed in this release.

Bringing up the rear is the fix to issue 7004 which detailed a few discrepencies between the /buildWithParameters and the /build remote APIs.

If you’re not affected by these issues, you may want to wait for the soon-to-be-released 1.369 which has even more juicy bug fixes in it (with a dash of enhancements) to upgrade.
---

You can go grab the latest .war file straight from our OSL mirror or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/07/28/hosting-your-hudson-plugin-at-github/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">28</div></div><h5 class="title">Hosting your Hudson plugin at Github</h5></div><p class="teaser">For as long as Hudson’s had a plugin model and development community, we’ve provided source code and binary hosting through our Subversion repo at java.net. But what if you’re a plugin developer and you don’t want to use Subversion? Well, we have an alternative for your source code: host it with Hudson on GitHub.

To get this in place, send an email to dev@hudson.dev.java.net (or ask in the IRC channel) asking to get a repository created for your plugin at Github. Make sure to include the name of the plugin and your Github username (and the Github usernames of any other developers who’ll be pushing to your plugin’s repo). If your plugin is already in Github, include the URL for the existing repo so that we can fork it. One of the Hudson admins will create the repository (forking if appropriate) and add the user(s) to the list of users with push access to the Hudson-hosted repositories at Github. Once you hear back from them, you’ll be able to push code to the new repository.

You will need to make a few changes to your plugin’s POM, as compared to what works for a plugin POM in the java.net Subversion tree.

First, add the following to the ` section: +
 +
`+                org.apache.maven.plugins         maven-release-plugin         2.0                                 org.apache.maven.scm             maven-scm-provider-gitexe             1.3                           +` +
 +
This is needed to make sure we&#x27;re overriding the parent POM&#x27;s SCM provider settings. Next, add the following to the ` section:

+                     org.jvnet.wagon-svn         wagon-svn         1.9            +

This is needed because we’re still going to be using wagon-svn to deploy the artifacts in the release process. Lastly, add an ` section, within the ` section of the POM, like the following:

+        scm:git:git://github.com/hudson/your-plugin-repo.git     scm:git:git@github.com:hudson/your-plugin-repo.git https://github.com/hudson/your-plugin-repo +

As with the first section, this is needed to override the default SCM settings in the parent POM. Make sure to change &quot;your-plugin-repo&quot; to your actual plugin repository name, of course! It’d also be a good idea to put a link to your Github repo on your plugin’s wiki page at the Hudson wiki, since the default source link will go to Subversion.

Now, with these changes in place, committed and pushed to the master branch in your plugin’s repository, you should be able to run &quot;mvn release:prepare release:perform&quot; just as you would if the plugin were hosted in Subversion, with your plugin showing up in the Update Center within a few hours. Be sure that you’ve configured the login information for the java.net Maven repository, as detailed here - this is still needed for plugins hosted at and released from Github, since Hudson’s Maven repository still lives at java.net. If you run into any issues releasing your plugin from Github, first be sure to review the wiki page on plugin hosting, which addresses many of the issues you may encounter when running the Maven release plugin.

If you’re still stumped, feel free to email the Hudson developer list or ask in the IRC channel for help.

+
(Andrew is a core committer to Hudson and the author of numerous plugins. He&#x27;s the build guy at https://digg.com[Digg], who, by the way, https://jobs.digg.com/[are hiring]!)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/02/dogfooding-hudson-were-looking-for-slaves/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 2</div></div><h5 class="title">Dogfooding Hudson - We&#x27;re Looking for Agents!</h5></div><p class="teaser">As you may have noticed, thanks to the link on this and the other pages here at hudson-labs.org, the Hudson development community has recently introduced ci.hudson-labs.org, the official Hudson-on-Hudson instance. We’re currently building Hudson proper, the Hudson core RC branch, individual builds for the various Hudson plugins and Gerrit, as well as various libraries and infrastructure jobs Hudson depends on.

We’re currently running all those builds on a dedicated Linux agent, generously provided to the Hudson project by Digg, my employer. This has been great - except for the day when I’d just added all the individual plugin jobs for the first time, we haven’t had real problems with capacity. But we are limited in the environments we can run our tests on as a result of only having a Linux agent. We’re currently playing with a temporary Windows agent, but we’d really like to have at least one more permanent Windows agent, and a Mac agent as well, so that we can run Hudson’s core integration tests on those platforms as well. Since this is Hudson we’re talking about, we don’t need the agent to be in any given physical location - we just need it to be running the agent process and talking to our server. If you’re interested in helping us out with this, please contact me at andrew dot bayer at gmail dot com. Thanks!

+
(Andrew is a core committer to Hudson and the author of numerous plugins. He&#x27;s the build guy at https://digg.com[Digg], who, by the way, https://jobs.digg.com/[are hiring]!)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/10/big-security-fix-hudson-1-371-released/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">10</div></div><h5 class="title">Big Security Fix! Hudson 1.371 Released</h5></div><p class="teaser">Hot on the heels of Hudson 1.370, which was released last Friday, the Hudson team released 1.371 which addresses a critical vulnerability in all Hudson versions prior to 1.371. The vulnerability was disclosed by InfraDNA in the following security advisory, which details the issue:

This critical vulnerability allows an attacker to use CLI commands that they are otherwise unauthorized for. CLI commands can perform various administrative operations.

It is advised that all Hudson instances be upgraded immediately to avoid data loss or other ill effects from this issue. If you’re upgrading from a version earlier than 1.370, you can consult the changelog for details on the other bug fixes and enhancements covered by the upgrade of your version to 1.371.

If you run a Hudson instance, it is recommended that Hudson system admins subscribe to either the security advisories RSS feed or the advisories@ mailing list
---

You can go grab the latest .war file straight from our OSL mirror or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/11/quiet-period-feature/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">11</div></div><h5 class="title">Quiet Period Feature</h5></div><p class="teaser">Commits often come in a burst. This seems to happen mainly for two reasons — people sometimes forget to commit some files, and in the tranquility of waiting for your SCM to finish a commit, people sometimes realize the problems in the commit and they quickly make follow-up changes. The conventional wisdom is that the CI server should wait for the burst to finish before attempting a build. This is said to reduce the chance of having broken build, and it is also sometimes useful in reducing the average turn-around time for builds that take longer.

As such, Hudson is capable of waiting for a commit burst to be over before it triggers a new build, and this feature is called &quot;quiet period.&quot; There are two parts in Hudson that interacts with the quiet period. One is the SCM polling behavior and the other is the queue.

The queue portion of the quiet period is straight-forward. When a build is scheduled into the queue with quiet period, the build will sit in the queue until the quiet period expires. If during this period, additional attempts are made to put the same build in the queue, the quiet period resets to its initial value. For example, if the quiet period is 5 minutes, and the build is put into the queue 9:00am and 9:03am, the actual build will only happen after 9:08am. Thus another way to think of the quiet period is that you are requiring a certain period of inactivity.

The above applies to all the mechanisms in Hudson that puts builds into the queue. This includes REST API call, CLI call, downstream triggers, and SCM pollings. So if you implement some kind of a &quot;push&quot; mechanism in your SCM to notify Hudson of a new commit, then you get the desired effect by just setting the quiet period in Hudson, and those push scripts don’t have to do anything tricky.

It is also possible for some of those to override the quiet period configured in the project. For example, when you click &quot;Build Now&quot; button in your browser, your browser is making a REST API call, but with the quiet period of zero. I used to run a &quot;push&quot; script that looks into a commit message and overrides the quiet period by taking advantages of this feature.

The other portion of the quiet period that often matters is the SCM polling behaviour. Up until Hudson 1.346, the way Hudson defined the SCM abstraction made it impossible for SCMs to correctly report newly detected commits since the last polling. Instead, it was only possible to report if the repository is newer than the workspace. As a result, if the polling interval is set shorter than the quiet period, the build stayed in the quiet period forever. This was tracked in HUDSON-2180.

Hudson 1.346 fixed this issue, and so if you are using a newer version of Hudson and SCM plugins that take advantage of this improvement, then everything works as expected. Otherwise, avoid setting quiet period longer than the polling interval.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/16/hudsonmobi-2-0-hits-the-android-market/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">16</div></div><h5 class="title">HudsonMobi 2.0 hits the Android Market</h5></div><p class="teaser">The folks over at LMT Software just released their HudsonMobi 2.0 to the Android market. This release of HudsonMobi brings a lot of the features to Android that iPhone/iPad users of HudsonMobi have enjoyed for some time.

Features unleashed to Android users in this revision of the app are:

Full Android user-experience with Menu and back controls

Embedded artifact viewer! For archived build artifacts that are text-based, you can view them directly on your handset.

Access to the build history and changes for a job.

Quick and easy access to a job’s last build\

Restyled and updated user-experience, making HudsonMobi &quot;feel better&quot; on an Android device

If you want to get HudsonMobi for free from the Android Market, whip our your phone and take a picture of its QR code:<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/17/hudson-1-372-sets-sail/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Hudson 1.372 sets sail</h5></div><p class="teaser">Last Friday the Hudson team rolled out a small 1.372 with two enhancements following the critical 1.371 release on Monday. Not a whole lot to say about this release other than go get it!

Enhancements

Persist matrix-based security settings in a consistent order ( issue 7138)

Jobs can now use boolean expression over labels to control where they run.

You can go grab the latest .war file straight from our OSL mirror or if you’re using a native package, use your package manager to upgrade.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/17/hudson-anonymous-usage-data/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Hudson Anonymous Usage Data</h5></div><p class="teaser">In late 2008, the Hudson team released version 1.264 which added an anonymous reporting feature (you can opt-out in the &quot;Manage Hudson&quot; screen). The reporting feature has been sending information back to the Hudson team to help us understand how Hudson is used in aggregate; the info being reported includes the number of jobs configured, agent configurations, what plugins (and what versions of those plugins) are installed, and more. This data has not been available publicly until now! The raw data needed to be decrypted and scrubbed of any potentially identifying information, such as non-public plugin names or usernames in snapshot versions. We’ve finally scrubbed the data and are making it available!

The data is currently in monthly JSON bundles, organized by unique install key. We’ve filtered out reports of installations without any jobs configured, as well as any installations with only one report in a given month.

If you’d like access to the data, please send an email to dev@hudson.dev.java.net or jump onto the IRC channel and ask - we’ll send you the URL and a private username/password which you’ll need to access the info. We’re also planning to do more analysis of the data ourselves, for now feast your eyes on this spreadsheet, which shows the total number of unique installations seen per month and the number of unique installations of each publicly available plugin per month.

+
(Andrew is a core committer to Hudson and the author of numerous plugins. He&#x27;s the build guy at https://digg.com[Digg], who, by the way, https://jobs.digg.com/[are hiring]!) +
 +

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/20/hudson-sauce-ondemand-webinar/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">20</div></div><h5 class="title">Hudson / Sauce OnDemand webinar</h5></div><p class="teaser">On September 1st, I’ll be presenting in a Sauce Labs webinar about Hudson and Sauce OnDemand. The talk will discuss how Hudson can be used with Sauce OnDemand, naturally, but it’ll also cover broader Hudson/Selenium integrations.

Please register to this free event, and looking forward to seeing to you virtually.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/26/cloudbees-announce-hudson-as-a-service/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">26</div></div><h5 class="title">CloudBees announce Hudson-as-a-Service</h5></div><p class="teaser">https://cloudbees.com/[CloudBees] announced the beta availability of their new Hudson-as-a-service &quot;HaaS&quot; today. I see this as yet another validation to Hudson, and as such, I welcome this new addition to the community and wish them well! — more companies betting on Hudson means we’ll get more investment to the project, which is all goodness for Hudson users. It’s been 5 months since I left Oracle to start InfraDNA, and I was initially worried about a possible negative impact on adoption, but instead Hudson has shown with no sign of slowing down (see picture on the right, from Andrew’s report, which shows # of estimated active installations that participates to our usage stats survey). And InfraDNA is going well too - we’ve helped companies big and small to improve their Hudson usage/adoption, and our commercial value-add Hudson distribution is getting plenty of interest.

Hosted Hudson offers an interesting trade-off, compared to on-premises Hudson. On the plus side, given the current hourly pricing of public clouds like EC2 and Rackspace, you get a better pricing model, as CloudBees charge by minutes. You also get rid of machines and upfront cost, which is great for small business. On top of that, you can also expect them to gradually develop more value-adds and better integration to various other pieces, which can get really interesting.

On the down side, you have less control over the environment that runs the builds, and you do not have access back to your intranet environment (think databases that you need to talk to, for example.) Also, in the current pricing (8.5 cents/hour of EC2 vs 1 cent/minute of CB), if your build takes longer than 9 minutes, you’ll save more by just using Hudson EC2 plugin.

On a related note, I think one of the sweet spots is Hudson that’s well integrated with on-premises cloud solution. As you can see in the discussion with Liferay Hudson setup, with sufficient load it gets cheaper to have your own hardware, and many companies need some degree of control to the build/test environment that matches with their production environment. Plus with those on-premises virtualized environments, you can do snapshots and forks, which can be made to do very interesting things.

Finally, I think the part that everyone can agree on is that the elasticity of build environment is hugely useful to the CI environment, as I discussed in my JavaOne 2009 talk ( slides.) I’m very happy to see that the foundation work we’ve made in Hudson for this is getting validated more and more, and I think the added elasticity will drive a lot more changes in Hudson and more broadly into the way we develop software. It is an exciting time!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/29/hudson-user-meet-up-in-copenhagen-oslo/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">29</div></div><h5 class="title">Hudson User Meet-up in Copenhagen/Oslo</h5></div><p class="teaser">I’ll be in Copenhagen from 9/5-9/7 and in Oslo 9/8-9/9 to present in JavaZone. I’d like to take advantage of the opportunities and have user meet-up events in those cities. Depending on the number of participants, it could be just a drink in a bar, or a talk in a meeting room.

So if you are:

in those cities,

available in the evening of 9/6, 9/8, or 9/9, and

willing to attend such an event,

... then please let me know.

Also, if you have an office in those cities and willing to provide a space for an event, that would be extra appreciated!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/30/pre-javaone-hudson-meetup/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">30</div></div><h5 class="title">Pre-JavaOne Hudson Meetup</h5></div><p class="teaser">As we near autumn up here in the Northern Hemisphere, the wind is starting to blow a bit chillier and here in the Bay Area that can only mean one thing: Oracle is suing everybody! it’s time for JavaOne!

A whole lot has changed since last year, Sun Microsystems was acquired by Oracle, Kohsuke left Snoracle to found InfraDNA and Hudson has continued to power on as the single best continuous integration server on the planet.

While the tickets for Oracle OpenWorld/JavaOne are just as outrageously expensive as they were last year, we are hosting a meetup/hackathon/continuous-drinking-contest at Digg the Sunday prior. We have not yet set any kind of agenda, but some core Hudson hackers and plenty of plugin developers should be in town so it should be a great time hacking on and/or with Hudson.

https://www.meetup.com/hudsonmeetup/calendar/14515128/

When: September 19th, 1:00 p.m.

Location: Digg’s Office: 1040 Mariposa St - Suite 100, San Francisco, CA 94107
https://maps.google.com/maps?f=q&amp;source=embed&amp;hl=en&amp;geocode=&amp;q=1040+Mariposa+St+-+Suite+100+San+Francisco,+CA+94107&amp;sll=37.0625,-95.677068&amp;sspn=39.780156,78.662109&amp;ie=UTF8&amp;hq=&amp;hnear=1040+Mariposa+St,+San+Francisco,+California+94107&amp;ll=37.764201,-122.394304&amp;spn=0.020356,0.025749&amp;z=14&amp;iwloc=A

Unlike last year, we’re trying to organize this with Meetup.com, if you experience any difficulties RSVPing let us know<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/08/31/hudson-at-javazone-meetup-in-oslo/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">Hudson at JavaZone, Meetup in Oslo </h5></div><p class="teaser">+
https://jz10.java.no/[JavaZone] is a big Java conference in Scandinavia, and Hudson is well represented there. On September 8th, Håkon Snøtun will be presenting &quot;Top 5 plugins for Hudson and Chuck Norris.&quot; and on September 9th, I&#x27;ll be presenting &quot;Getting more out of your Hudson.&quot; +
 +

+
But more importantly, what is a conference without drinking!? So in that spirit, https://infradna.com/[InfraDNA] will be organizing a Hudson User Meetup at https://maps.google.com/maps?hl=en&amp;q=Oslo&amp;ie=UTF8&amp;hq=&amp;hnear=Oslo,+Norway&amp;ll=59.912614,10.743604&amp;spn=0.001589,0.004823&amp;t=h&amp;z=18[The Scotsman] from Sep 8th 19:30 (https://www.scotsman.no/[website].) We&#x27;ll get together, have some drinks, and enjoy geeky conversations. +
 +
 +

+
So if you are local or visiting Oslo for JavaZone, come join us. If you plan to join us at The Scotsman, please mailto:kohsuke@infradna.com[RSVP], and watch out for https://twitter.com/kohsukekawa[my twitter updates] for any last minute time/location changes. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/01/copenhagen-hudson-user-meetup/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 1</div></div><h5 class="title">Copenhagen Hudson User Meetup</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Kopenhagen_Innenstadt.JPG/280px-Kopenhagen_Innenstadt.JPG[image]September is turning into a meetup month for the Hudson community. In parallel to https://hudson-labs.org/content/hudson-javazone-meetup-oslo[the meetup in Oslo] and https://hudson-labs.org/content/pre-javaone-hudson-meetup[the meetup in JavaOne], https://www.nokia.com/[Nokia] and https://infradna.com/[InfraDNA] are hosting a meetup in Copenhagen on September 6th, Monday. Read on for the details. +
 +

+
The current tentative plan is to do a short &quot;state of the union / what&#x27;s new&quot; kind of presentation, then use the rest of the time for open mic Q&amp;A, but if you have other ideas, or better yet if you want to do some talks, please let me know. I think the event will be fun. +
 +

+
If you plan on coming, please mailto:event@infradna.com[drop me a note], so that we can get some sense of the attendance. +
 +

When: September 6th, 18:30

Where: Auditorium 1, Nokia Denmark A/S, København ( map)

Food will be provided.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/02/recent-label-and-matrix-project-improvement/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 2</div></div><h5 class="title">Recent label and matrix project improvement</h5></div><p class="teaser">Today, I’d highlight two recent improvements to the label and matrix projects.

When you have multiple agents in your Hudson build farm, you can use labels to classify agents by their capability/environment/architecture/etc. For example, your one agent might have “32bit” and “windows” label, while another one might have “linux”, “ubuntu”, and “64bit.” (with plugins like platform-labeler plugin, you can attach labels automatically, too.) Or if you do Selenium testing, you might add browser names as labels to indicate which agent has which browser available.

With such set up, you then specify that such and such jobs can be only run on such and such labels. For example, you might say your “test-foo” job requires the “windows” label, while your “compile-bar” job might require the “macos” label.
Starting 1.372, Hudson now lets you use boolean expressions here, instead of just specifying one label as the requirement. For example, your “seleniumTest-zot” job can now say it requires “windows&amp;&amp;firefox” since it’s meant to run on Windows with Firefox. Or if your job requires a shell script, you might say “!windows” to indicate that it has to be run somewhere that’s not Windows.

Labels are also often used in the context of the multi-configuration project (a.k.a. matrix project.) In a multi-configuration project, you specify what to execute to build your project, then specify a number of “axes” that represents the variable and their possible values to execute a build. There are several different kinds of axes (and this is of course extensible), and one of them is the label axis.

For example, say you have a test suite that you want to run on Windows, Linux, and Solaris, to make sure it works correctly under all these environments. In such a case, you define one label axis, and tell Hudson that you have three possible values “windows”, “linux”, and “solaris.” When you build this project, Hudson will run your build three times by finding appropriate agent that carries the specified label.

In 1.373, you can now specify multiple label axes. For example, you might have a C++ project that needs to be compiled on various platforms. In such a case, you can define one label axis to be “windows”, “linux”, “solaris”, and you can define another label axis to be “32bit” and “64bit”. This will generate 3x2=6 combinations to be executed.

Sometimes the exhaustive combinations do not make sense. In such a case, you can use a filter boolean expression to eliminate some values. You can also use the same mechanism to create a sparse matrix — that is, you tell Hudson to reduce the coverage to 33%, and Hudson will eliminate every 2 out of 3 combinations.

Finally, I’d like to thank Sandia National Laboratories for sponsoring this work, which made it possible for InfraDNA to provide this feature to the community. People often think that contributing code is the only way to give back to the project, but sponsoring features like this is another great way to do it.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/04/hudson-events-calendar/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 4</div></div><h5 class="title">Hudson Events Calendar</h5></div><p class="teaser">Just wanted to let everybody know that I’ve gone ahead and added a Calendar for all the upcoming Hudson-related events.

Hopefully we’ll be able to add more and more events for the rest of the year including seminars, more meetups and potentially a few drink-ups!

Worth mentioning that I’ve not yet tested the iCal feed so if you have troubles with it, let me know (via the comments).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/05/hudsonmobi-dons-a-black-turtleneck-and-jumps-to-ios4/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 5</div></div><h5 class="title">HudsonMobi dons a black turtleneck and jumps to iOS4</h5></div><p class="teaser">Last time I talked about HudsonMobi 2.0 there were some hiccups with the QR code which made me pretty irritated. Now the leading mobile app for Hudson users has regained my trust with their lastest release for iOS 4, the latest incarnation of Apple’s mobile operating systems for iPhones and iPod Touches.

Since I fall into the category of subhumans who for one reason or another choose not to own an iPhone, I can’t verify the awesomeness of this new HudsonMobi release. If it is anything like the 2.0 release for Android you can expect enhancements such as:

Tighter integration with iOS 4

Embedded artifact viewer! For archived build artifacts that are text-based, you can view them directly on your handset.

Access to the build history and changes for a job.

Quick and easy access to a job’s last build

If you own a device with iOS 3.0 or higher you should be able to download HudsonMobi 2.0 from the appstore, if you give it a whirl, please leave a comment to let me know how awesome it is :)

---<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/09/lets-talk-about-hudson-at-javaone/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 9</div></div><h5 class="title">Let&#x27;s talk about Hudson at JavaOne</h5></div><p class="teaser">A few months ago I enjoyed running a couple interviews with folks who were using Hudson but lately I’ve lacked the time and coffee to get more interviews done.

I am planning on making up for it by bringing my fancy smancy tape recorder (i.e. a smartphone) and a few notepads to the upcoming JavaOne conference here in San Francisco.

If you’re interested in talking to me about how you or your company uses Hudson in your quest for world domination, you will be able to find me at the Hudson hackathon on Sunday the 19th, or at JavaOne on Monday, Tuesday and maybe Wednesday.

Feel free to drop me a line at tyler[at]linux.com and we’ll set something up!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/17/javaone-taking-shape/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">17</div></div><h5 class="title">JavaOne taking shape</h5></div><p class="teaser">Last night on my way out of San Francisco I stopped by 4th and Howard St to get my first taste of JavaOne/Oracle OpenWorld which was already taking shape at the location. Besides snapping the photo below, I also managed to get yelled out by an old woman wearing a red &quot;security&quot; jacket; suffice to say my JavaOne experience is already everything I expected! image:https://farm5.static.flickr.com/4107/4997929716_1675745efe.jpg

Unlike last year’s Oracle OpenWorld, which also shut down this segment of Howard St in San Francisco and took over the adjacent Yerba Buena Gardens, this event will be crammed together with JavaOne.

At this point I’m not sure what I can expect as far as the JavaOne portion of the event goes, we do have two Hudson related events scheduled:

Getting More Out of Your Hudson - Monday at 10:00 a.m. - Hosted by our very own Kohsuke Kawaguchi, the session will be 60 minutes at Parc 55, Embarcadero.

Getting More from Your CI Server: Taking Hudson to the Next Level - Tuesday at 9:30 a.m. - Hosted by the (in)famous John Smart the session will also be 60 minutes at Parc 55, Cyril Magnin 1.

Unfortunately those were the only specifically-Hudson related tracks I could find, as Andrew Bayer has mentioned before, finding a proper schedule is near impossible. While at JavaOne, I intend on posting updates, pictures and maybe a little scathing commentary (they did give me a blogger pass for some silly reason).

If you’re going to be at JavaOne, think about coming and talking to me about how you/your company uses Hudson. I might just have stickers!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/20/live-blog-kohsukes-presentation-at-javaone/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">20</div></div><h5 class="title">Live Blog: Kohsuke&#x27;s Presentation at JavaOne</h5></div><p class="teaser">Editor’s note: This is a very rough set of notes from Kohsuke Kawaguchi’s presentation at JavaOne 2010.

Kohsuke takes the stage, asks &quot;who uses’s Hudson&quot; the majority of
audience raises their hands

Discussing the great ecosystem using Hudson across the wide-variety of platforms/languages.
330+ community written plugins. Last year at JavaOne we had 230+ plugins

Eclipse Community Survey, Hudson adoption from 9.1% in 2009 to 21.8%

Discussing Hudson adoption, going over Hudson job postings on indeed.com going up compared to a stagnant Cruise Control.

Kohsuke introduces himself and InfraDNA, started Hudson in 2004/2005.

First steps to CI, 10,000 foot overview of SCM monitoring/build/testing. Delving into using Hudson
for automating everything to get &quot;more out of your Hudson deployment.

&quot;Interconnecting Jobs aka Workflows&quot;

Hudson allows for hosting many projects on one Hudson deployment, meaning you need a smaller number of administrators for a larger number of jobs compared to Cruise Control.

Building Block #1: Triggering. Using &quot;upstream&quot; and &quot;downstream&quot; jobs ot interconnect jobs to form a workflow in Hudosn. Triggering is asynchronoys in Hudson, useful for separating builds and multiple test jobs. Splitting the build and test jobs so you build quickly test many tests in parallel.

Avoid recompiling compilation/builds in the &quot;downstream&quot; test runs. &quot;Copy Artifact&quot; plugin very useful for passing built executables to test jobs.

Upstream/downstream separation also highly useful for separating build and deployment into a continuous workflow.

Building Block #2: Join plugin. Fan downstream jobs out and then bring everything back together for final
steps.

Shows Join plugin configuration screen because &quot;perhaps the configuration is a little unintuitive&quot;.

Building block #3: Fingerprints. Using MD5 checksums from artifacts to learn more about those artifacts in your
Hudson, tying together artifacts from different jobs/builds. Letting Hudson recording these fingerprints of those artifacts in your lifecycle allows Hudson to help you find out where/when those executables came from.

Fingerprinting mechanism good for tracking dependencies from third parties, Hudson uses 3rd party fingerprints to compute additional information. Also useful for aggregating reports.

Going a bit further using the &quot;build promotion plugin&quot; to weed out which builds are &quot;better than others.&quot; Taking fingerprints from a build job all the way through the life cycle and passing that fingerprint around test/smoke test jobs, if that passes, build passes on to more rigorous testing, only if it’s passed base-level testing. Basic model of promotion maps to a &quot;confidence level&quot;, 1st level passes compilation, 2nd level passes smoke test, 3rd level passes expensive/time-consuming tests.

One of the reasons to use promotion in your lifecycle to ensure that artifacts meet a minimum &quot;confidence level&quot; so you’re not expending resources running the longer tests )think about a promotion hierarchy)

Demo time!

Kohsuke demoing build promotion live with fingerprinting of sample jar files. Creating a &quot;component-X&quot; build and a &quot;test-X&quot; build. test-X job using the &quot;Copy Artifact&quot; plugin to grab artifacts from the component-X build.

Defining the promotion criteria in &quot;component-X&quot;, &quot;test-X&quot; promoted, indicates that certain builds promoted a build.

End demo time!

Maven Integration

Maven integration highlights. Going over POM comprehension and simplified configuration due to more information
getting inferred from the POMs. Building dependency chains with Maven integration.

&quot;That’s the basics, let’s talk about advanced integration with Maven&quot;

Parallel-module builds! Letting Hudson builds modules with a single checkbox, meaning wherever possible Hudson will try to build your modules in parallel when possible.

Incremental builds! Only building changed modules in a build run to be more efficient, preventing the need to rebuild the whole project from scratch every time. Hudson’s SCM integration to determine what the mapping between files changed and modules needing to be built.

Private Maven repositories! Avoiding artifacts being overwritten by others, telling Hudson to create a Maven repository per-project (at the expense of more bandwidth/disk space needed), helps segregate builds to avoid them stomping on each other.

After-the-fact deployment, avoiding deploying modules unless the whole build is successful (all modules properly built). Instead of using mvn deploy, you tell Hudson to deploy to your Maven repository with a single checkbox.

Matrix Project

No longer alpha! Production-ready!

Often used to build/test across slight variations of build environments such as different platforms for a C++ project. Conceptually it’s like running your build in a for loop.

Hudson supports a number of different axes, most popular of which being a &quot;agent axis&quot; which allows you to use different labels or specific agents for the build. Hudson also supports arbirtrary text fields as axes to be passed along to the build steps as environment variables.

Touching on &quot;filtering&quot; in the matrix project support to remove parts of an axis that you do not need. I.e if you have a &quot;platform&quot; and a &quot;browser&quot; axes for web testing, you can exclude the &quot;iexplore&quot; value of the &quot;browser&quot; axis when the &quot;platform&quot; axis is &quot;mac&quot;.

Demo time!

Defining two axes, &quot;agent&quot; axis and the &quot;JDK&quot; axis to build against different JDK versions on linux, solaris and windows. Excluding &quot;touchstone builds&quot; to avoid rebuilding a large number of matrix builds unless a limited subset of the combinations successfully build. Used to avoid spending a lot of time spinning cycles on very obvious errors that the first few builds &quot;recognize&quot; immediately.

End demo time

Doing Selenium testing on Hudson

Use &quot;Selenium Grid plugin&quot; to install Selenium binaries on all agents and prepares them all to talk to each other. Useful for &quot;overloading&quot; an existing Hudson cluster as a Selenium cluster.

Using labels in Hudson to better determine which node has which browser.

Selenium integration is very powerful when combined with the join plugin and the matrix configuration support in Hudson for web testing across a large number of platforms and browsers.

The Hudson project has invested heavily in getting great cluster support which helps tremendously with Selenium which has invested as heavily in clustering.

How to you deal with Selenium needing a GUI while Hudson agents are largely headless. Use the Xvnc plugin! On Windows things are bit trickier, easier to let Hudson agent/service &quot;interact with desktop&quot; such that it can access dialogs/etc. Failing everything else, configuring Windows for auto-login and then have JNLP agents autostart at login will work for allowing the agent to use the GUI and network resources.

The rest of the session was dedicated to some good Q&amp;A. Great session by Hudson’s founder.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/20/pre-javaone-hudson-meetup-redux/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">20</div></div><h5 class="title">Pre-JavaOne Hudson Meetup Redux</h5></div><p class="teaser">Yesterday Digg was kind enough to host and &quot;sponsor&quot; (read: free drinks and
pizza!) a Hudson meetup at their offices in San Francisco. While Digg has been
the source of some controversy and press due to their recent redesign and corporate
shake-ups, as far as the Hudson community goes they’ve been largely responsible for
a great case study on continuous deployment using Hudson and Gerrit. image:https://farm5.static.flickr.com/4130/5005123971_403f24733d.jpg

Attendees included all of InfraDNA (Kohsuke and Kedar), some folks from CloudBees, a
number of local users/developers like LewisHam and myself, and
to top off the list a couple Oracle employees including Winston Prakash who is now hacking on Hudson inside of Oracle.

As folks started arriving there was a lot of discussion around &quot;Hudson at Scale&quot;, specifically
regarding Hudson &quot;in the cloud&quot;. We also got to hear about one of the most interesting Hudson
use-cases I’ve ever seen by Edward M. Goldberg who I’ll post an
interview with shortly, imagine using Hudson with thousands of machines, it’s that interesting.

Through the afternoon there were a number of great discussions concerning Hudson stability,
engaging more of the community and nitty-gritty details regarding Hudson’s internals such
as the plugin API.

I’ve posted photos from the event on
Flickr for posterity in case you’re interested. Overall I’d judge the meetup to be a success, it was a
lot of fun and a great way to spend a Sunday with Hudson.

If you’re going to be at JavaOne, come track me down and let’s talk about Hudson, if you’re not in San Francisco for the event, you can always follow my updates on Twitter or hit up Flickr<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/20/tweet-of-the-day/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">20</div></div><h5 class="title">Tweet of the Day</h5></div><p class="teaser">Some of you may have been following all the photos posted to the hudsonlabs Flickr account from this year’s JavaOne conference in San Francisco.

Alan O’Leary responded to this photo with one of the funniest comments of the day:
&quot;Java and Oracle - &#x27;In Opposite Directions&#x27;&quot;<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/21/javaone-day-one-in-pictures/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">21</div></div><h5 class="title">JavaOne: Day One in Pictures</h5></div><p class="teaser">In case you haven’t been following the frequently updated @hudsonci Twitter stream. Here’s a collection of photos I’ve taken thus far.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/21/live-blog-john-smart-demos-advanced-hudson-usage/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">21</div></div><h5 class="title">Live Blog: John Smart demos advanced Hudson usage</h5></div><p class="teaser">Editor’s Note: This is a very rough set of notes from John Ferguson Smart’s presentation at JavaOne 2010. Unlike Kohsuke’s presentation, John spent a lot of time in demos which made live-blogging a bit difficult. image:https://farm5.static.flickr.com/4129/5012383102_cf258075a6.jpg

John takes the stage at 9:30, this presentation is totally different from yesterday’s presentation from Kohsuke

Taking Hudson a little further, beyond just scheduling a build job.

Who is not using Hudson, less than 10% raise hands.

Focusing on the more technical/nitty-gritty things with Hudson. Looking at:

CI Basics

Notification strategies

Quality metrics

Build promotions

Automated deployment
Who knows what build promotions? Who uses build promotions? Very few in the audience use build promotions.

Who uses Hudson for automated deployment, a handful raise their hands. Plenty of Tomcat and JBOSS users automating deployment. John going to use Tomcat for the automated deployment demo in this presentation.

John mentions he’s authoring the &quot;Continuous Integration with Hudson&quot; book, which will be available for download as it comes out.

Let’s talk about Continuous Integration! Summing up what CI is in three words: feedback, visibility and delivery. CI is about snappy feedback. You want feedback in minutes.

Visibility should be associated with continuous integration, getting everybody in the product life cycle into the loop with continuous integration (product people, QA, developers, etc).

What makes Hudson so great? (according to John)

Easy to use

Plenty of plugins/the ecosystem around Hudson for extending/integrating Hudson

Reporting/coverage features

Distributed builds

First demo, the Hudson dashboard (starring the Nested View plugin). Starting with a basic dashboard filled with some unstable and stable builds. Cloudy builds thanks to Cobertura coverage grading.

Using the Nested View plugin to group views to make the dashboard more useflu for a ton of jobs.

Covering build radiators, not enough of the audience uses radiators. John advocates commandeering big monitors for radiators as part of your &quot;notification strategy&quot;

Covering the basic version control integration, John highly recommneds using a &quot;Repository Browser&quot;. &quot;The point is, you want one&quot; John starts improvising with making some changes, pops over to Eclipse and refactors some code, commits and kicks off a build. Navigates to the source changes for the newly broken build in &quot;Sventon&quot;, his repository browser of choice which was connected to the job

John shows the job using Maven integration and deploying artifacts to the Maven repository he’s set up on his local machine.

Hudson will automatically keep track of jar files/war files, so enable the &quot;Discard Old Builds&quot; checkbox to prevent Hudson from eating all kinds of disk space. Useful to only discard the artifacts for the last X builds instead of the test results/code coverage.

Desktop build notifiers are quite useful, email can tend to get clutter/lost in the mess with everything else coming into your inbox.

Test results integration

Going into the test results dashboard per-build and the test-result and build time trends for a specific job.

Why is the build time trend useful? If the build suddenly takes a huge amount of time to run, you’ve likely got performance issues that need fixing.

Publishing HTML reports

Starring the HTML Publisher plugin! Using the plugin to publish HTML reports generated from easyb for publishing acceptance test results for more wide-spread consumption.

Bouncing from HTML reports to integrating with Sonar for code quality metrics

Build Promotion

Starring the Promoted Builds plugin! Covering some similar concepts to Kohsuke’s talk yesterday but literally going into the Hudson configuration and setting it up.

Time is running out, John’s flipping back and forth between the M2 release plugin and his automatic deployment to his local Tomcat environment.

Q&amp;A
&quot;Can Hudson be used for other environments&quot;. Yes! Supports a number of build plugins, MSBuild, NAnt, CMake, in addition to the freestyle build. &quot;Maven 3 support&quot; Sonatype is apparently working on an integrated version of Hudson with Maven 3, Hudson core planning support &quot;eventually.&quot;<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/21/video-kohsuke-talks-hudson-on-otn/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">21</div></div><h5 class="title">Video: Kohsuke talks Hudson on OTN</h5></div><p class="teaser">For the uninitiated, &quot;OTN&quot; is short for the &quot;Oracle Technology Network&quot; where speakers and other persons of interest sit in front of cameras and their words are streamed live to the internets.

After his session yesterday, Kohsuke hustled over to OTN headquarters, which look suspiciously like a tent in the middle of Mason St., and gave the following interview/chat.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/09/22/javaone-day-two-in-pictures/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">22</div></div><h5 class="title">JavaOne: Day Two in Pictures</h5></div><p class="teaser">On the off chance you’ve not seen some of the photos posted to the @hudsonci Twitter stream, here’s some of the photos from day two of JavaOne.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/10/21/hudson-user-meet-up-in-jerusalem/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">21</div></div><h5 class="title">Hudson User Meet-up in Jerusalem</h5></div><p class="teaser">+
In tradition of taking advantages of my travel, https://www.tikalk.com/[Tikal], https://web.archive.org/web/20171202185204/https://exlibris.co.il/[ExLibris], and https://infradna.com/[InfraDNA] hosted a Hudson users meetup in Jerusalem yesterday. +
 +

+
image:https://web.archive.org/web/20150327193330if_/http://www.gate1travel.com/israel-travel/Images/photos/JerusalemNight.jpg[image] +

+
+

+
There were 10+ people from Jerusalem and Tel Aviv who came over, which was great given the lack of upfront advertisement (my fault.) I did a short presentation about the current state of the Hudson project and where we are focusing efforts on. Then we had a very energetic Q&amp;A sessions that lasted like 3 hours. +
 +

+
image:https://hudson-labs.org/sites/default/files/images/DSC00105.preview.JPG[image,width=400] +

+
+

+
People from Tikal told me that they deploy and manage a lot of Hudson instances, so their feedbacks in the workflow/choreography/orchestration related features were very useful. And as usual, people have some positively fascinating crazy use cases — One of the participants was from a semiconductor company that builds GPU, and he said he tests their graphics cards with Hudson, which involves multiple reboots of a computer, installing software, and making sure the card doesn&#x27;t produce unwanted visual artifacts! +
 +

+
After the discussion, we went out for a nice dinner in a restraunt inside one of the old buildings (one of the many things Jerusalem is good at!), and by the time I got back to the hotel it was 11pm. You can see https://www.tikalk.com/alm/hudson-israeli-users-group-meetup[Ittay&#x27;s take on this meetup here]. +
 +

+
image:https://hudson-labs.org/sites/default/files/images/IMG_0199.JPG[image,height=400] +

+
+

+
One of my concerns before starting this world-wide spontaneous Hudson users meetups was if enough people show up, but I&#x27;m starting to feel comfortable now that I&#x27;ve done several. Hudson appears to be entrenched everywhere, and people are interested in finding out their neighbors who are using them. So stay tuned for future Hudson meetups around the world — it might be in your city!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/11/23/java-net-migration-status-update/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">23</div></div><h5 class="title">Java.net migration status update</h5></div><p class="teaser">+
Monday morning I came into work and discovered that I cannot commit to the Hudson Subversion repository. Initially I wasn&#x27;t worried — I thought it was just another java.net outage that will resolve itself in a few hours — but a little research a bit later revealed that Hudson was locked down and being https://weblogs.java.net/blog/communitymanager/archive/2010/11/03/javanet-begins-migration-collabnet-kenai-infrastructure[migrated to new java.net infrastructure]. +
 +

+
I and the whole community was quite surprised by this, as we are supposed to be &quot;notified as soon as we assign a date for [our] projects to move.&quot; But by the time the developer community noticed, the project was already locked down, repository is read-only, and mailing lists can stop functioning any time. My immediate action was to contact the folks who are doing migration to get Hudson out of this cycle of the migration, but I was told that the ship has sailed and it was too late. +
 +

+
Even worse, there&#x27;s no ETA — it&#x27;ll definitely take a week, but since this is a Thanksgiving weekend, it can take longer, Oracle said. +
 +

+
I find this situation plain unacceptable, and https://java.net/projects/jersey/lists/dev/archive/2010-11/message/3[e-mails from the earlier migration effort] made me doubt if the new infrastructure is any better. I also had a pleasure of working closely with CollabNet folks over the past years and I was also involved in some earlier conversation and experiments about the new java.net infrastructure, and when it comes to performance and monitoring, CollabNet folks really knew what they are doing. So I had multiple reasons to worry if the new infrastructure can handle the load of java.net, which the old CollabNet-hosted one couldn&#x27;t handle. +
 +

+
But fortunately, since the general java.net migration has been announced, we&#x27;ve https://hudson.361315.n4.nabble.com/Mailing-list-change-proposal-td3047548.html[discussed] the migration of some of the project infrastructure. So we&#x27;ve accelerated the plan and implemented it, so as not to lose the critical project infrastructure services. +
 +
 +

Mailing Lists

+

+
Hudson mailing lists are moved to Google Groups. See https://hudson-labs.org/content/mailing-lists[more details here] and https://wiki.jenkins.io/display/JENKINS/Mailing%20List[here]. The new mailing lists provide a real search capability, decent UI for archives, and it makes it easier for people with multiple e-mail addresses to post from multiple addresses and receive just one copy. The stability of the service is also much better. +
 +

Source code

+

+
Hudson core source code has been long synced to GitHub. We&#x27;ve been getting several contributions through that already, and people have been asking https://hudson.361315.n4.nabble.com/On-the-future-of-Hudson-hosting-and-infrastructure-td393278i20.html[for] https://hudson.361315.n4.nabble.com/Git-repository-for-Hudson-td394409.html#a394412[Git] https://hudson.361315.n4.nabble.com/hudson-plugins-git-repository-td1477941.html[migration] https://hudson.361315.n4.nabble.com/Hudson-on-github-td2252960.html[for] https://hudson.361315.n4.nabble.com/Expose-the-Hudson-SVN-as-a-GIT-repository-td391333.html[long] https://hudson.361315.n4.nabble.com/version-control-for-hudson-source-bidirectional-git-lt-gt-svn-td978706.html[time] anyway. So going forward I&#x27;ll be committing to and producing releases from https://github.com/hudson/hudson[the Hudson repository on GitHub] at `+https://kohsuke@github.com/hudson/hudson.git+`. +
 +

+
The new Git-based repository would be far snappier to work with, and it&#x27;ll make it easier for people to maintain private changes and contribute changes back. There&#x27;s also a work in progress to set up Gerrit to streamline the patch review process to the core. So I think this further reduces the barrier of entry to the Hudson project and accelerate the progress. +
 +

+
The migration of Hudson plugin repositories still needs to be discussed, so stay tuned for the updates in https://groups.google.com/group/hudson-dev[the dev list] today or tomorrow. I&#x27;ve developed a bulk import program whose output can be seen https://github.com/HudsonLabs[here], so I&#x27;m going to propose this as the migration strategy. +
 +
 +

Conclusions

+

+
My apologies that these changes had to happen quickly — I&#x27;m just as frustrated as you are, but given the circumstances, I think this is the best course of action. Hopefully everything will be in place within a few days. And in the mean time, thanks for your patience. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/11/23/new-hudson-mailing-lists/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">23</div></div><h5 class="title">New Hudson Mailing Lists!</h5></div><p class="teaser">As Kohsuke mentioned in this post, the Java.net migration has caught just about everybody off-guard in the Hudson community.

The tools we use hosted by Java.net are essentially locked from us until further notice (no ETA on the migration) which is, as you might imagine frustrating both for the core developers but hundreds of plugin developers that make Hudson the best damned CI server on the planet.

For source code we’re working on getting something in place for contributions on GitHub thanks to some assistance from the GitHub team.

For mailing lists we’ve gone ahead and dumped Java.net mailing lists in favor of a collection of Google Groups:

hudson-dev

hudson-users

hudson-commits

hudson-issues

Contrary to popular belief, you do not need a Google account to subscribe to these lists, else we wouldn’t have chosen Google Groups. All you need to do is send an email to &quot; hudson-users+subscribe@googlegroups.com&quot; and you’ll receive a confirmation email from the mailing list server shortly.

Since our issues.hudson-ci.org isn’t actually hosted on Java.net, but rather on a machine provided by Oracle, they should continue to function as per usual. The login for the systems is somewhat tied to Java.net so I am honestly not sure how stable they will be this week.

I apologize sincerely for the confusion and frustration, you can trust that we’re likely ten-times more frustrated with this situation right now.
---<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/11/30/whos-driving-this-thing/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">30</div></div><h5 class="title">Who&#x27;s driving this thing?</h5></div><p class="teaser">There’s been a lot of discussion on the new mailing lists as of late regarding some of the infrastructure and ownership of the Hudson project. In case you haven’t been following along at home, I’ll try to catch you up as impartially as possible.

The Facts

2009.06.02 : After substantial problems with Java.net infrastructure, the
dev community discusses new infrastructure
options,
including SourceForge, Google Code, Kenai, Berlios, GitHub, etc. Instead of
moving the entire project, some key components such as the
issues.hudson-ci.org are moved off of
Java.net. Discussions about moving source code off of Java.net and onto other hosts like
GitHub come up almost every four months on the mailing lists, typically
coinciding with serious Java.net downtime or reliability issues..

2010.11.01 : A discussion occurs on the developers mailing list about
adding Winston Prakash, the Oracle engineer re-assigned to replace Kohsuke Kawaguchi (Hudson
founder/lead developer), as a co-owner to the Java.net project. Winston
mentions that his question was driven by Oracle management who felt he should
&quot;co-own the project.&quot; After a round of discussion, it’s decided by the devs
list that it’s acceptable and grants Winston co-ownership of the project as a
sign of good faith from the community towards Oracle.

2010.11.17 : Andrew Bayer, core contributor
and maintainer of numerous plugins emails the users and devs list with a
proposal to move the mailing lists off of Java.net which has had notorious
reliability issues within the Java ecosystem and was scheduled for a series of
downtimes and migrations over the coming weeks. Google Groups is selected as the
most reasonable by the community.

2010.11.19 : Hudson project is lumped into the same Java.net migration bucket as Glassfish. Emails are sent to project owners, the users and the developers list. The mail to users and developers never arrives due to the sender not being subscribed. Both project owners (Kohsuke, Winston) miss the message, leaving the Hudson community in the dark regarding the pending migration.

2010.11.22 : Shortly after midnight, Jacob Robertson reports that his
SVN credentials no longer work, Kohsuke informs the developers list that the project is
locked due to the migration, SVN is inaccessible and mailing lists fail shortly after that. The Hudson Java.net project
begins its migration from the legacy infrastructure to the newer
Java.net infrastructure (formerly known as &quot;Kenai&quot;). A group of core Hudson
community members accelerate the move to Google Groups, pushing out
announcements via this
blog and
twitter hoping to keep as many members in the
loop as possible.

2010.11.23 : Frustrated by the locking down of Hudson’s source code,
which sees between 3-8 commits to &quot;core&quot; a day, not counting the 300+
plugins, Kohsuke proposes moving to
GitHub
on the new developers mailing list. The general consensus amongst the plugin
and core developers was to go forward with moving to GitHub, no major
objections were raised by the developer community.

2010.11.27 : After Thanksgiving, Andrew Bayer submits the &quot; formal
proposal&quot;
for migrating over to GitHub, Sets a deadline of the following tuesday
(2010.11.30) for raising any major objections before &quot;flipping the switch.&quot;

The Monday morning prior to the planned switchover to GitHub, Oracle Senior VP
of Tools and Middleware Ted
Farrell sent a
message to the users list expressing concerns he had regarding the migration of
the Hudson codebase from Java.net to GitHub:

Oracle’s goal is to grow the community and make hudson stronger. You all might not be aware of this, but the actual hudson user base is very large. Much bigger than what you see on the mailing lists or in the forums. The unfortunate part of that is how many of these users do not contribute to the core, and do not participate in these discussions. They want to do that, but don’t feel like they can be heard. We want them to be heard. We need to make the hudson community a place that will welcome all the hudson users and encourage its growth and longevity. We will be announcing some changes in the upcoming weeks that we believe will foster that.

For now, however, we are going to stay on the java.net
infrastructure.  We believe it is important for hudson to stay
connected with the rest of the the java community, as well as take
advantage of some of the cool changes we will have coming to
java.net.  Moving to GIT can be done while staying on java.net.  It is
not a requirement to move to github.

…​

Because it is open source, we can’t stop anybody from forking it.  We
do however own the trademark to the name so you cannot use the name
outside of the core community.  We acquired that as part of Sun.  We
hope that everyone working on hudson today will do as they claim to
want, and work with us to make hudson stronger.

(Ted’s message was rather long, you can read the whole
post here)

As one might expect, Ted’s response to the thread was received with
mixed responses ranging from general confusion to obvious frustration.

Long time contributor to Hudson’s Git plugin, Nigel Magnay tried to clarify the benefits of migrating to GitHub instead of using Git on the &quot;new&quot; Java.net as succinctly as possible:

Just having git support != git support on github. They work full time on providing the best community development tools; I doubt kenai could even catch up, let alone surpass what they’re doing.

…​

I’m confused.

What things are you saying you will not let the Hudson developer community
do?

I.E: Are you saying that, as the holders of the Hudson &#x27;name&#x27;, you are
prohibiting the developer community from choosing (for ourselves) to migrate
the infrastructure (bug tracking / wiki)? The repositories ?

So far the response from the developers has been pretty strongly in favour
of the migration to google groups for mail, to github for code repositories
and collaboration, and to a self-hosted site for bug tracking and
information.

Ted’s response to Nigel contained one of the most important nugget of
information for the whole discussion nestled in the middle of the message :

Nigel, what I am saying is that I believe the _final decision of what to do w.r.t. infrastructure belongs to Oracle and that decision should be made according to the will of the community as it makes sense_

The part where I editorialize

I readily admit, there is a lot of information to take in here, for clarification there are two distinct &quot;communities&quot; involved in Hudson:

developers : the hundreds of developers actively communicating on the
developers list and
contributing to the 300+ plugins

users : tens of thousands of individuals and companies using Hudson
either as a straight.war file, or using the native packages provided by
the community

The fundamental issue here is that the developers want to make a change in
how they contribute to Hudson, and have made their voices heard to that end.
From the users&#x27; perspective, such a change would have literally zero impact
on them, which makes Oracle’s conflation of the two sides of Hudson
particularly frustrating.

Part of the impasse between Oracle management and the developer community lies
in an inherent meritocracy in any large open source project, whether it be the
Linux kernel, the Python language and runtime, or the PostgreSQL database
server, those that contribute carry more weight within the community
because they are actively pushing things forward. On top of that, Oracle
continues to cite a &quot;larger community&quot; that’s apparently larger than those
active committing to Hudson on a daily or weekly basis, without naming names or
citing specific contributions.

Ted, and in turn, Oracle’s approach to the Hudson community seems to stem from
a systematic misunderstanding of how most (if not all) major open source
projects operate. Mentiong closed-door meetings between Sonatype and Oracle
regarding &quot;how to make Hudson better&quot; do nothing to aid many developers&#x27;
concerns about Oracle’s commitment to Hudson as an open source project or a
community.

In my humble opinion, we are being told one thing while Oracle’s actions speak
to another. Insisting that Hudson development remain on Java.net, after the
development community committed to GitHub, contradicts the words promising to
work with the Hudson community and to help facilitate its growth. Asserting
that Oracle isn’t trying to exert unwelcome control over the project, while
doing exactly that.

Personally, I do want Oracle to continue to be involved, along with CloudBees,
Sonatype and many other companies that contribute to the ever-growing Hudson
ecosystem. The involvement of a plethora of different companies only helps
emphasize the importance of Hudson to the developer community and underline the
value of Hudson as a community owned and operated project.

December will be an interesting month, stay tuned.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/12/01/a-brief-update/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 1</div></div><h5 class="title">A brief update</h5></div><p class="teaser">Let me be the first to say thank you all for your overwhelming support for
Hudson and the work we’ve been doing. The Hudson community in general has
always been incredibly supportive and friendly, but the outpouring of support from
friends and users who’ve not previously spoken up has been awe inspiring.

That said, let’s get down to business. As I covered
yesterday there is some
bubbling frustration within the developer community regarding some project
infrastructure decisions and Oracle’s reactions to them. If you can’t spare the
time to read that novel of a blog post, the extremely shortened version is: devs want to
move codebase to GitHub, Oracle disagrees and claims to have final say (hijinks
ensue).

While there is still a lot unresolved, several of the core contributors are
debating and weighing our options for moving forward in a way that best
suits Hudson both as a project and community. In the next couple days, Kohsuke
or Andrew will be proposing a course of action for the community after some of
the options have been fully vetted. Please bear in mind that Hudson is a very big project with some fairly unique needs. We have hundreds of contributors committing either to core or the plugins, we release core once a week with plugin releases occurring to the tune of 20-40 updates a week. We’ve been pinging folks who work with various foundations and major open source projects to make sure we’re covering all our bases to make sure distractions like this don’t come up again for the foreseeable future.

Due to issues with MySQL, Java, OpenOffice/LibreOffice, there is clearly a lot of anti-Oracle emotion out there right now, but I want
to make sure that it’s clear that this is not about &quot;Us versus Oracle.&quot;

Our goal isn’t to &quot;stick it to the man,&quot; that doesn’t help make Hudson any better.

Our goal is to foster the kind of community that we all want to
participate in, and to build and improve the best continuous integration
server available.

Stay tuned :)
---<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2010/12/05/weekend-update-with-andrew-bayer/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 5</div></div><h5 class="title">Weekend Update with Andrew Bayer</h5></div><p class="teaser">[ Ed. note Andrew was not involved in selecting this post’s title - rtyler ]

I wanted to give the Hudson community a quick update on the current status of the issues Tyler has discussed in the earlier posts here.

Friday afternoon, Kohsuke, CloudBees CEO Sacha Labourey and myself jumped on a conference call with Hudson contributor/Oracle employee Winston Prakash, Oracle manager Denis Tyrell and of course Ted Farrell.

We discussed a wide range of issues relating to the Hudson project, such as governance, the rights to the name Hudson, and the infrastructure hosting the Hudson project. While we didn’t agree on resolutions to all issues, I feel real progress was made towards a framework that provides what the Hudson community needs while also preventing the sort of conflicts we’ve seen the last week or two.

More work has to be done - we’ll be talking again next week, and I’m hoping we can reach agreement on the contentious issues by the end of the week.

Thanks for your patience.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/01/08/installing-plugins-has-always-been-easy-now-its-fast-too/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 8</div></div><h5 class="title">Installing plugins has always been easy, now it&#x27;s fast too!</h5></div><p class="teaser">As one of the &quot;men behind the scenes&quot; of the Hudson project, a lot of my contributions tend to be in writing articles or handling infrastructure, anything to ensure folks like Kohsuke can continue to make Hudson great without being distracted by inane system administration tasks. This past week, one of my long-running infrastructure projects has finally &quot;gone live,&quot; making downloads of plugins and packages faster than ever!

Some number of months ago I became frustrated with the download speeds reported by our international users, while the majority of Hudson’s infrastructure is all colocated inside of the United States, there is a huge number of Hudson users and developers who are both in Europe and Asia.

After discussing things with some of the folks that run download.opensuse.org, a MirrorBrain powered redirector, I set out to build something similar. A mirroring network which could be easily managed and help direct users&#x27; downloads to the geographically closest and fastest mirror available.

Where are we mirrored?

Currently we have mirrors in a few locations within the United States, and one overseas:

Southwest U.S. (Utah) - Thanks to XMission

Midwest U.S. (Chicago) - Thanks to the OSUOSL

Northeast U.S. (New York City) - Thanks to the OSUOSL

Germany - Thanks to aragost Trifork ag

Using the mirrors

If you’ve updated or installed plugins from within Hudson lately, guess what! You’re already using mirrors! In fact, since we flipped the switch on January 7th, over 800 plugins and 600 hudson.war updates have been downloaded from the mirroring network!
If you’d like to download directly from the mirrors, you can browse on over to mirrors.hudson-labs.org, which will redirect your request for specific files to the appropriate mirror based on your IP address. It’s just that easy!

We are currently working with more providers to add additional mirrors, hopefully we’ll have an Asian mirror online within the next two weeks and if we’re lucky, we’ll find some more European mirrors too.

I would like to thank the immensely helpful and supportive engineers over at the OSUOSL for offering gratis tech support, suggestions, and bandwidth to serve as our primary mirror.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/01/11/hudsons-future/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">11</div></div><h5 class="title">Hudson&#x27;s future</h5></div><p class="teaser">First, my apologies for the lack of updates on the Hudson/Oracle situation for
the last few weeks. While talks have been ongoing, the holidays have slowed
things down, and we didn’t want to send out information that would later turn
out not to be true. We’ve been waiting for the talks to reach a resolution -
and I believe they now have.

Since the java.net migration problems, Oracle and representatives from the
Hudson community have been involved in talks on the future of the project in a
number of areas. The Hudson representatives have been myself, Kohsuke
Kawaguchi, and Sacha Labourey (CEO of CloudBees and Kohsuke’s boss), who was
brought in to help provide experience with discussions on a corporate/executive
level which neither Kohsuke nor I have, with Alan Harder and R. Tyler Croy
advising on the side.

These talks have in many ways been fruitful - we came to working agreements
with Oracle on the project infrastructure (such as mailing lists and SCM
repository location), code review policy for Hudson core, and perhaps most
significantly, a governance structure for the project going forward. Some
issues are not yet entirely resolved, such as questions on restrictions on
third party dependency licenses. But one issue, which we feel is the most
significant issue of all, one for which we now believe no resolution is
possible: the rights to the name Hudson.

Oracle has told us that they have trademark applications filed in both the EU
and US for Hudson, based on Hudson’s creation by Kohsuke while working at Sun.
The problem is that this trademark ownership gives Oracle the ability to revoke
the Hudson project’s right to call itself Hudson at any time, and while Oracle
has made an attempt to offer some guarantees (most notably, that binary
releases of Hudson, once they’ve been released with the name Hudson attached,
will always retain the right to the name), they are not offering any binding
guarantee that the Hudson project will be able to retain its use of the name in
perpetuity.

Therefore, to continue using the name Hudson means ceding some of the project’s
independence to Oracle - if the project and its governance board opted to go in
a direction Oracle disapproved of, Oracle would be able to take away the naming
rights. Or, in a less dramatic scenario, Oracle could insist on certain changes
to the code, infrastructure decisions, process, etc, regardless of opposition
from the Hudson development community, in order to retain the rights to the
name.

In short, we’d be living under a sword of Damocles, regardless of the goodwill
of the individuals we’ve been negotiating with at Oracle - Hudson as a project
would be beholden to Oracle’s whims for its continued use of its own name, and
we believe that’s not viable.
As I see it, the only viable option facing the project now is to rename it, in
order to free it from the burden of Oracle’s ownership of its name. This is not
a first choice, not by a long shot, but I don’t see any other choice available
to us that would preserve the integrity of the project going forward. Oracle
will be presenting their proposal for the project continuing under their
umbrella - I encourage you to read it when it becomes available and weigh it
accordingly. I’ll just focus on what Kohsuke, other prominent Hudson community
members and I have endorsed.

The Proposal

First, we rename the project - the choice for a new name is Jenkins, which we
think evokes the same sort of English butler feel as Hudson. We’ve already
registered domains, Twitter users, etc for the new name, and have done our best
to verify that there are no existing trademarks which would conflict with it.
Kohsuke will be registering the trademark for Jenkins in his name, with the
intent of transferring ownership of the trademark to the umbrella of the
Software Freedom Conservancy once the Jenkins project has been admitted to it
(which, I should add, is very much our plan, hopefully in their next round of
new projects in a few months - we’ve already had preliminary contacts with
SFC). We still invite Oracle to remain involved with the project, on equal
terms with all other contributors, and hope they’ll take us up on this
invitation.

Second, out of respect for Oracle’s trademark claim on Hudson, we will move our
infrastructure off of Oracle-owned and hosted servers, and we will rename
existing independent components of the infrastructure to no longer use &quot;Hudson&quot;

i.e., mailing lists, Github repos, etc. This would be a gradual process,
obviously.

Third, we will put in place an interim governance board for the project,
consisting of three members - myself, Kohsuke and, if Oracle elects to remain
involved, Winston Prakash, the Oracle engineer working on Hudson. The interim
board members will serve for the next 3-6 months, until the governance
structure can be nailed down securely enough to hold elections for the board
members.

Obviously, such a move could not be undertaken without the agreement and
support of the Hudson community. We believe this proposal is the best choice
for the project in the situation it’s currently in, but we aren’t closing off
discussion, questions, etc, and we encourage your feedback and comments. If
there’s anything you need clarified, please ask and we’ll do our best to
answer.

Once Oracle’s proposal is available later this week (hopefully Wednesday,
possibly Thursday, from what I’ve been told), which I strongly advise you all to
read and consider, we’ll be putting up a poll to determine the position of the
community. Once that vote is done, assuming the consensus is to rename, we’ll
put the mechanisms in motion and switch over as fast we can.

There may be some confusion as to whether we’re proposing to fork Hudson, or
rename the existing project. I firmly believe we are proposing the latter - for
me, the project’s key component is Kohsuke himself. If the community decides to
support renaming the project to Jenkins, and Oracle chooses to continue
development themselves under the name Hudson, they are, obviously, entirely
welcome to do so. But with Kohsuke working on Jenkins, that’s the true home and
the future of the project for me, regardless of the name.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/01/29/jenkins/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">29</div></div><h5 class="title">Jenkins!</h5></div><p class="teaser">(This was sent as an email to the Hudson dev and users mailing lists after voting concluded, but I thought it’d be good to post it here as well.)

The vote is closed, and the results are in. More than half of the total votes were from ineligible voters, but the result would have been the same either way. The final result of all eligible votes is as follows: 214 votes to rename, and 14 for the status quo. You can see the individual votes hudson-jenkins-vote.
So what does this mean now? Well, it means Jenkins lives. We’ve registered jenkins-ci.org, though it’s empty at the moment. In the coming days, we will be renaming the existing Google Groups to jenkins-*@googlegroups.com, renaming the Twitter account from @hudsonci to @jenkinsci, and renaming our organization at Github from hudson to jenkinsci. I wanted to make sure everyone had notice ahead of time that this was happening, so that no one gets surprised by changes to their incoming mail, etc. As said before, the initial, interim governance board will consist of me, Kohsuke and, if he and Oracle are willing, Winston. If Winston is unwilling or unable to continue in that role with Jenkins, we will select a replacement interim member. The interim board will work on the details of a more permanent governance process going forward. Discussions on the infrastructure changes (including things like the Maven groupId/artifactIds, etc) will be in public, on these lists. We’re working to get the JIRA and wiki contents migrated over to the Jenkins site, and hope to work with Oracle to get that done in the next couple days.

Putting aside logistics, I want to personally thank everyone for voting, and especially thank everyone who voted for renaming for supporting the Jenkins project and its future. Jenkins is not Oracle’s project, nor CloudBee’s project, nor my project, nor Kohsuke’s project - it’s the community’s project, and it’s going to thrive.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/02/04/governance-meeting-today/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 4</div></div><h5 class="title">Governance Meeting Today</h5></div><p class="teaser">Amongst all the work this week with setting up project infrastructure, the first release of Jenkins and a flood of developer activity on GitHub, the interim governance board has decided to hold periodic virtual meetings.

The first meeting will be held today at 3pm PST (23:00 UTC) in the #jenkins channel on IRC ( more details here).

In Kohsuke’s post to the mailing list, he further explained the goals of such meetings:

We can use it to report/discuss various issues of the project (not bugs in code, but more project level stuff.) I also plan to report the infrastructure work that’s done thus far.

We’d like to hear from you, and the point is to engage the broader community, so please join us.

This is a new thing, so it’s not like we’ve figured this all out, but let’s see how it goes.

If you don’t have an IRC client, you can use the Freenode webchat client to join in, hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/02/04/the-first-24-hours-in-downloads/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 4</div></div><h5 class="title">The first 24 hours in downloads</h5></div><p class="teaser">As I had mentioned in a previous post back when Jenkins was called something else, who can remember what anymore, I spent a lot of time working on a mirroring network. With our departure from any and all Oracle infrastructure, this mirroring network has now become our sole distribution mechanism for pushing out all releases and all plugins, in short, lots and lots of bits.

Just how much data are we now distributing through the Jenkins mirror network?

Over 52GB in 24 hours

Here’s the following in terms of a loose breakdown of the number of files served over the past day:

788.war

447.deb

290.rpm

1759.hpi (plugins)

We’re off to a great start! I’d like to extend my thanks again to the OSUOSL and XMission for their help getting the Jenkins mirrors functional as soon as possible<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/02/05/first-governance-meeting-recap/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 5</div></div><h5 class="title">First Governance Meeting Recap</h5></div><p class="teaser">As mentioned on Friday the Jenkins project held it’s first meeting on the IRC channel at the request of the interim board. In the interest of transparency, we recorded meeting minutes and tried to involve as many folks as possible.

Topics Covered

Proposal/Discussion of Jenkins project governance structure

What to do about the logo

Registering the Jenkins trademark

Moving Jenkins under an umbrella organization

What shall we do with a new CLA?

Logistics for the next project meeting

If you’re interested, you can read through the full logs or just look over the high-level meeting minutes.

This first meeting went a bit long due to the massive amount of items needing to be discussed, so the project has scheduled another meeting for Wednesday Feb 9, 11am PST (19:00 UTC); mark your calendars!

Thanks to everybody who participated, we’ll see you again next time.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/02/14/upcoming-jenkins-events-in-tokyo/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">14</div></div><h5 class="title">Upcoming Jenkins events in Tokyo</h5></div><p class="teaser">+
image:https://farm4.static.flickr.com/3280/2964930888_6a91b9ddda_m.jpg[image] +

+
+

+
I&#x27;ll be visiting Tokyo again for the week of 2/21 for a number of events. +
 +

Tokyo Jenkins User Meetup

+

+
The Japanese Jenkins user community may not be as visible from outside but very strong. This is the 2nd meet up in Tokyo, and once again we maxed out the 80 people room capacity in just a few days (but you can https://kokucheese.com/event/index/6710/[still RSVP for the social event] after the meetup.) This meetup is focused on Java &amp; Jenkins, so we have a number of speakers lined up to discuss hwo they use Jenkins in their Java projects. This will be the first user meetup event after the name has changed to Jenkins. +
 +
 +

CloudBees Jenkins training in Tokyo

+

+
I&#x27;ll deliver this one-day training course, all about Jenkins from the setup to continuous deployment to code analysis. If you are interested, you can find https://www.cloudbees.com/training_ja.cb[more details about this]. +
 +
 +

Japan Grails/Groovy User Group (JGGUG)

+

+
Jenkins internally use Groovy a lot in many places (as well as some of its peripheral tools depend on Groovy.) So I&#x27;ll be speaking in the JGGUG meetup event, on behalf of the Jenkins project, and highlight those usages and how much we all love Groovy. Yes, I do. +
 +

+
Aside from these public events, I have a few visits planned to various companies. If you are interested in having me over and look at your Jenkins, or want to discuss something, please let me know at kk at kohsuke dot org.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/03/03/updated-usage-stats-available/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 3</div></div><h5 class="title">Updated Usage Stats Available!</h5></div><p class="teaser">Updated usage statistics are now available at https://jenkins-ci.org/census This data has been scrubbed of distinguishing information as much as possible, filtered for installations we’ve seen at least twice a month with at least one job set up, and split up into monthly JSON files. Starting with August, we only have data on installations of version 1.368 or later - before that, reports go to the old Oracle-owned server, and we aren’t able to retrieve them. So that’s why you’ll see a fairly hefty drop in install count, etc from July to August.

I haven’t had a chance to do any analysis to speak of on the data. I intend to get the plugin usage spreadsheet updated n the next few days, but I wanted to make this data available to you all ASAP. If you come up with any interesting analysis or use of the data, please let us know!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/03/13/jenkins-hits-1-400/"><div class="header"><div class="date"><div class="month">March</div><div class="day">13</div></div><h5 class="title">Jenkins hits 1.400</h5></div><p class="teaser">+
https://jenkins-ci.org/[Jenkins] is now at 1.400 (as of last Monday, yes, I know. But better late than never...). As with https://weblogs.java.net/blog/2009/04/22/hudson-hits-1300?force=752[1.300] and https://weblogs.java.net/blog/kohsuke/archive/2008/03/hudson_hits_120.html?force=824[1.200], this release doesn&#x27;t particularly signify any substantial major release, but nonetheless it is a milestone for those of us who are involved in the project — I think repeating something 400 times is something one can be proud of. It&#x27;s a bit like climbing a mountain. Left foot, right foot, left foot, right foot, ... and when you look up, voila! +
 +

+
In 2 years since 1.300, which was April 2009, we&#x27;ve added a lot of features. We now have a CLI to manipulate the server, auto-installation of JDK/Ant/Maven to simplify cluster management, concurrent builds of the same job, community-contributed localizations to 20+ languages, boolean expression over the job/label assignment control, parallel initialization based on a dynamically built acyclic directed graph, console annotations to enrich the build output, far more extensible queue (that enabled a lot of plugins), Windows 7 / Vista support, improved controller/agent communication stability, Maven 3 support, and then all around performance improvements, in memory footprint, in startup time, and in page rendering speed. +
 +

+
And of course, we had to change the name of the project. That was a real distraction, but now that the divorce is over, things have been https://bobbickel.blogspot.com/2011/03/jenkins-vs-hudson-time-to-upgrade.html[moving well] for Jenkins. I guess any organization (including any sizable OSS project) is really more than sum of all individuals. If you take a store of Target and replace all its workers by those of nearby Staples, it&#x27;ll probably not work out well. I think https://jenkins-ci.org/why[people understand that]. +
 +

+
And on the positive side, I do think we came out stronger. We are now running https://jenkins-ci.org/node/280[governance meetings on IRC], we now have https://jenkins-ci.org/content/jenkins[somewhat more formal governance structure]. The core development is actually accelarating with the help of https://github.com/jenkinsci/jenkins/graphs/impact[many new developers], such as Olivier Lamy, (scroll to the right), and https://twitter.com/#!/jenkins_release[plugin releases kept coming at amazing rate] — we are now at 350+ plugins, more than doubled since 1.300. +
 +

+
Looking at future, we are working on a number of new initiatives in the community, too. For example, Arnaud Héritier is working on revisiting https://issues.jenkins.io/[our JIRA project structure], Andrew Bayer is running a contest for new logo, Tyler is in process of getting additional hardwares at OSUOSL for the project. I&#x27;m also doing a lot of things, but for example, I&#x27;m going to write a proposal to start a stable patch releases of Jenkins that only consists of backported important bug fixes, in addition to the current weekly release model. Several large users maintain private branches of Jenkins, and so I think it makes a lot of sense for those folks to align their efforts around this release line. I&#x27;m also thinking that we could launch a community acceptance testing (CAT) effort around this, much like https://qa.netbeans.org/processes/cat/67/faqs.html[NetBeans] and https://glassfish.java.net/quality/portal/[GlassFish] have done it. I think the first stable release line would branch off from 1.400, so if anything that&#x27;s another reason you should upgrade to 1.400. +
 +

+
When I reflect on the project, I&#x27;m surprised at just how much work there is to be done, after so much that has been achived. But I&#x27;m still excited at what we can do with this platform. I thank everyone for their continued patoronage of Jenkins, and I hope to see more of you in the mailing lists, in the chat rooms, and in the meet-up events. And here is https://en.wikipedia.org/wiki/Buzz_Lightyear[to infinity and beyond!] +
 +

+
(Cross-posted to https://kohsuke.org/2011/03/13/jenkins-hits-1-400/[Kohsuke&#x27;s blog])<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/03/21/the-polls-are-open-for-the-jenkins-logo-contest/"><div class="header"><div class="date"><div class="month">March</div><div class="day">21</div></div><h5 class="title">The polls are open for the Jenkins Logo Contest!</h5></div><p class="teaser">After a number of absolutely fantastic logo submissions from a number of designers, I’m extremely pleased to open the polls on the vote for the brand new Jenkins logo!

The thumbnails do not do any of these logos justice in my opinion, so I recommend opening each logo up in its own tab to get the full effect :)

I plan to end voting March 28th at 12:01 UTC.

The Logos

Logo #1
Logo #2
Logo #3

Logo #4
Logo #5
Logo #6

Logo #7
Logo #8
Logo #9

Logo #10
Logo #11

The Vote

If the iframe doesn’t properly load for you, you can open Loading...&quot; class=&quot;bare&quot;&gt;https://spreadsheets.google.com/viewform?formkey=dE9GNlpNbVEwa0VPZHl1TkJCaUI1Z2c6MQ Loading...<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/03/23/windows-installers-are-now-available/"><div class="header"><div class="date"><div class="month">March</div><div class="day">23</div></div><h5 class="title">Windows installers are now available</h5></div><p class="teaser">+
Good portion of Java developers use Windows, so we tend to think the opposite is true, that a good portion of Windows folks use Java. But this is not true. +
 +

+
As Jenkins gains traction among .NET developers, it&#x27;s becoming increasingly clear that Java is very alien to them. They naturally have no idea of what a war file means, and often don&#x27;t even have Java installed, and so it was _just not easy enough_ for them to start using Jenkins. +
 +

+
I&#x27;m happy to report that I&#x27;ve finally fixed this problem with the new Windows installer. It is primarily packaged as https://en.wikipedia.org/wiki/Windows_Installer[an MSI file] — a common format that seasoned Windows devs/admins are familiar with. It can, for example, be deployed remotely on a large number of servers via Active Directory remotely. Or you can just double-click it to install it interactively. It bundles JRE, so no separate Java installation is needed. +
 +

+
The package also contains the bootstrap `+setup.exe+`, to install .NET 2.0 runtime if it&#x27;s not installed yet. Between that and JRE, it got all the dependencies covered. I tested that by installing it on a fresh Windows XP install. +
 +

+
So I hope this makes Jenkins more attractive to .NET and other developers who live and die by Windows.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/04/01/san-francisco-jenkins-meetup-wednesday-april-13th/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 1</div></div><h5 class="title">San Francisco Jenkins Meetup - Wednesday, April 13th</h5></div><p class="teaser">We’re happy to announce that there’ll be a Jenkins meetup in San Francisco on Wed., Apr 13th, generously hosted by Engine Yard. The meetup will start at 6:30 - you can find more information here. Dr Nic Williams of Engine Yard will talk about their use of Jenkins with Ruby, and Kohsuke will give an update on the JRuby plugin development work he and cowboyd have been working on. If you’re interesting in giving a short talk on your usage of Jenkins, plugin work, or whatever, there should be time for an open mic. Hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/04/04/the-final-two-run-off-vote-for-the-new-jenkins-logo/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 4</div></div><h5 class="title">The final two: run-off vote for the new Jenkins logo</h5></div><p class="teaser">A little over a week ago we opened the polls to the larger user-base to vote for the new and improved Jenkins logo. After receiving hundreds of votes, we are now ready to enter the final round of voting (click images to see larger versions in a new window).

Voting will end April 9th at 23:59 UTC, so make sure to tell your friends, coworkers and bus drivers to get their votes in as soon as possible!

+ Logo #1&quot;&gt;
+ Logo #2&quot;&gt;

The Vote

If the iframe doesn’t properly load for you, you can open Loading...&quot; class=&quot;bare&quot;&gt;https://spreadsheets.google.com/viewform?formkey=dEl2T1gwdko1YXBxcktiTEJzUXZleUE6MQ Loading...

If you’re interested in the results for the first round, you can find them in this gist<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/04/14/jenkins-new-look/"><div class="header"><div class="date"><div class="month">April</div><div class="day">14</div></div><h5 class="title">Jenkins&#x27; New Look</h5></div><p class="teaser">As you might have noticed Jenkins finally has
a brand spankin&#x27; new logo! Over the past couple weeks we’ve run two series
of votes, one for the initial 11 logo
submissions
and then a final, run-off election, for the two most popular
choices.
I’d like to take this opportunity to thank everybody that submitted logos! It
is incredibly flattering to have so many people passionate about the project
and willing to spend the time creating new art for us. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/images/runoff_election_piechart.png

At the end of the votes, there was a clear winner though, everybody seems to
really love the submission by the folks over at The
FrontSide which you can see adorning this very page.

If you’d like to download the SVG version of the logo, or the variants in different sizes, I’ve gone ahead and uploaded a tarball and all the variants to this directory, there is also a good color palette here ( obligatory PDF warning).

Once again, thank you to everybody that participated!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/05/04/hamburg-hackathon-a-great-success/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 4</div></div><h5 class="title">Hamburg hackathon a great success!</h5></div><p class="teaser">+
Thanks to the kindness of https://www.bigpoint.net/[BigPoint GmbH] and Kutzi, we had the first Jenkins Hackathon in Europe, in a very large and airly conference room in their Hamburg campus, on a nice sunny Sunday of May 1st. About 10 people came, including the https://wiki.jenkins.io/display/JENKINS/Static+Code+Analysis+Plug-ins[static code analysis plugin] fame Ullrich Hafner, https://wiki.jenkins.io/display/JENKINS/Android+Emulator+Plugin[Androd emulator plugin] fame https://twitter.com/orrc[Christopher Orr], the https://wiki.jenkins.io/display/JENKINS/Instant+Messaging+Plugin[instant messenger plugin] (and others) fame https://twitter.com/#!/kutzi[Christoph Kutzinski]. Some of us came from pretty far away places like Munich, Bonn, and Netherland. There was a good mix of existing developers and new developers, too. +
 +

+
During the hackathon, new folks developed whopping three plugins — a security realm that connects to https://github.com/jenkinsci/kerberos-authenticator-plugin[Kerberos (password entering kind, not SSO)], https://github.com/jenkinsci/builton-column-plugin[a plugin that adds a list view column to show where the last build was done], and https://github.com/jenkinsci/extra-columns-plugin/[another plugin that attempts to collect small list view column implmentations]. German translations were improved, automated installation of Android SDKs are discussed and its implementation strategies explained. I&#x27;ve done my share of contribution by working on https://github.com/jenkinsci/jruby-xstream[XStream support for JRuby], which is one of the ground work necessary for JRuby-based Jenkins plugin development, and I also showed the prototype Groovy-based templating that can potentially supercede Jelly. There were additional exchange of tips and tricks, how you do this and that. +
 +

+
Strong coffee and engaged conversations kept me awake all day, although German keyboard layout (on top of usual IDE difference + Mac/PC difference) made it hard to code on other people&#x27;s computers, but all in all it was a very productive hackathon. In fact, the best ever. We wrapped up around 7pm and headed to a seafood restaurant near Elbe river, stayed there until 11pm-ish. +
 +

+
The next hackathon is planned in Paris toward the end of the month. I&#x27;m looking forward to another productive Hackathon, so if you are nearby, please https://www.meetup.com/jenkinsmeetup/events/17178842/[RSVP and join us]. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/05/12/ruby-plugins-hack-session-5-12-2011/"><div class="header"><div class="date"><div class="month">May</div><div class="day">12</div></div><h5 class="title">Ruby Plugins Hack Session 5/12/2011</h5></div><p class="teaser">[ Editor’s Note: For the past few weeks Jenkins community member Charles Lowell has been working with Kohsuke on adding support for building plugins in Ruby. As part of this effort, Charles has been hosting weekly hack sessions via WebEx ]

As always, last night’s Ruby Plugins hack session was a pleasure. Below is a quick notation of what items were discussed and/or accomplished followed by next steps to be taken my those in attendance.

Discussion/Accomplished

Ruby Plugin project structure and how to bundle into an .hpi file.

Review of the new XSTREAM serialization method

API for marking fields as transient

What mods, if any, are required to get .hpl to work with Ruby plugin

Next Steps

Charles

to research what can be shared between JRuby ScriptingContainer s

API for unmarshaling hooks on serialized ruby objects

Change the name of the repo :)

Document…​ something!

Kohsuke

test more view functions

add debug mode outside of hpi:run<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cowboyd/">Charles Lowell</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/05/12/the-state-of-the-jenkins-project/"><div class="header"><div class="date"><div class="month">May</div><div class="day">12</div></div><h5 class="title">The State of the Jenkins Project</h5></div><p class="teaser">A few weeks ago our very own Kohsuke Kawaguchi gave a presentation at the Silicon Valley CI Summit held in Mountain View.

Within the presentation, Kohsuke included a collection of numbers about the vibrancy of the Jenkins project that certainly hasn’t gotten enough attention. While the slideshow is embedded below, here’s some good high-level points:

Over 170 GitHub pull requests in the past four months, with more being sent every day.

Formalization of a &quot;Jenkins Stable&quot; branch of development with longer release cycles and back-ported bugfixes.

Over 280 tickets in JIRA have been resolved.

After posting a &quot;special&quot; release of Hudson which presents users with a choice, 87.25% are choosing to upgrade to Jenkins.

Over 500 tickets have been created

Roughly 13,000 downloads of jenkins.war and native packages a week

New and vibrant community-driven initiatives like Frederic Camblor’s plugin compatibility tester and Charles Lowell’s JRuby plugin support project.

We’ve crossed 1500 participants on the jenkinsci-user mailing list, and are over 900 participants on the jenkinsci-dev list.

The @jenkinsci twitter account recently crossed the 4,000 follower threshold.

On a personal note, I think this speaks all to the level of unbridled enthusiasm about the future of Jenkins by contributors both new and old.

Without further delay, the slides: Current state of Jenkins<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/05/27/ruby-plugins-hack-session-5-27-2011/"><div class="header"><div class="date"><div class="month">May</div><div class="day">27</div></div><h5 class="title">Ruby Plugins Hack Session 5/27/2011</h5></div><p class="teaser">After a one week hiatus, we returned to the weekly hack session on a mission light up the sky with fire!

Attendees

Charles Lowell, Rasheed Abdul-Aziz, Hiroshi Nakamura

Discussion/Accomplished

How to manage the different ScriptingContainers inside the Jenkins

renamed the experimental repo where we’ve been doing all of our development from fog.hpi to the more aptly name [ https://github.com/cowboyd/jenkins-ruby-plugins-playground ]

started a separate gem for housing the support libraries for jenkins here [ https://github.com/cowboyd/jenkins-plugins.rb ]

started with more formal definition of the plugin API there.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cowboyd/">Charles Lowell</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jruby">jruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/06/08/building-a-software-diamond-with-jenkins/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 8</div></div><h5 class="title">Building a software diamond with Jenkins</h5></div><p class="teaser">[ Editor’s Note: This is a guest post from Jenkins community member Tom Rini ]

Alternatively: How to make your parallel jobs kick one last job at the end

Many of us have had occasion to think: &quot; I could make this project build quicker if I could just run parts in parallel and then one final job to wrap it up.&quot;

Well, good news! Jenkins is here to help!  With the Join Plugin you can do just that.  Over on the confluence page it’s got a number of examples and fancy flow charts.  But the take-away is that if you can describe the flow, you can make it happen.  But you’re saying &quot;wait, I need to pass information around between the jobs.&quot;

We’ve got that one covered for you too with the Parameterized Trigger Plugin.  And here’s the best part, these two can work together!  With both plugins installed you can follow the steps listed in the Build Parameters section of the Join Plugin. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/join_trigger.png

And as they say, now you’re cooking with gas!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/06/09/a-big-thanks-to-rackspace/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 9</div></div><h5 class="title">A big thanks to Rackspace</h5></div><p class="teaser">This post is long over-due and I really apologize for that.

Some months ago we put out the call for &quot;more agent machines!&quot; through the
mailing lists, sky-writers and twitter. We had a serious problem, for a
continuous integration project, a large number of our plugins and
dependencies weren’t being built in a continuous and automated fashion!

We had some builds on a couple of flakey machines on home connections
contributed by various individuals, until Rackspace stepped up in a big
way and donated an infrastructure server for the project to use. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/rackspace.jpg

For months now, just about all plugins and core have been built and tested on spinach,
the always-on machine in the Rackspace Cloud. Dutifully chugging away building
core, plugin after plugin and occasionally getting flooded with work from Frederic
Camblor’s plugin compatibility tester!

In hindsight, having a powerful infrastructure machine for nothing other than
builds has helped us build great software faster; I can’t imagine how difficult
things might be otherwise.

I’ve personally had a lot of interaction with Rackspace engineers through the OpenStack
project and have a number of friends who operate businesses on
Rackspace/Rackspace Cloud hybrid infrastructures.

The folks at Rackspace are
top notch and I can’t thank them enough for contributing to the Jenkins
project.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/06/14/upcoming-events-in-june-and-early-july/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">14</div></div><h5 class="title">Upcoming Events in June and early July</h5></div><p class="teaser">I’ve just added three events coming up in the next few weeks to the Jenkins calendar. Conveniently, they are all events I’ll be attending while traveling around Western Europe!

The Cologne JUG is having a meetup on Saturday, June 25th, starting at 2pm. We’ll be talking about Jenkins, maybe doing some coding, and then heading out for drinks and more talk! You can find more information and sign up at Xing.

A few days later, TNG Technology Consulting is generously hosting a meetup in Munich, on Wednesday, June 30th, starting at 3pm. I’ll be giving a quick talk on the state of the Jenkins project, followed by Ullrich Haffner (the author of the static analysis plugins for Jenkins) giving a quick talk on how those plugins are used. After that, we’ll be having a hackathon, and then more beer! Again, you can find more information and sign up at Xing.

A week later, the London CI meetup group is hosting a meetup as well, on Wednesday, July 6th, starting at 6:30pm. We’ll be meeting up at the Royal Festival Hall for discussion and drinking. You can find more information and sign up at Meetup.

Do you have a Jenkins event you’d like to have added to our calendar? Let us know!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/06/16/jenkins-long-term-support-release/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">16</div></div><h5 class="title">Jenkins Long-Term Support Release</h5></div><p class="teaser">We have released 1.409.1, our first long-term support (LTS) release, from the Jenkins project.

The idea of the LTS release is to provide a second release line the favors more stability and bug fix only maintenance. This release line branches off from a bit old Jenkins release (in this case 1.409), and we will only put important backported bug fixes. We’ll keep releasing 1.409.2, 1.409.3, and so on, as such bugs appear, and in several months (our current thinking is 3 months) we’ll designate another release and repeat this process all over again. I think it provides more comfortable upgrade path for larger deployments. For more about this, see Wiki.

In large companies that use Jenkins in a large scale, there often is a team of people who looks at incoming Jenkins release, tests it with their environments and their plugins, and then let their internal group consume them. With this release line, I’m calling for them to join the effort on this branch. Vojtech Juranek from Red Hat is already helping us tremendously, so is Yahoo in choosing the base release line and backporting. But it’d be great to get more people on board, as I think it’ll benefit everyone to have a larger number of eyeballs on the same code. You’ll also have a say on what bugs need to be backcported, etc. If you are interested in this effort, please let us know.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/06/24/ruby-plugins-hack-session-notes-6-23-2011/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">24</div></div><h5 class="title">Ruby Plugins Hack Session Notes 6/23/2011</h5></div><p class="teaser">You know that the night is going to be productive whenever @kohsukekawa shows up, and last night was no exception. We talked about problems on the horizon, potential solutions, and then I spent the last half hour ripping a bit of code.

The truth of the matter is that most of the changes that have to be done to Jenkins core have already been made, so now the bulk of the heavy lifting falls to the Ruby side of things (right now, me).

Anyhow, on to the notes!

Attendees

@kohsukekawa, @cowboyd

extract more stuff into the jenkins-plugins.rb support library (@cowboyd)

We’re in the process of extracting, normalizing, documenting all the goop that’s currently residing in the ruby plugins playground into a formal plugin support gem called jenkins-plugins https://github.com/cowboyd/jenkins-plugins.rb

recruit Rubyists to implement non-Jenkins specific code (@kohsukekawa)

If you know Ruby and would like to be able to write Jenkins plugins with it, but don’t know the first thing about Jenkins and/or JRuby, that’s OK. You can help by implementing some of the cucumber features found in that repo

@kohsukekawa is going to be knocking on your door to ask if you’re ready to step up, so I hope you’ve been nice this year!

testing strategy (@cowboyd, @kohsukekawa)

Ruby folk love their tests, and a plugin develompent solution won’t be complete unless testing is a breeze. That means that as we extract the plugin support library, we take make sure you can test plugin classes in isolation.

On the Jenkins side, KK will think about how to run tests that require a full Jenkins environment. A system like this exists currently for testing java plugins, but some thought might be required on how to do this for Ruby.

packaging reloaded (@kohsukekawa)

KK is going to jump in and write some rake tasks to take a ruby plugin structure and package it into a valid .hpi file, and with no maven involved.  According to him, Ruby plugins aren’t the only system that wants to run maven-free. There is desire to be able to do plugin development with Gradle (another Java build system), so this could be a double win.

different schedule (@kohsukekawa)

8:30pm Central in North America, doesn’t seem to be a very good time. Especially for hackers in Asia Pacific. KK will investigate a new time that works for everybody and encourages more participation.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cowboyd/">Charles Lowell</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jruby">jruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/07/18/mirror-mirror-on-the-wall/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">18</div></div><h5 class="title">Mirror, mirror on the wall</h5></div><p class="teaser">Let me preface this entire post with this: I love
Contegix .

While working on some infrastructure tasks I had long-since put-off for the
Jenkins project, I noticed something this weekend that scared the hell out of
me.

At some undetermined time, our MirrorBrain
installation stopped redirecting to our mirror network. Absolutely zero
downloads were being redirected, meaning that cucumber, the 1U machine
graciously colocated by Contegix had served up
far more bits than I ever wanted it to.

As such, I would like to publicly apologize to Contegix on behalf of the
Jenkins project. Their support for the project has been tremendous but
this glitch caused such an incredible amount of traffic to be pushed through
their network that I feel exceptionally bad about it (turns out, Jenkins is pretty popular!)

Now, for the good news. In diagnosing and debugging this issue (in a
caffeine-fueled frenzy I might add) I managed to do a couple things:

I corrected the redirection relatively easily

I fixed our long-standing geo-location issue, finally enabling redirection to our european
and asian mirrors!

Within 30 minutes of correcting the error, I was able to add two mirrors in
Germany, re-enable one from Taiwan and add a new mirror in Japan!

I’m hoping to add even more mirrors in even more regions as volunteers with
bandwidth step-forward, if you’re interested in hosting a mirror you can drop
me a line at tyler@linux.com.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/08/08/jenkins-user-conference/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 8</div></div><h5 class="title">Jenkins User Conference</h5></div><p class="teaser">We’ve done meetups, we’ve done sessions, we’ve done workshops, now it’s about time we went ahead and did user conference don’t you think?

Our pals over at CloudBees (Harpeet specifically) have taken the initiative in starting to organize just that: a Jenkins User Conference on October 2nd.

If you have your calendar at the ready, you’ll notice that October 2nd is the Sunday before JavaOne kicks off this year in San Francisco.

The details are still coming together, but a proposed agenda has already been posted by Harpeet.

As this is a community event, I’ll be sure to keep the updates coming on this site but you may want to add the CloudBees&#x27; Blog to your feed reader just in case (or just follow them on Twitter: @CloudBees).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/08/08/jruby-branch-merged/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 8</div></div><h5 class="title">JRuby Branch merged!</h5></div><p class="teaser">Yesterday, Kohsuke announced that the &#x27;jruby&#x27; branch of jenkins-core had been merged to master.

This doesn’t mean that we’re done and that you can go forth and write pure ruby plugins…​ not by any stretch of the imagination. Instead, what it does mean, is that the Jenkins mainline is much more friendly to runtime analysis of classes with which it is not familiar.

The problem

When analyzing plugin classes, Jenkins uses just about every kind of metadata you can think of to get information about them: Class name, Field names, method names, member modifiers, annotations, you name it. It even uses the containing class relationship for inner classes to match Descriptors with what they describe.

It’s all a great example of convention over configuration (CoC). In fact, I’ve never really seen CoC implemented in a Java project before as successfully as it has been in Jenkins. Plugin authors don’t have to duplicate any metadata that Jenkins can figure out for you — and it’s alot! The drawback though, is that extensions depend very heavily on conforming to the structure of a conventional Java class.

The changes in this merge, and in several of the modules on which Jenkins depends, allow more than ever to get this information by asking an object directly rather than querying its private class structure.

The Kicker

Many of theses changes aren’t even JRuby specific! While they do enable JRuby integration, They’re really just making things more friendly for dynamic languages in general. So, in theory, it should pave the way for others like JavaScript and Python.

Where now?

We’re still working on the ruby runtime and tools which will provide as crisp a Ruby development experience as we can. I don’t want to proffer an estimate of when those will begin to be useable, but it is important to mark this very important milestone and explain what it does and does not mean.

We need you!

There is still much work to be done to enable a writing Jenkins plugins in Ruby, we are looking for people who know Ruby and feel like pitching in: writing Rake tasks, improving the glue layer, documentation, etc.

If you’re interested, most of the action is happening on the jenkinsrb@googlegroups.com mailing list, so join us!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cowboyd/">Charles Lowell</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jruby">jruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/08/09/jenkins-user-conference-call-for-papers/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 9</div></div><h5 class="title">Jenkins User Conference: Call for Papers</h5></div><p class="teaser">As we announced yesterday, we are organizing a Jenkins User Conference, and we are delighted to announce its Call for Papers is now open. We are looking forward to receiving amazing proposals from infrastructure experts to novice developers in the Jenkins community. Use your creativity. Share and showcase your unique approach to utilizing Jenkins technology.

We do not encourage overt marketing pitches. We encourage breakout sessions, work shops, good case studies with transferable, tangible lessons and other topics like:

plug-in development

Specific Jenkins applications that solve testing/building problems in particular areas: mobility, enterprise/web/cloud applications, and UI testing

Beyond Java (i.e Jenkins w/ PHP, Ruby, etc)

Jenkins best practices, lessons learned, case studies, tips and tricks

Lightning Talks (10 min)

+
+

+
*IMPORTANT:* Submit your proposal as soon as possible to mailto:juc-cfp@cloudbees.com[CFP alias]. Call for Papers closes Sept 1, 2011. +
 +

+
Sessions are 50 min long. In your proposal pls include the following info: +
 +

Name

Job Title

Email

twiter id

Company/website

Paper Title

Audience Level (General, Beginner, Intermediate, Advance)

Paper Abstract

Your bio

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/09/01/call-for-testers-upcoming-lts-update/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 1</div></div><h5 class="title">Call for Testers: Upcoming LTS update</h5></div><p class="teaser">A couple of months
ago Jenkins embarked on an new project, the
Jenkins &quot;LTS&quot; (Long Term Support) release line. A LTS branch of development is
common in most major open source projects, especially those with substantial
corporate adoption, so this was a great step for the project as a whole.

We’re now coming up on the second LTS release, which will be an incremental
update to the previous one (1.409.1) with only the most important fixes
back-ported to the branch.

Now is when we need your help.

We need testers and interested parties from the community to help verify the
stability of the planned LTS update, 1.409.2, which is now in the release
candidate stages.

The testing of 1.409.2 has been spearheaded by community member vjuranek who
has created this fantastic test
matrix to
help coordinate testing of release candidates.

The LTS project is entirely community driven, so your input is invaluable in making
these releases successful.

If you’re interested in helping, speak up on the -dev mailing
list and start pitching in on the test matrix!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/09/14/jenkins-long-term-release-1-409-2-is-out/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">14</div></div><h5 class="title">Jenkins Long-Term Release 1.409.2 is out</h5></div><p class="teaser">We just posted the updated Long-term Release (LTS) of 1.409.2.

+
Just as a recap, with LTS releases, we plan on providing a release train that only has backported changes. 1.409.2 contains https://jenkins-ci.org/changelog-stable[a handful of important bug fixes] since 1.409.1. For more about LTS, https://wiki.jenkins.io/display/JENKINS/LTS+Release+Line[see this wiki page]. +
 +

+
Thanks to the heroic effort of those who are involved, namely Vojtech Juranek and a bunch of heroes, this release went through a rather rigorous testing, including all the automated tests we have plus https://wiki.jenkins.io/display/JENKINS/LTS+1.409.x+RC+Testing[a considerable number of manual eye-ball tests]. +
 +

+
To download, click the &quot;Long-Term Support Release&quot; tab from https://jenkins-ci.org/[the top page]. If you&#x27;ve already been using LTS, you should start receiving update notifications soon.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/09/19/2011-donation-drive/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">19</div></div><h5 class="title">2011 Donation Drive</h5></div><p class="teaser">Since the end of April, Jenkins has been officially part of the
SPI (Software
in the Public Interest), an umbrella organization which offers a useful level
of legal status for the project.

Up until recently we had not taken proper advantage of this new legal
umbrella, thankfully that’s changed as we’re now capable of accepting
donations!

For the project this is a big step forward as it will allow us to offset the
cost of servers for the project, bandwidth, SSL certificates and other costs
incurred as part of running such a large open source project.

Trivia: The machine that this page is being served from originally started
out as &quot;hudson labs&quot;, purchased and colocated by
abayer,
kohsuke and
myself.

Since we’re now able to accept donations, we’re kicking off a donation drive to
help recover some of the costs incurred this summer ( which I’ve discussed
previously). Our immediate goal is to raise $5130
to recoup bandwidth costs, if you can spare some change, head on over to the
SPI online donation
page and help
us out :)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/09/20/ips-packages-of-jenkins-for-solaris-openindiana/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">20</div></div><h5 class="title">IPS Packages of Jenkins for Solaris/OpenIndiana</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/en/thumb/3/3b/Solaris_OS_logo.svg/220px-Solaris_OS_logo.svg.png[image] +

+

+
Image Packaging System (IPS) is a new package manager Sun has developed for OpenSolaris. While I have my doubts about whether a brand-new package manager was a good way of spending engineering resources, OpenSolaris had a number of very nice features that made it a convincing platform to run Jenkins, thanks to SMF, ZFS, and zones. So I used to produce IPS packages for Jenkins. I lost the ability to do this as I left Oracle and lost access to a Solaris system, but https://www.dev-eth0.de/jenkins-continuous-integration-on-opensolaris/[a recent blog post] renewed my interest. +
 +

+
So I&#x27;m happy to announce that the Jenkins project has started producing https://ips.jenkins-ci.org/[IPS packages for the releases]. With this addition, the Jenkins project now produces 9 packages on different platforms (10, if you count https://rubygems.org/gems/jenkins-war[Ruby as a separate platform] :-) +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/10/05/ci-dinner-wednesday-at-630/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 5</div></div><h5 class="title">CI Dinner Wednesday at 6:30</h5></div><p class="teaser">Apologies for the late notice, I think most of us have been pre-occupied with that fantastic Jenkins User Conference. While there are plenty of folks in town for JavaOne, I wanted to host a meetup/dinner at Cafe Chaat here in San Francisco.

If you’re coming from JavaOne directly, use these directions

If you’re coming from Oracle OpenWorld, use these directions

Kohsuke will be in attendance as will some other Jenkins User Conference speakers, so if you still have left-over questions, I’m sure you can get them answered before the last of the Mango Lassi is finished!

Look forward to seeing you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/10/17/andrew-bayer-discusses-jenkins-with-tim-obrien/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">17</div></div><h5 class="title">Andrew Bayer discusses Jenkins with Tim O&#x27;Brien</h5></div><p class="teaser">Recently, Jenkins Interim Governance Board member and core contributor, Andrew Bayer sat down with Tim O’Brien to discuss the Jenkins project.

You can watch the video on YouTube or via the embed below.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/10/21/report-bugs-and-win-kindle/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">21</div></div><h5 class="title">Report bugs and win Kindle</h5></div><p class="teaser">CloudBees is running a 60-days&quot;bring me bugs&quot; contest for the Jenkins project where you may win a Kindle and Amazon gift cards for a bug report you made during the contest period. See the linked site for details about how to enter into the drawing. Greg Moy from Electronic Arts has already won for the first week, but there are more rounds to come.

Several years ago Sun did the same thing around GlassFish, and it was useful to drive more participations into the project. Whether or not you were around the last time, don’t forget to participate this time.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/11/03/jenkins-community-survey/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 3</div></div><h5 class="title">Jenkins Community Survey</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Census[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Volkstelling_1925_Census.jpg/300px-Volkstelling_1925_Census.jpg[image,height=140] +
] +

+
+

+
There&#x27;s currently https://bit.ly/rYnFy2[a survey running] to get a better sense of our use base. Those inputs help us steer the effort wisely, so we appreciate your taking time to fill it in. The result would be more useful if larger number of people participate, so feel free to encourage others to fill it in as well. +
 +

+
In the same spirit of the fundraising drive in NPR, CloudBees is throwing in a &quot;thank you gift&quot; of AppleTV as an added incentive. See https://blog.cloudbees.com/2011/11/take-jenkins-survey.html[their blog post] for more details.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/11/04/a-dead-bug-is-a-good-bug/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 4</div></div><h5 class="title">A dead bug is a good bug</h5></div><p class="teaser">+
image:https://www.cloudbees.com/sites/default/files/imagefield_thumbs/Buggy_Code.png[image,width=129,height=96] +

+

+
As if https://jenkins-ci.org/content/report-bugs-and-win-kindle[getting a Kindle for reporting bugs] and https://jenkins-ci.org/content/jenkins-community-survey[getting an AppleTV for filing a survey] aren&#x27;t enough, you can also https://www.cloudbees.com/jenkins-community-contests.cb#bugbounty[win an iPad for fixing an issue]. +
 +

+
So if you&#x27;ve been thinking about tinkering with https://wiki.jenkins.io/display/JENKINS/GitHub+Repositories[Jenkins code base] but haven&#x27;t done so yet, this is a great opportunity to get going. There&#x27;s https://wiki.jenkins.io/display/JENKINS/Extend+Jenkins[documentation about how to get started], and there&#x27;s https://wiki.jenkins.io/display/JENKINS/Office+Hours[Jenkins Office Hours] and https://jenkins-ci.org/content/chat[IRC channel] if you need some interactive help from existing devs. I think new features, not just bug fixes, would qualify, so long as it&#x27;s recorded in the issue tracker. And similarly, I think the plugins would qualify, not just core. +
 +
 +

+
Aside from iPad, there&#x27;s one $50 Amazon gift certificate going out every week, which is almost a steal! So be sure to submit your entry! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/11/07/jenkins-meetup-munich-videos/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 7</div></div><h5 class="title">Jenkins Meetup Munich Videos</h5></div><p class="teaser">Better late than never right? Back in June, during his world tour, Andrew Bayer stopped by Munich to participate in a Jenkins Meetup along with Dr. Ullrich Hafner.

Andrew gave a talk titled &quot;The State of Jenkins&quot; ( slides) and Ullrich talked about &quot;Static Code Analysis with Jenkins&quot; ( slides)

You can view the videos on this page hosted by TNG.

Thanks to Stefan Wolf for the heads up!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/11/10/jenkins-conference-slides-and-videos-online/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">10</div></div><h5 class="title">Jenkins Conference Slides and Videos Online</h5></div><p class="teaser">It is just turning into a video heavy week isn’t it? First the videos from the Munich Meetup were made available, and now the videos from the first ever Jenkins User Conference.

The full list of slides and videos can be found on this page , hosted by CloudBees who  did a phenomenal job helping to organize and host the conference.

I want to thank everybody else involved once again, the fantastic speakers, the enthusiastic attendees and of course the sponsors for making it possible (CloudBees, Red Hat, LifeRay, New Relic, Sauce Labs, Chariot Solutions and eXo).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/11/15/the-beginning-of-a-new-era-ruby-plugins-now-a-reality/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">15</div></div><h5 class="title">The beginning of a new era: Ruby plugins now a reality</h5></div><p class="teaser">It’s not often that I get to use that much hyperbole in a Jenkins blog post, but I think in this case it’s allowable. A journey that started over a year ago by Charles Lowell has reached a new level, thanks to lots of help from Kohsuke along with Hiroshi Nakamura and Jørgen Tjernø.

As of today, with Jenkins 1.438, you can now download and install Ruby plugins from the update center (the Path Ignore plugin being the first).

Words simply can’t express what a monumental achievement this is for the Jenkins project, both from the technical perspective but also in terms of what this means for the future of the project.

According to the languages dashboard on GitHub, Ruby is over two times as popular as Java on the site. I do not intend to start a language popularity contest here, but if we pretend just for a minute that the GitHub ecosystem is all that exists. Can you then imagine how powerful it would be to engage and include a community of open source developers that would be two times the size of the current pool of contributors? That’s tremendous potential!

Great! Where do I start?

For those that are curious, the first officially released Ruby plugin for Jenkins is Jørgen’s pathignore-plugin which can be found in the update center. If you’re looking for a reference project, this is currently the most up-to-date plugin.

There is also a wiki page covering Ruby plugin development , which might be a little out-of-date but covers most of the essentials.

Additionally you might find the jenkins-prototype-plugin an interesting resource as it is practically a kitchen sink of demo/test Ruby plugin code.

Currently only a few extension points (BuildStep, Publisher, BuildWrapper) are mapped in a Ruby-friendly manner. Don’t let that scare you though! If you dig around in the jenkins-plugin-runtime you can see how the existing extension points are mapped from Java into Ruby, because Ruby plugins are running under JRuby, if you need to access some Java APIs, you can do so without too much trouble.

The Thank Yous

Great efforts like this one don’t just happen without support, which is why I’d like to call out and thank The FrontSide for their wonderful support, helping to cover costs of WebEx for Office Hours and covering Charles&#x27; time while he worked with Kohsuke on the internal plumbing needed to make Ruby plugins possible within Jenkins core. If the name &quot;The FrontSide&quot; looks familiar to you, that might be because they also created and donated the Jenkins logo!

We should also thank Lookout, Inc ( full disclosure: Lookout is my employer) and CloudBees for affording some employee time for Jørgen and Kohsuke respectively to work on the project.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jruby">jruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/12/02/community-contributed-localizations-to-be-bundled-in-jenkins-1-443/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 2</div></div><h5 class="title">Community-contributed localizations to be bundled in Jenkins 1.443</h5></div><p class="teaser">+
In 1.430, we added https://wiki.jenkins.io/display/JENKINS/Translation+Assistance+Plugin[the translation assistance plugin] in the hope of increasing the contribution from the community. It&#x27;s been 3 months, and I&#x27;ve finally took the opportunity to integrate them into Jenkins. +
 +

+
The result is pretty amazing. Before this, we had 26 languages, with wildly varying degree of completeness, such as French, Japanese, German, etc. This is still pretty good, but this integration added updates to 40 languages, including 17 brand-new languages, pushing the total up to whopping 43 languages. Among the newly added languages are Arabic (sorry, no right-to-left support yet), Esperanto, Hebrew, as well as large amount of Chinese (both simplified and traditional) and Korean. +
 +

+
While working with this, I&#x27;ve also discovered an issue that prevented Jenkins from correctly showing Hebrew, Indonesian, and Yedish localizations. All these changes will be in 1.443. And going forward, I&#x27;ll be integrating changes more frequently to reduce the delay. +
 +

+
So big thank you for everyone who contributed localizations, and please keep them coming! https://wiki.jenkins.io/display/JENKINS/Translation+Assistance+Plugin[Contributing localization is very easy]. If you are interested in more seriously working on localizations, please see https://wiki.jenkins.io/display/JENKINS/Internationalization#Internationalization-Whattranslatorsneedtoknow%2Fdo[this Wiki page] and request the committership in the project. This is yet another way people can contribute to OSS without writing code.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/12/05/holiday-appeal-please-help-jenkins-pay-the-project-expense/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 5</div></div><h5 class="title">Holiday appeal: please help Jenkins pay the project expense</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Mcol_money_bag.svg/100px-Mcol_money_bag.svg.png[image] +

+

+
As we approach the holiday season, which is when people start to feel more charitable, at least in the U.S. So I&#x27;d like to make one more plea, that the Jenkins project needs your help in link:/donate/[paying its expense], and that we are still about $1000 shy of the goal we need to get to. So if you can, please help us by https://co.clickandpledge.com/advanced/default.aspx?wid=46160[donating to Jenkins via SPI]. +
 +

+
Think about all the benefits you are getting from your Jenkins, and think about all the volunteer efforts that went into it. Some help by writing code, some help by answering other users questions, and some help by spreading words about Jenkins. If you&#x27;ve been wanting to contribute to the project but you haven&#x27;t figured out how, this is one way to do it. +
 +

+
As a thank you, I&#x27;m writing a special &quot;friend of Jenkins&quot; plugin that I&#x27;d like to send out to those who have donated, so that you can show off your support on your Jenkins instance. +
 +

+
Once again, please help us reach link:/donate/[our fundraising goal]. +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/12/19/fundraising-drive-update-thank-you-everyone/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">19</div></div><h5 class="title">Fundraising drive update: thank you everyone!</h5></div><p class="teaser">&quot;&gt;

Our earlier appeal for donation was a drastic boost to our fund-raising drive, (and looking at the twitter reactions, it feels like the Wikipedia parody we put on Jenkins on Jenkins helped spread the words — I guess jokes do work!

And I’m happy to report that we’ve successfully raised over $12000 as of today. That’s more than enough to pay off all the current balance and it should keep the project going for quite a while. I’ve assembled the donor list in appreciation.

So once again, thanks everyone for their generous support!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/12/20/thanks-for-the-support-pagerduty/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">20</div></div><h5 class="title">Thanks for the support PagerDuty!</h5></div><p class="teaser">Over drinks this evening Kohsuke pointed out that he never saw a blog post about PagerDuty. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/images/pagerduty_logo.png

If you’ve never worked in a sysadmin role or in any other position that would require an on-call rotation, then you may have never seen PagerDuty.

In essence the service provides a great series of integration points with Pingdom or Nagios for handling monitoring. As an infrastructure guy (part time), I can honestly say it’s a great tool and I’m grateful to PagerDuty for supporting Jenkins with our own account to help manage project infrastructure.

A couple weekends ago I finished setting up Nagios (read-only username/password: jenkins / jenkins) for critical project services which by itself is a good step forward. Combine that with PagerDuty’s Nagios integration and a solid on-call rotation, and I’m more confident than I’ve ever been that Kohsuke or myself could actually take a vacation!

Check them out, and be sure to thank them on Twitter at @PagerDuty for supporting Jenkins!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/12/23/jenkins-survey-result-and-what-ui-improvement-would-you-like/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">23</div></div><h5 class="title">Jenkins survey result and what UI improvement would you like?</h5></div><p class="teaser">&quot;&gt;

Jenkins community survey result is in, which shows a number of interesting stats for us developers, such as 82% of people saying their Jenkins is mission critical, or the spread of distributed builds, especially compared to my earlier similar usage analytics.

But just as interesting is the free-form answers to questions like &quot;If there was anything you could you change about Jenkins CI, what would it be?&quot;, and while the answer is colorful, there are a few common themes that one can easily spot.

One of them is &quot;nothing!&quot;, which made me feel good, but another is &quot;UI improvement.&quot; And incidentally, Domi has started a thread in the Jenkins-users list about this exact topic a week ago.

The idea is to brainstorm what kind of concrete improvements people would like to see, then run them through some real user experience designers and decide which ones are good ideas and which ones are not.

I find this thread useful — so much so that one of those ideas (always show the &quot;Save&quot; button at the bottom in the config page) is already implemented toward the next release of Jenkins. So if you have some thoughts to share, please chime in on that thread.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2011/12/28/adding-diagrams-to-wiki/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">28</div></div><h5 class="title">Adding diagrams to Wiki</h5></div><p class="teaser">Thanks to the kindness from Gliffy, we can now add diagrams to Wiki pages, in a way that enables collaborative edits.

See more info, including a sample diagram in a Wiki page.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/01/09/2012-jenkins-survey-results-are-in/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 9</div></div><h5 class="title">2012 Jenkins Survey results are in</h5></div><p class="teaser">+
image:https://rhetoricalcommons.org/OSAAC/sites/default/files/images/survey.jpg[image] +

+

+
The https://jenkins-ci.org/node/403[Jenkins survey] we’ve been running since https://jenkins-ci.org/content/come-join-jenkins-user-conference-san-francisco-september-30th[the Jenkins User Conference in San Francisco] has concluded. All in all we counted 721 responses --- thanks everyone for voicing their thoughts! +
 +

+
Naturally, it took a while to tally that many responses, but thanks to https://twitter.com/ProductPrincipl[Lisa], we https://www.cloudbees.com/jenkins/jenkins-ci/2012-survey.cb[now have the result] in time for the holiday. +
 +

+
As you can see in https://stats.jenkins-ci.org/jenkins-stats/svg/total-jenkins.svg[our installation tracking], Jenkins installation base has grown 66% since the last year, so I was naturally very curious if this has affected the area of focus for us the developers. +
 +

+
However, when https://pages.cloudbees.com/Jenkins_Survey_2011_JenkinsSurveyDownloadPage.html[compared to the result from the last year], the first thing I notice is the consistency in many metrics. For example, about 83% of people considers Jenkins mission critical this year, and the last year it was 82%. The distribution between beginner/intermediate/expert users are also quite similar. +
 +

+
But this year, we asked a number of questions that we didn’t ask the last year. One of them is the version control systems that people use. Here, we get 61% Subversion, 50% Git, and everything else is within 10%. So clearly we need to start shipping Git plugin pre-bundled! +
 +

+
Another interesting question that we asked is the languages people use. There’s a surprising number of C/C++ projects on Jenkins (and good number of Ruby, PHP, Python, and C#!), which made me feel that we need to hear more from those users about the kind of tool integrations we need to be providing. +
 +

+
One more gem is that whopping 11% of the respondents said they have written and contributed plugins to the community (that’s 82 people!), and another 9% of the respondents said they wrote one but just not sharing it because it doesn’t make sense (7%), or they couldn’t (2%). That’s about 1 in every 5 respondents writing some plugins, which is amazing, if you ask me. +
 +

+
Another big part of the survey was asking respondents what are important in Jenkins --- is it documentation, quality, UI, etc? But I guess I shouldn’t spoil your fun of actually https://www.cloudbees.com/jenkins/jenkins-ci/2012-survey.cb[looking at the result], so please go take a look yourself! Also, if you want to tally the numbers yourself, here’s the anonymized raw data. +
 +

+
I’ll hopefully do a separate post on the efforts we are taking to answer those points raised in the survey in coming days. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/01/26/report-jenkins-meet-up-seoul/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">26</div></div><h5 class="title">Report: Jenkins meet-up Seoul</h5></div><p class="teaser">+
People in far eastern countries use languages that are quite different from English, and live in a time zone that&#x27;s largely incompatible from the U.S./Europe time. So naturally these folks tend to keep things to themselves. +
 +

+
That&#x27;s why I&#x27;ve been wanting to do a meet-up in Seoul for some time, yet I didn&#x27;t know anyone there to get one going. That changed in Jenkins User Conferene in San Francisco last year. I pitched this to someone who worked for Samsung, and he introduced me to folks in Seoul, and the ball started rolling from there. +
 +

+
The meet-up was held Friday, at Samsung headquarter in https://www.youtube.com/watch?v=9bZkp7q19f0&amp;list=PLEC422D53B7588DC7&amp;index=10[Gangnam], Seoul. +
 +

+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Samsung_headquarters.jpg/320px-Samsung_headquarters.jpg[image] +

+
+

+
I kicked off the meet-up with a short presentation on why I think local communities are important, especially in Korea. Jang Seung-heui from Samsung then talked about Groovy scripting in Jenkins, and how it helps him manage a large installation of Jenkins (the slides and the talk were in Korean, so this is my guess based on the occasional English words that appeared in slides.) Junho Yoon from NHN talked about his simple update site plugin to show how he helps teams run their own Jenkins instances. I&#x27;ve done another presentation showing various Jenkins plugins for workflow-ish things. +
 +

+
+

+
I wasn&#x27;t sure how many people would actually come, since I really didn&#x27;t have any reach in the Korean software developer community. But somehow the words must have spread, as I counted more than 50 people in the room. +
 +

+
+

+
Unfortunately, due to the rules in the building, I wasn&#x27;t allowed to record the talks. So no videos from this meet-up — if you missed this one, you&#x27;d have to come to the next one! +
 +

+
After the meet-up, a dozen of us headed to the busy night scene in Gangnam. There were so many people that we had to form a line to get to the street! +
 +

+
Eventually we found ourselves in a German-style pub. I say German &quot;style&quot; because everything from beer to foods were Korean, except the name of the pub and the wall paper. +
 +

+
+

+
I&#x27;ve pitched my hope that we keep it going, and that there&#x27;ll be the next meet-up. Judging from https://www.meetup.com/jenkinsmeetup/events/90236092/[the feedbacks on the meetup.com] and Twitter, I&#x27;m optimistic: +
 +

@https://twitter.com/kyunamjo[kyunamjo] @https://twitter.com/kohsukekawa[kohsukekawa] Kohsuke, please push him constantly to put his effort to settle a local community for Jenkins. He wishes to do that.

— 김상희 SangHee Kim (@sangheestyle) January 25, 2013

+

+
+

+
The book Junho is holding contains some chapters about Jenkins that he wrote: +
 +

+
+

+
After drink-up, Junho kidnapped me into a coffee shop and showed me a lot more that he has done for NHN that I presumably cannot talk about in public. I&#x27;ve encouraged him to try to split the generic parts from company specific parts and open-source the former, so we&#x27;ll see. By the time I headed back to hotel, it was past midnight. +
 +

+
I wanted to thank folks from Samsung for making this possible. If you are interested in stay connected, please join https://groups.google.com/forum/?fromgroups#!forum/jenkinsci-kr[the mailing list]. +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/01/30/jenkins-hits-1-500/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">30</div></div><h5 class="title">Jenkins hits 1.500</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Toasting_Champagne.jpg/171px-Toasting_Champagne.jpg[image] +

+
+

+
The last week the Jenkins project has reached a miletone release — https://jenkins-ci.org/changelog[Version 1.500]. That&#x27;s no 1.5 nor 1.5.0. That&#x27;s the 501st release since its inception, counting all the way up from 1.0, 1.1 to 1.500. +
 +

+
We&#x27;ll be celebrating this release in https://wiki.jenkins.io/display/JENKINS/FOSDEM[the upcoming FOSDEM conference] in Brussels, but I wanted to thank everyone for making this great community possible by participating and using it. +
 +

+
Despite https://jenkins-ci.org/changelog-old.html[all] https://jenkins-ci.org/why[the] https://wiki.jenkins.io/display/JENKINS/Governance+Meeting+Agenda[distances] we&#x27;ve thus far come, there are https://www.slideshare.net/kohsuke/jenkins-user-conference-2012-san-francisco[still a lot of work] to be done, both in the core and plugins, so we look forward to keep on keeping on in the coming years. +
 +

+
So here is to the next 500 release!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/02/15/jenkins-ci-the-origins-of-butlers-build-masters-and-bowties/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">15</div></div><h5 class="title">Jenkins CI: The Origins of Butlers, Build Masters and Bowties</h5></div><p class="teaser">+
https://zeroturnaround.com/rebellabs/devs/jenkins-ci-the-origins-of-butlers-build-masters-and-bowties/[image:https://zeroturnaround.com/wp-content/uploads/2013/02/JENKINS-CI-Cover.jpg[image]] +

+
+

+
The folks at https://zeroturnaround.com/rebellabs/[Rebel Labs] picked Jenkins as the last installation of their technical report series. It is a beautifully crafted 50 page PDF that covers the overview of the technology. You get to see a bit of details about how ZeroTurnaround uses Jenkins, and it contains a section where I get interviewed by them. +
 +

+
Also, while they failed to mention this in the document, you can https://wiki.jenkins.io/display/JENKINS/Developing+with+JRebel[use JRebel when developing Jenkins plugins] and it&#x27;ll reduce the # of times you need to restart the VM. To the extent that you use it to develop open-source Jenkins plugins, you can https://zeroturnaround.com/software/jrebel/buy/[apply for a free OSS license], too. +
 +

+
If that sounds interesting enough, you can https://zeroturnaround.com/rebellabs/devs/jenkins-ci-the-origins-of-butlers-build-masters-and-bowties/[get your copy now]. Be forewarned that a registration is required.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/03/12/coming-to-gdc-join-us-for-a-jenkins-drink-up-at-21st-amendment/"><div class="header"><div class="date"><div class="month">March</div><div class="day">12</div></div><h5 class="title">Coming to GDC? Join us for a Jenkins Drink-Up at 21st Amendment</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Twenty-first_Amendment_to_the_United_States_Constitution[image:http://www.nationalreview.com/sites/default/files/nfs/uploaded/u23105/2012/12/amendment%2021%202.jpeg[image]] +

+
 +
If you are coming to https://www.gdconf.com/[Game Developers Conference] in the week of 25th, or if you are local to San Francisco bay area, come join us to the small drink up in the evening of 26th at http://21st-amendment.com/[21st amendment]. +
 +

+
If you are coming, https://www.meetup.com/jenkinsmeetup/events/108919962/[please RSVP] so that we know how many to expect, and we can stay connected.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/04/19/neuroscientists-embrace-continuous-integration-served-by-jenkins/"><div class="header"><div class="date"><div class="month">April</div><div class="day">19</div></div><h5 class="title">Neuroscientists embrace continuous integration served by Jenkins</h5></div><p class="teaser">+
_ +
Guest post by Yury V. Zaytsev and Abigail Morrison. To download the PDF file of the journal article mentioned below, https://www.frontiersin.org/Neuroinformatics/10.3389/fninf.2012.00031/abstract[click here]!_ +
 +

+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Gray739.png/250px-Gray739.png[image] +

+
+

+
As recently exemplified by several reports on this blog, automation tools such as continuous integration servers, that help to defuse the exploding complexity of software under the ever-increasing pressure to deliver, are steadily gaining well-deserved mindshare in the industry. +
 +

+
However, it is not just developers of enterprise software who need solutions to the complexity problem. Scientists are arguably even worse off: most of them are not trained as software engineers, yet, in the last decades, creating custom software has become an integral part of virtually any research activity, be it data analysis, simulation or experiments. Frequently, there is a great emphasis on numerical accuracy and reproducibility of results, which requires extensive testing. As a coup de grâce, most publicly funded research projects are running on tight budgets, excluding the possibility of hiring professional contractors to outsource required software development work. +
 +

+
Enter Jenkins the Butler! +
 +

+
Back in 2011, Yury V. Zaytsev, a doctoral candidate now working at Jülich Research Center, Germany was supported by a Google Summer of Code stipend to design a continuous integration infrastructure for http://www.nest-initiative.org[NEST], a spiking neuronal network simulator for neuroscientific research released under the GPL license. An overwhelmingly positive experience with this new setup motivated him to write up https://www.frontiersin.org/Neuroinformatics/10.3389/fninf.2012.00031/abstract[a case study], which was recently published in &quot;Frontiers in Neuroinformatics&quot;, an open access scientific journal. +
 +

+
&quot;The new CI system boosts our productivity, because it helps us find and fix breakages very quickly, even when they only occur for obscure combinations of configuration options. Automated integration testing is a major breakthrough for NEST, as it ensures that developing new features does not come at the cost of reliability or accuracy&quot; - said Markus Diesmann, director of the Institute of Neuroscience and Medicine (INM-6) at the Jülich Research Center, Germany and NEST Initiative board member. +
 +

+
We hope that through a peer-reviewed publication in a prominent scientific journal we will be able to reach the scientific community more efficiently, as compared to the materials targeting professional software developers. However, we likewise believe that our case study might be of interest to the readers of this blog, especially those who are still only considering implementing continuous integration. +
 +

+
Lastly, we would like to thank all developers and users of Jenkins whose contributions throughout the years made it the versatile and robust continuous integration server it is today!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/04/25/munich-hackathon/"><div class="header"><div class="date"><div class="month">April</div><div class="day">25</div></div><h5 class="title">Munich Hackathon</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Munchen_collage.jpg/300px-Munchen_collage.jpg[image] +

+
+

+
It&#x27;s been a while we had a hackathon in Germany. Let&#x27;s get together, get some coding done, and get to know fellow Jenkins developers! The date is June 15th Saturday. +
 +

+
TNG Technology Consulting, where https://github.com/wolfs[Stefan Wolf] (dependency graph viewer plugin, etc) works, will be hosting us (thanks!) +
 +

+
We&#x27;ll try to arrange some themes or agenda, based on who&#x27;s coming and how many of us will be there. For example, +
 +

If there are many people who have never done a plugin development, we can do a plugin development tutorial.

If we see a concentration of devs in a specific area of Jenkins (say mobile), we can try some focused development in a specific area.

If you have things you need from the core to do what you want, this is the chance to get that implemented on the spot!

If you want to see a certain development happen in Jenkins but don’t know how, please make a pitch to us in the form of presentations (short or long) would be welcome

+
+

+
Finally, assuming there&#x27;s interest, we&#x27;ll head out somewhere for a dinner afterward. +
 +

+
If you are interested in coming, https://www.meetup.com/jenkinsmeetup/events/116074032/[please RSVP at meetup.com] so that we can prepare accordingly.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/04/30/registration-and-call-for-papers-open-for-juc-palo-alto/"><div class="header"><div class="date"><div class="month">April</div><div class="day">30</div></div><h5 class="title">Registration &amp; Call for Papers Open for JUC Palo Alto</h5></div><p class="teaser">This year, the West Coast Jenkins User Conference will be in Palo Alto rather than San Francisco. If you’re nearby — or even if you’re not — join Kohsuke and other fellow developers for a solid day of Jenkins.

The Date: Wednesday, October 23, 2013

The Venue: Palo Alto Jewish Community Center

Details

Register

The Call for Papers is open until June 9 (scroll to bottom of page for form). JUC will be much better with your involvement, so please submit your abstracts and share your Jenkins knowledge with the community.

image::https://www.cloudbees.com/sites/default/files/Kohsuke-Kawaguchi-Opening-San-Fran-Thumbnail.png [Kohsuke Kawaguchi – Keynote Address, JUC San Francisco,link=https://www.youtube.com/watch?v=HXEbFfAeymw?rel=0?autoplay=1&amp;rel=1&amp;modestbranding=1&amp;showsearch=0]

A very special thanks to our JUC Palo Alto sponsors, who will make sure you are fed, caffeinated, clothed (in this year’s collectible Jenkins tshirt), and generally well cared for at the conference: CloudBees, JFrog, XebiaLabs, appvance, ZeroTurnaround, LMIT Software, Black Diamond Software, New Relic, Liferay, AppDynamics, and SOASTA.

Two other differences this year — the conference is not timed to coincide with JavaOne, and it falls on a Wednesday rather than a Sunday. We thought we’d try these changes and are interested to know if they work better for everyone.

The agenda won’t be populated until after the Call for Papers closes and talks are selected. But you can check out previous JUC agendas, slides, and video:

2012 JUC San Francisco

Inaugural JUC San Francisco - 2011

If JUC Palo Alto is not convenient for you, there’s also a JUC coming up in Herzelia, Israel on June 6 and a Jenkins event planned for Copenhagen, Denmark on September 6.

Hope you can join us at JUC!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/05/06/giving-back-to-the-community-3-ways-to-keep-jenkins-growing/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 6</div></div><h5 class="title">Giving Back to the Community:  3 Ways to Keep Jenkins Growing</h5></div><p class="teaser">With more than 600 plugins, Jenkins has a vibrant community and we’re dependent on YOU to keep it that way. Here are 3 ways you can give back to the community to ensure that everyone benefits and Jenkins keeps growing…​

Giving it back to the community #1: vendor+community=win

+
Jenkins is becoming ubiquitous enough that tool vendors and service providers often find their users asking them to provide Jenkins plugins. The challenge for these companies is that they don’t necessarily possess the necessary Jenkins expertise to do one. +
 +

+
Here at the Jenkins project, what we are trying to do is to work with these people to deliver a plugin. It gets the job done a whole lot more quickly if the vendor brings in their expertise on their tool/services and we bring in our expertise on Jenkins plugin development. +
 +

+
For example, we recently worked with https://www.soasta.com/press-releases/soasta-and-cloudbees-partner-to-deliver-first-jenkins-plugin-for-continuous-integration-on-mobile-platforms/[SOASTA] to help them open-source the plugin they developed in house, then help them add a whole bunch of new functionalities. By open-sourcing a plugin in the Jenkins project, vendors win as the community helps fix bugs and improve plugins. The Jenkins project wins by building relationship with vendors. And finally the users win by having more integrations. +
 +

+
So the next time you ask your vendor to provide a Jenkins integration, please tell them to drop us a note, and we are happy to talk. +
 +

Giving it back to the community #2: scratch your itch and take credit

+

+
If you are working for a company and hacking some Jenkins plugins for your team, then you should definitely consider contributing those changes back. Let’s take https://developer.sonymobile.com/2012/11/22/sony-contributes-to-jenkins-software-tool/[Robert and Tomas] for example, who contributed a number of significant plugins from Sony Mobile. +
 +

+
The company wins, because it shows off their technical excellence. Plus the flexibility to let engineers work on these OSS projects helps them retain and attract high-caliber developers. It also lets the community shoulder some of the burdens of maintaining plugins.

+
You win, because now you have more things to show to future employers. After all, GitHub is your new resume! And when you aren’t sure how to go about implementing a feature or fixing a bug, open-sourcing your plugin lets us jump in and get you unstuck.

+
The community wins, thanks to your new awesome plugin.

+
Besides all of those pragmatic reasons, when you share something with others and they tell you how much it helped them, even if it’s just one or two people, it’s a deeply moving experience.

+
+

+
It just has so many advantages, it’s a no brainer! +
 +

Giving it back to the community #3: contribute by proxy

+

+
If you are working for a company, wanting to see particular features/integrations in Jenkins but don’t have time to do it yourself, there’s yet another way, and that’s to contribute by proxy. +
 +

+
The idea is that you contract with those who already know how to develop Jenkins plugins, and you have them produce/improve Jenkins plugins in open-source. https://wiki.jenkins.io/display/JENKINS/Praqma[Praqma] is a great example of one such company. They are well connected in the community, with lots of experience under their belts, and your company takes the credit for the work. There are also a number of individuals who can do this for you. +
 +

+
Why give it away something for free when you paid for it, you might ask. That’s because the code sitting in house rots when it’s not maintained by anybody. In contrast, when the rest of the world can hack on your code, you get occasional random bug fixes by strangers (the worst case), and sometimes it gets its own life (the best case.) +
 +

+
If this way of giving back suits you better, feel free to send an e-mail to https://jenkins.361315.n4.nabble.com/Jenkins-dev-f387835.html[the dev list].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/05/17/continuous-information-jenkins-newsletter-vol-4/"><div class="header"><div class="date"><div class="month">May</div><div class="day">17</div></div><h5 class="title">Continuous Information - Jenkins Newsletter vol. 4 </h5></div><p class="teaser">Volume 4 of Continuous Information came out last night. It contains insights and highlights from founder Kohsuke, the latest growth stats, upcoming event info, Jenkins resources, and more.

Highlights:

Jenkins has nearly 20,000 more active installations than it had last June, up from 43,500 to more than 61,000

Nearly 100 plugins have been added since late last Fall when we did the last Jenkins survey. Now there are more than 730 plugins

Bay Area JUC (Oct 23), JUC Israel (Jun 6) and several other Jenkins events around the world have open registration

Latest, greatest Jenkins improvements include a new LTS based on 1.509, more context menu improvements, and controller/agent data transfer performance improvement

There’s also a Security advisory out recommending upgrade to at least 1.502

A plethora of Jenkins and Continuous Delivery resources

+
 +
https://pages.cloudbees.com/index.php/email/emailWebview?mkt_tok=3RkMMJWWfF9wsRow5%2FmYJoDpwmWGd5mht7VzDtPj1OY6hBomJr6JK1TtuMFUGpsqOOqSDhcUEZVk0w%3D%3D[View the full newsletter], and then https://www.cloudbees.com/jenkins/jenkins-ci/jenkins-newsletter.cb[sign up to receive it yourself].

+
 +
And if you have content to feature in a future newsletter, please mailto:continuous-information@cloudbees.com[email us]. +
 +
 +
 +
 +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/05/22/jenkins-user-conference-israel-coming-june-6/"><div class="header"><div class="date"><div class="month">May</div><div class="day">22</div></div><h5 class="title">Jenkins User Conference Israel - Coming June 6</h5></div><p class="teaser">Your favorite Butler will visit Israel on June 6 for the Jenkins User Conference Israel. More than 200 people have already registered to hobnob with other Jenkins users and eat like kings.

The agenda is up here. You’ll find a great list of speakers from Israel, Europe and the US to compliment a plethora of treats. There will be an ice cream break, fruits break, beer break and special chef lunch. And everyone gets a limited-edition JUC Israel t-shirt, designed by the t-shirt-design gurus at JFrog.

Featured speakers:

Kohsuke Kawaguchi, the creator of Jenkins (formerly, Hudson) and elite architect at CloudBees, will deliver a keynote about the current state and the future roadmap of Jenkins.

Hans Dockter, the creator of Gradle and the founder of Gradleware will speak about next generation build tool to CI server integration.

Fred Simon, JFrog’s co-founder and Chef architect will share JFrog’s vision of the future of continous integration in the cloud.

**

Many thanks to lead sponsors JFrog and CloudBees, who have put a lot of time and energy into organizing the conference. Thanks also to sponsors Cloudify and White Source for showing their support for Jenkins!

Register here.

Can’t make it to Israel? Here are more Jenkins events:

Moving to Continuous Delivery in the Enterprise — June 10, London

Jenkins Meetup — June 15, Munich

Jenkins User Event — September 6, Copenhagen

Jenkins User Conference — October 23, Palo Alto, CA<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/06/21/reducing-the-of-threads-in-jenkins-ssh-slaves/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">21</div></div><h5 class="title">Reducing the # of threads in Jenkins: SSH agents</h5></div><p class="teaser">+
As the usage of Jenkins expands, we started seeing users who run multiple 100s of agents on one controller, and thus it became a lot more important for us to scale well to even larger number of agents. +
 +

+
While I was looking at the thread dump of a large system, I started noticing that there are a large number of threads lying around pumping `+InputStream+` and writing to another `+OutputStream+`. On Linux, each thread occupies 2MB just for its stack size, so if we can eliminate some of them, it&#x27;d be a good saving. +
 +

+
So this morning, I tackled one source of such waste. +
 +

+
Jenkins has https://wiki.jenkins.io/display/JENKINS/SSH+Slaves+plugin[the ability to launch agent on a remote server via SSH] for the longest time, and to simplify this, we&#x27;ve been using a https://github.com/jenkinsci/trilead-ssh2[pure-Java implementation of SSH client]. +
 +

+
To cut the long story short, I was able to eliminate two pump threads per every SSH connection. Furthermore, when it runs on the upcoming Jenkins 1.521, it&#x27;ll save one more thread per every SSH connection. So if you have 100 agents connected through SSH, this alone saves up 600MB of memory. That&#x27;s pretty good for a few hours work! +
 +

+
If you run a lot of agents, be sure to pick up version 0.27 of https://wiki.jenkins.io/display/JENKINS/SSH+Slaves+plugin[the SSH agents plugin] to take advantages of this! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/07/01/office-hours-this-week-git-plugin-refactoring/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 1</div></div><h5 class="title">Office hours this week: Git plugin refactoring</h5></div><p class="teaser">This Wednesday’s Jenkins office hours is all about the Git plugin refactoring that’s going on.

Git plugin is one of the most popular plugins out there, and it’s been around for quite some time. Combine that with the fact that there are so many different ways to use Git, it was inevitable that Git plugin became quite a capable but complex plugin over time. It has more than a dozen options and switches, and it was becoming harder to use and harder to maintain.

As early as 2010, some of us have already been saying that we should refactor this plugin, but none of us have managed. The good news is, I finally started tackling this problem last month while I was in London, and I’ve made a steadily progress since then and I’m ready for a wider review.

So we’ll spend this Wednesday going over the changes. I’ll show you how the new version looks, what changes are made internally, and what it’ll enable us in the future.

If the Git plugin is important to you, and you want to see what’s cooking, please join us in the office hours on Google Hangout.

Looking forward to seeing you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/07/11/jenkins-user-conference-israel-summary/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">11</div></div><h5 class="title">Jenkins User Conference Israel Summary</h5></div><p class="teaser">+
https://www.cloudbees.com/jenkins/juc2013/juc2013-israel.cb[Jenkins User Conference in Israel] was held this year on a different venue than the last year, because we have grown! I believe Shlomi Ben-Haim of JFrog said in his opening speech that the attendance has grown more than 50%, despite the ticket price increase. +
 +

+
This year, the event was held at a former Kibbutz turned into an event facility. This was rather fit for Jenkins for both emphasizes the community. The auditorium was big, the sky was bright &amp; clear, and it was a wonderful day. JFrog folks even made a few Jenkins drapes (that I eventually brought back with me, so expect to see them) +
 +

+ +

+
+

+
For me, talks like one from Haggai are more interesting, as it shows me how Jenkins works in a domain that I’m not familiar with (in this case, .NET). And if you are Jenkins users, there are all sorts of talks, ranging from talks on CLI/XML interface of Jenkins (stuff for those who are writing tools and scripts that interface with Jenkins) to how someone managed user interface automation testing with Jenkins. Another talk that I got hooked was a talk from https://www.cloudbees.com/jenkins/juc2013/juc2013-israel-abstracts.cb#YardenaMeymann[Yardena Meymann] about the review board Jenkins plugin that she wrote that lets you test out code change under the review, much the same way https://buildhive.cloudbees.com/[BuildHive] or https://wiki.jenkins.io/display/JENKINS/Github+pull+request+builder+plugin[GitHub pull request builder plugin] does it for GitHub pull requests, but for Subversion. I also liked the 45 minutes format better, which helps cut the fat and take people straight to the point. +
 +

+
Outside talks, Israeli people kept me busy! They cornered me on multiple occasions and we had a lot of interesting conversations, so much so that I missed about half the talks! I just wish we had coordinated this upfront so that I could have visited them while I was there. This also made me wonder what if we designate one corner of the site and did a series of birds-of-feather around specific topics. This led me to try https://www.meetup.com/jenkinsmeetup/events/126595572/[Jenkins Scalability Summit] in the upcoming JUC Palo Alto. +
 +

+
https://www.cloudbees.com/jenkins/juc2013/juc2013-israel.cb[All the slides and videos are available], if you want to take a look --- be forewarned that some of them are in Hebrew. +
 +

+
If you aren’t in Israel but like the concept of JUC, looking forward to seeing you in the upcoming https://www.eventbrite.com/event/6367028955[Jenkins User Conference in Palo Alto] this October.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/07/24/faster-slave-classloading/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">24</div></div><h5 class="title">Faster agent classloading</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Chloride[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Calcium_chloride_CaCl2.jpg/320px-Calcium_chloride_CaCl2.jpg[image]] +

+
+

+
Jenkins comes with https://github.com/jenkinsci/remoting[the remoting library] that it uses to communicate between a controller and agents. This is a pretty awesome library, I think, which served us well. +
 +

+
One of the things this remoting layer does it to transfer the Java byte code on demand from the controller to agents on demand. This approach helps us keep agent deployment simple, as you don&#x27;t have to keep the controller and all the agents in sync, but it also made the agent start-up slower, because none of the byte code loaded to agents are kept around. It was all forgotten once the agent gets disconnected. +
 +

+
When agents are static and stays online for hours, this wasn&#x27;t a problem at all. But as more and more agents become elastic (think EC2 or CloudBees DEV@cloud), This delay is becoming more and more noticeable. A similar issue happens when the Maven project type, which uses the same remoting library to talk to the running Maven build. +
 +

+
Another related performance bottleneck is the round-trip latency. When your agent is far away from a controller, every classloading would incur a network round-trip, and it can add up quickly. This is because Java classloading abstraction is funamentally chatty. +
 +

+
Jesse and I https://issues.jenkins.io/browse/JENKINS-15120[started seriously thinking about this problem] last year, and we&#x27;ve https://github.com/jenkinsci/remoting/pull/10[kept a branch going] to address this problem. +
 +

+
After several trans-atlantic hacking during flights, we were finally able to release this in 1.519. +
 +

+
Starting this version, the remoting layer uses a local jar file cache to store jar files that were downloaded from the controller. This pretty much eliminated the need to send class files over the wire. +
 +

+
In addition, the controller will analyze class files as a agent request them and &quot;push down&quot; information about how related other classes should be loaded by the agent. This speculative &quot;prefetching&quot; saves the agent from making an expensive network round trip to the controller. +
 +

+
In https://jenkins-ci.361315.n4.nabble.com/Efficient-class-jar-prefetching-in-remoting-td4665943.html[my benchmark using Maven builds, the prefetching cut the # of roundtrips to about half]. +
 +

+
If you do a lot of Maven builds, or if you have elastic agents, we highly encourage you to upgrade. +
 +
 +
 +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/07/24/jenkins-user-event-in-copenhagen-on-september-6/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">24</div></div><h5 class="title">Jenkins User Event in Copenhagen on September 6</h5></div><p class="teaser">Seize the opportunity to join the Jenkins community!

Just like last year, the Scandinavian Jenkins Conference will be in Copenhagen, Denmark, hosted by Praqma and sponsored by CloudBees, Sony, Switch::Gears, and PRQA. The open source community will gather on September 6th for a full day of networking and knowledge sharing at The Department of Computer Science at The University of Copenhagen.

Based on last year’s success, Jenkins developers, architects, business managers, etc. from all over the world will gather to exchange experiences and promote the open source platform. As a special feature the conference will include an opening keynote from Jenkins founder Kohsuke Kawaguchi as well as other industry pioneers, who will take the podium to present findings within the latest technology, best practice, hand-on experiences, etc.

To get updates on the conference follow the JCI13Blog where you can view the latest news on venue and speakers.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/07/31/jenkins-user-conference-palo-alto-2013/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">31</div></div><h5 class="title">Jenkins User Conference Palo Alto 2013</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Palo_Alto%2C_CA_welcome_sign.JPG/180px-Palo_Alto%2C_CA_welcome_sign.JPG[image] +

+
+

+
Jenkins User Conference is back to California again! +
 +

+
Just like the last two years, this full day event packs talks from Jenkins developers and users, and it would be a great opportunity for Jenkins users to get to know each other and share their experiences. +
 +

+
https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto.cb[The agenda is already posted], covering everything from robotics to mobile developments, effective management of Jenkins instances to branching techniques. I&#x27;m personally looking forward to a number of talks from serious large-scale users, and https://www.cloudbees.com/jenkins/juc2013/juc2013-israel.cb[JUC Israel] was of any indication, it&#x27;d be a great opportunity to get feedback from people. +
 +

+
This year, we are moving the event to a weekday (Oct 23rd) to see if it helps or hurts the attendance. Similarly, the event is now in Palo Alto, as opposed to San Francisco. The site also happens to be a former Sun Microsystems headquarter, a place of some nostalgic value to me. +
 +

+
I am also very happy to see a number of active community members https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto.cb[signing up their employers to sponsor the event]. These will help us manage the cost of the event. +
 +

+
So really, all that&#x27;s needed is YOU! https://www.eventbrite.com/event/6367028955[Please register for the event] (I believe the early bird price stays until this Friday), and looking forward to seeing you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/08/01/2-version-control-plugins-in-beta-testing-before-a-major-release/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 1</div></div><h5 class="title">2 version control plugins in beta testing before a major release</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/4/49/Testing22222.jpg[image,width=150,height=160] +

+
+

+
https://wiki.jenkins.io/display/JENKINS/Git+plugin+2.0+beta+testing[Git plugin] and https://wiki.jenkins.io/display/JENKINS/TFS+plugin+2.0+beta+testing[TFS plugin] are calling for interested parties to try out their 2.0 beta binaries before they get released. +
 +

+
Git plugin 2.0 contains a major refactoring and UI simplifications, and TFS plugin contains a rewritten polling logic that does not require a workspace. +
 +

+
If you think you&#x27;d benefit from these changes, please head to their respective beta testing page and try out the new bits, while we can still change them.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/09/05/extreme-feedback-lamp-switch-gear-style/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 5</div></div><h5 class="title">Extreme Feedback Lamp, Switch Gear style</h5></div><p class="teaser">+
This is a guest post by https://twitter.com/dvaske[Aske Olsson] +
 +

+
Extreme feedback is an incredibly powerful way to drive quality and accelerate your developer fast feedback loop. +
 +

+
Having eXtreme Feedback Devices (XFDs) hooked up to your Jenkins jobs gives everyone on your team instant insight into the current software state. At customer after customer we&#x27;ve seen extreme feedback devices drive significant incremental productivity gains, so about a year ago we started talking about taking the concept mainstream and making it easily available to any development team. So, as a small side-project, we&#x27;ve decided to scratch our own itch and developed an easy-to-deploy, Linux-based, laser-cut, extreme feedback device, specifically designed for Jenkins. It infers a feeling of urgency when the build is broken, and a better sense of a achievement once the problem is fixed. Just connect the XFD to your network, install the &quot;extreme feedback plugin&quot; on your Jenkins server and configure which jobs to feedback extremely. +
 +
 +

+
At the Jenkins Code Camp in Copenhagen today (with Kohsuke) we&#x27;ve made the lamp speak the name of the developer who broke the build :), improved the plugin&#x27;s UI in Jenkins, and gotten the the lamp&#x27;s display to list all the developers who contributed to the last change. Of course you can contribute too, just fork the repositories at https://github.com/switchgears/extremefeedbacklamp[here] and https://github.com/switchgears/extreme-feedback-plugin[here] and create a pull request. +
 +

+
If you&#x27;re interested in trying out extreme feedback in your own team you can order https://web.archive.org/web/20180826231109/https://gitgear.com/xfd/[your own XFD lamp] +
 +

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/09/09/loader-io-plugin-developer-interview/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 9</div></div><h5 class="title">Loader.io plugin developer interview</h5></div><p class="teaser">This is a guest post by Mike Rowan, VP R&amp;D at SendGrid.

+

+
image:https://jenkins-ci.org/sites/default/files/images/loaderio.png[image,width=150,height=150] +

+
+

+
*Q: Tell us a bit about what your service and plugin do. Who is it for? What are the highlights of your plugin?* +
 +

+
A: https://loader.io[Loader.io] is a simple-to-use cloud-based load testing service. The service is designed for developers and people who need to ensure applications are performing as they should. It allows developers to perform large-scale load tests on demand, which lets them understand the scalability and performance of their applications. We realize Jenkins is the preferred build service for a lot of our users, and we know providing a way for them to implement, measure and improve application performance during the continuous build cycle is important. So we wrote a Jenkins plugin that allows load testing to be brought into the continuous build and deployment process with ease. +
 +

+
Q: Did you have to convince your boss/lawyers to open-source your plugin? What was the pitch?*

+
A: No, at SendGrid our focus is always to help make developers’ lives easier, and when we can, we like to provide tools that they can hack on. Since the Jenkins platform is itself an open source project, following the same model to provide our plugin made perfect sense. In addition, we encourage others to build on our work, help improve it and ultimately make it better for everyone using it. +
 +

+
Q: How did you learn how to write a plugin?

+
+

+
A: We use the Jenkins platform ourselves, and we leverage a number of the plugins available. Having access to these and the Jenkins documentation gave us a great head start. It was an easy decision to write the Jenkins plugin for loader.io, and the Jenkins community provided both detailed instructions as well as support when we needed it. +
 +

+
Q: Any gotchas in the experience of developing a plugin that you want to share?

*

+
A: The overall process of developing the plugin was straightforward and simple, but we did run into some scope creep in the middle of the dev process. We found that since the platform was so easy to write for, it made us keep adding more and more features. Usually this is good, but in the case of our project, we wanted to provide the most value as quickly as possible. So we scaled back, focused on solid execution for the most important features, and are already preparing to launch a new version with the things we reserved for post v1 availability. +
 +
 +

+
Q: What is the reaction from users so far?

+
+

+
A: The users we’ve spoken with love the plugin. In addition we’ve already gotten great feedback from some community members on “nice to have’s” in the plugin, some of which we’re already working on. +
 +

+
Q: What tips do you share to those who are interested in writing plugins?

+
+

+
A: If you have a service that provides value in the build, deployment and post deployment process, then you should be writing a Jenkins plugin. Two things are important for anyone writing a plugin: 1) be sure the plugin you’re writing is going to provide true value (if you need it yourself this is a good sign), and 2) make sure you understand the scope of the project and deliver core features and value first, then focus on some extra things. Providing a valuable plugin sooner than later will help you identify all the right additional features to include, especially when collecting live community feedback. +
 +

+
Some of the things we focused on early in the process were to identify the core features, and more importantly to make it very easy for users of Jenkins to install, use and interpret the loader.io plugin and results. We wanted to allow users to leverage our plugin for multiple environments and builds with system and global credentials. To do this, we decided to make use of the Credentials plugin (https://wiki.jenkins.io/display/JENKINS/Credentials+Plugin), which is a heavily-adopted plugin that provides a standardized API for plugins to store and retrieve credentials. This plugin allows our users to add and use different credentials in one single Jenkins environment. In addition, we created a new re-run feature which, when used with continuous build and testing, provides a deep view into the performance of an application over time. Finally, we wanted to bring the same UI experience users have in our environment into Jenkins, which we did by preserving the load test report model and making it function the same in the Jenkins UI. Doing this makes it easy for users to have consistency between the UIs and more easily understand the results regardless of where they’re viewing them. +
 +

+
It’s very easy to write a Jenkins plugin - I hope these insights will encourage you to write your own. +
 +

+
ps - We’d love your feedback too. Check out our newly-released https://wiki.jenkins.io/display/JENKINS/loaderio[Jenkins plugin] for loader.io and let us know what you think.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/09/11/behind-the-scenes-of-the-jenkins-user-conference-palo-alto/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">11</div></div><h5 class="title">Behind the Scenes of the Jenkins User Conference Palo Alto!</h5></div><p class="teaser">+
The Jenkins User Conference (JUC) Palo Alto is less than two months away! +
The organizing committee, 13 sponsors and 16 speakers have been hard at work coordinating a fun and educational day for the Jenkins community on October 23. Check out the https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto.cb[agenda] and see for yourself! Speakers are traveling from around the globe to take part in this conference, including a number of usual suspects. Dedicated Jenkins experts are coming in from London, Israel, Estonia, Sweden, Taiwan, Boston, Seattle, Texas and, of course, the local Bay Area. +
 +

+
New this year, we’ll live stream an entire track, courtesy of our Silver sponsor, https://confreaks.com/[Confreaks]. +
 +

+
In keeping with tradition, every year we create a one-of-a-kind Jenkins t-shirt for JUC attendees. This year we are sticking with the ever-popular landmark of Palo Alto, Stanford University. And we are going bright…hope you like (Jenkins) red! +
 +

+ +

+
+

+
We are always on the look out for unique and creative ideas for Jenkins t-shirt designs. If you have a cool design in mind please send it to `+events@lists.jenkins-ci.org+`. You may just see the Jenkins community wearing your design at next year’s conference. +
 +

+
Also check out the great Jenkins collectible that https://www.cloudbees.com[CloudBees], the Platinum sponsor, is giving out at the CloudBees table (I heard he looks even better in person). Quantity is limited so be sure to pick one up at the CloudBees table. You might have to sing, dance, bark or just complete a survey in exchange for the Jenkins bobble head. Most importantly, don’t forget to have Kohsuke sign it to make it official. +
 +

+ +

+
+

+
JUC isn’t complete without some good BEvERages. Gold sponsor https://www.bds.com[Black Diamond Software] is ponying up a keg of beer after the conference. Leave us a comment (below) about what kind of beer strikes your fancy and it might just be there. +
 +

+
If you’ve read this entire blog and have not yet registered to https://www.eventbrite.com/event/6367028955[attend], here’s additional incentive for you. Use discount code *BEE-JUC* to get early bird pricing, that’s a $26 saving off the current price of $80. Discount expires October 4, 2013. +
 +

+
As JUC Conference Chair, I am always looking for ways to improve JUC. Leave your comments below on ways we can make this ‘Your’ conference. +
 +

+
Looking forward to seeing you at JUC on October 23. +
 +

+
Alyssa Tong +
JUC Conference Chair<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/09/16/continuous-information-jenkins-newsletter-vol-5/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">16</div></div><h5 class="title">Continuous Information - Jenkins Newsletter vol. 5</h5></div><p class="teaser">+
 +
The latest edition of Continuous Information is out for your reading pleasure. +
Highlights: +

Health Check-up for Jenkins: Kohsuke’s Tips on Keeping Jenkins Happy

Jenkins continues to take over the world, with more than 65,000 active installations and more than 800 plugins

Events: Jenkins User Conference – 10/23 in Palo Alto, CA (use discount code BEE-JUC); Jenkins Scalability Summit 10/24; and more

Jenkins made the SD Times 2013 Top 100!

What’s new in Jenkins? The hottest new Jenkins improvements…

How to build your own Jenkins Traffic Light

+
 +
https://pages.cloudbees.com/index.php/email/emailWebview?mkt_tok=3RkMMJWWfF9wsRonvanBZKXonjHpfsX%2B4%2B0uT%2Frn28M3109ad%2BrmPBy82IoIWp8na%2BqWCgseOrQ8kFQLV9C%2BRs0Vq6c%3D[Read the whole newsletter], and then https://www.cloudbees.com/jenkins/jenkins-ci/jenkins-newsletter.cb[sign up to receive it directly when it comes out]. +
 +
 +
PS - We love contributions to Continuous Information, so if you have a Jenkins tip, trick, or plugin you’d like to feature, please mailto:continuous-information@cloudbees.com[email us].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/09/23/literate-builds-wtf/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">23</div></div><h5 class="title">Literate builds, WTF?</h5></div><p class="teaser">(This is a guest post by Stephen Connolly)

Every developer, at some stage, will be handed a project to maintain that somebody else was responsible for. If you are lucky, the developer will not have left the organization yet and you get a brief Knowledge Transfer as the developer packs up their desk before heading on to their new job. If you are unlucky, you don’t even get given the details of where the source code is hiding.

Now begins the detective work, as you try to figure out how to build and release the project, set up Jenkins jobs to build the project and run the tests…​

It doesn’t have to be this way, you know!

What if I told you there was a file sitting at the top level that told you exactly how to build the project and do the important things? You’d be interested, wouldn’t you?

When I tell you it’s the README file? “But that’s all lies. Nobody keeps that up to date. Argh!!!”

But what if Jenkins reads the README file and uses it for the build definition? Now you not only have a CI system ensuring that the build definition is correct, but you have less work to do setting up the job.

What if, because the build definition is now in Source Control, you can have Jenkins create jobs for each branch with ease? The joy of cheap branches that modern source control systems such as GIT and Mercurial give us, no longer comes with the pain of having to create Jenkins jobs for each branch (and more pain having to remember to tidy up when the branch is gone.)

That is the promise delivered by the Literate plugin.

How does it work?

First of all, because Jenkins will be looking at all your branches, you need a way to tell Jenkins which branches it makes sense to try and build. For example, if your project lives on GitHub, you are unlikely to want the gh-pages branch to be treated like a branch of your actual code, and there are going to be branches that have a README file, but not one that Jenkins understands, so we will want to ignore them too.

You tell Jenkins that a branch is one to build by putting a marker file in the root of the branch. By default the marker file is called.cloudbees.md. If the marker file is present and empty, then the literate job type will assume the build instructions are in README.md. If the marker file is present and has build instructions, then the literate job type will just use those instructions.

In order to make it easy to provide the instructions, there is rather minimal formatting requirements for a literate description of a project’s build commands.

The minimal description is just a section with the word build and a verbatim code block in that section. Here is the obligatory minimal “hello world” project description:

# Build

    echo hello world

or if you don’t like indenting you could use the GitHub style triple-back-tick

# Build

```
echo hello world
```

Part of what makes this a literate style of build description is that you can freely intersperse the description of what and why the commands do with the actual commands, e.g.

# Build

We will greet the world with our great literate project description

    echo -n &quot;Hello&quot;

Now that we have announced our intention to greet some people, we need to qualify exactly who we are greeting

    echo &quot; world&quot;

That was just perfect. Time for a cup of tea

The first section heading containing the word build identifies the section that is assumed to be the build instructions. (The keyword that is searched for is configurable, but not yet exposed in the literate plugin’s UI). The following is also a valid README.md for printing hello world:

Our super hello world project
=============================

This is a project to say hello to the world

How to build
------------

You can build this project by running the following command:

    echo hello world

Credits
-------

This project would not have been possible without the existence of Assam loose leaf tea.

Now this is all very well, but what about if you need different instructions for building on Windows versus on Linux, and for that matter how does Jenkins know where we should build this project. Plus Mr Joe Random needs to know what he needs to install on his machine to build it for himself.

The first section containing the word environment identifies the section that contains the details of the environments to run the build on.

Hello world project
===================

This is a simple hello world literate project

Environment requirements
------------------------

The project is built and tested by Jenkins on the following build environments, so it is known that the build instructions work on the following environments:

* `windows`
* `linux`

How to build
------------

The build instructions are platform dependent:

* On `windows`:

        echo &quot;hello world&quot;

* On `linux`:

        echo hello\ world

When Jenkins sees bullet points in the environment section it assumes each bullet point corresponds to an environment to run the build on. Each environment is specified by at least one code snippet which helps define the requirements of the environment. By default Jenkins will look for tool installers with the same name as the labels. If it cannot find any matching tool installers it assumes that the labels are Jenkins agent node labels. (The strategy is plugable, but not yet exposed in the UI of literate builds)

When you have multiple environments on which to build and test, you have two choices on your build instructions. You can either:

Have one and only one set of commands that work on all environments; or

Have bullet points that cover all the specified environments.

So for example, if you are building on the following environments:

windows, java-1.6, ant-1.7

windows, java-1.6, ant-1.8

windows, java-1.7, ant-1.8

linux, java-1.7, ant-1.7

linux, java-1.7, ant-1.8

You need to have bullet points in your build section that can match each of those options, but as long as there is a match for every option you are ok. So for example:

ANT version finder
==================

Finding out the version of ANT on various platforms

Environments
------------

Nesting bullet points multiplies out the options

* `windows`
    * `java-1.6`
        * `ant-1.6`
        * `ant-1.7`
    * `java-1.7`, `ant-1.8`
* `linux`, `java-1.7`
    * `ant-1.7`
    * `ant-1.8`

Build
-----

The first match with the highest number of matches wins, so we want windows to get special treatment:

* `windows`

        call ant.bat -version

* `java-1.7`

        ant -version

We could have picked `linux` for the above if we wanted, but this matching will have the same effect and better illustrates how matching works.

That is a mostly complete detail of how the build and environment sections work. In general everything except verbatim code blocks and bullet points with code snippets get ignored.

There are other sections that the literate project type allows for, these are called “task” sections. We haven’t written the code to support them yet, but the idea is that these will work a bit like basic build promotions with the promoted builds plugin. There will be a UI in Jenkins that lets you kick off any of the task sections that you define as being valid for the job type, in pretty much exactly the same was as the promoted builds plugin works.

After that, everything else in the README.md is ignored.

How do I get the test results into Jenkins?

Jenkins is not just about build and test. A lot of the utility in Jenkins comes from the additional reporting plugins that are available for Jenkins. (The build step ones are less relevant with literate style projects because you want to give people consuming the content instructions they can also follow)

So there is additional metadata about your project that you want to give to Jenkins. We put that metadata into a folder called.jenkins in the root of your source control.

There are two levels of integration that a Publisher/Notifier can have with the literate project type. The first level is a basic XML description of the plugin configuration. If you have ever looked at the config.xml of a Jenkins job, you will be familiar with this format.

If we have a Maven project and we want to collect the Unit test results in Jenkins we might have a README.md like this:

Maven project with tests
========================

Environments
------------

* `java-1.7`, `maven-3.0.5`

Build
-----

```
mvn clean verify
```

And then we create a.jenkins/hudson.tasks.junit.JUnitResultArchiver.xml file with the following:

**/target/surefire-reports/*.xml, **/target/failsafe-reports/*.xml
true

The literate plugin adds an Action to all Free-style projects that allows exporting these XML configuration snippets in a.zip file for unpacking into your project’s source control. Each publisher/notifier has its own file, so it should be easy to mix and match configuration across different projects and enable/disable specific publishers just by adding/removing each publisher’s file.

The XML itself can be a bit ugly, so there is a second level integration, where a Publisher/Notifier plugin can implement its own DSL. The literate plugin ships with two such DSLs. One for archiving artifacts and the other for JUnit test results. So the above XML file could be replaced by a.jenkins/junit.lst file with the following contents

**/target/surefire-reports/*.xml
**/target/failsafe-reports/*.xml

Not everything makes sense in source control though…​

There are always going to be things that you need to configure in Jenkins. So for example there may be some sources of branches that you don’t trust. A good example would be pull requests on GitHub. We have a concept of branch properties in the literate project type that will allow defining what exactly a trusted branch source should be allowed do and what an untrusted branch source should be allowed do. It does not make sense for that information to be embedded within the untrusted branch itself.

Similarly coordination between different Jenkins projects is something that does not make sense in source control. The names of those Jenkins projects (and even their existence) is not knowable from source control. It does not make sense to keep that information in source control.

Information about how to map the description of the build environment in the README.md file to the build environments available to Jenkins does not make sense in source control because your Jenkins node configuration details may change over time.

In other words, literate projects do not remove the need to configure things in Jenkins. They do however remove a lot of the need, and especially the need to tweak the exact build commands and the location of where build results should be picked up from.

What’s not done yet?

Here is a list of some things I want to see for literate builds:

A literate build step so that people can use some of the literate magic in their free-style projects while they migrate them to literate-style

Support for literate task promotion flows (I think Kohsuke has signed up to help deliver this)

Exposing the configuration points such as the marker file name (a global config option as well as per-project override) and the keywords to search for in the README.md (this is mostly UI work)

Adding in some support for other markup languages (I’d really like to see AsciiDoc formatted README parsing, e.g. README.asc)

Branch properties for untrusted builds (to do things like restrict the build execution to one explicit environment, put an elastic build timeout in place, wrap the shell commands in a chroot jail, etc)

Branch properties for build secrets (So that the production and staging branches can get the keys to deploy into their respective environments.

Collapsing the intermediate level in the UI when there is only one build environment.

Eliminating the double SCM checkout when the backing SCM supports the SCMFileSystem API so that builds work even faster

Reusing the GIT repository cache when using GIT branch sources.

Some nicer integration with GitHub (I have most of this done, but I think it would be irresponsible to release this without having the Untrusted branch properties implemented as otherwise Pull Requests could become a vector for abuse)

Finishing the support for Subversion credentials migration from the legacy credentials storage mechanism to the new Credentials plugin storage mechanism (not strictly literate project related, but Subversion is still a popular SCM and until this gets done we cannot release a version of the Subversion plugin with literate project support)

Adding nice DSLs for all the Publishers and Notifiers

Adding SCM support to all the SCM plugins

Adding branch property support for the Build Wrapper / Build Environment / Job Property plugins where that makes sense.

Having said all that, the core functionality works right now for GIT/Subversion/Mercurial on Jenkins 1.509+, and it is only by playing with this functionality that you can see how this could change the way you use Jenkins.

How do I try this out myself

Last week Kohsuke set up a new “Experimental” update center in Jenkins OSS. The reason for this new update center is that we have a lot of (potentially disruptive) changes to many plugins and if we started cutting releases, users may get annoyed if they end up upgrading to these plugins until they have all been better tested.

The “Experimental” update center includes plugins that have alpha or beta in their version number, while the other update centers now exclude those plugin versions.

So if you want to play with these plugins you need to change your Jenkins instance’s update center URI to:

https://updates.jenkins-ci.org/experimental/update-center.json

I would recommend that you use a test Jenkins instance for playing with.

(WARNING: shameless plug) You could also just fire up a Jenkins in the cloud using CloudBee’s DEV@cloud service and follow these handy instructions to enable access to the experimental plugins:

The 10 best bug reports on literate builds before the Jenkins User Conference next month will receive a prise from CloudBees, Inc. I was able to get a commitment that the prise would be at least a T-shirt. I am hoping to get some more swag added to the prize pool. CloudBees employees or relatives of CloudBees employees are not eligible for the bug report prise!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/10/09/jenkins-at-netflix-juc-speaker-interview/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 9</div></div><h5 class="title">Jenkins at Netflix / JUC speaker interview</h5></div><p class="teaser">(This is a guest post from Gareth Bowles, a Senior Software Engineer at Netflix.)

+
image:https://www.cloudbees.com/sites/default/files/juc/juc2013/Palo-Alto-Gareth-Bowles.jpg[image] +

+

+
Jenkins has been a central part of the Netflix build and deploy infrastructure for several years now, and we&#x27;ve been attending and speaking at JUC since it started in 2011. It&#x27;s a great opportunity to meet people who are as passionate about build, test and deployment automation as we are - although as Kohsuke said last year, having all those folks in one place could be dangerous if there&#x27;s an earthquake ! +
 +

+
CloudBees and the JUC Organizing Committee have put another great program together this year. We&#x27;ll be doing two talks. Justin Ryan and Curt Patrick will present &quot;Configuration as Code: Adoption of the Job DSL Plugin at Netflix&quot;, describing how we&#x27;re shifting our users from manual job configuration via the UI, to defining their jobs as Groovy code using the https://wiki.jenkins.io/display/JENKINS/Job+DSL+Plugin[Job DSL plugin]. Justin and Curt will describe how Netflix development teams can now create and maintain complex sets of jobs for their projects with the bare minimum of coding. +
 +

+
In my lightning talk &quot;Managing Jenkins with Jenkins&quot;, I&#x27;ll go over how we use Jenkins&#x27; system Groovy scripts to maintain and monitor our Jenkins controllers at a scale that couldn&#x27;t be achieved with manual processes, and without the overhead of writing custom plugins. +
 +

+
As usual, there will be a whole crew of Netflix engineers at JUC this year. If you&#x27;re interested in working on build and deployment at Netflix scale, find one of us (we&#x27;ll all be wearing Netflix gear) to learn more - we&#x27;re hiring ! +
 +

+
+

+
https://www.eventbrite.com/event/6367028955[Register for JUC - October 23 in Palo Alto]. If you can&#x27;t make it in person, https://www.eventbrite.com/event/8328596055[register to watch the live stream!]<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/10/09/meet-the-community-in-juc/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 9</div></div><h5 class="title">&quot;Meet the community&quot; in JUC</h5></div><p class="teaser">(This is a guest post from Owen B. Mehegan aka autojack)

+
+

+
The Jenkins User Conference - Palo Alto is coming up on October 23rd! The schedule for talks is full, but we&#x27;ve been looking for a way to give other members of the Jenkins community some visibility. There are many people who have contributed to the project in various ways, whether it&#x27;s contributing to core, developing plugins, writing documentation or just helping new users. +
 +

+
If this sounds like you, we&#x27;re interested in giving you 10-15 minutes to talk to the rest of the conference attendees! The format is currently undefined and may be left up to you. You could do a Q&amp;A, talk about features you&#x27;ve worked on and why they were important to you, or just offer some &quot;pro tips&quot; that you&#x27;ve developed based on your experience. The main point is to help put faces to some of the names in the community, and also help encourage others to contribute themselves! We&#x27;re thinking of having these sessions during lunch and the exhibit hour (https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto.cb[see here for the schedule]). +
 +

+
If you&#x27;re interested in this, or know someone else who might be that I could contact, please let me (owen at nerdnetworks dot org) know! If we can get some critical mass around it then we&#x27;ll go ahead. +
 +

+
Thanks!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/10/18/jenkins-user-conference-is-completely-full/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">18</div></div><h5 class="title">Jenkins User Conference is completely full!</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/alyssa.jpg[image,width=150,height=150] +

+
+

+
(This is a guest post by Alyssa Tong, the lead coordinator of Jenkins User Conference) +
 +

+
Our https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto.cb[3rd annual Jenkins User Conference in the Bay Area] being held next Wednesday in Palo Alto is booked fully to the capacity and we couldn’t be more excited for this event! It’s going to be an amazing day of learning, talking to technology experts, networking with other Jenkins users, seeing cool demos and finding out how you can contribute to the Jenkins open source projects. +
 +

+
This event is being held at the https://www.paloaltojcc.org/[Oshman Jewish Community Center] and registration begins at 8am. There will be breakfast and plenty of coffee to get you caffeinated. Welcoming announcement will begin sharply at 9am and the keynote address follows shortly after. We’re so excited to have https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto.cb[thirteen sponsors] investing in and supporting the Jenkins community in this continuous integration space. +
 +

+
New this year, there will be BoF sessions so be sure to sign up for your preferred discussion at check-in. Or suggest a topic by leaving your suggestion in the comments section below. Let us know what Jenkins topic(s) is near and dear to your heart. +
 +

+
For those who missed out on purchasing your ticket or are unable to attend, we are happy to offer the https://www.eventbrite.com/event/8328596055[live stream] of Track 1. You can choose to watch the entire track or just specific session(s). Either way don’t forget to chat and tweet. We will also tweet live from the conference so you can follow along that way as well. Follow @jenkinsconf for the latest updates. +
 +

+
Thank you to everyone for making this sold-out event possible. +
 +

+
Can’t wait to see everyone on Wednesday! +
 +

+
— Alyssa<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/11/08/jenkins-scalability-summit-recap/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 8</div></div><h5 class="title">Jenkins Scalability Summit Recap</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Scale_(anatomy)[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Lepidoptera_wing.jpg/220px-Lepidoptera_wing.jpg[image] +
]

+
+

+
The day after https://jenkins-ci.org/content/jenkins-user-conference-completely-full[Jenkins User Conference], we held a smaller meet-up of serious large-scale Jenkins users dubbed as https://www.meetup.com/jenkinsmeetup/events/126595572/[&quot;Jenkins Scalability Summit&quot;]. +
 +

+
In this https://en.wikipedia.org/wiki/Open_Space_Technology[Open Space Technology] style event, we went over war stories from users. Just to show the degree of seriousness, some of those people run 1500+ agents, and others run Jenkins in HA configuration with a data center fail over! We then picked various topics in the afternoon and discussed what people would like to see to make Jenkins scale further. Slides and raw notes from this meeting is https://bit.ly/jss13[available here]. +
 +

+
The event allowed me to rethink and revisit what I thought we should do in coming days in the area of scalability. +
 +

+
The event was far more popular than we anticipated originally, and we had to turn down many folks. So I&#x27;m going to do a webinar to go over what we did, and what we talked about. If you are interested in this area, and want to see what&#x27;s being considered and provide your thoughts, please join us on https://www.cloudbees.com/webinars/jenkins-scalability-summit-recap.cb[Nov 19th 10am PT].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/11/17/dkim-and-spf-deployed/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">17</div></div><h5 class="title">DKIM and SPF deployed</h5></div><p class="teaser">+
In the hope of streamlining account creation e-mail delivery and mailing list moderations, I have deployed https://en.wikipedia.org/wiki/Sender_Policy_Framework[SPF] and https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail[DKIM] over the weekend for e-mails coming out of `+@jenkins-ci.org+`, which includes account appliations, Confluence, and JIRA. +
 +

+
I&#x27;ve also used this opportunity to switch back the sender of JIRA notifications to `+noreply@jenkins-ci.org+`. It was originally this way, then changed to `+jenkinsci-no-reply@googlegroups.com+` when someone complained (on what ground I do not remember any more.) +
 +

+
To the degree that I have tested the setup, it is working correctly, but if you notice anything strange, please let me know.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/11/20/juc-call-for-volunteers-to-join-the-organizing-committee-and-venues/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">20</div></div><h5 class="title">JUC: Call for Volunteers to Join the Organizing Committee (and Venues!)</h5></div><p class="teaser">This is a guest post from Alyssa Tong, who drives JUC organizations around the world.

If you missed JUC Palo Alto on Oct 23, 2013 the videos are now available.

We are off to planning JUC 2014. It is hard to believe this will be the 4th annual JUC in the Bay Area. The growth in the Jenkins community since the first JUC is astounding.

Every year we are in search of a larger venue to accommodate the larger crowd. For 2014, the challenge of finding a venue for a capacity of 500+ attendees at a low cost will prove even more daunting. We would love to hear your suggestions for low cost venues (in the Bay Area) so that we may continue to keep entry cost low while providing convenience and the highest level of Jenkins education to attendees. Please send suggestion(s) to events@lists.jenkins-ci.org

We are proud to launch the call for volunteers to join the JUC organizing committee (OC). If you are interested in shaping the 4th edition of this great event, please send email to events@lists.jenkins-ci.org

We encourage you to share this blog within your network in case other people
would be interested in joining the JUC OC or have ideas for a great JUC 2014 location.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/11/25/summary-report-git-repository-disruption-incident-of-nov-10th/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">25</div></div><h5 class="title">Summary Report: Git Repository Disruption Incident of Nov 10th</h5></div><p class="teaser">As reported in various places, there was an incident in early November where commits in our Git repositories have become misplaced temporarily by accident. By the mid next week we were able to resurrect all the commits and things are back to normal now.

As there are many confusions and misunderstandings in people’s commentary, we wrote this post to clarify what exactly happened and what we are doing to prevent this.

Timeline

In the early morning of Nov 10th 2013, one of the 680 Jenkins developers had mistakenly launched Gerrit with a partially misconfigured Gerrit replication plugin, while pointing Gerrit to his local directory that contains 186 Git repositories cloned from the Github Jenkins organization. These repositories were checked out about 2 months ago and weren’t kept up to date. Gerrit replication plugin had then tried to “replicate” his local repositories back to GitHub, which it considers mirrors, by doing the equivalent of “ git push --force ” instead of regular push. Unfortunately, Gerrit replication plugin defaults to a forced push, which is the opposite of what Git normally does. The replication also happens automatically, which is why this mistake has impacted so many repositories in such a short time.

As a result, these repositories have their branch heads rewinded to point to older commits, and in effect the newer commits were misplaced after the bad git-push.

When we say commits were &quot;misplaced&quot;, this is an interesting limbo state that’s worth an explanation for people who don’t use Git. A Git commit is identified by its SHA1 hash, and these objects will never get overwritten. So the misplaced commits are actually very much on the server intact. What was gone was the pointer that associates a human-readable branch name (such as &quot;rc&quot;) to the latest commit on the branch.

By Nov 10th 12:54pm GMT, multiple developers had noticed this, and within several hours, we figured out what happened. From Gerrit log files and with the help of GitHub technical support, he was able to figure out all the affected repositories, and later an independent script was written to verify the accuracy of this list.

Some of the Jenkins developers were closely following this development, and were able to restore branches to point to correct commits by simply pushing their up-to-date local workspaces back into the official repositories. Git makes it very easy to do this, and most of the popular plugins affected were restored in this manner within 24 hours.

At the same time, we needed to systematically restore all the affected repositories, to make sure that we have not lost anything. For this, we contacted GitHub and asked for their help, and they were able to mostly restore branch heads to their correct positions. We have also independently developed a script to find out exactly what commits branch heads should be pointing to, based on the GitHub events API that exposes the activities to Git repositories. This script found a dozen or so branches that fell through the cracks of GitHub support, and we have manually restored those.

Mitigation in the future

The level of support we got from GitHub and our ability to independently verify lost commits and subsequently restore them made us feel good about GitHub, and we have gained confidence in our ability to recover from future incidents.

That said, what happened was a serious disruption, and it’s clear we’d better prepare ourselves both to reduce the chance of accidents like this and increase the ability to recover. To that end, we hope GitHub would expose a configuration option to disable forced ref updates. They already do this on GitHub Enterprise after all. Dariusz pointed out that CollabNet takes this one step further and offers ability to track deleted branches, tags, and forced updates. Something like that would have made the recovery a lot easier.

We are going to make two improvements to our process so that we can recover from this kind of problems more easily in the future.

Firstly, we’ll develop a script that continuously records the ref update events across the GitHub Jenkins organization. This will accurately track which branch/tag is created/updated/deleted by who. In case of an incident like this one, we can use this log to roll back the problematic push more systematically.

Secondly, we’ll allow people to control access to individual Git repositories, as opposed to give them all or nothing access to the entire array of plugin repositories.

The Jenkins developers decided to continue the current open commit policy despite the incident to preserve our culture, which helped us navigate through this incident without a single argument nor flame war.

FAQ

Does everyone in the organization have full commit privileges to all the repositories?

Yes, with some exceptions. To encourage co-maintenance of plugins by different people, and to reduce the overhead of adding and removing people from our 1100+ repositories, we use one team that gives access to most repositories, and put committers in this team.

I prevent forced push in my Git repositories. I’m safe from this trouble, right?

No, unfortunately something like this can still happen to you, as you can also accidentally delete branches. If you want to learn from our mistakes, you should definitely enable server-side reflog, to track ref updating activities. “git config core.logAllRefUpdates true” on the server will enable this.

Can’t you just have people with up-to-date copy push their repos and fix it?

This is indeed how some of the repositories got fixed right away, where some individuals are clearly in charge and are known to have the up-to-date local repositories. But this by itself was not sufficient for an incident of this magnitude. Some repositories are co-maintained by multiple people, and none of them are certain if he/she was the last one to push a change. Many plugin developers just scratch their own itch and do not closely monitor the Jenkins dev list. We needed to systematically ensure that all the commits are intact across all the branches in all the affected repositories.

Can’t you just roll back the problematic change?

Most mistakes in Git can be rolled back, but unfortunately ref update is the one operation in Git that’s not version controlled. As such Git has no general-purpose command to roll back arbitrary push operation. The closest equivalent is reflog, which offers the audit trail that Git offers for resolving those cases. But that requires direct access on the server, which is not available on GitHub. But yes, this problem would not have happened if we were hosting our own Git repositories, or using Subversion for example.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/12/04/jenkins-user-conference-2013-palo-alto-wrap-up/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 4</div></div><h5 class="title">Jenkins User Conference 2013 Palo Alto Wrap-up</h5></div><p class="teaser">+
It&#x27;s been a month now, but I realized that I&#x27;ve never posted a wrap-up post of JUC 2013. So in the spirit of &quot;better later than, never&quot;, here it goes. +
 +

+
First of all, I wanted to thank everyone who came. More than 400 of you came, and another 600 signed up for live streaming of events (and I know some people watched those live streams past midnight in their local time zone!). I did my part in https://bobbickel.blogspot.com/2013/10/kk-jenkins-and-triumph-of-technology.html[signing bobble heads] and answering questions, and I was able to finally put faces to some of the people who I actively interact in the community but never met before. +
 +

+
I tried to https://www.flickr.com/photos/12508267@N00/sets/72157637144035034/[take as many pictures as I can], and https://www.facebook.com/media/set/?set=a.700790069940324.1073741828.150316981654305&amp;type=3[Lisa and Alyssa had posted their pictures as well]. If you have your pictures, please share it with us! My favorite is Jenkins cupcake: +
 +

+ +

+
+

+
All https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto-abstracts.cb[the slides are video recordings are available online] if you couldn&#x27;t join us. +
 +

+
Alyssa said she&#x27;s got a lot of feedbacks from folks, and https://wiki.jenkins.io/display/JENKINS/Governance+Meeting+Agenda[she&#x27;s already planning for the next year] — if you are interested in sharing your thoughts on how to better do this next year, we&#x27;ve put it up for the next week&#x27;s Jenkins project meeting agenda to talk about how to do it. +
 +

+
Finally, everything in the San Francisco Bay Area is incredibly costly, and events like this was really only made possible by generous sponsors, and we really want to make them happy so that they can help us make this event happen next year as well. So I thought the least I can do is to give them a spotlight and talk about who they are and what they do: +
 +

+

+

+

+

+

+

+

+

Platinum Sponsor

+

+

+

+

+

+

+
**https://www.blogger.com/null[]**https://www.cloudbees.com/[*image:https://www.cloudbees.com/sites/default/files/CloudBees-web.png[image]*] +
 +

+

+

CloudBees is the lead organizer for JUC and offers Jenkins in whatever
form you wish to use it - on-premises or in the cloud. Check out the many
resources available on the CloudBees website for Jenkins fans - whether
you use open source Jenkins, Jenkins Enterprise by CloudBees or Jenkins in the cloud.

+

+

+

+

* *

+

+

Gold Sponsors

+

+

+

+

+

+
**https://www.blogger.com/null[]**https://www.appvance.com/[*image:https://www.cloudbees.com/sites/default/files/appvance%202.png[image]*]

+

+
Appvance delivers technology and services to prove and improve +
performance, security and scalability of websites, apps and mobile apps. +
The largest brands in the world choose Appvance, from Pepsi to Best Buy +
to Bell Alliant. https://www.appvance.com/[Learn more].https://www.appvance.com/[]

+

+
+

+

+

+
*https://www.blogger.com/null[]https://www.bds.com/[image:https://www.cloudbees.com/sites/default/files/BDS%20Logo.jpg[image]]*

+
Have questions on SDLC tools or agile process (especially Jenkins +
Enterprise, CI or CD)? Leverage our 25 years of expertise for assistance +
with CloudBees, Xebia Labs, Sonatype, JFrog, Atlassian, SVN, Git, +
Rational, Microsoft TFS and many more. Visit https://www.bds.com/[www.BDS.com] to learn more..

+

+

+

+
*https://www.blogger.com/null[]https://www.brightroll.com/[image:https://www.cloudbees.com/sites/default/files/BrightRoll_Logo_noslogan_High_Res.png[image]]*

+

+
As the largest independent video advertising platform, BrightRoll powers +
digital video advertising for the world’s largest brands. Jenkins has +
become a core piece of our productivity tech stack here at BrightRoll, +
and its importance is increasing. During the time that we&#x27;ve used it +
we&#x27;ve seen a huge benefit to participating in the Jenkins community, +
getting support from core contributors and plugin authors, and we try to +
contribute back whenever we can. https://www.brightroll.com/[www.brightroll.com]

+

+

+
*https://www.blogger.com/null[]https://www.jfrog.com/[image:https://www.cloudbees.com/sites/default/files/JFrogIcon.png[image]]*

+
The Jenkins User Conference is the only place you can actually feel the +
Jenkins community and understand that being part of it is not just a +
commitment, it is a privilege we are honored to share. Learn more about +
https://www.jfrog.com/[JFrog], our https://www.jfrog.com/home/v_artifactory_opensource_overview[Artifactory] Binary Repository solution, and our new https://bintray.com/[Bintray] social platform for sharing, publishing and managing binaries. +
 +

+

+

+

+

+

+
*https://www.blogger.com/null[]https://web.archive.org/web/20140106081207/http://lmitsoftware.com/[image:https://www.cloudbees.com/sites/default/files/gerritforge-logo.png[image]]*

+
LMIT Software is now GerritForge, the leader in Agile coaching and +
Development Management. We are active contributors of Jenkins (see https://jenkins-ci.mobi/[https://jenkins-ci.mobi]) and https://gerrithub.io/[Gerrit Code Review] and we can enable their adoption and integration into the Enterprise Continuous Delivery chain.

+

+
*https://www.blogger.com/null[]https://newrelic.com/[image:https://www.cloudbees.com/sites/default/files/NewRelic-logo_small.jpg[image]]*

+

+
New Relic is a SaaS application performance management solution that +
provides end-to-end, real time visibility into the operations of network +
connected applications wherever they run – across browsers, mobile +
devices and servers. Sign up for a FREE account at +
https://newrelic.com/cloudbees[newrelic.com/cloudbees].

+

+

+

+

+
**https://www.blogger.com/null[]**https://xebialabs.com/[*image:https://www.cloudbees.com/sites/default/files/Xebia-Logo.png[image]*]

+

+
With  CloudBees https://www.cloudbees.com/dev.cb[DEV@cloud] (Jenkins in the cloud) or https://www.cloudbees.com/jenkins/enterprise[Jenkins Enterprise by CloudBees,] you can instantly connect to https://www.xebialabs.com/deployit[XebiaLabs Deployit] (a fully automated deployment solution) and immediately begin reaping  +
the benefits of delivering continuously. Missed Andrew Phillips&#x27; JUC presentation, Preparing for Enterprise Continuous Delivery: 5 Critical Steps? https://www.slideshare.net/xebialabs/jenkins-user-conference-27508869[View the slides here].

+

+

+
*https://www.blogger.com/null[]https://zeroturnaround.com/[image:https://www.cloudbees.com/sites/default/files/Zeroturnaround1.jpg[image]]*

+
ZeroTurnaround help software eat the world faster. Rapidly develop +
applications with https://zeroturnaround.com/software/jrebel/?src=jucpaloalto2013[JRebel] and continuously deliver them with https://zeroturnaround.com/software/liverebel/?src=jucpaloalto2013[LiveRebel]. +
 +

+
+

+

+
+

+

+
+

+

+

+

+

+

* *

+

+

Silver Sponsors

+

+

+

+

+

+
*https://www.blogger.com/null[]https://www.appdynamics.com/[image:https://www.cloudbees.com/sites/default/files/AD_cl_H_RGB.png[image]]*

+

+

+
*https://www.blogger.com/null[]https://confreaks.com/[image:https://www.cloudbees.com/sites/default/files/Confreaks.png[image]]*

+

+

+

+

https://www.blogger.com/null https://www.liferay.com/[ ]

+

+
*https://www.blogger.com/null[]https://www.soasta.com/[image:https://www.cloudbees.com/sites/default/files/SOASTA_ProfilePic_LinkedIn.jpg[image]]*

+

+

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2013/12/05/jenkins-sao-paulo-meetup-this-weekend/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 5</div></div><h5 class="title">Jenkins Sao Paulo Meetup this weekend</h5></div><p class="teaser">I’m going to visit Sao Paulo once again this weekend to attend the second annual Jenkins users meet-up. It’s a whole day free event Saturday full of Jenkins goodness.

You’ll hear from a number of active Jenkins folks, and I’ll be presenting about what CloudBees (where I currently work) has contributed to the Jenkins project, including recent new OSS plugins and some services. I’m also stuffing my suitcase with lots of give-aways, including Jenkins stickers and popular Jenkins bobble heads. I don’t intend to bring anything back to the U.S.

The morning half of the event is a cross-atlantic hackathon between Brazil and Copenhagen. you can check what’s being planned on the western side of the ocean and the eastern side of the ocean. The afternoon half is a series of presentations. Please come join us. I’m really looking forward to seeing you!

I’ll be in Sao Paulo for the whole Sunday and Monday as well. If you are interested in talking to me, please feel free to drop me a note.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/01/04/building-jenkins-plugins-with-gradle/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 4</div></div><h5 class="title">Building Jenkins plugins with Gradle</h5></div><p class="teaser">Until now, Jenkins plugins written in Java or Groovy could only be built with Maven, using the maven-hpi-plugin to generate a proper manifest and archive which Jenkins can consume. But starting now, you can also use Gradle!

See the wiki for information on how you can use Gradle and the new gradle-jpi-plugin to build, test and release your Java or Groovy Jenkins plugin.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/01/05/thank-you-page-for-windows-os-x-installers/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 5</div></div><h5 class="title">&quot;Thank you&quot; page for Windows/OS X installers</h5></div><p class="teaser">I’ve tweaked the website so that downloading the Windows and Mac installers will navigate the browser to &quot;thank you/what’s next&quot; page. These pages have links to Wiki that educate the users on where/how the installer will run Jenkins.

Hopefully this makes it little easier for new users to get started on Jenkins. I’ve tested the new mechanism with IE, Safari, and Firefox, but if you notice a problem, please let us know.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/01/20/highlight-video-from-juc-2011/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">20</div></div><h5 class="title">Highlight video from JUC 2011</h5></div><p class="teaser">A slick highlight video from the Jenkins User Conference, 2011 was posted recently which captures some great quotes from a number of the fantastic speakers who participated in the inaugural JUC.

I’ve embedded the video below, enjoy!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/02/02/happy-birthday-jenkins/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 2</div></div><h5 class="title">Happy birthday Jenkins!</h5></div><p class="teaser">On February 2nd, 2011 the first release of Jenkins, version 1.396, was made available for public consumption. Thus marking a new beginning for many of us who had come to rely on this very versatile piece of software and wanted to see it continue to thrive.

Along with some other bug fixes, the 1.396 release of Jenkins included a very important changelog item:

Fixed a trademark bug that caused a considerable fiasco by renaming to Jenkins

On behalf of the core Jenkins team and the governance board I would like to extend a extremely large Thank You! to all of the plugin developers, bug filers, wiki page editors, book authors and the users who have helped grow Jenkins into the project it is today.

Some of the tidbits from our highlight reel:

As of this writing there have been 54 releases of Jenkins

Jenkins now supports writing plugins in Ruby as well as Java (more languages in the process)

We have 7 high-speed mirrors streaming Jenkins packages to users around the world.

There are now over 450 different plugins available for Jenkins

Over 80 donors participated in our end of year fundraising drive

5 &quot;Long Term Support&quot; releases have been published by the Jenkins community, offering users a slower moving upgrade target (supported even further by CloudBees&#x27; Enterprise Jenkins product)

Public project governance meetings are held and recorded (almost) every couple of weeks.

More than 340 individuals contribute on GitHub to the project in some form or another.

About 750 members of the developers mailing list and around 1700 on the users mailing list

There are many other impressive sounding numbers I could rattle off, but the list is far too long to be interesting.

The project isn’t perfect and nor is the software, but we’re off to a fine start and I hope you’ll join us in making this next year of Jenkins even better than the first.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/02/13/jenkins-user-conference-2012-paris/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">13</div></div><h5 class="title">Jenkins User Conference 2012 Paris</h5></div><p class="teaser">+ +

+
(English text follows the French text) +
 +

+
Après le succès de la https://www.cloudbees.com/jenkins-user-conference-2011-session-abstracts.cb[Jenkins User Conference l’an dernier à San Francisco] et à l’intérêt qu’elle a soulevé, nous organisons cette année la JUC dans quatre grande villes à travers le monde. La premiére étape de cette tournée est la https://www.cloudbees.com/juc2012.cb[JUC 2012 à Paris], le 17 avril. La conférence aura lieu la veille de https://www.devoxx.com/display/FR12/Accueil[Devoxx France] dans les mêmes locaux. La date a été spécialement choisie pour que vous puissiez faire d’une pierre deux coups, ou plutôt deux confs ! +
 +

+
Les https://cloudbees-jenkins-user-confs.eventbrite.com/[inscriptions sont ouvertes]. Inscrivez-vous dès maintenant pour bénéficier de la réduction réservée au plus enthousiastes. Vous pouvez également https://www.cloudbees.com/forms/jenkins-user-conference-call-papers.cb[proposer un sujet] ou bien https://www.cloudbees.com/jenkins-user-conference-2012-sponsorship.cb[soutenir la conférence en tant que sponsor]. Comme il est bien connu que les Français aiment voir leurs compatriotes sur scène, j’espère que nos nombreux développeurs jenkins francophones (les meilleurs, soit dit en passant) proposeront un sujet ! +
 +

+
Cette année, nous demandons une contribution pour les inscriptions (avec un tarif réduit avant le 18 février), afin de couvrir les frais d’organisation, mais nous vous offrirons en contrepartie le T-shirt officiel ainsi que des autocollants Jenkins. Si on se base sur la JUC 2011, https://jenkins-ci.org/event/jenkins-scale-10x-los-angeles[SCALE 10x], ou le link:/blog/2012/02/21/fosdem-2012-recap/[FOSDEM], ce sera une opporunité exceptionnelle pour rencontrer et discuter avec les dévelopeurs majeurs du coeur ou des plugins, ainsi que les nombreux utilisateurs prêts à partager leur expérience et à répondre à toutes vos questions. +
 +

+

+
Thanks to the success of https://www.cloudbees.com/jenkins-user-conference-2011-session-abstracts.cb[the Jenkins User Conference last year at San Francisco] and high interest, this year we are bringing JUC to 4 cities around the world. And the first stop is https://www.cloudbees.com/juc2012.cb[JUC 2012 in Paris], on April 17. This is one day before https://www.devoxx.com/display/FR12/Accueil[Devoxx France], and in the same venue. The date is specifically chosen so that you can kill two conferences in one stone! +
 +
Register for JUC Paris now (https://www.cloudbees.com/juc2012.cb) and get the Early Bird discount - which is a significant reduction in the registration fee! The conference is https://cloudbees-jenkins-user-confs.eventbrite.com/[accepting registrations] as well as looking for https://www.cloudbees.com/forms/jenkins-user-conference-call-papers.cb[talk submissions] and https://www.cloudbees.com/jenkins-user-conference-2012-sponsorship.cb[sponsors]. I get the impression that French people like other fellow French speaking, so I hope our French-speaking plugin developers will submit talks. +
 +

+
This year, we are charging a small amount of money in the hope of covering the expense, but we&#x27;ll give out T-shirts (which were really hot last year!) as well as stickers. And if the experience at JUC 2011, https://jenkins-ci.org/event/jenkins-scale-10x-los-angeles[SCALE 10x], and link:/blog/2012/02/21/fosdem-2012-recap/[FOSDEM] was any indication, this is a great opportunity to meet and talk with plugin/core developers, and other fellow users with whom you can discuss your experience/questions. +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ndeloof/">Nicolas De Loof</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/02/21/fosdem-2012-recap/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">21</div></div><h5 class="title">FOSDEM 2012 Recap</h5></div><p class="teaser">( Editor’s note: Apologies for the delay in getting this wrap-up out, it’s been quite a busy month!)

This year has already been full of milestones, the first of which being our first birthday as an open source project. The second major milestone for the project was that we went to FOSDEM 2012, arguably the largest volunteer-organized and operated open source conference on the planet.

We had a couple of things going on at FOSDEM that merit a mention:

The Jenkins project had a stand in the K building, the same building where the Free Java, Config and Systems Management, and a few other pertinent dev rooms were located

The Jenkins project gave away 2 free copies of John Smart’s book: &quot; Jenkins: The Definitive Guide&quot; (thanks to O’Reilly!)

Community member R. Tyler Croy gave a talk on running the Jenkins project infrastructure with Puppet

The O’Reilly folks brought 10+ Jenkins books to sell at their stand.

Project founder Kohsuke Kawaguchi and a number of project members held a constructive UI Enhancements discussion.

We were very fortunate to have so many Jenkins contributors in attendance, who all helped with the Jenkins stand, introducing people to Jenkins and much more.

FOSDEM in their own words

( after the break)

Nicholas de Loof :

FOSDEM was for me an opportunity to meet other Jenkins contributors I only knew by IRC nickname. Those two days were awesome to discuss with users on our stand, joke and socialize, as well as having some more technical debates and encourage folks to get involved in the community. Even I couldn’t attend the talks I selected on the conference agenda due to room being full, I really enjoyed this 100% geek weekend.

Christopher Orr :

The people, the talks, the social events, the sheer size of FOSDEM all make for a pretty inspiring weekend.  And incredibly, it’s all for free.

You can not help but feel motivated after attending.  You always learn something new, discover myriad projects — in niches you never knew existed — and talk to smart folk from all over.

Talking to people at the Jenkins stand was no different.  Though in a striking number of cases, people had already heard of Jenkins, were big fans and took a clutch of stickers back home for their colleagues.

Speaking with those who weren’t yet using Jenkins was equally
interesting. My favourite was talking to one guy who described a
particularly complex workflow; at each step he asked if Jenkins could do it, and I was able to cheerily reply &quot;yes&quot; to every single one.

Getting to put faces to names of Jenkins developers was also a huge plus, and resulted in numerous great conversations.

Domi :

It was great to get some faces to the short names on IRC. Talking to other commiters was awesome, I thought they are cool before I went to FOSDEM, but now I know!

Its was great to talk to people who are using the tools you are working on, there where so many just coming up to say thank you! (?and there where/are by far more then I thought!)
I know I’m standing on the shoulders of a giant - but I also do feel that my commitment is of value for others too.

Feels great to be part of this community!

R Tyler Croy :

I spent so much time at the stand telling people about Jenkins or showing them, that I only ended up seeing a couple actual sessions the whole weekend.
The kinds of people who came to talk to us almost entirely developers of one kind or another, which was really great to talk about how Jenkins can be used effectively for Perl shops, for Python, C++, C#, Java (of course) or even for deployment automation. The spread was a pretty big endorsement, I think, of the extensible nature of the Jenkins plugin ecosystem.
In planning for FOSDEM I had urged Kohsuke to order thousands of stickers for the event, and when all was said and done I think we had given away around 1000 stickers to new Jenkins fans, old Jenkins fans and a few folks in the community who were looking forward to going back to their local JUG to share.

I’m looking forward to making the trip to the bitter cold of Brussels in February again next year.

Fred G :

FOSDEM had lots of interesting talks and was very well organized (from my point of view) and best of all…​ it’s free! Apart from the talks and nice lineup of speakers, it has been a great opportunity to meet people. People I already knew, some in person, some only from IRC, the mailing list, or as a maintainer of a plugin; but also people thatcame up to the Jenkins stand.

From the people that I talked to:

60% knew Jenkins and use it every day (&quot;Yeah, I know Jenkins. The whole company uses it and nothing works without it!&quot;)

35% had heard of it or were very interested (&quot;I know Jenkins, but we bought the Atlassian package and now we have to use Bamboo, Jira and Confluence.&quot; [me mentioning the Jira integration of Jenkins] &quot;Wow, I really have to try that out and convince our team to switch to Jenkins!&quot;.

5% Weirdos and WTF!? ( disgusted&quot;Is this another one of these
projects funded by Red Hat? They fund everything!&quot;)

Meeting Tom Huybrechts without knowing it (at first) was a big
suprise. He has created or contributed to some of the best plugins
(eg. the parameterized-trigger plugin) and I see his name at least
once whenever I browse through core source code. During the impromptu UI enhancement meetings he showed us another three plugins that he wrote but never made public just because he doesn’t have time to support them all.

Then at the stand he casually mentioned that he is administering
around 3000 jobs on 100+ build machines. At the same time he seems
like a very humble and low key character.

To sum it up, the best thing about an open source project like Jenkins is the community. Working together with nice people from all over the world to create the best CI server has been a great experience. The FOSDEM weekend was another event that proved that.
I’ll definitely come back.

Kohsuke Kawaguchi :

FOSDEM is one of the few conferences that has a distinctive hand-made geek-for-geek feeling to it. No marketing people, no bullshit flyers, but lots of technical folks and good beer. I really enjoyed talking to users, as always, but above all I was very happy to see developers and project members in the Jenkins community come out in full force, and I felt they enjoyed it just as much. I’m really hoping that we’ll now keep this going for years to come.

I think it’s safe to assume we’ll be back next year for FOSDEM 2013, hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/02/21/sponsor-a-jenkins-user-conference/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">21</div></div><h5 class="title">Sponsor a Jenkins User Conference!</h5></div><p class="teaser">With the JUC Paris 2012 call for papers open, it’s important to mention that we are also looking for sponsors for the various Jenkins User Conferences that are being planned around the world right now!

Currently there are four conferences being put together right now:

JUC Paris

JUC New York

JUC San Francisco

JUC Antwerp

If your company is heavily invested in Jenkins or interested in reaching the kind of audience that will be at a JUC (highly technical, motivated) then you should consider becoming a sponsor one of these conferences (link below)!

Sponsor the Jenkins User Conference<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/03/06/critical-security-advisory-in-jenkins-core/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 6</div></div><h5 class="title">Critical security advisory in Jenkins core</h5></div><p class="teaser">+
We&#x27;ve identified and fixed a critical security vulnerabilities in +
Jenkins core. This affects all the releases of Jenkins to date (main line releases up to 1.452 and LTS up to 1.424.3.) Please upgrade to the new releases at your earliest convenience, especially if your Jenkins is internet facing. +
 +

For more details about the vulnerabilities, affected versions, and so on, please consult the security advisory.

(See our page about security advisories about how we do these.)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/03/13/why-does-jenkins-have-blue-balls/"><div class="header"><div class="date"><div class="month">March</div><div class="day">13</div></div><h5 class="title">Why does Jenkins have blue balls?</h5></div><p class="teaser">It is interesting having an open source project that is sufficiently old to start generating &quot;lore&quot; of some form or another. Jenkins is starting to get to be that age, having been started over 6 years ago.

One of the most commonly asked questions, is about Jenkins&#x27; use of &quot;blue balls&quot; to indicate success by default. This is enough of an &quot;issue&quot; for some users that the Green Balls plugin is in the list of top 10 installed plugins.

The reason behind our use of blue to indicate success has its basis in Kohsuke’s Japanese upbringing. The cultural differences were enumerated in a bug report comically titled &quot;s/blue/green/g&quot; ( JENKINS-369):

This response Kohsuke cited was taken from this Q&amp;A thread

Q.&quot; Why do Japanese people say that they have blue traffic lights when they are really green?&quot; --Question submitted by John Sypal

A: According to the book, Japan From A to Z: Mysteries of Everyday
Life Explained by James and Michiko Vardaman, the first traffic
signals in Japan were blue instead of green, but the blue lights were difficult to see from a long distance away so they were replaced with green ones. Vardaman says that the custom of referring to traffic lights is a holdover from those days.

This sounds like a good explanation, but the problem with it is that you will hear Japanese people refer to other green things (like
cucumbers, spinach, and sometimes grass) as being blue as well. This
is because historically, Japanese people considered green to be a
shade of blue. For example, the Chinese character for blue,
pronounced ao is made up of two characters, iki (life) and i (well)
and refers to the colour of plants which grow around a well, a colour between green and blue. When Chinese people see the character, they say it means green, but Japanese people say it means blue.

Japanese books on colours tell us that there are four tertiary colours: red, blue, white and black, and that all others are shades of those four main ones. Ao, therefore, is a sort of ideal blue, halfway between green and blue. The sky is said to be blue, but it is a different shade of ao than a traffic light is. Tree leaves are said to be green, but green is a shade of ao, like crimson is a shade of red.

In another interesting cultural difference relating
to colour, Japanese children always colour the sun red instead of
yellow.

( here’s a direct link to Kohsuke’s comment )

Unfortunately it’s not for color blind users, although that’s a pretty convincing explanation. Jenkins has blue balls because in Japan, red means stop and blue means go!

Image courtesy of this site<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/03/26/announcing-the-jenkins-cia/"><div class="header"><div class="date"><div class="month">March</div><div class="day">26</div></div><h5 class="title">Announcing the Jenkins CIA</h5></div><p class="teaser">For years, we’ve been hearing about covert installations of Jenkins by groups
of developers within larger companies. Rogue engineers, frustrated by the lack
of continuous integration would download jenkins.war and run it off their
workstation. As time went on, word-of-mouth within the organization spread
Jenkins far and wide.

Today we announce an initiative to help support these rogue agents: the
Jenkins CIA. CIA being short for Continuous
Integration Ambassador of course.

If you’re going to be speaking at a JUG or another event where you will have
the opportunity to promote and teach people about Jenkins, you too can join the
CIA:

Send us an email telling us about the event and how many people you expect

Write us a guest blog post ahead of time, talking about the event

We dispatch Jenkins stickers and a CIA Agent shirt for you to wear.

Write up a summary blog post about the event afterwards

Repeat!

In the coming months, we’ll start collaborating and creating standard
presentations that can be easily re-used to introduce people not only to
Jenkins, but continuous integration in general, so stay tuned.

If you’re not the speaking type but instead prefer to work behind the scenes,
you can join the OSS by checking out the Beginner’s Guide to contributing
to Jenkins.

Agent Dero, over and out.

This message will self-destruct in 5.

4.

3.

2.

1.

poof .<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/04/13/continuous-information-vol-2/"><div class="header"><div class="date"><div class="month">April</div><div class="day">13</div></div><h5 class="title">Continuous Information vol.2</h5></div><p class="teaser">+
Because I work on Jenkins day in day out, it&#x27;s easy for me to forget that most people don&#x27;t pay /that/ much attention to Jenkins. If you fit that category, and if you want to stay on top of the latest happenings in Jenkins, don’t miss Volume 2 of https://pages.cloudbees.com/index.php/email/emailWebview?mkt_tok=3RkMMJWWfF9wsRow5%2FmYJoDpwmWGd5mht7VzDtPj1OY6hBksIr%2BJK1TtuMFUGpsqOOqSDhcUEZVk0w%3D%3D[Continuous Information, the CloudBees Newsletter for Jenkins]. +
 +

+
This issue... +
 +

Features details about the 6 upcoming Jenkins User Conferences (don’t miss these)

Announces the new Jenkins CIA Program (join us to promote Jenkins around the globe)

Shows you where to find in-depth information about the latest Jenkins UI improvements and featured plugins (cool stuff)

Highlights the importance of Jenkins Security Advisories (install these regularly)

Tells you why Jenkins has blue balls instead of green ones (seriously)

Shows you the latest Jenkins Usage Stats (still growing super-fast)

… and more great stuff, including a bit of Jenkins humor (courtesy of our friends at Geek and Poke)

+
+

+
https://pages.cloudbees.com/index.php/email/emailWebview?mkt_tok=3RkMMJWWfF9wsRow5%2FmYJoDpwmWGd5mht7VzDtPj1OY6hBksIr%2BJK1TtuMFUGpsqOOqSDhcUEZVk0w%3D%3D[View this issue in full] or https://www.cloudbees.com/jenkins-newsletter.cb[sign up to receive future newsletters] directly or to stay on top of the latest Jenkins goodness. +
 +

+
On somewhat unrelated note, https://www.cloudbees.com/forms/jenkins-user-conference-call-papers.cb[call for Papers] for upcoming JUC 2012 is open! Please help us spread the word...<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/05/10/jenkins-user-conference-paris-summary/"><div class="header"><div class="date"><div class="month">May</div><div class="day">10</div></div><h5 class="title">Jenkins User Conference Paris Summary</h5></div><p class="teaser">+
https://www.cloudbees.com/jenkins-user-conference-2012-paris.cb[The first stop of Jenkins User Conference world tour] this year was Paris, where there&#x27;s a considerable concentraion of Jenkins developers and users (sometiems those of us on the other side of the Atlantic call them &quot;the French gang&quot;) The event was held a day before Devoxx France, in the hope that we attract more attendance. +
 +

+
https://photo.kohsuke.org/picture.php?/62/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423115916-5ed0a69e.jpg[image]] +

+
+

+
I believe there are 100+ people that actually showed up, and we had a full day divided in two tracks, talking all things about Jenkins. While many are French, some of the attendees come from all over the Europe. I was able to see some familiar faces, as well as those who I&#x27;ve only known by their names. +
 +

+
I tried to get in and out of both tracks to get the sense of what&#x27;s going on, so that I can report them later, and here&#x27;s my notes. +
 +

+
https://photo.kohsuke.org/picture.php?/75/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423121146-816f0806.jpg[image]] +

+
+

+
I kicked off the whole day with a keynote, looking back what we&#x27;ve done since we became Jenkins. I&#x27;ve looked into various activities in the community, such as LTS, https://wiki.jenkins.io/display/JENKINS/Jenkins+CIA+Program[Jenkins CIA], https://wiki.jenkins.io/display/JENKINS/Jenkins+plugin+development+in+Ruby[Ruby plugin development], and https://wiki.jenkins.io/display/JENKINS/UI+Enhancements[UI enhancements]. I updated my adoption statistics slides (we are happy to report that we crossed https://imod.github.com/jenkins-stats/svg/svgs.html[40K installations] in our tracking), and reported that JFrog is now https://java.dzone.com/announcements/jenkins-ci-and-jfrog-announce[hosting our repositories] that we rely on for the development. I showed some of what we&#x27;ve been lately working on at CloudBees — such as the upcoming version of https://www.cloudbees.com/jenkins-enterprise-by-cloudbees-overview.cb[Jenkins Enterprise by CloudBees] that support high-availability, https://www.cloudbees.com/press-room/cloudbees-donates-five-plugins-jenkins-community.cb[our giving away the folder plugin for free] (as in beer), and previews of some not quite public yet features, which is a treat only for those who came! +
 +

+
https://photo.kohsuke.org/picture.php?/89/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423123054-9f4acaef.jpg[image]] +

+
+

+
In the first slot, https://twitter.com/gboissinot/[Gregory Boissinot] went through a plugin development workshop. This was actually something I really wanted to understand, so that I get the objective view on where the pitfalls are. Even though the talk was in French, I did understand the code he was showing, and I took some notes about having some kind of skeleton code generator — for example, there&#x27;s a common pattern for building an UI bound model object (for asking the user to enter data that has structures, persisting them, and so on), and having a code generator command line tool (like https://github.com/jenkinsci/jenkins.rb[jenkins.rb] has) could be really handy. +
 +

+
https://photo.kohsuke.org/picture.php?/93/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423123825-9ef5019f.jpg[image]] +

+
+

+
In another room, https://twitter.com/ndeloof[Nicolas] and Mathieu were showing their https://wiki.jenkins.io/display/JENKINS/Build+Flow+Plugin[&quot;build flow&quot;] plugin, which lets you write a workflow in Groovy DSL. Choreographing a complex workflow that involves multiple jobs is a commoon challenge among any Jenkins users, and so this talk was well attended, and I&#x27;m really looking forward to seeing this plugin mature (there&#x27;s https://cisco.webex.com/ciscosales/lsr.php?AT=pb&amp;SP=MC&amp;rID=60616172&amp;rKey=7caa63dde29ef758[a separate effort] to integrate BPMN workflow into Jenkins, see more about that here.) One thing I learned about Groovy DSL since then is the AST transformation. I&#x27;m thinking it might allow us to convert the DSL workflow script into a continuation passing style so that you can suspend/resume workflow at arbitrary point. +
 +

+
https://photo.kohsuke.org/picture.php?/106/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423125816-eb3613bb.jpg[image]] +

+
+

+
The day was so packed that we didn&#x27;t even waste the lunch time! While attendees are eating, we had lightening talks in the room. Olivier showed off how Apache runs Jenkins, which is quite sizable, then I pitched in for https://twitter.com/4imod[Domonik], who couldn&#x27;t make it to the conference, and covered the scriptler plugin. Vincent followed and covered the similar Groovy system console. Harpreet then closed off the lunch lightening talks by showing the templates plugin in Jenkins Enterprise by CloudBees. +
 +

+
https://photo.kohsuke.org/picture.php?/111/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423130341-35bbfbae.jpg[image]] +

+
+

+
In the afternoon, https://twitter.com/aheritier[Arnaud], one of our French gangs, showed how you can set up the iOS development on Jenkins (from code change to test to the delivery of the binaries to actual phones.) Bruno then did a demo of how he uses DEV@cloud and RUN@cloud to quickly set up continuous deployment for Java webapps. For system integraters that deal with lots of projects, I think it is a great combination (for example allowing you to hand over the entire development environment to the customer when the project is over.) +
 +

+
https://photo.kohsuke.org/picture.php?/140/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423133439-5a7b4fbe.jpg[image]] +

+
+

+
While all that is going on in one room, in another room Lars Kruse showed off how the old meets the new — where you https://wiki.jenkins.io/display/JENKINS/ClearCase+UCM+Plugin[take ClearCase UCM and use it to do validated merge], in which only the changes tested by Jenkins become visible to the rest of the team. I personally don&#x27;t know much about ClearCase, but it was very interesting that emerging techniques like validated merge can be applied on more traditional SCM tools. He also said his company works with clients to develop custom Jenkins plugins. I always felt that any big company adopting Jenkins need some custom glue plugins, and I regularly come across those companies, but CloudBees can only help so many. It&#x27;s great to see that there are more help available now! +
 +

+
https://photo.kohsuke.org/picture.php?/188/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423164957-bae4f4ad.jpg[image]] +

+

+
The talk that followed was from https://twitter.com/#!/jcarsique[Julien Carsique] from Nuxeo, discussing how he manages and improves the CI environment for his organization. Now, I regret I didn&#x27;t take all the notes about details, but I think this was one of the best presentations of the day for me. I remember thinking that if we had the best Jenkins administrator award for those who push things to the limit and beyond, he would be my top pick. IIRC, he had a major Maven projects that span across different repos and all. He set up Jenkins such that any change triggers a cascade of new builds of downstream jobs, which later then fan out to cross-platform test jobs, then he made the whole thing visualized so you can track exactly where the time is spent and how those changes propagate. I think this was very inspirational to many other fellow Jenkins users, and I hope he will put his slides somewhere so that other people can mimic what he&#x27;s done. +
 +

+
https://photo.kohsuke.org/picture.php?/144/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423134050-8dd4dca8.jpg[image]] +

+

+
Back to the big room, my fellow colleagues https://twitter.com/#!/connolly_s[Stephen] and https://twitter.com/#!/singh_harpreet[Harpreet] did the only introductory talk in the whole day, going through check lists of production Jenkins deployments, recapping why you want CI, etc. (And I always forget that there are still many who don&#x27;t know much about Jenkins!) +
 +

+
https://photo.kohsuke.org/picture.php?/156/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423135955-e072a9a0.jpg[image]] +

+
+

+
It was also great to see and hear https://sebastian-bergmann.de/[Sebastian Bergmann], the guy behind https://jenkins-php.org/[Jenkins PHP], talk about Jenkins and PHP integrations. I wish we had more of those people who bridge our community to different communities and help us spread the ideas. He even kindly gave me his Jenkins/PHP book and signed it for me! +
 +
 +

+
https://photo.kohsuke.org/picture.php?/159/category/2[image:https://photo.kohsuke.org/upload/2012/04/23/thumbnail/TN-20120423140457-1e3a42c8.jpg[image]] +

+

+
Aside from talks, food was great, especially for those of us who came from the U.S. I&#x27;ve got some good inspirations about where we need to work. And I also managed to implement the search filter in the update center during the day, in response to the valid complaint from Sebastian. For virtual communities like ours, it&#x27;s really good to meet people in the meat space and put faces on names. Build automation engineers are often somewhat lonely in their respective organizations — there just aren&#x27;t that many people who get excited about automating things away, and so having so many of like-minded folks in one room was by itself a great experience. +
 +

+
On the things to improve side, I felt that workshops was tricky to do in a limited time and in a big room. Maybe it would work out better if there&#x27;s a smaller room where smaller number of people can gather and hack away (probably some time slots designated for some specific topics), then we can collectively merge pending important pull requests, teaching how to develop plugins, or ask others to look at their plugins, etc. There also can be a valid discussion about JUC, run nicely in exchange of admission fee, vs JUC run cheaply but free. +
 +

+
In any case, I think the quality of presentations were very good, and knowing local Jenkins developers/users would help expand your horizon. As I said in the beginning, we are takin JUC around the world this year. https://www.cloudbees.com/jenkins-user-conference-2012-newyork.cb[The one in New York] is just in the next week, followed by Herzelia (Israel), Tokyo, San Francisco, and Antwerp. Please https://www.cloudbees.com/juc2012.cb[register while seats are still available]! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/05/21/nyc-jenkins-user-conference-recap/"><div class="header"><div class="date"><div class="month">May</div><div class="day">21</div></div><h5 class="title">NYC Jenkins User Conference Recap</h5></div><p class="teaser">Editor’s Note: The following is a write-up courtesy of Jesse Farinacci

This past week I had the pleasure of attending the Jenkins User Conference in NYC. A hundred other like-minded continuous integration enthusiasts and I packed a very posh Marriott Marquis for a full day of Jenkins excitement.

Famed Hudson and Jenkins founder Kohsuke Kawaguchi delivered the opening address to a crowded room.

+
https://3.bp.blogspot.com/-zONIv2yCm1s/T7pLy0yCalI/AAAAAAAAANg/hXadCIg5XC0/s1600/kohsuke.jpg[image:https://3.bp.blogspot.com/-zONIv2yCm1s/T7pLy0yCalI/AAAAAAAAANg/hXadCIg5XC0/s320/kohsuke.jpg[image,width=239,height=320]]

+
I&#x27;m sure everyone knows the statistics by now, that Jenkins adoption and development continues at an unbridled pace. Pushing past all the mailing list users and posts, the JIRAs opening and closing, the Twitter followers, the *five* Jenkins User Conferences scheduled for this year, the unprecedented number of installations reporting anonymous usage, the native availability for *nine* different OSes, in pushing past all of that.. +
 +
For me, the most impressive number was that on average there was about 1 plugin created every day over the past year. Let me reiterate that: *1 plugin created every day for a year*. If that isn&#x27;t the best testament to the versatility, extensibility, and just plain usefulness of a piece of software, then I don&#x27;t know what would be! +
 +
Announced at the conference was the general availability of https://buildhive.cloudbees.com/[CloudBees BuildHive], this is a mechanism for quickly and easily obtaining access to cloud-based Jenkins. If you have projects on https://github.com/[GitHub], you can effortlessly log in to BuildHive via GitHub OAuth, import your projects with literally a single click, and start benefiting from the powerful promise of the cloud. You&#x27;ll no longer have to worry about managing infrastructure, you&#x27;ll just get all that great Jenkins CI capability for your projects immediately. +
 +
 +
 +
With BuildHive enabled projects, if a user of your project creates a pull request, then it will automatically pre-test that request before it hits the master tree -- https://github.com/jenkinsci/naginator-plugin/pull/2#issuecomment-5732481[commenting inside the pull request] whether or not the change broke the build. If a developer wants to test some changes before pushing them to the master tree, there&#x27;s the https://www.cloudbees.com/jenkins-enterprise-by-cloudbees-features-validated-merge-plugin.cb[Validated Merge feature], which can be used to screen commits before they land in master. Both of these features are wickedly awesome, to not use them would be a mistake for any F/OSS community. +
 +
I would encourage you to try out BuildHive, it&#x27;s already active for most/all of the Jenkins plugins. There&#x27;s also an existing https://groups.google.com/d/topic/jenkinsci-dev/kqPAOziY1as/discussion[RFC thread] which is in discussion for making this the de facto location for Jenkins plugin on Jenkins testing. Please give it a shot and then post your comments. +
 +
Aside from this major announcement, I think the most interesting perspective I took away from the conference was the sheer diversity of Jenkins exploitation. People are using it on all sorts of hardware platforms, from mobile to cloud, on all sorts of languages from Java and C/C++ to Python and Ruby. I was also impressed with how many teams are using Jenkins as part of their mission critical business process. +
 +
Finally, I&#x27;d like to thank all the Jenkins developers and users for making it the best continuous integration software available today. Keep up the good work!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/05/28/jenkins-a-besoin-de-vous/"><div class="header"><div class="date"><div class="month">May</div><div class="day">28</div></div><h5 class="title">Jenkins a besoin de vous</h5></div><p class="teaser">[ Editor’s Note : The following is a guest post by Jenkins contributor Baptiste Mathus. For the non-French speakers, we’re looking for French speakers to help translate &quot;Jenkins: The Definitive Guide&quot; ]

Si vous vous intéressez à Jenkins et que vous aimeriez pouvoir y contribuer, lisez la suite.

L’année dernière, en août, nous avons attaqué la traduction en français du Jenkins Definitive Guide, écrit en bonne partie par John Ferguson Smart. Le travail a avancé doucement, mais a avancé tout de même. A ce jour, sur la quinzaine de
chapitres, trois sont traduits et relus, et presque tout le reste est en cours.

Mais je ne parle pas bien anglais…​

Ce n’est pas grave. Il y a plusieurs chapitres où il faut simplement relire, et donc parler et écrire correctement le français est suffisant. Si éventuellement, vous ne comprenez pas certaines parties traduites, et qu’il faut relire l’original, vous pouvez toujours soulever la question sur la liste de diffusion du projet où on parle français.

Je ne suis pas développeur, ou je ne connais pas Git, ou les deux

Si vous voulez vous former à Git, c’est l’occasion. On se fera un plaisir de répondre à vos questions sur la liste de diffusion, même si elles sont exclusivement liées à Git, et pas (encore) à la traduction :-).

Mais si vous ne le sentez pas ou n’avez pas le temps, ce n’est pas grave. Vous devez simplement savoir éditer un fichier XML. Il y en a un pour chaque chapitre.

Super ! Par où je commence alors ?

Comment se signaler :

Il y a une page wiki qui récapitule l’état de la traduction, chapitre par chapitre. Indiquez votre nom en tant que relecteur, et c’est parti.

Si vous le souhaitez, mais ce n’est pas une obligation, vous pouvez vous présenter sur la liste de diffusion du projet.

Comment relire les chapitres ?

Le plus simple est de lire la version HTML publiée en continu grâce à CloudBees.

Comment faire part de mes corrections ? Deux solutions :

Git : vous forkez le projet GitHub : Jenkins - Le Guide Complet, vous créez une branche pour la relecture, vous committez vos vos corrections, et vous faites une pull-request.

Copiez le fichier XML du chapitre qui vous intéresse à partir de la page du projet puis vous l’envoyez sur la liste de diffusion lorsque vous avez fini.

Si vous êtes intéressé, mais que vous avez des questions, surtout n’hésitez pas à les poser.

On vous attend ! :-)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/06/19/jenkins-and-bioinformatics-catch-us-at-bosc-2012/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">19</div></div><h5 class="title">Jenkins and Bioinformatics, catch us at BOSC 2012</h5></div><p class="teaser">[ Editor’s Note: The following is a post from Jenkins CIA member Bruno P. Kinoshita ]

Jenkins will be represented at this years Bioinformatics Open Source Conference ( BOSC 2012) on July 13-14th in Long Beach, California. I will be talking about Jenkins during my talk about BioUno.

BOSC 2012 will be held just before ISMB 2012, while registration is through ISMB you don’t have to register for ISMB in order to register for BOSC.

I will be at the event with some Jenkins stickers and available to answer questions you might have about BioUno and Jenkins!

About BioUno

BioUno is a project that uses Jenkins as basis for building
biology workflows.
BioUno provides an alternative update center with custom plug-ins for
bioinformatics tools like
MrBayes,
Structure,
Figtree,
Beast,
among others.

While the actual task of analysing or displaying data is handled by specific
tools, that are wrapped by plug-ins, Jenkins is responsible for user control,
web interface, notifications, distributed execution, job schedule and
management, as well as other important low level tasks.

BioUno is similar to BioHPC,
Galaxy and
Taverna, in that all these tools enable creating and managing pipelines using different bioinformatics tools.

However, as it is using Jenkins, BioUno has the advantage of having an Open Source community of hackers that can answer questions and provide assistance for creating new plug-ins. There is plenty documentation for extending Jenkins
and troubleshooting issues, as well as plenty existing plug-ins (that can be used as reference while writing new plug-ins).

There are projects and plug-ins that enable Jenkins to use resources in clouds or turn Jenkins into a Hadoop node, for big data processing. The next steps of the project include the deployment of BioUno to a computer facility, basic infrastructure for BioUno, definition of the process for releasing plug-ins, the creation of more plug-ins and a study on how to handle large data structures, used by many bioinformatics tools.

The project is being developed by TupiLabs under MIT License, and contributions and new plug-ins are welcome.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/06/22/intro-to-jenkins-meetup-in-copenhagen/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">22</div></div><h5 class="title">Intro to Jenkins meetup in Copenhagen</h5></div><p class="teaser">[ Editor’s Note : This was originally posted to the jenkinsci-users mailing list by community member Bue Petersen ]

Praqma inviterer til Gå-Hjem-Møde i Allerød, onsdag d 27. juni kl 17:00. Få en introduktion og demo af Jenkins CI server (Open Source). Vi byder på pizza og en kold øl eller vand. Arrangement er gratis, tilmelding er nødvendig.

Continuous Integration — er et princip der dikterer, at alle ændringer skal integreres, i det øjeblik de er skabt — kontinuerligt og automatisk. Continous Software Validation går skridtet videre - alle ændringer skal valideres, i det øjeblik de er skabt.

Jenkins Continuous Integration Server hurtigt blevet de facto standard for Continuous Integration. Og den er hjørnestenen i build- og softwarevaliderings-systemet og bindeledet mellem samtlige tools i hele den tool-chain, man ønsker at indføre eller udbygge.

På Jenkins konfigureres jobs, som udover at bygge og eksekvere unittests også kan tage ansvar for valideringer som statisk kodeanalyse, rapportering af warnings, coverage-målinger af unittests, automatisk generering af dokumentation, eksekvering af funktionelle tests etc.

Vi holder et uformelt gå-hjem-møde med pizza, øl og sodavand, hvor vi præsenterer Jenkins Continuous Integration og viser dig, hvordan du nemt kommer i gang, så du allerede dagen efter kan høste synlige fordele på dine projekter.

Du kan få helt ny viden og indsigt i din kodebase, og du kan skabe grundlag for ændring af arbejdsgange i udviklingen.

Onsdag 27. juni 2012  kl. 17.00 - 18.30

Praqma A/S

Allerød Stationsvej 4

3450 Allerød

Denmark

Tilmelding<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/07/23/jenkins-user-conference-israel/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">23</div></div><h5 class="title">Jenkins User Conference Israel</h5></div><p class="teaser">+
I&#x27;m back from the latest Jenkins User Conference in Israel, and I had such a fun (except the part where I strained my lower back on the day I head back to home so 10+5 hour flights were a torture.) I have this impression that Israeli people form a close-knit community on their own (somewhat like Japanese people do), perhaps because of the difference in the language or the culture. One of the great things about those communities are that people are well connected, and so reaching the right ears and spreading the ideas are easier. JUC Israel turns out to be the biggets JUC we had this year. Shlomi told me that some 230 people registered and 240 people showed up, and this negative last-minute cancellation ratio is unheard of! We had booths from sponsors, 2 concurrent tracks of technical talks, and wonderful Israeli food, in a nice hotel by the beach. +
 +

+
https://photo.kohsuke.org/picture.php?/296/category/5/created-monthly-list-2012-7[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712090747-e447b7c7.jpg[image] +
] +

+
+

+
For me, the conference started the night before, when JFrog folks took us to the Hudson restaurant, which was a wonderful steak house. Needless to say I took a lot of pictures. Hudson was great, and I got a wet-wipe in the end to wipe my hands off with Hudson. +
 +

+
https://photo.kohsuke.org/picture.php?/324/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712091422-d48662cb.jpg[image] +
] +

+
+
+

+
As for the hightlights from the sessions. +
 +

+
https://photo.kohsuke.org/picture.php?/363/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712092442-6b807f97.jpg[image] +
]

+
+

+
After I and Shlomi have done the keynote, Amir from HP did a wonderful job showing off how he uses the multi-configuration project type (AKA &quot;matrix project&quot;.) This is one of the areas where we made a lot of improvements lately, and one that I highlighted in my talk. I&#x27;ve always been feeling that this feature needs to be advertised more, so it was just perfect in that regard. It was also very useful for me personally, as I got some inspirations about improvements while he talks. +
 +

+
https://photo.kohsuke.org/picture.php?/384/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712093014-62a9271b.jpg[image] +
]

+
+

+
Sacha then talked about why the future of server-side applications are in PaaS. He had this one point where he said increasing the failure rate of software projects isn&#x27;t necessarily a bad thing — if in a time frame of a year, you can do 10 projects and 2 succeed, then while that&#x27;s only 20% success rate, it&#x27;s better than doing 4 projects in the same time and having only 1 succeed. IOW, a machine-gun does a far more damage than a pistol, even though their accuracy can be much lower. And PaaS/Continuous-delivery plays a central role here becauses those are what lets you deliver 10 features in a year, instead of 4. +
 +

+
https://photo.kohsuke.org/picture.php?/397/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712093400-c7816855.jpg[image] +
]

+
+

+
Eyal from RedHat and Ronen from Ginger did two sessions showing off their use of Jenkins. One of the common theme in them is to use a text format (Puppet for Eyal and Groovy DSL for Ronen) to manage definitions of a large number of jobs. I think there&#x27;s a lot of value in managing job definitions outside the current GUI, and I&#x27;m going to encourage Ronen to move his Groovy DSL project into the Jenkins CI project. I also felt that the template feature in Jenkins Enterprise by CloudBees was validated, as it provides a similar capability (and in my opinion more easily deployable.) +
 +

+
https://photo.kohsuke.org/picture.php?/391/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712093221-0c896346.jpg[image] +
]

+
+

+
Another talk that made a strong impression on me was the introductory plugin development talk from Noam, who works for JFrog and develops the Jenkins Artifactory plugin. I expected there to be only like 20-30 people, but it turns out about half the audience is there, indicating the high degree of interest to customizing Jenkins! In the past, all my favorite JUC talks came from those who I call &quot;super Jenkins admins&quot; who not only figure out how to combine some plugins, but also developed a few glue plugins. And those those extra finish makes all the difference! +
 +

+
https://photo.kohsuke.org/picture.php?/411/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712093759-5aec89e0.jpg[image] +
]

+
+

+
The conference concluded with a social in the garden looking a sunset into the Mediterranean sea. Thank you very much for JFrog and CloudBees for making this event happen, and Marina in particular for lining up all the ducks in a row. +
 +

+
https://photo.kohsuke.org/picture.php?/428/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712094258-6527b7cd.jpg[image] +
] +
 +
https://photo.kohsuke.org/picture.php?/434/category/5[ +
image:https://photo.kohsuke.org/upload/2012/07/12/20120712094422-b45159bc.jpg[image] +
] +

+
+

+
The next JUC will be in Tokyo, at the end of this month. Believe it or not, as of this writing we got 930 people registered, so it&#x27;ll be another awesome show! For future schedules of Jenkins User Conferences and registrations, check out https://www.cloudbees.com/juc2012.cb[the JUC website]! +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/07/26/jenkins-user-conference-san-francisco-call-for-papers/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">26</div></div><h5 class="title">Jenkins User Conference San Francisco: call for papers</h5></div><p class="teaser">+
link:/node/tags/juc[Jenkins User Conference] is touring around the world and coming back to San Francisco for this September, colocated with JavaOne. +
 +

+
And here is https://www.cloudbees.com/forms/jenkins-user-conference-call-papers.cb[the call for papers] — we&#x27;d love users and plugin developers to share their experience with others. Please tell us how you combine plugins in an interesting way, how some of the features in Jenkins did or did not work for you, tricks you use to effectively manage Jenkins instances, and so on. +
 +

+
I personally know many bay area tech companies that depend heavily on Jenkins. Really looking forward to hearing from you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/08/20/report-intro-to-jenkins-meet-up-in-copenhagen/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">20</div></div><h5 class="title">Report: Intro to Jenkins meet-up in Copenhagen</h5></div><p class="teaser">We have hosted two informal meetups introducing Jenkins Continuous Integration Server.

The first in end of June (announced here on this blog) and the second on the 7th of August. The first meet-up in June was only announced 8 days before, but had very good attendance  - the second was completely booked (15 seats).

The agenda is a short presentation of continuous integration and software validation to inspire the use of Jenkins, then a few words and terms about Jenkins and finally a live demo.
The live demo starts from scratch by downloaded the latest Jenkins java web archive, starts it, define a job on one of our Maven based java projects on Github. We add two easy plugins (Warnings and Task Scanner). Second part of the demo is about unit testing and coverage and we show how easy it is to enable a JUnit report and add a Cobertura coverage report if there is already unit tests for the project.

The meetups have about 90 minutes scheduled, including questions and the discussion session after the demo, where we serve pizza, beer and cola. The theoretical presentation and live demo is typically finished within one hour, even though we encourage our guests to ask questions and discuss whatever comes into their mind on the way. The relatively short time used for the introduction demonstrates how easy it is to get started with continuous integration and software validation using Jenkins.

As the live demo is based on a Java/Maven project we ask the guests about their technologies and try to relate that to their setup, so they know there also is an easy approach for them to use Jenkins.

The meeting is quite informal, and limited to 15 participants, leaving plenty of time to dicsuss and answer questions both before and after the meeting. We are always a few developers from Praqma to facilitate the discussions about the participants individual setup and questions.

These informal discussions are one of the main gains for us in Praqma, as it  is very interesting to share our experience with our guests and hear about all of their interesting challenges, that might have brough them north of Copenhagento attend our meeting.

Because these first meet-ups have been so popular and interesting we have decided to arrange them regularly in the future. Not just the Jenkins introduction, which will be repeated as long as there is an interest, but we are also making plans for meetups about Git, Mercurial and other topics.

If you’re interested in more Jenkins and CI related meet-ups in the Copenhagen area, visit our homepage or follow the #pragma hashtag on Twitter.

We also have a Jenkins User Event in Copenhagen coming in September.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/08/27/volunteers-needed-for-juc-sf/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">27</div></div><h5 class="title">Volunteers needed for JUC SF</h5></div><p class="teaser">Recently, Jenkins User Conference organizer Alyssa Tong sent out the following request:

Jenkins User Conf SF is looking for volunteers to help us record the
sessions. Pls drop me an email if you’re able to help.

We’re trying to make sure we can capture video of as much of this year’s conference as possible, but the only way we can do that is with your help!

If you’ll be in town for JavaOne, or just live in the bay area, drop Alyssa an email at atong@cloudbees.com.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/11/come-join-the-jenkins-user-conference-san-francisco-on-september-30th/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">11</div></div><h5 class="title">Come join the Jenkins User Conference San Francisco on September 30th!</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Golden_Gate_Bridge[image:https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/GoldenGateBridge-001.jpg/250px-GoldenGateBridge-001.jpg[image]] +

+
+

+
https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco.cb[Jenkins User Conference] is back to San Francisco after a world tour. The conference is on the 30th of this month (Sunday), which makes it back to back with JavaOne, just like the last year. This schedule allows the community people from all over the world to attend and talk, so you see speakers from https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco-abstracts.cb#JevgeniKabanov[different part] of https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco-abstracts.cb#BaruchSadogursky[the world]! +
 +

+
You can see https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco.cb[the agenda and the speaker list here], there&#x27;s a number of speakers from the big/serious users of Jenkins in the bay area, such as https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco-abstracts.cb#JustinRyan[NetFlix], and https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco-abstracts.cb#MaxSpring[Cisco], and https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco-abstracts.cb#JamesBlair[HP]. All of these guys not only just use Jenkins but wrote additional plugins/programs to really tailor Jenkins into fitting their needs, and I think those would be really informative for those who are already using Jenkins, as well as those who are thinking about using Jenkins. +
 +

+
This time we also have a couple of talks that discuss how to develop plugins. In JUC Israel, I was pleasantly surprised that a talk on this topic attracted a lot of people! If you are interested in writing a plugin, this would be a great chance to get started. +
 +

+
We are also trying to bring https://wiki.jenkins.io/display/JENKINS/Governance+Meeting+Agenda[the Jenkins project meeting], which normally happens in IRC, into the real world in this conference. We are hoping that this would allow those who don&#x27;t normally come to the meeting to voice their thoughts. If you are interested, feel free to add stuff to the agenda list! +
 +

+
And oh, did you check out who&#x27;s on the sponsors list this year? +
 +

+
I hope I convinced you that you must come to this conference — if so, https://juc-san-francisco-september-2012-eorg.eventbrite.com/[please register]. I&#x27;ve been told that right now you can use the promotion code `+JUC-2012SF+` to cut the price in half, so please use it while it still works! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/12/jenkins-user-event-cph/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">12</div></div><h5 class="title">Jenkins User Event CPH</h5></div><p class="teaser">This article was originally posted on my personal blog

+
https://4.bp.blogspot.com/-U254sLok_CA/UEyaAzMGpYI/AAAAAAAAHuI/--wuCdF0j2Y/s1600/IMAG0397.jpg[image:https://4.bp.blogspot.com/-U254sLok_CA/UEyaAzMGpYI/AAAAAAAAHuI/--wuCdF0j2Y/s640/IMAG0397.jpg[image,width=640,height=102]]

+
 +
 +
Last week, https://www.praqma.com/[praqma] was organizing in Copenhague a &quot;Jenkins User Event&quot;. A User Event, compared to JenkinsConf, is a lighter meeting with (suposed to be) reduced costs organized by volunteers. Praqma got sponsorship from both https://www.cloudbees.com/[CloudBees] and https://www.programmingresearch.com/[Programing Research] so that they can book a high quality conference room and prepare a nice meeting with all commodities. +
 +
 +
 +

+
https://3.bp.blogspot.com/-v4CkSM9Sdog/UEyXZlXwSFI/AAAAAAAAHt4/D8g72T1meas/s1600/IMAG0388.jpg[image:https://3.bp.blogspot.com/-v4CkSM9Sdog/UEyXZlXwSFI/AAAAAAAAHt4/D8g72T1meas/s320/IMAG0388.jpg[image,width=240,height=320]]

+
That was my first travel to Danemark. I enjoyed the winds-farm on northern sea as well as the duty-free lego shop at airport, but didn&#x27;t have much time to discover the city - so will have to come back next year ;) +
 +

+
https://3.bp.blogspot.com/-GrC_1TF4XMY/UEyXRU5U7rI/AAAAAAAAHtw/nB_jKjSbiFE/s1600/IMAG0412.jpg[image:https://3.bp.blogspot.com/-GrC_1TF4XMY/UEyXRU5U7rI/AAAAAAAAHtw/nB_jKjSbiFE/s320/IMAG0412.jpg[image,width=320,height=130]]

+
+
+
+
+

+
https://www.praqma.com/sites/default/files/img/codecamp.jpg[image:https://www.praqma.com/sites/default/files/img/codecamp.jpg[image,width=320,height=139]]

+
Thursday was about a https://www.praqma.com/jcicodecamp12[Jenkins Code Camp] (aka &quot;hackathon&quot;), that I joined late at 2pm due to flight being delayed. 20 geeks were talking about some technical issues, new features, implementation strategies for a large set of topics. I contribute a group to solve an integration issue by https://github.com/jenkinsci/jenkins/pull/558[creating a new extension] point in jenkins-core. Those already confident with jenkins development helped to write this code, some discovered the extension point design as well as way to contribute to jenkins (github pull request, etc), some were looking at jenkins source code for first time so learned a lot. +
 +
 +
 +

+
https://3.bp.blogspot.com/-8aFBYs3PV2I/UEyZp3x53sI/AAAAAAAAHuA/T0_1zOKFVn8/s1600/IMAG0391.jpg[image:https://3.bp.blogspot.com/-8aFBYs3PV2I/UEyZp3x53sI/AAAAAAAAHuA/T0_1zOKFVn8/s640/IMAG0391.jpg[image,width=640,height=292]]

+
 +
 +
 +
 +
Day ended with beer then a chinese restaurant (typical Danish food :P), with lots of fun and nice discussions. +
 +
 +
 +

+
https://www.praqma.com/sites/default/files/img/event_logo.png[image:https://www.praqma.com/sites/default/files/img/event_logo.png[image,width=320,height=138]]

+

+
+

+

+

+

+
Friday was the Jenkins User Event. To reduce costs for such an event, compared to other Jenkins Conferences organized by CloudBees this year, lunch was not provided and conference program was &quot;packed&quot; into afternoon. This let praqma get a &quot;reasonable&quot; cost for this nice event, but still have a high quality conference, with printed programs, goodies, and coffee break. All praqma team was involved to make this event as pleasant as possible for all attendees, thanks a lot to them for contributing ! +
 +
 +
 +
Conference was sold-out on friday morning, with 80 attendees. +
 +
 +
 +
After Lars Kruse welcome speak, and CloudBees to announce partnership with Praqma for DK, the conference started with two options : either an introduction to Jenkins, or an open-space discussion (~barcamp-like) for those that already know it well. I joined a small group first discussing about pre-tested commit, and then we divert speaking about best-practices, job and test performances issues, etc. Was a great exchange with interesting feedback. +
 +
 +
 +
The rest of the conference was single-track. +
 +
 +
 +

+
https://3.bp.blogspot.com/-oCA1lQnDBeE/UEybtag0JmI/AAAAAAAAHuY/QSofsZ_ae1M/s1600/IMAG0408.jpg[image:https://3.bp.blogspot.com/-oCA1lQnDBeE/UEybtag0JmI/AAAAAAAAHuY/QSofsZ_ae1M/s400/IMAG0408.jpg[image,width=400,height=300]]

+
 +
 +
1rst session was about &quot;_facilitate strategic reuse of software_&quot; using jenkins CI. This session exposed how a industrial company changed it&#x27;s internal software development practices and team organization to share components and be more efficient. This for sure introduced some coordinations and integration costs but resulted in a significant productivity improvement. This talk was interesting as it demonstrate that highly industrial companies (here, a low energy consuming water pumps producer) today follow development practice to share component and use continuous integration practice to help. I just wondered speaker said &quot;Clearcase facilitated&quot; sharing components  -I wouldn&#x27;t expected those two words in same sentence :P +
 +
 +
 +
&quot;_Tales from the trenches_&quot; was a funny session explaining how Nokia came from stone age (manual integration with code freezes) to modern development practices. After reinventing the wheel with ~15 home made, perl-script based CI tools, they switched to Jenkins and Git as common tooling. Explanation on Git selection, evaluating multiple DVCS popularity, then migration from ClearCase, [.underline]#helping a lot# early adopters, and later evaluating benefits (1 day / week / developer) was very interesting. Conclusion was that, &quot;some tools a radically better&quot; and &quot;deep process renewal depends heavily on tools renewal&quot;. +
 +
 +
 +
&quot;_Continuous Code Inspection_&quot; talk explained use of industrial C++ coding standard and normative coding convention, with dedicated analysis tools. After explanation on those rules and tooling, a dedicated jenkins plugin was demonstrated. Such jenkins integration makes QA mostly a single checkbox to enable, and provide history graphs, reports, and external tools integration. Introduction was a little slow imho but content was demonstrating the power of jenkins plugin model to adapt software factory to specific industrial needs. +
 +
 +
 +

+
https://4.bp.blogspot.com/-Vgq2K5JLj30/UEyfE86usmI/AAAAAAAAHuw/q4vbgqguyuY/s1600/IMAG0409.jpg[image:https://4.bp.blogspot.com/-Vgq2K5JLj30/UEyfE86usmI/AAAAAAAAHuw/q4vbgqguyuY/s320/IMAG0409.jpg[image,width=320,height=240]]

+
 +
 +
Coffee break with delicious Danish chocolates ... +
 +
 +
 +
Sony was presenting its &quot;_Huge Jenkins Cluster_&quot;, with 4 controllers, some of them handling up to 6000 jobs, 300 agents, 7000 builds a day an executing 175,000 tests a day for android platforms. Development teams use a dedicated agent machine with android devices connected through USB. +
 +
 +
 +
Such a build farm requires a dedicated support team and monitoring/maintenance tooling. IT only provides the computer and maintain the OS, but all Jenkins stuff is under the hands of a dedicated team. They evaluate plugins and core upgrades, educate teams, and analyse errors. +
 +
 +
 +
With 45Gb for a single full android build, they have to monitor available disk space, and developed maintenance scripts to delete old build artifacts and cleanup /tmp. They also use a local git mirror to speed-up cloning, and integrated with CFEngine-managed infrastructure to ensure no update occurs as a agent is running a build. They also significantly optimized build speed by switching from NFS to SAN, and are now evaluating XFS. +
 +
 +
 +
Remaining issue is about jenkins build queue (subject discussed on Jenkins Code Camp) because a 9 in the morning, thousand users connect to jenkins controller and the UI widget to expose the queue status hits the queue synchronisation bottleneck. +
 +
 +
 +
 +
 +
Next talk was mine, exposing https://www.cloudbees.com/jenkins-enterprise-by-cloudbees-overview.cb[Jenkins Enterprise] and demonstrating one ouf our Enterprise plugins. I&#x27;m not pleased by my talk, both because my english is crappy (maybe you already noticed?) and also because I was not confident with the standard JE slides. Assuming I had more time to prepare this talk, and as a tribute to this Danish event, I&#x27;d have used a bunch of lego bricks pictures to present Cloudbee plugins. So I quickly left the slides to run a demo, setting-up Jenkins Enterprise to run https://www.cloudbees.com/jenkins-enterprise-by-cloudbees-features-validated-merge-plugin.cb[pre-tested commits]. Hope you enjoyed the talk. +
 +
 +
 +
https://4.bp.blogspot.com/-mnHy9gx9uGw/UEyixY_2Q0I/AAAAAAAAHvI/_KDQbGOTjw8/s1600/IMAG0407.jpg[image:https://4.bp.blogspot.com/-mnHy9gx9uGw/UEyixY_2Q0I/AAAAAAAAHvI/_KDQbGOTjw8/s320/IMAG0407.jpg[image,width=240,height=320]]Last talk was Lars one, exposing praqma &quot;_Corporate approach to opensource_&quot;. This light, generalist talk was welcome as last one after a heavy-technical afternoon. Lars exposed reason to switch to open-source : +
 +
 +
 +

costs - for sure,

but also open standards and interoperability,

and contribution to public good.

+
This last point distinguish &quot;_innovators_&quot; that create new content and contribute to the oss project, and &quot;_free riders_&quot; that only want to save money and consume other efforts. Lars didn&#x27;t went deeper into what &quot;contributing&quot; can be about, but spending some time joining the mailing lists, exposing detailled bug report, or writing blogs or documentation about the issues you encounter is already a huge contribution to opensource. Organizing such a great user event also is ;) +
 +
 +
 +
 +
 +
 +
 +
Meeting ended with a &quot;socialize&quot; time, sponsored by Pragmatic Research, with beer and sandwiches. A nice time to discuss with speakers, know a face to match an #irc nickname, discuss about everything geeks like to discuss about, and round off this pleasant day. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ndeloof/">Nicolas De Loof</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/21/start-your-own-jenkins-meetup-in-10-easy-steps/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">21</div></div><h5 class="title">Start Your Own Jenkins Meetup in 10 Easy Steps</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/IMAG0786.jpg[image,width=200] +

+
+

+
... and be a https://wiki.jenkins.io/display/JENKINS/Jenkins+CIA+Program[Jenkins CIA agent] too! If you&#x27;re interested in building an active local Jenkins community, read on to learn how. Really, we can sum it up in one simple step: +
 +

Just Do It!

+
+

+
Admittedly more detailed guidelines can be useful, so hopefully these steps will give you a roadmap and some ideas: +
 +

+
Find an organizer or two. This is probably you. If you can draft a friend, colleague, or random acquaintance or three to help, even better. To enlist additional help in your area, put the word out on the Jenkins Dev email list and on your Twitter account using the hashtag #JenkinsCI.

+
Let the Jenkins project know. Let us know so that we can help you. We can promote it on the JenkinsCI blog, promote that on Twitter, and post a summary blog. We can send stickers for you to hand out in the meetup, and we can send you a T-shirt for you to wear. We might be even able to find you additional agents I mean helpers in your city. And if you’re recording the event or streaming it live (we can tell you how), the whole Jenkins world may want to know!

+
Decide how often you want to meet. Once a month is a good frequency, but if you feel like all you can manage is every two months or even every quarter, go for it! You can always change it.

+
Go to Meetup.com. We have an account that we can let you use, or you can create your own meetup. They make it very easy to manage attendance and also to spread the word to people with similar interests in your community.

+
Determine the topic for your first meetup. You could feature a speaker or two, or host a panel discussion, or just get folks together to talk about how you use Jenkins. YOU would probably be a great speaker for your first meetup – or perhaps some of your colleagues or friends. If you prefer to stay behind the scenes, Twitter and the Jenkins Dev list can help you find a speaker too. And as your meetup grows, you’ll have an automatic pool of interested parties.

+
Come up with a format for the meetup. Here’s an idea for a schedule:
6-6:30pm: Check in, Networking &amp; Munchies
6:30-6:35: Announcements
6:35-7:15: Speaker/panel (can also have 2 speakers, which might go longer)
7:15-7:30: Q&amp;A
7:30: Wrap up, chat
8:00: Say goodnight, or go out together and keep drinking

+
Find a venue, preferably a free one. Ideally, your company or one you know can host… then the venue is free. Alternate solutions: hotels (which unfortunately cost $$$) or reserve a room at a local bar or restaurant. Sometimes a university or even a library can help out with a free room.

+
Ask a company or two to sponsor the meetup, which consists of paying for food and drinks for all (and some companies will bring along SWAG). Often the company hosting the venue will also sponsor. Sponsoring is a great way for companies to generate positive publicity in their locale, to get the word out that they’re hiring, and to support the Jenkins community in general.

+
Plan the room logistics. Consider how you want the room to be set up – theater style or as individual tables to encourage group discussions. Also make arrangements to secure a projector and screen. It’s a good idea to bring along connectors for both Mac and PC.

+
Get the word out in any way you can. Some ideas:

Tell us so that we can promote it through our existing channels.

If you use Meetup.com, they’ll help get the word out. And as more people join to attend one meetup, they’ll receive word about future meetups too. EventBrite is also good about suggesting events in your area that might interest you.

Email folks at your company who might be interested

Email friends and former colleagues and ask them to spread the word

Post the event to your Twitter, Facebook, and/or LinkedIn profiles

If you know of any calendars that highlight local Tech events in your area, post your meetup there. Likewise for any Tech email digests you may receive.

+

+
 +
Additional tips: +

Get someone to record the event. Doesn’t have to be professional quality – a Flip cam or SmartPhone can take perfectly usable video (just make sure they can record long enough!). Better yet, stream it live if you can! Broadcasting makes the event accessible to the world, not just your community, and word will travel even farther! As well, future speakers can get an idea for how your group does things.

Plan that ~50% of the people who RSVP won’t make it. It’s a free event, and plans tend to change. Order food and drink accordingly.

Remember that free food and BEvERages are strong motivators! Pizza, giant subs, or other local favorite are great choices. For BEvERages, you’re probably fine with beer, Coke and water.

Bring a sign-in sheet and name tags (and pens).

Consider asking the sponsor to bring SWAG or raffle off something cool (maybe even their product or service).

At the beginning or end of the meetup, ask attendees to suggest topics they want to cover in future meetups. Or have them write down suggestions and put them in a box (then maybe raffle off a prize from the pool of contributors).

Vary the format of your meetup – presentation, Birds of a Feather discussion, hackathon, lightning talks, white board night, Jenkins problem-solving session… all of these may interest your audience. If you can, switch the venue as well – that way people get to see other interesting companies, and can also choose to attend meetups that may be more convenient to them.

Start and end on time. If things start to run over, you can always break and let people know they can go if they need to, but are welcome to stay if they like.

Join forces with other groups when you can – this builds up both of your groups! For example, host a joint Jenkins-Selenium group on the topic of Testing with Jenkins.

+
 +
Still have questions? https://twitter.com/jenkinsci[Give us a holler]! +
 +
 +
**Special thanks to our friends at https://www.saucelabs.com[Sauce Labs] for some of this content — they wrote https://sauceio.com/index.php/2011/10/so-you-want-to-start-a-selenium-meetup-group-now-what/[a similar guide] for starting Selenium meetups.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/24/jenkins-project-meeting-in-the-meat-space-call-for-agenda/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">24</div></div><h5 class="title">Jenkins project meeting in the meat space / Call for agenda</h5></div><p class="teaser">As you may or may not know, the Jenkins project has a bi-weekly IRC meeting where we discuss and decide on things necessary to keep the project running.

Next Sunday, we’ll bring this project meeting live to Jenkins User Conference San Francisco.

Since this is an unique opportunity to engage people who don’t normally come to these meetings, I’d like to encourage everyone to propose agenda items and add it to the agenda page.

The Wiki page lists all the past meetings, so you can get a sense of what it is like. But this time, we hope to have a good number of users to the meeting, not just project insiders. So if you have things you’d like to get users feedback on, or if you like project insiders to update you on things, please don’t hesitate to add them.

I still need to work on the logistics, but the plan is to do a cross-over with IRC — I’d like to show the IRC client projected in the room, so that people in the room can see the conversation in IRC, and I’d like either real-time transcribing of voice conversations to IRC and/or live broadcasting of the room.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/26/dinner-after-juc/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">26</div></div><h5 class="title">Dinner after JUC</h5></div><p class="teaser">+ +

+

+
https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco.cb[Jenkins User Conference 2012 San Francisco] is this weekend! +
 +

+
Based on the experience from the last year, we are going to make a reservation for a dinner after JUC. If you are interested in joining us, https://www.meetup.com/jenkinsmeetup/events/84235932/[please RSVP]. We haven&#x27;t decided where to go, but we&#x27;ll place a reservation somewhere (and if you know a good place to go, please tell us, too!), so that we won&#x27;t have to spend 30 minutes on the street looking for a place for a crowd. +
 +

+
Eating is more fun when there are more people. Please join us!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/26/jenkins-sessions-at-javaone/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">26</div></div><h5 class="title">Jenkins sessions at JavaOne</h5></div><p class="teaser">It’s the JavaOne season again in San Francisco. This year, there are whopping 6 sessions that discuss Jenkins (including myself, which is the very first session in Monday!) Unfortunately some of them happen in the same time, but I for one am looking forward to seeing the mobile app test talk from Intuit.

CON6256 - Large-Scale Automation with Jenkins (Monday 8:30am, Hilton)

Jenkins is the most adopted open source continuous integration server today, and beyond the automated build and test, it is a platform for launching all kinds of automation tasks. As the use of Jenkins grows inside an organization, people are automating complex activities that need to be choreographed—such as deploying an application, running a load test, cleaning up the environment, and then handing over the build to the operation team. Such orchestration of activities is a very useful building block for continuous delivery, a practice promoted in recent years. This session looks at various patterns and plug-ins that deal with this kind of choreography. It also briefly discusses what’s new in recent versions of Jenkins.

CON3648 - Take Your Mobile Applications Tests to the Next Level: Continuous Integration (Monday 1pm, Hilton)

Mobile tests today can be automated by popular mobile testing frameworks in Java such as monkeyrunner, Sikuli, and Robotium. However, getting mobile tests running in continuous integration is not widely understood and rarely implemented. Whether you are an experienced mobile developer or tester or new to the mobile field, this session informs you about the complexities of emulators and devices and how you can navigate through each challenge to integrate mobile tests into Jenkins. You will be guided step-by-step through two case studies on how to integrate native Android and iPhone application tests by using monkeyrunner and Sikuli, respectively, into Jenkins. Leave with Java code samples of these automated tests as well as practical knowledge of mobile devices and emulators.

CON2822 - Real-World Strategies for Continuous Delivery with Maven and Jenkins (Tuesday 10am, Hilton)

Maven is close to ubiquitous in the world of enterprise Java, and the Maven dependency ecosystem is the de facto industry standard. However, the traditional Maven build and release strategy, based on snapshot versions and carefully planned releases, is difficult to reconcile with modern continuous delivery practices, where any commit that passes a series of quality-control gateways can qualify as a release. How can teams using the standard Maven release process still leverage the benefits of continuous delivery? This presentation discusses strategies that can be used to implement continuous delivery solutions with Maven and demonstrates one such strategy using Maven, Jenkins, and Git.

CON12570 - Pragmatic Continuous Delivery (Tuesday 10am, Hilton)

When you send a package via FedEx, it goes through a tracked, automated process that makes sure the package arrives promptly at the destination. Continuous delivery describes how this process can similarly be made fully automated and transparent, with your commits “fedexed” to production. The focus of continuous delivery is the delivery pipeline. Every commit that enters the pipeline should go through automated integration and testing, and if successful, produce a release candidate. This presentation is based on a demo that uses Jenkins to orchestrate the delivery pipeline; Nexus for long-running and manual workflows; and LiveRebel to make production updates quick, automated, nondisruptive, and reversible.

CON3363 - HTML5 Testing in All Browsers with Java (Tuesday 11:30am, Parc 55)

Would you love to test your HTML5 app in all browsers? The biggest challenge in writing HTML5 applications is that your application must run on many platforms, ranging from old desktop browsers to cutting-edge mobile browsers. Each browser behaves nearly the same, but inconsistencies can lead to major bugs. In this session, JavaOne Rockstar and Java Champion Kevin Nilson shows how you can leverage open source Java tools to test your HTML5 application in all browsers. The presentation shows examples of using tools such as TestSwarm, QUnit, jQuery, Jenkins/Hudson, Oracle VM VirtualBox, GlassFish Server technology, and Sun SPOTs to test your HTML5 application in all browsers.

CON12983 - Java PaaS: The Engine for Delivering Enterprise and Mobile Applications (Wednesday 8:30am, Parc 55)

Attend this demo-filled session that shows you how to use Java platform as a service (PaaS) to deploy complete enterprise applications in the cloud with Eclipse, Jenkins, and MySQL in addition to iOS/Android clients and full end-to-end continuous integration. In a few minutes, you’ll have cloud-based Git/SVN repositories set up with CI builds triggered automatically and your apps, databases, and supporting services up and running live. The presentation also shows how you can add more PaaS services—ALM, Web monitoring and analytics, hosted log management, e-mail integration, enterprise search, cloud DB services, and much more—to your apps right off the bat. Experience the future of Java development!

+
 +
And it looks like the jclouds session will also touch jgroups plugin: +
 +

CON8009 - What’s New in jclouds 1.5 (Monday 10am, Parc 55)

jclouds 1.5 is the result of 3.5 years of development by nearly 100 developers interested in portable cloud computing. During this session, you’ll get up-to-date with cloud computing technology developments such as OpenStack. You’ll learn how to use jclouds 1.5 to control private and public infrastructures and storage clouds programmatically. You’ll also see examples of new tools powered by jclouds, including Jenkins and Brooklyn.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/28/saturday-night-drink-up/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">28</div></div><h5 class="title">Saturday night drink-up</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/NCI_Visuals_Food_Beer.jpg/320px-NCI_Visuals_Food_Beer.jpg[image] +

+
+

+
Because https://www.meetup.com/jenkinsmeetup/events/84235932/[the dinner looks popular], here&#x27;s another last minute gathering for https://www.cloudbees.com/jenkins-user-conference-2012-san-francisco.cb[JUC San Francisco]. +
 +

+
We&#x27;ll have a small drink-up Saturday night at http://21st-amendment.com/[21st Amendment] (563 2nd Street), like from 6pm to whenever. If you are coming from out of town, you probably are around, so why not join us! +
 +

+
At least abayer, majost, and kohsuke should be there, and hopefully more. If you are coming, please leave a comment in this post so that we get the sense of who to expect!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/09/28/take-the-jenkins-survey/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">28</div></div><h5 class="title">Take the Jenkins Survey!</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/0/01/Paid-surveys.jpg[image,width=200] +

+
+

+
Just like https://blog.cloudbees.com/2011/12/jenkins-community-survey-results-82.html[the last year], link:/survey[we are running a survey this year], to get some objective insights into what our users would like to see in the project. Obviously, the developers in the project deal with https://issues.jenkins.io[individual bug reports and feature requests] all the time, but sometimes those day-to-day issues distract you from a bigger picture. +
 +

+
This year, we kept some of the questions the same, so that we can see the trend. But we also http://meetings.jenkins-ci.org/jenkins/2012/jenkins.2012-09-19-18.00.log.html#l-142[discussed what we wanted to ask] among ourselves and revised some more. +
 +

+
The tricky thing about being an open-source project is that it&#x27;s not like some of us can actually decide what we&#x27;ll be working on — in the end it&#x27;s up to individual contributors to decide what they want to work on. So I can&#x27;t make promises, but in a way, that&#x27;s precisely why we&#x27;d like to get these objective, measurable, quantitative feedbacks. It lets us discuss how to solve the problem, instead of spending time discussing what the problem is. +
 +

+
Last year, we&#x27;ve heard loud and clear that people wanted to see some UI improvements. So a bunch of us sit down at link:/blog/2012/02/21/fosdem-2012-recap/[FOSDEM], picked up several key UI improvements, and https://wiki.jenkins.io/display/JENKINS/UI+Enhancements[we&#x27;ve actually delivered on those]. This year I hope to do the same. +
 +

+
The survey will close at the end of October, and if you participate, you&#x27;ll get to see the results first. As an added incentive, CloudBees had pitched in a $100 Amazon gift card. So https://jenkins-ci.org/survey[please let your voice be heard].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/11/14/sponsor-jenkins-bugs-with-freedom-sponsors/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">14</div></div><h5 class="title">Sponsor Jenkins bugs with Freedom Sponsors</h5></div><p class="teaser">(This is a guest post by Tony França)

Hi all, my name is Tony, I’m the creator of ( FreedomSponsors) and today I want to talk how Jenkins has inspired me to build it.

Before starting, I’d like to thank the Jenkins crew for letting me publish this guest post in their blog.
On top of that, thank you for maintaining Jenkins as well - I’m a big fan and a heavy user. Jenkins potential to make peoples lives easier is really amazing.
You guys are amazing.
And Kohsuke, you’re my personal hero :-)

All right, that being said, let’s move on with the story.

Most people who like FreedomSponsors probably don’t know that Jenkins is sort of the reason it exists in the first place. That’s right, if it wasn’t for Jenkins I’d probably never had the idea for FS.

This is how it happened.

I was playing with the ( Jenkins OpenID plugin), and I was having some trouble with it.
After a little research, I found that there was a JIRA bug for it - ( JENKINS-9216: Make OpenID work with Google Apps accounts).

&quot;Bummer&quot; - I thought - &quot;Maybe I can try to debug it. Oh boy, but I don’t know anything about Jenkins code. That would be too…​ expensive! I bet there are a few people out there that would be willing to even pay a few bucks to the Jenkins crew to prioritize this.&quot;

The moment I thought that, a storm of ideas came rushing into my head.
It was like a conversation with myself in my mind.

&quot;Wait a minute…​ why can’t people actually do just that?! They should be able to.&quot;

&quot;Maybe a JIRA plugin could let them…​&quot;

&quot;But what about other projects, ones that don’t use JIRA?&quot;

&quot;Maybe there could be a central place for all those offers. If many people &#x27;sponsor&#x27; the same issue, the developer who solve it might get a decent piece of gold - rightfully deserved. That could even free up more of their time to work on the projects they love :-)&quot;

&quot;The sponsors would pay the developers out of gratitude, and for the sake of keeping their word.&quot;

&quot;This has the Agile spirit in it: Customer collaboration over contract negotiation&quot;

And I kept thinking, and it didn’t took very long until I had the whole &quot;sponsoring model&quot; in my head.
I realised that that was one of the best ideas I had in my life. I was very excited and I had to act on it.

I started studying Django on that same day. I had already learned some Python before and Django had been on my queue for some time. And I’m glad I did it. I’ve been building JavaEE (Java web) applications for about 8 years now, and, oh boy, Django makes things soooo much easier, and simpler, and faster to code - I’m in love with it…​ Okay, but I’m missing the point here.

So, I started building &quot;it&quot; alone on my free time. It took me a few days to pick a name for &quot;it&quot;.
The &quot;FreedomSponsors&quot; name came very naturally - it rightfully conveys what the platform would do, and the spirit of software freedom that I’d like to encourage.

Seven weeks later it was done. I had already bought the domain and created an account at Amazon AWS.
So I put it up and started bugging everyone about it.
And guess who was the first person I wanted to tell? Kohsuke Kawaguchi :-)
It was just fair. So I sent him this email.

On Sun, Jul 8, 2012 at 3:36 AM, Tony França tonylampada@gmail.com wrote:

Hi Kohsuke.
My name is Tony, I’m a Software Architect.
I’m a big fan and a (very) heavy user of Hudson - Jenkins.
It has really been enabling our company to move towards a &quot;continuous delivery&quot;-like development process in the past couple of years.

So, thank you for that.

Also, if it wasn’t for Jenkins, maybe I would never had the idea to build the FreedomSponsors web site.
That’s my personal project - an idea that I had about six weeks ago.

You see, most of the time I was developing it, I had you in mind.
I have always felt that &quot;Jenkins is so great, that Kohsuke really deserves to get rich for it&quot;.

I just launched FreedomSponsors - a few minutes ago.
It just felt right to come here and tell you about it :-)

Let’s see if I can get you rich now :-).

Cheers!
Tony Lâmpada

And his reply just made my day

On Thu, Jul 12, 2012 at 5:19 PM, Kohsuke Kawaguchi wrote:

Congratulations for launching your service.

I thought about a similar idea long time ago over a lunch with my colleagues, but my hats off to you for actually making it real. I can imagine a lot of obstacles (most of those you already note in FAQ), but if this works out I think it’d be great.

By the way, I wonder if you have considered open-sourcing this, say under Aflo GPL. With the network effect and being the dominant contributor, it’s very difficult for anyone else to run the same code on public internet to compete with you, and it does let other people contribute small changes, and given your audience is open-source developers, I think it sends the right message as well as help you boost your development. It also seeds the ecosystem (of Bugzilla plugin, JIRA plugin, dashboard, etc.), too.

Just my 2 cents.

You see, FS’s code was still closed when I launched it. I was worried about competition indeed.
But his arguments were very convincing. Specially when he talked about sending the right message to the Free Software community. I thought about it for while and came to the conclusion that he has absolutely right. It still took me a few weeks until I moved the code to Github. I’m glad I did it. The feedback loop has been great.

And that was not his only contribution. He also gave us this very useful piece of feeback:
( JIRA plugin to link from tickets to FreedomSponsors)

Indeed, that was a great idea. My friend and associate Arthur is the one who built it.
Kohsuke suggested that I joined the Jenkins crew at the ( Jenkins Governance meeting) to see if everyone would agree about installing it on Jenkins JIRA. Everyone liked the idea and had no ojections.

I can’t say enough how trilled and honored I felt knowing that Jenkins would be the first project to install our plugin. Thank you folks. Thanks Kohsuke. You guys are awesome :-)

Now FreedomSponsors is growing, slowly but steadily. And what makes us really happy is that almost every developer we tell about it just loves the idea. We’ve received valuable, constructive feedback from a lot of people who want to see us moving forward. That’s the best incentive that I could wish for.

We still have a lot of challenges ahead of us. The biggest and closest one in the horizon is to start a &quot;movement&quot; that will help spread within companies a culture of contributing more to the free software projects they depend on, by making they realise that that’s what’s best for everyone. If we can achieve that then we’ll have made the free software world even better.

So, everything I wrote so far is, hopefully, only the begginning of this story. And I’m really excited and looking forward to see it unfold. Being a part of it is even more exciting.

What about you? If you want to be updated about, or even help write the next chapters, then
join, follow, like, read, spread the word, give feedback and contribute with code or new issues.

Thank you Jenkins crew, thank you Kohsuke.
We wouldn’t have made it here without you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/11/15/fundraising-for-travel-grant/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">15</div></div><h5 class="title">Fundraising for travel grant</h5></div><p class="teaser">+ +

+
+

+
We are trying to https://co.clickandpledge.com/advanced/default.aspx?wid=46160[raise $2000 travel grants] for assisting Jenkins contributors to travel, meet, and strengthen their relationships with the other Jenkins contributors. Specifically, we have https://fosdem.org/2013/[FOSDEM] and https://www.socallinuxexpo.org/scale11x/[SCALE11x] in mind, in which there already are a fair amount of Jenkins contributors concentration. +
 +

+
Being an open-source project, Jenkins developers are highly dispersed, yet a lot gets done in the community through human relationships, just like any other organizations. This poses a challenge, because most of the contributors work on Jenkins on their spare times, and so people are on their own to travel to the shows, creating greater divides between those of us in the U.S., Europe, and in Asia. +
 +

+
This fundraising is a bit of experiment to see if it&#x27;s worth the money. The goal is to sponsor two people who don&#x27;t work on Jenkins full time to travel to those events (and hopefully present talks, although that&#x27;s subject to the acceptance by conferences.) We&#x27;ll also report back what came out of them. +
 +

+
If you think this is a worthy goal, https://co.clickandpledge.com/advanced/default.aspx?wid=46160[please consider donating]. If you&#x27;d like to donate but not for this cause, please drop us a note so that we can attribute it accordingly.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/11/16/new-mailing-list-for-better-event-meet-up-local-community-coordination/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">16</div></div><h5 class="title">New mailing list for better event/meet-up/local community coordination</h5></div><p class="teaser">+
As per http://meetings.jenkins-ci.org/jenkins/2012/jenkins.2012-11-14-19.01.log.html#l-68[the discussion in the project meeting today], we created http://lists.jenkins-ci.org/mailman/listinfo/jenkins-events[a new mailing list `+events@lists.jenkins-ci.org+`] for: +
 +

discussing and coordinating Jenkins related events

share knowledge between different local communities

helping new organizers by having existing community people offering advices

improving visibility and transparency of event organization work

+
+

+
If you are interested in facilitating local communities (being from Japan, I know for a fact that a local community that speaks the native language makes a big difference in many parts of the world!) +
 +

+
The list is http://lists.jenkins-ci.org/mailman/listinfo/jenkins-events[open for anyone to join] and the archive is public. Looking forward to seeing you in the list.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mailing list">mailing list</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/11/18/comunidade-verde-amarela-do-jenkins-uni-vos/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">18</div></div><h5 class="title">Comunidade verde-amarela do Jenkins, uni-vos!</h5></div><p class="teaser">O Jenkins, servidor de integração favorito de todos, é muito utilizado no Brasil, e agora tem uma lista de e-mails em Português além do primeiro encontro de usuários Jenkins no Brasil. Se você utiliza o Jenkins, desenvolve plug-ins, tem interesse em aprender mais sobre esta incrível ferramenta Open Source e sobre Integração Contínua, essa é a sua chance!

Além de matar dúvidas sobre o Jenkins e aprender com os outros participantes, há várias outras atividades na comunidade como a tradução de documentação, tutoriais e livros, bem como a divulgação de eventos e treinamentos.

Gostei! Como participo?

Você pode começar se inscrevendo na lista de e-mails de usuários do Jenkins em Português (jenkinsci-br). Lá você poderá enviar suas perguntas, bem como ajudar outros usuários com dúvidas sobre o Jenkins ou plug-ins. Se você utiliza o Twitter, os anúncios e links serão disponibilizados no @jenkins_br.

Encontro de usuários Jenkins do Brasil 2012

O primeiro encontro de usuários Jenkins do Brasil acontecerá no próximo dia 1 de Dezembro de 2012. O evento é gratuito e acontecerá na USP, em São Paulo. Lá você poderá acompanhar palestras, lighting talks, conversar com outros profissionais e também terá a oportunidade de conhecer pessoalmente Kohsuke Kawaguchi, outros usuários e desenvolvedores de plug-ins do Jenkins.

Confirme já sua presença no encontro de usuários Jenkins do Brasil 2012! Apesar de gratuito temos lugares limitados e precisamos estimar o número de participantes para brindes, bebidas e para acomodar bem todos os  participantes.

Esperamos você lá! :-)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kinow/">Bruno P. Kinoshita</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/12/13/office-hours-next-week-metadata-plugin/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">13</div></div><h5 class="title">Office hours next week: metadata plugin</h5></div><p class="teaser">+
https://wiki.jenkins.io/display/JENKINS/Office+Hours[The last Jenkins office hour of the year] hosts Robert Sandell and Tomas Westling, who will go over https://wiki.jenkins.io/display/JENKINS/Metadata+plugin[newly open-sourced metadata plugin] from Sony Mobile Communications (https://developer.sonymobile.com/2012/11/22/sony-contributes-to-jenkins-software-tool/[more about this story on their website]). This team from Sony Mobile has been known for several other popular plugins, including https://wiki.jenkins.io/display/JENKINS/Gerrit+Trigger[the Gerrit trigger plugin]. And I think this latest batch of plugins will not disappoint! +
 +

+
As I understand, this plugin is a https://wiki.jenkins.io/label/JENKINS/plugin-library[library plugin], which is primarily meant to be consumed by other plugins. With help of other plugins using this plugin, it can classify jobs and agents by adding metadata tags to them. This in turn enables more intelligent scheduling, views, access control, and so on. +
 +

+
Personally, I&#x27;m very interested in integrating https://wiki.jenkins.io/display/JENKINS/iOS+Device+Connector+Plugin[the iOS device connector plugin], so that one could say &quot;run this job on a Mac where iPad2 is connected&quot;, etc. The other piece is to integrate this with https://wiki.jenkins.io/display/JENKINS/External+Resource+Dispatcher[the external resource dispatcher] so that Jenkins can grant exclusive device access to jobs while they are running so that tests don&#x27;t end up trying to use the same device. +
 +

+
If you are a plugin developer, hopefully this gets you excited. See you https://www.timeanddate.com/worldclock/fixedtime.html?msg=Jenkins+Office+Hours&amp;iso=20121219T11&amp;p1=283&amp;ah=1[Dec 19th 11am PST]. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/12/19/los-altos-hackathon-this-friday/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">19</div></div><h5 class="title">Los Altos Hackathon This Friday</h5></div><p class="teaser">+
What better way to end the year than to come join a little Jenkins hackathon this Friday afternoon with Kohsuke (the core developer), Max Spring (https://wiki.jenkins.io/display/JENKINS/Jenkow+Plugin[Jenkow plugin]), and hopefully other Jenkins hackers? +
 +

+
We&#x27;ll do this at https://maps.google.com/maps/ms?msid=204997319446652334724.0004d13cfa1eb16f65a99&amp;msa=0&amp;ll=37.377281,-122.113874&amp;spn=0.007656,0.00478[CloudBees Los Altos office], starting around Friday 1pm. +
 +
 +
[.small]#View https://maps.google.com/maps/ms?msid=204997319446652334724.0004d13cfa1eb16f65a99&amp;msa=0&amp;ie=UTF8&amp;ll=37.377281,-122.113874&amp;spn=0.007656,0.00478&amp;t=h&amp;source=embed[CloudBees Los Altos office] in a larger map# +
 +

+
Our plan is to primarily hack on the Jenkow plugin, but if you have other projects you&#x27;d like to hack on, that&#x27;d be welcome. Or if you&#x27;ve been interested in getting started on writing a plugin but haven&#x27;t had a chance to, this is a great time to do this, and when you get stuck the help is right next to you. Or heck, if you just want to drop by and say hello, that&#x27;s fine, too. +
 +

+
Beer, cofee, and other drinks are provided, as well as Jenkins stickers.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/12/20/jenkins-keynote-at-fosdem-2013/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">20</div></div><h5 class="title">Jenkins keynote at FOSDEM 2013</h5></div><p class="teaser">Earlier this year we participated in FOSDEM 2012 in Brussels, Belgium. Overall the event was a major success and we’re very happy we were able to take part in it!

For FOSDEM 2013, we’ll be back in Brussels and participating in a major way. The first day of FOSDEM (February 2, 2013) will be the 2nd birthday for the Jenkins project, and seems appropriate that project founder Kohsuke Kawaguchi will be giving a keynote session titled: &quot; How we made the Jenkins community &quot;

Here’s an excerpt from Kohsuke’s talk proposal:

Jenkins project has an interesting history. It started from scratch on my spare time, and grow over time to boast 600+ open-source plugins developed by 300+ contributors from all around the world.

There are several key ingredients, both technical and social, that enabled this model, and I think those ingredients are useful to other projects. In this talk, I’ll discuss how Jenkins project and the community works, what these ingredients are, why they help you attract more developers into your projects, and why it matters.

You can read more about Kohsuke’s keynote here

In addition to the keynote, I ( R. Tyler Croy), and a number of members of the Jenkins, Cucumber and Selenium communities are hosting the first ever Testing and Automation devroom at FOSDEM.

If you’re interested in submitting a talk proposal for the dev room the deadline is 23:59 UTC on December 21st 2012! The Call for Proposals can be found here, and the proposal submission form can can be found here.

We are very likely going to have a table in the hall again this year, but the FOSDEM committee hasn’t yet confirmed whether or not we will have a table.

Regardless, a lot of Jenkins community members will be at FOSDEM in February in addition to hundreds of other open source contributors and users from around the world.

If you’re interested in participating and/or meeting up with the Jenkins crowd, there’s details coming together on the FOSDEM wiki page .

We hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2012/12/25/jenkins-meet-up/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">25</div></div><h5 class="title">한국에서의 첫번째 Jenkins meet-up!</h5></div><p class="teaser">&quot;&gt;

우리는 2013년 1월25일 저녁에 Jenkins meet-up을 삼성전자와 함께 준비하고 있습니다.
Meet-up은 서초사옥에서 진행될 예정이며 추후 변경될 수 있습니다.
발표자는 일본 커뮤니티에서 활동중인 Cactuman과 삼성이고 Groovy script를 이용한 job 일괄설정
에 대해서 발표할 예정입니다.

Jenkins를 설치한 통계를 통해 저희도 한국에 많은 사용자가 있다는것을 알고 있었습니다.
지금까지는 메인 Jenkins community에서 컨택하는데 실패했었지만 이번에 그런 상황이 해결된것에 너무 흥분됩니다.

이번 meet-up에 참가할 의사가 있으면 meetup.com 에 회답해 주시면 됩니다.
참가비는 없으며 우리는 Jenkins,plugin 들과 함께한 경험들(간단한 주제를 포함)을 한국의 Jenkins user와
공유 할 더 많은 발표자를 찾고 있습니다.

여러분의 많은 참가를 기대합니다.

We are organizing a Jenkins meet-up in Seoul in the evening of Jan 25th 2013, thanks to the help of folks at Samsung. The meeting will be in the evening, at the location to be determined. I am presenting in person, as well as Cactusman, one of the key community people in Japan. Seung-Heui Jang from Samsung would be presenting about job batch processing by Groovy scripts.

According to the installation statistics, we know there are significant user base in Korea, but so far the main Jenkins community has failed to establish contacts with them. I’m really excited that I can finally fix this situation!

If you are interested in coming, please RSVP at meetup.com. The event will be free. We are still looking for a few more speakers (including lightning talks), so please share your experiences with Jenkins, plugins you’ve been working on, and so forth with the rest of the Korean Jenkins people.

Looking forward to seeing many of you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/01/25/jenkins-at-fosdem-2014/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">25</div></div><h5 class="title">Jenkins at FOSDEM 2014</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/fosdem.png[image] +

+

+
https://en.wikipedia.org/wiki/FOSDEM[FOSDEM] is probably the biggest open-source developers&#x27; conference in Europe. +
 +

+
This year will be the 3rd year for us to be present in FOSDEM. There will be https://wiki.jenkins.io/display/JENKINS/FOSDEM[a bunch of community people], handing out flyers and stickers, showing Jenkins, and generally be available to talk to people! This year, we&#x27;ll bring some Jenkins T-shirts to sell, and hopefully some bobble heads as well. So please be sure to drop by. +
 +

+
And if you are already involved in the Jenkins project and willing to help us man the booth, that&#x27;d be awesome! Looking forward to seeing you! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/03/19/jenkins-user-conferences-this-year/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Jenkins User Conferences This Year</h5></div><p class="teaser">+
Over the past three years, the Jenkins User Conference is held annually in the https://www.cloudbees.com/jenkins/juc2013/juc2013-palo-alto-abstracts.cb#FlorianLier[Bay Area] with a few events in different locations around the world. The Jenkins User Conference has established a reputation as a focal point for the Jenkins community to come together to share new ideas and best practices. Each year we have experienced the growth and expansion within the Jenkins community. This year we are taking this platform to other regions of the world, offering regional gatherings of Jenkins users and developers. +
 +

+
At the moment, we are working on the following JUCs and events for 2014: +
 +

JUC Boston - June 18

JUC Berlin - June 25

JUC Israel - July 16

JUC San Francisco Bay Area - October (TBD)

JUC Australia/New Zealand - November/Dec (TBD)

+
+

+
Jenkins Events +
 +

Copenhagen - September

Brazil - November/December (TBD)

+
+

+
There are a few different ways to get involved: +
 +

Register Now to Attend: JUC Boston. Registration pages for other JUCs/events are coming soon. Please check back here often.

Be a Sponsor : There are a few ways to become a sponsor.

Submit a Talk Proposal : deadline is March 30

Submit a great idea for t-shirt design in the comment box below or email atong@cloudbees.com

Submit ideas for swag in the comment box below or email atong@cloudbees.com

Be part of the JUC committee: contact atong@cloudbees.com

+
+

+
Learn more: +
 +

Learn more about Jenkins User Conferences

Sign up and stay up to date with the latest Jenkins newsletter

+
+

+
Looking forward to seeing you at a local JUC near you! :o) +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/03/21/call-for-sponsors-2014-jenkins-user-conferences/"><div class="header"><div class="date"><div class="month">March</div><div class="day">21</div></div><h5 class="title">Call for Sponsors: 2014 Jenkins User Conferences</h5></div><p class="teaser">Jenkins User Conference (JUC) season is upon us! It’s a busy year for the Butler — he’s hosting conferences all over and looking for sponsors to help:

Boston — June 18

Berlin — June 25

Herzelia, Israel — July 16

Bay Area (California) — October (date TBD)

Mr. Jenkins and the JUC Organizing Committee want to invite you and your company to sponsor a JUC this year. Show your support for the Jenkins community and help keep costs low for attendees*. The funds go to are put to good use: conferences are two full tracks. Lunch, light breakfast, coffee and a coveted Jenkins t-shirt are also included.

Sponsors get all sorts of thanks from the Jenkins community:

Your logo on the conference t-shirt and all other conference communication (emails, website, signage, etc.)

A blog featuring sponsors

Free passes

Silver and Gold sponsors get a table to talk to folks and hand out swag

Gold sponsors get either a speaking slot, happy hour sponsorship or a dedicated room for demos

And more, but most especially, you get to support JenkinsCI. Just let us know if you’re interested to get the details. We’d love to have you join us. Friendly reminder: We are looking for speakers for all four cities. Call for Papers ends March 30 for Boston, Berlin and Israel. Submit your abstract now and come share your expertise with the Jenkins community. We hope to see you at a JUC this year! Lisa, Alyssa and the JUC Organizing Committee *PS - Registration just opened for Boston and early-bird tickets are only $59.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/01/your-java-web-start-slaves-will-be-always-clean/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 1</div></div><h5 class="title">Your Java Web Start slaves will be always clean</h5></div><p class="teaser">+ +

+
+

+
If you have agents that connect through https://wiki.jenkins.io/display/JENKINS/Distributed+builds#Distributedbuilds-LaunchslaveagentviaJavaWebStart[Java Web Start] (such as https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+as+a+Windows+service#InstallingJenkinsasaWindowsservice-InstallSlaveasaWindowsservice%28require.NET2.0framework%29[agents installed as Windows services]), we have a good news for you. +
 +

+
In case of a connection loss, this type of agents has been designed to automatically attempt to reconnect to the controller. This makes sense because you want these agents to remain online all the time, even if your janitor trips over the ethernet cable. Unfortunately, it also means that over the time, these agents accumulate gunk, such as mutated static states, any left-over threads or memory leaks, or https://issues.jenkins.io/browse/JENKINS-20913[native libraries that are loaded into JVM]. +
 +

+
To prevent that, a better approach is to https://issues.jenkins.io/browse/JENKINS-19055[restart the agent JVM (JENKINS-19055)] and have the new JVM reconnect, instead of having the same JVM reconnect. That would ensure that the agent always stays clean. I&#x27;ve planned to make this change for a while now, and I&#x27;m happy to report that this change is finally landing to the upcoming 1.559. +
 +

+
Restarting JVM is easy on Unix, where I could just https://man7.org/linux/man-pages/man3/exec.3.html[exec(3)] to itself. We&#x27;ve been doing this for ages on controllers, for example when you update a plugin and tell Jenkins to restart. +
 +

+
The hard part is to do this for Windows, where the most of the time was spent. I had to improve https://github.com/kohsuke/winsw[windows service wrapper] to support self-restarting services, which turned out to be trickier because Windows service control manager doesn&#x27;t provide &quot;restart&quot; as an atomic operation. It also kills not just the service process itself but all the processes in the group. So I had to double-fork the service wrapper into a separate process group just to restart a service from within itself. +
 +

+
In any case, the end result is that if https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+as+a+Windows+service#InstallingJenkinsasaWindowsservice-InstallSlaveasaWindowsservice%28require.NET2.0framework%29[you have installed a service through GUI], be it on Windows, Unix, or OS X, agents will restart themselves every time it gets disconnected from the controller. +
 +

+
I&#x27;ve also taken the opportunity to make `+jenkins-slave.exe+` on the agent self-updating. Every time it connects to the controller, it gets the latest version from the controller. +
 +

+
If you have installed Web Start agents as services, make sure to update the local copy of `+agent.jar+` on these agents to 2.37 or later. This &quot;restart on reconnect&quot; feature only kicks in when you are running this very recent version of `+agent.jar+`. And yes, we realize it&#x27;d be nice for `+agent.jar+` to update itself, which is tracked as https://issues.jenkins.io/browse/JENKINS-22454[JENKINS-22454]. But that&#x27;s a work for another day. +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/04/maven-job-type-performance-improvements-in-maven-plugin-2-2/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 4</div></div><h5 class="title">Maven job type performance improvements in Maven plugin 2.2</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Grumman_F-14_Tomcat[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/US_Navy_040925-N-0295M-030_An_F-14D_Tomcat_conducts_a_high_speed_flyby_during_the_tactical_air_power_demonstration_at_the_2004_Naval_Air_Station_Oceana_Air_Show.jpg/300px-thumbnail.jpg[image]] +

+
+

+
I recently had an opportunity to visit a big Jenkins user on site, and one of the things they&#x27;ve told me is that building projects in the Maven job type is substantially slower than doing the same with the freestyle project type. +
 +

+
This is partly expected, because this job type does more for you. For example, it automatically archives your build artifacts, fingerprints all the relevant information, and so on. These are good things, and naturally, it cost time. +
 +

+
But the slow down they are seeing was substantial, and this is a complaint I&#x27;ve heard from others as well. So I started looking into it. +
 +

+
With a help of https://linux.die.net/man/8/tc[artificial delay] induced to my network interface and several custom scripts to probe into the running processes, I was able to understand what was going on and make some good improvements. +
 +

+
First, in Maven plugin 2.0, we&#x27;ve made a change in the way we archive artifacts from Maven. Previously, the artifacts were copied between the controller and the Maven JVM, and for a reason I&#x27;ll mention later, this was very slow, especially in a network that has a large latency. With Maven plugin 2.0 and onward, artifacts are archived between the controller and the agent JVM. +
 +

+
The second problem that I discovered was that the spy program we put inside Maven is causing excessive amount of unnecessary classloading. Some classes have static initializers that too eagerly refer to other classes, which in turn brings in other classes, and so on. Despite https://jenkins-ci.org/content/faster-slave-classloading[the jar file caching that we do], these classloading still sometimes requires precious roundtrips to the controller, which costs in the order of 10s of ms. I was able to make various changes in Jenkins core to cut this down, and these fixes will land in Jenkins 1.559 (ETA is April 14th.) The classloading overhead is independent of the size of your Maven build, so this improvement is more for people who have lots of small Maven builds, like https://ci.jenkins.io/[Jenkins building Jenkins plugins]. +
 +

+
Now, on to the biggest fruit of this investigation I was able to discover and fix. Imagine the Maven JVM has a lot of data to send to the controller, say you are archiving test reports or code coverage report. A good implementation would send these data as fast as possible to the controller, paying respect to the limit of flow control to avoid overwhelming the controller. +
 +

+
It turns out that the way we set up this communication channel was far from optimal. Instead of having the Maven JVM push data with flow control, we were relying on the controller to pull data. That is, controller has to send out a request to the agent to fetch the next batch of data (8KB), then once it receives that data, it sends out another request to fetch the next batch of data, and so on. If your network latency is 10ms, this scheme only lets us send 500KB/sec, even if you have a gigabit ethernet. No wonder it was so slow! +
 +

+
This fix is in in Maven plugin 2.2. See https://issues.jenkins.io/browse/JENKINS-22354[JENKINS-22354] if you want to know more about the actual diffs and such. +
 +
Unfortunately, none of these are available for those who are on 1.532.x LTS, but http://meetings.jenkins-ci.org/jenkins/2014/jenkins.2014-04-02-18.02.html[the next 1.554.1 LTS] will be able to run the newer Maven 2.2 plugin. So the help is on the way! +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/09/more-scalable-slaves/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 9</div></div><h5 class="title">More scalable agents</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Nio[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Nikko_Toshogu_Nio_M3043.jpg/160px-Nikko_Toshogu_Nio_M3043.jpg[image] +
] +

Nio

+

+
+

+
https://en.wikipedia.org/wiki/New_I/O[NIO]-based https://wiki.jenkins.io/display/JENKINS/Distributed+builds#Distributedbuilds-LaunchslaveagentviaJavaWebStart[Java Web Start (JNLP) agent handling] is coming to 1.560. This will help you run a large number of JNLP agents more efficiently. A connected JNLP agent used to occupy one thread on the controller, but now it occupies none. Combined with the earlier change that eliminated threads from idle executors, now you can connect thousands of agents. +
 +

+
All you have to do is to use the latest `+agent.jar+` from Jenkins 1.560. No other changes are necessary on users&#x27; part. +
 +

+
A bulk of this is implemented in https://github.com/jenkinsci/remoting[remoting 2.38], and a good part of it was implemented about a year ago on the airplane on the way to Europe. +
 +

+
We plan to make CLI connections take advantages of this too, which helps those who use that a lot. That&#x27;s not in 1.560, but hopefully it&#x27;ll be in the near future. This change also paves a way for multi-participant bus-topology communication, which I think would be an useful building block for https://github.com/jenkinsci/master-to-master-api-plugin/[the work-in-progress controller-to-controller API].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/11/infoq-ci-survey-2014/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">InfoQ CI survey 2014</h5></div><p class="teaser">+
InfoQ has been https://www.infoq.com/research/ci-server[running a CI server survey] for more than a month now, and here is the current result: +
 +

+
https://www.infoq.com/research/ci-server[ +
image:https://jenkins-ci.org/sites/default/files/images/infoq.preview.png[image] +
] +

+
+

+
Jenkins has gotten more than 70% of the votes, once again proving the wide adoption among developers. If you are one of those who picked Cruise Control into the &quot;considering&quot; section, I&#x27;d encourage you to look around a bit more. +
 +

+
You can still https://www.infoq.com/research/ci-server[vote from their website or leave comments if you want]. +
 +

+
By the way, the design of two axes make no sense to me; for example, I&#x27;d order the adoption axis to &quot;considering -&gt; migrating to -&gt; using now -&gt; moving away from&quot;, and the circle seems to imply two axes are somehow interchangeable, when it should probably be just in a checkerboard to indicate those are independent axes.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/11/jenkins-1-532-3-lts-is-released/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">Jenkins 1.532.3 LTS is released</h5></div><p class="teaser">+
The final LTS release of the 1.532.x line is out today. You can download it from http://mirrors.jenkins-ci.org/[the usual location]. Changelog is https://jenkins-ci.org/changelog-stable[here]. +
 +

+
Starting with the next 1.554.x LTS, the release model will https://wiki.jenkins.io/display/JENKINS/LTS+Release+Line[switch to the train model], where we commit to dates and get whatever we can ship by that date. +
 +

+
You can see https://jenkins-ci.org/content/event-calendar[the scheduled dates in our event calendar]. Backporting window for 1.554.1 is almost closing, so if you want to have your favorite issues nominated for it, please see https://wiki.jenkins.io/display/JENKINS/LTS+Release+Line[the process] in the Wiki and hurry!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/15/upcoming-jenkins-office-hours-acceptance-test-harness/"><div class="header"><div class="date"><div class="month">April</div><div class="day">15</div></div><h5 class="title">Upcoming Jenkins Office Hours: Acceptance Test Harness</h5></div><p class="teaser">+
image:https://clsdf.com/wp-content/uploads/2011/06/tumblr_lkzltkxTmF1qersu1.gif[image] +

+

+
One of the new efforts in Jenkins this year is https://github.com/jenkinsci/acceptance-test-harness[the acceptance test harness] for Jenkins. +
 +

+
We will be doing the Jenkins office hours next week to go over this and sync up and coordinate between people in the community that are trying to work on this. +
 +

+
It&#x27;ll be *April 23rd 11am PT* (https://www.timeanddate.com/worldclock/fixedtime.html?msg=Jenkins+Governance+Meeting&amp;iso=20140423T11&amp;p1=224&amp;ah=1&amp;sort=1[see what this time is in your time zone]) on Google Hangout at https://jenkins-ci.org/hangout. If you are intereste in hacking Jenkins or if you are a large user of Jenkins who have acceptance tests, we are looking forward to seeing you there. +
 +

+
For those of you who haven&#x27;t looked, this test harness allows you to write blackbox tests of Jenkins and its plugins. It was originally used to test LTS releases, but over the time, it acquired a number of features, such as ...: +
 +

Docker support for launching complex fixtures to test Jenkins with.

Pluggability to launch Jenkins under test (JUT) in many different environments

Pluggability to provision Jenkins and agents from EC2 to test large deployments

Choice of cucumber or JUnit to write test scripts

+
+

+
We are working on porting over existing test cases, but we&#x27;d like to work with users to move their acceptance tests on top of this same harness. The idea is to pool those test cases in the community so that we can test Jenkins and its plugins as we develop them. For this to work, we want tests to have lots of metadata (such as what plugins it touches), and for the harness to have sufficient modularity that different people can run the same scenario against different deployments, including existing instance. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/16/active-directory-plugin-improvements/"><div class="header"><div class="date"><div class="month">April</div><div class="day">16</div></div><h5 class="title">Active Directory plugin improvements</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Active_Directory[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Active-directory.svg/170px-Active-directory.svg.png[image] +
] +

+
+

+
One of the few plugins that I still personally maintain is https://wiki.jenkins.io/display/JENKINS/Active+Directory+plugin[Active Directory plugin]. In the past few months, I&#x27;ve been making steady improvements in this plugin, thanks to various inputs and bug reports given to me from the ClodBees customers. +
 +

+
One of the recent fixes was to get https://issues.jenkins.io/browse/JENKINS-9258[the &quot;remember me&quot; feature] finally working for Active Directory. This requires a relatively new Jenkins 1.556, but it eliminates the need to having to constantly type the password in. +
 +

+
Then I&#x27;ve rebumped the version of https://github.com/kohsuke/com4j[COM4J], which was https://issues.jenkins.io/browse/JENKINS-16429[causing a thread leak] when Jenkins runs on Windows. If you are running a Windows deployment with lots of active users, this probably would have contributed to the instability of Jenkins. +
 +

+
And then lastly, a small but crucial improvement was made to the way we search group membership, so that we can avoid recursively searching AD. This should result in a significant speed improvement when you are logging into Jenkins through AD. +
 +

+
The latest version of the plugin as of writing is 1.37. I hope you&#x27;ll have a chance to update the plugin soon. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/05/19/jenkins-office-hour-tutorial-on-writing-an-acceptance-test/"><div class="header"><div class="date"><div class="month">May</div><div class="day">19</div></div><h5 class="title">Jenkins Office Hour: Tutorial on writing an acceptance test</h5></div><p class="teaser">+
image:https://wiki.jenkins.io/download/attachments/57181939/hangout.png?version=1&amp;modificationDate=1361998218000[image,width=200] +

+
+

+
This week I&#x27;m going to do an office hour on how to write an acceptance test in https://github.com/jenkinsci/acceptance-test-harness[Jenkins acceptance test harness]. The event is on https://www.timeanddate.com/worldclock/fixedtime.html?msg=Jenkins+Office+Hours&amp;iso=20140519T11&amp;p1=283&amp;ah=1[Wednesday 11am PT]. +
 +

+
This new Selenium-based test harness is full of page objects and other abstractions that let you write blackbox integration tests on Jenkins and its plugins, as well as how they behave under various environments. +
 +

+
Unlike our regular office hours, https://plus.google.com/u/0/events/cpr7lhq3d544rj5uqid4rin3deg[the event is done through Hangout on air]. But I do want at least several people to join Hangout interactively, not just watch the event in a read-only mode. +
 +

+
To join the event interactively (as opposed to read-only), I think you need to https://plus.google.com/hangouts/_/hoaevent/AP36tYeeXozAE_RiZWtTfX-O-sEtxJ3qhu4Asnfy7tZOZf3hs3jX1Q[come here] (but since Hangout URL can change, please check back on this post right before the office hour begins, so that I can post an up-to-date URL.) +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/18/come-join-the-infra-team/"><div class="header"><div class="date"><div class="month">April</div><div class="day">18</div></div><h5 class="title">Come join the infra team!</h5></div><p class="teaser">+
https://puppetlabs.com/[image:https://i.stack.imgur.com/RZN4l.jpg[image,width=100]]

+

+
We are looking for volunteers to join the small infra team here at the Jenkins project. We are the butlers of the butler that get Mr.Jenkins going. +
 +

+
We&#x27;ve been https://github.com/jenkins-infra/jenkins-infra[managing our servers through puppet], and have been slowly folding pieces one at a time to puppet, but there&#x27;s still a lot of snowflake services that need proper operationalization. +
 +

+
So to fix them up, https://puppetlabs.com/[PuppetLabs] folks generously agreed to help us get going with a deployment of Puppet Enterprise. Tyler has managed to arrange a &quot;rapid deployment&quot; engagement. To kick start the effort, an instructor would come for one week (April 28th-May 2nd) to bring us up to speed on modern Puppet. we&#x27;ll then spend some time on our own to puppt-ize more, and deploy Puppet Enterprise. +
 +

+
The end goal is to ensure sustainability of our infrastructure, in case of unexpected server loss. +
 +

+
As we are about to get this effort going, we think this is a good time to solicit a few more volunteers. We are looking for someone who could join this two week engagement in San Francisco, and keep their involvement beyond that. This is a part time volunteer work, and you&#x27;d get some visibility and exposure to the inner guts of open-source projects, not to mention the satisfaction of getting thanked for your work. +
 +

+
If you are interested, please https://jenkins-ci.org/content/mailing-lists[drop us a note at the infra list]. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/05/27/acceptance-test-project-progress-report/"><div class="header"><div class="date"><div class="month">May</div><div class="day">27</div></div><h5 class="title">Acceptance test project progress report</h5></div><p class="teaser">+
Over the past 30 days or so, https://github.com/jenkinsci/acceptance-test-harness/[the acceptance test project] has made a great progress. +
 +

+
This project consists of a reusable harness that can be used by plugin developers and users to write functional test cases. These tests can be run against Jenkins instances that are deployed in https://github.com/jenkinsci/acceptance-test-harness/blob/master/docs/CONTROLLER.md[all sorts of different ways], and can interact with https://github.com/jenkinsci/acceptance-test-harness/blob/master/docs/FIXTURES.md[complex real fixtures]. These tests can be also run with specific version of Jenkins core and a combination of plugins. +
 +

+
The number of tests have https://jenkins.ci.cloudbees.com/job/core/job/acceptance-test-harness/[steadily increased to above 300]. Several of those are by https://github.com/eidottermihi[Michael Prankl], where he tests https://github.com/jenkinsci/acceptance-test-harness/blob/master/src/test/java/plugins/LdapPluginTest.java[the LDAP plugin with the real OpenLDAP server instance] that runs inside Docker — a kind of test that just wasn&#x27;t possible before can be now easily written. +
 +

+
https://github.com/jenkinsci/acceptance-test-harness/graphs/contributors[More than a dozen people] have contributed. https://github.com/jenkinsci/acceptance-test-harness/commits/master[A dozen changes are going in every single day], and more are coming — for example, Stephen is working on modularizing this harness and adding new pieces that allow people to do scalability and load testing. That&#x27;ll be a part of this effort soon. +
 +

+
If you are one of the large scale users who are interested in automating some of your Jenkins acceptance testing, please https://groups.google.com/forum/#!forum/jenkinsci-dev[drop us a note at the DEV list] so that we can work together. You can also watch the recording of our last https://wiki.jenkins.io/display/JENKINS/Office+Hours[office hours] where I demoed how you&#x27;d develop a test on top of this: +
 +
 +
 +

+
I think we all agree that this is an important effort/ Looking forward to joining the efforts with more people in the community! +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/05/30/adopt-a-plugin/"><div class="header"><div class="date"><div class="month">May</div><div class="day">30</div></div><h5 class="title">Adopt a plugin</h5></div><p class="teaser">+

+

+
Today on IRC, I was asked how someone new to the project can get started working on Jenkins, when s/he has no particular preference or pet-peeve. +
 +

+
This is a good question for which the project should have a canned answer ready, so here is one approach — adopt a plugin! +
 +

+
Often, a Jenkins plugin gets developed by someone to scratch his own itch. That person shares the plugin with the community, and since it does everything he needs, he moves on to work on something else. Then another person starts using that plugin, comes up with an idea for improvement, implements that, and then moves on. Given that we have more than 900 plugins today, there are a plenty of plugins that are currently co-maintained by the community, which could really use a focused loving caregiver. +
 +

+
So why don&#x27;t you adopt a plugin? You can pick up one of those plugins and act as a maintainer. You&#x27;ll hear appreciation from people who are using that plugin, and most plugins are small and simple enough even for people new to Jenkins. Above all, working on plugins don&#x27;t require much communication with existing developers and implicit processes, which is often difficult for new people to find out. +
 +

+
Here&#x27;s how you can find a plugin to adopt. You can look at https://wiki.jenkins.io/display/JENKINS/Pending+Pull+Requests[repositories that have most pending pull requests]. Plugins with lots of pull requests likely could use some help, so check if anyone is actively working on it and talk to him, or if you don&#x27;t see much activities from a single person, just go ahead and adopt the plugin. +
 +

+
https://stats.jenkins-ci.org/jenkins-stats/svg/svgs.html[Usage statistics] has `+top-plugins500.svg+` (this is for https://stats.jenkins-ci.org/jenkins-stats/svg/201404-top-plugins500.svg[the last month]). Open that in Firefox, which lets you zoom in. Scroll all the way to the right, and you see popular plugins. Compare that with https://github.com/jenkinsci/[our GitHub repositories], and you can find popular plugins that aren&#x27;t getting enough love. +
 +

+
https://issues.jenkins.io/browse/JENKINS#selectedTab=com.atlassian.jira.plugin.system.project%3Acomponents-panel[Issue tracker] is also a good place to look for a plugin in need of help. Every plugin has a separate component, so look at bugs and RFEs filed against those, especially with lots of votes. Fix a bug is great, but even just helping with the triage process would be highly appreciated. +
 +

+
Try adopting a plugin for a while, and when you get the hang of it, let https://groups.google.com/forum/#!forum/jenkinsci-dev[the dev list know]. Update `+pom.xml+` to have your name listed as a maintainer. Come https://jenkins-ci.org/content/chat[join IRC]. That way, we know who you are and how to reach you. +
 +

+
See, it&#x27;s really not that hard. And there&#x27;s something really satisfying in making things a little better and seeing happy users. Anyway, looking forward to working with you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jobs">jobs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/03/jenkins-user-conference-boston-is-around-the-corner/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 3</div></div><h5 class="title">Jenkins User Conference Boston is around the corner!</h5></div><p class="teaser">+
Only a few weeks until https://www.cloudbees.com/jenkins/juc-2014/boston[our Jenkins User Conference US East] kicks off in Boston on June 18. Right now more than 300 people have registered and we’ve had to https://www.eventbrite.com/e/jenkins-user-conference-us-east-boston-june-18-2014-tickets-10558652213[release more tickets]! If you will be anywhere near New England on June 18, https://www.eventbrite.com/e/jenkins-user-conference-us-east-boston-june-18-2014-tickets-10558652213[sign up fast so you don’t miss the fun]. +
 +

+ +

+
+

+
This year marks the butler’s first conference tour to https://en.wikipedia.org/wiki/New_England[New England]. He has chosen https://www.seaportboston.com/[the fabulous Seaport hotel] on the waterfront for a venue — a hotel that&#x27;s far better than what I usually stay in :-). You can even take a water taxi to https://en.wikivoyage.org/wiki/Boston[see the sites] or get to and from the airport. For airport transfers, you can also just hop on https://www.mbta.com/schedules_and_maps/subway/lines/?route=SILVER[the silver line bus] and arrive across the street from the hotel (the stop is called &quot;https://www.mbta.com/schedules_and_maps/subway/lines/stations/?stopId=25092&amp;lat=42.349098&amp;lng=-71.04206[World Trade Center Station]&quot;.) +
 +

+
This year we have https://www.cloudbees.com/jenkins/juc-2014/boston[an incredible line-up of speakers]. Attendees will be well fed, caffeinated, and even pickled if they choose... the afternoon break will feature BEvERages. And everyone gets this year’s Jenkins World Tour t-shirt. +
 +

+
Nothing about conference-throwing is cheap, so we’d like to take a moment to thank our generous JUC US East sponsors. It speaks so well for the JUC community that so many companies have stepped up to support Jenkins and produce a first-class conference. So here is the shout-out for them: +
 +

+
image:https://jenkins-ci.org/sites/default/files/images/JUC-boston-sponsors.preview.png[image] +

+
+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/03/jenkins-won-sdtimes-100-2014/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 3</div></div><h5 class="title">Jenkins won SDTimes 100, 2014</h5></div><p class="teaser">Jenkins won SDTimes 100, 2014

+
image:https://www.sdtimes.com/images/sdt100/2014SDT100_logo_120x123.gif[image] +

+
+

+
For the 5th year in a row, Jenkins project won https://sdtimes.com/content/article.aspx?ArticleID=71295&amp;page=4[SDTimes 100, 2014] this year under DevOps and SCM categories, along with other open-source projects like Chef, Docker, Git, LLVM, and Puppet. +
 +

+
I&#x27;d like to take this opportunity to once again thank the community for keeing us going strong. There&#x27;s https://groups.google.com/forum/#!topic/jenkinsci-dev/qrG7bAnZSHQ[a lot] of https://groups.google.com/forum/#!topic/jenkinsci-dev/zDaX4yiWLLw[interesting] efforts https://groups.google.com/forum/#!topic/jenkinsci-dev/l5vrC8BqVJQ[going on] in https://github.com/jenkinsci/acceptance-test-harness[the project], as always, so expect more stuff to come out from us in the coming days! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/05/get-drunk-on-the-code-in-juc-boston/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 5</div></div><h5 class="title">Get drunk on the code in JUC-Boston</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/christou.jpg[image] +

+
+

+
Let me start by introducing myself, my name is Steven Christou. Many of you might know me on IRC as schristou, my github id as https://github.com/christ66[christ66], or my twitter handle https://twitter.com/schristou88[@schristou88]. In Jenkins, I am currently working on some significant improvements to the subversion-plugin, along with various random bug fixes. I am also the current maintainer of https://cobertura.github.io/cobertura[Cobertura], an open source code coverage tool for java. Prior to working on Jenkins, I was working on Hudson at the Eclipse Foundation. +
 +

+
While working on Jenkins, I usually get requests (usually in IRC) about where to start when writing a plugin. Some examples are &quot;Where do I start?&quot; or &quot;Do you have any examples?&quot;. Well at https://www.cloudbees.com/jenkins/juc-2014/boston[JUC Boston], I will be hosting a small lecture called Get Drunk on the Code! I will be giving the lecture in the rooms &quot;Back Bay&quot; (1 &amp; 2) where people will be able to sit down, drink a beer, and learn how to write a Jenkins plugin! I will be teaching people everything from how to get started, to some advanced techniques like writing a new https://wiki.jenkins.io/display/JENKINS/Jenkins+CLI[CLI Command], and writing your own builder. I forgot to mention that I will be handing out beer while this is happening! +
 +

+
This session will be happening after the exhibit break from 3:30pm to 6:00pm. It will be two hours where I will be walking around, and helping users if they encounter any issues while the session is happening. So grab your laptop, a beer and get drunk on the code! Don&#x27;t get too drunk, but if you do at least you can improve the https://wiki.jenkins.io/display/JENKINS/Beer+Plugin[beer plugin]!&quot;<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/christ66/">Steven Christou</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/06/other-events-for-juc-visitors-cd-seminar/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 6</div></div><h5 class="title">Other events for JUC visitors: CD seminar</h5></div><p class="teaser">+ +

+
+

+
If you will be on the US East Coast or in Berlin for JUC, some of the JUC sponsors are organizing separate events called https://www.cloudbees.com/cdsummit[Continuous Delivery Seminar], which might be of interest to you. These events focus more on higher-level business value questions as well as vendor solutions that are difficult in community-focused JUC. +
 +

New York City on June 19, the day after JUC US East — headlined by Forrester Research analyst Kurt Bittner
+

Berlin on June 24, the day before JUC Europe — headlined by Jan Hagen, author of Confronting Mistakes: Lessons from the Aviation Industry when Dealing with Errors
+

+
+

+
Read more about the events https://blog.cloudbees.com/2014/06/cd-summit-learn-from-continuous.html[here]. The events are free and I&#x27;ve heard that there&#x27;ll be some souveniors. I&#x27;m one of the speakers, and I&#x27;ll be talking about Jenkins, as always! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/09/thinking-about-moving-on-to-servlet-3-0/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 9</div></div><h5 class="title">Thinking about moving on to Servlet 3.0</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Subaru_Legacy[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Subaru_Legacy_V_Kombi_rear_20100402.jpg/320px-Subaru_Legacy_V_Kombi_rear_20100402.jpg[image,width=240,height=156] +
] +

+
+

+
One of the current efforts under way in the dev list is driven by https://github.com/tfennelly[Tom Fennelly] et al, who is working on introducing a series of small ball improvements to the user interface in Jenkins. If this is something you are interested in (and who aren&#x27;t?), you should see https://gist.github.com/kevinburke/9d4f127a7005eaa9d970[Kevin Burke&#x27;s manifest] that sets out the plan of attack, and https://groups.google.com/forum/#!topic/jenkinsci-dev/zDaX4yiWLLw[This mega thread on the dev list] for the discussion. +
 +

+
There are numerous sub-conversations born out of this, and one of them is the minimum required servlet spec version for Jenkins. +
 +

+
Jenkins devs are thinking about ways to update page contents post load, for example so that the list view will keep updating as stuff happens. https://en.wikipedia.org/wiki/Websocket[WebSocket] was discussed as an option, and then https://en.wikipedia.org/wiki/Server-sent_events[server-side events], which seems to be the current favorite. +
 +

+
To use any of those async HTTP features, we need servlet 3.0. Unfortunately, if we are to do it, Jenkins will not run on earlier versions of the container. There&#x27;s no graceful fallback that works with servlet 2.5 containers due to the way servlet 3.0 is written. +
 +

+
So I looked into https://docs.google.com/spreadsheets/d/14YzFgKBB6BvbRU_1OjChC3efECWPs77TEGTU09t3KGw/edit#gid=873989456[the impact of this change to the users]. +
 +
It turns out that the most users run Jenkins through `+java -jar jenkins.war+`, which are already running servlet 3.0 compatible Winstone 2.x (based on Jetty 8.) And people running newer version of Jenkins tends to run newer version of containers. When I look at people who are running &gt;=1.509 and later, 70% of them run on servlet 3 compatible container. The number for &gt;=1.532 is 84%, then for &gt;=1.554 it&#x27;s 94%. +
 +

+
When I look at which container is dragging us down as of &gt;= 1.554, you see that there&#x27;s a sizable Tomcat6 deployments (2.5%). If we start requiring Servlet 3.0 these people will be in a nasty surprise. Then there&#x27;s about 1.8% who claims to be running on Winstone 0.9.10, which is really puzzling, but I&#x27;m assuming these people are getting OEM-ed Jenkins of a sort (multiple large companies are known to do this), so these people will likely be able to update to Winstone 2.x automatically by virtue of getting a new jenkins.war from their upstream. So all in all I&#x27;d say if we start requiring servlet 3.0 today, there&#x27;ll be about 3% user base who will be impacted. +
 +

+
This post is a trial balloon to see the community reaction to this idea. If you have reasons to argue against us moving to servlet 3.0, we&#x27;d like to hear from you — https://issues.jenkins.io/browse/JENKINS-23378[please share your thoughts on our issue tracker]! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/10/two-weeks-till-jenkins-user-conference-berlin/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">10</div></div><h5 class="title">Two Weeks Till Jenkins User Conference Berlin</h5></div><p class="teaser">Following right on the heels of our US-East Jenkins User Conference in Boston, we have JUC Europe in Berlin on June 25. Like the East Coast conference, the Berlin one is almost full, so sign up while you can.

Our venue in Berlin is KOSMOS, a building with a fascinating history. The building was inaugurated as a cinema in 1961. With 1001 seats, it was the largest, most modern and most popular film theatre in the former GDR and has since been extensively modernized in line with the requirements of historically listed buildings.

We have an excellent line-up of speakers filling up two conference tracks.

Once again, we have some fabulous sponsors to thank. Without them, there would be no JUC.

This year we’ve introduced a new Community sponsorship level, which allows non-corporate groups like JUGSs to help support the conference as well. (Drop a note to juc-oc-ext AT cloudbees DOT com if your group is interested).

We are very grateful to all of our sponsors – thank you! Hopefully see everyone at JUC.

PS – if you are coming to Berlin for JUC, check out the CD Summit on June 24 at the same venue. There’s also one on June 19 in NYC. The summit will focus on how continuous integration with Jenkins streamlines processes and automates testing and deployment, providing the foundation you need for continuous delivery.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/11/juc-speaker-sneakpeak-a-build-ecosystem-for-loosely-compiled-code/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">11</div></div><h5 class="title">JUC speaker sneakpeak: A build ecosystem for loosely compiled code</h5></div><p class="teaser">+

+
https://www.cloudbees.com/jenkins/juc-2014/boston/speakers#ForestHandford[ +
 +
image:https://jenkins-ci.org/sites/default/files/images/Forest_Handford_0.preview.jpg[image,width=240,height=320] +
 +
] +

+
 +
_We&#x27;re getting excited about the Boston and Berlin JUC&#x27;s in the next two weeks! Here&#x27;s a preview of Forest Handford&#x27;s upcoming JUC-US East Lightning Talk on June 18..._ +
 +
When https://home.meditech.com/en/d/home/[MEDITECH] migrated to Subversion from a home-grown first generation version control system we needed a way to get the code compiled and sent to the running server. We selected Jenkins as our build server, with the hope of eventually using it for CI. +
 +
A MEDITECH application consists of hundreds of source files. Each source file translates to an object code file that the interpreter executes. This is one of the last major projects I worked on prior to leaving MEDITECH to work at Carbonite. In my Lightning Talk, &quot;A Build Eco-System for Loosely Compiled Code,&quot; I&#x27;ll discuss the toughest challenges my team had in getting Jenkins to work as our build server and how we eventually overcame them. +
 +
Staff from both https://www.carbonite.com[Carbonite] and MEDITECH will be in attendance. Both companies are hiring! +
 +
_You&#x27;ll find more great talks in the full https://www.cloudbees.com/jenkins/juc-2014/boston[JUC-US East] agenda and the https://www.cloudbees.com/jenkins/juc-2014/berlin[JUC-Europe] agenda._<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/16/get-together-at-beer-garden-for-juc-berlin/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">16</div></div><h5 class="title">Get together at beer garden for JUC Berlin</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/-_Beer_garden_sign_-_Germany_-.jpg/160px--_Beer_garden_sign_-_Germany_-.jpg[image] +

+
+

+
There&#x27;ll be a number of active community people in the event, so let&#x27;s take advantages of that and meet up. And there&#x27;s no better place to do it than a beer garden in summer! +
 +

+
If you are coming to https://www.cloudbees.com/jenkins/juc-2014/berlin[JUC Berlin], I&#x27;ve just set up https://www.meetup.com/jenkinsmeetup/events/189413622/[an RSVP page for a beer garden get together the day before], and https://www.meetup.com/jenkinsmeetup/events/189405872/[another dinner afterward]. +
 +

+
Looking forward to seeing you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/19/juc-europe-sneak-peak-integrated-pipelines/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">19</div></div><h5 class="title">JUC Europe Sneak Peak: Integrated Pipelines</h5></div><p class="teaser">This is a guest post from Markos Rendell, a Senior Manager at Accenture.

+
https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions#MarkRendell[ +
 +
image:https://www.cloudbees.com/sites/default/files/juc/juc2014/berlin/Mark-Rendell.jpg[image,width=200,height=200] +
 +
] +

+
 +
I am very much looking forward to the Jenkins User Conference in Berlin next week which I will be attending with a three other members of my team. We are all very passionate about automation, infrastructure-as-code, configuration management and of course… Jenkins. +
 +
My team and I specialize in implementing continuous delivery for large scale transformation deliveries. We work with a wide range of technologies from open source, packaged products, through to software-as-a-service. We work with physical infrastructure, private cloud, public cloud and platforms-as-a-service, but there is one almost uniquely common factor… using Jenkins. +
 +
At the conference I will be expecting to exchange views with others using Jenkins at similar scale and am particularly interested in https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions#JosefFuchshuber[sessions] covering using Jenkins with Docker and making Jenkins https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions#HarpreetSingh[more resilient]. +
 +
I am also looking forward to presenting https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions#MarkRendell[this lightening talk] where I will be demoing ways in which we’ve extended Jenkins to implement complex integrated pipelines for large-scale software implementations. https://markosrendell.wordpress.com/2014/05/28/reducing-continuous-delivery-impedance-part-2-solution-complexity/[See here] for a sneak preview.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lisawells/">Lisa Wells</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/06/20/juc-boston-what-a-day/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">20</div></div><h5 class="title">JUC Boston, what a day!</h5></div><p class="teaser">+
https://twitter.com/BostonVC/status/479338642331426816[ +
image:https://pbs.twimg.com/media/Bqbz9JQIIAA9gKG.jpg[image,width=300,height=225] +
] +

+
+

+
We kicked off this year&#x27;s Jenkins User Conference world tour in Boston this Wednesday. The event was well-attended with more than 450 people registered and 400+ people showed up. So big thank you for everyone who came! +
 +

+
https://github.com/jenkinsci/workflow-plugin[Workflow plugin] that Jesse presented was a big hit and https://twitter.com/search?q=%23jenkinsconf&amp;src=typd[lit up twittersphere], and while I was only able to listen to parts of sessions as people had questions and comments for me, ones that I&#x27;ve seen were great. https://jenkins-ci.org/content/jenkins-user-conference-completely-full[Alyssa] told me that the sponsors were happy too, which is also important to keep events like this going. +
 +

+
Perhaps the biggest hit of all was https://jenkins-ci.org/content/get-drunk-code-juc-boston[the &quot;get drunk on the code show] by Steven Christou. When I got in, he packed 30 or so people in the room learning how to write a simple Jenkins plugin, and all the beer bottles were long gone! +
 +

+
One of the &quot;fun&quot; activities we did during the event was a trivia quiz. I&#x27;m happy to announce the winners here — Tamara from IBM and Prabhu from Staples. Congrats for your Amazon gift cards! +
 +

+
During the show, I&#x27;ve heard from several people that they&#x27;d love to see more regular local meet-ups. https://twitter.com/duncanmak[Duncan] had shown interest in organizing, and https://twitter.com/tyvole[Jesse] is a Bostonian, so please encourage them to get one going +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/01/jenkins-user-meet-up-in-london/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 1</div></div><h5 class="title">Jenkins User Meet-up in London?</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/London[image:https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/London_Big_Ben_Phone_box.jpg/179px-London_Big_Ben_Phone_box.jpg[image]] +

+
+

+
I&#x27;ll be visiting London in early September, and if possible I&#x27;d love to organize some get together of Jenkins users/devs. I wonder if anyone is interested in hosting the event? +
 +

+
I think it just needs to fit 20 or so people, so all we need is a single conference room somewhere in London. If you think you might be able to help, please drop us a note at http://lists.jenkins-ci.org/pipermail/jenkins-events/[the events list].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/01/jenkins-office-hours-dotci/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 1</div></div><h5 class="title">Jenkins Office Hours: dotCi</h5></div><p class="teaser">+
image:https://upload.wikimedia.org/wikipedia/commons/f/fe/Hangouts_Icon.png[image] +

+
+

+
Tomorrow in Jenkins office hours, Surya Gaddipati will be going over https://github.com/jenkinsci/dotci[DotCi], a package of features that integrates Jenkins closely with GitHub, configuration via .ci.yml file in source tree, built-in Docker support and MongoDB backend. +
 +

+
I think there&#x27;s a number of interesting pieces here that could be split into individual plugins for reuse, and possible alignment with existing efforts like https://wiki.jenkins.io/display/JENKINS/Script+Security+Plugin[Script Security plugin] or https://wiki.jenkins.io/display/JENKINS/Literate+Plugin[Literate plugin]. +
 +

+
To record the show, https://plus.google.com/events/cmatf87mb6cfo090e063l10709g[this event will be in a different hangout from the usual one], but https://www.timeanddate.com/worldclock/fixedtime.html?msg=Jenkins+Office+Hours&amp;iso=20140702T11&amp;p1=224&amp;ah=1&amp;sort=1[the time is the same]. Looking forward to seeing you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/03/jenkins-office-hours-dotci/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 3</div></div><h5 class="title">Jenkins Office Hours: dotCi</h5></div><p class="teaser">+
Surya walked us through https://github.com/jenkinsci/dotCI[the dotCI source code] yesterday, and a bunch of ideas about how to reuse pieces are discussed. The recording is on YouTube, and https://docs.google.com/document/d/1zXYOz9Zy-CLu2t8PgqIU0jMO8890PRNjPEAvlrx-HW8/edit#[my notes are here]. +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/03/jenkins-user-event-and-code-camp-2014-copenhagen/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 3</div></div><h5 class="title">Jenkins User Event &amp; Code Camp 2014, Copenhagen</h5></div><p class="teaser">+
This is a guest post from Adam Henriques. +
 +

+
+

+
On August 22nd Jenkins CI enthusiasts will gather in Copenhagen, Denmark for the 3rd consecutive year for a day of networking and knowledge sharing. Over the past two years the event has grown and this year we are expecting a record number of participants representing Jenkins CI experts, enthusiasts, and users from all over the world. +
 +

+
+

+
https://www.praqma.com/events/jcicph14[The Jenkins CI User Event Copenhagen] has become cynosure for the Scandinavian Jenkins community to come together and share new ideas, network, and harness inspiration from peers. The program offers invited as well as contributed speaks, tech talks, case stories, and facilitated Open Space discussions on best practice and application of continuous integration and agile development with Jenkins. +
 +

The Jenkins CI Code Camp 2014

+
+

+
The Jenkins CI User Event will be kicked off by https://www.praqma.com/events/jcicodecamp14[The Jenkins CI Code Camp] on August 21st, the day before the User Event. Featuring Jenkins frontrunners, this full day community driven event has become very popular, where Jenkins peers band together to contribute content back to the community. The intended audience is both experienced Jenkins developers and developers who are looking to get started with Jenkins plugin development. +
 +

+
For more information please visit the https://www.praqma.com/events/jcicph14[Jenkins CI User Event 2014, Copenhagen website]. +

+
image:https://www.praqma.com/sites/default/files/img/DSC_0045_scaled.jpg[image,scaledwidth=40.0%] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/03/juc-berlin-summary/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 3</div></div><h5 class="title">JUC Berlin summary</h5></div><p class="teaser">+
https://www.flickr.com/photos/12508267@N00/14555329583[image:https://farm4.staticflickr.com/3875/14555329583_c464879a8d_m.jpg[IMG_9194,width=240,height=160]] +

+
+

+
After a very successful https://jenkins-ci.org/content/juc-boston-what-day[JUC Boston] we headed over to Berlin for JUC Berlin. I&#x27;ve heard the attendance number was comparable to that of JUC Boston, with close to 400 people registered and 350+ people who came. +
 +

+
The event kicked off at https://www.meetup.com/jenkinsmeetup/events/189413622/[a pre-conference beer garden meetup], except it turned out that the venue was closed on that day and we had to make an emergency switch to another nearby place, and missed some people during that fiasco. My apologies for that. +
 +

+
But the level of the talks during the day more than made up for my failing. They covered everything from large user use cases from BMW to Android builds, continuous delivery to Docker, then of course workflow! +
 +

+
One of the key attractions of events like this is actually meeting people you interact with. There are https://twitter.com/fr3dg[all] the https://github.com/kutzi[usual] https://github.com/orrc[suspects] of the https://github.com/vlatombe[community], including https://github.com/daniel-beck[some who I&#x27;ve met for the first time]. +
 +

+
https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions[Most of the slides are up], and I believe the video recordings will be uploaded shortly, if you missed the event.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/03/pictures-from-juc-and-cdsummit/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 3</div></div><h5 class="title">Pictures from JUC and cdSummit</h5></div><p class="teaser">+
I&#x27;ve uploaded pictures I&#x27;ve taken during JUC Boston and JUC Berlin. +
 +

+
https://www.flickr.com/photos/12508267@N00/sets/72157645016261249/[JUC Berlin pictures] starts with pre-conference beer garden meet-up. See https://github.com/vlatombe[Vincent Latombe] gives a talk about https://wiki.jenkins.io/display/JENKINS/Literate+Plugin[Literate plugin]. I really appreciated his coming to this despite the fact that the event was only a few days before his wedding: +
 +

+
https://www.flickr.com/photos/12508267@N00/14512095456[image:https://farm6.staticflickr.com/5577/14512095456_7d592d5f9b_n.jpg[image,width=320,height=213]] +

+
+

+
In https://www.flickr.com/photos/12508267@N00/sets/72157645015219907/[JUC Boston pictures], you can see some nice Jenkins lighting effect, as well as my fellow colleague Corey Phelan using World Cup to lure attendees into a booth: +
 +

+
https://www.flickr.com/photos/12508267@N00/14555175333[image:https://farm3.staticflickr.com/2908/14555175333_48aa816387_n.jpg[IMG_8721,width=213,height=320]] +

+
+

+
https://www.flickr.com/photos/12508267@N00/14535019775[image:https://farm3.staticflickr.com/2939/14535019775_60e691c1dc_n.jpg[IMG_8745,width=320,height=213]] +

+
+

+
Pictures from https://www.cloudbees.com/cdsummit/[the cdSummits] are also available https://www.flickr.com/photos/12508267@N00/sets/72157645015519967/[here] and https://www.flickr.com/photos/12508267@N00/sets/72157645015398517/[here]. +
 +

+
If you have taken pictures, please share with us as your comment here so that others can see them.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/08/workflow-plugin-tutorial-writing-a-step-impl/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 8</div></div><h5 class="title">Workflow plugin tutorial: writing a Step impl</h5></div><p class="teaser">+
The other day I was explaining how to implement a new workflow primitive to https://github.com/vivek[Vivek Pandey], and I captured it as a recording. +
 +
 +
 +

+
The recording goes over how to implement the `+Step+` extension point, which is the workflow equivalent of `+BuildStep+` extension point. If you are interested in jumping on the workflow plugin hacking, this might be useful (and don&#x27;t forget to get in touch with us so that we can help you!) +
 +

+
image:https://www.thatvideogameblog.com/wp-content/uploads/2012/11/Link-Dangerous-to-Go-Alone.jpg[image,width=310,height=206] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/09/planned-changes-in-jenkins-user-conference-contact-information-collection/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 9</div></div><h5 class="title">Planned changes in Jenkins User Conference contact information collection</h5></div><p class="teaser">+ +

+
+

+
One of the challenges of running Jenkins User Conferences is to ballance the interest of attendees and the interest of sponsors. Sponsors would like to know more about attendees, but attendees are often weary of getting contacted. Our past few JUCs have been run by making it opt-in to have the contact information passed to sponsors, but the ratio of people who opt-in is too low. So we started thinking about adjusting this. +
 +

+
So our current plan is to reduce the amount of data we collect and pass on, but to make this automatic for every attendee. Specifically, we&#x27;d limit the data only to name, company, e-mail, and city/state/country you are from. But no phone number, no street address, etc. We discussed this in http://meetings.jenkins-ci.org/jenkins/2014/jenkins.2014-07-09-18.02.html[the last project meeting], and people generally seem to think this is reasonable. That said, this is a sensitive issue, so we wanted more people to be aware. +
 +

+
By the way, https://www.cloudbees.com/forms/jenkins-user-conference-call-papers.cb[the call for papers to JUC Bay Area] is about to close in a few days. If you are interested in giving a talk (and that&#x27;s often the best way to get feedback and take credit on your work), please make sure to submit it this week. +
 +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/18/juc-israel-report/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">18</div></div><h5 class="title">JUC Israel report</h5></div><p class="teaser">+
This year marks the 3rd annual Jenkins User Conference in Israel. While the timing of the event turned out to be less than ideal for reasons beyond our control, that didn&#x27;t stop 400 Jenkins users from showing up at the &quot;explosive&quot; event at a seaside hotel near Tel Aviv. +
 +

+
https://twitter.com/shlomibenhaim[Shlomi Ben-Haim] kicked off the conference by reporting that JUC Israel just keeps getting bigger, and that we sold out 2 weeks earlier and the team had to turn down people who really wanted to come in. The degree of adoption of Jenkins is amazing in this part of the world, and we might have to find a bigger venue next year to accomodate everyone who wants to come. +
 +

+
https://www.flickr.com/photos/12508267@N00/14497395798[image:https://farm6.staticflickr.com/5562/14497395798_52a7c92866_n.jpg[IMG_9716,width=320,height=213]] +

+
+

+
It turns out most of the talks were in Hebrew, so it was difficult for me to really understand what&#x27;s going on, but the talks ranged from highly technical ones like how to provision Jenkins from configuration management (the server as welll as jobs), all the way to more culture focused one like how to deploy CD practice in an organization. Companies large and small were well represented, and I met with a number of folks who actively contribute to the community. +
 +

+
There were a lot of hall way conversations, and those of us at the booth had busy time. +
 +

+
Thanks everyone who came, thanks JFrog for being on the ground for the event (and congratulations for the new round of funding) and CloudBees for hosting the event. Please let us know if there are things we can do better, and see you again next year! +
 +

+
https://www.flickr.com/photos/12508267@N00/14680851721[image:https://farm4.staticflickr.com/3903/14680851721_fd36aac023_n.jpg[IMG_9777,width=320,height=213]]

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/28/jenkins-figure-is-available-in-shapeways/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">28</div></div><h5 class="title">Jenkins figure is available in shapeways </h5></div><p class="teaser">+
Some time ago, we&#x27;ve built https://jenkins-ci.org/content/behind-scenes-jenkins-user-conference-palo-alto[Jenkins bobble head figures]. This was such a huge hit that everywhere I go, I get asked about them. The only problem was that it cannot be individually ordered, and we didn&#x27;t have enough cycles to individually sell and ship them for those who wanted them. +
 +

+
So I decided to have the 3D model of Mr.Jenkins built, which would allow anyone to print them via 3D printer. I comissioned https://www.fast-d.com/search/engineers/2798[akiki], a 3D model designer, to turn our beloved butler into a fully-digital color-printable figure. He was even kind enough to discount the price with the understanding that this is for an open-source project. +
 +

+
The result was IMHO excellent, and when I finally came back to my house yesterday from a two-weeks trip, I found it delivered to my house: +
 +

+
image:https://images1.sw-cdn.net/model/picture/625x465_2183445_3844009_1406574114.jpg[image,width=312,height=232] +

+
 +
With the red bow tie, a napkin, a blue suit, and his signature beard, it is instantly recognizable as Mr.Jenkins. He&#x27;s mounted on top of a red base, and is quite stable. I think the Japanese sensibility of the designer is really showing! Note that https://www.shapeways.com/materials/full-color-sandstone[the material] has a rough surface and it is not very strong, but that&#x27;s what you trade to get full color. +
 +

+
https://www.shapeways.com/model/2183445/mr-jenkins.html?modelId=2183445&amp;materialId=26[I&#x27;ve put it up on Shapeways so that you can order it yourself]. The figure is about 2.5in/6cm tall. The price includes a bit of markup toward recovering the cost of the design. My goal is to sell 25 of them, which will roughly break it even. Any excess, if it ever happens, will be donated back to the project. +
 +

+
Likewise, once I hit that goal, I will make the original data publicly available under CC-BY-SA, so that other people can modify the data or even print it on their own 3D printers. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/07/30/geek-choice-awards-2014/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">30</div></div><h5 class="title">Geek Choice Awards 2014</h5></div><p class="teaser">+
image:https://wiki.jenkins.io/download/attachments/58000204/Geek-Choice-Awards-CI-Server-300x300-black.png?version=1&amp;modificationDate=1406550449057[image,width=100,height=100] +

+
+

+
RebelLabs started annual https://zeroturnaround.com/rebellabs/10-kick-ass-technologies-modern-developers-love/12/[Geek Choice Awards], and Jenkins was one of the 10 winners. See https://zeroturnaround.com/rebellabs/10-kick-ass-technologies-modern-developers-love/6/[the page they talk about Jenkins]. +
 +

+
My favorite part is, to quote, &quot;Jenkins has an almost laughably dominant position in the CI server segment&quot;, and &quot;With 70% of the CI market on lockdown and showing an increasing rate of plugin development, Jenkins is undoubtably the most popular way to go with CI servers.&quot; +
 +

+
image:https://zeroturnaround.com/wp-content/uploads/2014/07/continuous-integration-server.jpg[image] +

+
+

+
If you want to read more about it and other 9 technologies that won, https://pages.zeroturnaround.com/Kickass-Technologies.html[they have produced a beautifully formatted PDF] for you to read.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/08/11/user-interface-refresh/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">11</div></div><h5 class="title">User Interface Refresh</h5></div><p class="teaser">+
This is a guest post from https://github.com/tfennelly[Tom Fennelly] +

+
+

+
Over the last number of weeks we&#x27;ve been trying to &quot;refresh&quot; the Jenkins UI, modernizing the look and feel a bit. This has been a real community effort, with collaboration from lots of people, both in terms of implementation and in terms of providing honest/critical feedback. Lots of people deserve credit but, in particular, a big thanks to https://github.com/kevinburke[Kevin Burke] and https://github.com/daniel-beck[Daniel Beck]. +
 +

+
You&#x27;re probably familiar with how the Jenkins UI currently looks, but for the sake of comparison I think it&#x27;s worth showing a screenshot of the current/old UI alongside a screnshot of the new UI. +
 +

+
https://jenkins-ci.org/sites/default/files/images/current.png[ +
image:https://jenkins-ci.org/sites/default/files/images/current.preview.png[image,width=500] +
] +

+
*_Current / Old Look &amp; Feel_* +

+
https://jenkins-ci.org/sites/default/files/images/new.png[ +
image:https://jenkins-ci.org/sites/default/files/images/new.preview.png[image,width=500] +
] +

+
*_New Look &amp; Feel_* +

+
+

+
Among other things, you&#x27;ll see: +

A new responsive layout based on elements (as opposed to elements). Try resizing the screen or viewing on a smaller device. More to come on this though, we hope.

Updated default font from Verdana to Helvetica.

Nicer form elements and nicer buttons.

Smoother side panels e.g. Build Executors, Build Queues and Build History panes.

Smoother project views with more modern tabs.

+
+

+
You might already be seeing these changes if you&#x27;re using the latest and greatest code from Jenkins. If not, you should see them in the next LTS release. +
 +

+
We&#x27;ve been trying to make these changes without breaking existing features and plugins and, so far, we think we&#x27;ve been successful but if you spot anything you think we might have had a negative effect on, then https://issues.jenkins.io[please log a JIRA] and we&#x27;ll try to address it. +
 +

+
One thing we&#x27;ve &quot;sort of&quot; played with too is cleaning up of the Job Config page - breaking into sections and making it easier to navigate etc. This is a big change and something we&#x27;ve been shying away from because of the effect it will have on plugins and form submission. That said, I think we&#x27;ll need to bite the bullet and tackle this sooner or later because it&#x27;s a big usability issue. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/08/12/jenkins-user-meet-up-in-london/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">12</div></div><h5 class="title">Jenkins User Meet-up in London</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/London[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Black_London_Cab.jpg/320px-Black_London_Cab.jpg[image] +
] +

+
+

+
https://jenkins-ci.org/content/jenkins-user-meet-london[As I was alluding to earlier], I was hoping to have a meetup of Jenkins users in London for a while. I&#x27;m happy to report that https://www.meetup.com/jenkinsmeetup/events/198004202/[the agenda is final and RSVP is open]! The date is September 8th. +
 +

+
I&#x27;ll talk about my recent chef/puppet integration work in Jenkins. Sven from Perforce will talk about how to leverage Perforce features from Jenkins, and then James Nord will talk about workflow. It will be a worthy 2 hours. +
 +

+
If the line up of talks will not be enough to sway you, you should also know that I will bring some Jenkins give-aways! +
 +

+
I&#x27;m not sure how many people to expect, but there&#x27;s a cap at 80 people, so if you are thinking about coming, https://www.meetup.com/jenkinsmeetup/events/198004202/[be sure to RSVP]. Looking forward to seeing many of you there! +
 +

+
Finally, if you are in London, the usual suspects (CloudBees, PuppetLabs, XebiaLabs, MidVision, SOASTA, et al) are doing https://www.eventbrite.com/e/how-to-accelerate-innovation-with-continuous-delivery-london-tickets-12229265061[a free event titled &quot;How To Accelerate Innovation with Continuous Delivery&quot;] that you might also be interested in.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/08/12/official-jenkins-lts-docker-image/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">12</div></div><h5 class="title">Official Jenkins LTS docker image</h5></div><p class="teaser">+
(This is a guest post from https://twitter.com/michaelneale[Michael Neale]) +

+
+

+
Recently at the Docker Conference (DockerCon) the https://hub.docker.com[Docker Hub] was announced.

+
+

The hub (which includes their image building and storage service) also provides some &quot;official&quot; images (sometimes they call them repositories - they are really just sets of images).

+
So after talking with all sorts of people we decided to create an official https://registry.hub.docker.com/_/jenkins/[Jenkins image] - which is hosted by the docker hub simply as &quot;jenkins&quot;.

+
+

So when you run &quot;docker pull jenkins&quot; - it will be grabbing this image. This is based on the current LTS (and will be kept up to date with the LTS) - but does not include the weekly releases (yet). Having a jenkins image that is fairly basic (it includes enough to run some basic builds, as well as jenkins itself) built on the LTS, on the latest LTS of Ubuntu seemed quite convenient - and easy to maintain using the official Ubuntu/Debian packaging of Jenkins.

+

+
Docker is a great way to try and use server based systems - it brings all the dependencies needed and the images actually are portable (ie anywhere docker runs you can run docker images). There are official images for many popular server platforms (redis, mysql, all the linux distros and so on) so it seemed crazy to not include Jenkins along with this list. +
&quot;docker run -p 8080:8080 jenkins&quot; is all you need to get going with LTS Jenkins now. +
You can also use &quot;docker run jenkins:1.554&quot; to get the latest of that lineage of LTS releases, or pick a specific one: &quot;docker run jenkins:1.554.3&quot; if you like. Leaving off a version assumes the latest. Check the https://registry.hub.docker.com/_/jenkins/tags/manage/[tags] page to see what is available. +

+
+

+
You can read more and see how you https://registry.hub.docker.com/_/jenkins/[can use it here.] +

+
+

+
There has been some questions and discussions on how to make use of Jenkins with the docker hub for creating new and interesting docker image based workflows for deployment. +
In fact, Jenkins featured in one of the first slides of the first keynote of docker con: +
 +
image:https://3.bp.blogspot.com/-qAC-f6ceVho/U5rfqpzj3VI/AAAAAAAAC8w/Ta4pzEhm-8A/s1600/Screen+Shot+2014-06-13+at+8.34.10+pm.png[image] +
 +
To make this dream a reality some additional https://wiki.jenkins.io/display/JENKINS/DockerHub+Plugin[plugins] had to be created - but this leaves the possibility of working with the docker hub (builds, stores images) and Jenkins (workflow, testing, deployment) to build out some kind of a continuous pipeline for handling docker based apps. I attempted to describe this more https://developer-blog.cloudbees.com/2014/07/announcing-dockerhub-jenkins-plugin.html[here]. +

+
+

+
This image is maintained in this github https://github.com/cloudbees/jenkins-ci.org-docker[repo] and the official images are build by the https://github.com/docker/stackbrew[&quot;stackbrew&quot; system]. (We may move this repo to the jenkinsci github group shortly so keep an eye out). +

+
+

It will be interesting to watch this grow and change.

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/08/28/juc-sf-2014-is-here/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">28</div></div><h5 class="title">JUC SF 2014 is Here!</h5></div><p class="teaser">+
https://www.cloudbees.com/event/juc/2014/san-francisco[JUC SF] on October 23, 2014 is shaping up to be bigger and better this year. +

+

+
Here’s what we have in store for you! +

+

Three Tracks

+

+
We’ve received a record high of 40 stellar proposals this year. To accommodate the many community proposals, we’ve decide to add a third track to the +
agenda. https://www.cloudbees.com/event/juc/2014/san-francisco[JUC SF sessions] are now available for you to view. We have speakers from Google, +
Target, Gap, Cloudera, Ebay, Chicago Drilling Company, and much more. https://www.eventbrite.com/e/jenkins-user-conference-us-west-san-francisco-oct-23-2014-tickets-10558684309[Register now] for early bird price. +
The early bird price is only good until September 21, 2014. +

+

Live Stream

+

+
If you can’t attend the conference in person, https://www.cloudbees.com/event/juc/2014/san-francisco[Track 1] sessions will be available via live +
stream, it’s all free. Brought to you by CloudBees. Registration for JUC SF live stream is https://www.eventbrite.com/e/jenkins-user-conference-us-west-san-francisco-live-stream-tickets-12240011203[here]. +

+

Get Drunk on Code

+

+
Have a beer while learning how to write Jenkins plugin. Steve Christou, Jenkins support engineer will lead this lecture from 3:30pm to 6:00pm. He will +
teach everything from how to get started, to techniques like writing a new https://wiki.jenkins.io/display/JENKINS/Jenkins+CLI[CLI Command], to writing your own builder. +

+

Ask the Experts

+

+
Meet the Jenkins creator, committers, support engineers, and developers. We have dedicated time slot(s) for our attendees to get 1 on 1 access to our +
experts. Exact time is TBD. Ask them anything from plugins, configuration, technical support, to bug fixes. +

+

+
Our current list of experts are: +

+

+
Andrew Bayer

+
Gareth Bowles

+
Steve Christou

+
Jesse Glick

+
Kohsuke Kawaguchi

+
Dean Yu

+

+
Want to join our panel of experts? Contact Alyssa Tong aly13@gmail.com +

+

Exhibit Mixer

+

+
Sixteen technology https://www.cloudbees.com/event/juc/2014/san-francisco[sponsors] will be showcasing their newest technologies during +
the exhibition hour from 2:25 – 3:30pm. Grab a beer, visit with sponsors and see how they are using Jenkins. +

+

+
This is just a taste of what you’ll see at JUC SF. We look forward to seeing you there!! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/08/28/workflow-plugin-code-walk-through/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">28</div></div><h5 class="title">Workflow plugin code walk-through</h5></div><p class="teaser">Jesse and I will walk through the source code of the workflow plugin, highlights key abstractions and extension points, and discuss how they are put together.

If you are interested in developing or retrofitting plugins to work with workflows, I think you’ll find this session interesting.

The event will be on Google Hangout tomorrow. The time of the day is the same as usual office hours.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/09/17/jenkins-workflow-summit-rsvp/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">17</div></div><h5 class="title">Jenkins Workflow Summit RSVP</h5></div><p class="teaser">+
https://groups.google.com/forum/#!msg/jenkinsci-dev/qY387kOQlW8/vaBxacXYhGwJ[As was discussed some time ago], the workflow summit is being organized, and it&#x27;s open for RSVP. +
 +

+
Due to the overwhelming demand, I&#x27;ve increased the capacity this time to 50, but this is an unconference where everyone needs to participate, which means we really cannot have too many people without changing the dynamics of the event. +
 +

+
So please make sure you are willing to participate, as in not just listening and watching, but actually willing to speak. We expect you to bring something to the table — opinions, experiences, rants, presentations, feedbacks, etc. If you don&#x27;t please let others take the seat, and rest assured we will give a presentation about workflow in https://wiki.jenkins.io/display/JENKINS/Jenkins+User+Conference+US+West+%28San+Francisco%29+Oct+23%2C+2014+-+Agenda[JUC Bay Area]. +
 +

+
If you understand the criteria, https://www.meetup.com/jenkinsmeetup/events/203777932/[please RSVP is from here]. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/09/02/jenkins-user-meet-up-in-paris/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 2</div></div><h5 class="title">Jenkins User Meet-up in Paris</h5></div><p class="teaser">+ +

+
+

+
My apologies for the last minute announcement, but there will be a https://www.meetup.com/jenkinsmeetup/events/203261692/[Jenkins user meet-up in Paris on Sep 10th 7:00pm], which is just next week. The event is hosted by Zenika. You&#x27;ll hear from https://twitter.com/gboissinot[Gregory Boissinot] and https://twitter.com/alecharp[Adrien Lecharpentier] about plugin development, and I&#x27;ll be talking about workflow. +
 +

+
It&#x27;s been a while we do a meet-up in Paris. Looking forward to seeing as many of you as possible. The event is free, but https://www.meetup.com/jenkinsmeetup/events/203261692/[please RSVP] so that we know what to expect.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/09/24/jenkins-in-javaone-2014/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">24</div></div><h5 class="title">Jenkins in JavaOne 2014</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/JavaOne.png[image] +

+
+

+
There&#x27;ll be several talks that touch Jenkins. The first is from me and Jesse called https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=3387[Next Step in Automation: Elastic Build Environment [CON3387]] Monday 12:30pm. +
 +

+
Then later Tuesday, there&#x27;s https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=11237[Building a Continuous Delivery Pipeline with Gradle and Jenkins [CON11237]] from Benjamin Muschko of Gradleware. +
 +

+
Thursday has several Jenkins talks. One is https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1880[The Deploy Factory: Open Source Tools for Java Deployment [CON1880]] from Bruno Souza (aka the Java Man from Brazil) and Edson Yanaga. In this same time slot, guys from eBay are doing https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=5685[Platform Upgrades as a Service [CON5685]], which discusses how they rely on automation to make platform upgrades painless. Then https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1844[Mastering Continuous Delivery and DevOps [CON1844]] from Michael Huttermann. +
 +

+
In https://www.oracle.com/javaone/exhibit.html[the exhibit area], the Jenkins project doesn&#x27;t have its own booth (JavaOne is too expensive for that), but I&#x27;ll be at https://www.oracle.com/us/assets/javaone-14-hilton-exhibits-2023244.pdf[the CloudBees booth], so is Jesse Glick. Find us at the booth for any Jenkins questions or impromptu hacking session, which would really help us as we get distracted from the booth duties that way. Or just drop by to get stickers, pin badges, and other handouts to take for your colleagues. +
 +

+
And finally, https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=2939[Script Bowl 2014: The Battle Rages On [CON2939]] gets an honorable mention because https://twitter.com/agentdero[our own Tyler Croy] is representing JRuby against other scripting languages, including my favorite Groovy. Hmm, who should I root for...<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javaone">javaone</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/09/24/more-jenkins-related-continuous-delivery-events-in-chicago-washington-dc-and-san-francisco/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">24</div></div><h5 class="title">More Jenkins-related continuous delivery events in Chicago, Washington DC, and San Francisco</h5></div><p class="teaser">+

+
+

+
The usual suspects, such as CloudBees, XebiaLabs, SOASTA, PuppetLabs, et al are https://www.cloudbees.com/cdsummit/[doing a Jenkins-themed continuous delivery event series] called &quot;cdSummit.&quot; The event is free, has a nice mix of user/vendor talks, and has an appeal to managers and team leads who are working on and struggling with continuous delivery and automation. +
 +

+
I&#x27;ve spoken in the past events, and I enjoyed the high-level pitches from various speakers. +
The last two events at Paris and London filled up completely, so I suspect others have liked them, too. +
 +

+
If you live near Chicago, Washington DC, or San Francisco, check out the date and see if you can make it. https://www.cloudbees.com/cdsummit/[RSVP is from here]. If you do, be sure to pick up Jenkins stickers and pin badges!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/09/25/cve-2014-6271-impact-on-jenkins/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">25</div></div><h5 class="title">CVE-2014-6271 impact on Jenkins</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Road_signs_in_Singapore[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Singapore_Road_Signs_-_Restrictive_Sign_-_Stop_-_Security_Check.svg/240px-Singapore_Road_Signs_-_Restrictive_Sign_-_Stop_-_Security_Check.svg.png[image] +
]

+
+

+
I suspect many of you have been impacted by https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6271[CVE-2014-6271] (aka &quot;shellshock&quot; bash vulnerability.) We had our share of updates to do for various *.jenkins-ci.org servers. +
 +

+
Java application servers in general (including one that ships in Jenkins) do not fork off processes like Apache does to serve requests, so the kind of CGI attacks you see on Apache does not apply. We are currently unaware of any vulnerabilities in Jenkins related to CVE-2014-6271, and no plan to issue a patch for that. +
 +

+
That said, we did come up with one possible way attackers can exploit vulnerable bash through Jenkins, that you might want to be aware of. +
 +

+
When a build is parameterized, parameters are passed to the processes Jenkins launch as environment variables. So if you have a shell step (which uses `+bash+` by default), and if Eve only has a BUILD permission but not CONFIGURE permission, then Eve can exploit this vulnerability by carefully crafting parameter values, and have the bash runs arbitrary processes on the agent that run the build. +
 +

+
In most such scenarios, Eve would have to be an authenticated user on Jenkins. Jenkins also leaves the record of who triggered what build with what parameters, so there&#x27;s an audit trail. But if your Jenkins fits this description, hopefully this serves as one more reason to update your bash. +
 +

+
Finally, to get notified of future security advisories from Jenkins, see https://wiki.jenkins.io/display/JENKINS/Security+Advisories[this Wiki page].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/10/06/gradle-fy-your-jenkins-plugin-project/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 6</div></div><h5 class="title">Gradle-fy your Jenkins Plugin Project</h5></div><p class="teaser">(This is a guest post from Daniel Spilker)

Jenkins supports building plugins using Gradle for a while now. Last week a new version of the Gradle JPI plugin has been released to iron out some issues.

The Gradle JPI plugin enables a 100% groovy plugin development environment with Groovy as primary programming language, Spock for writing tests and Gradle as build system. Have a look at the Job DSL plugin for an example.

An existing Maven build can be converted to Gradle by using the build.gradle template from the Gradle JPI plugin’s README. For instance, the POM from the Gradle plugin translates to this build.gradle file:

buildscript {
    repositories {
        mavenCentral()
        maven {
            url &#x27;https://repo.jenkins-ci.org/releases/&#x27;
        }
    }
    dependencies {
        classpath &#x27;org.jenkins-ci.tools:gradle-jpi-plugin:0.6.0&#x27;
    }
}

apply plugin: &#x27;jpi&#x27;

group = &#x27;org.jenkins-ci.plugins&#x27;
version = &#x27;1.25-SNAPSHOT&#x27;

jenkinsPlugin {
    coreVersion = &#x27;1.480&#x27;
    displayName = &#x27;Jenkins Gradle plugin&#x27;
    url = &#x27;https://wiki.jenkins.io/display/JENKINS/Gradle+Plugin&#x27;
    gitHubUrl = &#x27;https://github.com/jenkinsci/gradle-plugin&#x27;

    developers {
        developer {
            id &#x27;gbois&#x27;
            name &#x27;Gregory Boissinot&#x27;
            timezone &#x27;+1&#x27;
        }
    }
}

dependencies {
    compile &#x27;org.jenkins-ci.lib:dry-run-lib:0.1&#x27;
}

Usage of the Gradle JPI plugin is similar to working with the Maven HPI plugin. Use gradle jpi to build the plugin file. gradle check runs the tests, gradle install copies the plugin into the local Maven repository, gradle uploadArchives deploys the plugin to the Jenkins Maven repository and gradle server starts a Jenkins development server with the plugin installed.

It is recommended to use Gradle 1.8 because that is the version used to build and test the Gradle JPI plugin.

For the next release it is planned to do some maintenance like fixing code style issues and adding tests. After that more issues need to be addressed to bring the plugin on par with the Maven HPI plugin, most notably fixing the test dependencies ( JENKINS-17129) and publishing the plugin’s JAR ( JENKINS-25007). Updating Gradle to 2.x and getting the plugin on the Gradle plugin portal is also on the wishlist.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/10/15/cve-2014-3566-poodle-impact-on-jenkins/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">15</div></div><h5 class="title">CVE-2014-3566 &quot;poodle&quot; impact on Jenkins</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Poodle[image:https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Freddie_%288467901543%29.jpg/160px-Freddie_%288467901543%29.jpg[image]] +

+
+

+
Another day, another SSL vulnerability! Google has https://poodle.io/[announced a vulnerability in SSL v3], and if you are using the &quot;Winstone&quot; servlet container built into Jenkins, and if you are using the HTTPS connector with the `+--httpsPort+` option (it is off by default), then you are vulnerable to this problem. +
 +

+
I&#x27;ve just issued link:/security/advisory/2014-10-15/[a security advisory] on this. If you haven&#x27;t already subscribed to https://wiki.jenkins.io/display/JENKINS/Security+Advisories[the Jenkins security advisory mailing list], this is a great opportunity to do so. +
 +
 +

+
The advisory includes the target delivery vehicles for the fix and how you can address the problem in the mean time. Inside corporate intranet, where Jenkins is typically used, I suppose there&#x27;s a degree of trust among participants to make this less of a problem. But if you run an internet facing Jenkins, be sure to deploy the fix. +
 +
 +

+
(And as I write this, I&#x27;ve fixed all the `+https://*.jenkins-ci.org+` servers to disable SSLv3, so we are covered there)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/10/20/freebsd-project-use-of-jenkins-for-os-testing/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">20</div></div><h5 class="title">FreeBSD project use of Jenkins for OS testing</h5></div><p class="teaser">This is a guest post by Craig Rodrigues

The FreeBSD project produces a modern operating system derived from BSD Unix.

In the past 6 months, we have set up Jenkins at https://jenkins.freebsd.org/, to continuously build FreeBSD as developers add new code to the project. This has helped us identify and fix build breaks very quickly.

We have gone even farther by integrating Jenkins, Kyua,
and Bhyve.
Kyua is a testing framework for infrastructure software.
Bhyve is the native hypervisor that comes with FreeBSD (similar to KVM on Linux).

We use the Build Flow plugin in this example Build flow to do the following:

Build the FreeBSD kernel and userland on amd64 whenever someone checks in new code to https://svn.freebsd.org

Create a bootable FreeBSD disk image with makefs

Boot the image under bhyve

Run these commands inside the bhyve VM:

cd /usr/tests; kyua test; kyua report-junit --output=test-output.xml

Shut down the bhyve VM

Imports test-output.xml into Jenkins.

Produces a full native test report in Jenkins

The results of this work were presented at the Bay Area FreeBSD Users Group
in this presentation in October 2014.

Jenkins has been very easy to set up and use under FreeBSD.   We hope that by using
Jenkins to run OS-level unit tests, we will be able to improve the quality of FreeBSD.
For further information, please feel free to contact us at freebsd-testing@FreeBSD.org.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/10/20/mobile-app-for-jenkins-user-conference-bay-area/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">20</div></div><h5 class="title">Mobile App for Jenkins User Conference Bay Area</h5></div><p class="teaser">+
Jenkins User Conference in Bay Area is this Thursday, and one of the new things this year is the mobile app. +
 +

+
https://doubledutch.me/download/jenkins-user-conference[ +
image:https://dl.doubledutch.me/images/downloadiphone.png[image,width=253,height=532] +
] +

+
+

+
There&#x27;s an Android version as well as an iPhone version. I&#x27;ve installed it locally, and it&#x27;s very handy for checking the agenda, get more info about speakers and sponsors.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/12/03/workflow-plugin-is-1-0/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 3</div></div><h5 class="title">Workflow plugin is 1.0</h5></div><p class="teaser">Jenkins started with a notion of jobs and builds at heart. One script is one job, and as you repeatedly execute jobs, it creates builds as records. As the use case of Jenkins gets more sophisticated, people started combining jobs to orchestrate ever more complex activities.

A number of plugins have been developed to enable all sorts of different ways to compose jobs, and many are used quite successfully in production. But this resulted in a certain degree of complexity for users to figure out how to assemble these plugins.

So we felt the need to develop a single unified solution that subsumes all these different ways to orchestrate activities that may span across multiple build agents, code repositories, etc. Various inputs from users as well as other plugin developers played a key role.

The result of this is the workflow plugin, which is what a number of us, including Jesse Glick an myself, are focused on in the past few months.

The plugin approaches the problem by defining a DSL for you to describe an execution of a job. Various convenient primitives are available, such as executing shell scripts, checking out the source code, obtaining an executor or a build workspace, etc. All sorts of classic existing plugins contribute their functionalities into this DSL, such as recording test results, fingerprints, or calling into other existing jobs. This allows you to leverage higher-level functionalities and report comprehension capability into a workflow. Similarly, you can leverage the ability of Groovy, the host language of workflow DSL, to define control flows, abstractions, and reuse.

A key feature of a workflow execution is that it’s suspendable. That is, while the workflow is running your script, you can shut down Jenkins or lose a connectivity to a agent. When it comes back, Jenkins will still remember what it was doing, and your workflow script resumes execution as if it was never interrupted. A technique known as the &quot; continuation-passing style&quot; execution plays a key role in achieving this.

I’m very happy to report that the workflow plugin is finally 1.0. This version runs on the latest 1.580-based LTS. and we created a docker image for you to play with too. There’s also a JUC presentation that explains this. We are working toward 1.0 release within this year, and in the meantime, the syntax is stable enough to allow you to start designing workflows today.

We’ve been hearing a lot of good feedbacks and enthusiasm for this new effort. Please let us know what you think.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/12/17/breakingbuilds/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">17</div></div><h5 class="title">#BreakingBuilds</h5></div><p class="teaser">+
A lot of us has grown fond of our loyal butler Mr.Jenkins over time, which was created by https://frontside.io/[Frontside] and chosen as https://jenkins-ci.org/content/the-polls-are-open-for-the-jenkins-logo-contest[a result of a logo contest]. In the true open-source style, the logo has since evolved into many different derivative works, such as https://wiki.jenkins.io/display/JENKINS/Emotional+Jenkins+Plugin[a plugin], https://jenkins-ci.org/content/jenkins-figure-available-shapeways[a 3D model], and https://jenkins-ci.org/content/behind-scenes-jenkins-user-conference-palo-alto[a bobble head]. +
 +

+
Our friends at CloudBees are running a https://twitter.com/search?q=%23BreakingBuilds[#BreakingBuilds] social media contest through Jan 5th to have some fun with Mr.Jenkins. https://ow.ly/FbZDb[Read Sacha Labourey&#x27;s blog post], where he draws parallels between what a butler does and what continuous delivery can do. +
 +

+
I especially agree with him on this point: +
 +

+
I always loved the idea of using a butler to represent what Jenkins is about, as it projects all of the qualities that define continuous delivery: it is built to be proactive, it will help you fix problems before they happen, it orchestrates your entire pipeline to production without you having to worry about the sophisticated underlying sequence of steps and, if things go wrong Jenkins uses his fingerprint database to trace back the source of the issue. Full service. As your right arm, Jenkins is the reliable and trustworthy guy you want on your team! +

+
+

+
https://ow.ly/FdEBD[Check out the contest rules] and participate. Let&#x27;s raise the visibility of Jenkins and have some fun in the process! +
 +

Read Sacha’s blog

Learn more about the contest and how to win Jenkins prizes

Go directly to the #BreakingBuilds images

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/01/27/2015-jenkins-user-conferences-call-for-papers/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">27</div></div><h5 class="title">2015 Jenkins User Conferences - Call for Papers</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Ballot_box[ +
image:https://upload.wikimedia.org/wikipedia/commons/9/99/Cardboard_ballot_box_-_Smithsonian.jpg[image,width=200]] +

+
+

+
The Jenkins User Conference 2015 is https://www.cloudbees.com/jenkins-user-conference-call-papers[seeking submissions] that reflect the latest innovations in Jenkins usage. This is your chance to educate, share and inspire the community with stories of how you&#x27;ve used Jenkins to continuously build that amazing project or how you developed that popular plugin that everyone is using. +
 +

+
If you&#x27;re gamed, here are some suggestions to get your creative juice going: +
 +

Scaling Jenkins within the enterprise

Jenkins as the orchestrator for continuous delivery

Plug-in development

Jenkins techniques that solve testing/building problems in specific application areas: mobile, enterprise/web/cloud and UI testing

War stories that speak to a problem you faced, the Jenkins solution you implemented to solve it and the results you realized

Jenkins best practices, tips and tricks

Jenkins in the cloud - if you or your company is currently using Jenkins in the cloud we’d love to hear your story

Beyond Java (Jenkins with PHP, Ruby, etc.)

+
+

+
We are upping the ante at this year&#x27;s JUCs. We are moving from a 1 day conference to a 2 days conference for SF and London - that&#x27;s 18 additional cutting edge sessions to be learned. +
 +

+
https://www.cloudbees.com/jenkins-user-conference-call-papers[*SUBMISSION DEADLINE IS MARCH 8, 2015!*] +
 +

+
There&#x27;s also a wide variety of event sponsorship opportunities available. There are offerings from Gold to Silver packages, exhibitor packages in our world-class expo hall, speaking sessions, free passes, and many branding opportunities. For inquiries, pls contact juc-sponsorship@cloudbees.com +
 +

+
Looking forward to receiving your amazing proposals!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/01/27/office-hours-tomorrow-workflow-security-model-and-plugin-compatibility/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">27</div></div><h5 class="title">Office Hours tomorrow: workflow security model &amp; plugin compatibility</h5></div><p class="teaser">+
https://plus.google.com/events/c4eagqodepqojlrv7glhc1ctg48[In tomorrow&#x27;s Jenkins office hours], Jesse Glick will talk about two topics in the workflow plugin that he has been asked about: +
 +

Security model: script security, permissions

Plugin compatibility: SimpleBuildStep and friends, custom steps, etc.

+
+

+
The session should be interesting to anyone using workflow or thinking about using workflow. Jesse is one of the top contributors in the community, so it&#x27;d be definitely worth your time! +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/02/09/jenkins-celebration-day-is-february-26/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 9</div></div><h5 class="title">Jenkins Celebration Day is February 26</h5></div><p class="teaser">+
Congratulations! The Jenkins project officially went over the 100K active users mark sometime in January. As of January 31, https://stats.jenkins-ci.org/jenkins-stats/svg/total-jenkins.svg[we were at 102,992]. YOU are one of the 100K active users! +
 +

+
As discussed on http://meetings.jenkins-ci.org/jenkins/2015/[a couple recent project meetings], we have designated *February 26* as Jenkins Celebration Day. +
 +

+
To make some noise, here is what we are doing starting NOW: +
 +

+
Write a blog about anything related to Jenkins. Post your blog and Tweet out a link to it. Include the hashtag #Jenkins100K in your post.

+
On February 26, we will hold a raffle and pick four names at random. The grand prize winner will get a 3D Jenkins Butler model. Five others will get their pick of Jenkins swag (up to $20) from the Jenkins online store.

+
+

OTHER WAYS TO CELEBRATE

+
+

+
There are a number of other things planned and we want YOU to be involved. This blog post is the central place to come for all things related to the celebration. +
 +

+
Recording – Jenkins Governance Board
Dean, Tyler, Andrew and I will get together this month and record some thoughts about the Jenkins project. We will share that recording with you from this page on February 26.

+
Twitter Badge
For those of us on social media that want to proudly celebrate our community, we will have a special badge that you can use for your profile image on Twitter or any of the other social media forums. Feel free to use the badge as long as you want – but let’s get as many of us using it as possible between now and February 27.

+
Social Media Images

CloudBees is donating a series of images that we can all push out on social media (whatever platform(s) you use).

Pick your favorite(s) and push them out on Twitter, Facebook, G+

+
 +
*  +
*Certificate* (available on this blog post soon) +
Download your very own “I am part of the Jenkins 100K” certificate. Print it out and proudly display it on the wall of your cube or office. +
 +
*  +
*Visibility* +
The Community will also issue a press release on February 26 announcing our milestone news. +
 +
*  +
*Sign the “card”* +
Consider this blog a Congratulations card to the entire community. Share your thoughts in a comment on this blog about anything Jenkins-related that you wish! +

+
+

+
This is a big milestone for the Community and one you should be proud to be part of! Let’s make some noise… +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/02/19/jenkins-100k-celebration-pictures/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">19</div></div><h5 class="title">Jenkins 100K celebration pictures</h5></div><p class="teaser">+
In preparation of the celebration of 100K installations, 1000 plugins, and 10 years of Jenkins, we&#x27;ve got these images created. +
 +

+
I hope folks can use these images to mark the occasion! https://www.flickr.com/photos/131462214@N04/sets/72157650510081118/[The full size pictures are here]. +
 +

+
image:https://jenkins-ci.org/sites/default/files/images/jenkins100k_1.jpeg[image,width=379,height=479] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/02/24/100k-celebration-podcast-recording/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">24</div></div><h5 class="title">100K Celebration Podcast Recording</h5></div><p class="teaser">+
In preparation for https://jenkins-ci.org/content/jenkins-celebration-day-february-26[Jenkins 100K celebration], I&#x27;m going to record a one-time podcast with Dean Yu, Andrew Bayer, and R. Tyler Croy. +
 +

+
My current plan is to go over the history of the project, how big the community was back then, how we grow, where we are now, and maybe a bit about future. +
 +

+
But if you have any other suggestions/questions that you&#x27;d like us to discuss, you have 3 or 4 more hours to send in that suggestion! Your feedback would help us make a better recording, so please don&#x27;t hesitate to tell us.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interview">interview</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/02/25/100k-celebration-podcast/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">25</div></div><h5 class="title">100K Celebration Podcast</h5></div><p class="teaser">+
As a part of https://jenkins-ci.org/content/jenkins-celebration-day-february-26[the Jenkins 100K celebration], Dean Yu, Andrew Bayer, R. Tyler Croy, Chris Orr, and myself got together late Tuesday evening to go over the history of the project, how big the community was back then, how we grow, where we are now, and maybe a bit about future. +
 +

+
We got carried away and the recording became longer than we all planned. But it has some nice sound bites, back stage stories, and stuff even some of us didn&#x27;t know about! I hope you&#x27;ll enjoy it. +
 +
https://get.jenkins.io/podcast/100k.mp3[The MP3 file is here], or you can use your favorite podcast app and subscribe to https://jenkins-ci.org/podcast. +
 +

+

+

+

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/03/03/jenkins-user-conference-save-the-date/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 3</div></div><h5 class="title">Jenkins User Conference – Save the Date</h5></div><p class="teaser">We have some exciting news to share with you! We have finalized most of the dates and locations for the 2015 Jenkins User Conference (JUC) World Tour.

+
+

Save the date(s):

+
+

US East (Washington DC): June 18-19

Europe (London): June 23-24

Israel: July 16 (ETA)

US West (Santa Clara): September 2-3

+
+

The big news? The JUC agenda has been expanded this year to cover two days! That means you get twice as many opportunities to learn how others are using Jenkins and to network with other Jenkins users.

+
+

CALL FOR PAPERS IS OPEN FOR ALL JUC CONFERENCES

+
+

We need JUC speakers! The Call for Papers is open now and you can apply here. This is an opportunity for YOU to give back to the community by sharing your Jenkins knowledge and success. Jenkins speakers contribute significantly to the overall JUC experience.

+
+

In return for speaking, you will receive free admission to the conference and fame/fortune within the Jenkins community. OK, we can’t guarantee the latter, but we can guarantee the former! Hurry and apply now, because the Call for Papers deadline for US East and Europe expires on March 22, 2015.

+
+

Not interested in speaking? Another way to contribute to the community is by letting us know who you want to hear from. Nominate or refer that amazing speaker and we’ll do the rest. Contact alytong13@gmail.com

+
+

JUC SPONSORSHIPS

+
+

Lastly, be a JUC sponsor. Any organization can do this – whether a vendor that sells into the Jenkins ecosystem or a company that has received value from Jenkins and wants to give back to the community. You can find out more here. (NOTE: JUC is not a moneymaking venture for the community – so sponsorships do make a difference.)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/03/06/google-apps-sso-no-longer-supported-in-jenkins-openid-plugin/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 6</div></div><h5 class="title">Google Apps SSO no longer supported in Jenkins OpenID plugin</h5></div><p class="teaser">+
_This is a guest post from Owen Mehegan (aka autojack)_ +
 +

+

+
https://commons.wikimedia.org/wiki/Sunset[image:https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Sunset_Marina.JPG/320px-Sunset_Marina.JPG[image,width=200]] +

+

+
In 2014 Google announced that they will be shutting down their OpenID 2.0 authentication endpoint and replacing it with Google+ Sign-in, a library built on top of OpenID Connect. *The old Google endpoint will shut down on April 20th, 2015!* Accordingly, if you are using the Jenkins OpenID plugin to authenticate users with the ‘Google Apps SSO’ feature (typically when Google hosts your personal or corporate email), you need to upgrade. Ryan Campbell took the initiative to develop the new Google Login plugin which implements the Google+ Sign-in functionality. This is the recommended solution going forward. Follow the steps https://wiki.jenkins.io/display/JENKINS/Google+Login+Plugin[here] to configure it for your site. *Note that you DON’T need to have a Google+ social network account/profile. Any Google account can be used.* +
 +

+
If you find yourself locked out of your Jenkins system after the old endpoint is shut down you will need to follow the steps https://wiki.jenkins.io/display/JENKINS/Disable+security[here] to disable Jenkins security temporarily. Then you can connect without authentication and switch to the Google Login plugin. You will probably want to uninstall the old OpenID plugin at that point as well. +
 +

References:

+

Shutdown announcement from Google

JENKINS-23431, bug tracking this fix

Old OpenID plugin

New Google Login plugin

+<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/03/17/juc-2015-call-for-paper-deadlines-approaching/"><div class="header"><div class="date"><div class="month">March</div><div class="day">17</div></div><h5 class="title">JUC 2015 Call for Paper Deadlines Approaching!</h5></div><p class="teaser">+ +

+

The deadlines to speak at a 2015 Jenkins User Conference are fast approaching. Don’t miss out on this great opportunity to share your Jenkins tips, tricks, stories, and know-how with the community! Submit your proposal by the below deadlines to have your talk considered by a panel of Jenkins experts:

+
+

Please note: The deadline to submit a speaking proposal for East Coast US (DC) and Europe (London) is SUNDAY, MARCH 22, 2015. That is only FIVE days away!

+
+

2015 JUC Cities &amp; Call for Papers Deadlines

+
+

East Coast US: Deadline to Submit - March 22, 2015

London: Deadline to Submit - March 22, 2015

West Coast US (Bay Area): Deadline to Submit - May 3, 2015

Israel: Deadline to Submit - May 15, 2015

+
+

Not interested in speaking? Contribute to the community in another way: nominate or refer a speaker you would like to hear from at JUC! Contact alytong13@gmail.com or simply become a sponsor.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/03/25/registration-for-juc-2015-is-open/"><div class="header"><div class="date"><div class="month">March</div><div class="day">25</div></div><h5 class="title">Registration for JUC 2015 is Open!</h5></div><p class="teaser">+
image:https://pbs.twimg.com/media/Bqbz9JQIIAA9gKG.jpg[image,width=300,height=225] +

+
+

It’s that time of the year again: 2015 Jenkins User Conference Registration is OPEN for all cities. This year, we are making some changes to JUC — JUC will be a two-day event in three out of the four cities across the globe. You will get opportunities to network with other users and developers in the community, learn more about how other people are using Jenkins and attacking broader continuous delivery problem. As always, we love to meet &amp; talk to you to learn what you are doing with Jenkins. To get the sense of how JUC is like, take a look at our past JUC reports like this and this.

+
+

Early Bird pricing for JUC tickets is available until May 1.

+
+

East Coast US: June 18-19

Europe: June 23-24

Israel: July 16

West Coast US: September 2-3

+
+

You can learn a lot more information here about the 2015 Jenkins User Conference World Tour. As always, we are tweaking JUC to make it better, based on feedback. I’ll post about those in coming months. Make sure to follow or tweet at @jenkinsconf to stay up to date on JUC news or to share which JUC you will be attending!

+
+

+
See you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/04/06/confluence-migration-this-weekend/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 6</div></div><h5 class="title">Confluence migration this weekend</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Structure_relocation[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/GMC_U-Haul_truck_front_1.JPG/320px-GMC_U-Haul_truck_front_1.JPG[image] +
]

+

+
For the past few weeks, I&#x27;ve burnt a lot of midnight oil to https://github.com/jenkins-infra/confluence[get Confluence containerized]. The goal is to make Confluence upgrade more manageable and testable. In the proces, I&#x27;ve not only containerized Confluence, but also containerized https://github.com/jenkins-infra/confluence-cache[some other services], including https://github.com/jenkins-infra/mock-ldap[mock LDAP server], to be able to test the copy of the production Confluence dataset against newer versions of Confluence before upgrading production. +
 +

+
The infra team is currently http://lists.jenkins-ci.org/pipermail/jenkins-infra/2015-April/000292.html[targeting this weekend] to migrate our current Confluence instance to this new container, and use the opportunity to move the service to a bigger system. Currently JIRA and Confluence has to live within 2.5GB RAM from the same host, and it&#x27;s really stretching both services. The new box has 4GB of RAM, and we are splitting JIRA and Confluence to two different servers. So there&#x27;s a lot of head room. +
 +

+
So please expect some Wiki outage over the next weekend. +
 +

+
As always, our sincere thank you to https://osuosl.org/[Oregon State University Open Source Lab] for generously hosting our servers. Please donate to them to show your support. Similarly, thank you https://atlassian.com/[Atlassian] for generously providing the license for running Confluence. +
 +

+
If this goes well, JIRA will follow suit.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/04/06/good-bye-java6/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 6</div></div><h5 class="title">Good bye Java6</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/6_(number)[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/U%2B2678_DejaVu_Sans.svg/200px-U%2B2678_DejaVu_Sans.svg.png[image] +
] +

+
+

+
About two years ago, we bumped our runtime JRE requirement https://github.com/jenkinsci/jenkins/commit/3431a7cba[from Java5 to Java6]. And so the time has come once again for us to finally move on to Java7. Because of all the new language features, https://groups.google.com/forum/#!topic/jenkinsci-dev/sw_WepGw0Pk[many of us the developers really wanted to move right on to Java8], but after much discussion we settled to move to Java7 first and then to Java8. +
 +

+
So here is the plan: +
 +

Starting Jenkins 1.608, we start advertising that we will be moving on to Java7, which is why you are reading this.

Starting Jenkins 1.610 (2 weeks from now), we will ship so-called 51.0 class files that will only load on Java7+. This gives some more warnings to those who don’t read our blog.

Unless we hear uproar from users, starting around 1.614 (6 weeks from now), core developers will start linking directly to new Java7 APIs. We will move on to servlet 3.0 at this time as well.

The current 1.596 line of LTS will remain compatible with Java6, and most likely the next LTS line will also remain compatible with Java6. So LTS users have additional 3 months before upgrading to Java7.

+
+

+
Java7 has more NIO improvements that allow us to do some file I/O in more portable manner. Similarly, servlet 3.0 will help us build more interactive UI. +
 +

+
Your Jenkins controller and all the build agents need to be running on Java7+. Similarly, those who are using the Maven2 job type must also run Maven with Java7+. However, this does not prevent you from using Jenkins to build your applications that are targeted to earlier versions of Java. According to our research, most platforms people run Jenkins on has been already shipping Java7 for quite some time now. But if you have a good reason why we shouldn&#x27;t force everyone to Java7, please let us know ASAP. +
 +

+
To put this into context, https://www.java.com/en/download/faq/java_7.xml[Oracle will not release updates to Java7 past April 2015]. We have always recommended users to run the latest general release according to Oracle, which is currently Java8. As I said, I suspect we will be requiring Java8 pretty soon. So if you are still running Java6, you should definitely upgrade to Java8. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/04/13/juc-world-tour-2015-keynote-speaker-news-and-early-bird-tickets/"><div class="header"><div class="date"><div class="month">April</div><div class="day">13</div></div><h5 class="title">JUC World Tour 2015 - Keynote Speaker News and Early Bird Tickets</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/The-Phoenix-Project-border_2.png[image,width=99] +

+
+

The 2015 JUC World Tour dates are rapidly approaching. Since the community has grown so tremendously since last year, the JUC in each city will be the largest gathering of Jenkins users in that region.

+
+

Kohsuke will, as always, be the opening keynote speaker at each JUC. But, with the conference going from one to two days, I am happy to announce that Gene Kim will be another keynote on the second day! He is the author of The Phoenix Project and a thought leader in DevOps.

+
+

To have these two experts in one place will provide a great opportunity to talk about Jenkins as the foundation of continuous delivery and DevOps practices.

+
+

Another exciting announcement: the 2015 Jenkins World Tour will run alongside the CD Summit conferences for both days (at the U.S. East, Europe and U.S. West locations only). Attendees of either conference can attend any of the talks and presentations at both events. Learn more about what CD Summit 2014 was like to get an idea for this year’s event.

+
+

Registration for all 2015 JUC locations is open. Early bird pricing ends May 1!

+
+

East Coast US: June 18-19

Europe: June 23-24

Israel: July 16

West Coast US: September 2-3

+
+

The Call for Papers for JUC is still open for Israel and U.S. West. Submit your own proposal or convince your favorite speaker/Jenkins user to submit one if speaking is not your thing!

+

East Coast US: June 18-19

Israel: July 16<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/04/22/jenkins-user-conference-agenda-news/"><div class="header"><div class="date"><div class="month">April</div><div class="day">22</div></div><h5 class="title">Jenkins User Conference - Agenda News</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/newjuc2_1.png[image,width=153,height=166] +

+
+

I have some exciting news — The agendas have been posted for the Jenkins User Conferences (JUC) to be held at U.S. East (Alexandria, VA) and Europe (London). Take a look here to learn more about the talks, speakers and schedules.

+
+

As always, there is a great lineup of presenters ready to share their Jenkins stories: Peter Vilim will be presenting “Proving a First Class User Experience with Jenkins” at the U.S. East JUC, and Sander Kieft’s talk is called “Automating a Big Data Platform with Jenkins” at JUC Europe. Learn more about all 2015 JUC speakers and talks here. Explore the pages and see the who/what/where of all JUC 2015 locations!

+
+

You will see some familiar names and talks as well: Andrew Bayer will be presenting his very popular talk called “Seven Habits of Highly Effective Jenkins Users” at JUC Europe. Will Soula is returning this year to JUC U.S. East to “chat” about “Chat Ops and Jenkins.” Lorelei McCollum is also back with two talks at JUC U.S. East called “Jenkins 101” and “Getting Groovy with Jenkins.”

+
+

This year, you will notice a few differences in the JUC agendas. JUC is now a two-day conference in the U.S. East, Europe and U.S. West locations! Also, each session is assigned a category according to its content: Continuous Delivery, Best Practices, Operations, Plugins, Case Studies/War Stories and more. This will help you decide which talks to attend. You will also notice that several talks, especially in JUC Europe, reflect the industry’s growing interest in big data and Docker.

+
+

The agendas are still being finalized for JUC Israel and JUC U.S. West. If you are interested in speaking at either of these locations, you can still send in your talk proposals. The U.S. West deadline is May 3 and the Israel deadline is May 15.

+
+

JUC is such a great opportunity for the community to come together and network face-to-face. You can meet Kohsuke Kawaguchi, creator of the Jenkins project, Gene Kim, author of The Phoenix Project and DevOps expert, but you will also have the opportunity to meet Jenkins users, just like you, from all over the world. And this year, with the Jenkins project at well over 100K active installations, JUC as a whole will be the largest gathering of Jenkins users ever.

+
+

Early bird pricing for JUC U.S. East and Europe ends May 1, so REGISTER NOW to take advantage of the lower pricing.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/04/24/jira-migration-this-weekend/"><div class="header"><div class="date"><div class="month">April</div><div class="day">24</div></div><h5 class="title">JIRA migration this weekend</h5></div><p class="teaser">In continuing my infra upgrade work, this weekend I’ll be migrating JIRA to another server.

This will make upgrade more manageable and testable. The service will be disrupted for a few hours. Check out our @jenkinsci on Twitter for up-to-the-minute status.

Once the migration is done, the next step is to upgrade them.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/05/07/juc-speaker-blog-series-denis-chernilevskiy-juc-europe/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 7</div></div><h5 class="title">JUC Speaker Blog Series: Denis Chernilevskiy, JUC Europe</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114] +

+
+

Jenkins is a great tool for automation of all kinds of processes in the software development cycle. Falling back to the year 2008 I remember myself creating my first job and the feeling of enlightenment flowing through my veins :) Then it was just one script running on just one agent (node) and it was enough for that particular task. But years have passed, software systems have become more complicated and terms like «cloud», «distributed environment», «CI/CD» are not a discovery for anyone nowadays. But how can these things be connected and used by Jenkins? The detailed answer for this question will be revealed in my presentation of &quot;compound-cloud&quot; plugin at JUC Europe 2015.

+
+

Before I got to Yandex, the QA’s automation concept was the following:

+
+

The job takes 1 free agent

The job installs the system under test and tests themselves to this node

The job runs tests

The job cleans-up and returns the agent back to the pool

+
+

When I started working for Yandex I understood that the concept of one single agent for a job is not a solution for our tasks because of one particular reason - the system under test was not able to work on a single node… This system is a Yandex MediaAd platform and it requires at least 4 separate nodes to be run on. Better - 8 nodes. Optimal - 40 nodes :)

+
+

Thinking about the problem, we thought we would get closer to the solution by simply using a single Jenkins agent as a launchpad for tests and for some tools which will then get some more nodes from the cloud (we already had OpenStack ready) and deploy the system inside them. Thank God we haven’t implemented this solution :)

+
+

We’ve been stopped by the following reasons:

+
+

We are lazy and want to write as little code as possible :)

There’s a JClouds plugin that can work with OpenStack. Why don’t we use it? &#x27;Cause it provisions only 1 agent per job. But it has provisioning algorithms implemented already, and we don’t want to reimplement them…

If we create cloud instances with a separate tool, then we have to manage them separately and can’t get profit of using Jenkins’ agent management, which is also implemented already…

if we do so, we also lose Jenkins’ agent features like running a script on the agent, get some reports or statistics and so on

We would also lose visibility: how many agents we have, how many are busy, how many left til we get to the cloud quota limit? We could go to OpenStack panel then, but it’s totally inconvenient…

+
+

As a result of this reasoning, the idea emerged! «We should provide an ability to either attach several agents to a job, or to allow a agent to consist of several nodes». The second way seemed to give more order in agents management and it was stated to be a final solution for our problem. We called this concept a «compound-agent». And then we coded…​

+
+

That’s how the compound-cloud plugin was born. It allows us to get such compound-agents from any cloud plugin installed to Jenkins. Of course there’s also a possibility to form a compound agent from single agents already attached to Jenkins, but it’s not the true way for hardcore IT guys ;)

+
+

Of course there are lots of details on how we use this concept in a real life for our purposes (and I will surely describe the main parts of them in my speech), but here’s a short list of common use-cases:

+
+

We configure a set of labels via the JClouds plugin. Each label represents 1 agent template, like «small_ubuntu_server» or «large_win_server».

We then configure a compound-agent label via compound-сloud plugin. Each label is a set of single cloud labels. As a result we have a label like «Small test env» consisting of &quot;1x large WinServer + 3x small Ubuntu».

We assign roles to each single node in a compound label, to be able to distinguish them, so the job can run a script on a particular node inside a compound-agent for example.

We assign a label to a job, like it’s done for a JClouds label, for example.

When the job starts, a compound-agent provisions from the cloud using the corresponding compound label.

We run a deployment tool on a ROOT role node of a compound-agent. It then deploys the system under test to other nodes inside this compound-agent.

We run tests.

We don’t bother with creating/cleaning/stopping/deleting agents. It’s done by Jenkins.

We get profit :)

+
+

The core feature is that we’ve reused all the provisioning and management mechanisms already implemented in Jenkins and cloud plugins. We just run our jobs and don’t care about the distributed infrastructure!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/Denis-Chernilevskiy_0.jpg[image,width=150] +

+
+

This post is by Denis Chernilevskiy, the head of QA/DevOps Services at Yandex. If you have your ticket to JUC Europe, you can attend his talk&quot;Multi-Node Environment as a Jenkins Agent (Compound-Agent)&quot; on Day 2.

+
+

Still need your ticket to JUC? Early bird pricing ends May 15. Also, if you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/05/14/juc-speaker-blog-series-lorelei-mccollum-juc-u-s-east/"><div class="header"><div class="date"><div class="month">May</div><div class="day">14</div></div><h5 class="title">JUC Speaker Blog Series: Lorelei McCollum, JUC U.S. East</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Have you heard Jenkins mentioned, but haven’t really done much with it? Are you at JUC because you want to learn more? Has your company been pushing you to use Jenkins or to adapt a more agile build/test process using a Continuous Delivery/Continuous Integration method?

+
+

Jenkins 101 is going to give you an introduction to Jenkins and get you started in the right direction. Many sessions may be too in-depth, too specialized, or do a deep dive too fast, and while that is good for the more intermediate Jenkins user, the beginner can get lost fast and lose interest. My session will go through the basics of Jenkins, so anyone without prior knowledge can get up and running in just a short amount of time. We will cover building/configuring jobs, design of pipelines, security of your Jenkins controller, fun groovy scripts and useful plugins to get you started. Whether you are a beginner or an advanced Jenkins user, you can always learn from how others are using Jenkins. Attend this session early on in your JUC lineup, so that you get the most out of the conference!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/01-02-1600-McCollum_0.png[image,width=149,height=180] +

+
+

This post is by Lorelei McCollum, Software Engineer at IBM. If you have your ticket to JUC U.S. East, you can attend her talk&quot;Jenkins 101&quot; on Day 1.

+
+

Still need your ticket to JUC? Early bird pricing ends May 15. Also, if you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/05/18/juc-speaker-blog-series-andrew-bayer-juc-europe/"><div class="header"><div class="date"><div class="month">May</div><div class="day">18</div></div><h5 class="title">JUC Speaker Blog Series: Andrew Bayer, JUC Europe</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+

In the fall of 2011, the very first Jenkins User Conference was held in San Francisco. Over 250 people showed up. It was, to be completely honest, a bit shocking to me - that little project I’d gotten involved with less than three years earlier was big enough, interesting enough, important enough for 250 people to travel from around the world to spend a day talking about it? That’s an amazing feeling, and it was an amazing day. Since then, there’ve been three more JUCs in the Bay Area, three in Israel and two in Europe, with more talks on more Jenkins subjects and an ever-increasing number of attendees. This year, there are another four scheduled - three of them for two days each this time! Find out more about the first two, JUC US East and JUC Europe, below!

+
+

Not only are there enough worthy talks to merit a full day a few times a year - now there are enough to merit two days! At JUC US East 2015 outside Washington, DC on June 18 and 19, you can see talks on the Workflow plugin for Jenkins, test automation, mobile testing, plugin development, and a few talks on new and fascinating ways people are using Jenkins - even driving big data workflows! And then, just a few days later, on June 23 and 24 in London, there’s JUC Europe 2015, with talks covering things like the fantastic Job DSL plugin, reproducible build environments, Jenkins and Docker together, and my personal favorite, the 2015 edition of my Seven Habits of Highly Effective Jenkins Users talk.

+
+

Whether you’re interested in the latest innovations in continuous integration and delivery, or you’re a Jenkins plugin developer wanting to learn how to make your plugins more mature and useful, or you’re a Jenkins administrator trying to understand how to provide your users with a great platform for their builds and testing, or even if you’ve just heard about CI/CD and you want to find out more, the Jenkins User Conferences are a great opportunity to see all those things and meet with other Jenkins users and developers. I’m excited to attend my fifth JUC in London, and I hope to see you there!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/smallerme.jpeg[image,width=150,height=188] +

+

This post is by Andrew Bayer, build and tools architect at Cloudera and longtime Jenkins contributor. If you have your ticket to JUC Europe, you can attend his talk&quot;Seven Habits of Highly Effective Jenkins Users&quot; on Day 1.

+
+

Still need your ticket to JUC? Early bird pricing ends May 15. Also, if you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/05/20/juc-speaker-blog-series-david-dang-juc-u-s-east/"><div class="header"><div class="date"><div class="month">May</div><div class="day">20</div></div><h5 class="title">JUC Speaker Blog Series:  David Dang, JUC U.S. East</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

I’ve implemented numerous test automation projects for clients, but recently I had a unique request. Jenkins plays a critical role.

+
+

The “digital channel” is an industry buzzword for many companies these days. The digital channel represents a company’s content that is delivered by websites and mobile devices. Companies want the same website to work across any channel in multiple browsers and different operating systems. They also want that same website to work across an explosion of mobile devices. Add the new generation of smart watches showing up and testing is becoming a huge challenge for IT departments. One big issue is there is too much duplication of testing efforts.

+
+

In a perfect world, you would create a core set of test automation scripts that work across all digital channels. A client recently requested that my team and I create this perfect-world scenario, and we are doing just that. Jenkins pulls it all together by managing the execution and reporting.

+
+

Join me for my talk to learn how I’m using Jenkins, Selenium, TestNG, and Perfecto Mobile to solve the digital channel testing challenges for one client.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/01-02-1030-dang_0.jpg[image,width=149,height=180] +

+
+

This post is by David Dang, VP of Automation Solutions at Zenergy Technologies. If you have your ticket to JUC U.S. East, you can attend his talk&quot;Integrating Mobile Automation with Jenkins: A Case Study Using Perfecto Mobile with Jenkins&quot; on Day 1.

+
+

Still need your ticket to JUC? Early bird pricing has been extended! Also, if you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/01/juc-speaker-blog-series-nobuaki-ogawa-juc-europe/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 1</div></div><h5 class="title">JUC Speaker Blog Series: Nobuaki Ogawa, JUC Europe</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

On the 23rd and 24th June, I’ll attend Jenkins User Conference 2015 Europe in London. And I’ll present a lightning talk about Continuous Delivery with Jenkins.

+
+

Here is short overview of what I’d like to talk about there.

+
+

1. Continuous Build

+
+

My starting point was to get to know JenkinsCI. Our developers used JenkinsCI to make the Continuous Build of our software.
So, our developing environment was quite Jenkins friendly from the beginning.

+
+

2. Continuous Deploy

+
+

--- Virtual Machine ---

+
+

We had to have an environment where we could deploy our new build. As we are big fans of Microsoft, we decided to use Azure as our environment to make Continuous Testing.

+
+

How do we control it? We use Powershell, which can be executed with JenkinsCI.

+
+

--- Product Deployment ---

+
+

How did we achieve the Continuous Deploy? Actually, my boss, who is DirectSmile’s Yoda developed a very powerful tool called “DirectSmile Installation Service” to enable this.

+
+

So we integrated this tool within JenkinsCI, and now Jenkins can deploy DirectSmile products on any target server with just one-button-click!

+
+

3. Continuous Testing

+
+

Of course, we use JenkinsCI to make the Continuous Testing.
How do we do that?
We use Selenium to make and run tests. So we can cover most features and we can execute it at anytime.

+
+

We are doing it after every new version build, to obtain Continuous Delivery.

+
+

4. Continuous Sharing

+
+

I think it’s important to share all knowledge and experiences I have had with others, especially those whom have just started with Continuous Delivery.

+
+

Don’t worry, it is probably much easier than you think.

+
+

As a part of this practice, I’d like to share all my knowledge and experiences with how easy it is to achieve Continuous Delivery with Jenkins at JUC 2015.

+
+

I’m really exciting to meet and talk about this there! See you at JUC 2015 in London!

+
+

About Me

+
+

My name is Nobuaki Ogawa, from Japan, and I currently work in Berlin, Germany for the software company DirectSmile as a DevOps QA Manager.

+
+

From the very first time I used JenkinsCI, it helped me a lot. Almost all the work I did last year was mainly with Continuous Delivery with Jenkins.

+
+

From Build to Deploy, Test, and even Maintenance and Monitoring, my Jenkins takes care of everything.

+
+

It was super easy to achieve Continuous Delivery in the DirectSmile world with the help of JenkinsCI.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/02-03-1530-ogawa_0.jpg[image,width=152,height=182] +

+
+

This post is by Nobuaki Ogawa, DevOps QA Manager at DirectSmile. If you have your ticket to JUC Europe, you can attend his talk&quot;Jenkins Made Easy&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/02/juc-speaker-blog-series-peter-vilim-juc-u-s-east/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 2</div></div><h5 class="title">JUC Speaker Blog Series: Peter Vilim, JUC U.S. East</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114] +

+
+

In this talk I will be focusing on plugin development for Jenkins. I aim to capture some of the lessons that we have learned at Delphix and that I learned while I was in graduate school. At Delphix we have been large users of Jenkins for over four years which is most of the history of our startup. We currently run thousands of jobs per day. We have been quite happy with the experience and expect these numbers to grow significantly as our business scales beyond our current 300 head count.

+
+

The core concept of Delphix is Data as a Service. Our software allows businesses to virtualize databases and data associated with their applications then provision these on demand to developers and others who need virtual copies of them. Our development for this software spans the entire stack. We have quite a few kernel developers, including the original team for the ZFS filesystem who work on developing the open source application, OpenZFS, which underpins our product. Further up the stack we have a large java application that interacts with ZFS to perform virtualization operations, provides user
facing webservices, and interfaces with our internal Postgres metadata store which stores the state of our system. Finally above this we have a modern Javascript front end for user interaction. Our full software product ships as a virtual machine on a variety of hypervisors. As a result of these numerous components, end to end integration testing is very important to us. This integration testing is the primary use of Jenkins for us. Before any developer checks in code to either our operating system or application repository, it must undergo several hours of automated integration testing. We also have nightly runs which go for far longer and tests a much more extensive set of functionality. In addition, we use Jenkins for the build process of our software as well as final packaging for release. Because Jenkins serves as a hub for our development processes, having a well designed system is very important to us and saves us significant time.

+
+

Below are some of the key points I will be discussing at my talk. I hope you attend to learn more about the areas that I find very interesting.

+
+

I’m planning to discuss the structure of a Jenkins plugin. I’ll also cover a few of the more advanced areas of plugins such as distributed builds that I see less frequently in plugins. In addition, I’ll briefly cover unit testing, which is something missing in many open source plugins.

I’ll talk about some good patterns to use in plugins as well as some areas where a plugin is not a good idea. I’m planning to pull from my own personal experience developing plugins, the experience of other people at Delphix working with Jenkins, and our experience using other open source plugins to talk about what works and what doesn’t.

I’ll give an overview of the current plugin development at Delphix. I’ll cover some of the lessons that we have learned along the way. We have also started to take a &quot;dogfooding&quot; approach to some of our development where we use plugins internally to help our test process and open source them since our customers find features used for testing our product to often be useful in their production environments. This has an added bonus of making it easier to justify our development time spent on making these plugins, since they are also features requested by our customers.

I’ll discuss the trade-offs between using an already developed plugin or group of plugins, writing some scripts, and building your own plugin. Being able to figure out when to do which can lead to major time savings as well as a better user experience.

+
+

I hope you attend. Even if you have no immediate plans to write your own plugins, hopefully you’ll be able to learn about what makes plugins tick and how to better evaluate plugins when picking them for your own projects. Plugins were what originally got me excited about Jenkins and they allowed me to see its true potential as a build and test system. I hope to share some of that inspiration.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/01-01-1400-vilim_0.jpg[image,width=152] +

+
+

This post is by Peter Vilim, Member of Technical Staff at Delphix. If you have your ticket to JUC U.S. East, you can attend his talk&quot;Providing a First Class User Experience with Jenkins Plugins&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/03/juc-speaker-blog-series-andrew-phillips-juc-u-s-east/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 3</div></div><h5 class="title">JUC Speaker Blog Series: Andrew Phillips, JUC U.S. East</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Automated Testing with Jenkins: At JUC East with Andrew Phillips

+
+

Next stop: Washington, DC! I’m looking forward to heading to JUC East in a couple weeks, which runs June 18-19. The Jenkins User Conference is the annual get-together for Jenkins customers, users, partners, developers and community members. It promises to be an exciting two days, and as an added bonus I get to catch up with Kohsuke Kawaguchi and Gene Kim!

+
+

I will be giving a talk about a topic that I think is a bit of an elephant in the room in the Continuous Delivery space: the critical importance of optimized Automated Testing. As you start to ship code faster, you’ll need numerous automated tests across many different tools, in many different jobs in your pipeline. But getting a grip on the results of all of your automated tests — and then figuring out whether your software is good enough to go live — becomes harder and harder as you speed up the delivery of your software.

+
+

I’ll share tips on how naming conventions, partitioning of testware and mirroring the application’s structure in the test code help you best handle automated testing with Jenkins. I’ll also try to provide some insight into how to keep the setup manageable, as well as share practical experiences of managing large portfolios of automated tests. Finally, we’ll showcase some practices that help you manage all your test results and add aggregation, trend analysis and qualification capabilities to your Jenkins setup.

+
+

Join us at the event, or check the slides or recording (which we’ll post after the talk) to learn more. Looking forward to seeing you there!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/01-01-1130-phillips_0.jpg[image,width=152,height=182] +

+
+

This post is by Andrew Phillips, at XebiaLabs. If you have your ticket to JUC U.S. East, you can attend his talk&quot;How to Optimize Automated Testing with Everyone’s Favorite Butler&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/09/juc-speaker-blog-series-damien-coraboeuf-juc-europe/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 9</div></div><h5 class="title">JUC Speaker Blog Series: Damien Coraboeuf, JUC Europe</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114] +

+
+

Scaling and maintenance of thousands of Jenkins jobs

+
+

How to avoid creating of a jungle of jobs when dealing with thousands of them?

+
+

In our organisation, we have one framework, which is used to develop products. Those products are themselves used to develop end user projects. Maintenance and support are needed at each level of delivery and we use branches for this. This creates hundreds of combinations.

+
+

Now, for each product or project version (or branch), we have a delivery pipeline. We start by compiling, testing, packaging, publishing. Then we deploy the application on the different supported platforms and go through different levels of validation, until we’re ready for delivery. Aside from a few details and configuration elements, most of the pipelines are identical from one branch to the other, from one project to the other.

+
+

So, one framework, some products, several projects, maintenance branches, complex pipelines… We end up having many many jobs to create, duplicate and maintain. Before even going into this direction, we saw this as a blocking issue - there was no way we could maintain manually thousands of jobs on a day to day basis.

+
+

The solution we were looking for should have the following characteristics:

+
+

Self service - our goal being to delegate the job and branch administration in Jenkins to the projects, in order to reduce the support time

Security - we didn’t want to open Jenkins to the projects at configuration level - not acceptable in our context

Simplicity - the solution should be simple enough to be manageable by people not knowledgeable about the core technologies of Jenkins

Extensibility - the solution must be flexible enough to allow extensions when needed

+
+

When we thought about using the Job DSL plug-in, delegating the creation of the pipeline to the project teams was OK from a self service point of view, but was not secure and definitely not simple for people not knowing Jenkins.

+
+

In the end, we opted for a solution where:

+
+

A project team would edit a simple property file listing the characteristics of the current branch, like which type of platform is supported, which version of the pipeline library to use, etc.

Upon commit of this shopping list, the complete branch pipeline is regenerated using the given version of the pipeline library

The pipeline library code reads the “shopping list” property file and runs a Job DSL script to generate the branch pipeline according to those parameters

+
+

By default, the pipeline library generates a classic pipeline, suitable for most needs. It is also possible to define and use extensions, like having additional jobs in the pipelines.

+
+

In case of new features or defects, we develop or branch a new version of the pipeline library and projects or branches can use it by changing the version of their shopping list file.

+
+

A project gets injected into the system by having only a project seed being generated. From it, the authorised members can generate the branch seed and any branch pipeline at any time. Those seed jobs and the pipelines themselves can also be driven directly from the SCM using our plugin.

+
+

The project teams are now autonomous and can pilot their pipelines without requesting any support. They act in a secure and isolated way, and cannot compromise the shared environment. The “shopping list” file is simple and well documented. The system is not rigid and allows for extensions.

+
+

This platform has been developed initially for a very specific framework and a set of projects which depend on it, but has been extended since to be able to support other stacks. It is structured in two different parts:

+
+

The seed platform itself - generation of branch structures in Jenkins and trigger end points for being piloted from the SCM

The pipeline libraries, referenced from the shopping list files

+
+

We still allow some small tools and applications to define directly their pipeline by providing a Job DSL script.

+
+

Using the same principle, we can also pilot other tools in the ecosystem - like Artifactory or Ontrack.

+
+

I’ll talk about this seed platform on June 24th, in the Jenkins User Conference in London.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/dcoraboeuf_0.preview.jpg[image,width=150] +

+
+

This post is by Damien Coraboeuf, Continuous Delivery Expert at Clear2Pay. If you have your ticket to JUC Europe, you can attend his talk&quot;Scaling of Jenkins Pipeline Creation and Maintenance&quot; on Day 2.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/15/juc-speaker-blog-series-stephan-hochdrfer-juc-europe/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">15</div></div><h5 class="title">JUC Speaker Blog Series: Stephan Hochdörfer, JUC Europe</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

I am very much looking forward to the Jenkins User Conference in London where I will present our insights on how to use Jenkins in a PHP related environment. Moving to Jenkins about 5 years ago bitExpert gained a lot of experience in running and managing a distributed Jenkins infrastructure. bitExpert builds custom applications for our clients which means that we have to deal with different project infrastructures, e.g. different PHP versions. We heavily rely on the build nodes concept of Jenkins which I will briefly outline in the session. Besides that I will give some in-depth insights on how we use Jenkins on a daily basis for the &quot;traditional&quot; CI related tasks (e.g. linting code, checking code style, running tests) as well as how Jenkins is used to power our integration tests. Last but not least I will cover how Jenkins acts as a kind of backbone for our Satis server which allows us to host the metadata of our company’s private Composer packages. Throughout the talk I will point out which Jenkins plugins we use in the different contexts to give you a good starting point if you are new in the Jenkins ecosystem.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/bitExpert-logo_0.png[image,width=220,height=76] +

+
+

This post is by Stephan Hochdoerfer, Head of Technology at bitExpert AG. If you have your ticket to JUC Europe, you can attend his talk&quot;Jenkins for PHP Projects&quot; on Day 2.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/08/juc-speaker-blog-series-will-soula-juc-u-s-east/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 8</div></div><h5 class="title">JUC Speaker Blog Series: Will Soula, JUC U.S. East</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Chat Ops and Jenkins

+
+

I am very excited to be attending the Jenkins User Conference on the East Coast this year. This will be my third presentation at a JUC and fourth time to attend, but my first on the East Coast. I have learned about a lot of cool stuff in the past, which is why I started presenting, to tell people about the cool stuff we are doing at Drilling Info. One of the cooler things we have implemented in the last year is Chat Ops and our bot Sparky. It started as something neat to play with (&quot;Oooo lots of kittens&quot;) but quickly turned into something more serious.

+
+

Ever get asked the same questions over and over? What jobs to run to deploy your code? What is the status of the build? These question and more can all be automated so you do not have to keep answering them. Furthermore, when you do get asked you can show them, and everyone else, how to get the information by issuing the proper commands in a chat room for everyone to see. With chat rooms functioning as the 21st century water coolers, putting the information in the middle of the conversation is a powerful teaching technique. You are not sending people to some out dated documentation on how to get their code deployed, nor are you showing them the steps today only to be forgotten tomorrow. Instead you can deploy your code and they see the exact steps needed to get their code deployed.

+
+

Even more impressive is the way ChatOps can bring your company together. Recently our CTO got a hipchat account so he could interact with Sparky. This gave me the idea that if we extend Sparky to deliver information useful to the other teams (Sales, Marketing, Finance, etc) then we would be able to get these wildly disparate teams in the same chat room together and hopefully they will talk and learn from each other. Where DevOps is the bringing together of Dev and Ops, ChatOps can be the bridge across the entire organization. Come see my presentation Day 1: Track 1 at 4:00 PM to learn how ChatOps can enrich your team, how Drilling Info is using it, and what our future plans entail for ChatOps.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/01-01-1600-soula_0.jpg[image,width=152,height=182] +

+
+

This post is by Will Soula, Senior Configuration Management/Build Engineer at Drilling Info. If you have your ticket to JUC U.S. East, you can attend his talk&quot;Chat Ops and Jenkins&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC near you.

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/16/juc-speaker-blog-series-martin-hobson-juc-u-s-east/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">16</div></div><h5 class="title">JUC Speaker Blog Series: Martin Hobson, JUC U.S. East</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

I’ve been using Jenkins for some time now as the build server for the various projects that are assigned to our four-person software development team, but recently I had exposure to how things were done in a much larger team, and I came away with a better understanding of the kinds of demands that are placed on a build pipeline in these environments. It was quite an education – while the CI pipelines that I administer in our small team might require a handful of virtual machines in our corporate cloud, the pipeline in this team supported over one hundred developers and required several hundred VM instances at any given time.

+
+

When operating at this scale, efficiency does become important, as the Amazon cloud charges add up and become significant at this level. Using some relatively simple techniques, I was able to gain insight into what actually happened in the more complex build jobs and learned just how these VM instances were utilized. These build jobs configured over a dozen virtual machines each, and understanding the startup and execution flows was critical to making changes and improving efficiencies. I will be discussing how to instrument and analyze these complex builds in my Lightning Talk:&quot;Visualizing VM Provisioning with Jenkins and Google Charts” and hope to see you all there!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/01-02-1615-hobson_0.jpg[image,width=152,height=182] +

+
+

This post is by Martin Hobson, Senior Software Developer at Agilex Technologies. If you have your ticket to JUC U.S. East, you can attend his lightning talk&quot;Visualizing VM Provisioning with Jenkins and Google Charts&quot; on Day 1.

+
+

JUC IS HERE! JUC U.S. East will begin with registration at 7AM, Thursday June 18. The two day conference is sure to be a blast! If you have not registered, you can still get a ticket! Check out the agenda for JUC U.S. East here and find the link to register.

+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/06/22/new-wiki-url-requirement-for-plugins/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">22</div></div><h5 class="title">New Wiki URL Requirement for Plugins</h5></div><p class="teaser">Let’s say you’re browsing the &#x27;Available&#x27; tab in the Jenkins plugin manager for interesting-looking plugins. How do you learn more about them, preferably without installing them on your production instance? You click the plugin’s name, which usually links to the plugin’s wiki page, of course!

Unfortunately, it’s possible for plugins to be published without a wiki page, or any other documentation aside from what’s provided in the plugin itself. This is really unfortunate, as users rely on wiki pages and similar documentation to learn more about a plugin before installing or upgrading it, like its features, limitations, or recent changes. Additionally, plugin wiki pages have a special section at the top that provides an automatically generated technical overview of the plugin, such as dependencies to other plugins, the minimum compatible Jenkins version, a list of developers, and links to the source code repository and issue tracker component. Everyone learning about or using a plugin benefits from a plugin wiki page and luckily, almost all plugins have one!

To ensure that every plugin has at least a basic wiki page with some documentation, we decided to only publish plugins in the Jenkins update center that have and link to a wiki page. To keep the impact to a minimum, we’re implementing this plan in several stages.

The first stage went live on June 1: All existing plugins that don’t have a (valid) wiki link got a wiki link assigned by the update center (a so-called &#x27;override&#x27;), either to an existing wiki page if there was one, or a generic&quot;This plugin has no documentation&quot; wiki page otherwise. This ensures that no currently existing plugins get dropped from the update center at this point. Of course, new plugins that don’t provide a wiki URL and don’t have an override URL will not show up at all.

The second stage will be enabled later this year: We’re planning to remove all the overrides mentioned above. At this point, plugins may get removed from the update center if they still don’t specify a wiki URL. Of course this isn’t our goal, and we’ll try to work with plugin authors to prevent this from happening.

So what can you do? Check the current overrides list to see whether the plugins you care about are affected, and if so, see the landing page in the wiki to learn what you can do. If you have any questions about this process not covered by the wiki, ask us on the Jenkins developers mailing list.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/09/jenkins-user-event-scandinavia-2015/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 9</div></div><h5 class="title">Jenkins User Event Scandinavia 2015</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/jues_0.png[image,width=270,height=181] +

+
+

For the 4th consecutive year the Jenkins CI community is gathering in Scandinavia. JUES inspires both current as well as soon-to-be Jenkins users to network and harness inspiration from peers and experts on best practice and implementation of Continuous Integration, Continuous Delivery, and agile development with Jenkins.

+
+

As always we’ll precede the JUES conference with a Code Camp on the day before. The Code Camp is a full day community event where developers learn from fellow developers on coding and plugin enhancement, all delivered back to the community.

+
+

We welcome you and other leading Jenkins developers, QA, DevOps, and operations personnel to this years Scandinavian Jenkins CI festival hoping to continuously support the growth of the Jenkins Open Source community.

+
+

REGISTER FOR JUES HERE<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/14/juseppe-a-custom-update-site-for-jenkins/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">14</div></div><h5 class="title">Juseppe, a custom update site for Jenkins</h5></div><p class="teaser">This is a guest post by Kirill Merkushev at Yandex. I met him at JUC Europe where he showed me the project he was working on: Juseppe. It looked really interesting, so I asked him to write this guest post.

When you write your first custom Jenkins plugin for internal use, it’s easy enough to deploy it on one or maybe two Jenkins instances. You can save it on your local drive and upload the HPI file via the Jenkins Plugin Manager as needed. It’s easy to do this for a few releases. But as your experience grows, the number of plugins and their releases grows as well. The plugins directory on your local drive soon looks like a garbage dump, and it’s difficult to find that most recent version of any plugin. And if you have a lot of Jenkins instances coordinating updates of your plugins may cause a lot of pain.

A similar situation is when you contribute a much-needed patch to an existing plugin, but you don’t have the time to wait until your pull request is be merged and a new release is cut. Or you may need to patch a plugin in ways not suitable for distribution, and decide to effectively fork the plugin for use on your Jenkins instances. How are you going to do this?

A solution avoiding the problems from these situations is to set up your own update site to serve your private plugin builds. Juseppe allows you to do this quickly and easily.

What is Juseppe?

Juseppe is an acronym for Jenkins Update Site Embedded for Plugin Publishing Easily. Juseppe can help you set up a Jenkins update site in just a few minutes.

Features

Generates signed update-center.json and release-history.json

Works with HPI files directly (stored in one folder), no need to set up a Maven repository

Watches for changes in the plugin folder and regenerates JSON files when changes are detected

Serves generated files and plugin files with built-in Jetty web server

Can be run in a &quot;generate-only&quot; mode when you want to use a different web server for these files.

How can I get Juseppe?

It ships as a Docker container, or can be built from source. Visit the GitHub project page to learn more. The complete user guide is available in the GitHub project wiki.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/15/advancing-the-jenkins-gui-configuring-items-in-jenkins/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">15</div></div><h5 class="title">Advancing the Jenkins GUI: Configuring Items in Jenkins</h5></div><p class="teaser">https://youtu.be/1Qn4jEwAeGc

Above is the screencast associated with this blog post

If you have ever used Jenkins you are familiar with what I am about to described, wading your way through job configuration page, looking for the settings that are important, and, depending on your plugin use, wondering where all these other setting came from and what they do.

+
Depending on how long you have used Jenkins, your negative opinion of this experience may vary. If you are a long-time user, you might even view the configuration page with that same reassuring nostalgia seeing a Facebook post from your ugly room mate induces. ‘Yup,he is still ugly and backwards, but we had some good times, back then.’ If you are a newer Jenkins user, it may well send you off to search the web for a viable alternative tool. +

+
The good news is that CloudBees, in cooperation with the greater Jenkins community, is looking to make some long overdue progress sorting through this user interaction in a way that is both approachable to new users and amenable to existing users who have grown comfortable with a great tool and a ‘stalwart friend’ in a world of otherwise clunky world of IT tools. ( that really is the swiss army knife of build automation.) +

+

If you happen to have had the opportunity to have attended any of the recent Jenkins User Conferences in Washington, DC, or London, you may have seen Tom and my presentation, which served as our initial introduction of this effort to the Jenkins Community. In this article and the associated video, I will be focusing specifically on the Create and Configuration screens in Jenkins, discussing some of the larger proposed changes, providing some context for the changes and examining their possible repercussions on existing plugins and future plugin development.

+
+

History of Jenkins

+

+
For newer Jenkins users, I have found the following visual a helpful guide to understanding the history of Jenkins and how its graphical user interfaces has evolved:

+
 +
image:/sites/default/files/images/history-jenkins_590.jpg[Jenkins timeline: a long history] +

+
The first thing to notice here, is that Jenkins has been around for a long time and in a lot of ways is really fundamental to the art of creating software. Back in 2005, the then Hudson project was using pretty much the same cave chalk as everyone else. 6 years later, the code and community underwent its most substantial transformation to date, as Jenkins emerged as the dominant fork of the Hudson project. If you look closely, you will see the GUI reflected that transformation by….. changing the picture of the butler. In recent times, the interface has taken a few additional steps forward, most notably by moving to a responsive CSS driven layout from its table based origin, but the pace of these changes has been very much akin to the pace of evolution. Slow. +

+
In our next phase of graphic interface development, however, Tom and I are looking to be a little more directed in our efforts and push the GUI toward a blend of strategic and tactical advancements that will help Jenkins take advantage of some of the advances in web design and browser technologies that have happened over the last 10 years. Our first major push will be in the job creation and configuration tasks. +

+

Creating and Configuring

+

[image]

+

+

+

In addition to a bit of a refresh of the look of these forms, this new effort focuses on the importance of dividing information and presentation into clear categories that ideally are meaningful to both new and veteran users of Jenkins alike.

+
+

In some cases, Jenkins has these categories already in the GUI, but misses the mark in clarification and emphasis. In other cases, additional categorizing concepts will need to be added. Compare the above screens to the existing screens.

+

[image]

+

[image]

+

The first thing you are likely to notice when comparing these two sets of screens is that in the existing screens, there is very little in the way of visual markers segmenting the form input choices on either the item type selection screens (fig 4 vs 2) or the configuration pages (fig 5 vs 3). Adding each new plugin progressively aggravates the situation, and consequently, as your Jenkins installation grows in sophistication and robustness, the average users ability to find the fundamental configuration settings in the sea of ad-hoc options diminishes. While adding functionality typically adds some amount of additional complexity to a UI, by giving each configuration option a visually distinguishable space in the form, the challenge can be greatly diminished and the pattern of creating an ever growing scrolling of toilet paper list of form elements can be avoided.

+

For figures 2 and 4, you might also notice that I have chosen Jenkins instances that already have several plugins installed as the basis for my example screens. You might rightly argue that for a basic install, there are not a lot of item types to create, so categorizing them adds a needless layer of complexity. Fair enough. It is my belief, though, that our software can be smart enough to count the item types available for creation and count the number within each category and handle the categorization as necessary. Counting and sorting is something that computers do incredibly well and is not the sort of thing busy people need to be overly burdened with.

+

In addition to the code being intelligent about when to present grouping categories to the user, The screen interaction can be similarly intelligent in how it enables the user to selectively show and hide the categories of interest. The following screenshot shows the configuration page focused in on CVS a particular option configuration in the source code management section of the configuration page. It, in turn, has its own sub settings for additional modules and locations (see fig 6).

+

[image]

+

…​and wait for it…​ …​for comparison, here is today’s CVS settings page…​

+

[image]

+

Despite some serious indentation, the existing page offers significantly less clarity about which settings pertain specifically to CVS instead of other aspects of a Jenkins job.

+

[image]

+

Identifying which settings go with which segment becomes all the more confusing when sub-sections can be re-ordered. To show you what I mean and fit the screen on a single printed page, I am needing to muck with the aspect ratio of today’s screen.

+

The image on the left (fig 7) shows a 2 step build process, each with sub parameters.

+

There are some fascinating looking red delete buttons in here, I hope I know exactly what part of the build step I am about to blow away…​. Did I mention these segments can be re-ordered? Care to guess which form inputs will move with which steps?

+

[image]

+

By contrast, the above screen shows the same 2 build steps with the same parameters. We still have our friend, Mr. Red Delete button, but now it is a good bit clearer who will get blown away.
Also, it is considerably clearer which block will be reordered, should I choose to do so.

+

What about plugins?

+

If you are a long-time Jenkins user, you may have a guess as to why some of these changes have been slow in coming, and if you are a plugin developer, you definitely know. These input controls have a lot of extension points in them that allow plugins to influence the content of this configuration screen. As a result, how plugins will respond to even the most minor layout changes is somewhat of a mystery. Further, the GUI control elements that make up the form are available to plugin authors to embed as they see fit in their own GUI elements. As a consequence, we have some serious compatibility issues ahead. These challenges are not at all trivial.

+

Fortunately, however, I believe with some careful manipulation and diligent testing we can overcome these challenges. The first set of changes are likely to revolve around a file called “hudson-behavior.js”. This file does most of the Jenkins client-side UI magic. If there is data to be bound to a control, this is the file that is likely to handle it. The difficulty with this file stems from two factors, its age (it is written following Yahoo UI framework patterns which have since been abandoned by Yahoo and the rest of the industry), and a presumption that the page layout will be governed by a single giant HTML table (likely due to the table renaissance happening around the same time, thanks to the emergence of GWT). Regardless of this bit of history trivia, these two issues combine to make changes to the HTML DOM structure of any Jenkins page problematic. Methods such as “findFollowingTR” assume a very rigid parent-child element positioning based on page layout rather than on the logical relationship between the data elements. The good news here is that despite some of their unfortunate names, can be refactored to both find the relevant element based on today’s table structure as well as a future logical nesting of related elements. With that change in place, Jenkins will continue to function as it always has and a future configuration DOM structure can share the same infrastructure.

+

+
The second step here will be finding efficient ways to integrate more modern Javascript libraries, such as JQuery and Bootstrap into the Jenkins GUI. We will want these libraries to be easier and cleaner for plugin authors to access than PrototypeJS and Yahoo UI are today. Likely this will involve using a Browserify/Requirejs like pattern to control script inclusion in page to avoid naming conflicts, excessively file attachment and global space pollution.

+

The final step would then be to begin amending, replacing and augmenting the Jelly based form control set, and thus, transforming the look and behavior of the Jenkins UI. As always, Jenkins is an open community, and we at CloudBees view that as a cherished cornerstone of our own corporate culture. Thus, at every phase of this undertaking we are eager to solicit feedback from and encourage participation by you the members of the community. Feel free to comment directly on this article. Additionally, I am maintaining and active thread on the Jenkins Developer group ( https://groups.google.com/forum/#!topic/jenkinsci-dev/6BdWZt35dTQ). I am looking forward to hearing from you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/gusreiber/">Gus Reiber</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/23/office-hours-are-back/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">23</div></div><h5 class="title">Office hours are back</h5></div><p class="teaser">After several months of inactivity, office hours, the bi-weekly meeting of Jenkins users and developers to learn more about Jenkins, are back.

I’ll host the first session next Wednesday at 11 am PDT. This session will be about Stapler, focusing on what Jenkins plugin authors need to know about it, e.g. request routing, form submission handling, or how Jelly/Groovy views work.

While this is going to be a developer-focused session, future session topics will also have Jenkins users as target audience.

For general information on office hours, and how to join, see the wiki.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/24/integrating-kubernetes-and-jenkins/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">24</div></div><h5 class="title">Integrating Kubernetes and Jenkins</h5></div><p class="teaser">Kubernetes is an open-source project by Google that provides a platform for managing Docker containers as a cluster. In their own words:

Kubernetes is an open source orchestration system for Docker containers. It handles scheduling onto nodes in a compute cluster and actively manages workloads to ensure that their state matches the users declared intentions. Using the concepts of &quot;labels&quot; and &quot;pods&quot;, it groups the containers which make up an application into logical units for easy management and discovery.

Kubernetes-related services by Google are the Google Container Engine, a Kubernetes-powered platform for hosting and managing Docker containers, and the Google Container Registry, a private Docker image registry.

Several new Jenkins plugins allow you to make use of Kubernetes and these services:

The Google Cloud Registry Auth Plugin allows users to authenticate with the Google Cloud Registry so they can push/pull images. This allows you to use the Google Cloud Registry with existing Docker-related plugins, like Docker build step plugin or CloudBees Docker Custom Build Environment Plugin.

The Kubernetes Plugin implements a cloud provider for Jenkins, and can create agents based on Docker images on-demand on your Kubernetes cluster or the Google Cloud Platform.

Watch Kohsuke demoing Jenkins/Kubernetes integration at OSCON earlier this week.

For a more in-depth look at how you can use Kubernetes with Jenkins, check out these posts on the CloudBees blog by Tracy Kennedy:

Orchestrating deployments with Jenkins Workflow and Kubernetes

On-demand Jenkins agents with Kubernetes and the Google Container Engine

Clustering Jenkins with Kubernetes in the Google Container Engine<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/24/juc-u-s-east-slides-and-video-are-now-available-online/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">24</div></div><h5 class="title">JUC U.S. East slides and video are now available online</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/dc_0.jpg[image,width=200,height=149] +

+
+

Slides and video from JUC U.S. East are now available online!

+
+

If you attended the conference, THANK YOU, and I’m sure you had fun, learned a lot and met many people from the Jenkins community. Now you can revisit your favorite talks or &quot;attend&quot; the ones that you missed.

+
+

If you were unable to attend JUC U.S. East, you now have the slides and video so you can &quot;attend&quot; anyways! If you like what you see and would like to attend a JUC this year, there is ONE date left in the 2015 Jenkins User Conference World Tour: JUC U.S. West is September 2-3 in Santa Clara, CA. Register here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/25/bay-area-jenkins-area-meet-up-is-looking-for-you/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">25</div></div><h5 class="title">Bay Area Jenkins Area Meet-up is looking for you </h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Fruit_preserves[image:https://upload.wikimedia.org/wikipedia/commons/7/7a/Welovejam_blenheim_apricot_jam.jpg[image]] +

+
+

+
Uday made a blog post yesterday that he is looking at organizing a regular Jenkins meet-up in the Silicon Valley Bay Area dubbed &quot;Bay Area Jenkins Area Meetup (JAM).&quot;

+
+

+
As a first step, he wants to have a kick-off meeting, to get more insights and opinions about what the topics could be and what people want to hear. I&#x27;m really looking forward to it as a means to build a local network, so I signed myself up as a speaker of the first meet-up.

+
+

+
If you are in the Peninsula, South Bay, East Bay, etc., please send some encouragements to him by posting a comment, or better yet, come to the kick-off meeting.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/28/reinforcements-for-the-subversion-plugin/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">28</div></div><h5 class="title">Reinforcements for the Subversion Plugin</h5></div><p class="teaser">This is a guest post by Manuel Recena Soto (aka recena).

Users of the plug-in know that it has undergone very important changes in the last two years.

Unfortunately, some of these changes resulted in regressions for some users that weren’t properly addressed in subsequent releases. Many users were therefore forced to keep using an older release of the plugin to keep their instances running.

To fix this difficult situation I’ve decided to dedicate my spare time to improving the plug-in and attempting to restore the stability that an essential plug-in like this requires.

In order to do so, me, my colleague Steven Christou and other members of the community have drawn up a plan.

In the coming weeks we will be focusing our efforts on:

Going through the Jira tickets

Checking whether they are duplicated

Checking whether they are still relevant

Asking for more information from the people who reported them

Establishing their priority

Reviewing pull requests

Investigating bug reports and try to reproduce them

Fixing serious bugs

Refactoring the plugin to improve its maintainability.

We’re planning to publish a new 2.5.x bugfix release once a fortnight. We are not considering the inclusion of new features or improvements. The priority now must be to obtain a stable and reliable plug-in, one that will allow us to take things up again in the future with greater security and peace of mind.

Interested in helping? Just send us a message!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/29/juc-europe-slides-and-video-are-now-available-online/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">29</div></div><h5 class="title">JUC Europe slides and video are now available online</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/london_0.jpg[image,width=250,height=165] +

+
+

Slides and video from JUC Europe are now available online!

+
+

If you made it to London to attend this year’s JUC Europe, I hope you enjoyed the conference , met plenty of community members and learned more about Jenkins. Now that the slides and video are up, you can revisit your favorite talks or &quot;attend&quot; the ones that you missed…​all at your leisure.

+
+

If you were unable to attend JUC Europe, well, now you can! The slides and video are here so you can &quot;attend&quot; any time you want. If JUC LIVE seems more appealing to you, there is one date left in the 2015 Jenkins User Conference World Tour: JUC U.S. West is September 2-3 in Santa Clara, CA. Register here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/07/30/juc-u-s-west-news-agenda-is-up/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">30</div></div><h5 class="title">JUC U.S. West News: Agenda is up</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/butler-kk-gk_0.jpg[image,width=250,height=194] +

+
+

It seems a bit unreal, but the last JUC agenda for 2015 is now online. Jenkins User Conference U.S. West is the last JUC of the year running from September 2-3 in Santa Clara, CA. So, if you haven’t attended JUC yet this year, this is your chance!

+
+

Register with a friend to take advantage of the community’s 2-for-1 deal and get two tickets for the price of one.

+
+

Which talk are you looking forward to most? Check out the agenda and tweet your choice to @jenkinsconf!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/03/just-a-month-left-until-juc-u-s-west/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 3</div></div><h5 class="title">Just a month left until JUC U.S. West</h5></div><p class="teaser">There’s only a month left until JUC U.S. West on September 2-3! If you’re still on the fence, check out the recaps of JUC Europe talks recently posted to the CloudBees blog. These should give you an idea about the kinds of talks you can expect at a Jenkins User Conference:

How to Optimize Automated Testing with Everyone’s Favorite Butler

Configuration as Code - The Job DSL Plugin

From DevOps to NoOps

If you’re interested in the upcoming Jenkins UI overhaul, make sure to attend Gus and Tom’s talk about it. Don’t want to wait until JUC to learn more about this? Follow the discussion on the developers mailing list and contribute through early testing.

This JUC will again have an Ask The Experts booth with several Jenkins experts and developers available there throughout the event. If you want to discuss Workflow with Jesse, or pitch your UI ideas to Gus, this is where you’ll be able to do that.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/04/bay-area-jenkins-area-meet-up-kick-off-gathering-today/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 4</div></div><h5 class="title">Bay Area Jenkins Area Meet-up kick-off gathering today</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Fruit_preserves[image:https://upload.wikimedia.org/wikipedia/commons/7/7a/Welovejam_blenheim_apricot_jam.jpg[image]] +

+
+

+
A week ago https://jenkins-ci.org/content/bay-area-jenkins-area-meet-looking-you[we reported that Uday is looking at organizing a regular Jenkins meet-up in Silicon Valley]. This has made a progress since then, and this evening we&#x27;ll get together to figure out logistics for the first meet-up:

+
+

Time

August 5th, Wednesday 6:30 PM - 7:30 PM

Location

Starbucks, 750 Castro St, Mountain View, CA 94041

+
+

+
The agenda is:

+
+

Determine the date for the first meet up

Speakers for the second slot. Kohsuke will be presenting first.

Future topics of interest for JAM

Sponsors / Volunteers

Ideas to make the JAM relevant and interesting for the extended community to participate and share their implementations

Q &amp; A

+
+

+
Uday and I will be there, and Uday told me that he heard from another guy who will join us. If you are around and is willing to come over, we&#x27;d love to see you. If you are interested, I&#x27;d also encourage you to join http://lists.jenkins-ci.org/mailman/listinfo/jenkins-events[the Jenkins events list], where a discussion is happening.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/04/wiki-and-issue-tracker-outage-over-the-weekend/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 4</div></div><h5 class="title">Wiki and issue tracker outage over the weekend</h5></div><p class="teaser">As you may have noticed, our wiki and issue tracker were unavailable from Thursday to Sunday last week. What happened?

We host parts of our infrastructure at the Open Source Lab at Oregon State (OSUOSL), including the databases for these two services. So far, there’s no post mortem by OSUOSL (they expect to post one later this week), so we need to piece together what we know.

The databases for the wiki and issue tracker became inaccessible around midnight/12 AM Thu/Fri night (all times UTC). Due to the large number and size of databases on that server, pulling from backups, restoring from backup and replaying the binlogs took them quite a while. During that time, we put up a maintenance screen on the wiki (and messed up the one for Jira, so there were connection timeouts instead).

The databases were back around 3 AM on Sunday. We disabled the maintenance screens around 6 PM later that day.

While this was a rather lengthy outage, it could have been much worse. We lost none of the data, after all. We thank the OSUOSL team for their efforts getting everything back up over the weekend!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/10/upcoming-office-hour-on-workflow/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">10</div></div><h5 class="title">Upcoming office hour on Workflow</h5></div><p class="teaser">Jesse Glick will host the next office hour this Wednesday, 11 AM PDT on Workflow.

Workflow has been Jesse’s project for the last year or so. If you don’t know what Workflow is, check out these talks about it from past JUCes:

June 2014

October 2014

June 2015

This will be a developer-focused session on integrating with Workflow. He’ll discuss things like how to make sure your plugin can be used as part of workflows, and best practices for extending the workflow DSL. There’s already been a session on Workflow in January, but Jesse hasn’t been idle, and there’s new stuff to share.

Participate in the Hangout on Air or watch live on YouTube.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/05/juc-speaker-blog-series-carlo-cadet-juc-u-s-west/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 5</div></div><h5 class="title">JUC Speaker Blog Series: Carlo Cadet, JUC U.S. West</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Mobile is Joining the Party At This Year’s Jenkins User Conference

+
+

Consider this as a shout out to mobile app developers: You are invited! For the first time, there’s a mobile track at this year’s Jenkins User Conference to discuss the best ways to extend CI/CD to mobile application testing.

+
+

As agile practices take hold, enterprises are expecting more collaboration between dev and test teams. Dev teams are doing more testing while QA teams are becoming more skilled at coding. This is happening now, and as a result open-source test automation frameworks like Selenium and Appium are flourishing. At the same time, CI/CD adoption is growing. This is happening more so for web development rather than mobile. It’s no secret that incorporating mobile test automation and CI comes with challenges. Mobile UI testing on real devices is still a manual process for many organizations. Manual testing is perhaps a path of least resistance, but it also commits teams to the longest delivery path. Some argue they lack the environment, resources or skilled people to create test automation. While the argument rages, its clear other teams are solving the challenge. Teams are prioritizing the requirement to build a test framework and aligning disparate tools into an effective CI workflow. Recent webinars with Paychex and RaboBank demonstrate CI/CD best practices can effectively extend to mobile app programs using real devices. Particularly when the lab is moved to the cloud and teams can focus on building robust test automation suites.

+
+

But overall, the transition to an agile SDLC for mobile apps is happening too slowly. Yet the mobile market demands constant updates. An essential part of an agile SDLC is utilizing automated testing and continuous integration. To test builds using a CI server requires automation which is key to agile development in a fast-paced mobile world because it allows testing to be done by developers early in the lifecycle.

+
+

Extending CI to mobile programs is easy with Perfecto Mobile’s support for open source frameworks such as Selenium Remote Web Driver, Appium and Calabash where existing CI plugins are available. Support for commercial tools like HP UFT is also available. With the Perfecto Mobile Jenkins Plugin, you can perform automated functional testing every build. The result is obvious, discover defects earlier, deliver faster feedback and increase release frequency and, ultimately, have better performing apps.

+
+

Learn more about extending your CI practice to mobile projects in our upcoming JUC mobile session: “Fast Feedback: Jenkins and Functional Mobile App Testing Without Pulling Your Hair Out.” The session will share suggested coding practices along with planning guidance on maximizing the quality coverage during daily, nightly and weekly builds.

+
+

The Jenkins User Conference US West takes place in Santa Clara, CA on Sep 2-3, 2015.

+
+

Stop by the Perfecto Mobile booth and share your story.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/cadet_0.jpg[image,width=152,height=182] +

+
+

This post is by Carlo Cadet, Director of Product Marketing at Perfecto Mobile. If you have your ticket to JUC U.S. West, you can attend his talk&quot;Fast Feedback: Jenkins + Functional &amp; Non Functional Mobile App Testing, Without pulling your Hair out!&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC U.S. West, the last JUC of the year!

+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/13/update-wiki-and-issue-tracker-outage/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">13</div></div><h5 class="title">Update: Wiki and issue tracker outage</h5></div><p class="teaser">I recently wrote about the two day outage of our wiki and issue tracker :

While this was a rather lengthy outage, it could have been much worse. We lost none of the data, after all.

OSUOSL have since published their post mortem. I was really wrong about not losing any data:

A further complication was that our backups were pointed at mysql2, which was out-of-date with mysql1, due to the initial synchronization failures. Fortunately, we had the binary logs from the 17th through the 30th. This means that though most data could be restored, some data from between the 15th and the 17th was lost.

For our issue tracker, that means that issues JENKINS-29432 to JENKINS-29468 were lost, as well as comments posted from about July 15 12:20 PM to July 17 2 AM (UTC). We know this thanks to the jenkinsci-issues mailing list where the lost issues and comments can be looked up for reposting.

We unfortunately don’t have such a record from our wiki.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/18/juc-speaker-blog-series-andrew-phillips-juc-u-s-west/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">18</div></div><h5 class="title">JUC Speaker Blog Series: Andrew Phillips, JUC U.S. West</h5></div><p class="teaser">Join Me at JUC West to Discuss Building an Enterprise Continuous Delivery Machine with Jenkins

+
+

+
image:https://blog.xebialabs.com/wp-content/uploads/2015/05/JUc.png[image,width=333,height=90] +

+
+

After a great event on the East Coast in June, now over to the West Coast for another exciting Jenkins User Conference! I’ll be there for JUC West on September 2-3 with the XebiaLabs team, and am looking forward to talking to the Jenkins users, partners, developers and community members that will be coming together.

+
+

At JUC East, I talked about the importance of Automated Testing in your Continuous Delivery pipeline, and I was really pleased by the number of interesting discussions and comments that came about as a result.

+
+

For JUC West, I’ll be taking a broader view, and will talk about building an &quot;Enterprise Continuous Delivery Machine&quot; around Jenkins. I’m going to focus on the challenge of identifying and choosing solutions for the many &quot;adjacent problem spaces&quot; to Continuous Integration that you run into when trying to move to Continuous Delivery: artifact management, feature tracking, environment provisioning, deployment automation, test management, pipeline orchestration, production feedback and more.

+
+

We’ll discuss some of the options available for each category, with a special focus on app deployment, test result management and pipeline orchestration. We’ll also present a couple of real-world Continuous Delivery Machine architectures, and analyze some of the motivations for each organization’s choices.

+
+

Most of our users use XebiaLabs tools/products in combination with Jenkins to build out their Continuous Delivery stack. If you’re scaling out your Jenkins usage too, stop by the XebiaLabs booth to see if you can pick up some tips and to say hello.

+
+

Look forward to seeing you at the event, or check the slides or recording we will post after the event. Hope to see you there!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/phillips_0.jpg[image,width=152,height=182] +

+
+

This post is by Andrew Phillips, VP, Product Management at XebiaLabs. If you have your ticket to JUC U.S. West, you can attend his talk&quot;Sometimes Even the Best Butler Needs a Footman: Building an Enterprise Continuous Delivery Machine Around Jenkins&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC U.S. West, the last JUC of the year!

+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/20/upcoming-office-hour-on-kubernetes/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">20</div></div><h5 class="title">Upcoming office hour on Kubernetes</h5></div><p class="teaser">Nicolas De Loof will host an office hour next Wednesday 11 AM PDT on integrating Kubernetes with Jenkins. Kubernetes is an open-source project by Google that provides a platform for managing Docker containers as a cluster.

During this session, Nicolas will introduce Kubernetes, explain how it can benefit Jenkins and demonstrate the Kubernetes Plugin.
Then he will discuss the design of the Kubernetes plugin and plans he has for future improvements.

Participate in the Hangout on Air or watch live on YouTube.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/20/volume-9-of-the-jenkins-newsletter-continuous-information-is-out/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">20</div></div><h5 class="title">Volume 9 of the Jenkins Newsletter: Continuous Information is out</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/volume9_0.preview.png[image,width=108,height=146] +

+
+

The Jenkins Newsletter is out a bit early this quarter. If you are not signed up to receive it via email, check out Volume 9 here.

+
+

You will be connected to all sorts of Jenkins resources from Jenkins training sessions, to some Jenkins User Conference news, to how Jenkins works with Kubernetes and Docker.

+
+

I hope that you enjoy this issue! Please let me know what content you find to be the most useful, reach out to me with content that you would like to see in the next issue, and feel free to tell me how I can improve the Jenkins Newsletter: Continuous Information. You can reach out to me at continuous-information@cloudbees.com. Thanks!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/24/juc-speaker-blog-series-kaj-kandler-juc-u-s-west/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">24</div></div><h5 class="title">JUC Speaker Blog Series: Kaj Kandler, JUC U.S. West</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Developing Enterprise-Ready Plugins

+
+

My greatest surprise at JUC 2014 in Boston was how many enterprise Jenkins CI users had developed plugins for their own use. I had not pictured enterprise release managers as plugin developers. Here at Black Duck Software, we developed Jenkins plugins for four years running. Fabrice Solami, a sales engineer, wanted to do more than automate our code scanning tool via a shell script step in the Jenkins job. He wrote a first plugin that added a build step to run the tool and configure the job more comfortably. The plugin became quickly popular, and when customers asked for it to also support maven builds and run on agents, it was time for help from the engineering team, particularly the integration team I lead.

+
+

Over the years we developed four more plugins and overhauled the original one with the user community (aka paying customers) growing to &gt;75 organizations, mostly large or really large development organizations. In the process, we received lots of feedback and discovered some Jenkins features we feel are essential for good plugin design for the enterprise. Let me share these insights so that you can consider them in your plugin development.

+
+

Credentials Plugin

+
+

Our plugins connect to our web applications and need authentication to utilize our SDK. The first plugins used username and password fields in every job configuration. That made tedious configuration work and stores the passwords in clear text in the configuration files on disk. Ouch!

+
+

We did wise up and started using the credentials plugin to manage username/passwords centrally and securely. It even allows setting authorization roles in such a way that the maintainer of a job can use the credentials without seeing the password. With that in place, our plugins are fit for banks and insurance companies and any other security-conscious organization.

+
+

Support the REST API

+
+

Did you know that Jenkins talks REST? We found it to be an easy way to create and update jobs. It is a really handy tool. The REST API is easy to script for all sorts of external interactions.

+
+

However, plugins need to do a little effort to support it on their part; yet it is almost trivial to do. So from our experience it should not be left out.

+
+

We wrote a small Java program that reads, creates, updates job configurations, and can trigger job runs. It reads the jobs and commits them to a file for easy mass editing and updates the jobs afterwards.

+
+

Our internal use case is to manage regression tests. We have medium-sized lists of jobs that run regression tests. With this tooling we can create a new set of jobs for a given plugin that runs against a new target server, that is, a server version under QA. It all happens in less than 15 minutes.

+
+

We also made this part of our migration from our first plugin to its successor with all the enterprise capabilities, but incompatible configuration. Using the REST API and some more Java programs we can create a csv file / Excel spreadsheet with jobs that are configured with the previous plugin. The user can filter the list with the spreadsheet application as needed, and then use the resulting list as input to the batch upgrade tool. This makes the upgrade a gradual affair and not a tedious exercise in UI configuration changes.

+
+

UpdateSites Manager Plugin

+
+

If you are developing plugins for in-house use, you have the option to install/update those through file upload. However, in an enterprise you likely have multiple Jenkins servers for different divisions, development groups, or regions. The notification of updates becomes tedious at best. Wouldn’t it be nice to run your own update site, so that your plugin(s) become discoverable in the “Available” tab of the “Manage plugins” screen? Wouldn’t it be a dream if available new versions show up automatically in the “Updates” tab, including Jenkins version compatibility check?

+
+

UpdateSites Manager plugin by IKEDA Yasuyuki is the answer to your prayers. It is easy to install, and the process to create and publish an update site is not too complicated and can become part of your Jenkins job building/releasing the plugin.

+
+

In my presentation at JUC 2015 West, I’ll share more details on how this makes a difference and how you can use these techniques to make your plugins enterprise-grade. As a bonus, I’ll show you how to get a free vulnerability report for your Maven or Gradle builds.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/Kandler_0.jpg[image,width=152,height=182] +

+
+

This post is by Kaj Kandler, Integration Manager atBlack Duck Software, Inc. If you have your ticket to JUC U.S. West, you can attend his talk&quot;Making Plugins that are Enterprise Ready&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC U.S. West, the last JUC of the year!

+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/25/announcing-the-travel-grant-program/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">25</div></div><h5 class="title">Announcing the travel grant program</h5></div><p class="teaser">We’re currently setting up a program to support community members&#x27; travel to Jenkins community events. Our goal is to enable more members of the community to meet each other and exchange ideas in person.

We’re still hashing out the details, but it’ll be available to every Jenkins community member. Apply, telling us what Jenkins-related event you’d like to attend and how awesome you are, and we may support your travel with up to 500 USD. For details on how this will work, see the current draft of the travel grant program.

The first person to be supported in this way is Pradeepto Bhattacharya from Pune, India. He was a speaker at this year’s JUC Europe in London, and will give two talks at JUC US West next week—​and we help him get there! He asked us a few weeks back whether the Jenkins project could support his trip to the US. We came to the conclusion that this would be a good idea—​so good in fact, that we decided to build a regular program from it.

Are you planning to attend a JUC or similar event, but worry about the cost of travel? We may be able to help you out!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/28/juc-speaker-blog-series-jamie-omeara-juc-u-s-west/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">28</div></div><h5 class="title">JUC Speaker Blog Series: Jamie O&#x27;Meara, JUC U.S. West</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Cloud Native and the benefits to Continuous Delivery (CD) Pipelines

+
+

There’s a lot of discussion lately around Cloud Native. If this term is new to you, I suggest a quick read of Cloud Native: What it Means and Why it Matters? From my perspective, Cloud Native offers tremendous benefit to enterprise companies, startups and developers looking to add value quickly or capture market share. Cloud Native platforms, such as Cloud Foundry, provide a number of features to reduce the effort of developing software and operating it on or off premise. A few notable features include load balancing, application routing, cluster scheduling, and containerisation. Cloud Native also offers a significant advancement for building integrated pipelines to deliver software. Before we discuss these advancements, let’s consider the role of the container.

+
+

Containers

+

One of the most influential components of Cloud Native is the container. At this point, containers are fairly ubiquitous and most developers have experimented or used containers. For instance, if you’ve pushed an application to Cloud Foundry or Pivotal Web Services, you’ve used an container without knowing it.

+
+

Initially containers were a place to automate the deployment and execution of your code, but over time customization became necessary to handle specific use cases. As a result, container creation now occurs earlier in the development and build phase. As applications are packaged within binaries and containers, validation of the application and container configuration needs to be validated before leaving the developer’s laptop. So what does this mean for the continuous delivery (CD) pipeline?

+
+

CD Pipelines

+

Developers will tell you their role has expanded over the years as agile methodologies have changed the way software is engineered. Techniques like Test Driven Development (TDD) and CD pipelines encourage software teams to deliver higher quality code in every build. Of course, a good CD pipeline starts at the developer’s laptop. Building and testing the start of a pipeline requires the correct tools while preserving the developer’s choice of container.

+
+

The diagram below demonstrates a simple CD pipeline. As you can see, the pipeline starts from the developer’s IDE and uses Cloud Foundry’s Lattice to provide a sandbox to validate the delivery artifacts. Lattice, based on Cloud Foundry’s container scheduler, delivers a small Cloud Native Platform that can be scaled up in the cloud or scaled down to a laptop. It includes a cluster scheduler, HTTP load balancing, log aggregation and health management for containers. Best part, it offers developer choice. Lattice provides support for both Docker containers and Cloud Foundry buildpacks.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/omeara-pic_0.png[image,width=600,height=366] +

+
+

Lattice’s flexibility makes it extremely easy to test how the application, which runs in a Docker container, will function in a Cloud Native environment. It’s also extremely helpful for developers engaged in a spike (prototype phase) where they want to push, validate and demonstrate code and let the platform handle the container creation, runtime environment and deployment artifacts via Cloud Foundry buildpacks.

+
+

Extending the CD pipeline beyond the developer’s laptop to deliver value to the organization will require additional tools like the CloudBees Jenkins Platform, Artifactory and Pivotal Cloud Foundry. These enterprise build-and-deploy solutions help developers deliver to a Cloud Native platform and reduce the time to establish the feedback loop. If the enterprise maintains a Hybrid cloud strategy, these tools make it seamless to deploy across different cloud providers.

+
+

As developers build more Cloud Native applications for Cloud Native platforms, it’s important to establish good tool chains and best practices early in the development phase. Interested to see these tools in action? Join us at Jenkins User Conference West on September 2nd to learn how I use these tools to build Integrated Deployment Pipelines with Jenkins and Cloud Foundry.

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/OMeara_0.jpg[image,width=145,height=180] +

+
+

This post is by Jamie O’Meara, Field Engineer at Pivotal. If you have your ticket to JUC U.S. West, you can attend his talk&quot;An Integrated Deployment Pipeline with Jenkins and Cloud Foundry&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC U.S. West, the last JUC of the year!

+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/31/jenkins-cia-program-and-meetup-updates/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">Jenkins CIA Program and Meetup Updates</h5></div><p class="teaser">A few years ago, the Jenkins community announced the Jenkins CIA program - the Continuous Integration Ambassador initiative to spread the word of Jenkins. As of recently, there hasn’t been as much activity, so this program needs to be revived!

+
+

There are over 120,000 active Jenkins installations now and that number just keeps climbing and climbing. It’s important to bring all of us together through big events like the Jenkins User Conference, but not everyone can get there. That is why Meetups and smaller Jenkins events are crucial.

+
+

To support this effort, CloudBees has announced that they will be sponsoring the kickoff of the CIA revival/https://jenkins-ci.org/content/bay-area-jenkins-area-meet-looking-you[JAM] to help the Jenkins community host these Meetups!

+
+

To kick this off, the first Jenkins Area Meetup (JAM) is in the San Jose CloudBees office on Sept 23. We are shooting to have a JAM everything 3rd Wednesday of every month to consistently bring the community together.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/31/juc-speaker-blog-series-laurette-cisneros-juc-u-s-west/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">JUC Speaker Blog Series: Laurette Cisneros, JUC U.S. West</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Jenkins_Butler_0.png[image,width=114,height=128] +

+
+

Last year’s JUC West 2014 was packed with good gems of information – such as &quot;how we did it&quot; talks where the speakers shared their points of view on the tools they use for automating their pipeline. At JUC and other conferences I especially seek out talks about how others implement their Continuous Delivery processes. At the upcoming JUC West 2015, it is my turn to share “how we did it” at Perforce. I will present my talk &quot;Continuous Delivery: Driving Lessons” and describe our journey, the rewards we reaped, and the challenges we faced along the way.

+
+

At Perforce, we see Continuous Delivery as taking the proven technique of automation and expanding it to a solid set of practices that make the pipeline even more efficient. This includes empowering the product teams to own production and quality all the way from requirements to delivery, and moving from a central build and release team to a self-serve infrastructure to remove the &quot;friction&quot; in the workflow. These changes have allowed us to quickly, efficiently and reliably adapt our software in line with user feedback, shifts in the market, and changes to the business strategy.

+
+

I look forward to seeing you there!

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/cisneros_0.preview.jpg[image,width=150,height=224] +

+
+

This post is by Laurette Cisneros, Engineering Tools Manager at Perforce Software. If you have your ticket to JUC U.S. West, you can attend her talk&quot;The Road to Continuous Delivery: Driving Lessons&quot; on Day 1.

+
+

Still need your ticket to JUC? If you register with a friend you can get 2 tickets for the price of 1! Register here for a JUC U.S. West, the last JUC of the year!

+
+
+
+
+
+
+
+

Thank you to our sponsors for the 2015 Jenkins User Conference World Tour:

+
+

+
image:https://jenkins-ci.org/sites/default/files/images/sponsors-06032015-02_0.png[image,width=598,height=579] +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/08/31/plugin-spotlight-version-column-plugin/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">Plugin Spotlight: Version Column Plugin</h5></div><p class="teaser">Most Jenkins controllers with a distributed build configuration will leverage nodes that run a agent.jar to start an agent. Regardless of whether the agent.jar is launched through a Java Web Start or SSH launcher, the jar will be copied from https://yourserver:port/jnlpJars/agent.jar to the build node. Keeping this jar up to date ensures that it picks up the newest features in a more recent release, such as the self-restart feature to keep agent JVMs “clean” and to automatically reconnect to their controller. Additionally, newer versions of this component may fix bugs or implement newer protocol versions with various improvements.

What is the Version Column Plugin?

Launch methods designed to pull the latest agent.jar are not always reliable and some launch methods don’t even try to update the agent.jar. Therefore it can be useful to see what agent.jar version is running on a given build node and take offline any nodes which fails to update to the latest version of the jar.

The Version Column Plugin allows Jenkins controllers to do just this, adding a new column to the “Manage Nodes” view and a new option for version enforcement on the node configuration screen.

Getting started

After installing the Version Column Plugin, navigate to the list of nodes in your Jenkins instance by clicking Build Executor Status in the executors widget below the side panel on the Jenkins home page.

If the plugin installed successfully, you will see a new column simply called “Version”. This column displays the version of the agent.jar that each build node is using.

This column is simply displaying the versions, so enforcement of agent.jar versions will need to be configured elsewhere. To activate this, click on the “Configure” link in the node manager’s left-hand menu.

You will then see a set of options for agents. To activate version enforcement, check the “Version” box and apply your changes.

When you update Jenkins, there’s a chance it’ll come with a new version of agent.jar. Now if the agent.jar on a particular agent doesn’t get updated automatically, the controller will take it offline and show a warning next to the out-of-date agent version number:

The Version Column Plugin is available for download in the Jenkins plugin manager or from its wiki page.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/09/01/take-the-2015-jenkins-survey/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 1</div></div><h5 class="title">Take the 2015 Jenkins Survey!</h5></div><p class="teaser">Just as in past years, we are running a survey this year, to get some objective insights into what our users would like to see in the Jenkins project. Obviously, the developers in the project deal with individual bug reports and feature requests all the time, but sometimes those day-to-day issues distract you from a bigger picture.

This year, we kept some of the questions the same, so that we can see the trend over time. But we also wanted to bring in some questions around how you are using Jenkins and what other technologies you leverage such as Linux containers and cloud services.

The survey will close at the end of September and, if you participate, you’ll get to see the results first. CloudBees is sponsoring the survey and as an added incentive for us to fill it out, CloudBees has pitched in a $100 Amazon gift card (thanks CloudBees!). Information you submit is only going to be used by the community and not by CloudBees. So please take the survey and let your voice be heard.

Finally, there are laws that govern prize giveaways like this and CloudBees has put up terms and conditions for this.

Take the survey here<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/09/03/jenkins-user-conference-west-day-1/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 3</div></div><h5 class="title">Jenkins User Conference West Day 1</h5></div><p class="teaser">+
image:https://pbs.twimg.com/media/CN6MLZnUsAAj0RD.jpg[image,width=300] +

+
+

+
Boy, what a day! This is the 5th annual JUC in San Francisco bay area, and the crowd is getting bigger. +

+
+

+
I brought the LEGO Jenkins + CloudBees logo mosaic that we built at the CloudBees San Jose office:

+
+

+
image:https://pbs.twimg.com/media/CN6Cid3UEAEx5xK.jpg[image,width=500] +

+
+

+
The community booth was very busy. We have people like Dean Yu (board), Andrew Bayer (board), Mark Waite (git), Jesse Glick (workflow and core), Daniel Beck (core), Vincent Latombe (literate), Steven Christou (subversion) and Owen Mehegan (community outreach) talking to people all day long.

+
+

+
If you are here, make sure to stop by, and if you are not, follow news with https://twitter.com/search?q=%23jenkinsconf[#jenkinsconf].<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/09/07/office-hour-on-proposed-ui-ux-changes/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 7</div></div><h5 class="title">Office hour on proposed UI/UX changes</h5></div><p class="teaser">Gus Reiber will host this week’s office hour on Wednesday, 11 AM PDT. He’ll talk about some of the UI/UX improvements in Jenkins that he’s working on, and will answer your questions about it.

He’s already given several talks about this, so you can check these out to learn more before the office hour:

JUC US East

JUC Europe

JUC US West

There are also some mailing list threads where he’s discussing his designs with the community:

February to April discussion

July discussion

The links to the Google Hangout (participate) and Youtube (watch live) will be posted to the wiki before the event. If you don’t get into the Hangout (limited number of participants), don’t worry: You’ll be able to send questions and suggestions to his Twitter account @gusreiber.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/09/19/office-hour-on-form-handling-in-jenkins/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">19</div></div><h5 class="title">Office hour on form handling in Jenkins</h5></div><p class="teaser">Update: This week’s office hour has been canceled.

This Wednesday, Sep 23, at 11 am PDT I will host another office hour on Stapler, the web framework used in Jenkins. This time, I’ll show you how structured form submission in Jenkins works, and how Stapler can help you with it.

As usual, the office hour will use Hangout on Air, and a limited number of people will be able to join and participate. The others will be able to watch the office hour live on YouTube. Links to participate and watch will be posted before the event on the Office Hours wiki page.

Update: This week’s office hour has been canceled.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/office hours">office hours</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/09/29/gui-improvements-on-the-horizon/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">29</div></div><h5 class="title">GUI improvements on the horizon</h5></div><p class="teaser">This past Thursday, September 24th, 2015, I presented a couple of prototypes of what I hope will be the future of the Jenkins GUI. Or perhaps more correctly, close enough to the future to start generating positive feedback from you the community that improving the Jenkins GUI is important and some pieces that I am showing are going in the right direction. If you have ~45 minutes to spare, I recommend the video (the narrator’s voice is very soothing). If not, I offer the following as a reasonable summary.

Jenkins has a lot of strengths as tool. Its robust user community along with its thoughtful and extensible design are two of the most immediate. They are the two pillars that have made Jenkins the leader in the CD/CI space and the de facto choice for most of us looking to automate our build and test processes. But let’s face it, by today’s standards, the GUI doesn’t really sing. I will even go so far as to say, I believe it is a platform liability at the moment, and even among we the Jenkins faithful, few of us look forward to using it.

In an effort to turn that tide, I traveled to this year’s 3 main JUC events, in DC, London, and Santa Clara, pushing the idea that enhancement is possible and providing an evolving sketch of what that might look like. The three main areas of enhancement I have targeted for a first round of improvement are these:

Item creation and configuration

Plugin selection

Workflow construction

Soon to follow, but not yet prototyped by me would be pieces dedicated to monitoring jobs in Jenkins as well as node and resource utilization and efficiency. Rightly or wrongly, I have started with the create and configure side of the GUI, as I see it as somewhat primary in a typical job creation scenario (you have to create a job before you can monitor it), but this second piece is no less important. Sadly, lips service is all I can offer you today, but more prototypes and video demonstrations are on the way.

Item Creation and Configuration in Jenkins

In most use cases, item creation means creating a freestyle job, so that is what I use as my base use case example. It is important to note, however, that most configuration in Jenkins happens through a shared set of GUI components. These components are a blend of Jelly files and Javascript and can be found in the …​/main/resources/lib/form directory in the Jenkins source code. In operating on these pieces, I have the opportunity to effectively enhance broad areas of the Jenkins experience, including aspects of plugin use that share these components. This greatly increases the upside of the effort as well as the possible drama and side effects, which I will go into more detail on later.

As for the upside piece, the first bit of improvement I am looking to attain is breaking up the many &#x27;toilet paper&#x27; style unbroken configuration lists sprinkled throughout Jenkins. The first example of this appears in item creation. On first installation, this issue is not immediately obvious, but if you have installed a variety of plugins or chosen to purchase CloudBee’s Jenkins Enterprise product, you will find that Jenkins can have quite a few types of items to create. While they do have descriptive text, I still find them difficult to differentiate and almost impossible to casually scan. Thus, my first suggestion is to add some form of categorization to the item types. For this to function correctly, the GUI will need to be smart enough to apply the categories only when item counts are sufficient to justify them (if you only have 4 item creation types, it doesn’t make sense to have 8 categories with which to sort them). But if you are a long time Jenkins user with many plugins you may also know it is possible to have more than a dozen item types. So if nothing else, an extension point that allowed for the categorization of item types seems helpful.

The configuration form itself, it also can become incredibly long with few landmarks or visual differentiation points. As a remedy, I propose calling out and clearly boxing each of the existing configuration sections and making sure that their names are as meaningful as possible. As an added step, I make the sections collapsible. This allows the user to jump to specific points in the form and tuck other areas out of the way. In some cases, we can make specific sections open by link context or even by user context.

Plugin Selection

Another essential piece of the Jenkins experience is plugin configuration. Today, if you are looking to add plugins to your Jenkins environment, you are almost certainly using Google to find a 3rd party review site, collecting the name of the plugin you want and then either linking to it on this website, or filtering for it in the Plugin Manager GUI.

Neither in the product nor on this website is there a particularly good resource for comparing plugins and evaluating which you might add.

Instead, I am looking to add something akin to an application store experience to both this website and the product UI. You should be able to group sort and compare plugins by a variety of criteria, including author, installation base, and user review. You should also have a set of general use categories that fits user needs and expectations, rather than the free ranging labels that plugin authors have arbitrarily applied today.

Workflow Script Builder

Finally, I have a GUI that allows for a sort of Drag-n-drop assembly of Workflows. A major tenant of the utility of Workflows as opposed to Freestyle jobs is that they can be completely separated from the Jenkins GUI and stored in a source repository. None-the-less, with absolutely no GUI, there is little to guide the user who is looking to get started without a upfront learning investment. As it turns out, a Workflow/Groovy script is pretty straight forward, but you don’t really know that until you have made one. Also, Workflow allows for the orchestration of jobs across multiple nodes of hardware resources, making it a potentially involved little bit of configuration. Thus, my goal here is two fold. Allow the user to model a workflow quickly and easily and showcase a few of the more advanced features workflow enables. The result is this script builder. My hope is to host the prototype somewhere you all might be able to use it directly, but in the meantime, my hope is that my video pretty well explains how it works. Please take a look and post whatever comments you see fit.

…​and really send along feedback…​

So with all things community related, please, please, send back whatever feedback makes sense. I can be reached via Twitter @gusreiber.

Other places you can find me include, IRC (freenode/#jenkins) and https://plus.google.com/GusReiberUI[Google ( https://plus.google.com/+GusReiberUI)]. I would love to hear from you.

Questions and Answers from the talk:

How likely is it that any of these UI changes will make it into the core open source Jenkins? When would we start seeing them there?
Most will be OSS. An exact schedule has not been determined, but most of it is still about a year away. Likely we will have an experimental wars for download along the way.

Is there anyway to determine which GUI attributes are contributed by which plugin?
I take it that is a bit of a feature request? It came up at JUC West as well. Should be something that can be surfaced in the GUI. I agree, it would be helpful.

What is the difference between ANT and Jenkins?
Ant is a good bit more bare-bones than Jenkins. In fact, you can add an Ant plugin to your Jenkins environment. You would typically use Ant to compile java source files. Jenkins orchestrates the fetching of the source files from some particular repository, the building of those files (often Jenkins uses Ant via its plugin to do this), running and reporting some suite of tests against that build, and then archiving or deploying the artifacts to wherever. Often times this requires navigating several computers with their own security constraints, so Jenkins helps you manage that as well.

What version of the Jenkins it is?
This isn’t available today, but I am building against 1.621-SNAPSHOT currently, but will upgrade with Jenkins to the coming December LTS. I’m interested in seeing the list of 100 plugins that you mentioned (by Daniel?) Me too. :^) He and the community (which can be you if want to join IRC freenode.net/#jenkins and attend the hangouts and governance meetings: https://jenkins.ci.org)

For IRC, I assume the server is freenode.net?
Yes.

Will there be any dashboard kind of feature for the build history in the new GUI?
So far, I have been focusing on the create and configuration portion of the Jenkins UX as I see it as a barrier to entry for new users. The read/report/analyze half of the Jenkins UX I actually see as the portion with more long term value, as you tend to read more often than you write, so I am eager to jump in here as well. …​.however, in its core today, Jenkins the tool seems to me to really want to see the world in the same context of flat XML files in folders as it actually persists its configuration data. To really make meaningful dashboards, it needs to be possible to query job configurations and build artifacts by a wide set of criteria that is not at all related to the folder in which the xml file happens to be stored. Also, some of the things you care about in the Jenkins universe are compute resources (controller/agents/exactures). These are also not the same as config files in folders and need to be queryable as their own first class type of entity. …​so what I am saying with a lot of words is that I see the config piece as a somewhat more immediate and urgent fix. The broccoli of the meal, if you will. I will want to get that out as fast as possible to get it out of the way. The reporting piece is actually the wine. At the moment, we are giving you Bartles and Jaymes in paper cups. …​so a lot of work is still needed there.

Have you investigated Google Polymer as UI components for jenkins UI?
I have not, but will now. I am actually quite a google fan-boy in much the way a lot of kids love Apple. (I also love Apple… being from Seattle, I even love MS). But, for the super near term, we are most focused on getting JQuery cleanly into core and Prototype.JS deprecated. Walk first, is my feeling.

Are there any tutorials on Jenkins workflow?
Jesse Glick or KK are better people to ask about that, really. They are also on IRC: freenode.net/#jenkins. Daniel Beck as well, might be a good person to ask. My little workflow demo is still really just fiction. Will there be a &#x27;Expand All&#x27; and &#x27;Collapse All&#x27; buttons for the accordions in new configure GUI? (I would probably inject one if not by default) Yes. Also, they should be URL controllable so that they can be set by link or user context easily. Maybe they should also remember what you had open last? …​stuff to tinker with that really needs to be right.

What impact does the UI changes have on job configuration behind the scenes? Is configuration still stored in XML format?
None. The post string stays the same and from then on, Jenkins is Jenkins.

Can the create item screen be configurable? At the moment, no, but ideally yes. It is still a big hand wave at the moment about how those categories are created, managed, and updated. The same categories ought to bubble back up when searching for the plugins to help relate what plugins generate what UI. I am hoping for guidance from the community. How will workflow fit in with new UI?
In some respects, the new configuration page is about enhancing the more traditional freestyle job and not workflow. However, the last bit of my presentation with the script builder is exclusively about workflow. The plugin manager is about plugins, so it would apply to both.

How is a human notified for the wait for approval step in this workflow?
So workflow approval can be done via the web GUI. But to get real notification, you would program that into your workflow Jenkins has a fairly large set of notification plugins. So you can use Jenkins to trigger email, or SMS, or HipChat, or Slack, or pretty much whatever. As these plugins are increasingly customized for workflow, you will get nice and nice workflow syntax for instantiating those actions. When my script builder is adopted, you would have a friendly button you could drag into the stage and it would notify you prior to the manual checkpoint.

Custom plugins still supported?
Yes. Though there is supported and supported. The highest level of support for a plugin would be a custom DSL for workflow that would make for streamlined syntax in workflow for interacting with that plugin via Groovy. But existing plugins do not need that level of support to be used within a Jenkins file / Groovy script. Instead, the syntax for accessing the plugin is likely to be more complicated. ….some plugins are freestyle specific, in which case, they no longer make sense in workflow. ….Daniel Beck or Jesse Glick are probably better suited to answering this question, however…​

Will there be an improvement in performance with docker builds, sonar scanning? From my experience sonar takes 20+ mins with jenkins plugin where as it takes 3 mins with maven plugin
Is this times it is taking the GUI to render, or the actual build to run? I am not sure I am following the question exactly, but regardless, I am not well equipped to answer many questions about performance issues in Jenkins. I know of a fairly major performance issue specifically in the configuration form that I believe will be fixed in the new GUI, but that isn’t build performance, it is just form rendering performance.

I like the graphical configuration. Thanks. The scripting of a complex workflow looked a bit daunting.
Cool. Yeah, my main and first goal is to get something out there that would allow folks to quickly sketch and deploy an actual working workflow that reasonably reflects an 80%ish use case. No GUI can ever be as fully flexible as a script, but I don’t think most people need the 95% case to get started and see the benefit of a versionable and robust config file format.

Will there be any effort to make the UI mobile friendly for the admin on the go?
Absolutely. Especially on the TBD read/reporting end of the UI, but everything new needs to meet a reasonably high bar of device responsiveness. Today, the Jenkins GUI is just not responsive. Which is terrible.

As a plugin developer do I need to change implementing the ui source from jelly or groovy to some other language/technique or will it be compatible?
So you will not NEED to change from whatever you are doing, except if you have built a plugin GUI that has custom script that either relies directly on behavior.js, hudson-behavior.js, or the particulars of the existing DOM structure (you do something in the client that requires your or some other input to be in a particular TABLE TR TD DOM traversal path). …​I believe 2 things are going to continue to happen at a faster and faster rate. New plugin authors are not going to want to write GUIs in Jelly and Prototype.js, but instead use some more modern client side MVC approaches like Angular, where the GUI interacts with a REST api instead of being a dom directly rendered from the server. It is a bit of a different mode of working than Jelly, and maybe slightly less direct, but it is a lot easier to find doc on how to do things with JQuery, Agile, Handlebars and the like, than it is to find doc on Jelly. And the responsiveness and breadth of gestures and controls in Jelly are already terribly behind what is now the main stream of web UI development. So I think plugin builders are, if they aren’t already, going to want better tools available to them. I also think that people are going to gravitate towards workflow or something similar. Since the UI for workflow is foremost a script, making a GUI for a plugin that works with it might be a fundamentally different beast. …​depending on what the plugin is trying to do… So again, new plugins or even upgrading existing plugins to work with workflow are likely want a new technology set, not just because the existing Jenkins GUI is changing, but because new plugins will want to do different and better stuff.

Are there connectors for other source control tools like CVS and Dimensions?
I am not sure exactly which connector plugins are already supporting Workflow or how deeply that support goes. Because Jenkins has plugins that provide access to these SCMs, you can use workflow to go and fetch those source trees. A greater level of support for workflow from these plugins would mean a more elegant workflow syntax for that interaction. At the moment, my GUI script builder is still fiction. My plan would be to add GUI buttons for whatever are the most popular SCMs and I will attempt to mask the syntax regardless of its clumsiness. ….the way I am constructing my initial prototype, there is already a reasonably clear extension point for adding buttons that generate some chunk of Groovy syntax when it is dragged into a stage. So I will add the initial set based on community feedback and then the community can continue to add their own.

What are the compatibility issues existing plugin developers needs to be aware of?
For plugins that interact with freestyle jobs, or really most job types that aren’t workflow, plugin developers should expect the page DOM structure to change. If for whatever reason, they find they are busting into some custom script to traverse the DOM to compare 1 setting to another, that will break. Also, hudson-behaviors.js itself has a number of functions in it that do DOM traversing, like “findFollowingTR”. In some cases the signatures of those functions might need to change and the DOM structure that they return might also change. If a plugin uses what were meant to have been internal functions, they are likely to break. Finally, the page geometry is going to change. This may seem so superficial and obvious that, who cares, but sometimes changing a column width translates into an important part of a GUI being hidden or otherwise inaccessible. That ends up being as critical a break as any other. …​so to combat these points of possible breakage, we are going to be looking for a handful somewhere between 20 and 100 plugins that we will want to test against. We haven’t made that list yet, let alone run any tests, so that is really a critical next step. For the plugin manager changes, I don’t see much if any of a braking issue, although I would like to add additional sorting and display power to the GUI, which means the GUI will need more metadata than currently exists, if the plugins want to take advantage of that new power in the GUI. This won’t break things, but plugin authors might want to go back to their plugins and fill in whatever the new bits of metadata end up being…. most likely they would be things like, richer descriptions, better category selections, and possibly icons.

I’ve not seen a lot of Jenkins but what I had I didn’t really get, was awkward for all the reasons Gus mentioned. This looks brilliant. When can we have it?
Tom and I, and now our junior pledge, Keith (not actually junior at all, just more fit than me), are busily typing as fast as we can as well as lobbying the community that our vision is more or less a correct one. We have a very interesting initial plugin selection GUI that might make this years final LTS (which I did not demo), which is none-the-less a nice step forward for Jenkins. In it will be a lot of the JS library bundling that will enable most of what I have shown in this demo. Our hope is that with each LTS we will be able to push out an additional piece of the GUI puzzle. Likely starting with the job create and configure GUI, which would be the mid year LTS. I am hoping that a year from now this will be how Jenkins looks and acts. ….in the meantime, we are grappling with how best to push preview releases so people can play with it and send me hate mail.

Is there any way to test front end of Jenkins plugins? And will that improve too?
A major and almost blocking portion of this work used to be the custom and somewhat broken version of HTMLUnit that was in core, which greatly hampered including libraries other than Prototype in Jenkins and writing code using those libraries in some sort of testable way. Our new approach to rebuilding the Jelly controls which are the foundation of the Jenkins config page and in general are shared by all plugins that need to post data back to Jenkins, already have a testing strategy backed into our design. Those Jelly form controls are extensible in Jenkins today and would remain so. Our hope would be that any plugin adding custom controls would follow our same design and test pattern we are building in core. ….so that was a long answer, but the short answer YES! Today, building GUI parts into your Jenkins plugin is a bit of a mystery, where most people copy something they saw someone else did, hack it, and the only test is, well…. it worked for me. That is no good and a fundamental piece we are looking to change. ….still a long answer… Node.js and Jasmine are the specific tools we using.

What’s the estimated rollout date for this workflow feature?
The workflow feature is the newest concept I demonstrated, but in a lot of ways may also be the easiest to ship. As a script generator, exclusively, it could be hosted anywhere, and then you just paste your generated workflow script into the whatever existing Jenkins GUI better, submit into your source code. ….but at the moment, it isn’t actually on an official roadmap yet. Assuming the response to it remain positive, I would expect that to change fairly quickly.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/gusreiber/">Gus Reiber</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/09/30/bay-area-jam/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">30</div></div><h5 class="title">Bay Area JAM</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Screen%20Shot%202015-09-30%20at%202.15.54%20PM_0.png[image,width=320] +

+
+

Last week, the first Jenkins Area Meetup (JAM) took place in San Jose, CA on Wednesday, Sept 23. What a way to kick off the first JAM other than to have Docker, John Willis as our guest speaker. John talked about immutable infrastructure and its benefits and role of containers.

+
+

Kohsuke discussed Jenkins Workflow, the motivation behind the same and latest features of Jenkins Workflow like multi branch support followed by docker use cases. The highlight of the meetup was definitely Kohsuke breaking the news about Jenkins 2.0 and his vision and motivation behind it.

+
+

The next Bay Area JAM is slated for Oct 21. Be sure to check HERE for the agenda. We’d love to have you join us if you’re in the area. If you’re interested in speaking, or become a food &amp; bev, venue, or recording sponsor please send email to the organizer or events@lists.jenkins-ci.org.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/02/winners-of-docker-global-hack-day-3-are/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 2</div></div><h5 class="title">Winners of Docker Global Hack Day #3 are...</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/docker-hack-day_0.preview.jpg[image,width=320] +

+
+

Over 2,000 members of the Docker community attended Docker Hack Day events around the world. One of the forty-two Docker Hacks has some familiar names attached…​

+
+

Nicolas De Loof and Yoann Dubreuil from Docker Rennes, who are also active in our community, waved the Jenkins flag in this event and produced Jenkins docker agents plugin.

+
+

+
This plugin lets you run builds inside containers, and in that sense it&#x27;s similar to https://wiki.jenkins.io/display/JENKINS/Docker+Plugin[the Docker plugin] and https://wiki.jenkins.io/display/JENKINS/CloudBees+Docker+Custom+Build+Environment+Plugin[the Docker custom build environment plugin]. But internally it uses a quite interesting approach. +

+
+

+
This fresh new implementation relies on a set of docker containers (aka ‘pod’) to setup a build executor, letting development team customize the build environment for their need without any constraint or prerequisite, and relying on docker containers to host test resources.

+
+

+
This project https://blog.docker.com/2015/09/docker-global-hack-day-3-winners/[won the 3rd place in the Freestyle category of Docker Hack Day]. Congratulations to Nicolas and Yoann on their win! Jenkins + Docker is a winning pair and this plugin will make a huge difference in your projects.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/09/cooking-up-jams/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 9</div></div><h5 class="title">Cooking Up JAMs</h5></div><p class="teaser">+
image:https://jenkins-ci.org/sites/default/files/images/Seville-JAM_logo_1024px_0.png[image] +

+
+

There’s been some active discussions and planning around Jenkins Area Meetups (JAMs) specifically in the following cities:

Rennes, France

Seville, Spain

Seattle, Washington

Barcelona,Spain

Raleigh, North Carolina

Atlanta, Georgia

+
+

I wanted to gauge Jenkins interests in these cities, so let us know at jenkinsci-jam@googlegroups.com if you live in one of these areas, and if you would be interested in becoming a member or be involved in JAM one way or another!

+
+

Of course, if the city you live in currently does not have a JAM and you’re interested in paying it forward, here’s HOW YOU can become a JAM organizer.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/01/upcoming-in-office-hours-jenkins-2-0/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 1</div></div><h5 class="title">Upcoming in office hours: Jenkins 2.0</h5></div><p class="teaser">+
I hope many of you have had a chance to see https://groups.google.com/forum/#!topic/jenkinsci-dev/vbXK7JJekFw[the Jenkins 2.0 thread]. +
I&#x27;m going to use https://wiki.jenkins.io/display/JENKINS/Office+Hours[the office hours next Wednesday] to go through this proposal. +

+
+

+
This is still primarily for developers in the project, as it&#x27;s &quot;just&quot; a proposal with lots of details unspecified. It&#x27;s more meant to help people understand where I&#x27;m coming from and what goals I have in mind for this effort. +

+
+

+
As always, this will be on Hangout on air. The event page is https://plus.google.com/events/co46heshe6i4io1dsaaj1h3th2c[here], and if you want to participate in the discussion, join https://plus.google.com/hangouts/_/hoaevent/AP36tYfvk_ZBO4dCmxysNPfi-R5_xlkgscU-r9WDq_8zXDv6VnN3kg[here]. Read-only viewers should use https://www.youtube.com/watch?v=fl5xfqtiNko[YouTube] to watch, and you can still send questions in real time to IRC and I&#x27;ll make sure to https://jenkins-ci.org/content/chat[go through them]. +<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/office hours">office hours</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/19/upcoming-in-office-hours-fosdem-planning-session/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">19</div></div><h5 class="title">Upcoming in office hours: FOSDEM Planning Session</h5></div><p class="teaser">For the past several years we’ve been attending FOSDEM, a massive free and open source event in Brussels, Belgium. In preparation for this upcoming FOSDEM (2016) event, we will be hosting an open planning meeting via Google Hangouts during this week’s &quot; Office Hours.&quot;

Agenda:

Gauge who can participate and at what capacity.

Pre-FOSDEM Contributor Summit

After-hours meetup/happy hour

Plans for a Jenkins stand (assuming we’re accepted):

What demo materials

Schwag

Revised Jenkins Flyer

The FOSDEM 2016 wiki page is where we will be recording plans and tasks will be added to JIRA. If you cannot join us via the FOSDEM Office Hours Hangout , we will also be watching the #jenkins-community channel on the Freenode network if you cannot participate directly.

Please join us on this Google Hangout at 11:00 a.m. PDT this Wednesday (Oct 21)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/office hours">office hours</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/25/jenkins-2-0-proposal-introduce-a-policy-for-api-deprecation/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">25</div></div><h5 class="title">Jenkins 2.0 Proposal: Introduce a policy for API deprecation</h5></div><p class="teaser">Over the past few weeks there has been a vibrant discussion happening on the
jenkinsci-dev@ mailing
list as to what &quot; Jenkins 2.0&quot; means.  While
Jenkins does not currently adhere to semantic versioning,
the change of a major version number does indicate a major milestone for the community.

Project founder, Kohsuke Kawaguchi presented his
vision for Jenkins 2.0 in a office
hours session, the slides for
which can be found in this Google
Presentation.
Roughly paraphrasing Kohsuke’s vision, 2.0 is primarily about making things
better for the thousands of users out there.

This week, we’ll be reviewing some key areas of the &quot;Jenkins 2.0&quot; proposal.
Asking you, the user community, to provide feedback on these proposals, going
from Jenkins internals to user interface.

Today’s post involves a proposal to introduce a policy for API
deprecation from community members Oliver
Gondža and Daniel
Beck. Extensibility is the heart of Jenkins, but over the past ten
years we’ve not had a proper API deprecation policy other than &quot;try not to
break plugins, ever.&quot;

Daniel, expanding more on the problem wrote:

We have no backward compatibility policy besides &quot;compatibility matters&quot;.
With 1000+ plugins and basically the entire core being available to
plugins, a lot of difficult or impossible to remove cruft has accumulated over
the last ten years. This limits both what can be changed in core, and makes
documentation difficult to use for plugin developers.

The two have put together a detailed proposal under
JENKINS-31035 which
suggests we:

limit the availability in APIs (classes, methods, fields, …​) provided by core
to a number of releases. Depending on the feature, this can range from a few
months, to a few years (e.g. two years being about 100 releases of Jenkins and
eight LTS baselines).

[…​]

I highly encourage you to read the entire proposal on the issue
tracker, where we are
trying to collect feedback/history.

Providing Feedback

We’re asking you to read the proposal in
JENKINS-31035 and provide
feedback if you have it.

If you have ever logged in to the issue
tracker or the
wiki, you have a &quot;Jenkins user account&quot; which
means you’ll be able to log into the issue tracker and vote for, or comment on
the issue linked above.

( note : if you have forgotten your password, use the account
app to reset it.)

We’re going to review feedback, make any necessary adjustments and either
approve or reject the proposal two weeks from today.

Stay tuned, and help make Jenkins 2.0 great!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/27/jenkins-2-0-proposal-split-groovy-out-of-core/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">27</div></div><h5 class="title">Jenkins 2.0 Proposal: Split Groovy out of &quot;core&quot;</h5></div><p class="teaser">As I mentioned in yesterday’s post, there’s been a lot of discussion recently about what &quot; Jenkins
2.0&quot; means. In a recent &quot;Office Hours&quot; session, Kohsuke Kawaguchi presented his
vision for Jenkins 2.0 in a office
hours session, the slides for
which can be found in this Google
Presentation.
Roughly paraphrasing Kohsuke’s vision, 2.0 is primarily about making things
better for the thousands of users out there.

This week, we’ll be reviewing some key areas of the &quot;Jenkins 2.0&quot; proposal.
Asking you, the user community, to provide feedback on these proposals, going
from Jenkins internals to user interface.

Thus far we’ve covered:

Introducing a policy for API deprecation

Today’s post involves a proposal originally from community member Jesse Glick who has proposed in JENKINS-29068 that Groovy be split out from the &quot;core&quot; Jenkins distribution. The linked issue expands on what the problem is here:

Currently Jenkins embeds a distribution of Groovy into &quot;core&quot; for a variety of scripting and management tasks. This version of Groovy is locked into core in such a way that users cannot upgrade Groovy independently from Jenkins itself. If the Jenkins-bundled version were upgraded to a different major version, it may break users&#x27; custom scripts as well as plugins that use Groovy due to API changes.

The proposal is relatively straight-forward and affects the many different users and use-cases for the embedded Groovy scripting support in Jenkins:

For ease of maintenance and modularity it would be useful to split Jenkins&#x27; use of Groovy into a library plugin; different clients could request 1.x and 2.x simultaneously by using different versions of the library, etc.

Stuff in core using Groovy that would need to either be put in this library (if infrastructure for other features) or put in another plugin depending on it (if first-class features themselves):

I selected this proposal to feature on this blog, despite its rather technical underpinnings, it will affect core developers, plugin developers, power and casual users alike. I encourage everybody to read through the proposal and its potential impact on the issue tracker.

Providing Feedback

We’re asking you to read the proposal in
JENKINS-29068 and provide
feedback if you have it.

If you have ever logged in to the issue
tracker or the
wiki, you have a &quot;Jenkins user account&quot; which
means you’ll be able to log into the issue tracker and vote for, or comment on
the issue linked above.

( note : if you have forgotten your password, use the account
app to reset it.)

We’re going to review feedback, make any necessary adjustments and either
approve or reject the proposal two weeks from today.

Stay tuned for the rest of the week as we keep with our theme of going &quot;from the inside out&quot; and help us make Jenkins 2.0 great!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/28/jenkins-2-0-proposal-pipeline-as-code-front-and-center/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">28</div></div><h5 class="title">Jenkins 2.0 Proposal: Pipeline as Code front and center</h5></div><p class="teaser">We have been featuring a few proposals this week for what &quot; Jenkins
2.0&quot; is going to include, today we’re discussing my personal favorite, which I believe will have a tremendously positive impact for years to come (not to be too biased!): moving the &quot;Pipeline as Code&quot; support in Jenkins to the front and center.

Thus far in this blog series we have reviewed proposals covering:

Introducing a policy for API deprecation

Splitting Groovy out of &#x27;core&#x27;

Today’s proposal comes from project founder Kohsuke Kawaguchi titled &quot; Pipeline as code front and center &quot; and represents perhaps the most important and dramatic shift we hope to make in Jenkins 2.0.

This functionality has existed through the workflow plugin, which we have discussed at various Jenkins events before but if you’re not aware of some of the power behind it, check out this presentation from Jesse Glick :

The proposal in JENKINS-31152 expands on the problem we aim to address:

The default interaction model with Jenkins has been very web UI driven, requiring users to manually create jobs, then manually fill in the details through a web browser. This requires large amounts of effort to create and manage jobs to test and build multiple projects and keeps the actual configuration of a job to build/test/deploy a project separate from the actual code being built/tested/deployed. This prevents users from applying their existing CI/CD best practices to the job configurations themselves.

To address this, Kohsuke is proposing that we :

Introduce a new subsystem in Jenkins that:

lets you design a whole pipeline, not just a single linear set of tasks

stores the said pipeline configuration as human-editable Jenkinsfile in your SCM

makes it automatic to set up new pipelines when Jenkinsfile is added

differentiates multiple branches in the same repository

This is the key new feature that positions Jenkins for continuous delivery use cases and other more complex automations of today.

Kohsuke’s proposal is largely about bringing together a lot of already existing pieces together to provide a very compelling experience for new and existing users alike. I hope it is clear now why this proposal is so exciting to me.

Providing Feedback

We’re asking you to read the proposal in
JENKINS-31152, which itself have some additional tickets linked under it, and provide
feedback if you have it.

If you have ever logged in to the issue
tracker or the
wiki, you have a &quot;Jenkins user account&quot; which
means you’ll be able to log into the issue tracker and vote for, or comment on
the issue linked above.

( note : if you have forgotten your password, use the account
app to reset it.)

We’re going to review feedback, make any necessary adjustments and either
approve or reject the proposal two weeks from today.

Stay tuned for a couple more posts covering proposals to improve the Jenkins interface and user experience!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/29/jenkins-2-0-proposal-ux-improvements-part-one/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">29</div></div><h5 class="title">Jenkins 2.0 Proposal: UX Improvements (Part One)</h5></div><p class="teaser">We have been featuring a few proposals this week for what &quot; Jenkins
2.0&quot; is going to include. Today we’ll be diving into the most noticeable changes being proposed for Jenkins 2.0: the User Experience (UX) improvements

Thus far in this blog series we have reviewed proposals covering:

Introducing a policy for API deprecation

Splitting Groovy out of &#x27;core&#x27;

Pipeline as code front and center

The UX improvements being proposed aren’t necessarily as uniform as the proposals from earlier in the week but represent a large amount of prototype and exploratory work done by folks like Tom Fennelly, Gus Reiber and a few others. Those following the dev list may have already seen some of these proposals in some of the &quot;mega threads&quot; that we have had discussing potential UI/UX improvements previously.

The improvements proposed for 2.0 can be found under JENKINS-31156 . The most promising proposal under this issue is to update the plugin manager experience.

Another very important proposal for 2.0 worth mentioning is the proposal to update UI work well on mobile devices.

Providing Feedback

We’re asking you to read the issues linked from JENKINS-31156 and comment and vote on those issues accordingly.

If you have ever logged in to the issue
tracker or the
wiki, you have a &quot;Jenkins user account&quot; which
means you’ll be able to log into the issue tracker and vote for, or comment on
the issue linked above.

( note : if you have forgotten your password, use the account
app to reset it.)

We’re going to review feedback, make any necessary adjustments and either
approve or reject the proposal two weeks from today.

Stay tuned for tomorrow’s post covering the remainder of the proposed user experience changes!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/10/30/jenkins-2-0-proposal-improved-out-of-the-box-user-experience/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">30</div></div><h5 class="title">Jenkins 2.0 Proposal: Improved &quot;Out of the box&quot; user experience</h5></div><p class="teaser">This week we have featured a number of proposals for what we would like to see in &quot; Jenkins
2.0&quot;, the vision of which is to make Jenkins users more efficient, productive and happy. We started with some more internally facing changes and have slowly progressed from the &quot;inside-out&quot; to today’s topic: improving the out of the box user experience. That is to say, the experience that a brand-new Jenkins user has when getting started with the server.

Just to recap, so far we’ve reviewed:

Introducing a policy for API deprecation

Splitting Groovy out of &#x27;core&#x27;

Pipeline as code front and center

User experience improvements (part one)

The subject of today’s proposal is captured in JENKINS-31157 , which, like yesterday’s proposal, contains a few issues linked from it with more details.

At a high level, the problem aiming to be solved is:

When a new user installs Jenkins, they are greeted with the main, empty, dashboard which suggests that they &quot;create jobs.&quot; This makes no mention of plugins or the configuration options that are relevant to helping the user make Jenkins match their needs.

In past and current versions of Jenkins, if you know what you’re looking for it’s relatively easy to move around the interface. If you’ve never used Jenkins before, it can be very challenging to find your way around or even know what it is possible to do with Jenkins.

The proposed changes aim to address this initial confusion:

Instead of changing the post-install defaults, which may not properly represent the user’s needs, the first-time user experience should help guide the user through configuration and plugin installation quickly so they can use Jenkins for their needs. Effectively it should be as easy as possible for a user to arrive at a good configuration for their usage.

Jenkins contributor Tom Fennelly, who has led this discussion on the mailing lists in the past, has posted a good prototype screencast of what some of this might entail:

Providing Feedback

We’re asking you to read the issues linked from JENKINS-31157 and comment and vote on those issues accordingly.

If you have ever logged in to the issue
tracker or the
wiki, you have a &quot;Jenkins user account&quot; which
means you’ll be able to log into the issue tracker and vote for, or comment on
the issue linked above.

( note : if you have forgotten your password, use the account
app to reset it.)

We’re going to review feedback, make any necessary adjustments and either
approve or reject the proposal two weeks from today.

This concludes this week’s blog series highlighting some of the Jenkins 2.0 proposals we felt were important to discuss with the broader Jenkins user audience. Many of these, and other minor proposals, can be found on the Jenkins 2.0 wiki page.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/11/01/adopt-a-plugin/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 1</div></div><h5 class="title">Adopt a plugin!</h5></div><p class="teaser">With more than a thousand public plugins in the Jenkins community now, it should come as no surprise that some of them are no longer actively maintained. Plugin authors move on when they change jobs, or lose interest in the plugin, and that’s fine. Plugins are hosted on the Jenkins project infrastructure after all, and when a maintainer moves on, others can continue their work.

The major problem of course is that it’s often difficult to tell whether a plugin is still maintained (and there’s just not a lot going on), or whether its maintainer has lost interest. Most plugins don’t get released every few weeks, or even every few months, and still do their job just fine.

To connect plugins that aren’t actively maintained with potential maintainers, we recently implemented the &quot;Adopt-a-plugin&quot; initiative: We built a list of plugins that are up for &quot;adoption&quot;, and display a prominent message on the plugins&#x27; wiki pages. Anyone interested in taking over as a plugin maintainer can then contact us, and we’ll set you up.

Are you interested in becoming a plugin maintainer? Maybe one of your favorite plugins isn’t actively maintained right now. Check out the Adopt a Plugin page for more details on this program, and a list of plugins that would benefit from your help.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/11/03/what-jvm-versions-are-running-jenkins/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 3</div></div><h5 class="title">What JVM versions are running Jenkins?</h5></div><p class="teaser">Preceding some of last week’s Jenkins 2.0 discussions, there had been some threads on whether we should move Jenkins to require Java 8. The introduction of Java 8 last year brought performance improvements and highly desirable API changes, which make developing Java-based applications (arguably) much easier than before. The release was followed earlier this year by the end-of-life announcement for Java 7; the writing is on the wall: upgrade to Java 8.

I wanted to answer the question &quot;does it even make sense to force an upgrade to Java 8?&quot; There are plenty of technical discussions that we can have in the community on whether or not this is the right approach, but my goal was to try and measure the current Jenkins install base for Java 8 preparedness.

While we do not currently (to my knowledge) collect Java runtime versions in our anonymous usage statistics, we do have access logs from our mirror redirector which might provide some insight.

With some access logs data, I went through the millions of requests made to Jenkins infrastructure in 2015 and started filtering out the user agent which made those requests.

NOTE: This data is totally not scientific and is only meant to provide a coarse insight into what versions of Java access Jenkins web infrastructure.

When Jenkins hits the mirror network, it’s not overriding the default user agent from the Java runtime, so many of the user agents for the HTTP request are something like Java/1.7.0_75. This indicates that the request came from a Java Runtime version 1.7.0 (update 75).

Looking at the major JVM versions making (non-unique) requests to Jenkins infrastructure we have:

1.8.0 : 21,278,960

1.7.0 : 27,340,214

1.6.0 : 4,148,833

This breaks down across various updates as well, which is also particularly interesting to me because many of these Java versions have long since had security advisories posted against them. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/jvm-versions-with-updates.png

As I mentioned before, this is not a rigorous analysis of the access log data and is also not filtered by unique IP addresses. What I found most interesting though is that the Java 8 upgrade numbers are actually fairly strong, which I didn’t expect. I expect that piece of the pie will continue to grow. Hopefully so much so that we’re able to move over to Java 8 before the end of 2016!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/11/06/mitigating-unauthenticated-remote-code-execution-0-day-in-jenkins-cli/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 6</div></div><h5 class="title">Mitigating unauthenticated remote code execution 0-day in Jenkins CLI</h5></div><p class="teaser">Updated 2015-11-11 15:00 UTC: We have released Jenkins 1.638 and 1.625.2 which contain a fix for this vulnerability. See the security advisory for more information about these releases.

Updated 2015-11-06 03:55 UTC: Included a updated mitigation script which doesn’t have a Jenkins boot race condition

Earlier today we received numerous reports about a previously undisclosed &quot; zero day&quot; critical remote code execution vulnerability and exploit in Jenkins core. Unfortunately the vulnerability was not disclosed to us ahead of its publication so we’re still working on more thorough fix. In the meantime however, we wanted to inform you of the issue and provide a workaround which will help prevent this exploit from being used against public Jenkins installations, for future reference this issue is being tracked privately as SECURITY-218 in our issue tracker.

The attack is mounted through the Jenkins CLI subsystem, so the work-around is to remove/disable the CLI support inside of the running Jenkins server.

Using the following Groovy script you can disable the attack vector in your Jenkins installations by navigating to “Manage Jenkins” and then to “Script Console”, or just go to https://your-jenkins-installation/script. This only addresses the current running Jenkins process, in order to make the workaround persist between restarts of the Jenkins server, add the script below to $JENKINS_HOME/init.groovy.d/cli-shutdown.groovy (create the directory if necessary, and the file).

import jenkins.*;
import jenkins.model.*;
import hudson.model.*;

// disabled CLI access over TCP listener (separate port)
def p = AgentProtocol.all()
p.each { x -&gt;
  if (x.name.contains(&quot;CLI&quot;)) p.remove(x)
}

// disable CLI access over /cli URL
def removal = { lst -&gt;
  lst.each { x -&gt; if (x.getClass().name.contains(&quot;CLIAction&quot;)) lst.remove(x) }
}
def j = Jenkins.instance;
removal(j.getExtensionList(RootAction.class))
removal(j.actions)

in order to make the workaround persist between restarts of the Jenkins server, add the script below to $JENKINS_HOME/init.groovy.d/cli-shutdown.groovy (create the directory if necessary, and the file).

The latest version of this script can be found in this GitHub repository.

As previously announced on the jenkinsci-advisories mailing list we’re preparing a security release for this upcoming Wednesday which will include patches for both the latest and LTS lines of Jenkins core. The Jenkins Security team is working to include a fix for this previously undisclosed exploit in or before this planned security release.

If you have questions about this exploit, join us in the #jenkins channel on Freenode or ask on the jenkinsci-users@ mailing list.

For security researchers and hobbyists, if you believe you have found a security vulnerability in Jenkins, we have some disclosure guidelines on this wiki page which will help us mitigate any discovered issues as quickly and safely as possible.

Be sure to subscribe to the jenkinsci-advisories mailing list ( jenkinsci-advisories), it’s the fastest way to get updates by the Jenkins Security team.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/11/06/october-jams/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 6</div></div><h5 class="title">October JAMs</h5></div><p class="teaser">It is great to see the pick up of local activities through hosted JAMs. In October, the Jenkins community hosted Atlanta JAM and Bay Area JAM. Many thanks to our sponsors: Ericsson, CloudBees, Blazemeter, NetRoadShow.

Here’s a summary of what was discussed:

Atlanta JAM - Jenkins workflow and Docker to reduce friction in DevOps efforts.

Bay Area JAM- Performance testing strategies, incorporating performance tests into Jenkins workflows and the metrics that matter most for troubleshooting and diagnosing issues.

A look forward to November and December:

Hacksgiving

Barcelona, Spain JAM

Toulouse,France JAM

As usual, if you’re interested in becoming an organizer or sponsor, here’s how to get started. If you’ve heard of a great Jenkins talk out there, shoot us an email with speaker info to jenkinsci-jam@googlegroups.com so we can invite him/her to our next meetups.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/11/11/new-jenkins-releases-with-important-security-fixes/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">11</div></div><h5 class="title">New Jenkins releases with important security fixes</h5></div><p class="teaser">We just released Jenkins 1.638 and 1.625.2 which contain important security fixes, including a fix for the zero-day vulnerability published on Friday. Please see the security advisory for more information.

Want to be kept up to date on Jenkins security releases, including advance notice on scheduled security updates? Subscribe to the jenkinsci-advisories mailing list!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/releases">releases</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/11/16/celebrating-hacksgiving/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">16</div></div><h5 class="title">Celebrating Hacksgiving!</h5></div><p class="teaser">Next week in the US we have a national holiday where, generally speaking, lots of turkey gets converted into left-over turkey sandwiches. For many software developers the Thanksgiving holiday also represents a lull in project schedules, freeing up some time to hack on pet projects or even contribute to open source projects.

Taking a cue from the Adopt a Plugin program that Daniel wrote about earlier this month, we thought it would be fun to organize a &quot;virtual hackathon&quot; to coincide with that gap in project schedules. Thus Hacksgiving 2015 was created!

We’ll be hosting Hacksgiving Nov 23rd and Nov 24 from 7:00PST - 15:00PST (10:00EST - 18:00EST) and would love for you to join! ( RSVP here)

You don’t need to know Java to help! We will have documentation and design hacking going on as well.

We have a few goals for Hacksgiving:

Introduce new contributors to the process of writing code and/or documentation ( documentation hacking details here).

Find some plugins which are up for adoption new maintainers.

Clean up or merge some existing plugins which need some care ( listed here).

=== Sessions to note

Here are some of the sessions scheduled that will be hosted by members of community that may interest you:

Day One

7:00PST/10:00EST ( 15-30min) - rtyler will host a welcome and introduction to contribution to the Jenkins project (walking through our contributors guide)

10:00PST/13:00EST ( 60min) - schristou will host a workshop titled &quot;Introduction to plugin development for Jenkins&quot;

Day Two

10:00PST/13:00EST ( 60min) - abayer will be hosting a &quot;Plugin Developer Open Q&amp;A&quot; session, so bring your questions!

Hacksgiving is very unconference structured right now, so if you’re interested in hosting a session please let us know in the #jenkins-community channel or by signing up for a session on the schedule

How to participate

Since this is a virtual hackathon, we’ll be congregating and chatting in a couple of ways:

On the #jenkins IRC channel as per usual

We’ll be hosting sessions and tutorials via Google Hangouts, see the &quot; hacker hangout * section on the wiki page up to date details

Via the #hacksgiving hashtag on Twitter

You can also RSVP on our meetup page!

We hope you can join in the festivities!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/just for fun">just for fun</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/02/hacksgiving-left-overs/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 2</div></div><h5 class="title">Hacksgiving Left-overs</h5></div><p class="teaser">Last week we hosted our first Hacksgiving event, a two-day virtual hackathon with a number of recorded sessions and plenty of pull requests submitted, I would say it was a success! I would like to thank everybody who took the time to watch, chat and present in the Hacker Hangout.

Now that everybody has had time to recover from the turkey and travel, we have some videos of the sessions sliced out and ready for publication.

In addition to the recorded sessions, there were a number of notes captured with useful links associated with practically each session. You can find those notes at the bottom of the Hacksgiving page.

The following videos are all available in this YouTube playlist

Intro to the Jenkins project

This session was hosted by rtyler and meant to provide a cursory overview of where to get started with contributing to the Jenkins project

Intro to Plugin Development Workshop

This session was given both days of Hacksgiving by schristou and does a really great job of introducing the viewer to getting started with developing a Jenkins plugin with Java.

Workflow Q&amp;A and Demo Session

This session was not originally scheduled, but some folks on the Jenkins IRC channel had some Workflow questions and Jesse Glick jumped into the Hacker Hangout to help us out!

Internationalization Live Coding / Q&amp;A

Another impromptu session, this time with danielbeck hosting. In this session Daniel walks through a plugin he was working on for Hacksgiving and adds internationalization support while answering a few questions here and there.

Intro to the new static site

Kicking off day two of Hacksgiving, rtyler hosted a session on the new statically-generated Jenkins site. The new site will dramatically lower the barrier to entry for contribution to Jenkins documentation and blogs, by pushing everything through GitHub.

Plugin Developer Open Q&amp;A

This was the last session of Hacksgiving, hosted by abayer and ended up being more like a casual discussion of the current status and future work in the plugin development ecosystem.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/video">video</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/03/pipeline-as-code-with-multibranch-workflows-in-jenkins/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 3</div></div><h5 class="title">Pipeline-as-code with Multibranch Workflows in Jenkins</h5></div><p class="teaser">Note: This is a guest post by Kishore Bhatia. Kishore works for CloudBees, building custom frameworks with Open Source software and helping customers solve engineering problems around continuous delivery and DevOps at scale.

This year some great new Jenkins features came out of the butler’s goodie bag - amongst them, the most important one being the ability to realize continuous delivery pipeline as code!
The features like Workflow Multibranch, pipeline-as-code (with a marker file that Jenkins looks for in your application’s SCM repository/branch, aptly named Jenkinsfile) are the foundations to making Jenkins super intelligent to automagically create workflows (rather, a CI/CD pipeline) to build your code and orchestrate the work required to drive your application from concept to delivery!

Overview

The Workflow Multibranch feature (provided by the workflow plugin) provides the following key abilities:

Automatic Workflow (job) creation in Jenkins per new branch in the repo (assuming webhooks are registered from GH to Jenkins).

Build specific to that child-branch and its unique scm change and build history.

Automatic job pruning/deletion for branches deleted from the repository, according to the settings.

Flexibility to individually configure branch properties, by overriding the parent properties, if required.

Jenkins pipeline-as-code (concept) enables you to maintain your CI/CD workflow logic in the project/application source code repo with no additional configuration to be maintained per branch in Jenkins.

The Workflow script to build/test/deploy your code is always synchronized with the rest of the source code you are working on.

To demonstrate the concept here - Let’s use a basic Java Web application project with a Maven pom.xml as shown in the structure below (this is using GitHub as the SCM but you can do this on SVN or Mercurial too).

This project has a marker file for Jenkins in the repo - Jenkinsfile. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic1.png

So, what’s a Jenkinsfile? The Jenkinsfile is essentially your Jenkins Workflow, a script, that defines the CI/CD pipeline logic for a project with steps to build/test/deploy etc. captured in various stages.

So for our sample Java web application, a basic Jenkinsfile could be something like -

node {
   // Mark the code checkout &#x27;stage&#x27;....
   stage &#x27;Checkout&#x27;

   // Checkout code from repository
   checkout scm

   // Get the maven tool.
   // ** NOTE: This &#x27;M3&#x27; maven tool must be configured
   // **       in the global configuration.
   def mvnHome = tool &#x27;M3&#x27;

   // Mark the code build &#x27;stage&#x27;....
   stage &#x27;Build&#x27;
   // Run the maven build
   sh &quot;${mvnHome}/bin/mvn clean install&quot;
}

Just having this file in the source code repo root would mean that -

Jenkins will automatically recognize this branch and create appropriate jobs by itself.

Quick, 1-step code checkout using: “checkout scm” in your workflow

Every time a new change is pushed to this branch, the branch is built and the commit status gets updated.

When the branch is destroyed in the repository, or if Jenkinsfile is removed, the corresponding job gets destroyed from Jenkins automatically ( You can retain these jobs and/or archive the builds for audit/compliance requirements using the retention property - Orphan Item strategy)

there are various mechanisms to promote reuse of Workflow scripts, such as the Workflow Global Library.

Required Jenkins configuration

Make sure you’ve the latest Workflow and (v1.11 as of writing this blog) Workflow Multibranch plugins installed on your Jenkins instance image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic2.png

Also, ensure that other dependencies, like SCM plugins and build tools, are met:

Either SVN/Git/Mercurial (depending on your SCM)

GitHub Branch Source Plugin (optimized to use the GitHub API and improve performance)

Maven build tool

Finally, make sure you’ve created the required Webhook from your SCM (Github in this case) to Jenkins.
Here’s how to do that:

Setting up GitHub Webhooks in Jenkins

Step-by-step guide to setting up Jenkins for GitHub projects

Then create a new Multibranch Workflow Job with configuration as shown below - mainly selecting the Branch Sources (Git, in this example) and providing the branch/repo URL with credentials.

Branch sources (Git) - https://github.com/kishorebhatia/pipeline-as-code-demo (or a repo where you’ve cloned this source code with Jenkinsfile)

Leave all other properties default and Save. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic3.png

You’ll observe that Jenkins would perform Branch Indexing on that “cd” job folder and start the workflow for the master branch, with an automatically created new job, named master, under the “cd” folder.

The workflow does a dummy step for application deploys to the environments in this sequence Staging -&gt; Waits for manual approval -&gt; PROD

Now, let’s create a new branch off of this master branch in your cloned git repo:

$ git branch newBranch (create a newBranch)

$ git checkout newBranch (switches to newBranch)

$ git push --set-upstream origin newBranch (pushes newBranch)

You’ll observe that your Jenkins instance automatically picks up this newBranch and starts running the workflow (with the Jenkinsfile in this newBranch) to build/test/deploy the code. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic4.png

Next, if you now delete this newBranch ( git branch -D newBranch), Jenkins will automatically remove the orphan Workflow job for newBranch. You can retain these jobs even after the branches are deleted using the Orphaned Item Strategy property in the main &quot;cd&quot; job’s configuration.

So we observed the following benefits of this pipeline-as-code approach:

Overall job definition is a script (Jenkinsfile)

Calls your build tools and scripts for details

The build script can be versioned alongside project sources

Jenkins handles feature/experimental branches automatically

Keep less configuration in $JENKINS_HOME

Dockerized Demo environment

You can also use the following docker image to run this demo with a preconfigured Jenkins environment and the sample job: jenkinsci/workflow-demo (i.e. docker pull jenkinsci/workflow-demo)

This docker container includes Jenkins with Workflow and Workflow Multibranch plugins, a local git repo with the aforementioned Java web application and Jetty to demonstrate a continuous delivery pipeline of this application deployed and tested across multiple environments in the pipeline with an approval gate before promoting to PROD (like QA, Staging and PROD).

There’s a &quot;cd&quot; job pre-configured as a multibranch Workflow job.

Launch the docker demo as: docker run -p 8080:8080 -p 8081:8081 -p 9418:9418 -ti jenkinsci/workflow-demo

Now, you can access Jenkins on port 8080 and Jetty on port 8081 from localhost or the IP of your boot2docker/docker-machine environment.

The demo container has a local git repo so you can clone: git://localhost/repo. When creating new branches, each branch automatically creates a matching subproject in Jenkins and triggers the build for that branch. The workflow:

Checks out source code from the same repository and commit as Jenkinsfile.

Builds sources via Maven with unit testing.

Runs two parallel integration tests that involve deploying the app to ephemeral server instances, which get thrown away when tests are done (this is done by using auto-deployment of Jetty)

Once integration tests are successful, the webapp gets to the staging server at localhost:8081/staging (or your docker-machine/boot2docker instance IP)

requires a human to Manually inspect the staging instance, and when ready, approves the deployment to the production server at http://localhost:8081/production/

References

Developer blog by jglick introducing multibranch support

workflow plugin tutorial

workflow plugin presentations

workflow plugin demo readme<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/guest post">guest post</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/09/security-updates-released-today/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 9</div></div><h5 class="title">Security updates released today</h5></div><p class="teaser">We released Jenkins updates today that include important security fixes: 1.641 and 1.625.3. For detailed information about the security content of these updates, see the security advisory.

One of these fixes, SECURITY-95, results in possible problems in plugins such as Maven Plugin, Javadoc Plugin, and HTML Publisher Plugin, so make sure to read all about that in the documentation.

Please note that the update site may lag a bit behind. If you want to update as soon as possible, download the releases from our site.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/16/workflow-best-practices-and-examples-repo-on-github/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">16</div></div><h5 class="title">Workflow Best Practices and Examples repo on GitHub</h5></div><p class="teaser">A lot of people are using the Workflow plugin, but as with any scripting environment, users often have to start from scratch and learn the same lessons and shortcuts that other users have already learned. While there are blog posts from developers and users in various places, and some samples in the Workflow plugin documentation, more examples and tips and tricks are always, always useful. To help with that, we’ve created the workflow-examples repository on GitHub, as a place to store community-developed Workflow scripts that can help new users get started, show how to accomplish some non-trivial goals, and find tips and trick for taking your Workflow pipeline to the next level.

The repository has four directories:

docs/ - documentation, guides, and more. Including a Best Practices document. We’d love to see more contributions to that doc, as well as any new ones that would be helpful to Workflow users!

workflow-examples/ - general Workflow examples, showing how to use a given plugin with Workflow, quirks of the Workflow DSL syntax, and more.

global-library-examples/ - examples of how to write code for the Workflow global library.

jenkinsfile-examples/ - Sample Jenkinsfiles or other Workflow scripts from SCM .

During Hacksgiving some initial content was added, but not everything is covered yet, which is why I’m posting this - more is needed. We’d love to see your tips, examples, gotchas and more. If you’ve got Workflow scripts you’d like to contribute, please read the README and send a pull request. Thanks!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/17/fosdem-2016-travel-grant-program/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">17</div></div><h5 class="title">FOSDEM 2016 Travel Grant Program</h5></div><p class="teaser">While we are gearing up for FOSDEM 2016 early next year in Brussels, I wanted to remind the Jenkins community about our Travel Grant Program. We’re a little late on mentioning it, but the board has allocated the money to help Jenkins contributors travel to Brussels to participate in FOSDEM and the Jenkins Contributor Summit which we will be hosting the day after, Feb 1st, which we’ll discuss more in a later blog post.

For the FOSDEM Travel Grant Program, we are able to cover up to $500 (USD) in expenses to help community members participate in FOSDEM.

If you’re interested, please read the description of the program below. Please note that some of the details of the program are different from the linked grant program page

Regardless we hope to see you all at FOSDEM on January 30th and 31st, 2016, in Brussels!

Eligibility

All community members are eligible for support unless they’ve received a travel grant within the last year (based on the event’s date). However, as we have very limited funds to support this program, we’ll prefer applications by active contributors to the Jenkins project.

If you have other possible funding sources, please look to them first. This will allow more people to attend a Jenkins community event.

Application

The application process for FOSDEM, due to our poor timing, deviates from the traditional Travel Grant Program.

To apply for a travel grant, send an email with the following information to the Governance Board at jenkinsci-board@googlegroups.com before January 6th.

Your name

The event you’d like to attend

The expected cost of travel (airfare, hotel, conference fees, etc.)

A description of your contributions to the Jenkins project, such as:

Plugins you developed

Pull requests you authored

Documentation you wrote

Public presentations on Jenkins-related topics

Why should we sponsor your trip?

Applicants Responsibilities

If you’ve been selected for a travel grant, we’ll expect you to:

Be available for a blog post about this program before the event.

Help out at the Jenkins stand at FOSDEM

If your schedule permits, we’d love to see you at the Jenkins 2.0 Contributor Summit the day after FOSDEM.

It should go without saying that we expect all Jenkins contributors representing the project at an event such as FOSDEM to act in a respectful and constructive manner. As we have not yet formally adopted our own Code of Conduct, we recommend reviewing the FOSDEM Code of Conduct.

After the trip, please submit a travel report to jenkinsci-dev@googlegroups.com mailing list. This report should include the following:

What you accomplished at the event

What you learned at the event

Contacts you made

Other useful information

We also expect you to submit your receipts via email to the person mentioned in the travel grant confirmation for review. We will reimburse actually incurred costs up to the 500 USD limit.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cia">cia</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/18/december-jam-world-tour-jenkins-developers-and-users-meetup-group-sf/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">18</div></div><h5 class="title">December JAM World Tour: Jenkins Developers and Users Meetup Group, SF</h5></div><p class="teaser">Thank you to Netflix for sponsoring the yummy
burrito bar and offered up their brand new auditorium to host Jenkins
Developers and Users Meetup group on Dec 16. We had 96 RSVPs which was
impressive. Our speaker for the evening was Akshay Dayal, Software Engineer at
Google. Akshay’s session was about Scaling Jenkins - how and why Google decided
to scale their existing Jenkins cluster (OSS) to meet their
security/availability and failover requirements and how heavy automation played
an important role in this effort.

The second talk was about how Google worked with Jenkins to read config data
externally. Slides are listed below. The video will be posted on the meetup
page) once it becomes
available.

Slides for the talks are linked below:

Scaling Jenkins

External Project

Check out where Jenkins Area Meetups
(JAMs) are located in the world. Don’t see a JAM in your area? why not start
your own, here’s
how.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/18/december-jam-world-tour-lima-peru/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">18</div></div><h5 class="title">December JAM World Tour:  Lima, Peru</h5></div><p class="teaser">Although December is a short month due to the holidays, there has been a good
amount of local Jenkins activities that took place regardless of holiday
obligations. Today and tomorrow I will be doing a series of posts to summarize
December JAM World Tour. Special thanks to the JAM organizers and co-organizers
who made it all happen in these cities:

Lima, Peru

St.Petersburg, Russia

Toulouse, France

Bay Area, CA

On December 9 Lima JAM
hosted their first Jenkins meetup in Lima, Peru. There were attendance from
various roles of DevOps: Dev, QA, and Ops. There was also a good mixture of
different levels of Jenkins users, some were new and just starting to use
Jenkins while others had extensive Jenkins experience.

The group has been invited by Docker and Ansible meetup organizers for a joint
event in January to showcase technologies from Jenkins, Docker, and Ansible.
Congrats to Lima JAM group.

Slides from the meetup can be found
here. Additional shared resources used in
the Lima JAM can be found here.

Check out where Jenkins Area Meetups
(JAMs) are located in the world. Don’t see a JAM in your area? why not start
your own, here’s
how.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/18/december-jam-world-tour-st-petersburg-russia/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">18</div></div><h5 class="title">December JAM World Tour: St. Petersburg, Russia </h5></div><p class="teaser">The first Jenkins meetup in Saint Petersburg, Russia took place on December
9th. The event has been organized with the help from Yandex and CloudBees.

In total there were about 80 attendees at the meetup. In addition to
meetup.com
the event has been promoted by Yandex so we quickly reached capacity limit.

There were 3 talks conducted, speakers from Yandex, ZeroTurnaround and
CloudBees. We discussed the current open-source project state, ongoing
activities in the community, Jenkins-powered CD case studies from
ZeroTurnaround and Jenkins plugin development approaches.

Intro slides [ru]

Who is Mr. Jenkins? Current State, common usage issues and trends in the community [ru], by Oleg Nenashev -   [ video ]

English version

Jenkins beyond CI. ZeroTurnaround’s experience [en], by Sergei Egorov - [ video ]

When to write your own plugin and when not to [ru], by Kirill Merkushev - [ video ]

Q&amp;A Session [ru], all speakers - [ video ]

Check out where Jenkins Area Meetups (JAMs) are located in the world. Don’t see a JAM in your area? Why not start your own, here’s how.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/21/december-jam-world-tour-toulouse-france/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">21</div></div><h5 class="title">December JAM World Tour: Toulouse, France</h5></div><p class="teaser">On December 15, the Toulouse
JAM
was co-hosted with the Toulouse
JUG and Toulouse
DevOps. Indeed it made sense since Jenkins is
written in Java, makes use of Groovy code in many places (system groovy script,
job dsl, workflow…​), and it also made sense to co-organize with the local
DevOps community since Jenkins is also a great tool to enable Continuous
Integration, Continuous Delivery and automation in general. There were 103
RSVPs, with 80 to 90 people in attendance.

There were 3 talks planned for the evening:

Job DSL
Intro [fr], by Ghislain Mahieux

Video recording

Workflow plugin [fr], by Michaël Pailloncy (co-maintainer of the Build Trigger Badge plugin)

Video recording

Feedback on almost 10 years of CI and what’s upcoming [fr], demo with Jenkins build scaling with Docker Swarm, by Baptiste Mathus

Video recording

Photos can be found here<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsci">jenkinsci</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2015/12/18/join-us-at-the-jenkins-2-0-contributor-summit/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">18</div></div><h5 class="title">Join us at the Jenkins 2.0 Contributor Summit!</h5></div><p class="teaser">As I mentioned in yesterday’s post, we’re planning a &quot;Contributor Summit&quot; on February 1st, after FOSDEM 2016 (January 30th/31st), to focus on Jenkins 2.0. Since many of us are already planning, the Monday following the event turned out to be the ideal time to discuss 2.0.

If you’re not already familiar with some of the key proposals that were put forth, you can review them in the Jenkins 2.0 proposals summery page.

We’ve hosted one or two Contributor Summits in the past, and they’re usually a day-long event where we try to gather a number of Jenkins core/plugin developers and active/power users to have detailed discussions around the theme of the summit. For this &quot;Jenkins 2.0 Contributor Summit&quot; we do not have a complete agenda yet, but we will post that to the Meetup event once it is fully prepared in the next couple weeks.

Suffice it to say, we’ll be discussing a lot!

Venue and RSVP

The Contributor Summit will be hosted in a CloudBees office at: Rue des Colonies, 11, Brussels, Belgium. If you’re already planning on attending FOSDEM, the office is near Grand Place and Cafe Delerium (where the Friday beer event is hosted).

The venue is of limited size, so if you’re planning to join us, please RSVP to the Meetup event as soon as you’re certain you will be able to attend. If you find yourself unable to attend, please remove yourself from the list to ensure that we can fit as many active contributors into the office as possible!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/01/05/new-website/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 5</div></div><h5 class="title">A new Jenkins website</h5></div><p class="teaser">When I first started working on the Jenkins
website, then called by a different name, I selected
Drupal, an extensible content management system, to
get the job done. Like Jenkins itself, Drupal is easy to set up, install
plugins and authoring content is done in a web UI. For the past seven years Drupal
has served us well, but it is time to move on to something better suited for our needs.

The general requirements for something newer were:

Easy to edit and create content

Changes to content should be tracked and reviewable

Any Jenkins contributor should be able to participate

Support mixed content types

The consensus was that a statically-generated site, with raw content hosted on
GitHub, would meet the majority of the &quot;ease-of-use&quot; type requirements. The
remainder could be addressed depending on the implementation. A couple of years
ago I tried to rebuild the site with static content using
Jekyll, commonly used by
GitHub Pages, but the effort stalled as I ran
into challenges with the mixture of content types we need to manage (stories,
events, pages, people, etc).

Having recently discovered Awestruct, a more
versatile and sophisticated static-site generator that powers sites like
asciidoctor.org, I ventured down that path.

To make a long story short, over the holiday break I finally pulled the trigger
and switched jenkins-ci.org over to the new site. In fact, the page you’re
reading right now was authored and published via our new
jenkins static site.

If you look at the bottom left-hand corner of this page
there is a link titled &quot;Improve this page&quot; which will take you directly to
GitHub to edit this post!

We have many more improvements to come for the Jenkins website, which are
tracked
in JIRA, but for now I invite members of the Jenkins community to help curate,
correct and create new blog posts and pages for jenkins-ci.org!

Check it all out on GitHub<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/www">www</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/01/07/official-code-of-conduct/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 7</div></div><h5 class="title">Jenkins Code of Conduct</h5></div><p class="teaser">Over the past couple months, we have been working on a long overdue
Code of Conduct for the Jenkins project (meeting minutes
here
and
here).
Following in the footsteps of other projects like the
Apache Software
Foundation, Go lang and
countless others, we have adopted this
code of conduct to help set guidelines for what behaviors are acceptable, and
what behaviors are not, when acting within the Jenkins community or on behalf
of the Jenkins project.

I would like to extend our gratitude to the authors of
the Contributor Covenant who provided us
with a very good and mostly finished Code of Conduct template. We have
adapted the covenant to meet the unique needs of a multifaceted
project like Jenkins.

The document itself is broken down into three sections, all of which I
encourage you to read:

The code of conduct itself

Instructions on how to report problems

An outline of how violations will be handled

Similar to many other process and philisophical documents in the Jenkins
project, the document is not etched in stone and is therefore intended to be
updated. If you’re interested in participating in the discussion about this,
and other topics around how the Jenkins project operates, I invite you to the
#jenkins-community IRC channel on the Freenode
network or to our regularly scheduled
governance
meetings.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/01/04/jenkins-at-scale14x/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 4</div></div><h5 class="title">Jenkins at SCaLE 14x</h5></div><p class="teaser">For the past few years, a couple members of the Jenkins project have made the
trip to Los Angeles for the
Southern California Linux Expo.
Despite the name it’s a fairly broad open source technology conference and
since it is hosted prior to FOSDEM, it’s also a good
conference to get us in the open source mood after the holiday break.

Unlike previous years, when SCaLE was hosted at the LAX Hilton, this year it has
grown and moved to the
Pasadena Convention
Center. There, as with previous years, we’ll have a table in the expo hall with plenty of
stickers and perhaps some other forms of swag available for devotees to
collect.

The expo hall will be open January 23rd and January 24th, and a few Jenkins
contributors will be there to ask questions to, talk about CI/CD and hand out
stickers.

Additionally, I have a presentation on
Saturday, January 23rd titled
&quot; Continuous
Delivery of Infrastructure with Jenkins&quot;

Talk abstract &quot;&quot;
In this talk we will review continuous delivery concepts and put them into
practice by building a continuous delivery pipeline with Jenkins to test, stage
and deploy to infrastructure code to production. Reducing the effort, error
rate and time it takes to deploy a configuration to change to production means
less time fighting fires and more time doing what you want.
&quot;&quot;

During the talk I’ll be highlighting some of the positive, and negative,
patterns used by the Jenkins
infrastructure team to manage, test and deliver the Jenkins project’s own
infrastructure. Sort of a followup from my
2014 PuppetConf talk about
migrating Jenkins infrastructure from controllerless
Puppet to a
Puppet Enterprise oriented
installation.

If you’re in the LA area, we hope to see you for SCaLE 14X in Pasadena!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/01/26/office-hour-javascript-development/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">26</div></div><h5 class="title">Office Hour: The State of JavaScript in Jenkins</h5></div><p class="teaser">Tom Fennelly will host tomorrow’s office hour on JavaScript in Jenkins.
The intended audience for this presentation is core and plugin developers.
In his own words:

I believe strongly that we can make meaningful user experience improvements to Jenkins, but it will require having more weapons in our arsenal in terms of how we build plugins etc. This is what we’ll be talking about in this week’s office hour. It will be a developer-focused session where we’ll start off by talking a little about how UI development has traditionally been done in Jenkins, before moving on to some newer patterns and tools that we have been developing over the last few months that let us make use of a wider range of more modern client-side development tools. We’ll also dissect and run some sample plugins that show these newer client-side dev tools in action.

As usual, the session will start 11am PST. Links to watch and participate will be posted to the Office Hours wiki page before it starts.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/office hours">office hours</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/01/27/jenkins-world-call-for-papers/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">27</div></div><h5 class="title">Jenkins World 2016: Call For Papers Is Open!</h5></div><p class="teaser">This is a guest post by Alyssa Tong.
Alyssa works for CloudBees, helping to organize
Jenkins community events around the
world.

Planning is underway for Jenkins World, a major Jenkins event for developers,
release engineers and others interested in automation. The conference will be
held from September 13th to 15th in Santa Clara, California and is being
organized and sponsored in part by CloudBees.
Just like the &quot;Jenkins User Conferences&quot; before it, this year’s event will
feature many experts from the Jenkins community that help make Jenkins
the most popular open source automation server on the planet. We’ve found that
we outgrew the popular multi-city one-day Jenkins User Conferences, so unlike
previous years Jenkins World will be a three-day event in one place with an
incredible amount of great content.

The goal of the event is to bring Jenkins contributors and users of all levels
together, from around the world, to discuss, share and learn from one another.
Starting today we’re opening the
call for
proposals . As a global event, users from all over the world are encouraged to
submit a talk between now and May 1st, 2016 (11:59pm PST).

We look forward to receiving your amazing submission, and seeing you in Santa
Clara this fall.

Submit a
proposal today!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins world">jenkins world</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/02/06/scale14x-conference-report/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 6</div></div><h5 class="title">SCaLE 14x Conference Report</h5></div><p class="teaser">Historically January has always been a very big month for the Jenkins
community. Between FOSDEM
Southern California Linux Expo (also known as
SCaLE) we seem to hand out more stickers during the last week in January than
any other week of the year.

This year’s SCaLE 14X conference finally outgrew the LAX Hilton in Los Angeles,
where it had been hosted in years past, and moved over to the Pasadena
Convention Center in Pasadena California. While the organizers of the
conference expanded their scope, so did the Jenkins project!

In addition to our normal Jenkins stickers, we also had some special edition
stickers with special
logos to give away this year, namely:

Angry Jenkins

General Jenkins

Superhero Jenkins

&quot;Cute&quot; Jenkins

Ninja Jenkins

To accompany the stickers we also had both blue Jenkins and red &quot;Angry Jenkins&quot;
pins. Savvy Jenkins users might recognize &quot;Angry Jenkins&quot; from the Jenkins
server’s internal 500 page; fortunately however very few people that came by
the booth to say &#x27;hello&#x27; were familiar with Angry Jenkins.

Talking Points

Aside from talking about the cool stickers and pins, we spent the vast
majority of time talking about Jenkins to two groups of people:

those who never had actually used Jenkins, even if they had heard of it

users who knew plenty about Jenkins but hadn’t actually heard about some of
the Jenkins 2.0 Proposals.

Anecdotally, it seemed like most of the people that I talked to about &quot;Jenkins
2.0&quot; were pretty excited about the Jenkinsfile idea and starting to define
their build processes and delivery pipelines as code
in their source repositories.

Perhaps more importantly though, we spoke with many users about where Jenkins
is causing them pain or frustration. Speaking directly with users at events
like SCaLE or Jenkins Area Meetups is always fun, having a high-bandwidth
conversation about what we can do better and/or offering solutions/workarounds
to hopefully relieve some pain-points.

In one such case, a contributor approached me and complained that he had
emailed the developers&#x27; mailing list and frustratingly never actually received
a response. Comically enough, neither of us were able to find the email he had
sent the mailing list (whoops!) but because of the dynamic nature of booth-duty
at SCaLE, we got him squared away with a repository to contribute a
Jenkins Charm for the Juju
configuration management tool.

Jammin&#x27;

Among the booth-duty highlights was meeting a few folks who were interested on
starting a southern California Jenkins meetup. Over the days following the
conference, and a brief discussion on the
jenkinsci-jam@
mailing list, and the
Los Angeles
Jenkins Area Meetup was born!

I’m looking forward to the meetup growing over the next couple months and
helping build a stronger local Jenkins community in Southern Califonia for the
other 51 weeks a year that SCaLE isn’t happening.

SCaLE is one of my more favorite
open source conferences, the positive community in attendance, a kid-friendly
atmosphere (&quot;Game Night&quot; was a blast) and the broad spectrum of sessions
available make it a great way to spent the weekend in southern California.

We hope to see you there again next year!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scale">scale</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/02/19/january-2016-sf-jam/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">19</div></div><h5 class="title">January 2016 San Francisco JAM Report</h5></div><p class="teaser">On January 20, the first San Francisco JAM
(Jenkins Area Meetup)
of the new year was held at Mesosphere ’s offices.
We had two speakers - myself, and Roger Ignazio, an infrastructure automation
engineer at Mesosphere. Around forty people attended and enjoyed the food and
drinks Mesosphere provided for us.

Links to the talks are below:

Elastic
Jenkins with Mesos and DCOS, by Roger
Ignazio

Who is Jenkins?,
by Andrew Bayer

More JAMs will be happening in the coming months - for example, the first
Los Angeles JAM is
tentatively planned for early March, 2016! You can always find out the latest
on JAMs around the world at the
Jenkins Area Meetup page.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/02/24/jenkins-security-update/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">24</div></div><h5 class="title">Jenkins security updates</h5></div><p class="teaser">We released Jenkins updates today that include important security fixes: 1.650 and 1.642.2. For detailed information about the security content of these updates, see the security advisory.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/02/29/jenkins2-alphas/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">29</div></div><h5 class="title">Jenkins 2.0 alphas released</h5></div><p class="teaser">After first
announcing the
Jenkins 2.0 effort last fall, we are pleased to announce the availability of
the first Jenkins 2.0 alpha builds. For months we have had builds
available from the jenkins_2.0
branch of development, but the &quot;alpha&quot; builds mark Jenkins 2.0 being
officially made available for testing and feedback.

Download 2.0-alpha now

Jenkins 2.0 Highlights

Pipeline as Code

The new Pipeline functionality in Jenkins allows you
to define configuration as code, which can be checked in and version controlled
along with the rest of your project’s source code.

Defining your pipeline’s configuration as code makes it easier to create a
simple &quot;build and test&quot; pipeline, while enabling more advanced and complex
pipelines through the expressive Groovy-based domain specific language.

Out of the box experience

For new users, Jenkins 2.0 starts off with set of recommended plugins, seen in
the image above,  to help get you started with the right set of tools to get up
and running with Jenkins quickly.

For the more adventurous users, the Jenkins 2.0 initial setup process
also allows you to pick and choose exactly the plugins you want to meet
your specific needs.

Totally backwards compatible

Jenkins 2.0 is a drop-in replacement of the Jenkins 1.x series of releases
and fully backward compatible. There will be practically no reason not to
upgrade once 2.0 is released in the next couple of months.

Tell us what you think!

We’re very interested in your feedback on what you think of the Jenkins 2.0
preview releases.

If you use Twitter, you can leave us some feedback
on
Twitter

Our jenkinsci-users
mailing list is also available for feedback in
this thread

And of course, since this is a preview release, if you find any issues please
report them to our
issue tracker
to the JENKINS project.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/02/toulousejam-hackergarten/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 2</div></div><h5 class="title">Jenkins Hackergarten : mercredi 9 mars 2016 à Toulouse</h5></div><p class="teaser">Vous êtes développeuse ou développeur, vous avez envie de découvrir le projet
Jenkins de l’intérieur, en bricolant sur un sujet qui vous intéresse, lisez
la suite !

Mercredi 9 mars, le Toulouse Jenkins Area Meetup
organise à Toulouse un Hackergarten Jenkins, occasion idéale pour faire ses
premiers pas dans la communauté assisté(e) d’un contributeur au projet.

Hackergart quoi ?

Hackergarten est un mot qui provient de la contraction des mots Hacker et
Kindergarten, ce dernier étant le mot allemand qui désigne en gros l’école
maternelle.

Comment ça va se passer ?

En partenariat avec le Toulouse Java User Group
(c’est sur ce lien qu’il faut s’inscrire), nous nous donnons rendez-vous à
partir de 18h30 dans les locaux de l’Epitech Toulouse, chacun avec son
ordinateur (non fourni), et on commence à jouer.

Et c’est bien sûr gratuit et ouvert à tous.

Un tableau trello a été initialisé
pour tenter de s’organiser un peu. La liste des choses à faire n’est pas du
tout figée, et les idées sont les bienvenues.

Les commentaires sont ouverts à tous, et l’accès sera donné à quiconque en fait
la demande (façon communauté Jenkins :-)).

Goodies !

Grâce à l’aide de CloudBees, on a pas mal de goodies à offrir : stickers,
badges, t-shirts et bobble-heads !

Les Bobble Heads Jenkins

Nous en avons 2 ! Et ceux-ci
seront offerts au deux premiers participants à voir leur pull-request
envoyée pendant la soirée mergée .

Que faire pour (se) préparer ?

Si vous n’en avez pas, créez-vous un compte pour les services suivants :

Jenkins

GitHub

Trello

Au niveau machine, idéalement, vous avez :

Git et Maven bien installés

Docker installé (natif sous Linux), ou via
Docker Toolbox pour
les autres OS

Des informations plus précises seront normalement données très bientôt aux
inscrits via meetup quant à la préparation des machines.

Quel(s) langage(s) faut-il connaître ?

Idéalement, puisque Jenkins est écrit en Java, il serait souhaitable que vous
 connaissiez au moins les bases.

Toutefois, même si par exemple vos compétences sont plutôt côté Web, il y aura
aussi des choses à faire, que ce soit jouer avec le
nouveau site en préparation,
ou ajouter une page web câblée
sur certains fichiers json des statistiques.

Connaître au moins les bases de Git sera un gain de temps, mais ce n’est pas
indispensable.

Récapitulatif

locale=fr-FR&quot;&gt;Pour s’inscrire (indiquez Jenkins à la question posée au _RSVP)

le tableau Trello dédié aux activités de la soirée (demandez l’accès !)

Cf. ci-dessus pour les choses à installer sur votre machine

N’hésitez pas : l’ambiance est accueillante, et on offre les pizzas !<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hackergarten">hackergarten</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/01/10/beautiful-jenkins-dashboard/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">10</div></div><h5 class="title">A beautiful Jenkins dashboard</h5></div><p class="teaser">This is a guest post by Julian Kleinhans,
Software Architect at AOE, who is outlining some of the
Jenkins dashboard work he’s done with
dashing-js

Jenkins offers a handful of third party dashboards, but none of them are really
beautiful and flexible enough from my point of view. For example, I could not
find a solution which gives me the possibility to easily decide which data
should be display in the widget and which not. It also doesn`t have the
possibility to add additional widgets to the dashboard which have nothing to do
with Jenkins. So I came up with something interesting that includes Jenkins
data. But I cannot do that with the existing built-in dashboards from Jenkins
plugins which are Jenkins-content specific.

So I decided to write a new, flexible and extensible dashboard. To avoid
re-inventing the wheel I also decided to use
dashing-js as a basis and not
Jenkins itself. dashing-js is a Node.js port of
Dashing, a Sinatra -based
framework that lets you build beautiful dashboards.

The key features of Dashing are:

Use pre-made widgets, or fully create your own with Sass, HTML and CoffeeScript

Widgets harness the power of data bindings (via batman.js) to keep things DRY and simple

Use the API to push data to your dashboards or make use of a simple Node.js script for fetching data

Drag &amp; drop interface for re-arranging your widgets

The advantage over a native Java-based Jenkins plugin is that you don’t need to
know Java and the whole Java stack. You can also easily add other pre-made
third-party widgets, for example a GitHub Pull Request count widget or an AWS
statistic widget or whatever else. In other words, it is completely independent
of Jenkins. All you need is Node.js and the permission to access the
Jenkins API.

Beside dashing-js you will need my
Jenkins Job widget. It is a
generic widget for Jenkins jobs which provides a highly visible view of the
build status and build progress of selected Jenkins jobs. Via configuration it
is possible to add multiple widgets for different Jenkins jobs (as you can see
in the screenshot below).

So, all you need is dashing-js, my Jenkins Job widget and some
npm packages.  The installation and the setup is really
easy and can be found here.

Example<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kj187/">Julian Kleinhans</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/dashboard">dashboard</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/03/gsoc2016-announcement/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 3</div></div><h5 class="title">Jenkins joins the Google Summer of Code 2016</h5></div><p class="teaser">We are happy to announce that Jenkins project application has been accepted to
Google Summer of Code 2016 (GSoC). Thanks
to everybody who helped prepare the application and submitted project ideas!

We would like to invite students to join the Jenkins community and work together
on the ongoing Jenkins 2.0 activities and other medium-term projects.

The student projects we are primarily interested in would improve the overall
Jenkins user experience in a number of different aspects. This includes user
interface changes and stability improvements but also major new features such
as Pipeline as code.

The projects we’ve suggested revolve around all parts of the Jenkins project:
core, plugins, website and our internal automation infrastructure. More details
on what has been suggested can be found on the
wiki
which include:

Jenkins web interface improvements

&quot;Update Center 2.0&quot;

New generation of the fingerprinting engine

External workspace manager

Integration of Docker plugins with Jenkins 2.0 features

Plugins for Electronic Design Automation and Embedded tools integration

Improvements of the Support plugin

Improvements to Jenkins project infrastructure: core infra, website, plugin documentation and more

If you are a student:

Check out the project ideas here.

Select an interesting project idea or draft your own proposal.

If you are not familiar with Jenkins, we highly recommend trying it out with one of your previous projects. You can also try available Jenkins features from the project ideas.

Introduce yourself the community and start your project proposal discussion (see the guidelines here).

Join us at GSoC office hours. We plan to have two meetings starting on March 7th.

If you want to be a mentor:

Feel free to team up with other mentors

We accept extra project proposals from mentors until March 9th.

Links

Jenkins project page on the GSoC2016 website

GSoC2016 page on our wiki

Announcement in Twitter<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/11/new-jenkins-20-preview/"><div class="header"><div class="date"><div class="month">March</div><div class="day">11</div></div><h5 class="title">Jenkins 2.0-alpha-3 Preview Build has been released!</h5></div><p class="teaser">We just published the new Jenkins 2.0-alpha-3 preview build.

What’s new?

Jenkins is now secure out of the box :
Administrators previously had to set up authentication and authorization
while Jenkins was accessible to anyone on the same network.  Now, Jenkins is
protected out of the box, so that it is always safe from unauthorized
access.

Plugin selection for setup :
We refined the plugin selection on the setup dialog.
You’ve always wondered why Jenkins does not install the Git Plugin by default?
Now it does, along with a number of other plugins popular in the Jenkins community.
We’re also including more plugins complementing the
Pipeline plugin :
The
Pipeline
Stage View plugin lets you quickly see what’s going on in your CD pipeline,
and the GitHub
Organization Folder will automatically scan your GitHub organization for
repositories with Pipeline definitions (e.g. Jenkinsfile), and set up jobs for those.

Redesigned job configuration forms :
The job configuration form has been redesigned so its structure is visually
clear when showing complex configuration forms.  Additionally, the tabs on
the top of the page show where you are, and can be used to quickly navigate
between the different sections of the configuration form.

Download now!

Get Jenkins 2.0 alpha 3 now, and tell us what you think:

If you use Twitter, you can leave us some feedback
on
Twitter.

Our
jenkinsci-users@
mailing list is also available for feedback in
this
thread..

And of course, since this is a preview release, if you find any issues please
report them on our
Issue Tracker
to the JENKINS project.

We have a list of
known issues on
our wiki but if you’re not sure whether you’re experiencing a known issue or
not, don’t hesitate to ask!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/15/jenkins-certification/"><div class="header"><div class="date"><div class="month">March</div><div class="day">15</div></div><h5 class="title">Introducing Jenkins Certification</h5></div><p class="teaser">This is a guest post by Francois
Dechery, he works at CloudBees managing Customer Engagement/Support, Consulting
and Training. He is also leading the Jenkins Certification program at CloudBees
which has been discussed in some of our previous ( 1,
2,
3)
governance
meetings.

In the IT world, namely in software, &quot;certification&quot; is used in many different
ways and for many different purposes. From very simple and light certifications
to very heavy and complex ones. In the &quot;light&quot; category you can usually be
certified on the basis of a short quiz at the end of an online training. At the
other end of the spectrum, certifications are based on a proctored
multiple-choice questionnaire-based exam and/or hands-on labs. In some
industries, certifications are even more demanding. For instance, to become a
Certified Public Accountant in the US, you have to pass a standard examination
and, on top of this, each state/jurisdiction has its own set of education and
experience requirements that individuals must meet.

Creating the Jenkins certification

When we started our internal discussions at CloudBees regarding a certification
program for Jenkins, we were aware of this broad set of certification
definitions. Therefore, our first goal was to define what type of certification
we wanted to develop and for what purpose. We quickly agreed on the fact that it
should be a professional-grade certification, whose purpose would be to provide
a professional standard for the Jenkins ecosystem, benefiting both individuals
and organizations, thanks to a common, respected and well-known body of
knowledge and practice. &quot;Professional&quot; means that you have the expected level of
skills and experience in order to leverage them in a professional environment,
for example in enterprise projects or as a consultant.

Many members of the CloudBees team have firsthand experience with certification
programs developed in other IT ecosystems such as telecoms (Cisco),
infrastructure (Microsoft, Red Hat) or business applications (SAP), to name a
few. This was definitely the type of professional certification we wanted to
bring to Jenkins. We knew it would represent a substantial investment but we
also knew that the whole Jenkins ecosystem would benefit. Whether at the overall
community or individual level, as well as IT organizations, system integrators
or recruiting firms looking for qualified Jenkins personnel.

I have had the privilege to supervise the creation and implementation of the
Jenkins Certification Program
at CloudBees. The program is comprised of two certifications: &quot;Certified Jenkins
Engineer&quot; (CJE) for Jenkins certification, and Certified CloudBees Jenkins
Platform Engineer (CCJPE) for certification on the CloudBees Jenkins Platform.

We started by creating a Certification Advisory Board whose members are:
Kohsuke Kawaguchi, Jenkins creator and CTO at
CloudBees; Harpreet Singh, VP Products at
CloudBees; Oliver Gondža, initially
representing the Jenkins community; Jason Shawn,
senior director DevOps at Ellucian, representing the CloudBees customer
constituency; and Jose Alvarez,
managing director at Zivra, representing the CloudBees partner ecosystem.

This dedicated group helped us first to create the certification blueprint which
defines the main sections of the exam and their relative importance in the
overall scoring. This blueprint also provides the high-level table of contents
of the certification
study guides.
They also helped to define the Jenkins Engineer profile that the certification
assesses.

With this blueprint in hand, we put together a team of 40 Jenkins subject-matter
experts (SMEs), mostly from CloudBees with a few from partners. Together they
worked for several months on the creation of hundreds of exam questions, doing
iterative peer reviews, filtering out any irrelevant or ambiguous questions and
narrowing down the pool of questions to the best questions for each section.
All this, plus a thorough analysis and balancing exercise to make sure the level
of difficulty was evenly distributed across each section of the exam.

The big lesson from the exam creation experience is that creating a
professional-grade exam is hard! And it requires very specific experience. In
short, being a subject-matter expert is definitely not enough and we’re glad to
have collaborated with Prometric &#x27;s
certification specialists who guided us through this process. The result is
definitely worth the effort. Either of the two certifications offered within the
Jenkins Certification Program are truly what we would consider
&quot;professional-grade certifications.&quot;

What does certification get you?

Getting certified means being recognized for your skills and experience as a
Jenkins professional. However, like any exam-based recognition, its actual value
depends on three criteria: the level of difficulty of the exam, its quality and
its integrity.

As far as difficulty is concerned, it is clear that not everyone will pass and
that is expected from a professional-grade certification, as mentioned earlier.
We have definitely created an exam that is demanding. It does not only measure
your theoretical knowledge of Jenkins but also your hands-on practical
experience. To ensure its quality, we have applied best-industry practices
regarding the exam’s creation and review process, working with certification
specialists. It includes the weighing of questions, the distribution of easy,
medium and difficult ones, the removal of any ambiguous wording, as well as
alpha and beta final test procedures, in order to only keep the most appropriate
questions. We are also putting in place a formal maintenance process to capture
any &quot;bug&quot; in the exam and adapt the questions to Jenkins evolutions over time.
Last but not least, we ensure the exam’s integrity by working with Prometric
for the administration of exams. Tests are taken in fully secured and proctored
test rooms, without any access to any human or electronic resource and
without any doubt about who takes the test. Thanks to Prometric’s hundreds
of test centers around the world, this integrity is ensured in any location.

Beyond this external recognition, getting certified is also a process that lets
you take a step back from your day-to-day practice of Jenkins and assess your
skills and knowledge. You start this reassessment process by reading the Study
Guides for the certifications. Then, by taking the test itself, you can identify
your strengths and weaknesses in a very practical way. In short, a certification
gives you a measurable goal to achieve.

Click here for more
information on the Jenkins Certification Program by CloudBees.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/fdechery/">Francois Dechery</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/certification">certification</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/18/jenkins-20-test-fest/"><div class="header"><div class="date"><div class="month">March</div><div class="day">18</div></div><h5 class="title">Jenkins 2.0 community test fest!</h5></div><p class="teaser">The beta release of Jenkins 2.0 is rapidly approaching! The development team is working hard to find and squash as many bugs as possible, but do you know what would make that effort even more successful? You! A big part of Jenkins’s power lies in its extensive flexibility, but that flexibility poses challenges to testing. In short, it’s difficult for the core team to test in all the myriad environments and with all the different workflows that Jenkins users have. To give just one example, users of Jenkins on Windows often uncover Windows-specific issues that are missed during development.

That’s where you come in! The Jenkins team has organized a Test Fest to take place all day on Monday, March 21st, wherever you are. We encourage you to download the lastest alpha release of Jenkins 2.0, start it up, and configure it in the way you would your production Jenkins installation. Try out your usual workflows, install those plugins you just can’t live without, and let us know about any issues you encounter. You can file them in the Jenkins JIRA, with the label &#x27;2.0,&#x27; or you can discuss them with us in the #jenkins-testfest IRC channel on the Freenode IRC network (connect to irc.freenode.org). We encourage you to hang out with us on IRC regardless; it’ll be an all-day party!

You can also find the list of the discovered Jenkins 2.0 issues using this link.

Thanks in advance for joining us, and for supporting Jenkins!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/omehegan/">Owen Mehegan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/21/vjam/"><div class="header"><div class="date"><div class="month">March</div><div class="day">21</div></div><h5 class="title">vJAM: Virtual Jenkins Area Meetup</h5></div><p class="teaser">Over the past few months, I’m happy to say, the number of
Jenkins Area Meetups (JAMs) has grown
tremendously! The excitement around JAMs has gotten us thinking about something
larger, something more globally focused. That led us to create
vJAM, an online Jenkins Area
Meetup, where we can share what we’re learning together. The effort will be
spear-headed by long time Jenkins contributor, R. Tyler Croy.

The key goals for the Virtual Jenkins Area Meetup are:

Connect the global Jenkins user and developer community.

Help spread the latest and greatest best practices.

Support other JAMs by offering
another, broader, audience for speakers and organizers

vJAM, originally inspired by Virtual JUG, will
supplement local JAMs but nothing virtual can replace the value of talking with
other Jenkins users over pizza and drinks.

We’re currently working on the agenda for the first vJAM, which will be posted
to this Meetup group, so be
sure to sign up if you’re interested in participating!

If you’re interested in creating your own local Jenkins Area Meetup, read
this page
for more details.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/24/jenkins-2-beta-released/"><div class="header"><div class="date"><div class="month">March</div><div class="day">24</div></div><h5 class="title">Jenkins 2.0 beta released</h5></div><p class="teaser">We released the Jenkins 2.0 beta earlier today. Download it here and try it!

Besides a number of bug fixes and minor improvements, the following changes are new since the last alpha preview release:

Redesigned &quot;New Item&quot; page

We redesigned the &quot;New Item&quot; page. Item types now have icons to be more visually distinctive.

Additionally, item types can now define a category they belong to (such as &quot;Project&quot; or &quot;Folder&quot;). Once the complexity of the &quot;New Item&quot; page reaches a certain threshold, the item types will be grouped into categories to be easier to find. However, for now, it’s unlikely that you will see these categories, as support for this mechanism will need to be added in plugins. This is a new API in core, and we invite plugin developers to support it to make Jenkins easier to use for users with a large number of item types. It doesn’t even require raising the minimum supported Jenkins version.

Separate configuration page for tools

The length and complexity of the Configure Jenkins page once a few dozen plugins are installed made it unnecessarily difficult to use. To improve that we’re moving the tools configuration (Git, Maven, Gradle, Ant, etc.) out of that page, into the new Global Tools Configuration.

Upgrade notice and plugin installer

The Pipeline plugin suite is a big part of Jenkins 2. Over the past few weeks, open-source plugins adding support for visualization (Pipeline Stage View), automatic GitHub project creation (GitHub Branch Source Plugin) and Bitbucket project creation (Bitbucket Branch Source Plugin) have been released. However, when upgrading from Jenkins 1.x, users weren’t even given any information on these features.

To address this, users upgrading from Jenkins 1.x will now be shown a banner when they first log into Jenkins as administrator, offering them to install the suite of Pipeline plugins.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/03/30/usage-statistics-privacy-advisory/"><div class="header"><div class="date"><div class="month">March</div><div class="day">30</div></div><h5 class="title">Important notice regarding usage statistics</h5></div><p class="teaser">A bug was introduced in Jenkins versions 1.645 and 1.642.2 which caused Jenkins
to send
anonymous
usage statistics, even if the administrator opted-out of reporting usage data
in the Jenkins web UI.

If you are running one of the affected versions, the best/easiest solution is
to upgrade. The bug does not affect Jenkins 1.653 or newer, or Jenkins LTS
1.642.4 or newer.

If you cannot upgrade, it is possible to immediately disable submission of
usage statistics by running the following script in &quot;Manage Jenkins » Script Console&quot;:

hudson.model.UsageStatistics.DISABLED = true

This will immediately disable usage data submission until you restart Jenkins.
To make this permanent, change your Jenkins startup script so it passes a
system property to the java process:

java -Dhudson.model.UsageStatistics.disabled=true -jar …/jenkins.war

For information how to do this when using one of the installers/packages, see the
installer/package documentation here.

To verify that usage stats submission is disabled, run the following script in
&quot;Manage Jenkins » Script Console&quot; and confirm the result is true:

println hudson.model.UsageStatistics.DISABLED

We have much more information about the issue and our usage statistics process
in
our wiki.

While we do not consider this a security advisory, if you are a Jenkins
administrator we highly recommend subscribing to our
jenkinsci-advisories@
mailing list.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/01/march-2016-jam-st-petersburg/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 1</div></div><h5 class="title">March 2016 St. Petersburg Jenkins Meetup Report</h5></div><p class="teaser">On March 10th we have conducted the second Jenkins meetup in Saint Petersburg,
Russia.  The meetup topic was&quot;Jenkins and Continuous Delivery&quot;.  We had 3
talks addressing various aspects of Jenkins usage in this area.

Talks

Introduction slides [ru]

Jenkins 2.0 and Pipeline-as-Code

Speaker: Oleg Nenashev, CloudBees

Presentation (en)

Presentation (ru)

Continuous Delivery for Documentation

Speaker: Stanislav Ovchar, Motorola Solutions

Presentation (ru)

Continuous Delivery with Jenkins at ZeroTurnaround

Speaker: Sergei Egorov, ZeroTurnaround

Presentation (en)

We also had a long Jenkins afterparty. Starting from the next meetup we hope to
make this part more official.

Links

St. Petersburg Meetup page (follow the events here)

Event page on the Yandex.Events portal

St. Petersburg Meetup Twitter

Jenkins RU Twitter

Jenkins RU Gitter Chat

Acknowledgments

The event has been organized with the help from
Yandex and
CloudBees.

More Jenkins meetups

If you want to organize a Jenkins meetup in St. Petersburg or to be a speaker
there, please contact us via the
Meetup
discussions page

Regarding other areas, check out where
Jenkins Area Meetups (JAMs) are
located in the world.

Don’t see a JAM in your area?  Why not start your own,
find out
how.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins_ru">jenkins_ru</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/07/2.0-release-candidate/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 7</div></div><h5 class="title">Jenkins 2.0 Release Candidate available!</h5></div><p class="teaser">Those who fervently watch the
jenkinsci-dev@
list, like I do, may have caught Daniel
Beck &#x27;s email today which quietly referenced a significant milestone on the
road to 2.0 which has been reached: the first 2.0 release
candidate is here!

The release candidate process, in short, is the final stabilization and testing
period before the final release of Jenkins 2.0. If you have the
cycles to help test, please download the release candidate and give
us your feedback as soon as possible!

The release candidate process also means that changes targeting release after
2.0 can start landing in the master branch, laying the groundwork 2.1 and
beyond.

I pushed the merge to &#x27;master&#x27;. So anything targeting 2.1+ can be now proposed
in pull requests to that branch.

Anything happening on &#x27;2.0&#x27; branch will be limited to critical fixes for the 2.0
release specifically.

— Daniel Beck

Compared to the
2.0 beta release, the first
release candidate has a number of fixes for issues discovered in the alpha and beta
process. Most notable perhaps is the stabilization of a system property which
configuration management tools, like Puppet/Chef/Ansible/etc, can use to suppress
the user-friendly Getting Started wizard. Since users of those tools
have alternative means of ensuring security and correctness of their Jenkins
installations, the out-of-the-box experience can be skipped.

Based on our
rough
timeline this gives us a couple weeks to test the release candidates and get
ready for a big exciting release of 2.0 at the end of April!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/07/jenkins-community-survey-results-blog/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 7</div></div><h5 class="title">Jenkins Community Survey Results</h5></div><p class="teaser">This is a guest post by Brian
Dawson at CloudBees, where he works as a DevOps Evangelist responsible for
developing and sharing continuous delivery and DevOps best practices. He also
serves as the CloudBees Product Marketing Manager for Jenkins.

Last fall CloudBees asked attendees at the Jenkins User Conference – US West
(JUC), and other in the Jenkins community to take a survey.  Almost 250 people
did – and thanks to their input, we have results which provided interesting
insights into how Jenkins is being used.

Back in 2012, at the time of the last community survey, 83% of respondents felt
that Jenkins was mission-critical. By 2015, the percentage saying that
Jenkins was mission-critical was 92%. Additionally, echoing the
importance of Jenkins, 89% of respondents said their use of Jenkins had
increased over the last year, while 11% said it had stayed the same. 0%
said that it had decreased.

The trend in the industry over the last couple of years has been to adopt
continuous delivery (CD), thus pushing automation further down the pipeline –
from development all the way into production.  Jenkins being an automation
engine applicable to any phase of the software delivery lifecycle, is readily
supporting this trend. Jenkins&#x27; extensible architecture and unparalleled plugin
ecosystem enables integration with and orchestration of practically any tool in
any phase of software delivery.

The trend towards adoption of CD is clearly reflected amongst the community: 59%
of respondents are using Jenkins for continuous integration (CI), but an
additional 30% have extended CI into CD and are manually deploying code to
production.  Finally, 11% are practicing continuous deployment – they have
extended CI to CD and are deploying code automatically into production.

Another trend tied to the adoption of CD and DevOps is the frequent deployment
of incremental releases to production. 26% of those respondents using continuous
delivery practices are deploying code at least once per day.  Another 37% are
deploying code at least once per week.

In keeping with the move to CD, 30% of survey takers are already using the
relatively new Pipeline plugin to automate their
software delivery pipelines.  Of those not using the Pipeline plugin, 79% plan
to adopt it in the next 12 months.

Survey respondents are also using Jenkins for many different activities.  97% of
survey takers use it for &quot;build&quot; – no surprise, since that is where Jenkins got
its start - but 58% now also use it for their deployment.

When the 2012 community survey was conducted, container technology was not as
well understood as it is today,  and many didn’t know what a “Docker” was. A
short four years later, 96% of survey respondents who use Linux containers are
using Docker.  Container technology has seen impressive adoption and arguably is
revolutionizing the way application infrastructure is delivered.  When coupled
with Jenkins as an automation engine, containers help accelerate software
delivery by providing rapid access to lightweight environments.  The Jenkins
community has recognized and embraced the power of containers by
providing plugins for Docker and Kubernetes.

The Jenkins improvements which survey respondents desired the most were
quality/timely bug fixes, a better UI and more documentation/examples.
Interestingly, Jenkins 2.0 - which is just about to officially launch,
provides UI improvements and the new Jenkins.io website
provides improved, centralized documentation.

Finally, the respondents favorite Star Wars character was R2-D2, followed by
Obi-Wan and Darth Vader. Yoda and Han Solo also got a fair amount of votes. The
votes for Jar-Jar Binks and Jabba the Hutt left us puzzled. Notably, BB-8 had a
write-in vote despite the fact the new Star Wars movie hadn’t been released yet.

As to where the community is headed, our prediction is that by the next Jenkins Community Survey:

More Jenkins users will have transitioned from just continuous
integration to continuous delivery with some evening practicing continuous
deployment

Pipeline plugin adoption and improvements will continue, leading to
pipeline-as-code becoming an essential solution for automating the software
(and infrastructure) delivery process

There will be a significant increase in use of the Docker plugin to support
elastic Jenkins infrastructure and continuous delivery of containers using
software development best practices

BB-8 will be the next favorite Star Wars character! &lt;3&lt;/p&gt;

See you at Jenkins World, September 13-15, in Santa Clara, California!
Register now for the largest Jenkins event on the planet in 2016 – and get the Early Bird discount. The Call for Papers is still open – so submit a talk and share your knowledge with the community about Jenkins.

2015 Community Survey Results (PDF)

State of Jenkins Infographic (PDF)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/bvdawson/">Brian Dawson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/continuousdelivery">continuousdelivery</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/07/pipeline-for-runs-on-hardware/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 7</div></div><h5 class="title">Automating test runs on hardware with Pipeline as Code</h5></div><p class="teaser">In addition to Jenkins development, during last 8 years I’ve been involved into continuous integration for hardware and embedded projects.
At JUC2015/London
I have conducted a talk about common automation challenges in the area.

In this blog post I would like to concentrate on Pipeline (formerly known as Workflow), which is a new ecosystem in Jenkins that allows implementing jobs in a domain specific language.
It is in the suggested plugins list in the upcoming Jenkins 2.0 release.

The first time I tried Pipeline two and half years ago, it unfortunately did not work for my use-cases at all.
I was very disappointed but tried it again a year later.
This time, the plugin had become much more stable and useful.
It had also attracted more contributors and started evolving more rapidly with the development of plugins extending the Pipeline ecosystem.

Currently, Pipeline a powerful tool available for Jenkins users to implement a variety of software delivery pipelines in code.
I would like to highlight several Pipeline features which may be interesting to Jenkins users working specifically with embedded and hardware projects.

Introduction

In Embedded projects it’s frequently required to run tests on specific hardware peripherals: development boards, prototypes, etc.
It may be required for both software and hardware areas, and especially for products involving both worlds.
CI and CD methodologies require continuous integration and system testing, and Jenkins comes to help here.
Jenkins is an automation framework, which can be adjusted to reliably work with hardware attached to its nodes.

Area challenges

Generally, any peripheral hardware device can be attached to a Jenkins node.
Since Jenkins nodes require Java only, almost every development machine can be attached.
Below you can find a common connection scheme:

After the connection, Jenkins jobs could invoke common EDA tools via command-line interfaces.
It can be easily done by a Execute shell build steps in free-style projects.
Such testing scheme is commonly affected by the following issues:

Nodes with peripherals are being shared across several projects.
Jenkins must ensure the correctness of access (e.g. by throttling the access).

In a single Freestyle project builds utilize the node for a long period. If you synthesize the item before the run, much of the peripheral utilization file may be wasted.

The issue can be solved by one of concurrency management plugins:
Throttle Concurrent Builds, Lockable Resources
or
Exclusions.

Test parallelization on multiple nodes requires using of multiple projects or
Matrix configurations, so it causes job chaining again.

These build chains can be created via
Parameterized Trigger and
Copy Artifacts, but it complicates job management and build history investigation.

Hardware infrastructure is usually flaky.
If it fails during the build due to any reason, it’s hard to diagnose the issue and re-run the project if the issue comes from hardware.

Build Failure Analyzer allows to identify the root cause of a build failure (e.g. by build log parsing).

Conditional Build Step and
Flexible Publish plugins allow altering the build flow according to the analysis results.

Combination of the plugins above is possible, but it makes job configurations extremely large.

Tests on hardware peripherals may take much time.
If an infrastructure fails, we may have to restart the run from scratch.
So the builds should be robust against infrastructure issues including network failures and Jenkins controller restarts.

Tests on hardware should be reproducible, so the environment and input parameters should be controlled well.

Jenkins supports
cleaning workspaces, so it can get rid of temporary files generated by previous runs.

Jenkins provides support of agents connected via containers (e.g.
Docker) or VMs, which allow creating clean environments for every new run.
It’s important for 3rd-party tools, which may modify files outside the workspace: user home directory, temporary files, etc.

These environments still need to be connected to hardware peripherals, which may be a serious obstacle for Jenkins admins

The classic automation approaches in Jenkins are based on Free-style and Multi-configuration project types.
Links to various articles on this topic are collected on the
HW/Embedded Solution page Embedded on the Jenkins website.
Tests automation on hardware peripherals has been covered in several publications by Robert Martin, Steve Harris, JL Gray, Gordon McGregor, Martin d’Anjou, and Sarah Woodall.
There is also a top-level overview of classic approaches made by me at JUC2015/London (a bit outdated now).

On the other hand, there is no previous publications, which would address Pipeline usage for the Embedded area.
In this post I want to address this use-case.

Pipeline as Code for test runs on hardware

Pipeline as Code is an approach for describing complex automation flows in software lifecycles: build, delivery, deployment, etc.
It is being advertised in Continuous Delivery and DevOps methodologies.

In Jenkins there are two most popular plugins:
Pipeline and Job DSL.
JobDSL Plugin internally generates common freestyle jobs according to the script, so it’s functionality is similar to the classic approaches.
Pipeline is fundamentally different, because it provides a new engine controlling flows independently from particular nodes and workspaces.
So it provides a higher job description level, which was not available in Jenkins before.

Below you can find an example of Pipeline scripts, which runs tests on FPGA board. The id of this board comes from build parameters ( fpgaId). In this script we also presume that all nodes have pre-installed tools (Xilinx ISE in this case).

// Run on node having my_fpga label
node(&quot;linux &amp;&amp; ml509&quot;) {
  git url:&quot;https://github.com/oleg-nenashev/pipeline_hw_samples&quot;
  sh &quot;make all&quot;
}

But such scenario could be also implemented in a Free-style project.
What would we get from Pipeline plugin?

Getting added-value from Pipeline as code

Pipeline provides much added-value features for hardware-based tests.
I would like to highlight the following advantages:

Robustness against restarts of Jenkins controller.

Robustness against network disconnects. sh() steps are based on the
Durable Task plugin, so Jenkins can safely continue the execution flow once the node reconnects to the controller.

It’s possible to run tasks on multiple nodes without creating complex flows based on job triggers and copy artifact steps, etc. It can be achieved via combination of parallel() and node() steps.

Ability to store the shared logic in standalone Pipeline libraries

etc.

First two advantages allow to improve the robustness of Jenkins nodes against infrastructure failures.
It is critical for long-running tests on hardware.

Last two advantages address the flexibility of Pipeline flows.
There are also plugins for freestyle projects, but they are not flexible enough.

Utilizing Pipeline features

The sample Pipeline script above is very simple.
We would like to get some added value from Jenkins.

General improvements

Let’s enhance the script by using several features being provided by pipeline in order to get visualization of stages, report publishing and build notifications.

We also want to minimize the time being spent on the node with the attached FPGA board.
So we will split the bitfile generation and further runs to two different nodes in this case: a general purpose linux node, and the node with the hardware attached.

You can find the resulting Pipeline script below:

// Synthesize on any node
def imageId=&quot;&quot;
node(&quot;linux&quot;) {
  stage &quot;Prepare environment&quot;
  git url:&quot;https://github.com/oleg-nenashev/pipeline_hw_samples&quot;
  // Construct the bitfile image ID from commit ID
  sh &#x27;git rev-parse HEAD &gt; GIT_COMMIT&#x27;
  imageId= &quot;myprj-${fpgaId}-&quot; + readFile(&#x27;GIT_COMMIT&#x27;).take(6)

  stage &quot;Synthesize project&quot;
  sh &quot;make FPGA_TYPE=$fpgaId synthesize_for_fpga&quot;
  /* We archive the bitfile before running the test, so it won&#x27;t be lost it if something happens with the FPGA run stage. */
  archive &quot;target/image_${fpgaId}.bit&quot;
  stash includes: &quot;target/image_${fpgaId}.bit&quot;, name: &#x27;bitfile&#x27;
}

/* Run on a node with &#x27;my_fpga&#x27; label.
In this example it means that the Jenkins node contains the attacked FPGA of such type.*/
node (&quot;linux &amp;&amp; $fpgaId&quot;) {
  stage &quot;Blast bitfile&quot;
  git url:&quot;https://github.com/oleg-nenashev/pipeline_hw_samples&quot;
  def artifact=&#x27;target/image_&#x27;+fpgaId+&#x27;.bit&#x27;
  echo &quot;Using ${artifact}&quot;
  unstash &#x27;bitfile&#x27;
  sh &quot;make FPGA_TYPE=$fpgaId impact&quot;

  /* We run automatic tests.
  Then we report test results from the generated JUnit report. */
  stage &quot;Auto Tests&quot;
  sh &quot;make FPGA_TYPE=$fpgaId tests&quot;
  sh &quot;perl scripts/convertToJunit.pl --from=target/test-results/* --to=target/report_${fpgaId}.xml --classPrefix=\&quot;myprj-${fpgaId}.\&quot;&quot;
  junit &quot;target/report_${fpgaId}.xml&quot;

  stage &quot;Finalization&quot;
  sh &quot;make FPGA_TYPE=$fpgaId flush_fpga&quot;
  hipchatSend(&quot;${imageId} testing has been completed&quot;)
}

As you may see, the pipeline script mostly consists of various calls of command-line tools via the sh() command.
All EDA tools provide great CLIs, so we do not need special plugins in order to invoke common operations from Jenkins.

Makefile above is a sample stuff for demo purposes.
It implements a set of unrelated routines merged into a single file without dependency declarations.
Never write such makefiles.

It is possible to continue expanding the pipeline in such way.
Pipeline Examples
contain examples for common cases: build parallelization, code sharing between pipelines, error handling, etc.

Lessons learned

During last 2 years I’ve been using Pipeline for Hardware test automation several times.
The first attempts were not very successful, but the ecosystem has been evolving rapidly.
I feel Pipeline has become a really powerful tool, but there are several missing features.
I would like to mention the following ones:

Shared resource management across different pipelines.

Runs of a single Pipeline job can be synchronized using the concurrency parameter of the stage() step

It can be done by the incoming Pipeline integration in the
Lockable Resources plugin
( JENKINS-30269).

Another case is integration with
Throttle Concurrent Builds plugin, which is an effective engine for limiting the license utilization in automation infrastructures
( JENKINS-31801).

Better support of CLI tools.

EDA tools frequently need a complex environment, which should be deployed on nodes somehow.

Integration with
Custom Tools Plugin seems to be the best option, especially in the case of multiple tool versions
( JENKINS-30680).

Pipeline package manager ( JENKINS-34186)

Since there is almost no plugins for EDA tools in Jenkins, developers need to implement similar tasks at multiple jobs.

A common approach is to keep the shared &quot;functions&quot; in libraries.

Pipeline Global Library and
Pipeline Remote Loader can be used, but they do not provide features like dependency management.

Pipeline debugger ( JENKINS-34185)

Hardware test runs are very slow, so it is difficult to troubleshoot and fix issues in the Pipeline code if you have to run every build from scratch.

There are several features in Pipeline, which simplify the development, but we still need an IDE-alike implementation for complex scripts.

Conclusions

Jenkins is a powerful automation framework, which can be used in many areas.
Even though Jenkins has no dedicated plugins for test runs on hardware, it provides many general-purpose &quot;building blocks&quot;, which allow implementing almost any flow.
That’s why Jenkins is so popular in the hardware and embedded areas.

Pipeline as code can greatly simplify the implementation of complex flows in Jenkins.
It continues to evolve and extend support of use-cases.
if you’re developing embedded projects, consider Pipeline as a durable, extensible and versatile means of implementing your automation.

What’s next?

Jenkins automation server dominates in the HW/Embedded area, but unfortunately there is not so much experience sharing for these use-cases.
So Jenkins community encourages everybody to share the experience in this area by writing docs and articles for Jenkins website and other resources.

This is just a a first blog post on this topic.
I am planning to provide more examples of Pipeline usage for Embedded and Hardware tests in the future posts.
The next post will be about concurrency and shared resource management in Pipelines.

I am also going to talk about running tests on hardware at the
upcoming Automotive event in Stuttgart on April 26th.
This event is being held by
CloudBees, but there will be several talks addressing Jenkins open-source as well.

If you want to share your experience about Jenkins usage in Hardware/Embedded areas, consider submitting a talk for the
Jenkins World conference or join/organize a
Jenkins Area Meetup in your city.
There is also a
Jenkins Online Meetup.

Links

Related articles and events:

HW/Embedded Solution page

Jenkins-Based CI for Heterogeneous Hardware/Software Projects

Accelerating Automotive Innovation with Continuous Integration &amp; Delivery - meetup in Stuttgart

Pipeline:

Pipeline page

Jenkins 2.0 and Pipeline as code overview

Pipeline Tutorial

Pipeline Examples<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/embedded">embedded</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/11/gsoc2016-mentors-call/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">Google Summer of Code. Call for Mentors</h5></div><p class="teaser">As you probably know, Jenkins project has been accepted to
Google Summer of Code 2016.

During last month we were working with students in order to discuss their project ideas and to review their application drafts.
Thanks again to all students and mentors for your hard work during about ten office hours and dozens of other calls/chats!

Current status

We have successfully handled the student application period

We have received a bunch of good project proposals (mentors cannot disclose the number)

We have done the preliminary filtering of applications

GSoC mentors and organization admins have prepared the project slot application draft

Currently we are looking for mentors.
We have a minimal required number for the current project slot application plan, but additional expertise would allow us to share the load and to provide more expertise to students.

If you want to be a mentor:

Check out mentor requirements here.

Check out the project ideas
here.

Student application period is finished, so it is too late to propose project ideas for this year

You can join the mentor team for one of the mentioned projects

Hot areas: UI improvements, Fingerprints, External Workspace Manager

Contact Google GSoC admins via jenkinsci-gsoc-org@googlegroups.com

Links

GSoC2016 page on our Wiki

Jenkins page on the GSoC2016 website<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/11/jenkins-plugins-security-update/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">Security fixes in Script Security Plugin and Extra Columns Plugin</h5></div><p class="teaser">The Script Security Plugin and the Extra Columns Plugin were updated today to fix medium-severity security vulnerabilities. For detailed information about the security content of these updates, see the security advisory.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/11/run-your-api-tests-continuously-with-jenkins-and-dhc/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">Run Your API Tests Continuously with Jenkins and DHC</h5></div><p class="teaser">This is a guest post by Guillaume Laforge.
Well known for his contribution to the Apache Groovy project,
Guillaume is also the &quot;Product Ninja and Advocate&quot; of Restlet,
a company focusing on Web APIs:
with DHC (an API testing client),
Restlet Studio (an API designer),
APISpark (an API platform in the cloud),
and the Restlet Framework
open source project for developing APIs.

Modern mobile apps, single-page web sites and applications, are more and more relying on Web APIs,
as the nexus of the interaction between the frontend and the backend services.
Web APIs are also central to third-party integration, when you want to share your services with others,
or when you need to consume existing APIs to build your own solution on top of their shoulders.

With APIs being a key element of your architecture and big picture,
it’s obviously important to assess that this API is functioning the way it should, thanks to proper testing.
Your framework of choice, regardless of the technology stack or programming language used,
will hopefully offer some facilities for testing your code,
whether in the form of unit tests, or ideally with integration tests.

Coding Web API tests

From a code perspective, as I said, most languages and frameworks provide approaches to testing APIs built with them.
There’s one I wanted to highlight in particular, which is one developed with a DSL approach (Domain-Specific Language),
using the Apache Groovy programming language, it’s
AccuREST.

To get started, you can have a look at the introduction,
and the usage guide.
If you use the contract DSL,
you’ll be able to write highly readable examples of requests you want to issue against your API,
and the assertions that you expect to be true when getting the response from that call.
Here’s a concrete example from the documentation:

GroovyDsl.make {
    request {
        method &#x27;POST&#x27;
        urlPath(&#x27;/users&#x27;) {
            queryParameters {
                parameter &#x27;limit&#x27;: 100
                parameter &#x27;offset&#x27;: containing(&quot;1&quot;)
                parameter &#x27;filter&#x27;: &quot;email&quot;
            }
        }
        headers {
            header &#x27;Content-Type&#x27;: &#x27;application/json&#x27;
        }
        body &#x27;&#x27;&#x27;{ &quot;login&quot; : &quot;john&quot;, &quot;name&quot;: &quot;John The Contract&quot; }&#x27;&#x27;&#x27;
    }
    response {
        status 200
        headers {
            header &#x27;Location&#x27;: &#x27;/users/john&#x27;
        }
    }
}

Notice that the response is expected to return a status code 200 OK, and a Location header pointing at /users/john.
Indeed, a very readable way to express the requests and responses!

Tooling to test your APIs

From a tooling perspective, there are some interesting tools that can be used to test Web APIs,
like Paw (on Macs),
Advanced REST client,
Postman or
Insomnia.

But in this article, I’ll offer a quick look at DHC,
a handy visual tool, that you can use both manually to craft your tests and assertions,
and whose test scenarios you can export and integrate in your build and continuous integration pipeline,
thanks to Maven and Jenkins.

At the end of this post, you should be able to see the following reporting in your Jenkins dashboard,
when visualising the resulting API test execution:

Introducing DHC

DHC is a Chrome extension, that you can
install from the Chrome Web Store,
in your Chrome browser. There’s also an online service available, with some limitations.
For the purpose of this article, we’ll use the Chrome extension.

In the main area, you can create your request, define the URL to call, specify the various request headers or params,
chose the method you want to use, and then, you can click the send button to issue the request.

In the left pane, that’s where you’ll be able to see your request history, create and save your project in the cloud,
or also set context variables.

The latter is important when testing your Web API, as you’ll be able to insert variables like for example
{localhost} for testing locally on your machine or {staging} and {prod} to run your tests in different environments.

In the bottom pane, you have access to actual raw HTTP exchange, as well as the assertions pane.

Again, a very important pane to look at! With assertions, you’ll be able to ensure that your Web API works as expected.
For instance, you can check the status code of the call, check the payload contains a certain element,
by using JSON Path or XPath to go through the JSON or XML payload respectively.

Beyond assertions, what’s also interesting is that you can chain requests together.
A call request can depend on the outcome of a previous request!
For example, in a new request, you could pass a query parameter whose value would be the value of some element
of the JSON payload of a previously executed request.
And by combining assertions, linked requests and context variables together, you can create full-blown test scenarios,
that you can then save in the cloud, but also export as a JSON file.

To export that test scenario, you can click on the little export icon in the bottom left hand corner,
and you’ll be able to select exactly what you want to export:

Running your Web API tests with Maven

Now things become even more interesting, as we’ll proceed to using Maven and Jenkins!
As the saying goes, there’s a Maven plugin for that! For running those Web API tests in your build!
Even if your Web API is developed in another technology than Java, you can still create a small Maven build
just for your Web API tests.
And the icing on the cake, when you configure Jenkins to run this build, as the plugin outputs JUnit-friendly test reports,
you’ll be able to see the details of your successful and failed tests, just like you would see JUnit’s!

Let’s sketch your Maven POM:

4.0.0

com.example
my-first-api-test
1.2.3

com.restlet.dhc
dhc-maven-plugin
1.1

test

test

companies-scenario.json

restlet-maven
Restlet public Maven repository Release Repository
https://maven.restlet.com

Visualizing Web API test executions in Jenkins

Once you’ve configured your Jenkins server to launch the test goal of this Maven project,
you’ll be able to see nice test reports for your Web API scenarios, like in the screenshot in introduction of this article!

Next, you can easily run your Web API tests when developers commit changes to the API,
or schedule regular builds with Jenkins to monitor an online Web API.

For more information, be sure to read the tutorial on
testing Web APIs with DHC.
There are also some more resources like a
screencast,
as well as the
user guide, if you want to learn more.
And above all, happy testing!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/glaforge/">Guillaume Laforge</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/webapis">webapis</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/testing">testing</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/14/jenkins-world-registration-is-open/"><div class="header"><div class="date"><div class="month">April</div><div class="day">14</div></div><h5 class="title">Registration is Open for Jenkins World 2016!</h5></div><p class="teaser">This is a guest post by Alyssa Tong.
Alyssa works for CloudBees, helping to organize
Jenkins community events around the
world.

Jenkins World 2016 will be the largest gathering of Jenkins users in the world. This event will bring together Jenkins experts, continuous delivery thought leaders and the ecosystem offering complementary technologies for Jenkins. Join us September 13-15, 2016 in Santa Clara, California to learn and explore, network face-to-face and help shape the next evolution of Jenkins development and solutions for DevOps.

Registration for Jenkins World 2016 is now live. Take advantage of the Super Early Bird rate of $399 (available until July 1st).

And don’t forget, the Call for Papers will be ending on May 1st. That’s 2.5 short weeks left to get your proposal(s) in.  We anxiously await your amazing stories.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/14/replay-with-pipeline/"><div class="header"><div class="date"><div class="month">April</div><div class="day">14</div></div><h5 class="title">Replay a Pipeline with script edits</h5></div><p class="teaser">This is a cross-post of
an article authored by
Pipeline plugin maintainer Jesse Glick on the
CloudBees blog.

For those of you not checking their Updates tab obsessively, Pipeline 1.14 [up
to 2.1 now] was
released
a couple of weeks ago and I wanted to highlight the major feature in this
release: JENKINS-32727,
or replay. Some folks writing &quot;Jenkinsfiles&quot; in the field had grumbled that it
was awkward to develop the script incrementally, especially compared to jobs
using inline scripts stored in the Jenkins job configuration: to try a change to
the script, you had to edit Jenkinsfile in SCM, commit it (perhaps to a
branch), and then go back to Jenkins to follow the output. Now this is a little
easier. If you have a Pipeline build which did not proceed exactly as you
expected, for reasons having to do with Jenkins itself (say, inability to find &amp;
publish test results, as opposed to test failures you could reproduce locally),
try clicking the Replay link in the build’s sidebar. The quickest way to try
this for yourself is to run the
stock CD demo in its
latest release:

$ docker run --rm -p 2222:2222 -p 8080:8080 -p 8081:8081 -p 9418:9418 -ti jenkinsci/workflow-demo:1.14-3

When you see the page Replay
#1 , you are shown two
(Groovy) editor boxes: one for the main
Jenkinsfile , one for a library script
it loaded
( servers.groovy , introduced to help demonstrate this feature). You
can make edits to either or both. For example, the original demo allocates a
temporary web application with a random name like
9c89e9aa-6ca2-431c-a04a-6599e81827ac for the duration of the functional tests.
Perhaps you wished to prefix the application name with tmp- to make it obvious
to anyone encountering the Jetty index page that these
URLs are transient. So in the second text area, find the line

def id = UUID.randomUUID().toString()

and change it to read

def id = &quot;tmp-${UUID.randomUUID()}&quot;

then click Run. In
the new build’s log
you will now see

Replayed #1

and later something like

… test -Durl=http://localhost:8081/tmp-812725bb-74c6-41dc-859e-7d9896b938c3/ …

with the improved URL format. Like the result? You will want to make it
permanent. So jump to the [second build’s index
page]( http://localhost:8080/job/cd/branch/master/2/) where you will see a note
that this build &gt; Replayed #1 (diff) If you
click on diff you
will see:

--- old/Script1
+++ new/Script1
@@ -8,7 +8,7 @@
 }

 def runWithServer(body) {
-    def id = UUID.randomUUID().toString()
+    def id = &quot;tmp-${UUID.randomUUID()}&quot;
     deploy id
     try {
         body.call id

so you can know exactly what you changed from the last-saved version. In fact if you replay #2 and change tmp to temp in the loaded script, in the diff view for #3 you will see the diff from the first build, the aggregate diff:

--- old/Script1
+++ new/Script1
@@ -8,7 +8,7 @@
 }

 def runWithServer(body) {
-    def id = UUID.randomUUID().toString()
+    def id = &quot;temp-${UUID.randomUUID()}&quot;
     deploy id
     try {
         body.call id

At this point you could touch up the patch to refer to servers.groovy
( JENKINS-31838), git
apply it to a clone of your repository, and commit. But why go to the trouble
of editing Groovy in the Jenkins web UI and then manually copying changes back
to your IDE, when you could stay in your preferred development environment from
the start?

$ git clone git://localhost/repo
Cloning into &#x27;repo&#x27;...
remote: Counting objects: 23, done.
remote: Compressing objects: 100% (12/12), done.
remote: Total 23 (delta 1), reused 0 (delta 0)
Receiving objects: 100% (23/23), done.
Resolving deltas: 100% (1/1), done.
Checking connectivity... done.
$ cd repo
$ $EDITOR servers.groovy
# make the same edit as previously described
$ git diff
diff --git a/servers.groovy b/servers.groovy
index 562d92e..63ea8d6 100644
--- a/servers.groovy
+++ b/servers.groovy
@@ -8,7 +8,7 @@ def undeploy(id) {
 }

 def runWithServer(body) {
-    def id = UUID.randomUUID().toString()
+    def id = &quot;tmp-${UUID.randomUUID()}&quot;
     deploy id
     try {
         body.call id
$ ssh -p 2222 -o StrictHostKeyChecking=no localhost replay-pipeline cd/master -s Script1 webapp-naming

Using the replay-pipeline CLI command (in this example via
SSH)
you can prepare, test, and commit changes to your Pipeline script code without
copying anything to or from a browser. That is all for now. Enjoy!<span class="more"></span></p></a><div class="attrs"><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/15/the-need-for-pipeline/"><div class="header"><div class="date"><div class="month">April</div><div class="day">15</div></div><h5 class="title">The Need For Jenkins Pipeline</h5></div><p class="teaser">This is a cross-post of
an article authored
by Viktor Farcic on the
CloudBees blog. Viktor is also the author
of The DevOps 2.0 Toolkit, which
explores Jenkins, the Pipeline plugin, and the ecosystem
around it in much more detail.

Over the years, Jenkins has become the undisputed ruler among continuous
integration (CI), delivery and deployment (CD) tools. It, in a way, defined the
CI/CD processes we use today. As a result of its leadership, many other products
have tried to overthrow it from its position. Among others, we got Bamboo and
Team City attempting to get a piece of the market. At the same time, new
products emerged with a service approach (as opposed to on-premises). Some of
them are Travis, CircleCI and Shippable. Be that as it may, none managed to get
even close to Jenkins&#x27; adoption. Today, depending on the source we use, Jenkins
holds between 50-70% of the whole CI/CD tools market. The reason behind such a
high percentage is its dedication to open source principles set from the very
beginning by Kohsuke Kawaguchi. Those same principles were the reason he forked
Jenkins from Hudson. The community behind the project, as well as commercial
entities behind enterprise versions, are continuously improving the way it works
and adding new features and capabilities. They are redefining not only the way
Jenkins behaves but also the CI/CD practices in a much broader sense. One of
those new features is the Jenkins Pipeline plugin. Before we
dive into it, let us take a step back and discuss the reasons that led us to
initiate the move away from Freestyle jobs and towards the Pipeline.

The Need for Change

Over time, Jenkins, like most other self-hosted CI/CD tools, tends to accumulate
a vast number of jobs. Having a lot of them causes quite an increase in
maintenance cost. Maintaining ten jobs is easy. It becomes a bit harder (but
still bearable) to manage a hundred. When the number of jobs increases to
hundreds or even thousands, managing them becomes very tedious and time
demanding.

If you are not proficient with Jenkins (or other CI/CD tools) or you do not work
for a big project, you might think that hundreds of jobs is excessive. The truth
is that such a number is reached over a relatively short period when teams
are practicing continuous delivery or deployment. Let’s say that an average
CD flow has the following set of tasks that should be run on each commit:
building, pre-deployment testing, deployment to a staging environment,
post-deployment testing and deployment to production. That’s five groups of
tasks that are often divided into, at least, five separate Jenkins jobs. In
reality, there are often more than five jobs for a single CD flow, but let
us keep it an optimistic estimate. How many different CD flows does a medium
sized company have? With twenty, we are already reaching a three digits
number. That’s quite a lot of  jobs to cope with even though the estimates
we used are too optimistic for all but the smallest entities.

Now, imagine that we need to change all those jobs from, let’s say, Maven to
Gradle. We can choose to start modifying them through the Jenkins UI, but that
takes too much time. We can apply changes directly to Jenkins XML files that
represent those jobs but that is too complicated and error prone. Besides,
unless we write a script that will do the modifications for us, we would
probably not save much time with this approach. There are quite a few plugins
that can help us to apply changes to multiple jobs at once, but none of them is
truly successful (at least among free plugins). They all suffer from one
deficiency or another. The problem is not whether we have the tools to perform
massive changes to our jobs, but whether jobs are defined in a way that they can
be easily maintained.

Besides the sheer number of Jenkins jobs, another critical Jenkins&#x27; pain point
is centralization. While having everything in one location provides a lot of
benefits (visibility, reporting and so on), it also poses quite a few
difficulties. Since the emergence of agile methodologies, there’s been a huge
movement towards self-sufficient teams. Instead of horizontal organization with
separate development, testing, infrastructure, operations and other groups, more
and more companies are moving (or already moved) towards self-sufficient teams
organized vertically. As a result, having one centralized place that defines all
the CD flows becomes a liability and often impedes us from splitting teams
vertically based on projects. Members of a team should be able to collaborate
effectively without too much reliance on other teams or departments. Translated
to CD needs, that means that each team should be able to define the deployment
flow of the application they are developing.

Finally, Jenkins, like many other tools, relies heavily on its UI. While that is
welcome and needed as a way to get a visual overview through dashboards and
reports, it is suboptimal as a way to define the delivery and deployment flows.
Jenkins originated in an era when it was fashionable to use UIs for everything.
If you worked in this industry long enough you probably saw the swarm of tools
that rely completely on UIs, drag &amp; drop operations and a lot of forms that
should be filled. As a result, we got tools that produce artifacts that cannot
be easily stored in a code repository and are hard to reason with when anything
but simple operations are to be performed. Things changed since then, and now we
know that many things (deployment flow being one of them) are much easier to
express through code. That can be observed when, for example, we try to define a
complex flow through many Jenkins jobs. When deployment complexity requires
conditional executions and some kind of a simple intelligence that depends on
results of different steps, chained jobs are truly complicated and often
impossible to create.

All things considered, the major pain points Jenkins had until recently are as
follows.

Tendency to create a vast number of jobs

Relatively hard and costly maintenance

Centralization of everything

Lack of powerful and easy ways to specify deployment flow through code

This list is, by no means, unique to Jenkins. Other CI/CD tools have at least
one of the same problems or suffer from deficiencies that Jenkins solved a long
time ago. Since the focus of this article is Jenkins, I won’t dive into a
comparison between the CI/CD tools.

Luckily, all those, and many other deficiencies are now a thing of the past.
With the emergence of the
Pipeline
plugin and many others that were created on
top of it, Jenkins entered a new era and proved itself as a dominant player in
the CI/CD market. A whole new ecosystem was born, and the door was opened for
very exciting possibilities in the future.

Before we dive into the Jenkins Pipeline and the toolset that surrounds it, let
us quickly go through the needs of a modern CD flow.

Continuous Delivery or Deployment Flow with Jenkins

When embarking on the CD journey for the first time, newcomers tend to think
that the tasks that constitute the flow are straightforward and linear. While
that might be true with small projects, in most cases things are much more
complicated than that. You might think that the flow consists of building,
testing and deployment, and that the approach is linear and follows the
all-or-nothing rule. Build invokes testing and testing invokes deployment. If
one of them fails, the developer gets a notification, fixes the problem and
commits the code that will initiate the repetition of the process.

In most instances, the process is far more complex. There are many tasks to run,
and each of them might produce a failure. In some cases, a failure should only
stop the process. However, more often than not, some additional logic should be
executed as part of the after-failure cleanup. For example, what happens if
post-deployment tests fail after a new release was deployed to production? We
cannot just stop the flow and declare the build a failure. We might need to
revert to the previous release, rollback the proxy, de-register the service and
so on. I won’t go into many examples of situations that require complex flow
with many tasks, conditionals that depend on results, parallel execution and so
on. Instead, I’ll share a diagram of one of the flows I worked on.

Some tasks are run in one of the testing servers (yellow) while others are run
on the production cluster (blue). While any task might produce an error, in some
cases such an outcome triggers a separate set of tasks. Some parts of the flow
are not linear and depend on task results. Some tasks should be executed in
parallel to improve the overall time required to run them. The list goes on and
on. Please note that this discussion is not about the best way to execute the
deployment flow but only a demonstration that the complexity can be, often, very
high and cannot be solved by a simple chaining of Freestyle jobs. Even in cases
when such chaining is possible, the maintenance cost tends to be very high.

One of the CD objectives we are unable to solve through chained jobs, or is
proved to be difficult to implement, is conditional logic. In many cases, it is
not enough to simply chain jobs in a linear fashion. Often, we do not want only
to create a job A that, once it’s finished running, executes job B, which, in
turn, invokes job C. In real-world situations, things are more complicated than
that. We want to run some tasks (let’s call them job A), and, depending on the
result, invoke jobs B1 or B2, then run in parallel C1, C2 and C3, and, finally,
execute job D only when all C jobs are finished successfully. If this were a
program or a script, we would have no problem accomplishing something like that,
since all modern programming languages allow us to employ conditional logic in a
simple and efficient way. Chained Jenkins jobs, created through its UI, pose
difficulties to create even a simple conditional logic. Truth be told, some
plugins can help us with conditional logic. We have Conditional Build Steps,
Parameterised Trigger, Promotions and others. However, one of the major issues
with these plugins is configuration. It tends to be scattered across multiple
locations, hard to maintain and with little visibility.

Resource allocation needs a careful thought and is, often, more complicated than
a simple decision to run a job on a predefined agent. There are cases when agent
should be decided dynamically, workspace should be defined during runtime and
cleanup depends on a result of some action.

While a continuous deployment process means that the whole pipeline ends with
deployment to production, many businesses are not ready for such a goal or have
use-cases when it is not appropriate. Any other process with a smaller scope, be
it continuous delivery or continuous integration, often requires some human
interaction. A step in the pipeline might need someone’s confirmation, a failed
process might require a manual input about reasons for the failure, and so on.
The requirement for human interaction should be an integral part of the pipeline
and should allow us to pause, inspect and resume the flow. At least, until we
reach the true continuous deployment stage.

The industry is, slowly, moving towards microservices architectures. However,
the transformation process might take a long time to be adopted, and even more
to be implemented. Until then, we are stuck with monolithic applications that
often require a long time for deployment pipelines to be fully executed. It is
not uncommon for them to run for a couple of hours, or even days. In such cases,
failure of the process, or the whole node the process is running on, should not
mean that everything needs to be repeated. We should have a mechanism to
continue the flow from defined checkpoints, thus avoiding costly repetition,
potential delays and additional costs. That is not to say that long-running
deployment flows are appropriate or recommended. A well-designed CD process
should run within minutes, if not seconds. However, such a process requires not
only the flow to be designed well, but also the architecture of our applications
to be changed. Since, in many cases, that does not seem to be a viable option,
resumable points of the flow are a time saver.

All those needs, and many others, needed to be addressed in Jenkins if it was to
continue being a dominant CI/CD tool. Fortunately, developers behind the project
understood those needs and, as a result, we got the Jenkins Pipeline plugin. The
future of Jenkins lies in a transition from Freestyle chained jobs to a single
pipeline expressed as code. Modern delivery flows cannot be expressed and easily
maintained through UI drag &#x27;n drop features, nor through chained jobs. They can
neither be defined through YAML (Yet Another Markup Language) definitions
proposed by some of the newer tools (which I’m not going to name). We need to go
back to code as a primary way to define not only the applications and services
we are developing but almost everything else. Many other types of tools adopted
that approach, and it was time for us to get that option for CI/CD processes as
well.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/21/dsl-plugins/"><div class="header"><div class="date"><div class="month">April</div><div class="day">21</div></div><h5 class="title">Making your own DSL with plugins, written in Pipeline script</h5></div><p class="teaser">In this post I will show how you can make your own DSL extensions and distribute
them as a plugin, using Pipeline Script.

A quick refresher

Pipeline has a well kept secret: the ability to add your own DSL
elements. Pipeline is itself a DSL, but you can extend it.

There are 2 main reasons I can think you may want to do this:

You want to reduce boilerplate by encapsulating common snippets/things you do
in one DSL statement.

You want to provide a DSL that provides a prescriptive way that your builds
work - uniform across your organisations Jenkinsfiles.

A DSL could look as simple as

acmeBuild {
    script = &quot;./bin/ci&quot;
    environment = &quot;nginx&quot;
    team = &quot;evil-devs&quot;
    deployBranch = &quot;production&quot;
}

This could be the entirety of your Jenkinsfile!

In this &quot;simple&quot; example, it could actually be doing a multi stage build with
retries, in a specified docker container, that deploys only from the production
branch.  Detailed notifications are sent to the right team on important events
(as defined by your org).

Traditionally this is done via the
global
library.  You take a snippet of DSL you want to want to make into a DSL, and
drop it in the git repo that is baked into Jenkins.

A great trivial
example
is this:

jenkinsPlugin {
    name = &#x27;git&#x27;
}

Which is enabled by git pushing the following into vars/jenkinsPlugin.groovy

The name of the file is the name of the DSL expression you use in the Jenkinsfile

def call(body) {
    def config = [:]
    body.resolveStrategy = Closure.DELEGATE_FIRST
    body.delegate = config
    body()

    // This is where the magic happens - put your pipeline snippets in here, get variables from config.
    node {
        git url: &quot;https://github.com/jenkinsci/${config.name}-plugin.git&quot;
        sh &quot;mvn install&quot;
        mail to: &quot;...&quot;, subject: &quot;${config.name} plugin build&quot;, body: &quot;...&quot;
    }
}

You can imagine many more pipelines, or even archetypes/templates of pipelines
you could do in this way, providing a really easy Jenkinsfile syntax for your
users.

Making it a plugin

Using the global DSL library is a handy thing if you have a single Jenkins, or
want to keep the DSLs local to a Jenkins instance.  But what if you want to
distribute it around your org, or, perhaps it is general purpose enough you want
to share it with the world?

Well this is possible, by wrapping it in a plugin. You use the same pipeline
snippet tricks you use in the global lib, but put it in the dsl directory of a
plugin.

My simple
build plugin shows how it is done.  To make your own plugin:

Create a new plugin project, either fork the simple build one, or add a
dependency to it in your pom.xml / build.gradle file

Put your dsl in the resources directory in a similar fashion to
this
(note the &quot;package dsl&quot; declaration at the top)

Create the equivalent extension that just points to the DSL by name like
this
This is mostly &quot;boiler plate&quot; but it tells Jenkins there is a GlobalVariable extension available when Pipelines run.

Deploy it to an Jenkins Update Center to share with your org, or everyone!

The advantage of delivering this DSL as a plugin is that it has a version (you
can also put tests in there), and distributable just like any other plugin.

For the more advanced, Andrew Bayer has a Simple
Travis Runner plugin that
interprets and runs
travis.yml files which is also implemented in pipeline.

So, approximately, you can build plugins for pipeline that extend pipeline, in
pipeline script (with a teeny bit of boiler plate).

Enjoy!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/dsl">dsl</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/22/pipeline-2.x/"><div class="header"><div class="date"><div class="month">April</div><div class="day">22</div></div><h5 class="title">Pipeline 2.x plugins</h5></div><p class="teaser">Those of you who routinely apply all plugin updates may already have noticed that the version numbers of the plugins in the Pipeline suite have switched to a 2.x scheme. Besides aligning better with the upcoming Jenkins 2.0 core release, the plugins are now being released with independent lifecycles.

“Pipeline 1.15” (the last in the 1.x line) included simultaneous releases of a dozen or so plugins with the 1.15 version number (and 1.15+ dependencies on each other). All these plugins were built out of a single workflow-plugin repository. While that was convenient in the early days for prototyping wide-ranging changes, it has become an encumbrance now that the Pipeline code is fairly mature, and more people are experimenting with additions and patches.

As of 2.0, all the plugins in the system live in their own repositories on GitHub—named to match the plugin code name, which in most cases uses the historical workflow term, so for example workflow-job-plugin. Some complex steps were moved into their own plugins, such as pipeline-build-step-plugin. The 1.x changelog is closed; now each plugin keeps a changelog in its own wiki, for example here for the Pipeline Job plugin.

Among other benefits, this change makes it easier to cut new plugin releases for even minor bug fixes or enhancements, or for developers to experiment with patches to certain plugins. It also opens the door for the “aggregator” plugin (called simply Pipeline) to pull in dependencies on other plugins that seem broadly valuable, like the stage view.

The original repository has been renamed pipeline-plugin and for now still holds some documentation, which might later be moved to jenkins.io.

You need not do anything special to “move” to the 2.x line; 1.642.x and later users can just accept all Pipeline-related plugin updates. Note that if you update Pipeline Supporting APIs you must update Pipeline, or at least install/update some related plugins as noted in the wiki.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/22/possible-infra-compromise/"><div class="header"><div class="date"><div class="month">April</div><div class="day">22</div></div><h5 class="title">Possible Jenkins Project Infrastructure Compromise</h5></div><p class="teaser">Last week, the infrastructure team identified the potential compromise of a key
infrastructure machine. This compromise could have taken advantage of, what
could be categorized as, an attempt to target contributors with elevated
access. Unfortunately, when facing the uncertainty of a potential compromise,
the safest option is to treat it as if it were an actual incident, and react
accordingly. The machine in question had access to binaries published to our
primary and secondary mirrors, and to contributor account information.

Since this machine is not the source of truth for Jenkins binaries, we verified
that the files distributed to Jenkins users: plugins, packages, etc, were not
tampered with. We cannot, however, verify that contributor account information
was not accessed or tampered with and, as a proactive measure, we are issuing a
password reset for all contributor accounts. We have also spent significant effort
migrating all key services off of the potentially compromised machine to
(virtual) hardware so the machine can be re-imaged or decommissioned entirely.

What you should do now

If you have ever filed an issue in JIRA,
edited a wiki page, released a plugin or
otherwise created an account via the Jenkins
website, you have a Jenkins community account. You should be receiving a
password reset email shortly, but if you have re-used your Jenkins account
password with other services we strongly encourage you to update your passwords
with those other services.  If you’re not already using one, we also encourage
the use of a password manager for generating and managing service-specific
passwords.

The generated password sent out is temporary and will expire if you do not
use it to update your account. Once it expires you will need recover your
account with the password reset
in the accounts app.

This does not apply to your own Jenkins installation, or any account that you
may use to log into it. If you do not have a Jenkins community account, there is
no action you need to take.

What we’re doing to prevent events like this in the future

As stated above, the potentially compromised machine is being removed from our
infrastructure. That helps address the immediate problem but doesn’t put
guarantees in place for the future. To help prevent potential issues in the
future we’re taking the following actions:

Incorporating more security policy enforcement into our
Puppet-driven infrastructure. Without a
configuration management tool enforcing a given state for some legacy services,
user error and manual mis-configurations can adversely affect project security.
As of right now, all key services are managed by Puppet.

Balkanizing our machine and permissions model more. The machine affected was
literally the first independent (outside of Sun) piece of project
infrastructure and like many legacy systems, it grew to host a multitude of
services. We are rapidly evolving away from that model with increasing levels
of user and host separation for project services.

In a similar vein, we have also introduced a trusted zone in our
infrastructure which is not routable on the public internet, where sensitive
operations, such as generating update center information, can be managed and
secured more effectively.

We are performing an infrastructure permissions audit. Some portions of our
infrastructure are 6+ years old and have had contributors come and go. Any
inactive users with unnecessarily elevated permissions in the project
infrastructure will have those permissions revoked.

I would like to extend thanks, on behalf of the Jenkins project, to
CloudBees for their help in funding and
migrating this infrastructure.

If you have further questions about the Jenkins project infrastructure, you can
join us in the #jenkins-infra channel on Freenode
or in an Infrastructure Q&amp;A session I’ve scheduled for next Wednesday (April
27) at 20:00 UTC (12:00 PST).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infra">infra</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/04/26/jenkins-20-is-here/"><div class="header"><div class="date"><div class="month">April</div><div class="day">26</div></div><h5 class="title">Jenkins 2.0 is here!</h5></div><p class="teaser">Over the past 10 years, Jenkins has really
grown to a
de-facto standard tool that millions of people use to handle automation in
software development and beyond.  It is quite remarkable for a project that
originally started as a hobby project under a different name. I’m very proud.

Around this time last year,
we’ve
celebrated 10 years, 1000 plugins, and 100K installations. That was a good time
to retrospect, and we started thinking about the next 10 years of Jenkins and
what’s necessary to meet that challenge.  This project has long been on a
weekly &quot;train&quot; release model, so it was useful to step back and think about a
big picture.

That is where three pillars of Jenkins 2.0 have emerged from.

First, one of the challenges our users are facing today is that the automation
that happens between a commit and a production has significantly grown in its
scope. Because of this, the clothing that used to fit (aka &quot;freestyle project&quot;,
which was the workhorse of Jenkins) no longer fits. We now need something that
better fits today’s use cases like &quot;continuous delivery pipeline.&quot; This is why
in 2.0 we’ve added the pipeline capability. This 2 year old effort allows you
to describe your chain of automation in a textual form. This allows you to
version control it, put it alongside your source tree, etc. It is also actually
a domain specific language (DSL) of Groovy, so when your pipeline grows in
complexity/sophistication, you can manage its complexity and keep it
understandable far more easily.

Second, over time, Jenkins has developed the &quot;assembly required before initial
use&quot; feeling. As the project has grown, the frontier of interesting development
has shifted to plugins, which is how it should be, but we have left it up to
users to discover &amp; use them. As a result, the default installation became very
thin and minimal, and every user has to find several plugins before Jenkins
becomes really functional. This created a paradox of choice and unnecessarily
hurt the user experience. In 2.0, we reset this thinking and tried to create
more sensible out of the box experience that solves 80% use cases for 80% of
people. You get something useful out of the box, and you can get some
considerable mileage out of it before you start feeling the need of plugins.
This allows us to focus our development &amp; QA effort around this base
functionality, too. By the way, the focus on the out of the box experience
doesn’t stop at functionality, either. The initial security setup of Jenkins is
improved, too, to prevent unprotected Jenkins instances from getting abused by
botnets and attacks.

Third, we were fortunate to have a number of developers with UX background
spend some quality time on Jenkins, and they have made a big dent in improving
various parts of Jenkins web UI. The setup wizard that implements the out of
the box experience improvement is one of them, and it also includes other parts
of Jenkins that you use all the time, such as job configuration pages and new
item pages. This brings much needed attention to the web UI.

As you can see, 2.0 brings a lot of exciting features on the table, but this is
an evolutionary release, built on top of the same foundation, so that your
existing installations can upgrade smoothly. After this initial release, we’ll
get back to our usual weekly release march.  Improvements will be made
to those pillars and others in coming months and years continuously. If you’d
like to get a more in-depth look at Jenkins 2.0, please join us in our virtual
Jenkins meetup 2.0 launch event.

Thank you very much for everyone who made Jenkins 2.0 possible. There are
too many of you
to thank individually, but you know who you are. I wanted to thank CloudBees in
particular for sponsoring the time of many of those people. Ten years ago, all I
could utilize was my own night &amp; weekend time. Now I’ve got a team of smart
people working with me to carry this torch forward, and a big effort like 2.0
wouldn’t have been possible without such organized effort.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/10/jenkins-20-vjam/"><div class="header"><div class="date"><div class="month">May</div><div class="day">10</div></div><h5 class="title">Jenkins 2.0 Online JAM Wrap-up</h5></div><p class="teaser">Last week we hosted our first ever
Online JAM with the debut
topic of: Jenkins 2.0. Alyssa, our
Events officer, and I pulled together a
series of
sessions focusing on some of the most notable aspects of Jenkins 2 with:

A Jenkins 2.0 keynote from project founder
Kohsuke Kawaguchi

An overview of &quot;Pipeline as Code&quot; from Patrick
Wolf

A deep-dive into Pipeline and related plugins like Multibranch, etc from
Jesse Glick and
Kishore Bhatia

An overview of new user experience changes in 2.0 from
Keith Zantow

A quick lightning talk about documentation by yours truly

Wrapping up the sessions, was Kohsuke again, talking about the road beyond
Jenkins 2.0 and what big projects he sees on the horizon.

The event was really interesting for me, and I hope informative for those who
participated in the live stream and Q&amp;A session. I look forward to hosting more
Virtual JAM events in the future, and I hope you will
join us!

Questions and Answers

Below are a collection of questions and answers, that were posed during the
Virtual JAM. Many of these were answered during the course of the sessions, but
for posterity all are included below.

Pipeline

What kind of DSL is used behind pipeline as code? Groovy or allow freely use
different languages as a user prefer?

Pipeline uses a Groovy-based domain specific language.

How do you test your very own pipeline DSL?

Replay helps in testing/debugging while creating pipelines and at the branch
level. There are some ideas which Jesse Glick
has proposed for testing Jenkinsfile and Pipeline libraries captured in
JENKINS-33925.

Isn’t &quot;Survive Jenkins restart&quot; exclusive to [CloudBees] Jenkins Enterprise?

No, this feature does not need
CloudBees
Jenkins Enterprise. All features shown
during the virtual JAM are free and open source. CloudBees&#x27; Jenkins Enterprise
product does support restarting from a specified stage however, and that is not
open source.

How well is jenkins 2.0 integrate with github for tracking job definitions?

Using the
GitHub
Organization Folder plugin, Jenkins can automatically detect a Jenkinsfile in
source repositories to create Pipeline projects.

Please make the ability for re-run failed stages Open Source too :)

This has been passed on to our friends at CloudBees for consideration :)

If Jenkinsfile is in the repo, co-located with code, does this mean Jenkins can
auto-detect new jobs for different branches?

This is possible using the
Pipeline Multibranch plugin.

What documentation sources are there for Pipeline?

Our documentation section contains a number of pagesaround Pipeline.
There is also additional documentation and examples in the plugin’s
git repository and the
jenkinsci/pipeline-examples
repository. (contributions welcome!)

Where we can find the DSL method documentation?

There is generated documentation on jenkins.io which
incldues steps from all public plugins. Inside of a running Jenkins instance,
you can also navigate to
JENKINS_URL/workflow-cps-snippetizer/dslReference
to see the documentation for the plugins which are installed in that instance.

If Pipeline is not support some plugins (there is a lot actually), I needed
SonarQube Runner but unfortunately it’s not supported yet, in Job DSL plugin i
can use &quot;Configure Block&quot; and cover any plugin via XML, how i can achieve the
same with a Pipeline?

Not at this time

Is there a possibility to create custom tooltips i.e. with a quick reference or
a link to internal project documentation? Might be useful i.e. for junior team
members who need to refer to external docs.

Not generally. Though in the case of Pipeline global libraries, you can create
descriptions of vars/functions like standardBuild in the demo, and these will
appear in Snippet Generator under Global Variables.

Oh pipeline supports joining jobs? It’s really good, but I cannot find document
at https://jenkins.io/doc/ could you tell me where is it?

There is a build step, but the Pipeline system is optimized for single-job
pipelines

We have multiple projects that we would like to follow the same pipeline.  How
would I write a common pipeline that can be shared across multiple projects.

You may want to look at implementing some additional steps using the
Pipeline Global
Library feature. This would allow you to define
organization-specific extensions to the Pipeline DSL to abstract away common
patterns between projects.

How much flexibility is there with creating context / setting environment
variables or changing / modifying build tool options when calling a web hook /
api to parameterize pipelines for example to target deployments to different env
using same pipeline

Various environment variables are exposed under the env variable in the Groovy
DSL which would allow you to construct logic as simple or as complex as
necessary to achieve your goal.

When you set up the job for the first time, does it build every branch in git,
or is there a way to stop it from building old branches?

Not at this time, the best way to prevent older branches from being built is to
remove the Jenkinsfile in those branches. Alternatively, you could use the
&quot;include&quot; or &quot;exclude&quot; patterns when setting up the SCM configuration of your
multibranch Pipeline. See also
JENKINS-32396.

Similar to GitHub organizations, will BitBucket &quot;projects&quot; (ways of organizing
collections of repos) be supported?

Yes, these are supported via the
Bitbucket
Branch Source plugin.

How do you handle build secrets with the pipeline plugin? Using unique
credentials stored in the credentials plugin per project and/or branch?

This can be accomplished by using the
Credentials
Binding plugin.

Similar to GitHub Orgs, are Gitlab projects supported in the same way?

GitLab projects are not explicitly supported at this time, but the extension
points which the GitHub Organization Folder plugin uses could be extended in a
similar manner for GitLab. See also JENKINS-34396

Is Perforce scm supported by the Pipeline plugin?

As a SCM source for discovering a Jenkinsfile, not at this time. The
P4
plugin does provide some p4 steps which can be used in a Pipeline script
however, see here for documentation.

Is Mercurial supported with multibranch?

Yes, it is.

Can Jenkinsfile detect when it’s running against a pull request vs an approved commit, so that it can perform a different type of build?

Yes, via the env variables provided in the DSL scope. Using an if statement,
one could guard specific behaviors with:

if (env.CHANGE_ID != null) {
    /* do things! */
}

Let’s say I’m building RPMs with Jenkins and use build number as an RPM
version/release number. Is there a way to maintain build numbers and leverage
versioning of Jenkinsfile?

Through the env variable, it’s possible to utilize env.BUILD_NUMBER or the
SCM commit ID, etc.

Love the snippet generator! Any chance of separating it out from the pipeline
into a separate page on its own, available in the left nav?

Yes, this is tracked in
JENKINS-31831

Any tips on pre-creating the admin user credential and selecting plugins to
automate the Jenkins install?

There are various configuration
management modules which provide parts of this functionality.

I’m looking at the pipeline syntax (in Jenkins 2.0) how do I detect a
step([…​]) has failed and create a notification inside the Jenkinsfile?

This can be done by wrapping a step invocation with a Groovy try/catch block.
See also JENKINS-28119

User Interface/Experience

Is the user experience same as before when we replace the Jenkins.war(1.x to
2.x) in an existing (with security in place) installation?

You will get the new UI features like redesigned configuration forms, but the
initial setup wizard will be skipped. In its stead, Jenkins will offer to
install Pipeline-related functionality.

Is it possible to use custom defined syntax highlighting ?

Within the Pipeline script editor itself, no. It is using the
ACE editor system,
so it may be possible for a plugin to change the color scheme used.

Can you elaborate on what the Blue Ocean UI is? Is there a link or more
information on it?

Blue Ocean is the name of user experience an design project, unfortunately at
this point in time there is not more information available on it.

General

How well this integrate with cloud environment?

The Jenkins controller and agents can run easily in any public cloud environment
that supports running Java applications. Through the
EC2,
JClouds,
Azure, or
any other plugins which extend the cloud
extension
point, it is possible to dynamically provision new build agents on a configured
cloud provider.

Are help texts and other labels and messages updated for other localizations /
languages as well?

Practically every string in Jenkins core is localizable. The extent to which those
strings have been translated depends on contributors by speakers of those
languages to the project. If you want to contribute translations, this
wiki
page should get you started.

Any additional WinRM/Windows remoting functionality in 2.0?

No

Is there a CLI to find all the jobs created by a specific user?

No, out-of-the-box Jenkins does not keep track of which user created which jobs.
The functionality provided by the
Ownership
plugin may be of interest though.

Please consider replacing terms like &quot;master&quot; and &quot;slave&quot; with &quot;primary&quot; and
&quot;secondary&quot;.

&quot;slave&quot; has been replaced with &quot;agent&quot; in Jenkins 2.0.

Updated 2020-09-18 : The term &quot;master&quot; is being replaced with &quot;controller&quot;.

We’ve been making tutorial videos on Jenkins for awhile (mostly geared toward
passing the upcoming CCJPE). Because of that we’re using 1.625.2 (since that is
what is listed on the exam), but should we instead base the videos on 2.0?

As of right now all of the
Jenkins Certification work done by CloudBees is
focused around the Jenkins LTS 1.625.x.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/12/sf-jam-jenkins-and-azure/"><div class="header"><div class="date"><div class="month">May</div><div class="day">12</div></div><h5 class="title">SF JAM Report: Scaling Jenkins for Continuous Delivery with Azure</h5></div><p class="teaser">A few weeks ago, my colleague Brian Dawson
and I were invited to present on
Scaling Jenkins for
Continuous Delivery with Microsoft Azure in Microsoft’s
Reactor space. Azure is Microsoft’s
public cloud offering and one of the many tools available to Jenkins users for
adding elastic compute capacity, among other things, to their build/test/deploy
infrastructure. While our presentations are applicable to practically
any cloud-based Jenkins environment, Thiago Almeida and Oguz Pastirmaci from
Microsoft were also on-hand and presented some interesting Azure-specific
offerings like
Azure
Container Service with Jenkins.

While we do not have video from the meetup, Brian and I did record
a
session with Thiago and Oguz for Channel9
which covers much of the same content:

To kick-off the meetup we asked attendees a few polling questions and
received very telling responses:

How big is your Development/IT organization?

What is your role?

By show of hands do you practice CI/CD/DevOps/etc?

At what scale (tooling and practice)?

The responses indicated that the majority of attendees were from small to medium
organizations where they practiced Continuous Delivery across multiple teams. A
notable 25% or greater attendees considered themselves &quot;fullstack&quot; or
participating in all of the roles of Developer, QA, and Operations. Interesting
when paired with the high number (~80%) of those who practice CD.  This is
likely because modern teams, with mature CD practices, tend to blur the
traditional lines of Developer, QA and Operations. However, In my experience,
while this is often the case for small to medium companies in large
organizations team members tend to fall into the traditional roles, with CD
providing the practice and platform to unify teams across roles.

— Brian Dawson

After gauging the audience, Thiago and Brian reviewed Continuous Delivery (CD)
and implementing it at scale. They highlighted the fact that CD is being rapidly
adopted across teams and organizations, providing the ability: to deliver a demonstrably
higher quality product, shipping more rapidly than before, and to keep team members happier.

However, when organizations fail to properly support CD as they scale, they run
into issues such as: developers acting as administrators at the cost of
productivity, potential lack of security and/or exposure of IP and difficulty in
sharing best practices across teams.

Thiago then highlighted that properly scaling CD practices in the organization
along with the infrastructure itself can alleviate these issues, and discussed
the benefits of scaling CD to on cloud platforms to provide &quot;CD-as-a-Service.&quot;

Overall I found the &quot;theory&quot; discussion to be on point, continuous delivery is
not just a technology nor a people problem. Successful organizations scale their
processes and tooling together.

The slides from our respective presentations are linked below:

(Brian) Scaling Jenkins for Continuous Delivery (.pdf)

(Tyler) Scaling Jenkins with Azure (.pdf)

I hope you join us at future
San Francisco
JAM s!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/11/security-update/"><div class="header"><div class="date"><div class="month">May</div><div class="day">11</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins that fix a number of low and medium severity issues. For an overview of what was fixed, see the security advisory.

One of the fixes may well break some of your use cases in Jenkins, at least until plugins have been adapted: SECURITY-170. This change removes parameters that are not defined on a job from the build environment. So, right now, a job could even be unparameterized, and plugins were able to pass parameters anyway. Since build parameters are added to the environment variables of scripts run during a build, parameters such as PATH or DYLD_LIBRARY_PATH can be defined — on jobs which don’t even expect those as build parameters — to change the behavior of builds.

A number of plugins define additional parameters for builds. For example, GitHub Pull Request Builder passes a number of additional parameters describing the pull request. Release Plugin also allows adding several additional parameters to a build that are not considered to be defined in the job as part of this security fix.

Please see this wiki page for a list of plugins known to be affected by this change.

Until these plugins have been adapted to work with the new restriction (and advice on that is available further down), you can define the following system properties to work around this limitation, at least for a time:

Set hudson.model.ParametersAction.keepUndefinedParameters to true, e.g. java -Dhudson.model.ParametersAction.keepUndefinedParameters=true -jar jenkins.war to revert to the old behavior of allowing any build parameters. Depending on your environment, this may be unsafe, as it opens you up to attacks as described above.

Set hudson.model.ParametersAction.safeParameters to a comma-separated list of safe parameter names, e.g. java -Dhudson.model.ParametersAction.safeParameters=FOO,BAR_baz,quX -jar jenkins.war.

I realize this change, among a few others that improve the security of Jenkins, may be difficult to adapt for some, but given the valuable secrets typically stored in Jenkins, I’m certain that this is the correct approach. We made sure to release this fix with the options described above, so that this change doesn’t block updating those that rely on this behavior.

Developers have several options to adapt to this change:

ParametersAction actually stores all parameters, but getParameters() only returns those that are defined on the job. The new method getAllParameters() returns all of them. This can be used, for example by EnvironmentContributor extensions, to add known safe parameters to build environments.

Don’t pass extra arguments, but define a QueueAction for your metadata instead. Those can still be made available to the build environment as needed.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/17/state-of-jam/"><div class="header"><div class="date"><div class="month">May</div><div class="day">17</div></div><h5 class="title">The State of Jenkins Area Meetups (JAM)</h5></div><p class="teaser">Recently, the Jenkins project announced the release of
Jenkins 2.0, a first major release
after 10 years and 655 weekly releases. This has been a major milestone for
Jenkins and its growing community of developers, testers, designers and other
users in the software delivery process.

With its rising popularity and wide adoption, the Jenkins community continues to
grow and evolve into the millions. Jenkins community meetup activity has risen
to an all time high since the first Jenkins meetup which was established on
August 23 2010, in San Francisco.

Over the last six months the number of
Jenkins Area Meetup (JAM) Groups has
grown from 5 to 30, with coverage in Asia, North America, South America and
Europe.  That’s an average growth of 4 new JAMs per month.

As of today, there are over 4,100 Jenkins fans within the Jenkins meetup
community.  This is the result of contributions from community JAM leaders who
have volunteered their time to provide a platform for learning, sharing and
networking all things Jenkins within their local communities.

For anyone who has not organized a meetup before, there are many moving parts
that have to come together at a specific location, date and time. This process
takes significant effort to methodically plan out. From planning the food and
beverages to securing speaker(s), a venue, audio/visual setup, technical
logistics and of course promoting the meetup. It does takes a level of passion
and effort to make it all happen.

Many THANKS to the 55 JAM leaders, who share this passion - they have
successfully organized over 41 meetups within the past six months in North
America, South America and Europe. That’s about 6 meetups a month!

There are still plenty of opportunities to be a JAM organizer. If there is not a
JAM near you, we’d love to hear from
you! Here’s
how you can get
started.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/JAM">JAM</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/18/announcing-azure-partnership/"><div class="header"><div class="date"><div class="month">May</div><div class="day">18</div></div><h5 class="title">Partnering with Microsoft to run Jenkins infrastructure on Azure</h5></div><p class="teaser">I am pleased to announce that we have partnered with Microsoft to migrate and
power the Jenkins project’s infrastructure with
Microsoft Azure. The partnership comes
at an important time, after the recent launch of Jenkins 2.0,
Jenkins users are more readily adopting Pipeline as
Code and many other plugins at an increasing rate, elevating the importance of
Jenkins infrastructure to the overall success of the project. That strong and
continued growth has brought new demands to our infrastructure’s design and
implementation, requiring the next step in its evolution. This partnership helps
us grow with the rest of the project by unifying our existing infrastructure
under one comprehensive, modern and scalable platform.

In March we
discussed
the potential partnership in our regularly scheduled
project
meeting,
highlighting some of the infrastructure challenges that we face:

Currently we have infrastructure in four different locations, with four
different infrastructure providers, each with their own APIs and tools for
managing resources, each with varying capabilities and capacities.

Project infrastructure is managed by a team of volunteers, operating
more than 15 different services and managing a number of additional external
services.

Our current download/mirror network, while geographically distributed, is
relatively primitive and its implementation prevents us from using more modern
distribution best practices.

In essence, five years of tremendous growth for Jenkins has outpaced our
organically grown, unnecessarily complex, project infrastructure. Migrating to
Azure simplifies and improves our infrastructure in a dramatic way that would
not be possible without a comprehensive platform consisting of: compute, CDN,
storage and data-store services. Our partnership covers, at minimum, the next
three years of the project’s infrastructure needs, giving us a great home for
the future.

Azure also enables a couple of projects that I
have long been dreaming of providing to Jenkins users and contributors:

End-to-end TLS encrypted distribution of Jenkins packages, plugins and
metadata via the Azure CDN.

More complete build/test/release support and capacity on
ci.jenkins.io for plugin developers using
Azure
Container Service and generic VMs.

The Jenkins infrastructure is all open
source which means  all of our Docker containers, Puppet code and many of our
tools are all available on GitHub. Not
only can you watch the migration process to Azure as it happens, but I also
invite you to participate in making our project’s infrastructure better (join
us in the #jenkins-infra channel on Freenode or our
mailing list).

Suffice it to say, I’m very excited about the bright [blue] future for the
Jenkins project and the infrastructure that powers it!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infra">infra</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/23/external-workspace-manager-plugin/"><div class="header"><div class="date"><div class="month">May</div><div class="day">23</div></div><h5 class="title">GSoC Project Intro: External Workspace Manager Plugin</h5></div><p class="teaser">About myself

My name is Alexandru Somai.
I’m following a major in Software Engineering at the Babes-Bolyai University of Cluj-Napoca, Romania.
I have more than two years hands-on experience working in Software Development.

I enjoy writing code in Java, Groovy and JavaScript.
The technologies and frameworks that I’m most familiar with are: Spring Framework, Spring Security, Hibernate,
JMS, Web Services, JUnit, TestNG, Mockito.
As build tools and continuous integration, I’m using Maven and Jenkins.
I’m a passionate software developer who is always learning, always looking for new challenges.
I want to start contributing to the open source community and Google Summer of Code is a starting point for me.

Project summary

Currently, Jenkins’ build workspace may become very large in size due to the fact that some compilers generate
very large volumes of data.
The existing plugins that share the workspace across builds are able to do this by copying the files from
one workspace to another, process which is inefficient.
A solution is to have a Jenkins plugin that is able to manage and reuse the same workspace between multiple builds.

As part of the Google Summer of Code 2016 I will be working on
the External Workspace Manager plugin.
My mentors for this project are Oleg Nenashev
and Martin d’Anjou.
This plugin aims to provide an external workspace management system.
It should facilitate workspace share and reuse across multiple Jenkins jobs.
It should eliminate the need to copy, archive or move files.
The plugin will be written for Pipeline jobs.

Usage

Prerequisites

Multiple physical disks accessible from controller.

The same physical disks must be accessible from Jenkins Nodes (renamed to Agents in Jenkins 2.0).

In the Jenkins global configuration, define a disk pool (or many) that will contain the physical disks.

In each Node configuration, define the mounting point from the current node to each physical disk.

The following diagram gives you an overview of how an External Workspace Manager configuration may look like:

Example one

Let’s assume that we have one Jenkins job. In this job, we want to use the same workspace on multiple Jenkins nodes.
Our pipeline code may look like this:

stage (&#x27;Stage 1. Allocate workspace&#x27;)
def extWorkspace = exwsAllocate id: &#x27;diskpool1&#x27;

node (&#x27;linux&#x27;) {
    exws (extWorkspace) {
        stage(&#x27;Stage 2. Build on the build server&#x27;)
        git url: &#x27;...&#x27;
        sh &#x27;mvn clean install&#x27;
    }
}

node (&#x27;test&#x27;) {
    exws (extWorkspace) {
        stage(&#x27;Stage 3. Run tests on a test machine&#x27;)
        sh &#x27;mvn test&#x27;
    }
}

Note: The stage() steps are optional from the External Workspace Manager plugin perspective.

Stage 1. Allocate workspace

The exwsAllocate step selects a disk from diskpool1
(default behavior: the disk with the most available size).
On that disk, let’s say disk1, it allocates a directory.
The computed directory path is: /physicalPathOnDisk/$JOB_NAME/$BUILD_NUMBER.

For example, Let’s assume that the $JOB_NAME is integration and the $BUILD_NUMBER is 14.
Then, the resulting path is: /jenkins-project/disk1/integration/14.

Stage 2. Build on the build server

All the nodes labeled linux must have access to the disks defined in the disk pool.
In the Jenkins Node configurations we have defined the local paths that are the mounting points to each disk.

The exws step concatenates the node’s local path with the path returned by the exwsAllocate step.
In our case, the node labeled linux has its local path to disk1 defined as: /linux-node/disk1/.
So, the complete workspace path is: /linux-node/disk1/jenkins-project/disk1/integration/14.

Stage 3. Run tests on a test machine

Further, we want to run our tests on a different node, but we want to reuse the previously created workspace.

In the node labeled test we have defined the local path to disk1 as: /test-node/disk1/.
By applying the exws step, our tests will be able to run in the same workspace as the build.
Therefore, the path is: /test-node/disk1/jenkins-project/disk1/integration/14.

Example two

Let’s assume that we have two Jenkins jobs, one called upstream and the other one called downstream.
In the upstream job, we clone the repository and build the project, and in the downstream job we run the tests.
In the downstream job we don’t want to clone and re-build the project, we need to use the same
workspace created in the upstream job.
We have to be able to do so without copying the workspace content from one location to another.

The pipeline code in the upstream job is the following:

stage (&#x27;Stage 1. Allocate workspace in the upstream job&#x27;)
def extWorkspace = exwsAllocate id: &#x27;diskpool1&#x27;

node (&#x27;linux&#x27;) {
    exws (extWorkspace) {
        stage(&#x27;Stage 2. Build in the upstream job&#x27;)
           git url: &#x27;...&#x27;
           sh &#x27;mvn clean install&#x27;
    }
}

And the downstream &#x27;s pipeline code is:

stage (&#x27;Stage 3. Allocate workspace in the downstream job&#x27;)
def extWorkspace = exwsAllocate id: &#x27;diskpool1&#x27;, upstream: &#x27;upstream&#x27;

node (&#x27;test&#x27;) {
    exws (extWorkspace) {
        stage(&#x27;Stage 4. Run tests in the downstream job&#x27;)
        sh &#x27;mvn test&#x27;
    }
}

Stage 1. Allocate workspace in the upstream job

The functionality is the same as in example one - stage 1.
In our case, the allocated directory on the physical disk is: /jenkins-project/disk1/upstream/14.

Stage 2. Build in the upstream job

Same functionality as example one - stage 2.
The final workspace path is: /linux-node/disk1/jenkins-project/disk1/upstream/14.

Stage 3. Allocate workspace in the downstream job

By passing the upstream parameter to the exwsAllocate step,
it selects the most recent stable upstream workspace (default behavior).
The workspace path pattern is like this: /physicalPathOnDisk/$UPSTREAM_NAME/$MOST_RECENT_STABLE_BUILD.
Let’s assume that the last stable build number is 12, then the resulting path is:
/jenkins-project/disk1/upstream/12.

Stage 4. Run tests in the downstream job

The exws step concatenates the node’s local path with the path returned by the exwsAllocate step in stage 3.
In this scenario, the complete path for running tests is: /test-node/disk1/jenkins-project/disk1/upstream/12.
It will reuse the workspace defined in the upstream job.

Additional details

You may find the complete project proposal, along with the design details, features, more examples and use cases,
implementation ideas and milestones in the design document.
The plugin repository will be available on GitHub.

A prototype version of the plugin should be available in late June and the releasable version in late August.
I will be holding plugin functionality demos within the community.

I do appreciate any feedback.
You may add comments in the design document.
If you are interested to have a verbal conversation, feel free to join our regular meetings on Mondays at
12:00 PM UTC
on the Jenkins hangout.
I will be posting updates from time to time about the plugin status on the
Jenkins developers mailing list.

Links

Design document

GSoC program

Jenkins GSoC Page

Project repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alexsomai/">Alexandru Somai</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/25/update-plugin-for-pipeline/"><div class="header"><div class="date"><div class="month">May</div><div class="day">25</div></div><h5 class="title">Refactoring a Jenkins plugin for compatibility with Pipeline jobs</h5></div><p class="teaser">This is a guest post by Chris Price.
Chris is a software engineer at Puppet, and has been
spending some time lately on automating performance testing using the latest
Jenkins features.

In this blog post, I’m going to attempt to provide some step-by-step notes on
how to refactor an existing Jenkins plugin to make it compatible with the new
Jenkins Pipeline jobs.  Before we get to the fun stuff, though, a little
background.

How’d I end up here?

Recently, I started working on a project to automate some performance tests for
my company’s products.  We use the awesome Gatling load
testing tool for these tests, but we’ve largely been handling the testing very
manually to date, due to a lack of bandwidth to get them automated in a clean,
maintainable, extensible way.  We have a years-old Jenkins server where we use
the gatling jenkins
plugin to track the
history of certain tests over time, but the setup of the Jenkins instance was
very delicate and not easy to reproduce, so it had fallen into a state of
disrepair.

Over the last few days I’ve been putting some effort into getting things more
automated and repeatable so that we can really maximize the value that we’re
getting out of the performance tests.  With some encouragement from the fine
folks in the #jenkins IRC channel, I ended up exploring
the JobDSL
plugin and the new Pipeline jobs.  Combining those two
things with some Puppet code to provision a Jenkins server via the
jenkins puppet module gave me
a really nice way to completely automate my Jenkins setup and get a seed job in
place that would create my perf testing jobs.  And the Pipeline job format is
just an awesome fit for what I wanted to do in terms of being able to easily
monitor the stages of my performance tests, and to make the job definitions
modular so that it would be really easy to create new performance testing jobs
with slight variations.

So everything’s going GREAT up to this point.  I’m really happy with how it’s
all shaping up.  But then…​ (you knew there was a &quot;but&quot; coming, right?) I
started trying to figure out how to add the
Gatling Jenkins
plugin to the Pipeline jobs, and kind of ran into a wall.

As best as I could tell from my Googling, the plugin was probably going to
require some modifications in order to be able to be used with Pipeline jobs.
However, I wasn’t able to find any really cohesive documentation that
definitively confirmed that or explained how everything fits together.

Eventually, I got it all sorted out.  So, in hopes of saving the next person a
little time, and encouraging plugin authors to invest the time to get their
plugins working with Pipeline, here are some notes about what I learned.

Spoiler: if you’re just interested in looking at the individual git commits that
I made on may way to getting the plugin working with Pipeline, have a look at
this github
branch.

Creating a pipeline step

The main task that the Gatling plugin performs is to archive Gatling reports
after a run.  I figured that the end game for this exercise was that I was going
to end up with a Pipeline &quot;step&quot; that I could include in my Pipeline scripts, to
trigger the archiving of the reports.  So my first thought was to look for an
existing plugin / Pipeline &quot;step&quot; that was doing something roughly similar, so
that I could use it as a model.  The Pipeline &quot;Snippet Generator&quot; feature
(create a pipeline job, scroll down to the &quot;Definition&quot; section of its
configuration, and check the &quot;Snippet Generator&quot; checkbox) is really helpful for
figuring out stuff like this; it is automatically populated with all of the
steps that are valid on your server (based on which plugins you have installed),
so you can use it to verify whether or not your custom &quot;step&quot; is recognized, and
also to look at examples of existing steps.

Looking through the list of existing steps, I figured that the archive step
was pretty likely to be similar to what I needed for the gatling plugin:

So, I started poking around to see what magic it was that made that archive
step show up there.  There are some mentions of this in the
pipeline-plugin
DEVGUIDE.md and the
workflow-step-api-plugin
README.md, but the real breakthrough for me was finding the definition of the
archive step in the workflow-basic-steps-plugin source
code.

With that as an example, I was able to start poking at getting a
gatlingArchive step to show up in the Snippet Generator.  The first thing that
I needed to do was to update the gatling-plugin project’s pom.xml to depend
on a recent enough version of Jenkins, as well as specify dependencies on the
appropriate pipeline
plugins

Once that was out of the way, I noticed that the archive step had some tests
written for it, using what looks to be a pretty awesome test API for pipeline
jobs and plugins.  Based on those archive
tests,
I added
a
skeleton for a test for the gatlingArchive step that I was about to write.

Then, I moved on to
actually
creating the step.  The meat of the code was this:

public class GatlingArchiverStep extends AbstractStepImpl {
    @DataBoundConstructor
    public GatlingArchiverStep() {}

    @Extension
    public static class DescriptorImpl extends AbstractStepDescriptorImpl {
        public DescriptorImpl() { super(GatlingArchiverStepExecution.class); }

        @Override
        public String getFunctionName() {
            return &quot;gatlingArchive&quot;;
        }

        @NonNull
        @Override
        public String getDisplayName() {
            return &quot;Archive Gatling reports&quot;;
        }
    }
}

Note that in that commit I also added a config.jelly file.  This is how you
define the UI for your step, which will show up in the Snippet Generator.  In
the case of this Gatling step there’s really not much to configure, so my
config.jelly is basically empty.

With that (and the rest of the code from that commit) in place, I was able to
fire up the development Jenkins server (via mvn hpi:run, and note that you
need to go into the &quot;Manage Plugins&quot; screen on your development server and
install the Pipeline plugin once before any of this will work) and visit the
Snippet Generator to see if my step showed up in the dropdown:

GREAT SUCCESS!

This step doesn’t actually do anything yet, but it’s recognized by Jenkins and
can be included in your pipeline scripts at that point, so, we’re on our way!

The step metastep

The step that we created above is a first-class DSL addition that can be used in
Pipeline scripts.  There’s another way to make your plugin work usable from a
Pipeline job, without making it a first-class build step.  This is by use of the
step&quot;metastep&quot;, mentioned in the pipeline-plugin
DEVGUIDE.
When using this approach, you simply refactor your Builder or Publisher to
extend SimpleBuildStep, and then you can reference the build step from the
Pipeline DSL using the step method.

In the Jenkins GUI, go to the config screen for a Pipeline job and click on the
Snippet Generator checkbox.  Select &#x27;step: General Build Step&#x27; from the
dropdown, and then have a look at the options that appear in the &#x27;Build Step&#x27;
dropdown.  To compare with our previous work, let’s see what &quot;Archive the
artifacts&quot; looks like:

From the snippet generator we can see that it’s possible to trigger an Archive
action with syntax like:

step([$class: &#x27;ArtifactArchiver&#x27;, artifacts: &#x27;foo*&#x27;, excludes: null])

This is the &quot;metastep&quot;.  It’s a way to trigger any build action that implements
SimpleBuildStep, without having to actually implement a real &quot;step&quot; that
extends the Pipeline DSL like we did above.  In many cases, it might only make
sense to do one or the other in your plugin; you probably don’t really need
both.

For the purposes of this tutorial, we’re going to do both.  For a couple of reasons:

Why the heck not?  :)  It’s a good demonstration of how the metastep stuff
works.

Because implementing the &quot;for realz&quot; step will be a lot easier if the Gatling
action that we’re trying to call from our gatlingArchive() syntax is using the
newer Jenkins APIs that are required for subclasses of SimpleBuildStep.

GatlingPublisher is the main build action that we’re interested in using in
Pipeline jobs.  So, with all of that in mind, here’s our next goal: get
step([$class: &#x27;GatlingPublisher&#x27;, …​) showing up in the Snippet Generator.

The javadocs for the SimpleBuildStep
class
have some notes on what you need to do when porting an existing Builder or
Publisher over to implement the SimpleBuildStep interface.  In all
likelihood, most of what you’re going to end up doing is to replace occurrences
of AbstractBuild with references to the Run class, and replace occurrences
of AbstractProject with references to the Job class.  The APIs are pretty
similar, so it’s not too hard to do once you understand that that’s the game.
There is some discussion of this in the pipeline-plugin
DEVGUIDE.

For the Gatling plugin, my
initial
efforts to port the GatlingPublisher over to implement SimpleBuildStep only
required the AbstractBuild → Run refactor.

After making these changes, I fired up the development Jenkins server, and, voila!

So, now, we can add a line like this to a Pipeline build script:

step([$class: &#x27;GatlingPublisher&#x27;, enabled: true])

And it’ll effectively be the same as if we’d added the Gatling &quot;Post-Build
Action&quot; to an old-school Freestyle project.

Well…​ mostly.

Build Actions vs. Project Actions

At this point our modified Gatling plugin should work the same way as it always
did in a Freestyle build, but in a Pipeline build, it only partially works.
Specifically, the Gatling plugin implements two different &quot;Actions&quot; to surface
things in the Jenkins GUI: a &quot;Build&quot; action, which adds the Gatling icon to the
left sidebar in the GUI when you’re viewing an individual build in the build
history of a job, and a &quot;Project&quot; action, which adds that same icon to the left
sidebar of the GUI of the main page for a job.  The &quot;Project&quot; action also adds a
&quot;floating panel&quot; on the main job page, which shows a graph of the historical
data for the Gatling runs.

In a Pipeline job, though, assuming we’ve added a call to the metastep, we’re
only seeing the &quot;Build&quot; actions.  Part of this is because, in the last round of
changes that I linked, we only modified the &quot;Build&quot; action, and not the
&quot;Project&quot; action.  Running the metastep in a Pipeline job has no visible effect
at all on the project/job page at this point.  So that’s what we’ll tackle next.

The key thing to know about getting &quot;Project&quot; actions working in a Pipeline job
is that, with a Pipeline job, there is no way for Jenkins to know up front what
steps or actions are going to be involved in a job.  It’s only after the job
runs once that Jenkins has a chance to introspect what all the steps were.  As
such, there’s no list of Builders or Publishers that it knows about up front to
call getProjectAction on, like it would with a Freestyle job.

This is where
SimpleBuildStep.LastBuildAction
comes into play.  This is an interface that you can add to your Build actions,
which give them their own getProjectActions method that Jenkins recognizes and
will call when rendering the project page after the job has been run at least
once.

So, effectively, what we need to do is to
get
rid of the getProjectAction method on our Publisher class, modify the Build
action to implement SimpleBuildStep.LastBuildAction, and encapsulate our
Project action instances in the Build action.

The build action class now constructs an instance of the Project action and
makes it accessible via getProjectActions (which comes from the
LastBuildAction interface):

public class GatlingBuildAction implements Action, SimpleBuildStep.LastBuildAction {
    public GatlingBuildAction(Run build, List sims) {
        this.build = build;
        this.simulations = sims;

        List projectActions = new ArrayList&lt;&gt;();
        projectActions.add(new GatlingProjectAction(build.getParent()));
        this.projectActions = projectActions;
    }

    @Override
    public Collection getProjectActions() {
        return this.projectActions;
    }
}

After making these changes, if we run the development Jenkins server, we can see
that after the first successful run of the Pipeline job that calls the
GatlingPublisher metastep, the Gatling icon indeed shows up in the sidebar on
the main project page, and the floating box with the graph shows up as well:

Making our DSL step do something

So at this point we’ve got the metastep syntax working from end-to-end, and
we’ve got a valid Pipeline DSL step ( gatlingArchive()) that we can use in our
Pipeline scripts without breaking anything…​ but our custom step doesn’t
actually do anything.  Here’s the part where we tie it all together…​ and it’s
pretty easy!  All we need to do is to make our step &quot;Execution&quot; class
instantiate a Publisher and call perform on
it.

As per the
notes
in the pipeline-plugin DEVGUIDE, we can use the @StepContextParameter
annotation to inject in the objects that we need to pass to the Publisher’s
perform method:

public class GatlingArchiverStepExecution extends AbstractSynchronousNonBlockingStepExecution {

    @StepContextParameter
    private transient TaskListener listener;

    @StepContextParameter
    private transient FilePath ws;

    @StepContextParameter
    private transient Run build;

    @StepContextParameter
    private transient Launcher launcher;

    @Override
    protected Void run() throws Exception {
        listener.getLogger().println(&quot;Running Gatling archiver step.&quot;);

        GatlingPublisher publisher = new GatlingPublisher(true);
        publisher.perform(build, ws, launcher, listener);

        return null;
    }
}

After these changes, we can fire up the development Jenkins server, and hack up
our Pipeline script to call gatlingArchive() instead of the metastep
step([$class: &#x27;GatlingPublisher&#x27;, enabled: true]) syntax.  One of these is
nicer to type and read than the other, but I’ll leave that as an exercise for
the reader.

Fin

With that, our plugin now works just as well in the brave new Pipeline world as
it did in the olden days of Freestyle builds.  I hope these notes save someone
else a little bit of time and googling on your way to writing (or porting) an
awesome plugin for Jenkins Pipeline jobs!

Links

Jenkins Pipeline Overview

Pipeline Plugin Developer Guide

Jenkins Source Code

Workflow Step API Plugin

Workflow Basic Steps Plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cprice404/">Chris Price</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/26/gsoc-jenkins-web-ui-project/"><div class="header"><div class="date"><div class="month">May</div><div class="day">26</div></div><h5 class="title">GSoC Project Intro: Improving Job Creation/Configuration</h5></div><p class="teaser">About me

My name is Samat Davletshin and I am from HSE University from Moscow, Russia. I
interned at Intel and Yandex, and cofounded a startup
project where I personally developed front-end and back-end of the website.

I am excited to participate in GSoC with Jenkins this summer as a chanсe to make
a positive change for thousands of users as well as to learn from great mentors.

Abstract

Although powerful, Jenkins new job creation and configuration process may be non
obvious and time consuming. This can be improved by making UI more intuitive,
concise, and functional. I plan to achieve this by creating a simpler new job
creation, configuration process focused on essential elements, and embedding new
functionality.

My mentors are Kirill Merkushev and
Michael Neale

Deliverables

New job creation

New job name validation

Initially, job validation was unresponsive, job creation was still allowed with
an invalid name, and some allowed characters even crashed Jenkins. Happily, two
of this problems were fixed in recent improvements and I plan add only a real
time name check for invalid characters.

Popup window

Jenkins has a lot of windows reloads that may time consuming. The creation of
new job is a simple process requiring only job name and job type. This way UI
may be improved by reducing page reloads and putting new job creation interface
in a dialog window. Such popup would likely consist of three steps of
implementation: rendering a dialog window, receiving JSON with job types,
sending a POST request to create the job.

Configuration page

Changing help information

As reported by some users, it would be useful to have the functionality to
change help information. Installation administrators would be able to change the
help info and choose editing rights for other users. That would likely require a
creation of extension points and a plugin using them. I also would like to
include the ability to style the help information using markdown as shown above.

[Optional] The functionality is extended to creation of crowd sourced &quot;wiki like&quot; documentation

As in
localization
plugin the changes are gathered and applied beyond installation of a particular
user.

More intuitive configuration page.

Pursuing to solve this  issue

Although there are a lot improvements in new configuration page, there is always
a room for improvements. An advanced job still has a very complicated and hard
to read configuration page. It is still open to discussion, but I may approach
it by better division of configuration parts such as an accordion based
navigation.

Home page

[Optional] Removing &quot;My Views&quot; page

&quot;My Views&quot; page may unnecessary complicate essential sidepanel navigation. Since
it contains very small functionality, the functions may be moved to the home
page and the whole page may be removed. That may be implemented by adding icons
to &quot;My Views&quot; tabs. Additionally, the standard view creation page can create
either of the types

[Optional] Reducing number of UI elements

The home page may contain some UI elements that are not essential and rarely
used. This way elements &quot;enable auto refresh&quot;, “edit description”, “icon sizes”,
”legend”, “RSS” may be removed from home page and placed under &quot;Manage Jenkins&quot;
or an upper menu. It is also possible to create new extension points to support
new UI elements through plugins.

Credentials store page

[Optional] Grouping credentials and their domains

Credentials page has too many reloads and requires many clicks to get to a
required credentials page. That may be improved by removing the last page and
showing credentials under domains.

Current progress

By May 25th I learned about the structure and tools of Jenkins and started
working on the first project:

I started with New Job Name validation first. Luckily, in last updates the
changes of recena there
were implemented all of the changes I proposed except real time check on name
validity. Here I proposed the change which fixes it by
sending GET request on keyup event in addition to blur.

I also made a New Job Popup with using existing interface.

View the current
pop-up progress

I used Remodal library for popup and put
there
existing
New Job container. Surprisingly, it was fully functional right away. On the GIF
you can see that popup receives all job types and then successfully submits the
post form creating a new job. I think that could be a good first step. Further I
can start changing the window itself.

Links

Initial proposal of the project

The project discussion on mailing list

Jenkins GSoC Page

Project repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/samatdav/">Samat Davletshin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/26/introducing-blue-ocean/"><div class="header"><div class="date"><div class="month">May</div><div class="day">26</div></div><h5 class="title">Introducing Blue Ocean: a new user experience for Jenkins</h5></div><p class="teaser">In recent years developers have become rapidly attracted to tools that are not
only functional but are designed to fit into their workflow seamlessly and are
a joy to use. This shift represents a higher standard of design and user
experience that Jenkins needs to rise to meet.

We are excited to share and invite the community to join us on a project we’ve
been thinking about over the last few months called Blue Ocean.

Blue Ocean is a project that rethinks the user experience of Jenkins, modelling
and presenting the process of software delivery by surfacing information that’s
important to development teams with as few clicks as possible, while still
staying true to the extensibility that is core to Jenkins.

While this project is in the alpha stage of development, the intent is that
Jenkins users can install Blue Ocean side-by-side with the Jenkins Classic UI
via a plugin.

Not all the features listed on this blog are complete but we will be hard at
work over the next few months preparing Blue Ocean for general use. We intend
to provide regular updates on this blog as progress is made.

Blue Ocean is open source today
and we invite you to give us feedback and to contribute to the project.

Blue Ocean will provide development teams:

New modern user experience

The UI aims to improve clarity, reduce clutter and navigational depth to make
the user experience very concise. A modern visual design gives developers much
needed relief throughout their daily usage and screens respond instantly to
changes on the server making manual page refreshes a thing of the past.

Advanced Pipeline visualisations with built-in failure diagnosis

Pipelines are visualised on screen along with the
steps and logs to allow simplified comprehension of the continuous delivery
pipeline – from the simple to the most sophisticated scenarios.

Scrolling through 10,000 line log files is a thing of the past. Blue Ocean
breaks down your log per step and calls out where your build failed.

Branch and Pull Request awareness

Modern pipelines make use of multiple Git branches, and Blue Ocean is designed
with this in mind. Drop a Jenkinsfile into your Git
repository that defines your pipeline and Jenkins will automatically discover
and start automating any  Branches and validating Pull Requests.

Jenkins will report the status of your pipeline right inside Github or
Bitbucket on all your commits, branches or pull requests.

Personalised View

Favourite any pipelines, branches or pull requests and see them appear on your
personalised dashboard. Intelligence is being built into the dashboard. Jobs
that need your attention, say a Pipeline waiting for approval or a failing job
that you have recently changed, appear on the top of the dashboard.

You can read more about Blue Ocean and its goals on the
project page and developers should watch the
Developers list for more information.

For Jenkins developers and plugin authors:

Jenkins Design “Language”

The Jenkins Design Language (JDL) is a set of standardised React components and
a style guide that help developers create plugins that retain the look and feel
of Blue Ocean in an effortless way. We will be publishing more on the JDL,
including the style guide and developer documentation, over the next few weeks.

Modern JavaScript toolchain

The Jenkins plugin tool chain has been extended so that developers can use
ES6,
React, NPM
in their plugins without endless yak-shaving. Jenkins
js-modules are already in use in
Jenkins today, and this builds on this, using the same tooling.

Client side Extension points

Client Side plugins use Jenkins plugin infrastructure. The Blue Ocean libraries
built on ES6 and React.js provide an extensible client side component model
that looks familiar to developers who have built Jenkins plugins before. Client
side extension points can help isolate failure, so one bad plugin doesn’t take
a whole page down.

Server Sent Events

Server Sent Events
(SSE) allow plugin developers to tap into changes of state on the server and make
their UI update in real time ( watch this for a
demo).

To make Blue Ocean a success, we’re asking for help and support from Jenkins
developers and plugin authors. Please join in our Blue Ocean discussions on the
Jenkins Developer
mailing list and the #jenkins-ux IRC channel on Freenode!

Links

Blue Ocean project page

Blue Ocean GitHub repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/i386/">James Dumay</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/05/31/pipeline-snippetizer/"><div class="header"><div class="date"><div class="month">May</div><div class="day">31</div></div><h5 class="title">New display of Pipeline’s &quot;snippet generator&quot;</h5></div><p class="teaser">Those of you updating the Pipeline Groovy plugin
to 2.3 or later will notice a change to the appearance of the configuration form.
The Snippet Generator tool is no longer a checkbox enabled inside the configuration page.
Rather, there is a link Pipeline Syntax which opens a separate page with several options.
(The link appears in the project’s sidebar; Jenkins 2 users will not see the sidebar from the configuration screen,
so as of 2.4 there is also a link beneath the Pipeline definition.)

Snippet Generator continues to be available for learning the available
Pipeline steps and creating sample calls given various configuration options.
The new page also offers clearer links to static reference documentation, online
Pipeline documentation resources, and an IntelliJ IDEA code completion file
(Eclipse support is unfinished).

One motivation for this change
( JENKINS-31831) was to
give these resources more visual space and more prominence.  But another
consideration was that people using multibranch projects or organization folders
should be able to use Snippet Generator when setting up the project, before
any code is committed.

Those using
Pipeline
Multibranch plugin or organization folder plugins should upgrade to 2.4 or
later to see these improvements as well.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/01/gsoc-automatic-plugin-documentation/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 1</div></div><h5 class="title">GSOC Project Intro: Automatic Plugin Documentation</h5></div><p class="teaser">About me

I am Cynthia Anyango from Nairobi, Kenya. I am a second year student at Maseno
University. I am currently specializing on Ruby on Rails and trying to learn
Python. I recently started contributing to Open source projects.My major
contribution was at Mozilla, where I worked with the QA for Cloud services. I did
manual and automated tests for various cloud services. I wrote documentation
too. Above that, I am competent and I am always passionate about what I get my
hands on.

Project summary

Currently Jenkins plugin documentation is being stored in Confluence. Sometimes
the documentation is scattered and outdated. In order to improve the situation we
would like to follow the documentation-as-code approach and to put docs to
plugin repositories and then publish them on the project website using the
awestruct engine. The project aims an implementation of a documentation
continuous deployment flow powered by Jenkins and Pipeline Plugin.

The idea is to automatically pull in the README and other docs from GitHub, show
changelogs with versions and releases dates. I will be designing file templates
that will contain most of the  docs information that will be required from
plugin developers. Initially the files will be written in
AsciiDoc. Plugin developers will get a chance to
review the templates. The templates will be prototyped by various plugin
developers.

The docs that will be automatically pulled from github and will be published on
Jenkins.io under the Documentation section.

My mentors are R.Tyler and
Baptiste Mathus

I hope to achieve this by 25th June when we will be having our mid-term
evaluations.

I will update more on the progress.

Links

Gsoc Page

Jenkins Gsoc Page

Mailing List discussion on Jenkins-Developers

My blog on Medium<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cynthia/">Cynthia Anyango</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/05/08/another-big-thank-you-to-rackspace/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 8</div></div><h5 class="title">Another big thank you to Rackspace</h5></div><p class="teaser">+
As the Jenkins project grows, https://jenkins-ci.org/content/come-join-infra-team[the need for our infrastructure has been growing]. https://ci.jenkins.io/[Our Jenkins-on-Jenkins] needs more build agents, we need more servers to run our infrastructure services. +
 +

+
And it was https://jenkins-ci.org/content/big-thanks-rackspace[once again] Rackspace who stepped up to the plate; they have kindly donated us more https://www.rackspace.com/cloud/servers/[cloud servers]. I also use Rackspace for one of my personal servers, and when I went back to their admin console this time, I noticed that they&#x27;ve added https://www.rackspace.com/cloud/[a lot more services] to their offering. +
 +

+
image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/rackspace.jpg[image,width=200,height=200] +

+
+

+
I am setting up these boxes as I write this. A huge thank you for Rackspace for their support of this project. And if you are interested in using Rackspace cloud servers as elastic build agents, https://wiki.jenkins.io/display/JENKINS/JClouds+Plugin[jclouds plugin] is your friend.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/links">links</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meta">meta</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2014/04/24/juc-agenda-posted/"><div class="header"><div class="date"><div class="month">April</div><div class="day">24</div></div><h5 class="title">JUC agenda posted</h5></div><p class="teaser">+
https://en.wikipedia.org/wiki/Kevin_Allen_(author)[ +
image:https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/The_Hidden_Agenda_3D.png/181px-The_Hidden_Agenda_3D.png[image] +
] +

+

+
Agenda is posted for Jenkins User Conference https://www.cloudbees.com/jenkins/juc-2014/boston[Boston] and https://www.cloudbees.com/jenkins/juc-2014/berlin[Berlin]. +
 +

+
For Boston, my favorite would be the https://www.cloudbees.com/jenkins/juc-2014/boston/sessions#JesseGlick[workflow in Jenkins] talk that will cover the new workflow job type Jesse and I are working on. As of this writing it is still very much a work in progress, but that talk is our way of putting a stake on the ground that we WILL have something we can talk about by then. There&#x27;s also some talks that describes how they&#x27;ve put together pieces (including Jenkins) to create a broad automation, such as https://www.cloudbees.com/jenkins/juc-2014/boston/sessions#HoiTsang[Distributed Scrum Development with Jenkins, Vagrant, Fabric and Selenium] and https://www.cloudbees.com/jenkins/juc-2014/boston/sessions#JimCrossley[Moving Existing Enterprise Systems to Continuous Integration and Deployment with Jenkins]. +
 +

+
For Berlin, it turns out that we have steller line up of the speakers far beyond my expectation. You have a number of key community contributors/developers like https://www.cloudbees.com/jenkins/juc-2014/berlin/speakers#ChristopherOrr[Christopher Orr] talking about https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions#ChristopherOrr[how he does mobile build/test/deploy], or https://www.cloudbees.com/jenkins/juc-2014/berlin/speakers#VincentLatombe[Vincent] talking about https://wiki.jenkins.io/display/JENKINS/Literate+Plugin[literate plugin]. I&#x27;m also looking forward to the https://www.cloudbees.com/jenkins/juc-2014/berlin/sessions#JulienPivotto[Puppetizing Jenkins Pipelines] from Julien Pivotto, which (if I understand correctly) is about deploying Jenkins and its jobs through Puppet — That is something I notice many people are very interested in nowadays. +
 +

+
All of them are looking forward to meeting you and hearing your thoughts and feedbacks, and I&#x27;m sure this is going to be a great learning/networking oppotunities. +
 +

+
https://www.eventbrite.com/e/jenkins-user-conference-boston-ma-june-18-2014-tickets-10558652213[Registration for Boston is here], and https://www.eventbrite.com/e/jenkins-user-conference-berlin-germany-june-25-2014-tickets-10557974185[registration for Berlin is here]. Seats are starting to fill up now, so don&#x27;t procrastinate too much!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/news">news</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workflow">workflow</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/10/save-costs-with-ec2-spot-fleet/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">10</div></div><h5 class="title">Save up to 90% of CI cost on AWS with Jenkins and EC2 Spot Fleet</h5></div><p class="teaser">This is a guest post by Aleksei Besogonov, Senior Software Developer at
Amazon Web Services.

Earlier this year, we published a case study on how
Lyft has used Amazon EC2 Spot instances to save 75% on their continuous delivery
infrastructure costs by simply changing four lines of code. Several other EC2 customers like Mozilla have
also reduced costs of their
continuous integration, deployment and testing pipelines by up to 90% on Spot instances. You can view
the current savings on Spot instances over EC2 On-demand instances using the
Spot Bid Advisor :

AWS Spot instances are spare EC2 instances that you can bid on. While your Spot instances may be
terminated when EC2’s spare capacity declines, you can automatically replenish these instances and
maintain your target capacity using
EC2 Spot fleets. As each
instance type and Availability Zone provides an alternative capacity pool, you can select multiple
such pools to launch the lowest priced instances currently available by launching a Spot
fleet on the Amazon EC2 Spot Requests console
or using the AWS CLI/SDK tools.

In this walkthrough, we’ll show you how to configure Jenkins to automatically scale a fleet of Spot
instances up or down depending on the number jobs to be completed.

Request an Amazon EC2 Spot fleet

To get started, login to Amazon EC2 console, and click on Spot Requests
in the left hand navigation pane. Alternatively, you can directly login to
Amazon EC2 Spot Requests console. Then click on the
Request Spot Instances button at the top of the dashboard.

In the Spot instance launch wizard, select the Request &amp; Maintain option to request a Spot fleet that automatically
provisions the most cost-effective EC2 Spot instances, and replenishes them if interrupted. Enter an initial
target capacity, choose an AMI, and select multiple instance types to automatically provision the lowest priced
instances available.

On the next page, ensure that you have selected a key pair, complete the launch wizard, and note the Spot
fleet request ID.

Amazon EC2 Spot fleet automates finding the lowest priced instances for you, and enables your Jenkins cluster
to maintain the required capacity; so, you don’t need any bidding algorithms to provision the optimal Spot
instances over time.

Configure Jenkins

Install the Plugin

From the Jenkins dashboard, select Manage Jenkins, and then click Manage Plugins. On the Available tab,
search for and select the EC2 Fleet Jenkins Plugin. Then click the Install button.

After the plugin installation is completed, select Manage Jenkins from the Jenkins dashboard, and
click Configure System. In the Cloud section, select Amazon Spot Fleet to add a new Cloud.

Configure AWS Credentials

Next, we will configure the AWS and agent node credentials. Click the Add button next to AWS Credentials,
select Jenkins, and enter your AWS Access Key, secret, and ID.

Next, click the Add button in the Spot fleet launcher to configure your agents with an SSH key.
Select Jenkins, and enter the username and private key (from the key pair you configured in your Spot fleet request)
as shown below.

Confirm that the AWS and SSH credentials you just added are selected. Then choose the region, and the Spot fleet
request ID from the drop-down. You can also enter the maximum idle time before your cluster automatically scales
down, and the maximum cluster size that it can scale up to.

Submit Jobs and View Status

After you have finished the previous step, you can view the EC2 Fleet Status in the left hand navigation pane on
the Jenkins dashboard. Now, as you submit more jobs, Jenkins will automatically scale your Spot fleet to add more
nodes. You can view these new nodes executing jobs under the Build Executor Status.
After the jobs are done, if the nodes remain free for the specified idle time (configured in the previous step),
then Jenkins releases the nodes, automatically scaling down your Spot fleet nodes.

Build faster and cheaper

If you have a story to share about your team or product, or have a question to ask, do leave a comment
for us; we’d love to connect with you!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cyberax/">Aleksei Besogonov</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/aws">aws</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ec2">ec2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/13/gsoc-usage-stats-analysis/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">13</div></div><h5 class="title">GSoC Project Intro: Usage Statistics Analysis</h5></div><p class="teaser">About myself

Hello, my name is Payal Priyadarshini.  I am pursing my major in Computer
Science &amp; Engineering at the Indian Institute of Technology Kharagpur, India.  I
am very proficient in writing code in Python, C++, Java and currently getting
familiar and hopefully good in Groovy too.

I have internship experiences in renowned institutions like Google and VMware
where I worked with some exciting technologies for example Knowledge Graphs,
BigTable, SPARQL, RDF in Google. I am a passionate computer science student who
is always interested in learning and looking for new challenges and
technologies.That’s how I came across to Google Summer of Code where I am
working on some exciting data mining problems which you are going to encounter
below in this blog.

Project Overview

Jenkins has collected anonymous usage information of more than 100,000
installations which includes set of plugins and their versions etc and also
release history information of the upgrades. This data collection can be used
for various data mining experiments. The main goal of this project is to perform
various analysis and studies over the available dataset to discover trends
in data usage. This project will help us to learn more about the Jenkins
usage by solving various problems, such as:

Plugin versions installation trends, will let us know about the versions installation behaviour of a given plugin.

Spotting downgrades, which will warn us that something is wrong with the version from which downgrading was performed.

Correlating what users are saying (community rating) with what users are doing (upgrades/downgrades).

Distribution of cluster size, where clusters represents jobs, nodes count which approximates the size of installation.

Finding set of plugins which are likely to be used together, will setup pillar for plugin recommendation system.

As a part of the Google Summer of Code 2016, I will be working on the above
mentioned problems. My mentors for the project are Kohsuke Kawaguchi and Daniel Beck. Some analyses has already been done over this
data but those are outdated as charts can be more clearer and interactive. This project aims to improvise existing
statistics and generating new ones discussed above.

Use Cases

This project covers wide-range of the use-cases that has been derived from the
problems mentioned above.

Use Case 1: Upgrade/Downgrade Analysis

Understanding the trend in upgrades and downgrades have lots of utilities, some
of them have already been explained earlier which includes measuring the
popularity, spotting downgrades, giving warning about the wrong versions quickly
etc.

Use Case 1.1: Plugin versions installation trends

Here we are analysing the trend in the different version installations for a
given plugin. This use-case will help us to know about:

Trend in the upgrade to the latest version released for a given plugin.

Trend in the popularity decrement of the previous versions after new version release.

Find the most popular plugin version at any given point of time.

Use Case 1.2: Spotting dowgrades

Here we are interested to know, how many installations are downgraded from any
given version to previously used version. Far fetched goal of this analysis is
to give warning when something goes wrong with the new version release, which
can be sensed using downgrades performed by users. This analysis can be
accomplished by studying the monotonic property of the version number vs.
timestamp graph for a given plugin.

Use Case 1.3: Correlation with the perceived quality of Jenkins release

To correlate what users are saying to what users are doing, we have community
ratings which tells us about the ratings and reviews of the releases and has
following parameters:

Used the release on production site w/o major issues.

Don’t recommend to other.

Tried but rolled it back to the previous version.

First parameters can be calculated from the Jenkins usage data and third
parameter is basically spotting downgrades(use case 1.2). But the second
parameter is basically an expression which is not possible to calculate. This
analysis is just to get a subjective idea about the correlation.

Use Case 2: Plugin Recommendation System

This section involves setting up ground work for the plugin recommendation
system. The idea is to find out the set of plugins which are most likely to be
used together. Here we will be following both content based filtering as well as
collaborative filtering approach.

Collaborative Filtering

This approach is based upon analysing large amount of information on
installation’s behaviours and activities. We have implicit form of the data
about the plugins, that is for every install ids, we know the set of plugins
installed. We can use this information to construct plugin usage graph where
nodes are the plugins and the edges between them is the number of installations
in which both plugins are installed together.

Content-based Filtering

This method is based on a properties or the content of the item for example
recommending items that are similar to the those that a user liked in the past
or examining in the present based upon some properties. Here, we are utilizing
Jenkins
plugin dependency graph to learn about the properties of a plugin. This graph
tells us about dependent plugins on a given plugin as well as its dependencies
on others. Here is an example to show, how this graph is use for content based
filetring, suppose if a user is using “CloudBees Cloud Connector”, then we can
recommend them for “CloudBees Registration Plugin” as both plugins are dependent
on “CloudBees Credentials Plugin”.

Additional Details

You may find the complete project proposal along with the detailed design of the
use-cases with their implementation details here in the
design
document.

A complete version of the use-case 1: Upgrade &amp; Downgrade Analysis should be
available in late June and basic version of plugin recommendation system will be
available in late July.

I do appreciate any kind of feedback and suggestions.  You may add comments in
the
design
doc.  I will be posting updates about the statistics generation status on the
jenkins-dev mailing
list and jenkins-infra mailing list.

Links:

Design Doc

Google Summer of Code

Github infra-stats

Jenkins statistics

Jenkins Plugin Dependency Graph

Github GSoC Jenkins Usage Statistics Analysis<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/payal94/">Payal Priyadarshini</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/usage-statistics">usage-statistics</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/13/june-jenkins-events/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">13</div></div><h5 class="title">Upcoming June Jenkins Events</h5></div><p class="teaser">It is hard to believe that the first half of 2016 is almost over and summer is
just around the corner.  As usual, there are plenty of educational Jenkins
events planned for this month. Below lists what’s happening in your neck of the
woods:

Online JAM

June 14: Plugin Development - Basics

North America JAMs

June 14: Pipeline in a Windows Environment - Boston, Massachusetts

June 15: Open Source Jenkins 2.0, What’s New? - Washington, DC

June 22: Continuously Deploying Containers with Jenkins Pipeline to a Docker Swarm Cluster - Seattle, Washington

Europe JAM

June 14: Jenkins 2.0 - London, United Kingdom

June 22: Pipeline As Code - Toulouse, France

Links

Start a JAM in your city if there isn’t one already.

Become a JAM member

Become an online JAM member

Speak or sponsor at a JAM. Contact us at jenkinsci-jam@googlegroups.com

Take advantage of the super-early-bird price to Jenkins World 2016

Become a Jenkins project contributor<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/14/gsoc-jenkins-support-core-plugin-improvements/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">14</div></div><h5 class="title">GSoC Project Intro: Support Core Plugin Improvements</h5></div><p class="teaser">About me

I am Minudika Malshan, an undergraduate student in Computer Science and Engineering from University of Moratuwa, Sri Lanka.

As a person who is passionate in open source software development and seeking for new knowledge and experience, I am willing to give my contribution for this project.

LinkedIn | Twitter

Abstract

The Support-Core Plugin provides the basic infrastructure for generating &quot;bundles&quot; of support information with Jenkins.
There are two kinds of bundles.

Automatic bundles: Bundles which are generated and get saved in $JENKINS_HOME/support once per hour starting 15 seconds after Jenkins starts the plugin.
The automatic bundles are retained using an exponential aging strategy. Therefore it’s possible to have a bunch of them over the entire lifetime after the plugin installing the plugin.

On demand bundles: These bundles are generated from the root &quot;Support&quot; action.

However current support-core plugin is not much user friendly. The object of this project is to make it more user friendly by adding some features which make a sophisticated environment for the user who use support plugin.

In this project scope, there are three features and improvements we are going to consider.

Ease the bundles management by the administrator ( JENKINS-33090)

Adding an option to anonymize customer labels (strings created by the user such as name of a job, folder, view, agent, and template etc). ( JENKINS-33091)

Allowing user to create an issue and submit a bundle into the OSS tracker using the support-core plugin. ( JENKINS-21670)

Arnaud Héritier and Steven Christou are guiding me through the project as my mentors.

Tasks and Deliverables

Ease the bundles management by the administrator.

Under this task, the following functions are going to be implemented.

Listing bundles stored on the jenkins instance with their details.

Allowing user to download each bundle.

Allowing user to delete each bundle or all bundles.

Allowing user to browse the content of each bundle.

Automatically purging old bundles.

Enabling user to create an issue and submit a bundle into the OSS tracker

When a Jenkins user sees an issue, he/she commonly contacts his support contacts (Jenkins instance admins) and then Jenkins admins troubleshoot the issue.
The objective of this task is to implement a feature which enables the user to report an issue to a admin through support core plugin.

When creating bundles to attach with the ticket, it is important to protect the privacy of the user who creates the ticket. When considering doing that, anonymizing user created labels (texts) comes to the front.

Adding  an option to anonymize customer labels

The following functions will be implemented under this taks.

Creating randomized tokens for labels created by users.

Producing a mapping for those labels.

Substituting encoded labels into all the files included in the support bundle.

When creating randomized tokens, it would be much useful and effective if we can create those tokens in a way they make sense to humans. (i.e. readable to humans). For that, I am hoping to use a suitable java library to create human friendly random tokens. One of such libraries is wordnet-random-name.

However in order to substitute randomized tokens, all files included in the bundle should be read. This can become inefficient when bundle consists of large number of files.  Therefore it’s important to follow an optimized method for this task.

References

Initial proposal of the project

Project repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/minudika/">Minudika Malshan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/support-core">support-core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/14/jenkins-world-agenda/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">14</div></div><h5 class="title">Jenkins World Agenda is Live!</h5></div><p class="teaser">Join us in Santa Clara, California on September 13-15, 2016!

We are excited to announce the Jenkins
World agenda is now live. There will be 50+ sessions, keynotes, training,
certifications and workshops. Here are a few highlights of what you can expect:

High level topics

Continuous delivery

DevOps

Microservices architectures

Testing

Automation tools

Plugin development

Pipeline

Best practices

And much more

Additionally, Jenkins World offers great opportunities for hands-on learning,
exploring and networking:

Plugin Development Workshop

Due to its popularity in previous years, we are bringing back the plugin
development workshop. This workshop will introduce developers to the Jenkins
plugin ecosystem and terminology. The goal is to provide a cursory overview of
the resources available to Jenkins plugin developers. Armed with this
information, Jenkins developers can learn how to navigate the project and
codebase to find answers to their questions.

Birds of a Feather Sessions

BoFs, as they are usually known, will be a new addition to Jenkins World this
year. Sessions will be curated on various technical topics from DevOps to how
enterprises are integrating Jenkins in their environment. Discussions will be
lead by the industry’s brightest minds who have an influence in shaping the
future of Jenkins.

Ask the Experts

Got a Jenkins question that’s been keeping you up at night? Need to bounce ideas
off somebody? Or you just need someone to fix your Jenkins issue? This is your chance
to get connected with the Jenkins Experts. Experts will be on hand to help with
all your Jenkins needs on Sept 14th &amp; 15th.

Prepare for Jenkins Certification

The objective of this session is to help you assess your level of readiness for
the certification exam - either the Certified Jenkins Engineer (CJE/open source)
certification or the Certified CloudBees Jenkins Platform Engineer
(CCJPE/CloudBees-specific) certification. After an overview about the
certification program, a Jenkins expert from CloudBees will walk you through the
various sections of the exam, highlighting the important things to controller ahead
of time, not only from a pure knowledge perspective but also in terms of
practical experience. This will be an interactive session.

Hope to see you at Jenkins World 2016!

Don’t miss out on
Super
Early Bird Rate $399. Price goes up after July 1.

Links

Start a JAM in your city if there isn’t one already.

Become a JAM member.

Become an online JAM member

Be a JAM speaker or sponsor. Let us know jenkinsci-jam@googlegroups.com

Become a Jenkins project contributor<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/15/jenkins-pipeline-scalability/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">15</div></div><h5 class="title">Jenkins Pipeline Scalability in the Enterprise</h5></div><p class="teaser">This is a guest post by Damien
Coraboeuf, Jenkins project contributor and Continuous Delivery consultant.

Implementing a CI/CD solution based on Jenkins has become very easy. Dealing
with hundreds of jobs? Not so much. Having to scale to thousands of jobs?
Now this is a real challenge.

This is the story of a journey to get out of the jungle of jobs…​

Start of the journey

At the beginning of the journey there were several projects using roughly the same
technologies. Those projects had several
branches, for maintenance of releases, for new features.

In turn, each of those branches had to be carefully built, deployed on different
platforms and versions, promoted so they could be tested for functionalities,
performances and security, and then promoted again for actual delivery.

Additionally, we had to offer the test teams the means to deploy any version of
their choice on any supported platform in order to carry out some manual tests.

This represented, for each branch, around 20 jobs. Multiply this by the number of
branches and projects, and there you are: more than two years after the start
of the story, we had more than 3500 jobs.

3500 jobs. Half a dozen people to manage them all…​

Preparing the journey

How did we deal with this load?

We were lucky enough to have several assets:

time - we had time to design a solution before the scaling went really out of
control

forecast - we knew that the scaling would occur and we were not taken by
surprise

tooling - the Jenkins Job DSL
was available, efficient and well documented

We also knew that, in order to scale, we’d have to provide a solution with the
following characteristics:

self-service - we could not have a team of 6 people become a bottleneck for
enabling CI/CD in projects

security - the solution had to be secure enough in order for it to be used by
remote developers we never met and didn’t know

simplicity - enabling CI/CD had to be simple so that people having
never heard of it could still use it

extensibility - no solution is a one-size-fits-all and must be flexible
enough to allow for corner cases

All the mechanisms described in this article are available through the
Jenkins Seed plugin.

Creating pipelines using the Job DSL and embedding the scripts in the code was
simple enough. But what about branching? We needed a mechanism to allow the
creation of pipelines per branch, by downloading the associated DSL and to
run it in a dedicated folder.

But then, all those projects, all those branches, they were mostly using the
same pipelines, give or take a few configurable items. Going this way would
have lead to a terrible duplication of code, transforming a job maintenance
nightmare into a code maintenance nightmare.

Pipeline as configuration

Our trick was to transform this vision of &quot;pipeline as code&quot; into a &quot;pipeline
as configuration&quot;:

by maintaining well documented and tested &quot;pipeline libraries&quot;

by asking projects to describe their pipeline not as code, but as property
files which would:

define the name and version of the DSL pipeline library to use

use the rest of the property file to configure the pipeline library, using
as many sensible default values as possible

Piloting the pipeline from the SCM

Once this was done, the only remaining trick was to automate the creation,
update, start and deletion of the pipelines using SCM events. By enabling SCM
hooks (in GitHub, BitBucket or even in Subversion), we could:

automatically create a pipeline for a new branch

regenerate a pipeline when the branch’s pipeline description was modified

start the pipeline on any other commit on the branch

remove the pipeline when the branch was deleted

Once a project wants to go in our ecosystem, the Jenkins team &quot;seeds&quot; the
project into Jenkins, by running a job and giving a few parameters.

It will create a folder for the project and grant proper authorisations, using
Active Directory group names based on the project name.

The hook for the project must be registered into the SCM and you’re up and
running.

Configuration and code

Mixing the use of strong pipeline libraries configured by properties and the
direct use of the Jenkins Job DSL is still possible. The Seed plugin
supports all kinds of combinations:

use of pipeline libraries only - this can even be enforced

use a DSL script which can in turn use some classes and methods defined in
a pipeline library

use of a Job DSL script only

Usually, we tried to have a maximum reuse, through only pipeline libraries, for
most of our projects, but in other circumstances, we were less strict and
allowed some teams to develop their own pipeline script.

End of the journey

In the end, what did we achieve?

Self service ✔︎

Pipeline automation from SCM - no intervention from the Jenkins team but for
the initial bootstrapping

Getting a project on board of this system can be done in a few minutes only

Security ✔︎

Project level authorisations

No code execution on the controller

Simplicity ✔︎

Property files

Extensibility ✔︎

Pipeline libraries

Direct job DSL still possible

Seed and Pipeline plugin

Now, what about the Pipeline plugin? Both
this plugin and the Seed plugin have common functionalities:

What we have found in our journey is that having a &quot;pipeline as configuration&quot;
was the easiest and most secure way to get a lot of projects on board, with
developers not knowing Jenkins and even less the DSL.

The outcome of the two plugins is different:

one pipeline job for the Pipeline plugin

a list of orchestrated jobs for the Seed plugin

If time allows, it would be probably a good idea to find a way to integrate the
functionalities of the Seed plugin into the pipeline framework, and to keep
what makes the strength of the Seed plugin:

pipeline as configuration

reuseable pipeline libraries, versioned and tested

Links

You can find additional information about the Seed plugin and its usage at the
following links:

the Seed plugin itself

JUC London, June 2015

BruJUG Brussels, March 2016<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/dcoraboeuf/">Damien Coraboeuf</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/dsl">dsl</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/16/parallel-test-executor-plugin/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">16</div></div><h5 class="title">Faster Pipelines with the Parallel Test Executor Plugin</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

In this blog post, I’ll show you how to speed up your pipeline by using the
Parallel Test Executor Plugin.

So much to do, so little time…​

In my career, I’ve helped many teams move to continuous integration and delivery. One problem
we always encounter is how to run all the tests needed to ensure high-quality
changes while still keeping pipeline times reasonable and changes flowing
smoothly. More tests mean greater confidence, but also longer wait times.
Build systems may or may not support running tests in parallel, but they still only use one
machine even while other lab machines sit idle. In these cases, parallelizing
test execution across multiple machines is a great way to speed up pipelines.
The Parallel Test Executor plugin lets us leverage Jenkins do just that with no
disruption to the rest of the build system.

Serial Test Execution

For this post, I’ll be running a pipeline based on the
Jenkins Git Plugin. I’ve modified
the Jenkinsfile from that project to allow us to compare execution times to our
later changes, and I’ve truncated the &quot;mvn&quot; utility method since it remains
unchanged.  You can find the original file
here.

node {
  stage &#x27;Checkout&#x27;
  checkout scm

  stage &#x27;Build&#x27;

  /* Call the Maven build without tests. */
  mvn &quot;clean install -DskipTests&quot;

  stage &#x27;Test&#x27;
  runTests()

  /* Save Results. */
  stage &#x27;Results&#x27;

  /* Archive the build artifacts */
  archive includes: &#x27;target/*.hpi,target/*.jpi&#x27;
}

void runTests(def args) {
  /* Call the Maven build with tests. */
  mvn &quot;install -Dmaven.test.failure.ignore=true&quot;

  /* Archive the test results */
  junit &#x27;**/target/surefire-reports/TEST-*.xml&#x27;
}

/* Run Maven */
void mvn(def args) { /* ... */ }

This pipeline expects to be run from a Jenkinsfile in SCM.
To copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with
git &#x27;https://github.com/jenkinsci/git-plugin.git&#x27;.

This is a Maven project, so the Jenkinsfile is pretty simple.
I’ve split the Maven build into separate “Build” and “Test”
stages. Maven doesn’t support this split very well, it wants to run all
the steps of the lifecycle in order every time. So, I have to call Maven twice:
first using the “skipTests” property to do only build steps in the first call,
and then a second time with out that property to run tests.

On my quad-core machine, executing this pipeline takes about 13 minutes and 30
seconds.  Of that time, it takes 13 minutes to run about 2.7 thousand tests in
serial.

Parallel Test Execution

This looks like an ideal project for parallel test execution: a short build
followed by a large number of serially executed tests that consume the most of
the pipeline time. There are a number of things I could try to speed this up.
For example, I could modify test harness to look for ways to parallelize
the test execution on this single machine. Or I could try speed up the tests
themselves. Both of those can be time-consuming and both risk destabilizing the
tests. I’d need to know more about the project to do it well.

I’ll avoid that risk by using Jenkins and the
Parallel Test Executor Plugin to
parallelize the tests across multiple nodes instead. This will isolate the tests
from each other, while still giving us speed gains from parallel execution.

The plugin reads the list of tests from the results archived in the previous execution of this
job and splits that list into a specified number of sublists. I can then use
those sublists to execute the tests in parallel, passing a different sublist to
each node.

Let’s look at how this changes the pipeline:

node { /* ...unchanged... */ }

void runTests(def args) {
  /* Request the test groupings.  Based on previous test results. */
  /* see https://wiki.jenkins.io/display/JENKINS/Parallel+Test+Executor+Plugin and demo on github
  /* Using arbitrary parallelism of 4 and &quot;generateInclusions&quot; feature added in v1.8. */
  def splits = splitTests parallelism: [$class: &#x27;CountDrivenParallelism&#x27;, size: 4], generateInclusions: true

  /* Create dictionary to hold set of parallel test executions. */
  def testGroups = [:]

  for (int i = 0; i }. */
    /*     includes = whether list specifies tests to include (true) or tests to exclude (false). */
    /*     list = list of tests for inclusion or exclusion. */
    /* The list of inclusions is constructed based on results gathered from */
    /* the previous successfully completed job. One additional record will exclude */
    /* all known tests to run any tests not seen during the previous run.  */
    testGroups[&quot;split-${i}&quot;] = {  // example, &quot;split3&quot;
      node {
        checkout scm

        /* Clean each test node to start. */
        mvn &#x27;clean&#x27;

        def mavenInstall = &#x27;install -DMaven.test.failure.ignore=true&#x27;

        /* Write includesFile or excludesFile for tests.  Split record provided by splitTests. */
        /* Tell Maven to read the appropriate file. */
        if (split.includes) {
          writeFile file: &quot;target/parallel-test-includes-${i}.txt&quot;, text: split.list.join(&quot;\n&quot;)
          mavenInstall += &quot; -Dsurefire.includesFile=target/parallel-test-includes-${i}.txt&quot;
        } else {
          writeFile file: &quot;target/parallel-test-excludes-${i}.txt&quot;, text: split.list.join(&quot;\n&quot;)
          mavenInstall += &quot; -Dsurefire.excludesFile=target/parallel-test-excludes-${i}.txt&quot;
        }

        /* Call the Maven build with tests. */
        mvn mavenInstall

        /* Archive the test results */
        junit &#x27;**/target/surefire-reports/TEST-*.xml&#x27;
      }
    }
  }
  parallel testGroups
}

/* Run Maven */
void mvn(def args) { /* ... */ }

That’s it!  The change is significant but it is all encapsulated in this one
method in the Jenkinsfile.

Great (ish) Success!

Here’s the results for the new pipeline with parallel test execution:

The tests ran almost twice as fast, without changes outside pipeline.  Great!

However, I used 4 test executors, so why am I not seeing a 4x? improvement.
A quick review of the logs shows the problem: A small number of tests are taking up
to 5 minutes each to complete! This is actually good news. It means that I
should be able to see further improvement in pipeline throughput just by refactoring
those few long running tests into smaller parts.

Conclusion

While I would like to have seen closer to a 4x improvement to match to number
of executors, 2x is still perfectly respectable. If I were working on a group of projects
with similar pipelines, I’d be completely comfortable reusing these same changes
on my other project and I’d expect to similar improvement without any disruption to
other tools or processes.

Links

https://wiki.jenkins.io/display/JENKINS/Parallel+Test+Executor+Plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/21/gsoc-midterm-presentations-ann/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">21</div></div><h5 class="title">GSoC: Mid-term presentations by students on June 23 and 24</h5></div><p class="teaser">As you probably know, on this year Jenkins projects participates in
Google Summer of Code 2016.
You can find more information about the accepted projects on the GSoC subproject page and in the
Jenkins Developer mailing list.

On this week GSoC students are going to present their projects as a part of mid-term evaluation,
which covers one month of community bonding and one month of coding.

We would like to invite Jenkins developers to attend these meetings.
There are two additional months of coding ahead for successful students, so any feedback from Jenkins contributors and users will be appreciated.

Meeting #1 - June 23, 7:00 PM UTC - 9:00 PM UTC

Support Core plugin improvements by Minudika Malshan

Intro blogpost

External Workspace Manager by Alex Somai

Intro blogpost

Plugin documentation publishing to jenkins.io by Cynthia Anyango

Intro blogpost

Q&amp;A session

Meeting link

Meeting #2 - June 24, 8AM UTC - 9 AM UTC

Jenkins WebUI: Improving Job Creation/Configuration by Samat Davletshin

Intro blogpost

Q&amp;A session

Meeting link

Both meetings will be conducted and recorded via Hangouts on Air.
The recorded sessions will be made public after the meetup.
The agenda may change a bit.

Links

Mid-term presentations announcement on Jenkins Developer mailing list

Jenkins GSoC 2016 Wiki Page

Jenkins project page on the GSoC2016 website<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/29/from-freestyle-to-pipeline/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">29</div></div><h5 class="title">Migrating from chained Freestyle jobs to Pipelines</h5></div><p class="teaser">This is a guest post by R. Tyler Croy, who is a
long-time contributor to Jenkins and the primary contact for Jenkins project
infrastructure. He is also a Jenkins Evangelist at
CloudBees, Inc.

For ages I have used the &quot;Build After&quot; feature in Jenkins to cobble together
what one might refer to as a &quot;pipeline&quot; of sorts. The Jenkins project itself, a
major consumer of Jenkins, has used these daisy-chained Freestyle jobs to drive
a myriad of delivery pipelines in our infrastructure.

One such &quot;pipeline&quot; helped drive the complex process of generating the pretty
blue charts on
stats.jenkins.io.
This statistics generation process primarily performs two major tasks, on rather
large sets of data:

Generate aggregate monthly &quot;census data.&quot;

Process the census data and create trend charts

The chained jobs allowed us to resume the independent stages of the pipeline,
and allowed us to run different stages on different hardware (different
capabilities) as needed. Below is a diagram of what this looked like:

The infra_generate_monthly_json would run periodically creating the
aggregated census data, which would then be picked up by infra_census_push
whose sole responsibility was to take census data and publish it to the
necessary hosts inside the project’s infrastructure.

The second, semi-independent, &quot;pipeline&quot; would also run periodically. The
infra_statistics job’s responsibility was to use the census data, pushed
earlier by infra_census_push, to generate the myriad of pretty blue charts
before triggering the
infra_checkout_stats job which would make sure stats.jenkins.io was
properly updated.

Suffice it to say, this &quot;pipeline&quot; had grown organically over a period time when
more advanced tools weren’t quite available.

When we migrated to newer infrastructure for
ci.jenkins.io earlier this year I took the
opportunity to do some cleaning up. Instead of migrating jobs verbatim, I pruned
stale jobs and refactored a number of others into proper
Pipelines, statistics generation being an obvious
target!

Our requirements for statistics generation, in their most basic form, are:

Enable a sequence of dependent tasks to be executed as a logical group (a
pipeline)

Enable executing those dependent tasks on various pieces of infrastructure
which support different requirements

Actually generate those pretty blue charts

If you wish to skip ahead, you can jump straight to the
Jenkinsfile
which implements our new Pipeline.

The first iteration of the Jenkinsfile simply defined the conceptual stages we
would need:

node {
    stage &#x27;Sync raw data and census files&#x27;

    stage &#x27;Process raw logs&#x27;

    stage &#x27;Generate census data&#x27;

    stage &#x27;Generate stats&#x27;

    stage &#x27;Publish census&#x27;

    stage &#x27;Publish stats&#x27;
}

How exciting! Although not terrifically useful. When I began actually
implementing the first couple stages, I noticed that the Pipeline might sync
dozens of gigabytes of data every time it ran on a new agent in the cluster.
While this problem will soon be solved by the
External
Workspace Manager plugin, which is currently being developed. Until it’s ready,
I chose to mitigate the issue by pinning the execution to a consistent agent.

/* `census` is a node label for a single machine, ideally, which will be
 * consistently used for processing usage statistics and generating census data
 */
node(&#x27;census &amp;&amp; docker&#x27;) {
    /* .. */
}

Restricting a workload which previously used multiple agents to a single one
introduced the next challenge. As an infrastructure administrator, technically
speaking, I could just install all the system dependencies that I want on this
one special Jenkins agent. But what kind of example would that be setting!

The statistics generation process requires:

JDK8

Groovy

A running MongoDB instance

Fortunately, with Pipeline we have a couple of useful features at our disposal:
tool auto-installers and the
CloudBees
Docker Pipeline plugin.

Tool Auto-Installers

Tool Auto-Installers are exposed in Pipeline through the tool step and on
ci.jenkins.io we already had JDK8 and Groovy
available. This meant that the Jenkinsfile would invoke tool and Pipeline
would automatically install the desired tool on the agent executing the current
Pipeline steps.

The tool step does not modify the PATH environment variable, so it’s usually
used in conjunction with the withEnv step, for example:

node(&#x27;census &amp;&amp; docker&#x27;) {
    /* .. */

    def javaHome = tool(name: &#x27;jdk8&#x27;)
    def groovyHome = tool(name: &#x27;groovy&#x27;)

    /* Set up environment variables for re-using our auto-installed tools */
    def customEnv = [
        &quot;PATH+JDK=${javaHome}/bin&quot;,
        &quot;PATH+GROOVY=${groovyHome}/bin&quot;,
        &quot;JAVA_HOME=${javaHome}&quot;,
    ]

    /* use our auto-installed tools */
    withEnv(customEnv) {
        sh &#x27;java --version&#x27;
    }

    /* .. */
}

CloudBees Docker Pipeline plugin

Satisfying the MongoDB dependency would still be tricky. If I caved in and installed
MongoDB on a single unicorn agent in the cluster, what could I say the next time
somebody asked for a special, one-off, piece of software installed on our
Jenkins build agents?

After doing my usual complaining and whining, I discovered that the CloudBees
Docker Pipeline plugin provides the ability to run containers inside of a
Jenkinsfile. To make things even better, there are
official MongoDB docker images readily
available on DockerHub!

This feature requires that the machine has a running Docker daemon which is
accessible to the user running the Jenkins agent. After that, running a
container in the background is easy, for example:

node(&#x27;census &amp;&amp; docker&#x27;) {
    /* .. */

    /* Run MongoDB in the background, mapping its port 27017 to our host&#x27;s port
     * 27017 so our script can talk to it, then execute our Groovy script with
     * tools from our `customEnv`
     */
    docker.image(&#x27;mongo:2&#x27;).withRun(&#x27;-p 27017:27017&#x27;) { container -&gt;
        withEnv(customEnv) {
            sh &quot;groovy parseUsage.groovy --logs ${usagestats_dir} --output ${census_dir} --incremental&quot;
        }
    }

    /* .. */
}

The beauty, to me, of this example is that you can pass a
closure to withRun which will
execute while the container is running. When the closure is finished executin,
just the sh step in this case, the container is destroyed.

With that system requirement satisfied, the rest of the stages of the Pipeline
fell into place. We now have a single source of truth, the
Jenkinsfile,
for the sequence of dependent tasks which need to be executed, accounting for
variations in systems requirements, and it actually generates
those pretty
blue charts!

Of course, a nice added bonus is the beautiful visualization of our
new Pipeline!

Links

Pipeline documentation

CloudBees Docker Pipeline plugin documentation

Live statistics Pipeline<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infra">infra</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/06/30/ewm-alpha-version/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">30</div></div><h5 class="title">GSoC: External Workspace Manager Plugin alpha version</h5></div><p class="teaser">Currently it’s quite difficult to share and reuse the same workspace between multiple jobs and across nodes.
There are some possible workarounds for achieving this, but each of them has its own drawback,
e.g. stash/unstash pre-made artifacts, Copy Artifacts plugin or advanced job settings.
A viable solution for this problem is the External Workspace Manager plugin, which facilitates workspace share and
reuse across multiple Jenkins jobs and nodes.
It also eliminates the need to copy, archive or move files.
You can learn more about the design and goals of the External Workspace Manager project in
this introductory blog post.

I’d like to announce that an alpha version of the External Manager Plugin has been released!
It’s now public available for testing.
To be able to install this plugin, you must follow the steps from the Experimental Plugins Update Center
blog post.

Please be aware that it’s not recommended to use the Experimental Update Center in production installations of
Jenkins, since it may break it.

The plugin’s wiki page may be accessed
here.
The documentation that helps you get started with this plugin may be found on the
README page.
To get an idea of what this plugin does, which are the features implemented so far and to see a working demo of it,
you can watch my mid-term presentation that is available here.
The slides for the presentation are shared on
Google Slides.

My mentors, Martin and Oleg,
and I have set up public meetings related to this plugin.
You are invited to join our discussions if you’d like to get more insight about the project.
The meetings are taking place twice a week on the Jenkins hangout,
every Monday at
12 PM UTC
and every Thursday at
5 PM UTC.

If you have any issues in setting up or using the plugin, please feel free to ask me on the plugin’s Gitter
chat.
The plugin is open-source, having the repository on
GitHub, and you may contribute to it.
Any feedback is welcome, and you may provide it either on the Gitter chat, or on
Jira by using the external-workspace-manager-plugin component.

Links

Project repository

Plugin wiki page

Mid-term presentation

Project intro blog post

GSoC page

Jenkins GSoC Page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alexsomai/">Alexandru Somai</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/external-workspace-manager">external-workspace-manager</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/07/01/html-publisher-plugin/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 1</div></div><h5 class="title">Publishing HTML Reports in Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Most projects need more that just JUnit result reporting.  Rather than writing a
custom plugin for each type of report, we can use the
HTML Publisher Plugin.

Let’s Make This Quick

I’ve found a Ruby project,
hermann, I’d like to build using Jenkins Pipeline. I’d
also like to have the code coverage results published with each build job.  I could
write a plugin to publish this data, but I’m in a bit of hurry and
the build already creates an HTML report file using SimpleCov
when the unit tests run.

Simple Build

I’m going to use the
HTML Publisher Plugin
to add the HTML-formatted code coverage report to my builds.  Here’s a simple
pipeline for building the hermann
project.

stage &#x27;Build&#x27;

node {
  // Checkout
  checkout scm

  // install required bundles
  sh &#x27;bundle install&#x27;

  // build and run tests with coverage
  sh &#x27;bundle exec rake build spec&#x27;

  // Archive the built artifacts
  archive (includes: &#x27;pkg/*.gem&#x27;)
}

This pipeline expects to be run from a Jenkinsfile in SCM.
To copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with
git &#x27;https://github.com/reiseburo/hermann.git&#x27;.

Simple enough, it builds, runs tests, and archives the package.

Now I just need to add the step to publish the code coverage report.
I know that rake spec creates an index.html file in the coverage directory.
I’ve already installed the
HTML Publisher Plugin.
How do I add the HTML publishing step to the pipeline?  The plugin page doesn’t
say anything about it.

Snippet Generator to the Rescue

Documentation is hard to maintain and easy to miss, even more so in a system
like Jenkins with hundreds of plugins the each potential have one or more
groovy fixtures to add to the Pipeline.  The Pipeline Syntax&quot;Snippet Generator&quot; helps users
navigate this jungle by providing a way to generate a code snippet for any step using
provided inputs.

It offers a dynamically generated list of steps, based on the installed plugins.
From that list I select the publishHTML step:

Then it shows me a UI similar to the one used in job configuration.  I fill in
the fields, click &quot;generate&quot;, and it shows me snippet of groovy generated from
that input.

HTML Published

I can use that snippet directly or as a template for further customization.
In this case, I’ll just reformat and copy it in at the end of my
pipeline.  (I ran into a minor bug
in the snippet generated for this plugin step. Typing
error string in my search bar immediately found the bug and a workaround.)

/* ...unchanged... */

  // Archive the built artifacts
  archive (includes: &#x27;pkg/*.gem&#x27;)

  // publish html
  // snippet generator doesn&#x27;t include &quot;target:&quot;
  // https://issues.jenkins.io/browse/JENKINS-29711.
  publishHTML (target: [
      allowMissing: false,
      alwaysLinkToLastBuild: false,
      keepAll: true,
      reportDir: &#x27;coverage&#x27;,
      reportFiles: &#x27;index.html&#x27;,
      reportName: &quot;RCov Report&quot;
    ])

}

When I run this new pipeline I am rewarded with an RCov Report link on left side,
which I can follow to show the HTML report.

I even added the keepAll setting to let I can also go back an look at reports on old jobs as
more come in.  As I said to to begin with, this is not as slick as what I
could do with a custom plugin, but it is much easier and works with any static
HTML.

Links

HTML Publisher Plugin

Jenkins Pipeline Snippet Generator<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/07/07/jenkins-2.7.1/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 7</div></div><h5 class="title">Jenkins 2 hits LTS</h5></div><p class="teaser">It’s been almost three months since we’ve released Jenkins 2.0, the first ever major version upgrade for this 10 year old project. The 2.x versions since then has been adopted by more than 20% of the users, but one segment of users who haven’t seen the benefits of Jenkins 2 is those who has been running LTS releases.

But that is no more! The new version of Jenkins LTS release we just released is 2.7.1, and now LTS users get to finally enjoy Jenkins 2.

This release also officially marks the end-of-life for Jenkins 1.x. There won’t be any future release of Jenkins 1.x beyond this point. If you are worried about the upgrade, don’t be! The core of Jenkins is still the same, and all the plugins &amp; existing configuration will just work.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/07/14/2-7-1-re-release/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">14</div></div><h5 class="title">New packages for Jenkins 2.7.1</h5></div><p class="teaser">We created new native packages for Jenkins 2.7.1 today. These replace the existing packages. Due to a release process issue, the packaging (RPM, etc.) was created the same way as Jenkins 1.x LTS, resulting in problems starting Jenkins on some platforms: While we dropped support for AJP in Jenkins 2.0, some 1.x packages had it enabled by default, resulting in an exception during startup.

These new packages for Jenkins 2.7.1, dated July 14, have the same scripts and parameters as Jenkins 2.x and should allow starting up Jenkins without problems. If you notice any further problems with the packaging, please report them in the packaging component.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/07/18/pipeline-notifications/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">18</div></div><h5 class="title">Sending Notifications in Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Rather than sitting and watching Jenkins for job status, I want Jenkins to send
notifications when events occur.  There are Jenkins plugins for
Slack,
HipChat,
or even email
among others.

Note: Something is happening!

I think we can all agree getting notified when events occur is preferable to
having to constantly monitor them just in case.  I’m going to continue from
where I left off in my
previous post with the
hermann project.  I added a Jenkins
Pipeline with an HTML publisher for code coverage. This week, I’d like to make
Jenkins to notify me when builds start and when they succeed or fail.

Setup and Configuration

First, I select targets for my notifications. For this blog post, I’ll use sample
targets that I control.  I’ve created Slack and HipChat organizations called
&quot;bitwiseman&quot;, each with one member - me.  And for email I’m running a Ruby SMTP server called
mailcatcher, that is perfect for local testing
such as this.  Aside for these concessions, configuration would be much the
same in a non-demo situation.

Next, I install and add server-wide configuration for the
Slack,
HipChat,
and Email-ext
plugins.  Slack and HipChat use API tokens - both products have integration
points on their side that generate tokens which I copy into my Jenkins
configuration. Mailcatcher SMTP runs locally. I just point Jenkins
at it.

Here’s what the Jenkins configuration section for each of these looks like:

Original Pipeline

Now I can start adding notification steps. The same as
last week, I’ll use the
Jenkins Pipeline Snippet Generator
to explore the step syntax for the notification plugins.

Here’s the base pipeline before I start making changes:

stage &#x27;Build&#x27;

node {
  // Checkout
  checkout scm

  // install required bundles
  sh &#x27;bundle install&#x27;

  // build and run tests with coverage
  sh &#x27;bundle exec rake build spec&#x27;

  // Archive the built artifacts
  archive (includes: &#x27;pkg/*.gem&#x27;)

  // publish html
  // snippet generator doesn&#x27;t include &quot;target:&quot;
  // https://issues.jenkins.io/browse/JENKINS-29711.
  publishHTML (target: [
      allowMissing: false,
      alwaysLinkToLastBuild: false,
      keepAll: true,
      reportDir: &#x27;coverage&#x27;,
      reportFiles: &#x27;index.html&#x27;,
      reportName: &quot;RCov Report&quot;
    ])
}

This pipeline expects to be run from a Jenkinsfile in SCM.
To copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with
git &#x27;https://github.com/reiseburo/hermann.git&#x27;.

Job Started Notification

For the first change, I decide to add a &quot;Job Started&quot; notification.  The
snippet generator and then reformatting makes this straightforward:

node {

  notifyStarted()

  /* ... existing build steps ... */
}

def notifyStarted() {
  // send to Slack
  slackSend (color: &#x27;#FFFF00&#x27;, message: &quot;STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;)

  // send to HipChat
  hipchatSend (color: &#x27;YELLOW&#x27;, notify: true,
      message: &quot;STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;
    )

  // send to email
  emailext (
      subject: &quot;STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;,
      body: &quot;&quot;&quot; STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;,
      recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
    )
}

Since Pipeline is a Groovy-based DSL, I can use
string interpolation
and variables to add exactly the details I want in my notification messages. When
I run this I get the following notifications:

Job Successful Notification

The next logical choice is to get notifications when a job succeeds.  I’ll
copy and paste based on the notifyStarted method for now and do some refactoring
later.

node {

  notifyStarted()

  /* ... existing build steps ... */

  notifySuccessful()
}

def notifyStarted() { /* .. */ }

def notifySuccessful() {
  slackSend (color: &#x27;#00FF00&#x27;, message: &quot;SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;)

  hipchatSend (color: &#x27;GREEN&#x27;, notify: true,
      message: &quot;SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;
    )

  emailext (
      subject: &quot;SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;,
      body: &quot;&quot;&quot; SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;,
      recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
    )
}

Again, I get notifications, as expected.  This build is fast enough,
some of them are even on the screen at the same time:

Job Failed Notification

Next I want to add failure notification.  Here’s where we really start to see the power
and expressiveness of Jenkins pipeline.  A Pipeline is a Groovy script, so as we’d
expect in any Groovy script, we can handle errors using try-catch blocks.

node {
  try {
    notifyStarted()

    /* ... existing build steps ... */

    notifySuccessful()
  } catch (e) {
    currentBuild.result = &quot;FAILED&quot;
    notifyFailed()
    throw e
  }
}

def notifyStarted() { /* .. */ }

def notifySuccessful() { /* .. */ }

def notifyFailed() {
  slackSend (color: &#x27;#FF0000&#x27;, message: &quot;FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;)

  hipchatSend (color: &#x27;RED&#x27;, notify: true,
      message: &quot;FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;
    )

  emailext (
      subject: &quot;FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;,
      body: &quot;&quot;&quot; FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;,
      recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
    )
}

Code Cleanup

Lastly, now that I have it all working, I’ll do some refactoring. I’ll unify
all the notifications in one method and move the final success/failure notification
into a finally block.

stage &#x27;Build&#x27;

node {
  try {
    notifyBuild(&#x27;STARTED&#x27;)

    /* ... existing build steps ... */

  } catch (e) {
    // If there was an exception thrown, the build failed
    currentBuild.result = &quot;FAILED&quot;
    throw e
  } finally {
    // Success or failure, always send notifications
    notifyBuild(currentBuild.result)
  }
}

def notifyBuild(String buildStatus = &#x27;STARTED&#x27;) {
  // build status of null means successful
  buildStatus = buildStatus ?: &#x27;SUCCESS&#x27;

  // Default values
  def colorName = &#x27;RED&#x27;
  def colorCode = &#x27;#FF0000&#x27;
  def subject = &quot;${buildStatus}: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;
  def summary = &quot;${subject} (${env.BUILD_URL})&quot;
  def details = &quot;&quot;&quot; STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;

  // Override default values based on build status
  if (buildStatus == &#x27;STARTED&#x27;) {
    color = &#x27;YELLOW&#x27;
    colorCode = &#x27;#FFFF00&#x27;
  } else if (buildStatus == &#x27;SUCCESS&#x27;) {
    color = &#x27;GREEN&#x27;
    colorCode = &#x27;#00FF00&#x27;
  } else {
    color = &#x27;RED&#x27;
    colorCode = &#x27;#FF0000&#x27;
  }

  // Send notifications
  slackSend (color: colorCode, message: summary)

  hipchatSend (color: color, notify: true, message: summary)

  emailext (
      subject: subject,
      body: details,
      recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
    )
}

You have been notified!

I now get notified twice per build on three different channels.  I’m not sure I
need to get notified this much for such a short build.  However, for a longer
or complex CD pipeline, I might want exactly that.  If needed, I could even
improve this to handle other status strings and call it as needed throughout
my pipeline.

Links

Slack Plugin

HipChat Plugin

Email-ext Plugin

Jenkins Pipeline Snippet Generator<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/notifications">notifications</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/slack">slack</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hipchat">hipchat</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/emailext">emailext</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/07/19/blue-ocean-update/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">19</div></div><h5 class="title">Blue Ocean July development update </h5></div><p class="teaser">The team have been hard at work moving the needle forward on the Blue
Ocean 1.0 features. Many of the features we have been working on have
come a long way in the past few months but here’s a few highlights:

Goodbye page refreshes, Hello Real Time updates!

Building upon
Tom &#x27;s great work on
Server Sent Events (SSE) both
Cliff and
Tom worked
on making the all the screens in Blue Ocean update without manual
refreshes.

SSE is a great technology
choice for new web apps as it only pushes out
events to the client when things have changed on the server. That means
there’s a lot less traffic going between your browser and the Jenkins
server when compared to the continuous AJAX polling method that has been
typical of Jenkins in the past.

New Test Reporting UI

Keith has
been working with Vivek to
drive out a new set of extension points that allow us to build a new
rest reporting UI in Blue Ocean. Today this works for JUnit test reports
but can be easily extended to work with other kinds of reports.

Pipeline logs are split into steps and update live

Thorsten and
Josh have
been hard at work breaking down the log into steps and making the live
log tailing follow the pipeline execution - which we’ve lovingly
nicknamed the “karaoke mode”

Pipelines can be triggered from the UI

Tom has
been on allowing users to trigger jobs from Blue Ocean, which is one
less reason to go back to the Classic UI :)

Blue Ocean has been released to the experimental update center

Many of you have asked us questions about how you can try Blue Ocean
today and have resorted to building the plugin yourself or running our
Docker image.

We wanted to make the process of trying Blue Ocean in its unfinished
state by publishing the plugin to the experimental update center - it’s
available today!

So what is the Experimental Update Center? It is a mechanism for the
Jenkins developer community to share early previews of new plugins with
the broader user community. Plugins in this update center are
experimental and we strongly advise not running them on production or
Jenkins systems that you rely on for your work.

That means any plugin in this update center could eat your Jenkins data,
cause slowdowns, degrade security or have their behavior change at no
notice.

You can learn how to
activate
the experimental update center on this post.

Stay tuned for more updates!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/i386/">James Dumay</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/07/26/join-me-at-jenkinsworld/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">26</div></div><h5 class="title">Join me for Jenkins World 2016</h5></div><p class="teaser">Jenkins World, September
13-15 at the Santa Clara Convention Center (SCCC), takes our 6th annual
community user conference to a whole new level. It will be one big party for
everything Jenkins, from users to developers, from the community to vendors.
There will be more of what people always loved in past user conferences, such
as technical sessions from users and developers, the Ask the Experts booth and
plugin development workshop, and even more has been added, such as Jenkins
training pre-conference, workshops and the opportunity to get certified for
free. Jenkins World is a not-to-be-missed.

For me, the best part of Jenkins World is the opportunity to meet other Jenkins
users and developers face-to-face. We all interact on IRC, Google Groups or
GitHub, but when you have a chance to meet in person, the person behind the
GitHub ID or IRC name, whose plugin you use every day, becomes a real person.
Your motivation might be a little different from mine, but we have the breath
in the agenda to cover everyone from new users to senior plugin developers.

This year, you’ll have more opportunities than ever before to learn about
Jenkins and continuous delivery/DevOps practices, and explore what Jenkins has
to offer.

If you are travelling from somewhere, you might as well get a two-day Jenkins training course to be held onsite, starting Monday.

On Tuesday, you can attend your choice of workshops, which gives you more hands-on time to go deeper, including:

The DevOps Toolkit 2.0 Workshop

Let’s Build a Jenkins Pipeline

Preparing for Jenkins Certification

Intro to Plugin Development

CD and DevOps Maturity for Managers

On Wednesday, the formal conference kicks off. Throughout Wednesday and
Thursday, you can choose from sessions spread across five tracks and covering
a diverse range of topics like infrastructure as code, security, containers,
pipeline automation, best practices, scaling Jenkins and new community
development initiatives.

At Jenkins World, you’ll be exposed to projects going on in the community such
as Blue Ocean, a new Jenkins UX project. You can
learn more about Jenkins 2 - a major release for the project, and based on the
huge number of downloads we saw in the weeks following its introduction at the
end of April, it was a big +1. At Jenkins World, you will be immersed in
Jenkins and community, and leave knowing that you are part of a meaningful open
source project that, with your involvement, can do anything!

This year there will only be one Jenkins World conference, so that everyone
involved in Jenkins can get together in one place at one time and actually see
each other. I understand that it might be a bit more difficult for Jenkins
users outside of the US to make it to Jenkins World, but hopefully we made the
event worth your visit. As the final push on the back, CloudBees has created a
special international program
for those who are coming from outside the United States.  You’ll have
time to talk with all of the other Jenkins users who have made the journey from
across the globe, you’ll be able to attend exclusive networking events and
more.

I hope to see you September 13th through 15th in Santa Clara at
Jenkins World in Santa Clara!

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/03/st-petersburg-jam-3-4-report/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 3</div></div><h5 class="title">St. Petersburg Jenkins Meetup #3 and #4 Reports</h5></div><p class="teaser">I would like to write about two last Jenkins Meetups in Saint Petersburg, Russia.

Meetup #3. Jenkins Administration (May 20, 2016)

In May we had a meetup about Jenkins administration techniques.
At this meetup we were talking about common Jenkins ecosystem components
like custom update centers, tool repositories and generic jobs.

Talks:

Kirill Merkushev, Yandex, &quot;Juseppe. A custom Update Center for Jenkins&quot;

Presentation (rus)

Keywords: Juseppe

Anna Muravieva, EMC, &quot;Generic jobs in Jenkins. How to build anything?&quot;

Presentation (rus)

Keywords: Generic Builds, Scripted Build Wrappers

Oleg Nenashev, CloudBees, &quot;Building Jenkins Tool infrastructures with help of Custom Tools Plugin and Docker&quot;

Presentation (rus)

Keywords: Custom Tools Plugin, Extra Tool Installers Plugin, Docker

Meetup #4. IT Global Meetup (July 23, 2016)

In Saint Petersburg there is a regular gathering of local IT communities.
This IT Global Meetup is a full-day event, which provides an opportunity to dozens of communities and hundreds of visitors to meet at a single place.

On July 23rd our local Jenkins community participated in the eight’s global meetup.
We conduced 2 talks in main tracks and also had a round table in the evening.

Talks:

Oleg Nenashev, CloudBees, &quot;About Jenkins 2 and future plans&quot;

Oleg provided a top-level overview about changes in Jenkins,
shared insights about upgrading to the new Jenkins 2.7.1 LTS and talked about Jenkins plans

Presentation (rus)

Aleksandr Tarasov, Alfa-Laboratory, &quot;Continuous Delivery with Jenkins: Lessons learned&quot;

Aleksandr summarized AlfaLab’s experience of Jenkins usage for Continuous Delivery in their environment.
He talked about the flow based on Jenkins Pipeline, JobDSL and BlueOcean prototype.

Presentation (rus)

After the talks we had a roundtable about Jenkins (~10 Jenkins experts).
Oleg provided an overview of Docker and Configuration-as-Code features available in Jenkins,
and then we talked about common use-cases in Jenkins installations.
We hope to finally organize a &quot;Jenkins &amp; Docker&quot; meetup at some point.

Q&amp;A

If you have any questions, all speakers can be contacted via
Jenkins RU Gitter Chat.

Links

St. Petersburg Meetup page (follow the events here)

St. Petersburg Meetup Twitter

Jenkins RU Twitter

Jenkins RU Gitter Chat

IT Global Meetup

Acknowledgments

The events have been organized with help from
CloudBees, EMC and
organizers of the St. Petersburg IT Global Meetup.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins_ru">jenkins_ru</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/08/docker-pipeline-environments/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 8</div></div><h5 class="title">Don&#x27;t install software, define your environment with Docker and Pipeline</h5></div><p class="teaser">This is a guest post by Michael Neale, long time open
source developer and contributor to the Blue Ocean
project.

If you are running parts of your pipeline on Linux, possibly the easiest way to
get a clean reusable environment is to use:
CloudBees
Docker Pipeline plugin.

In this short post I wanted to show how you can avoid installing stuff on the agents, and have per project, or even per branch, customized build environments.
Your environment, as well as your pipeline is defined and versioned alongside your code.

I wanted to use the Blue Ocean project as an
example of a
project that uses the CloudBees Docker Pipeline plugin.

Environment and Pipeline for JavaScript components

The Blue Ocean project has a few moving parts, one of
which is called the &quot;Jenkins Design Language&quot;.  This is a grab bag of re-usable
CSS, HTML, style rules, icons and JavaScript components (using React.js) that
provide the look and feel for Blue Ocean.

JavaScript and Web Development being what it is in 2016, many utilities are
need to assemble a web app.  This includes npm and all that it needs, less.js
to convert Less to CSS, Babel to &quot;transpile&quot; versions of JavaScript to other
types of JavaScript (don’t ask) and more.

We could spend time installling nodejs/npm on the agents, but why not just use
the official off the shelf docker image
from Docker Hub?

The only thing that has to be installed and run on the build agents is the Jenkins agent, and a docker daemon.

A simple pipeline using this approach would be:

node {
        stage &quot;Prepare environment&quot;
          checkout scm
          docker.image(&#x27;node&#x27;).inside {
            stage &quot;Checkout and build deps&quot;
                sh &quot;npm install&quot;

            stage &quot;Test and validate&quot;
                sh &quot;npm install gulp-cli &amp;&amp; ./node_modules/.bin/gulp&quot;
          }
}

This uses the stock &quot;official&quot; Node.js image from the Docker Hub, but doesn’t let us customize much about the environment.

Customising the environment, without installing bits on the agent

Being the forward looking and lazy person that I am, I didn’t want to have to
go and fish around for a Docker image every time a developer wanted something
special installed.

Instead, I put a Dockerfile in the root of the repo, alongside the Jenkinsfile :

The contents of the Dockerfile can then define the exact environment needed
to build the project.  Sure enough, shortly after this, someone came along
saying they wanted to use Flow from Facebook (A
typechecker for JavaScript).  This required an additional native component to
work (via apt-get install).

This was achieved via a
pull
request to both the Jenkinsfile and the Dockerfile at the same time.

So now our environment is defined by a Dockerfile with the following contents:

# Lets not just use any old version but pick one
FROM node:5.11.1

# This is needed for flow, and the weirdos that built it in ocaml:
RUN apt-get update &amp;&amp; apt-get install -y libelf1

RUN useradd jenkins --shell /bin/bash --create-home
USER jenkins

The Jenkinsfile pipeline now has the following contents:

node {
    stage &quot;Prepare environment&quot;
        checkout scm
        def environment  = docker.build &#x27;cloudbees-node&#x27;

        environment.inside {
            stage &quot;Checkout and build deps&quot;
                sh &quot;npm install&quot;

            stage &quot;Validate types&quot;
                sh &quot;./node_modules/.bin/flow&quot;

            stage &quot;Test and validate&quot;
                sh &quot;npm install gulp-cli &amp;&amp; ./node_modules/.bin/gulp&quot;
                junit &#x27;reports/**/*.xml&#x27;
        }

    stage &quot;Cleanup&quot;
        deleteDir()
}

Even hip JavaScript tools can emit that weird XML format that test
reporters can use, e.g. the junit result archiver.

The main change is that we have docker.build being called to produce the
environment which is then used.  Running docker build is essentially a
&quot;no-op&quot; if the image has already been built on the agent before.

What’s it like to drive?

Well, using Blue Ocean, to build Blue Ocean, yields a pipeline that visually
looks like this (a recent run I screen capped):

This creates a pipeline that developers can tweak on a pull-request basis,
along with any changes to the environment needed to support it, without having
to install any packages on the agent.

Why not use docker commands directly?

You could of course just use shell commands to do things with Docker directly,
however, Jenkins Pipeline keeps track of Docker images used in a Dockerfile
via the &quot;Docker Fingerprints&quot; link (which is good, should that image need to
change due to a security patch).

Links

The project used as as an example is here

The pipeline is defined by the Jenkinsfile

The environment is defined by the Dockerfile

Read more on Docker Pipeline<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javascript">javascript</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/nodejs">nodejs</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/09/ewm-beta-version/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 9</div></div><h5 class="title">GSoC: External Workspace Manager for Pipeline. Beta release is available</h5></div><p class="teaser">This blog post is a continuation of the External Workspace Manager Plugin related posts, starting with
the introductory blog post, and followed by
the alpha version release announcement.

As the title suggests, the beta version of the External Workspace Manager Plugin was launched!
This means that it’s available only in the
Experimental Plugins Update Center.

Take care when installing plugins from the Experimental Update Center, since they may change in
backward-incompatible ways.
It’s advisable not to use it for Jenkins production environments.

The plugin’s repository is on GitHub.
The complete plugin’s documentation can be accessed
here.

What’s new

Bellow is a summary of the features added so far, since the alpha version.

Multiple upstream run selection strategies

It has support for the
Run Selector Plugin (which is still in beta),
so you can provide different run selection strategies when allocating a disk from the upstream job.

Let’s suppose that we have an upstream job that clones the repository and builds the project:

def extWorkspace = exwsAllocate &#x27;diskpool1&#x27;

node (&#x27;linux&#x27;) {
    exws (extWorkspace) {
        checkout scm
        sh &#x27;mvn clean install -DskipTests&#x27;
    }
}

In the downstream job, we run the tests on a different node, but we reuse the same workspace as the previous job:

def run = selectRun &#x27;upstream&#x27;
def extWorkspace = exwsAllocate selectedRun: run

node (&#x27;test&#x27;) {
    exws (extWorkspace) {
        sh &#x27;mvn test&#x27;
    }
}

The selectRun in this example selects the last stable build from the upstream job.
But, we can be more explicit, and select a specific build number from the upstream job.

def run = selectRun &#x27;upstream&#x27;,
 selector: [$class: &#x27;SpecificRunSelector&#x27;, buildNumber: UPSTREAM_BUILD_NUMBER]
def extWorkspace = exwsAllocate selectedRun: run
// ...

When the selectedRun parameter is given to the exwsAllocate step, it will allocate the same workspace that was
used by that run.

The Run Selector Plugin has several run selection strategies that are briefly explained
here.

Automatic workspace cleanup

Provides an automatic workspace cleanup by integrating the
Workspace Cleanup Plugin.
For example, if we need to delete the workspace only if the build has failed, we can do the following:

def extWorkspace = exwsAllocate diskPoolId: &#x27;diskpool1&#x27;

node (&#x27;linux&#x27;) {
    exws (extWorkspace) {
        try {
            checkout scm
            sh &#x27;mvn clean install&#x27;
        } catch (e) {
            currentBuild.result = &#x27;FAILURE&#x27;
            throw e
        } finally {
            step ([$class: &#x27;WsCleanup&#x27;, cleanWhenFailure: false])
        }
    }
}

More workspace cleanup examples can be found at this
link.

Custom workspace path

Allows the user to specify a custom workspace path to be used when allocating workspace on the disk.
The plugin offers two alternatives for doing this:

by defining a global workspace template for each Disk Pool

This can be defined in the Jenkins global config, External Workspace Definitions section.

by defining a custom workspace path in the Pipeline script

We can use the Pipeline DSL to compute the workspace path.
Then we pass this path as input parameter to the exwsAllocate step.

def customPath = &quot;${env.JOB_NAME}/${PULL_REQUEST_NUMBER}/${env.BUILD_NUMBER}&quot;
def extWorkspace = exwsAllocate diskPoolId: &#x27;diskpool1&#x27;, path: customPath
// ...

For more details see the afferent
documentation page.

Disk Pool restrictions

The plugin comes with Disk Pool restriction strategies.
It does this by using the restriction capabilities provided by the
Job Restrictions Plugin.

For example, we can restrict a Disk Pool to be allocated only if the Jenkins job in which it’s allocated was triggered
by a specific user:

Or, we can restrict the Disk Pool to be allocated only for those jobs whose name matches a well defined pattern:

What’s next

Currently there is ongoing work for providing flexible disk allocation strategies.
The user will be able to define a default disk allocation strategy in the Jenkins global config.
So for example, we want to select the disk with the most usable space as default allocation strategy:

If needed, this allocation strategy may be overridden in the Pipeline code.
Let’s suppose that for a specific job, we want to allocate the disk with the highest read speed.

def extWorkspace = exwsAllocate diskPoolId: &#x27;diskpool1&#x27;, strategy: fastestRead()
// ...

When this feature is completed, the plugin will enter a final testing phase.
If all goes to plan, a stable version should be released in about two weeks.

If you have any issues in setting up or using the plugin, please feel free to ask me on the plugin’s Gitter
chat.
Any feedback is welcome, and you may provide it either on the Gitter chat, or on
Jira by using the external-workspace-manager-plugin component.

Links

Project repository

Project intro blog post

Alpha version announcement

GSoC page

Jenkins GSoC Page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alexsomai/">Alexandru Somai</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/external-workspace-manager">external-workspace-manager</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/10/rails-cd-with-pipeline/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">10</div></div><h5 class="title">Continuous Security for Rails apps with Pipeline and Brakeman</h5></div><p class="teaser">This is a guest post by R. Tyler Croy, who is a
long-time contributor to Jenkins and the primary contact for Jenkins project
infrastructure. He is also a Jenkins Evangelist at
CloudBees, Inc.

When the Ruby on Rails framework debuted it
changed the industry in two noteworthy ways: it created a trend of opinionated web
application frameworks ( Django,
Play, Grails) and it
also strongly encouraged thousands of developers to embrace test-driven
development along with many other modern best practices (source control, dependency
management, etc). Because Ruby, the language underneath Rails, is interpreted
instead of compiled there isn’t a &quot;build&quot; per se but rather tens, if not
hundreds, of tests, linters and scans which are run to ensure the application’s
quality. With the rise in popularity of Rails, the popularity of application
hosting services with easy-to-use deployment tools like Heroku or
Engine Yard rose too.

This combination of good test coverage and easily automated deployments
makes Rails easy to continuously deliver with Jenkins. In this post we’ll cover
testing non-trivial Rails applications with Jenkins
Pipeline and, as an added bonus, we will add security scanning via
Brakeman and the
Brakeman
plugin.

Topics

Preparing the app

Preparing Jenkins

Writing the Pipeline

Security scanning

Deploying the good stuff

Wrap up

For this demonstration, I used Ruby Central &#x27;s
cfp-app :

A Ruby on Rails application that lets you manage your conference’s call for
proposal (CFP), program and schedule. It was written by Ruby Central to run the
CFPs for RailsConf and RubyConf.

I chose this Rails app, not only because it’s a sizable application with lots
of tests, but it’s actually the application we used to collect talk proposals
for the &quot; Community Tracks&quot; at this
year’s Jenkins World. For the most part,
cfp-app is a standard Rails application. It uses
PostgreSQL for its database,
RSpec for its tests and
Ruby 2.3.x as its runtime.

If you prefer to just to look at the code, skip straight to the
Jenkinsfile.

Preparing the app

For most Rails applications there are few, if any, changes needed to enable
continuous delivery with Jenkins. In the case of
cfp-app, I added two gems to get
the most optimal integration into Jenkins:

ci_reporter, for test report
integration

brakeman, for security scanning.

Adding these was simple, I just needed to update the Gemfile and the
Rakefile in the root of the repository to contain:

Gemfile

# .. snip ..
group :test do
  # RSpec, etc
  gem &#x27;ci_reporter&#x27;
  gem &#x27;ci_reporter_rspec&#x27;
  gem &quot;brakeman&quot;, :require =&gt; false
end

Rakefile

# .. snip ..
require &#x27;ci/reporter/rake/rspec&#x27;
# Make sure we setup ci_reporter before executing our RSpec examples
task :spec =&gt; &#x27;ci:setup:rspec&#x27;

Preparing Jenkins

With the cfp-app project set up, next on the list is to ensure that Jenkins itself
is ready. Generally I suggest running the latest LTS of
Jenkins; for this demonstration I used Jenkins 2.7.1 with the following
plugins:

Pipeline plugin

Brakeman plugin

CloudBees
Docker Pipeline plugin

I also used the
GitHub
Organization Folder plugin to automatically create pipeline items in my
Jenkins instance; that isn’t required for the demo, but it’s pretty cool to see
repositories and branches with a Jenkinsfile automatically show up in
Jenkins, so I recommend it!

In addition to the plugins listed above, I also needed at least one
Jenkins agent with the Docker daemon installed and
running on it. I label these agents with &quot;docker&quot; to make it easier to assign
Docker-based workloads to them in the future.

Any Linux-based machine with Docker installed will work, in my case I was
provisioning on-demand agents with the
Azure
plugin which, like the
EC2 plugin,
helps keep my test costs down.

If you’re using Amazon Web Services, you might also be interested in
this blog post from
earlier this year unveiling the
EC2
Fleet plugin for working with EC2 Spot Fleets.

Writing the Pipeline

To make sense of the various things that the Jenkinsfile needs to do, I find
it easier to start by simply defining the stages of my pipeline. This helps me
think of, in broad terms, what order of operations my pipeline should have.
For example:

/* Assign our work to an agent labelled &#x27;docker&#x27; */
node(&#x27;docker&#x27;) {
    stage &#x27;Prepare Container&#x27;
    stage &#x27;Install Gems&#x27;
    stage &#x27;Prepare Database&#x27;
    stage &#x27;Invoke Rake&#x27;
    stage &#x27;Security scan&#x27;
    stage &#x27;Deploy&#x27;
}

As mentioned previously, this Jenkinsfile is going to rely heavily on the
CloudBees
Docker Pipeline plugin. The plugin provides two very important features:

Ability to execute steps inside of a running Docker container

Ability to run a container in the &quot;background.&quot;

Like most Rails applications, one can effectively test the application with two
commands: bundle install followed by bundle exec rake. I already had some
Docker images prepared with RVM and Ruby 2.3.0 installed,
which ensures a common and consistent starting point:

node(&#x27;docker&#x27;) {
    // .. &#x27;stage&#x27; steps removed
    docker.image(&#x27;rtyler/rvm:2.3.0&#x27;).inside { (1)
rvm &#x27;bundle install&#x27; (2)
rvm &#x27;bundle exec rake&#x27;
    } (3)
}

1
Run the named container. The inside method can take optional additional flags for the docker run command.

2
Execute our shell commands using our tiny sh step wrapper
rvm . This ensures that the shell code is executed in the correct RVM environment.

3
When the closure completes, the container will be destroyed.

Unfortunately, with this application, the bundle exec rake command will fail
if PostgreSQL isn’t available when the process starts. This is where the
second important feature of the CloudBees Docker Pipeline plugin comes
into effect: the ability to run a container in the &quot;background.&quot;

node(&#x27;docker&#x27;) {
    // .. &#x27;stage&#x27; steps removed
    /* Pull the latest `postgres` container and run it in the background */
    docker.image(&#x27;postgres&#x27;).withRun { container -&gt; (1)
echo &quot;PostgreSQL running in container ${container.id}&quot; (2)
} (3)
}

1
Run the container, effectively docker run postgres

2
Any number of steps can go inside the closure

3
When the closure completes, the container will be destroyed.

Running the tests

Combining these two snippets of Jenkins Pipeline is, in my opinion, where the
power of the DSL
shines:

node(&#x27;docker&#x27;) {
    docker.image(&#x27;postgres&#x27;).withRun { container -&gt;
        docker.image(&#x27;rtyler/rvm:2.3.0&#x27;).inside(&quot;--link=${container.id}:postgres&quot;) { (1)
stage &#x27;Install Gems&#x27;
            rvm &quot;bundle install&quot;

            stage &#x27;Invoke Rake&#x27;
            withEnv([&#x27;DATABASE_URL=postgres://postgres@postgres:5432/&#x27;]) { (2)
rvm &quot;bundle exec rake&quot;
            }
            junit &#x27;spec/reports/*.xml&#x27; (3)
}
    }
}

1
By passing the --link argument, the Docker daemon will allow the RVM container to talk to the PostgreSQL container under the host name &#x27;postgres&#x27;.

2
Use the withEnv step to set environment variables for everything that is in the closure. In this case, the cfp-app DB scaffolding will look for the DATABASE_URL variable to override the DB host/user/dbname defaults.

3
Archive the test reports generated by ci_reporter so that Jenkins can display test reports and trend analysis.

With this done, the basics are in place to consistently run the tests for
cfp-app in fresh Docker containers for each execution of the pipeline.

Security scanning

Using Brakeman, the security scanner for Ruby
on Rails, is almost trivially easy inside of Jenkins Pipeline, thanks to the
Brakeman
plugin which implements the publishBrakeman step.

Building off our example above, we can implement the &quot;Security scan&quot; stage:

node(&#x27;docker&#x27;) {
    /* --8 (1)
publishBrakeman &#x27;brakeman-output.tabs&#x27; (2)
/* --8

1
Run the Brakeman security scanner for Rails and store the output for later in brakeman-output.tabs

2
Archive the reports generated by Brakeman so that Jenkins can display detailed reports with trend analysis.

As of this writing, there is work in progress
( JENKINS-31202) to
render trend graphs from plugins like Brakeman on a pipeline project’s main
page.

Deploying the good stuff

Once the tests and security scanning are all working properly, we can start to
set up the deployment stage. Jenkins Pipeline provides the variable
currentBuild which we can use to determine whether our pipeline has been
successful thus far or not. This allows us to add the logic to only deploy when
everything is passing, as we would expect:

node(&#x27;docker&#x27;) {
    /* --8 (1)
sh &#x27;./deploy.sh&#x27; (2)
}
    else {
        mail subject: &quot;Something is wrong with ${env.JOB_NAME} ${env.BUILD_ID}&quot;,
                  to: &#x27;nobody@example.com&#x27;,
                body: &#x27;You should fix it&#x27;
    }
    /* --8

1
currentBuild has the result property which would be &#x27;SUCCESS&#x27;, &#x27;FAILED&#x27;, &#x27;UNSTABLE&#x27;, &#x27;ABORTED&#x27;

2
Only if currentBuild.result is successful should we bother invoking our deployment script (e.g. git push heroku master)

Wrap up

I have gratuitously commented the full
Jenkinsfile
which I hope is a useful summation of the work outlined above. Having worked
on a number of Rails applications in the past, the consistency provided by
Docker and Jenkins Pipeline above would have definitely improved those
projects&#x27; delivery times. There is still room for improvement however, which
is left as an exercise for the reader. Such as: preparing new containers with
all their
dependencies
built-in instead of installing them at run-time. Or utilizing the parallel
step for executing RSpec across multiple Jenkins agents simultaneously.

The beautiful thing about defining your continuous delivery, and continuous
security, pipeline in code is that you can continue to iterate on it!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/rails">rails</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/brakeman">brakeman</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/continuousdelivery">continuousdelivery</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/11/speaker-blog-edx-jenkins-world/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">11</div></div><h5 class="title">Using Jenkins for Disparate Feedback on GitHub</h5></div><p class="teaser">This is a guest post by Ben Patterson, Engineering Manager at
edX.

Picking a pear from a basket is straightforward when you can hold it in your hand, feel its weight, perhaps give a gentle squeeze, observe its color and look more closely at any bruises. If the only information we had was a photograph from one angle, we’d have to do some educated guessing.

As developers, we don’t get a photograph; we get a green checkmark or a red x. We use that to decide whether or not we need to switch gears and go back to a pull request we submitted recently. At edX, we take advantage of some Jenkins features that could give us more granularity on GitHub pull requests, and make that decision less of a guessing game.

Multiple contexts reporting back when they’re available

Pull requests on our platform are evaluated from several angles: static code analysis including linting and security audits, javascript unit tests, python unit tests, acceptance tests and accessibility tests. Using an elixir of plugins, including the GitHub Pull Request Builder Plugin, we put more direct feedback into the hands of the contributor so s/he can quickly decide how much digging is going to be needed.

For example, if I made adjustments to my branch and know more requirements are coming, then I may not be as worried about passing the linter; however, if my unit tests have failed, I likely have a problem I need to address regardless of when the new requirements arrive. Timing is important as well. Splitting out the contexts means we can run tests in parallel and report results faster.

Developers can re-run specific contexts

Occasionally the feedback mechanism fails. It is oftentimes a flaky condition in a test or in test setup. (Solving flakiness is a different discussion I’m sidestepping. Accept the fact that the system fails for purposes of this blog entry.) Engineers are armed with the power of re-running specific contexts, also available through the PR plugin. A developer can say “jenkins run bokchoy” to re-run the acceptance tests, for example. A developer can also re-run everything with “jenkins run all”. These phrases are set through the GitHub Pull Request Builder configuration.

More granular data is easier to find for our Tools team

Splitting the contexts has also given us important data points for our Tools team to help in highlighting things like flaky tests, time to feedback and other metrics that help the org prioritize what’s important. We use this with a log aggregator (in our case, Splunk) to produce valuable reports such as this one.

I could go on! The short answer here is we have an intuitive way of divvying up our tests, not only for optimizing the overall amount of time it takes to get build results, but also to make the experience more user-friendly to developers.

Ben will be presenting more on this topic at
Jenkins World in September,
register with the code JWFOSS for a 20% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/17/jenkins-world-speaker-blog-aquilent/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Continuously Delivering Continuous Delivery Pipelines</h5></div><p class="teaser">This is a guest post by Jenkins World speaker Neil Hunt, Senior DevOps Architect at Aquilent.

In smaller companies with a handful of apps and fewer silos, implementing CD
pipelines to support these apps is fairly straightforward using one of the many
delivery orchestration tools available today. There is likely a constrained
tool set to support - not an abundance of flavors of applications and security
practices - and generally fewer cooks in the kitchen. But in a larger
organization, I have found that in the past, there were seemingly endless
unique requirements and mountains to climb to reach this level of automation on
each new project.

Neil will be presenting more
of this concept at Jenkins World in
September, register with the code JWFOSS for a 20% discount off your pass.

Enter the Jenkins Pipeline plugin. My recently departed former company, a large
financial services organization with a 600+ person IT organization and 150+
application portfolio, set out to implement continuous delivery
enterprise-wide. After considering several pipeline orchestration tools, we
determined the Pipeline plugin (at the time called Workflow) to be the superior
solution for our company. Pipeline has continued Jenkins&#x27; legacy of presenting
an extensible platform with just the right set of features to allow
organizations to scale its capabilities as they see fit, and do so rapidly. As
early adopters of Pipeline with a protracted set of requirements, we used it
both to accelerate the pace of onboarding new projects and to reduce the
ongoing feature delivery time of our applications.

In my presentation at Jenkins World, I will demonstrate the methods we used to
enable this. A few examples:

We leveraged the Pipeline Remote File Loader plugin to write shared common
code and sought and received community enhancements to these functions.

Jenkinsfile, loading a shared AWS utilities function library

awsUtils.groovy, snippets of some AWS functions

We migrated from EC2 agents to Docker-based agents running on Amazon’s
Elastic Container Service, allowing us to spin up new executors in seconds
and for teams to own their own executor definitions.

Pipeline run #1 using standard EC2 executors, spinning up EC2 instance for each
node; Pipeline run #2 using shared ECS cluster with near-instant instantiation
of a Docker agent in the cluster for each node.

We also created a Pipeline Library of common pipelines, enabling projects
that fit certain models to use ready-made end-to-end pipelines. Some
examples:

Maven JAR Pipeline: Pipeline that clones git repository, builds JAR file
from pom.xml, deploys to Artifactory, and runs maven release plugin to
increment next version

Anuglar.JS Pipeline: Pipeline that executes a grunt and bower build, then
runs S3 sync to Amazon S3 bucket in Dev, then Stage, then Prod buckets.

Pentaho Reports Pipeline: Pipeline that clones git repository, constructs
zip file, and executes Pentaho Business Intelligence Platform CLI to import new
set of reports in Dev, Stage, then Prod servers.

Perhaps most critically, a shout-out to the saving grace of this quest for our
security and ops teams: the manual &#x27;input&#x27; step! While the ambition of
continuous delivery is to have as few of these as possible, this was the
single-most pivotal feature in convincing others of Pipeline’s viability, since
now any step of the delivery process could be gate-checked by an LDAP-enabled
permission group. Were it not for the availability of this step, we may still
be living in the world of: &quot;This seems like a great tool for development, but
we will have a segregated process for production deployments.&quot; Instead, we had
a pipeline full of many &#x27;input&#x27; steps at first, and then used the data we
collected around the longest delays to bring management focus to them and unite
everyone around the goal of strategically removing them, one by one.

Going forward, having recently joined Aquilent’s Cloud Solutions Architecture
team, I’ll be working with our project teams here to further mature the use of
these Pipeline plugin features as we move towards continuous delivery. Already,
we have migrated several components of our healthcare.gov project to Pipeline.
The team has been able to consolidate several Jenkins jobs into a single,
visible delivery pipeline, to maintain the lifecycle of the pipeline with our
application code base in our SCM, and to more easily integrate with our
external tools.

Due to functional shortcomings in the early adoption stages of the Pipeline
plugin and the ever-present political challenges of shifting organizational
policy, this has been and continues to be far from a bruise-free journey. But
we plodded through many of these issues to bring this to fruition and
ultimately reduced the number of manual steps in some pipelines from 12 down to
1 and brought our 20+ Jenkins-minute pipelines to only six minutes after months
of iteration. I hope you’ll join this session at Jenkins World and learn about
our challenges and successes in achieving the promise of continuous delivery at
enterprise scale.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/22/ewm-stable-release/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">22</div></div><h5 class="title">GSoC: External Workspace Manager for Pipeline is released</h5></div><p class="teaser">This blog post is the last one from the series of
Google Summer of Code 2016, External Workspace Manager Plugin project.
The previous posts are:

Introductory blog post

Alpha release announcement

Beta release announcement

In this post I would like to announce the 1.0.0 release of the External Workspace Manager Plugin version to the main
update center.

Here’s a highlight of the available features:

Workspace share and reuse across multiple jobs, running on different nodes

Automatic workspace cleanup

Provide custom workspace path on the disk

Disk Pool restrictions

Flexible Disk allocation strategies

All the above are detailed, with usage examples, on the plugin’s
documentation page.

Future work

Currently, there is work in progress for the workspace browsing feature (see pull request
#37).
Afterwards, I’m planning to integrate fingerprints, so that the user can view a specific workspace in which
other jobs was used.
A particular feature that would be nice to have is to integrate the plugin with at least one disk provider
(e.g. Amazon EBS, Google Cloud Storage).

Many other features and improvements are still to come, they are grouped in the phase 3 EPIC:
JENKINS-37543.
The plugin’s repository is on GitHub.
If you’d like to come up with new features or ideas, contributions are very welcome.

Closing

This was a Google Summer of Code 2016 project.
A summary of the contributions that I’ve made to the Jenkins project during this time may be found
here.
It was a great experience, from which I learned a lot, and I’d wish I could repeat it every year.

I’d like to thank to my mentors, Oleg Nenashev and
Martin d’Anjou for all their support, good advices and help they gave me.
Also, thanks to the Jenkins contributors with which I have interacted and helped me during this period.

If you have any issues in setting up or using the plugin, please feel free to ask me on the plugin’s Gitter
chat.
Any feedback is welcome, and you may provide it either on the Gitter chat, or on
Jira by using the external-workspace-manager-plugin component.

Links

Project repository

Work product page

GSoC page

Jenkins GSoC Page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alexsomai/">Alexandru Somai</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/external-workspace-manager">external-workspace-manager</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/24/jenkins-world-2016-festivities/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">24</div></div><h5 class="title">Jenkins World 2016 Festivities</h5></div><p class="teaser">At Jenkins World 2016 on
September 14-15, stop by the &quot;Open Source Hub&quot;, located in the Partner Expo
hall at the Santa Clara Convention Center in Santa Clara, CA. The Open Source
Hub will have many Jenkins contributors, committers, JAM leaders, and
officers from
the governance board under one roof, so there will be plenty of knowledge and
talents on hand to share. We hope you’ll join in on the festivities.

Ask the Experts

The setup that is waiting for you: white boards, monitors and lots of brain
power to help answer those Jenkins questions that have been keeping you up at
night.  Jenkins experts can help with beginner questions to the more advanced
ones. All you need to do is bring your laptop and your questions; the experts
will help answer them!

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.

Live Demos

Sometimes seeing is believing, there will be plenty of demos in the &quot;Open
Source Hub&quot; during the lunch hours on Wednesday September 14th, and Thursday
September 15th in the expo hall. Jenkins experts will be show-casing their
favorite Jenkins features, plugins and projects. Grab your lunch, take a seat
in the open source theater to learn about:

Pipelines for Building and Deploying Android Apps by Android Emulator
plugin maintainer Chris Orr

Git Plugin - Large Repos, Submodule Authentication, and more by Git plugin
maintainer Mark Waite

Docker and Pipeline by Jenkins infrastructure contributor
R Tyler Croy

Extending Pipeline with Libraries by Pipeline plugin maintainer
Jesse Glick

Blue Ocean in Action by Blue Ocean contributor
Keith Zantow

External Workspace Manager plugin for Pipeline by
Google Summer of Code student
Alexandru Somai

And many more

Jenkins Mural

Jenkins World participants will take part in the realization of a giant
collaborative mural painting with the
CommitStrip team.  Thomas, the writer and
Etienne, the cartoonist, teamed up with a few Jenkins contributors to design a
5m x 2m mmural which will be drawn live! Brushes and colors will be
available for all attendees who wish to help paint this one of a kind piece of
Jenkins art.

Sticker Swap

Jenkins World attendees will have a chance to swap stickers. There will be a
table where attendees are welcome to place/take stickers. Bring your cool
stickers to share with others and take stickers that interest you.

After Dark Reception Sponsored by CloudBees

After Dark reception will be from 6-8pm on Wed Sept 14 in the Partner Expo.
Enjoy cocktails, appetizers, mingle, and dance to a live band. A big THANK
YOU
goes out to CloudBees for their generous contributions! See you at After Dark!

Contributor Summit - Tuesday, September 13

If Blue Ocean, Pipeline and Storage Pluggability sounds interesting to you,
join the interactive discussions surrounding these topics. The Jenkins project
is also looking to hear use-cases, war stories, and pain points. The objective
of the summit is to work towards improving the Jeknins project.
Seats are limited.

Don’t forget to register; I look forward to
seeing you at the conference!

Links

Jenkins World 2016

Acknowledgements

Special thanks to CloudBees as the premier
sponsor and BlazeMeter, Microsoft, Red
Hat and all the other sponsors who have made this event possible.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/26/ask-the-experts-jenkins-world/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">26</div></div><h5 class="title">Ask the Experts at Jenkins World 2016</h5></div><p class="teaser">Our events officer Alyssa has been working for
the past several weeks to organize the &quot;Open Source Hub&quot; at
Jenkins World 2016. The Hub
is a location on the expo floor where contributors to the Jenkins project can hang
out, share demos and help Jenkins users via the &quot;Ask the Experts&quot; program. Thus
far we have a great list of experts who have volunteered to help staff the
booth, which includes many frequent contributors, JAM
organizers and board members.

A few of the friendly folks you will see at Jenkins World are:

Paul Allen -
P4 Plugin
maintainer and Pipeline contributor.

R Tyler Croy -
Jenkins infrastructure maintainer and
board member.

Jesse Glick - Pipeline
maintainer and long-time contributor to Jenkins
core.

Eddú Meléndez Gonzales - Organizer for
the Lima (Perú)
Jenkins Area Meetup and contributor to Spring.

Jon Hermansen - Organizer for the
Los Angeles
Jenkins Area Meetup, developer and Pipeline user.

Owen Mehegan -
GitLab plugin
contributor, release engineer and copy editor for jenkins.io.

Oleg Nenashev -
Google Summer of Code organizer, maintainer of multiple
plugins and St.
Petersburg Jenkins Area Meetup organizer.

Christopher Orr - Maintainer of multiple
Android-related plugins, including the
Android
Emulator plugin and contributor to numerous projects behind the scenes of
Jenkins.

Casey Vega - Organizer for the
Los Angeles
Jenkins Area Meetup and release engineer at Verizon Digital Media.

Mark Waite - Maintainer of the
Git plugin and
contributor to a number of other Git-related plugins.

Dean Yu - Long-time contributor, board member
and release engineer at Shutterfly.

I hope that this list isn’t exhaustive! If you are an active member of the
Jenkins community and/or a contributor, consider taking part in the &quot;Ask the
Experts&quot; program. It’s a great opportunity to bond with other contributors and
talk with fellow users at Jenkins World.

You will be able to find us in the expo hall under the &quot;Open Source Hub&quot; sign;
please stop by at Jenkins World to say hello, pick up stickers and to ask
questions!

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/29/jenkins-world-speaker-blog-goodgame/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">29</div></div><h5 class="title">Enforcing Jenkins Best Practices</h5></div><p class="teaser">This is a guest post by Jenkins World speaker David Hinske, Release
Engineer at Goodgame Studios.

Hey there, my name is David Hinske and I work at Goodgame Studios (GGS), a game
development company in Hamburg, Germany. As Release Engineer in a company with
several development teams, it comes in handy using several Jenkins instances.
While this approach works fine in our company and gives the developers a lot of
freedom, we came across some long-term problems concerning maintenance and
standards. These problems were mostly caused by misconfiguration or non-use of
plugins. With “configuration as code” in mind, I took the approach to apply
static code analysis with the help of SonarQube, a platform to manage code
quality, for all of our Jenkins job configurations.

As a small centralized team, we were looking for an easy way to control the
health of our growing Jenkins infrastructure. With considering “configuration
as code“, I developed a simple extension of SonarQube, to manage the quality
and usage of all spawned Jenkins instances. The given SonarQube features (like
customized rules/metrics, quality profiles and dashboards) allow us and the
development teams to analyze and measure the quality of all created jobs in our
company. Even though Jenkins configuration analysis cannot cover all
SonarQube’s axes of code quality, I think there is still potential for
conventions/standards, duplications, complexity, potential bugs
(misconfiguration) and design and architecture.

The results of this analysis can be used by all people working with Jenkins. To
achieve this, I developed a simple extension of SonarQube, containing
everything which is needed to hook up our SonarQube with our Jenkins
environment. The implementation contains a new basic-language “Jenkins“ and an
initial set of rules.

Of course the needs depend strongly on the way Jenkins is being used, so not
every rule implemented might be useful for every team, but this applies to all
types of code analysis. The main inspirations for the rules were developer
feedback and some articles found in the web. The different ways Jenkins can be
configured provides the potential for many more rules. With this new approach
of quality analysis, we can enforce best practices like:

Polling must die (Better to triggerb uilds from pushes than poll the
repository every x minutes).

Use Log Rotator (Not using log-rotator can result in disk space problems on
the controller).

Use agents/labels (Jobs should be defined where to run).

Don’t build on the controller (In larger systems, don’t build on the controller).

Enforce plugin usage (For example: Timestamp, Mask-Passwords).

Naming sanity (Limit project names to a sane (e.g. alphanumeric) character
set).

Analyze Groovy Scripts (For example: Prevent System.exit(0) in System Groovy
Scripts).

Besides taking control of all configuration of any Jenkins instance we want,
there is also room for additional metrics, like measuring the amount and
different types of jobs (Freestyle/Maven etc…​) to get an overview about the
general load of the Jenkins instance. A more sophisticated idea is to measure
complexity of jobs and even pipelines. As code, jobs configuration gets harder
to understand the more steps are involved. On the one hand scripts, conditions
and many parameters can negatively influence the readability, especially if you
have external dependencies (like scripts) in different locations. On the other
hand, pipelines can also grow very complex when many jobs are involved and
chained for execution. It will be very interesting for us to see where and why
too complex pipelines are being created.

On visualization we rely on the data and its interpretation of SonarQube, which
offers a big bandwidth of widgets. Everybody can use and customize the
dashboards. Our centralized team for example has a separate dashboard where we
can get a quick overview over all instances.

The problem of &quot;growing&quot; Jenkins with maintenance problems is not new.
Especially when you have many developers involved, including with the access to
create jobs and pipelines themselves, an analysis like this SonarQube plugin
provides can be useful for anyone who wants to keep their Jenkins in shape.
Customization and standards are playing a big role in this scenario. This blog
post surely is not an advertisement for my developed plugin, it is more about
the crazy idea of using static code analysis for Jenkins job configuration. I
haven’t seen anything like it so far and I feel that there might be some
potential behind this idea.

Join me at my Enforcing Jenkins Best Practices session at the 2016 Jenkins
World to hear more!

David will be
presenting
more of this concept at
Jenkins World in September.
Register with the code JWFOSS for 20% off your full conference pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/29/sauce-pipeline/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">29</div></div><h5 class="title">Browser-testing with Sauce OnDemand and Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Testing web applications across multiple browsers on different platforms can be challenging even for smaller applications.
With Jenkins and the
Sauce OnDemand Plugin,
you can wrangle that complexity by defining your Pipeline as Code.

Pipeline ♥ UI Testing, Too

I recently started looking for a way to do browser UI testing for an open-source JavaScript project to which I contribute.
The project is targeted primarily at
Node.js
but we’re committed to maintaining browser-client compatibility as well.
That means we should run tests on a matrix of browsers.
Sauce Labs
has an &quot;open-sauce&quot; program that provides free test instances to open-source projects.
I decided to try using the
Sauce OnDemand Plugin
and
Nightwatch.js
to run Selenium tests on a sample project first, before trying a full-blown suite of tests.

Starting from Framework

I started off by following Sauce Labs&#x27; instructions on
&quot; Setting up Sauce Labs with Jenkins&quot;
as far as I could.
I installed the
JUnit and
Sauce OnDemand
plugins, created an account with Sauce Labs, and
added my Sauce Labs credentials to Jenkins.
From there I started to get a little lost.
I’m new to Selenium and I had trouble understanding how to translate the instructions to my situation.
I needed a working example that I could play with.

Happily, there’s a whole range of sample projects in
&quot; saucelabs-sample-test-frameworks&quot;
on GitHub, which show how to integrate Sauce Labs with various test frameworks, including Nightwatch.js.
I forked the Nightwatch.js sample to
bitwiseman/JS-Nightwatch.js
and set to writing my Jenkinsfile.
Between the sample and the Sauce Labs instructions,
I was able to write a pipeline that ran five tests on one browser via
Sauce Connect :

node {
    stage &quot;Build&quot;
    checkout scm

    sh &#x27;npm install&#x27; (1)

stage &quot;Test&quot;
    sauce(&#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;) { (2)
sauceconnect(options: &#x27;&#x27;, useGeneratedTunnelIdentifier: false, verboseLogging: false) { (3)
sh &#x27;./node_modules/.bin/nightwatch -e chrome --test tests/guineaPig.js || true&#x27; (4)
junit &#x27;reports/**&#x27; (5)
step([$class: &#x27;SauceOnDemandTestPublisher&#x27;]) (6)
}
    }
}

1
Install dependencies

2
Use my
previously added sauce credentials

3
Start up the
Sauce Connect
tunnel to Sauce Labs

4
Run Nightwatch.js

5
Use JUnit to track results and show a trend graph

6
Link result details from Sauce Labs

This pipeline expects to be run from a Jenkinsfile in SCM.
To copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with
git url:&#x27;https://github.com/bitwiseman/JS-Nightwatch.js&#x27;, branch: &#x27;sauce-pipeline&#x27;.

I ran this job a few times to get the JUnit report to show a trend graph.

This sample app generates the SauceOnDemandSessionID for each test, enabling the Jenkins Sauce OnDemand Plugin’s result publisher to link results to details Sauce Labs captured during the run.

Adding Platforms

Next I wanted to add a few more platforms to my matrix.
This would require changing both the test framework configuration and the pipeline.
I’d need to add new named combinations of platform, browser, and browser version (called &quot;environments&quot;) to the Nightwatch.js configuration file,
and modify the pipeline to run tests in those new environments.

This is a perfect example of the power of pipeline as code.
If I were working with a separately configured pipeline,
I’d have to make the change to the test framework, then change the pipeline manually.
With my pipeline checked in as code,
I could change both in one commit,
preventing errors resulting from pipeline configurations going out of sync from the rest of the project.

I added three new environments to nightwatch.json :

&quot;test_settings&quot; : {
  &quot;default&quot;: { /*----8 &lt;----*/ },
  &quot;chrome&quot;: { /*----8 &lt;----*/ },

  &quot;firefox&quot;: {
    &quot;desiredCapabilities&quot;: {
      &quot;platform&quot;: &quot;linux&quot;,
      &quot;browserName&quot;: &quot;firefox&quot;,
      &quot;version&quot;: &quot;latest&quot;
    }
  },
  &quot;ie&quot;: {
    &quot;desiredCapabilities&quot;: {
      &quot;platform&quot;: &quot;Windows 10&quot;,
      &quot;browserName&quot;: &quot;internet explorer&quot;,
      &quot;version&quot;: &quot;latest&quot;
    }
  },
  &quot;edge&quot;: {
    &quot;desiredCapabilities&quot;: {
      &quot;platform&quot;: &quot;Windows 10&quot;,
      &quot;browserName&quot;: &quot;MicrosoftEdge&quot;,
      &quot;version&quot;: &quot;latest&quot;
    }
  }
}

And I modified my Jenkinsfile to call them:

//----8 (1)
&#x27;chrome&#x27;,
        &#x27;firefox&#x27;,
        &#x27;ie&#x27;,
        &#x27;edge&#x27;
    ].join(&#x27;,&#x27;)
    // Run selenium tests using Nightwatch.js
    sh &quot;./node_modules/.bin/nightwatch -e ${configs} --test tests/guineaPig.js&quot; (2)
} //----8

1
Using an array to improve readability and make it easy to add more platforms later.

2
Changed from single-quoted string to double-quoted to support variable substitution.

Test frameworks have bugs too. Nightwatch.js (v0.9.8) generates incomplete JUnit files,
reporting results without enough information in them to distinguish between platforms.
I implemented a fix for it and
submitted a PR to Nightwatch.js.
This blog shows output with that fix applied locally.

As expected, Jenkins picked up the new pipeline and ran Nightwatch.js on four platforms.
Sauce Labs of course recorded the results and correctly linked them into this build.
Nightwatch.js was already configured to use multiple worker threads to run tests against those platforms in parallel, and
my Sauce Labs account supported running them all at the same time,
letting me cover four configurations in less that twice the time,
and that added time was most due to individual new environments taking longer to complete.
When I move to the actual project, this will let me run broad acceptance passes quickly.

Conclusion: To Awesome and Beyond

Considering the complexity of the system, I was impressed with how easy it was to integrate Jenkins with Sauce OnDemand to start testing on multiple browsers.
The plugin worked flawlessly with Jenkins Pipeline.
I went ahead and ran some additional tests to show that failure reporting also behaved as expected.

//----8 (1)
//----8

1
Removed --test filter to run all tests

Epilogue: Pipeline vs. Freestyle

Just for comparison here’s the final state of this job in Freestyle UI versus fully-commented pipeline code:

This includes the
AnsiColor Plugin
to support Nightwatch.js&#x27; default ANSI color output.

Freestyle

Pipeline

node {
    stage &quot;Build&quot;
    checkout scm

    // Install dependencies
    sh &#x27;npm install&#x27;

    stage &quot;Test&quot;

    // Add sauce credentials
    sauce(&#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;) {
        // Start sauce connect
        sauceconnect(options: &#x27;&#x27;, useGeneratedTunnelIdentifier: false, verboseLogging: false) {

            // List of browser configs we&#x27;ll be testing against.
            def platform_configs = [
                &#x27;chrome&#x27;,
                &#x27;firefox&#x27;,
                &#x27;ie&#x27;,
                &#x27;edge&#x27;
            ].join(&#x27;,&#x27;)

            // Nightwatch.js supports color ouput, so wrap this step for ansi color
            wrap([$class: &#x27;AnsiColorBuildWrapper&#x27;, &#x27;colorMapName&#x27;: &#x27;XTerm&#x27;]) {

                // Run selenium tests using Nightwatch.js
                // Ignore error codes. The junit publisher will cover setting build status.
                sh &quot;./node_modules/.bin/nightwatch -e ${platform_configs} || true&quot;
            }

            junit &#x27;reports/**&#x27;

            step([$class: &#x27;SauceOnDemandTestPublisher&#x27;])
        }
    }
}

This pipeline expects to be run from a Jenkinsfile in SCM.
To copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with
git url:&#x27;https://github.com/bitwiseman/JS-Nightwatch.js&#x27;, branch: &#x27;sauce-pipeline&#x27;.

Not only is the pipeline as code more compact,
it also allows for comments to further clarify what is being done.
And as I noted earlier,
changes to this pipeline code are committed the same as changes to the rest of the project,
keeping everything synchronized, reviewable, and testable at any commit.
In fact, you can view the full set of commits for this blog post in the
blog/sauce-pipeline
branch of the
bitwiseman/JS-Nightwatch.js
repository.

Links

Sauce OnDemand Plugin

bitwiseman/JS-Nightwatch.js

saucelabs-sample-test-frameworks<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/saucelabs">saucelabs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/selenium">selenium</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/nightwatch">nightwatch</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/30/ask-experts-demos/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">30</div></div><h5 class="title">Demos at Jenkins World 2016</h5></div><p class="teaser">At this year’s Jenkins World,
our events officer Alyssa has been working to
organize various activities in the &quot;Open Source Hub&quot; on the expo floor.  Both
days of the conference (Sept. 14th and 15th), during the break for lunch, there
will be 15 minute demos by many of the
experts helping to staff
the Open Source Hub.

Demo Schedule

Wednesday, September 14th

Time
Session
Details
Presenter

12:15 - 12:30
Blue Ocean in Action
Showcase of Blue Ocean and how it will make Jenkins a pleasure to use.
Keith Zantow

12:30 - 12:45
Notifications with Jenkins Pipeline
Sending information to Slack, HipChat, email and more from your Pipeline
Liam Newman

12:45 - 13:00
Docker and Pipeline
Learn how to use Docker inside of Pipeline for clean, repeatable testing environments
R Tyler Croy

13:00 - 13:15
Git plugin - large repos, submodule authentication and more
Techniques for managing large Git repositories, Submodule authentication, Pipelines and Git
Mark Waite

13:15 - 13:30
Freestyle to Pipeline
Overview of how easy it is to migrate from a confusing series of Freestyle Jobs to Jenkins Pipeline
R Tyler Croy

13:30 - 13:45
package.json and Jenkins
Using package.json to control your build; running tests, coverage and generating documentation in Jenkins
Casey Vega

13:45 - 14:00
Extending Pipeline with Libraries
When you have many jobs using similar configuration, it is natural to factor out the common parts into libraries. See some ways Pipeline lets you do this.
Jesse Glick

Thursday, September 15th

Time
Session
Details
Presenter

12:15 - 12:30
A simpler way to define Jenkins Pipelines
Get to know a new way to define your Pipelines in a more configuration-like way!
Andrew Bayer

12:30 - 12:45
Multibranch Pipelines + Git symbolic-ref
Pipeline Multibranch Plugin is amazing, but is even better when used with
Git symbolic references. The combination of the two gives users a way to create
individual Jenkins jobs for each of their build/test configurations, instead of
using a single parameterized job. I’ll show how to use these tools together to
home in on problematic tests, systems under test, or both.
Jon Hermansen

12:45 - 13:00
External Workspace Manager plugin for Jenkins Pipeline
Meet the External Workspace Manager plugin, which supports managing workspaces across multiple Jenkins jobs running on different nodes and more!
Alex Somai

13:00 - 13:15
Ownership plugin for Jenkins
The presentation will introduce the Ownership engine for Jenkins jobs, folders and nodes. The presentation will cover plugin WebUI features, Ownership-based security and integration with Jenkins Pipeline
Oleg Nenashev

13:15 - 13:30
Pipelines for building and deploying Android apps
Using the various Android-related plugins for Jenkins, we will demonstrate pipelines to automatically build, test, and securely deploy Android apps.
Christopher Orr

As you can see there is a lot to see in the Open Source Hub at Jenkins World.
To my knowledge these demos are not going to be recorded, so your only
opportunities to see them might be at Jenkins World or your local
Jenkins Area Meetup!

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/08/31/scaling-jenkins-at-jenkins-world/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">Scaling Jenkins at Jenkins World 2016</h5></div><p class="teaser">This is a guest post by R. Tyler Croy, who is a
long-time contributor to Jenkins and the primary contact for Jenkins project
infrastructure. He is also a Jenkins Evangelist at
CloudBees, Inc.

I find the topic of &quot;scaling Jenkins&quot; to be incredibly interesting because,
more often than not, scaling Jenkins isn’t just about scaling a single instance
but rather scaling an organization and its continuous delivery processes. In
many cases when people talk about &quot;scaling Jenkins&quot; they’re talking about
&quot;Jenkins as a Service&quot; or &quot;Continuous Delivery as a Service&quot; which introduces a
much broader scope, and also more organization-specific requirements, to the
problem.

One of my favorite parts of a big conference like
Jenkins World is getting to
see how other people are solving similar problems at different organizations,
in essence:
&quot; how
the sausage is made.&quot; This year’s Jenkins World will be no different, with a number
of sessions by developers and engineers from the companies leading the way,
scaling continuous delivery and Jenkins.

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.

In the realm of &quot;scaling Jenkins&quot; the following sessions stand-out to me as
&quot;must-attend&quot; for those interested in the space:

JenkinsOps:
An Initiative to Streamline and Automate Jenkins

September 14th 4:15 PM - 5:00 PM, Exhibit Hall A-1

NPR’s Digital Media team uses Jenkins to build, test and deploy code to various
staging and production environments. As the complexity of the software
components, environments and tests have grown - both generally and due to our
quest to achieve continuous deployment - management of Jenkins has become a
challenge. In this talk, we share information about our “JenkinsOps” effort
which has allowed us to automate many of the administrative tasks necessary to
manage feature code branches, handle deployments, run tests and configure our
environments properly.

— Paul Miles and Grant Dickie of NPR

Thinking
Inside the Container: A Continuous Delivery Story

September 15th 1:30 PM - 2:15 PM, Exhibit Hall C

At Riot Games, we build a lot of software. Come learn how we built an
integrated Docker solution using Jenkins that accepts Docker images submitted
as build environments by engineers around the company. Our containerized farm
now creates over 10,000 containers per week and handles nearly 1,000 jobs at a
rate of about 100 jobs per hour. All this is done with readily available, open
source Jenkins plugins. We’ll explore lessons learned, best practices and how
to scale and build your own system, as well as why we chose to solve the
problem this way…and whether or not we succeeded!

— Maxfield F Stewart of Riot Games

How
to Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes

September 15th 2:30 PM - 3:15 PM, Great America J

In this talk, we’ll show how to use Jenkins Pipeline together with Docker and
Kubernetes to implement a complete end-to-end continuous delivery and
continuous improvement system for microservices and monolithic applications
using open source software. We’ll demonstrate how to easily create new
microservices projects or import existing projects, have them automatically
built, system and integration tested, staged and then deployed. Once deployed,
we will also see how to manage and update applications using continuous
delivery practices along with integrated ChatOps - all completely automated!

— James Strachan of Red Hat

Scaling
Jenkins with Docker: Swarm, Kubernetes or Mesos?

September 15th 2:30 PM - 3:15 PM, Exhibit Hall C

The Jenkins platform can be dynamically scaled by using several Docker cluster
and orchestration platforms, using containers to run agents and jobs and also
isolating job execution. But which cluster technology should be used? Docker
Swarm? Apache Mesos? Kubernetes? How do they compare? All of them can be used
to dynamically run jobs inside containers. This talk will cover these main
container clusters, outlining the pros and cons of each, the current state of
the art of the technologies and Jenkins support. I believe people will be very
interested in learning about the multiple options available.

— Carlos Sanchez of CloudBees

So,
You Want to Build the World’s Biggest Jenkins Cluster?

September 15th 3:45 PM - 4:30 PM, Exhibit Hall C

How can we do it? We start with some real world results realized by Jenkins
users who have built large clusters and review how they got there. Next, we
will do experiments scaling some individual sub-components of Jenkins in
isolation and see what challenges we will face when integrated. The famous
large, distributed systems undoubtedly faced problems scaling - and we can
learn from them, too. The result will be recipes for building Jenkins
clusters with different scaling capabilities. After all of this, you can
build the biggest Jenkins cluster in the world…or maybe just make your own
Jenkins cluster more efficient.

— Stephen Connolly of CloudBees

Jenkins at
Splunk and Splunking Jenkins

September 15th 3:45 PM - 4:30 PM, Exhibit Hall A-1

This session will highlight how Splunk uses Jenkins to provide an end-to-end
solution in the development CI system. Attendees will see how test results are
delivered to a Splunk indexer, where they can be analyzed and presented in a
variety of ways. This session will also include a live demonstration.

— Bill Houston of Splunk

Jenkins inside Google

September 15th 4:45 PM - 5:30 PM, Exhibit Hall C

Last year, we presented our initial investigations and stress testing as we
prepared to deploy a large-scale Jenkins installation at Google. Now, with a
year of real-world use under our belts, we’ll discuss how our expectations held
up, what new issues we encountered and how we have addressed them.

— David Hoover of Google

In addition to these, we will also be hosting a
Jenkins World
Contributor Summit where &quot;scaling&quot; relevant topics such as &quot;Storage
Pluggability&quot; will be discussed.

The Jenkins World agenda is packed
with even more sessions, so it should be a very informational event for
everybody; hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/01/jenkins-world-contributor-summit/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 1</div></div><h5 class="title">Jenkins World Contributor Summit</h5></div><p class="teaser">At previous Jenkins User Conferences we have hosted &quot;Contributor Summits&quot; to
gather developers and power-users in one room to discuss specific areas of
Jenkins, such as Scalability, Pipeline, etc. As part of this year’s
Jenkins World we’re hosting
another Contributor
Summit, to discuss: Blue Ocean ,
Pipeline and Storage Pluggability.

Contributors to these three areas of the Jenkins ecosystem will be in
attendance to present details of their design, requirements, and tentative
roadmaps. After the presentations, the afternoon will be &quot;unconference style&quot; which
is much more fluid to allow discussions, feedback, and brain-storming around
the three focus areas.

The program for the
Jenkins World
Contributor Summit includes:

Updates from the various project
officers.

A discussion of the Blue Ocean technology stack,
overall architecture, and how to develop plugins that integrate with Blue
Ocean. Led by Keith Zantow.

Presentation on the current status of Pipeline, lessons
learned, new changes and the future. Led by
Jesse Glick.

Overview of &quot;Storage Pluggability&quot;, a new scalability-oriented project to
revamp the underlying storage mechanisms in Jenkins. Led by
Kohsuke Kawaguchi.

I cannot recommend participating in the Contributor Summit enough. I have found
previous Summits to be immensely useful for sharing my own thoughts, as well as
for hearing new perspectives from the others in attendance.

Our space is limited however! I encourage you to join us, so please
RSVP soon!

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/06/jenkins-world-speaker-blog-pipeline-model-definition/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 6</div></div><h5 class="title">Introducing a New Way to Define Jenkins Pipelines</h5></div><p class="teaser">This is a guest post by Jenkins World speaker Andrew Bayer, Jenkins
developer at CloudBees.

Over the last couple years, Pipeline as code has very much become the future of
Jenkins - in fact, at this point, I’d say it’s pretty well established as the
present of Jenkins. But that doesn’t mean it’s done, let alone that it’s
perfect. While many developers enjoy the power and control that they get from
writing Pipelines using scripting, not everyone feels the same way. A lot of
developers want to specify their build as configuration and get on with building
software.

Pipeline scripts haven’t been a good way to do that…​until now.

With new changes to Jenkins Pipeline, you are now able to define your Pipeline
from configuration in your Jenkinsfile by installing the new
Pipeline Model Definition
plugin. It’s available today for you to try via the update center.
Be sure to check the documentation for examples on how to get started for a
variety of languages and platforms.

Here’s a quick example based on the plugin’s own Jenkinsfile :

pipeline {
    // Make sure that the tools we need are installed and on the path.
    tools {
        maven &quot;Maven 3.3.9&quot;
        jdk &quot;Oracle JDK 8u40&quot;
    }

    // Run on any executor.
    agent label:&quot;&quot;

    // The order that sections are specified doesn&#x27;t matter - this will still be run
    // after the stages, even though it&#x27;s specified before the stages.
    postBuild {
        // No matter what the build status is, run these steps. There are other conditions
        // available as well, such as &quot;success&quot;, &quot;failed&quot;, &quot;unstable&quot;, and &quot;changed&quot;.
        always {
            archive &quot;target/**/*&quot;
            junit &#x27;target/surefire-reports/*.xml&#x27;
        }
    }

    stages {
        // While there&#x27;s only one stage here, you can specify as many stages as you like!
        stage(&quot;build&quot;) {
            sh &#x27;mvn clean install -Dmaven.test.failure.ignore=true&#x27;
        }
    }

}

It’s still early days for this feature, with a lot of further functionality
planned to make it easier and more intuitive to define your Pipelines. All of
that functionality lives on top of Pipeline scripting, so we’ll also keep
improving Pipeline steps and syntax outside of the model! And perhaps most
exciting, the Pipeline model will be used by an in-the-works visual editor
that will be part of the Blue Ocean project - while the editor isn’t ready yet,
the Pipeline Model Definition plugin will be bundled with the Blue Ocean beta
for you to try out.

I’ll be going into all of this and more at my talk on Thursday, September 15th, at
3:45pm at Jenkins World, and showing off the same day at the lunchtime demo
theater. I can’t wait to see you all there and hear what you think of all this!

Andrew will be
presenting
more of this concept at
Jenkins World in September.
Register with the code JWFOSS for 20% off your full conference pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/07/pipeline-at-jenkins-world/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 7</div></div><h5 class="title">Pipeline at Jenkins World 2016</h5></div><p class="teaser">This is a guest post by R. Tyler Croy, who is a
long-time contributor to Jenkins and the primary contact for Jenkins project
infrastructure. He is also a Jenkins Evangelist at
CloudBees, Inc.

I have been heavily using Jenkins Pipeline for just about
every Jenkins-related project I have contributed to over the past year. Whether I am
building and publishing Docker
containers, testing
infrastructure code or
publishing this very web
site, I have been adding a Jenkinsfile to nearly every Git repository I
touch.

Implementing Pipeline has been rewarding, but has not been without its own
challenges. That’s why I’m excited to see lots of different Jenkins Pipeline
related content in the agenda at
Jenkins World.

I don’t think it’s possible for a single person to attend all of the Pipeline
talks, or the Pipeline-related demos
in the &quot;Open Source Hub&quot;, but fortunately CloudBees
will be recording the sessions. If you have Pipeline-related questions unanswered by
all these presentations, feel free to join us at the &quot;Open Source Hub&quot; in the
expo hall and Ask the
Experts.

On the first day of Jenkins World (September 13th), Isaac Cohen is hosting a
workshop titled
Let’s
Build a Jenkins Pipeline which may be interesting to you if you haven’t yet
worked with Pipeline.

Pipelining
DevOps with Jenkins and AWS

September 14th 2:00 PM - 2:45 PM, Exhibit Hall A-1

Automated workflow is a proven method for removing process variability. DevOps
pipelines are the next step in the evolution of CI/CD/DevOps. This talk covers
Jenkins pipelines, both with and without AWS integration, and explains how
Jenkins can be used to create, execute and manage pipelines.

— Jimmy Ray of nextSource

Perfecting
Your Development Tools: Updates to the Helix Plugin for Jenkins

September 14th 5:00 PM - 6:00 PM, Exhibit Hall C

Considering a mono repo that can manage all your source code, binary and other
assets? Join us at the Perforce Birds of a Feather Session for updates and
discussions around the Helix Plugin for Jenkins (or ‘P4 plugin’).

This session will look at the latest DSL PipeLine support in the ‘P4 plugin’
for Jenkins and will include a live demo. We will show you how to map your
Branches and Streams into a Jenkins Workspace, publish assets back into
Helix, and more. You may even get a sneak preview at the latest ‘P4 plugin’
for Jenkins that allows you the freedom to query and run commands from
within Jenkins directly against your Helix connection.

— Paul Allen of Perforce

Continuously
Deploying Containers with Jenkins Pipeline to Docker Swarm Cluster

September 14th 3:00 PM - 3:45 PM, Exhibit Hall A-3

Many of us have already experimented with Docker - for example, by running one
of the pre-built images from Docker Hub. It is possible that your team might
have recognized the benefits that Docker provides in building microservices and
the advantages the technology could bring to development, testing, integration
and, ultimately, production. However, you must create a comprehensive build
pipeline before deploying any containers into a live environment. Integrating
containers into a CD pipeline is far from easy. Along with the benefits Docker
brings, there are challenges both technically and process-related. This
presentation attempts to outline the steps you need to take for a
fully-automated Jenkins pipeline that continuously builds, tests and deploys
microservices into a Docker Swarm cluster.

— Viktor Farcic

No,
You Shouldn’t Do That! Lessons from Using Pipeline

September 15th 10:30 AM - 11:15 AM, Exhibit Hall A-1

Pipeline is as powerful as a loaded gun, but with skill can be as delicate as a
surgeon’s knife. This talk will give an overview of health and safety so that
you can avoid shooting yourself in the head and walk the path to medical
school. It will cover not only what not to do, but also why, and share some
solutions so you are not left high and dry. Both James and Bobby have bullet
wounds from “Champagning” pipeline to automate the test and release of several
of the CloudBees products and can occasionally still be seen walking with a
limp from shooting for the moon and hitting their feet.

— Bobby Sandell and James T. Nord of CloudBees

Docker
Image Lifecycle Implemented with Jenkins Pipeline

September 15th 11:30 AM - 12:15 PM, Exhibit Hall A-2

While Docker has enabled an unprecedented velocity of software production, it
is all too easy to spin out of control. A promotion-based model is required to
control and track the flow of Docker images as much as it is required for a
traditional software development lifecycle. We will demonstrate how to go from
development to containerization to distribution utilizing binary management
promotion in a framework implemented on Jenkins, using the Pipeline
functionality.

— Mark Galpin

Directions for Pipeline

September 15th 11:30 AM - 12:15 PM, Exhibit Hall A-1

The Pipeline feature has matured and is now included in Jenkins 2.0. During the
time since its release, copious user feedback has been received about missing
features and pain points. Come hear about some things we know should be worked
on - or are already in progress - and bring your suggestions.

— Jesse Glick of CloudBees

How
to Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes

September 15th 2:30 PM - 3:15 PM, Great America J

In this talk, we’ll show how to use Jenkins Pipeline together with Docker and
Kubernetes to implement a complete end-to-end continuous delivery and
continuous improvement system for microservices and monolithic applications
using open source software. We’ll demonstrate how to easily create new
microservices projects or import existing projects, have them automatically
built, system and integration tested, staged and then deployed. Once deployed,
we will also see how to manage and update applications using continuous
delivery practices along with integrated ChatOps - all completely automated!

— James Strachan of Red Hat

Introducing
a New Way to Define Jenkins Pipelines

September 15th 3:45 PM - 4:30 PM, Great America J

Pipeline is quickly establishing itself as the direction that Jenkins jobs are
going, enabling the definition of a complete CD pipeline in a single job;
Pipeline as Code via the “Jenkinsfile”; job durability across controller restarts;
and more. I’ll be talking here about the next evolution for Pipeline: a simple,
declarative model to define your Pipelines with no need to write scripts. This
configuration syntax for Pipeline allows you to automatically configure all
stages of your pipeline, the complete build environment, post-build actions,
notifications and more. All while providing syntactic and semantic validation
before the build actually gets going.

— Andrew Bayer of CloudBees

The
Need For Speed: Building Pipelines To Be Faster

September 15th 4:45 PM - 5:30 PM, Exhibit Hall A-1

Response time is paramount for a CI/CD system. In this session, you will see
how a few best practices in constructing pipelines can yield faster turnaround
times and reduced resource use. We’ll also run through plugins and tools to
analyze and visualize performance, including the Pipeline Stage View plugin. If
time permits, we may briefly discuss some of the computer science theory behind
different aspects of performance.

— Sam Van Oort of CloudBees

Continuously Delivering
Continuous Delivery Pipelines

September 15th 4:45 PM - 5:30 PM, Exhibit Hall J

Our 600-person IT organization has committed to implementing continuous
delivery practices enterprise-wide. This isn’t a single momentous event put in
place overnight. Rather, it’s a strategic journey towards a common goal, and
through which each application will take its own unique path. A seminal
component of our CD journey is the Pipeline plugin and it has become our
standard for CD pipeline orchestration. We will discuss a few of the diverse
paths taken by the application teams at our company and show how the use of the
Pipeline plugin has uniquely enabled continuous delivery for us in a way that
no competing tool can.

— Neil Hunt of Aquilent

CD Pipelines as Code with
Github and Bitbucket

September 15th 4:45 PM - 5:30 PM, Exhibit Hall J

Pipeline Multibranch projects come as a natural evolution of pipeline as code:
define your CD pipeline in your source code repository and Jenkins will create
isolated branch and pull requests jobs for it. This talk is about the
integration of the Pipeline Multibranch plugin with Github and Bitbucket as
branch sources.

— Antonio Muñiz of CloudBees

Register for Jenkins World in
September with the code JWFOSS for a 20% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/08/continuous-delivery-of-infra/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 8</div></div><h5 class="title">Continuous Delivery of Infrastructure with Jenkins</h5></div><p class="teaser">This is a guest post by Jenkins World speaker
R Tyler Croy, infrastructure maintainer for the
Jenkins project.

I don’t think I have ever met a tools, infrastructure, or operations team that
did not have a ton of work to do. The Jenkins project’s
infrastructure&quot;team&quot; is no different; too much work, not enough time. In lieu of hiring more
people, which isn’t always an option, I have found heavy automation and
continuous delivery pipelines to be two solutions within reach of the
over-worked infrastructure team.

As a big believer in the concept of &quot;Infrastructure as Code&quot;, I have been,
slowly but surely, moving the project’s infrastructure from manual tasks to
code, whether implemented in our
Puppet code-base,
Docker containers,
or even as
machine specifications
with
Packer.
The more of our infrastructure that is code, the more we can apply continuous
delivery practices to consistently and reliably build, test and deliver our
infrastructure.

This approach integrates nicely with
Jenkins Pipeline,
allowing us to also define our continuous delivery pipelines themselves as
code. For example, by sanity-checking our BIND zone files:

Jenkinsfile

node(&#x27;docker&#x27;) {
    def dockerImage = &#x27;rtyler/jenkins-infra-builder&#x27;

    checkout scm
    docker.image(dockerImage).inside {
        sh &quot;/usr/sbin/named-checkzone jenkins-ci.org dist/profile/files/bind/jenkins-ci.org.zone&quot;
        sh &quot;/usr/sbin/named-checkzone jenkins.io dist/profile/files/bind/jenkins.io.zone&quot;
    }
}

Or delivering our Docker containers automatically to
Docker Hub, with a Jenkinsfile such as:

Jenkinsfile

node(&#x27;docker&#x27;) {
    checkout scm

    /* Get our abbreviated SHA-1 to uniquely identify this build */
    def shortCommit = sh(script: &#x27;git rev-parse HEAD&#x27;, returnStdout: true).take(6)

    stage &#x27;Build ircbot&#x27; {
        withEnv([&quot;JAVA_HOME=${tool &#x27;jdk8&#x27;}&quot;, &quot;PATH+MVN=${tool &#x27;mvn&#x27;}/bin&quot;]) }
            sh &#x27;make bot&#x27;
        }
    }

    def whale
    stage &#x27;Build container&#x27; {
        whale = docker.build(&quot;jenkinsciinfra/ircbot:build${shortCommit}&quot;)
    }

    stage &#x27;Deploy container&#x27; {
        /* Push to Docker Hub */
        whale.push()
    }
}

In
my talk at Jenkins World
(September 14th, 3:00 - 3:45pm in Exhibit Hall A-1) I will discuss these
Jenkinsfiles along with some of the strategies, patterns and code used with the
Jenkins project’s
open source
infrastructure to get the most out of the team’s limited time.

R Tyler will be
presenting
more about continous delivery of infrastructure at
Jenkins World
in September.  Register with the code JWFOSS for 20% off your full conference
pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/09/take-the-2016-jenkins-survey-blog/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 9</div></div><h5 class="title">Take the 2016 Jenkins Survey!</h5></div><p class="teaser">This is a guest post by Brian
Dawson on behalf of CloudBees, where he works as a DevOps Evangelist
responsible for developing and sharing continuous delivery and DevOps best
practices. He also serves as the CloudBees Product Marketing Manager for
Jenkins.

Once again it’s that time of year when CloudBees sponsors the
Jenkins Community Survey to
assist the community with gathering objective insights into how jenkins is
being used and what users would like to see in the Jenkins project.

Your personal information (name, email address and company) will NOT be used by CloudBees for
sales or marketing.

As an added incentive to take the survey, CloudBees will enter participants
into a drawing for a free pass to Jenkins World 2017 (1st prize) and a $100
Amazon Gift Card (2nd prize). The survey will close at the end of September, so
click the link at the end of the blog post to get started!

All participants will be able to access reports summarizing survey results. If
you’re curious about what insights your input will provide, see the results of
last year’s 2015 survey:

2015 Community Survey Results (PDF)

State of Jenkins Infographic (PDF)

Your feedback helps capture a bigger picture of
community trends and needs. There are laws that govern prize giveaways and
eligibility; CloudBees has compiled all those fancy
terms and conditions here.

Please take the survey and let your voice be heard - it will take less than 10
minutes.

Take me to the survey<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/bvdawson/">Brian Dawson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/19/blueocean-beta-declarative-pipeline-pipeline-editor/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">19</div></div><h5 class="title">Announcing the Blue Ocean beta, Declarative Pipeline and Pipeline Editor</h5></div><p class="teaser">At Jenkins World on Wednesday 14th of September, the Jenkins project was happy to
introduce the beta release of Blue Ocean. Blue Ocean is the new user experience
for Jenkins, built from the ground up to take advantage of Jenkins Pipeline.
It is an entire rethink of the the way that modern developers will use Jenkins.

Blue Ocean is available today via the Jenkins Update Center for Jenkins users
running 2.7.1 and above.

Get the beta

Just search for BlueOcean beta in the Update Center, install it,
browse to the dashboard, and then click the Try BlueOcean UI button on the dashboard.

Whats included?

Back in April we open sourced Blue Ocean
and shared our vision with the community. We’re very happy that all the things we showed you then have
shipped in the beta (software projects run on time?!).

For a refresher on Blue Ocean, watch this short video:

Declarative Pipeline

We have heard from the community about the usability of Jenkins
Pipeline. Much of the feedback we received was to a desire to
configure Pipelines rather than script them, and to make it easy for beginners
to get started with their first Pipeline.

This is how Declarative Pipeline was born. We’ve introduced a new method whereby
you declare how you want your Pipeline to look rather than using Pipeline Script
 - it’s configuration rather than code.

Here’s a small example of a Declarative Pipeline for nodejs that runs the whole
Pipeline inside a Docker container:

// Declarative //
pipeline {
  agent docker:&#x27;node:6.3&#x27;
  stages {
    stage(&#x27;build&#x27;) {
      sh &#x27;npm --version&#x27;
      sh &#x27;npm install&#x27;
    }
    stage (&#x27;test&#x27;) {
      sh &#x27;npm test&#x27;
    }
  }
}

// Script //
node(&#x27;docker&#x27;) {
  docker.image(&#x27;node:6.3&#x27;).inside {
    stage(&#x27;build&#x27;) {
      sh &#x27;npm --version&#x27;
      sh &#x27;npm install&#x27;
    }

    stage(&#x27;test&#x27;) {
      sh &#x27;npm test&#x27;
    }
  }
}

Docker support in Declarative Pipeline allows you to version your application code,
Jenkins Pipeline configuration, and the environment where your pipeline will run,
all in a single repository. It’s a crazy powerful combination.

Declarative Pipeline introduces the postBuild section that makes it
easy to run things conditionally at the end of your Pipeline without the
complexity of the try…​ catch of Pipeline script.

// Declarative //
postBuild {
  always {
    sh &#x27;echo &quot;This will always run&quot;&#x27;
  }
  success {
    sh &#x27;echo &quot;This will run only if successful&quot;&#x27;
  }
  failure {
    sh &#x27;echo &quot;This will run only if failed&quot;&#x27;
  }
  unstable {
    sh &#x27;echo &quot;This will run only if the run was marked as unstable&quot;&#x27;
  }
  changed {
    sh &#x27;echo &quot;This will run only if the state of the Pipeline has changed&quot;&#x27;
    sh &#x27;echo &quot;For example, the Pipeline was previously failing but is now successful&quot;&#x27;
    sh &#x27;echo &quot;... or the other way around :)&quot;&#x27;
  }
}


// Script //
node(&#x27;docker&#x27;) {
  try {
    stage(&#x27;build&#x27;) {
      /* .. snip .. */
    }
    stage(&#x27;test&#x27;) {
      /* .. snip .. */
    }

    sh &#x27;echo &quot;This will run only if successful&quot;&#x27;
  }
  catch (exc) {
    if (currentBuild.result == &#x27;UNSTABLE&#x27;) {
      sh &#x27;echo &quot;This will run only if the run was marked as unstable&quot;&#x27;
    }
    if (currentBuild.result == &#x27;FAILURE&#x27;) {
      sh &#x27;echo &quot;This will run only if failed&quot;&#x27;
    }
  }
  finally {
    sh &#x27;echo &quot;This will always run&quot;&#x27;
  }
}

And there is so much more!

If you have the Blue Ocean beta installed you already have Declarative Pipeline.
While Declarative Pipeline is still alpha at the moment, we do encourage you to
follow our getting started guide,
 give us feedback on the Jenkins Users mailing list
or file bugs against the &#x27;pipeline-model-definition&#x27; component in JIRA.

Introducing the Pipeline Editor

The Pipeline Editor is a graphical user interface that gives Jenkins users the
simplest way yet to get started with creating Pipelines in Jenkins. It will also
save a lot of time for intermediate and advanced Jenkins users as a way to author
Pipelines.

When you build your Pipeline in the Editor and click the save button, the editor
will commit a new Jenkinsfile back to your repository in the form of the new
Declarative Pipeline. When you want to edit again, Jenkins will read it from
your repository exactly how you saw it previously.

The Pipeline Editor is a work in progress and should arrive in a beta release soon.

Thank you

Thanks for reading our news from Jenkins World and be sure to check the blog
for regular updates!

I’d also like to thank our amazing community for their feedback and support
as we change the way software teams around the world use Jenkins. We couldn’t
do this without you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/i386/">James Dumay</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/20/jom-plugin-development/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">20</div></div><h5 class="title">Jenkins Online Meetup report. Plugin Development - WebUI</h5></div><p class="teaser">On September 6th we had a Jenkins Online Meetup.
This meetup was the second event in the series of Plugin Development meet ups.
At this meetup we were talking about Jenkins Web UI development.

Talks

1) Classic Jenkins UI framework -
Daniel Beck

In the first part of his talk, Daniel presented how Stapler, the web framework used in Jenkins, works, and how you can add to the set of URLs handled by Jenkins.
In the second part he was talking about creating new views using Jelly and Groovy, and how to add new content to existing views.

Keywords:
Stapler,
Jelly,
Groovy-defined UIs

2) Developing modern Jenkins UIs with Javascript -
Tom Fennelly

Feel that Jenkins UI is a bit old? You are not alone.
In addition to the old stack Jenkins offers a framework for writing UI components in Javascript with help of Node.js.
Tom presented this new engine, which is being used in new Jenkins Web UI components like Jenkins installation wizard.
He also provided several examples from the BlueOcean project he is working on.

Keywords:
Node.js,
ReactJS,
Jenkins JS Builder,
Jenkins Design Language,
Blue Ocean

Links

Meetup page

Event page: Plugin Development. Web UI

Webinar recording

Want to conduct a meetup?

We are looking for speakers, who would be interested to share their experience about Jenkins best-practices, war stories and plugin development.

If you are interested to conduct a presentation,
please contact meetup organizers using meetup.com “contact organizers” feature
or via the events@lists.jenkins-ci.org mailing list.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/21/jenkins-world-2016-wrap-up/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">21</div></div><h5 class="title">Jenkins World 2016 Wrap-up - Introduction</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

That’s a Wrap!

Any way you look at it, last week’s Jenkins World Conference 2016 was a huge success.

In 2011, a few hundred users gathered in San Francisco for the first &quot;Jenkins User Conference&quot;.
Over successive years, this grew into several yearly regional Jenkins user conferences.
This year, over 1,300 people came from around the world to &quot;Jenkins World 2016&quot;,
the first global event for the Jenkins community.

This year’s Jenkins World conference included:

Keynote presentation by Jenkins creator, Kohsuke Kawaguchi, announcing a number of great new Jenkins project features, such as &quot;Blue Ocean&quot;.

More than 50 sessions on everything from the new &quot;Blue Ocean&quot; UI, to &quot;Continuous Security&quot; to &quot;Dockerizing Jenkins&quot;.

Jenkins Open-source Hub, with &quot;Ask the Experts&quot; and demos by 20+ Jenkins contributors.

Booths from 30+ sponsors.

Stickers!

Over the next week, I’ll be posting highlights from the event,
including slides, videos, and links to other useful resources.  Stay tuned!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/24/jenkins-world-2016-wrap-up-pipeline/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">24</div></div><h5 class="title">Jenkins World 2016 Wrap-up - Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

As someone who has managed Jenkins for years and manually managed jobs, I think
pipeline is fantastic. I spent much of the conference manning the
Ask the Experts desk of the
&quot;Open Source Hub&quot; and was glad to find I was not alone in that sentiment.
The questions were not &quot;Why should I use Pipeline?&quot;, but &quot;How do I do this in Pipeline?&quot;

Everyone was interested in showing what they have been able to accomplish,
learning about best practices, and seeing what new features were on the horizon.
The sessions and demos on Pipeline that
I saw were all well attended, but no one could have seen all of them.

Here’s a recap of the some of the sessions on Jenkins Pipeline,
with links to slides and videos shared by CloudBees :

Jesse Glick discussed the past, present, and future of Jenkins Pipeline in
Directions for Pipeline .
He reviewed a broad range of improvements made to Pipeline over the last year, including
syntax, documentation, plugin support, and stability.  He reviewed the changes
currently underway.  He also pointed out that many of the improvements have been
driven by user feedback and invited everyone to continue to participate in making
pipeline even better.

Download Presentation

Stream Presentation

In
Pipelining DevOps with Jenkins and AWS ,
Jimmy Ray
of
nextSource showed how Pipeline can be used to automate CI/CD build processes,
and how to integrate Jenkins and Pipeline with AWS.
He also discussed some admin-level considerations,
such as how to install Jenkins on EC2
and the merits of &quot;LTS&quot; and &quot;latest build&quot;.

Download Presentation

Stream Presentation

Christopher Orr examined how to create
&quot; Continuous Build and Delivery Pipelines for Android &quot;
applications.
He showed how to set up Android-capable build agents, ensure traceable application releases,
reporting warnings, run various types of tests, and deploy and app to Google Play.
This included live demonstrations and discussion of best practices.

Download Presentation

Stream Presentation

Andrew Bayer presented
A New Way to Define Jenkins Pipelines .
He showed the next evolution for Pipeline, based on a simpler declarative model.
This declarative syntax for Pipeline still supports the creation of complex pipelines,
including complete build environments, post-build actions, and notifications, while
also being easier to understand. This declarative syntax also makes in it easier to
implement other interesting scenarios such as early validation of pipelines and
a visual pipeline editor.

Download Presentation

Stream Presentation

In
Perfecting Your Development Tools: Updates to the Helix Plugin for Jenkins ,
Paul Allen of
Perforce walked through using Perforce’s &quot;Monorepo&quot; model with Jenkins Pipeline.
He explained in detail how to work with the Perforce&quot;P4&quot; plugin in Jenkins,
including credential passing and workspace management.
Of particular interest was his side-by-side comparison the various actions done with the Jenkins UI vs Pipeline.

Download Presentation

Sam Van Oort
demonstrated strategies for faster pipelines in
The Need For Speed: Building Pipelines To Be Faster .
He discussed various elements that contribute to making pipelines faster or slower,
such a number of resources and latency.  He then showed several best practices
for constructing pipelines that have lower turnaround times and reduced resource use.
He also reviewed plugins and tools that can help analyze and visualize pipeline
performance, including the Pipeline Stage View plugin and Blue Ocean.

Download Presentation

Stream Presentation

Bobby Sandell and
James T. Nord talked about what not to do with Pipeline in
No, You Shouldn’t Do That! Lessons from Using Pipeline .
They told the story of their own experiences as early adopters of
Jenkins Pipeline at CloudBees. They described a number of key scenarios they attempted
to address, detailed various mistakes and false starts, and finally share what
they learned in each case.

Download Presentation

Stream Presentation

Alexandru Somai gave a
lightning talk on his
Google Summer of Code (GSoC) 2016 project,
&quot; External Workspace Manager Plugin for Jenkins Pipeline&quot;.
The build workspace for Jenkins projects may become very large.
Alex showed how the External Workspace Manager plugin addresses this issue,
adding support for managing and reusing the same workspace between multiple pipeline builds.

A recording of his presentation for GSOC is available
here.

How to Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes ,
presented by
James Strachan of
Red Hat, showed how to use Jenkins Pipeline with
Docker and Kubernetes to implement a complete end-to-end continuous delivery and
continuous improvement system using open source software for both microservices
and monolithic applications. He demonstrated how to
create or import projects, and have them automatically build, run
system and integration tests, stage, and finally deploy. He also showed to
manage and update those deployed applications using continuous
delivery practices.

Download Presentation

Stream Demo Video<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/27/jenkins-world-2016-wrap-up-scaling/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">27</div></div><h5 class="title">Jenkins World 2016 Wrap-up - Scaling</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

One of the great features of Jenkins is how far it
can scale, not only from a software perspective, but also from an
organizational one.  From a single Jenkins controller with one or two agents to a
multiple controller with thousands of agents, from a team of only a few people
to a whole company with multiple disparate departments and organizations,
you’ll find space where Jenkins is used.

Like any software or organization,
there are common challenges for increasing scale with Jenkins and some common best practices, but
there are also some unique solutions.  A big conference like
Jenkins World brings users
from all scales together to see how people in other organizations at similar or
greater scale are solving similar problems.

Here’s a recap of the some of the sessions on scaling Jenkins,
with links to slides and videos shared by CloudBees :

Paul Miles and
Grant Dickie of
NPR talked about
JenkinsOps: An Initiative to Streamline and Automate Jenkins .
They shared ways their team has used Jenkins to automate many of the
administrative tasks related to managing feature code branches,
handling deployments, running tests, and properly configuring their environments.
They also showed code samples and talked about future challenges in their quest
to achieve
continuous deployment.

Download Presentation

Stream Presentation

Maxfield F Stewart of
Riot Games showed how they built an
integrated Docker solution using Jenkins in
Thinking Inside the Container: A Continuous Delivery Story
He showed how their system allows engineers around the company to
submit Docker images as build environments.
This has let their containerized farm now create over 10,000 containers per week
and handles nearly 1,000 jobs at a rate of about 100 jobs per hour.
And they have done this using readily available, open
source Jenkins plugins. He also talked about how they settled on this design,
lessons learned, best practices, and how to build and scale other similar system.

Download Presentation

Stream Presentation

How to Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes ,
presented by
James Strachan of
Red Hat, showed how to use Jenkins Pipeline with
Docker and Kubernetes to implement a complete end-to-end continuous delivery and
continuous improvement system using open source software for both microservices
and monolithic applications. He demonstrated how to
create or import projects, and have them automatically build, run
system and integration tests, stage, and finally deploy. He also showed to
manage and update those deployed applications using continuous
delivery practices.

Download Presentation

Watch the Video Demo from the Presentation

Carlos Sanchez of
CloudBees discussed
Scaling Jenkins with Docker: Swarm, Kubernetes or Mesos?
He compared various Docker Swarm, Apache Mesos, and Kubernetes in terms of their
ability to dynamically scale in Jenkins by running jobs inside containers.
He also discussed the pros and cons, best practices, level of Jenkins support for each
of these technologies.

Download Presentation

Stream Presentation

Stephen Connolly of
CloudBees asked
&quot; So, You Want to Build the World’s Biggest Jenkins Cluster? &quot;
and explained how to do so.  He started with
real world results realized by Jenkins users who have built large clusters.
Next, he showed experiments around scaling some individual sub-components of Jenkins in
isolation to see what challenges have been faced when integrated. Finally,
he arrived at recipes for building Jenkins clusters with different scaling capabilities and
making existing Jenkins clusters more efficient.

Download Presentation

Stream Presentation

Bill Houston and
Ali Raza of
Splunk
gave a talk in two parts,
Jenkins at Splunk and Splunking Jenkins
In the first part, Bill showed how Splunk uses Jenkins to implement their end-to-end CI system.
They discussed features and design goals, challenges they encountered, and how they addressed
these challenges.
In the second part, Ali showed how to use the Jenkins Splunk plugin.  Using plugin, he gathered
test results and Jenkins environment data, and delivered it to a Splunk indexer for analysis and presentation.

Download Presentation

Stream Presentation

David Hoover of
Google talked about
Jenkins inside Google .
Last year, they
presented
their initial investigations and stress testing as they
prepared to deploy a large-scale Jenkins installation at Google. Now, with a
year of real-world use under their belts, they returned to present on how their
expectations held up, what new issues they encountered, how they have addressed those issues, and
the challenges and opportunities they see ahead.

Download Presentation

Stream Presentation<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/29/jenkins-world-2016-wrap-up-experts-demos/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">29</div></div><h5 class="title">Jenkins World 2016 Wrap-up - Ask the Experts &amp; Demos</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

As I mentioned in my
previous post,
Jenkins World brought together
Jenkins users from organizations of all sizes.  It also brought together Jenkins
users of all skill levels; from beginners to experts (including to JAM
organizers, board members, and long time contributors).  A number
of those experts also volunteered to staff the Open Source Hub’s
&quot;Ask the Experts&quot; desk throughout the conference to answer Jenkins questions.
This included, but was not limited to:
Paul Allen,
R Tyler Croy,
James Dumay,
Jesse Glick,
Eddú Meléndez Gonzales,
Jon Hermansen,
Owen Mehegan,
Oleg Nenashev,
Liam Newman,
Christopher Orr,
Casey Vega,
Mark Waite,
Dean Yu,
and
Keith Zantow.

I actually chose to spend the majority of my time at the booth. It was
fantastic to hear all the different ways people are using
Jenkins and wanting use Jenkins to do even more. I answered dozens of questions
on both days of the conference, often learning new things in the process of answering them.
And for questions that were beyond any one person’s knowledge, there was such a
breadth of expertise, very few questions were beyond our combined abilities.

While &quot;Ask the Experts&quot; saw a lot traffic, the Open Source Hub’s lunch-time demos drew
really big crowds. They covered wide range of subjects in a quick succession and offered people
a chance to be introduced to new areas of in Jenkins without spending a whole session on them.
Some demos were only presented at lunch while others were abbreviated versions of
longer talks presented at other times during the conference.  Here’s the full list with related links:

Keith Zantow gave a live demo of
Blue Ocean in Action on their
live Jenkins instance.

Christopher Orr presented a lightning version of his talk
Pipelines for building and deploying Android apps
( Slides)
( video).

Oleg Nenashev showed a different way to
manage security with the
Ownership plugin for Jenkins
( Slides).

Alex Somai presented his
Google Summer of Code (GSoC) 2016 project, the
External Workspace Manager plugin for Jenkins Pipeline ( GSOC Video).

Mark Waite discussed
Git plugin - large repos, submodule authentication and more
( Slides).

Liam Newman gave a live demo of
Notifications with Jenkins Pipeline
(based on this blog post).

Jesse Glick talked about
Extending Pipeline with Libraries using the
Pipeline Shared Groovy Libraries Plugin

Jon Hermansen demonstrated some cool ways to use
Multibranch Pipelines + Git symbolic-ref to optimize build times.

R Tyler Croy showed the power of
Docker and Pipeline
( Slides)

R Tyler Croy also showed how easy it can be to migrate from
Freestyle to Pipeline
( Slides)

Casey Vega gave a live demo,
package.json and Jenkins, on using package.json to control all aspects of Jenkins builds.

Andrew Bayer presented at lightning version of his talk,
A simpler way to define Jenkins Pipelines
( Slides)
( Video).

Thank you to everyone who staffed the booth and gave demos.

Also, thanks to everyone who attended the demos and came by to ask questions.
If you have more questions, you don’t have to wait until next year’s Jenkins World.
Join the
jenkinsci-users mailing list or the
#jenkins IRC channel to
get help from experts around the world.

And finally, a special thanks to the Jenkins Events officer, Alyssa Tong,
for getting the entire booth designed, prepared, and keeping everything
on track before, during, and after the conference.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/09/30/jenkins-world-2016-wrap-up-complete/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">30</div></div><h5 class="title">Jenkins World 2016, That&#x27;s a Wrap!</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

This year’s Jenkins World conference
was a huge milestone for the Jenkins project - the first global event for the Jenkins community.
It brought users and contributors together to exchange ideas on the current state
of the project, celebrate accomplishments of the past year, and look ahead at all the exiting enhancements
coming down the pipe(line).

Contributor Summit

To kick off Jenkins World, we had a full day &quot;Contributor Summit&quot;.
Jenkins is a distributed project with contributors from all over the globe.
Conferences like this are perfect time to get contributors together face-to-face,
to talk through current issues and upcoming plans for the the project.
Some key topics discussed during this summit were:

Infrastructure - In the past year, the Jenkins project has moved new domain name,
a statically generated website, and has entered a
partnership with Microsoft
to host to host infrastructure on Azure.

Events - A year ago, there were five
Jenkins Area Meetups, today there are 37 around the
world, with ~7000 members.

Security - Daniel Beck has done a great job a &quot;Security Officer&quot; for the project over the last year.
Jenkins 2 includes tighter security out of the box, 9 security alerts have been addressed, and the
Security Team is continuing to evaluate threats as they are reported.

Pipeline - Pipeline has been a success and there many improvements on the way, including better
Pipeline Library support, a UI-based Pipeline Editor, and Declarative Pipeline syntax.

Blue Ocean - Blue Ocean announced their &quot;1.0 Beta&quot; release and discussed their roadmap.

Storage Pluggability - One of the big upcoming goals is reducing Jenkins&#x27;
dependence on local file system storage on the server system
(job configuration, build logs, etc.).  There was extensive
discussion of how to accomplish this goal.

Keynote: The State of Jenkins 2016

The next day,
Kohsuke gave a great
keynote,
showing how far the project as come this year and where it is headed.
You can get the slides
here
or see the full video below.

What’s Next?

Overall, Jenkins World was a very enjoyable event. I’m sure everyone came away having
learned a lot and made many new connections.  I know I’m excited to see
what the coming year brings for Jenkins and the Jenkins community.

Don’t forget that there are many ways to continue
to build connections to the rest of the Jenkins community throughout the year, such as the
Jenkins Online Meetup which
hosts online events year-round.  Or, see if there is a
Jenkins Area Meetup (JAM) near you.  If
there isn’t, take a look at the
Jenkins Area Meetup page to see about starting one.

Thanks, and I hope to see you all and Jenkins World 2017!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/10/16/stage-lock-milestone/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">16</div></div><h5 class="title">Controlling the Flow with Stage, Lock, and Milestone</h5></div><p class="teaser">This is a guest post by Patrick Wolf,
Director of Product Management at CloudBees.

Recently the Pipeline team began making several changes to improve the stage step and increase control of concurrent builds in Pipeline. Until now the stage step has been the catch-all for functionality related to the flow of builds through the Pipeline: grouping build steps into visualized stages, limiting concurrent builds, and discarding stale builds.

In order to improve upon each of these areas independently we decided to break this functionality into discrete steps rather than push more and more features into an already packed stage step.

stage - the stage step remains but is now focused on grouping steps and providing boundaries for Pipeline segments.

lock - the lock step throttles the number of concurrent builds in a defined section of the Pipeline.

milestone - the milestone step automatically discards builds that will finish out of order and become stale.

Separating these concerns into explicit, independent steps allows for much greater control of Pipelines and broadens the set of possible use cases.

Stage

The stage step is a primary building block in Pipeline, dividing the steps of a Pipeline into explicit units and helping to visualize the progress using the &quot;Stage View&quot; plugin or&quot;Blue Ocean&quot;. Beginning with version 2.2 of &quot;Pipeline Stage Step&quot; plugin, the stage step now requires a block argument, wrapping all steps within the defined stage. This makes the boundaries of where each stage begins and ends obvious and predictable. In addition, the concurrency argument of stage has now been removed to make this step more concise; responsibility for concurrency control has been delegated to the lock step.

stage(&#x27;Build&#x27;) {
  doSomething()
  sh &quot;echo $PATH&quot;
}

Omitting the block from stage and using the concurrency argument are now deprecated in Pipeline. Pipelines using this syntax will continue to function but will produce a warning in the console log:

Using the &#x27;stage&#x27; step without a block argument is deprecated

This message is only a reminder to update your Pipeline scripts; none of your Pipelines will stop working. If we reach a point where the old syntax is to be removed we will make an announcement prior to the change. We do, however, recommend that you update your existing Pipelines to utilize the new syntax.

note: Stage View and Blue Ocean will both work with either the old stage syntax or the new.

Lock

Rather than attempt to limit the number of concurrent builds of a job using the stage, we now rely on the &quot;Lockable Resources&quot; plugin and the lock step to control this. The lock step limits concurrency to a single build and it provides much greater flexibility in designating where the concurrency is limited.

lock can be used to constrain an entire stage or just a segment:

stage(&#x27;Build&#x27;) {
  doSomething()
  lock(&#x27;myResource&#x27;) {
    echo &quot;locked build&quot;
  }
}

lock can be also used to wrap multiple stages into a single concurrency unit:

lock(&#x27;myResource&#x27;) {
  stage(&#x27;Build&#x27;) {
    echo &quot;Building&quot;
  }
  stage(&#x27;Test&#x27;) {
    echo &quot;Testing&quot;
  }
}

Milestone

The milestone step is the last piece of the puzzle to replace functionality originally intended for stage and adds even more control for handling concurrent builds of a job. The lock step limits the number of builds running concurrently in a section of your Pipeline while the milestone step ensures that older builds of a job will not overwrite a newer build.

Concurrent builds of the same job do not always run at the same rate. Depending on the network, the node used, compilation times, test times, etc. it is always possible for a newer build to complete faster than an older build. For example:

Build 1 is triggered

Build 2 is triggered

Build 2 builds faster than Build 1 and enters the Test stage sooner.

Rather than allowing Build 1 to continue and possibly overwrite the newer artifact produced in Build 2, you can use the milestone step to abort Build 1:

stage(&#x27;Build&#x27;) {
  milestone()
  echo &quot;Building&quot;
}
stage(&#x27;Test&#x27;) {
  milestone()
  echo &quot;Testing&quot;
}

When using the input step or the lock step a backlog of concurrent builds can easily stack up, either waiting for user input or waiting for a resource to become free. The milestone step will automatically prune all older jobs that are waiting at these junctions.

milestone()
input message: &quot;Proceed?&quot;
milestone()

Bookending an input step like this allows you to select a specific build to proceed and automatically abort all antecedent builds.

milestone()
lock(resource: &#x27;myResource&#x27;, inversePrecedence: true) {
  echo &quot;locked step&quot;
  milestone()
}

Similarly a pair of milestone steps used with a lock will discard all old builds waiting for a shared resource. In this example, inversePrecedence: true instructs the lock to begin most recent waiting build first, ensuring that the most recent code takes precedence.

Putting it all together

Each of these steps can be used independently of the others to control one aspect of a Pipeline or they can be combined to provide powerful, fine-grained control of every aspect of multiple concurrent builds flowing through a Pipeline. Here is a very simple example utilizing all three:

stage(&#x27;Build&#x27;) {
  // The first milestone step starts tracking concurrent build order
  milestone()
  node {
    echo &quot;Building&quot;
  }
}

// This locked resource contains both Test stages as a single concurrency Unit.
// Only 1 concurrent build is allowed to utilize the test resources at a time.
// Newer builds are pulled off the queue first. When a build reaches the
// milestone at the end of the lock, all jobs started prior to the current
// build that are still waiting for the lock will be aborted
lock(resource: &#x27;myResource&#x27;, inversePrecedence: true){
  node(&#x27;test&#x27;) {
    stage(&#x27;Unit Tests&#x27;) {
      echo &quot;Unit Tests&quot;
    }
    stage(&#x27;System Tests&#x27;) {
      echo &quot;System Tests&quot;
    }
  }
  milestone()
}

// The Deploy stage does not limit concurrency but requires manual input
// from a user. Several builds might reach this step waiting for input.
// When a user promotes a specific build all preceding builds are aborted,
// ensuring that the latest code is always deployed.
stage(&#x27;Deploy&#x27;) {
  input &quot;Deploy?&quot;
  milestone()
  node {
    echo &quot;Deploying&quot;
  }
}

For a more complete and complex example utilizing all these steps in a Pipeline check out the Jenkinsfile provided with the Docker image for demonstrating Pipeline. This is a working demo that can be quickly set up and run.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hrmpw/">Patrick Wolf</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/newfeatures">newfeatures</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/10/18/jenkins-world-2016-videos/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">18</div></div><h5 class="title">Jenkins World 2016 Session Videos</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

The videos of the sessions from
Jenkins World 2016 are up!

I’ve updated the wrap-up posts with links to each of the sessions mentioned:

Jenkins Pipeline

Scaling Jenkins

Ask the Experts &amp; Demos

You can also find video from all the sessions
here.  Enjoy!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2016">jenkinsworld2016</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/10/31/xunit-reporting/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">31</div></div><h5 class="title">xUnit and Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

The
JUnit plugin
is the go-to test result reporter for many Jenkins projects,
but the it is not the only one available.  The
xUnit plugin
is a viable alternative that supports JUnit and many other test result file formats.

Introduction

No matter the project, you need to gather and report test results.
JUnit is one of the most widely supported formats for recording test results.
For a scenarios where your tests are stable and your framework can produce JUnit output,
this makes the JUnit plugin ideal for reporting results in Jenkins.
It will consume results from a specified file or path, create a report,
and if it finds test failures it will set the the job state to &quot;unstable&quot; or &quot;failed&quot;.

There are also plenty of scenarios where the JUnit plugin is not enough.
If your project has some failing tests that will take some time to fix,
or if there are some flaky tests,
the JUnit plugin’s simplistic view of test failures may be difficult to work with.

No problem, the Jenkins plugin model lets us replace the JUnit
plugin functionality with similar
functionality from another plugin and Jenkins Pipeline lets us do this in safe
stepwise fashion where we can test and debug each of our changes.

In this article, I will show you how to replace the JUnit plugin with the
xUnit plugin in Pipeline code to address a few common test reporting scenarios.

Initial Setup

I’m going to use the &quot;JS-Nightwatch.js&quot; sample project from my
previous post to demonstrate a couple
common scenarios that the xUnit handles better.
I already have the latest
JUnit plugin
and
xUnit plugin
installed on my Jenkins server.

I’ll be keeping my changes in
link: my fork
of the &quot;JS-Nightwatch.js&quot; sample project on GitHub, under the
&quot; blog/xunit&quot; branch.

Here’s what the Jenkinsfile looked like at the end of that previous post and what
the report page looks like after a few runs:

Jenkinsfile

node {
    stage &quot;Build&quot;
    checkout scm

    // Install dependencies
    sh &#x27;npm install&#x27;

    stage &quot;Test&quot;
    // Add sauce credentials
    sauce(&#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;) {
        // Start sauce connect
        sauceconnect(options: &#x27;&#x27;, useGeneratedTunnelIdentifier: false, verboseLogging: false) {

            // List of browser configs we&#x27;ll be testing against.
            def platform_configs = [
                &#x27;chrome&#x27;,
                &#x27;firefox&#x27;,
                &#x27;ie&#x27;,
                &#x27;edge&#x27;
            ].join(&#x27;,&#x27;)

            // Nightwatch.js supports color ouput, so wrap this step for ansi color
            wrap([$class: &#x27;AnsiColorBuildWrapper&#x27;, &#x27;colorMapName&#x27;: &#x27;XTerm&#x27;]) {
                // Run selenium tests using Nightwatch.js
                // Ignore error codes. The junit publisher will cover setting build status.
                sh &quot;./node_modules/.bin/nightwatch -e ${platform_configs} || true&quot;
            }

            junit &#x27;reports/**&#x27;

            step([$class: &#x27;SauceOnDemandTestPublisher&#x27;])
        }
    }
}

Switching from JUnit to xUnit

I’ll start by replacing JUnit with xUnit in my pipeline.
I use the Snippet Generator to create the step with the right parameters.
The main downside of using the xUnit plugin is that while it is Pipeline compatible,
it still uses the more verbose step() syntax and has some very rough edges around that, too.
I’ve filed
JENKINS-37611
but in the meanwhile, we’ll work with what we have.

// Original JUnit step
junit &#x27;reports/**&#x27;

// Equivalent xUnit step - generated (reformatted)
step([$class: &#x27;XUnitBuilder&#x27;, testTimeMargin: &#x27;3000&#x27;, thresholdMode: 1,
    thresholds: [
        [$class: &#x27;FailedThreshold&#x27;, failureNewThreshold: &#x27;&#x27;, failureThreshold: &#x27;&#x27;, unstableNewThreshold: &#x27;&#x27;, unstableThreshold: &#x27;1&#x27;],
        [$class: &#x27;SkippedThreshold&#x27;, failureNewThreshold: &#x27;&#x27;, failureThreshold: &#x27;&#x27;, unstableNewThreshold: &#x27;&#x27;, unstableThreshold: &#x27;&#x27;]],
    tools: [
        [$class: &#x27;JUnitType&#x27;, deleteOutputFiles: false, failIfNotNew: false, pattern: &#x27;reports/**&#x27;, skipNoTestFiles: false, stopProcessingIfError: true]]
    ])

// Equivalent xUnit step - cleaned
step([$class: &#x27;XUnitBuilder&#x27;,
    thresholds: [[$class: &#x27;FailedThreshold&#x27;, unstableThreshold: &#x27;1&#x27;]],
    tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

If I replace the junit step in my Jenkinsfile with that last step above,
it produces a report and job result identical to the JUnit plugin but using the xUnit plugin.  Easy!

node {
    stage &quot;Build&quot;
    // ... snip ...

    stage &quot;Test&quot;
    // Add sauce credentials
    sauce(&#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;) {
        // Start sauce connect
        sauceconnect(options: &#x27;&#x27;, useGeneratedTunnelIdentifier: false, verboseLogging: false) {

            // ... snip ...

            // junit &#x27;reports/**&#x27;
            step([$class: &#x27;XUnitBuilder&#x27;,
                thresholds: [[$class: &#x27;FailedThreshold&#x27;, unstableThreshold: &#x27;1&#x27;]],
                tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

            // ... snip ...
        }
    }
}

Accept a Baseline

Most projects don’t start off with automated tests passing or even running.
They start with a people hacking and prototyping, and eventually they start to write tests.
As new tests are written, having tests checked-in, running, and failing can be valuable information.
With the xUnit plugin we can accept a baseline of failed cases and drive that number down over time.

I’ll start by changing the Jenkinsfile to fail jobs only if the number of failures is greater than an expected baseline,
in this case four failures. When I run the job with this change, the reported numbers remain the same, but the job passes.

Jenkinsfile

// The rest of the Jenkinsfile is unchanged.
// Only the xUnit step() call is modified.
step([$class: &#x27;XUnitBuilder&#x27;,
    thresholds: [[$class: &#x27;FailedThreshold&#x27;, failureThreshold: &#x27;4&#x27;]],
    tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

Next, I can also check that the plugin reports the job as failed if more failures occur.
Since this is sample code, I’ll do this by adding another failing test and checking the job
reports as failed.

tests/guineaPig.js

// ... snip ...

    &#x27;Guinea Pig Assert Title 0 - D&#x27;: function(client) { /* ... */ },

    &#x27;Guinea Pig Assert Title 0 - E&#x27;: function(client) {
        client
            .url(&#x27;https://saucelabs.com/test/guinea-pig&#x27;)
            .waitForElementVisible(&#x27;body&#x27;, 1000)
            //.assert.title(&#x27;I am a page title - Sauce Labs&#x27;);
            .assert.title(&#x27;I am a page title - Sauce Labs - Cause a Failure&#x27;);
    },

    afterEach: function(client, done) { /* ... */ }

// ... snip ...

In a real project, we’d make fixes over a number of commits bringing the number of failures down and adjusting our baseline.
Since this is a sample, I’ll just make all tests pass and set the job failure threshold for failed and skipped cases to zero.

Jenkinsfile

// The rest of the Jenkinsfile is unchanged.
// Only the xUnit step() call is modified.
step([$class: &#x27;XUnitBuilder&#x27;,
    thresholds: [
        [$class: &#x27;SkippedThreshold&#x27;, failureThreshold: &#x27;0&#x27;],
        [$class: &#x27;FailedThreshold&#x27;, failureThreshold: &#x27;0&#x27;]],
    tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

tests/guineaPig.js

// ... snip ...

    &#x27;Guinea Pig Assert Title 0 - D&#x27;: function(client) { /* ... */ },

    &#x27;Guinea Pig Assert Title 0 - E&#x27;: function(client) {
        client
            .url(&#x27;https://saucelabs.com/test/guinea-pig&#x27;)
            .waitForElementVisible(&#x27;body&#x27;, 1000)
            .assert.title(&#x27;I am a page title - Sauce Labs&#x27;);
    },

    afterEach: function(client, done) { /* ... */ }

// ... snip ...

tests/guineaPig_1.js

// ... snip ...

    &#x27;Guinea Pig Assert Title 1 - A&#x27;: function(client) {
        client
            .url(&#x27;https://saucelabs.com/test/guinea-pig&#x27;)
            .waitForElementVisible(&#x27;body&#x27;, 1000)
            .assert.title(&#x27;I am a page title - Sauce Labs&#x27;);
    },

// ... snip ...

Allow for Flakiness

We’ve all known the frustration of having one flaky test that fails once every ten jobs.
You want to keep it active so you can working isolating the source of the problem,
but you also don’t want to destablize your CI pipeline or reject commits that are actually okay.
You could move the test to a separate job that runs the &quot;flaky&quot; tests,
but in my experience that just leads to a job that is always in a failed state
and a pile of flaky tests no one looks at.

With the xUnit plugin, we can keep the this flaky test in main test suite but allow
the our job to still pass.

I’ll start by adding a sample flaky test.  After a few runs, we can see the test
fails intermittently and causes the job to fail too.

tests/guineaPigFlaky.js

// New test file: tests/guineaPigFlaky.js
var https = require(&#x27;https&#x27;);
var SauceLabs = require(&quot;saucelabs&quot;);

module.exports = {

    &#x27;@tags&#x27;: [&#x27;guineaPig&#x27;],

    &#x27;Guinea Pig Flaky Assert Title 0&#x27;: function(client) {
        var expectedTitle = &#x27;I am a page title - Sauce Labs&#x27;;
        // Fail every fifth minute
        if (Math.floor(Date.now() / (1000 * 60)) % 5 === 0) {
            expectedTitle += &quot; - Cause failure&quot;;
        }

        client
            .url(&#x27;https://saucelabs.com/test/guinea-pig&#x27;)
            .waitForElementVisible(&#x27;body&#x27;, 1000)
            .assert.title(expectedTitle);
    }

    afterEach: function(client, done) {
        client.customSauceEnd();

        setTimeout(function() {
            done();
        }, 1000);

    }

};

I can almost hear my teammates screaming in frustration just looking at this report.
To allow specific tests to be unstable but not others,
I’m going to add a guard &quot;suite completed&quot; test to the suites that should be stable,
and keep flaky test on it’s own.
Then I’ll tell xUnit to allow for a number of failed tests, but no skipped ones.
If any test fails other than the ones I allow to be flaky,
it will also result in one or more skipped tests and will fail the build.

// The rest of the Jenkinsfile is unchanged.
// Only the xUnit step() call is modified.
step([$class: &#x27;XUnitBuilder&#x27;,
    thresholds: [
        [$class: &#x27;SkippedThreshold&#x27;, failureThreshold: &#x27;0&#x27;],
        // Allow for a significant number of failures
        // Keeping this threshold so that overwhelming failures are guaranteed
        //     to still fail the build
        [$class: &#x27;FailedThreshold&#x27;, failureThreshold: &#x27;10&#x27;]],
    tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

tests/guineaPig.js

// ... snip ...

    &#x27;Guinea Pig Assert Title 0 - E&#x27;: function(client) { /* ... */ },

    &#x27;Guinea Pig Assert Title 0 - Suite Completed&#x27;: function(client) {
      // No assertion needed
    },

    afterEach: function(client, done) { /* ... */ }

// ... snip ...

tests/guineaPig_1.js

// ... snip ...

    &#x27;Guinea Pig Assert Title 1 - E&#x27;: function(client) { /* ... */ },

    &#x27;Guinea Pig Assert Title 1 - Suite Completed&#x27;: function(client) {
      // No assertion needed
    },

    afterEach: function(client, done) { /* ... */ }

// ... snip ...

After a few more runs, you can see the flaky test is still being flaky,
but it is no longer failing the build.  Meanwhile, if another test fails,
it will cause the &quot;suite completed&quot; test to be skipped, failing the job.
If this were a real project, the test owner could instrument and eventually fix
the test.  When they were confident they had stabilized the test the could add
a &quot;suite completed&quot; test after it to enforce it passing without changes to other
tests or framework.

Conclusion

This post has shown how to migrate from the JUnit plugin to the
xUnit plugin on an existing project in Jenkins pipeline.  It also covered how to
use the features of xUnit plugin to get more meaningful and effective Jenkins
reporting behavior.

What I didn’t show was how many other formats xUnit supports - from CCPUnit to MSTest.  You can
also write your own XSL for result formats not on the known/supported list.

Links

xUnit plugin

bitwiseman/JS-Nightwatch.js

saucelabs-sample-test-frameworks<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/xunit">xunit</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/nightwatch">nightwatch</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/11/11/monthly-jam-recap-october/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">11</div></div><h5 class="title">Monthly JAM Recap - October 2016</h5></div><p class="teaser">October has proven to be a busy month within the Jenkins Area Meetup groups.
Below is a recap of topics discussed at various JAMS in the month of October.

Dallas Forth Worth, Texas (DFW) JAM

James Dumay
took time out of his vacation to present Blue Ocean, a project that rethinks
the user experience of Jenkins, modeling and presenting the process of software
delivery by surfacing information that is important to development teams with
as few clicks as possible, while still staying true to the extensibility that
Jenkins always has had as a core value.

See recording HERE.

San Francisco, CA JAM

Andrey Falko from Salesforce shared how he and his Diagnostics team used
Jenkins to deliver software securely and reliably to production within
Salesforce.

See videos HERE and
HERE.

Boulder, CO JAM

This was a meetup with CA Technologies and included
Mark Waite, maintainer of the Jenkins git plugin
and a director at CA Technologies in Fort Collins.
Tyler did a great presentation about Jenkins
Pipeline and Blue Ocean and showed off how the community is using Blue Ocean to
build Jenkins.

Barcelona, Spain JAM

At this meetup, there were plenty of engaging discussions surrounding the
Jenkins Certification and DevOps 2.1 Toolkit: Continuous Deployment with
Jenkins and Docker Swarm.  Guillem Sola shared his Jenkins certification
experience HERE while Viktor
Farcic presented his thoughts on the aspects of building, testing, deploying,
and monitoring services inside Docker Swarm clusters and Jenkins
https://www.youtube.com/watch?v=fs1ED_y5mUc.

Lima, Peru JAM

October’s meetup was a joint effort with collaboration from Perú JUG, and
Docker Lima. The first talk was an Introduction to
Docker Ecosystem, second was
Building and Testing Apps with Docker and
Arquillian Cube
and the last one was
CI/CD using Docker and Jenkins Pipelines.

We had a full house at the meetup. Now, everyone in the room has a Mr. Jenkins
branded on their laptop :)

Special thanks to Mario Inga and
Héctor Paz for their collaborations during the
last meetups.

Links

Start a JAM in your city if there isn’t one already.

Become a JAM member.

Become an online JAM member

Be a JAM speaker or sponsor. Let us know jenkinsci-jam@googlegroups.com

Become a Jenkins project contributor<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/JAM">JAM</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/11/12/addressing-remote-vulnerabilities-in-cli/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">12</div></div><h5 class="title">Addressing recently disclosed vulnerabilities in the Jenkins CLI</h5></div><p class="teaser">The Jenkins
security team
has been made aware of a new attack vector for a remote code execution
vulnerability in the
Jenkins CLI,
according to
this
advisory
by Daniel Beck:

We have received a report of a possible unauthenticated remote code execution
vulnerability in Jenkins (all versions).

We strongly advise anyone running a Jenkins instance on a public network
disable the CLI for now.

As this uses the same attack vector as SECURITY-218, you can reuse the script
and instructions published in this repository: https://github.com/jenkinsci-cert/SECURITY-218

We have since been able to confirm the vulnerability and strongly recommend
that everyone follow the instructions in the linked repository.

As Daniel mentions in the security advisory, the advised mitigation strategy is
to disable the CLI subsystem via
this
Groovy script.
If you are a Jenkins administrator, navigate to the &#x27;Manage Jenkins&#x27; page and
click on the &#x27;Script Console&#x27;, which will allow you to run the Groovy script to
immediately disable the CLI.

In order to persist this change across restarts of your Jenkins controller, place
the
Groovy script
in $JENKINS_HOME/init.groovy.d/cli-shutdown.groovy so that Jenkins executes
the script on each boot.

We are expecting to have a fix implemented, tested and included in an updated
weekly and LTS release this upcoming Wednesday, November 16th.

For users who are operating Jenkins on public, or otherwise hostile, networks,
we suggest hosting Jenkins behind reverse proxies such as Apache or Nginx.
These can help provide an additional layer of security, when used appropriately,
to cordon off certain URLs such as /cli.

Additionally, we strongly recommend that all Jenkins administrators subscribe
to the
jenkinsci-advisories@googlegroups.com
mailing list to receive future advisories.

The Jenkins project has a responsible disclosure policy, which we strongly
encourage anybody who believes they have discovered a potential vulnerability
to follow. You can learn more about this policy and our processes on our
security page.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lts">lts</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/11/13/november-jenkins-events/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">13</div></div><h5 class="title">Upcoming November Jenkins Events</h5></div><p class="teaser">November is packed full of meetups and events. If you are in any of the areas
below please stop by to say &quot;Hi&quot; and talk Jenkins over beer.

North America

November 15 | SF JAM: Let’s Talk CI/CD and DevOps with ClusterHQ and Jenkins

November 15 | DC JAM: Jenkins and Fannie Mae

November 30 | Albuquerque JAM: Learn About Blue Ocean

November 30 | Guadalajara JAM: Jenkins Install and Setup

Europe

November 10 | Amsterdam JAM: Jenkins and Docker - Multiple Uses for Containers and Jenkins

November 10 | Milano JAM: Meet and Greet

Australia

November 15 | Melbourne JAM: Blue Ocean - A New User Experience

Asia

November 17 | Singapore JAM: CI Using Source Code on GitHub

Links

Start a JAM in your city if there isn’t one already.

Become a JAM member

Become an online JAM member

Speak or sponsor at a JAM. Contact us at jenkinsci-jam@googlegroups.com

Become a Jenkins project contributor<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/11/16/security-updates-addressing-zero-day/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">16</div></div><h5 class="title">Security updates addressing zero day vulnerability</h5></div><p class="teaser">A zero-day vulnerability in Jenkins was published on Friday, November 11.  Last
week
we provided an immediate mitigation
and today we are releasing updates to Jenkins which fix the vulnerability. We
strongly recommend you update Jenkins to 2.32 (main line) or 2.19.3 (LTS) as
soon as possible.

Today’s
security advisory
contains more information on the exploit, affected versions, and fixed
versions, but in short:

An unauthenticated remote code execution vulnerability allowed attackers to
transfer a serialized Java object to the Jenkins CLI, making Jenkins connect to
an attacker-controlled LDAP server, which in turn can send a serialized payload
leading to code execution, bypassing existing protection mechanisms.

Moving forward, the Jenkins security team is revisiting the design of the
Jenkins CLI over the coming weeks to prevent this class of vulnerability in the
future. If you are interested in participating in that discussion, please join
in on the
jenkinsci-dev@
mailing list.

The Jenkins project encourages administrators to subscribe to the
jenkinsci-advisories@
mailing list to receive future Jenkins security notifications.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/11/21/gc-tuning/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">21</div></div><h5 class="title">Tuning Jenkins GC For Responsiveness and Stability with Large Instances</h5></div><p class="teaser">This is a
cross
post by Sam Van Oort, Software Engineer at
CloudBees and contributor to the Jenkins project.

Today I’m going to show you how easy it is to tune Jenkins Java settings to
make your controllers more responsive and stable, especially with large heap sizes.

The Magic Settings:

Basics: -server -XX:+AlwaysPreTouch

GC Logging: -Xloggc:$JENKINS_HOME/gc-%t.log -XX:NumberOfGCLogFiles=5 -XX:+UseGCLogFileRotation -XX:GCLogFileSize=20m -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCCause -XX:+PrintTenuringDistribution -XX:+PrintReferenceGC -XX:+PrintAdaptiveSizePolicy

G1 GC settings: -XX:+UseG1GC -XX:+ExplicitGCInvokesConcurrent -XX:+ParallelRefProcEnabled -XX:+UseStringDeduplication -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20 -XX:+UnlockDiagnosticVMOptions -XX:G1SummarizeRSetStatsPeriod=1

Heap settings: set your minimum heap size ( -Xms) to at least 1/2 of your maximum size ( -Xmx).

Now, let’s look at where those came from!  We’re going to focus on garbage
collection (GC) here and dig fast and deep to strike for gold; if you’re not
familiar with GC fundamentals
take a look at this source.

Because performance tuning is data driven, I’m going to use real-world data
selected three very large Jenkins instances that I help support.

What we’re not going to do: Jenkins basics, or play with max heap.  See the
section &quot;what should I do before tuning.&quot;  This is for cases where we really
do need a big heap and can’t easily split our Jenkins controllers into smaller
ones.

The Problem: Hangups

Symptom: Users report that the Jenkins instance periodically hangs, taking
several seconds to handle normally fast requests.  We may even see lockups or
timeouts from systems communicating with the Jenkins controller (build agents,
etc).  In long periods of heavy load, users may report Jenkins running slowly.
Application monitoring shows that during lockups all or most of the CPU cores
are fully loaded, but there’s not enough activity to justify it.  Process and
JStack dumps will reveal that the most active Java threads are doing garbage
collection.

With Instance A, they had this problem.  Their Jenkins Java arguments are very
close to the default, aside from sizing the heap:

24 GB max heap, 4 GB initial, default GC settings (ParallelGC)

A few flags set (some coming in as defaults): -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:+ReduceSignalUsage -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation

After enabling garbage collection (GC) logging we see the following rough stats:

.

Diving deeper, we get this chart of GC pause durations:

Key stats:

Throughput: 99.64%  (percent of time spent executing application code, not doing garbage collection)

Average GC time: 348 ms (ugh!)

GC cycles over 2 seconds: 36 (2.7%)

Minor/Full GC average time: 263 ms / 2.803 sec

Object creation &amp; promotion rate: 42.4 MB/s &amp; 1.99 MB/s

Explanations:

As you can see, young GC cycles very quickly clear away freshly-created
garbage, but the deeper old-gen GC cycles run very slowly: 2-4 seconds. This is
where our problems happen.  The default Java garbage collection algorithm
(ParallelGC) pauses everything when it has to collect garbage (often called a
&quot;stop the world pause&quot;). During that period, Jenkins is fully halted: normally
(with small heaps) these pauses are too brief to be an issue.  With heaps of 4
GB or larger, the time required becomes long enough to be a problem: several
seconds over short windows, and over a longer interval you occasionally see
much longer pauses (tens of seconds, or minutes.)

This is where the user-visible hangs and lock-ups happen.  It also adds
significant latency to those build/deploy tasks.  In periods of heavy load, the
system was even experiencing hangs of 30+ seconds for a single full GC cycle.
This was long enough to trigger network timeouts (or internal Jenkins thread
timeouts) and cause even larger problems.

Fortunately there’s a solution: the concurrent low-pause garbage collection
algorithms, Concurrent Mark Sweep (CMS) and Garbage First (G1). These attempt
to do much of the garbage collection concurrently with application threads,
resulting in much shorter pauses (at a slight cost in extra CPU use).  We’re
going to focus on G1, because it is slated to become the default in Java 9 and
is the official recommendation for large heap sizes.

Let’s see what happens when someone uses G1 on a similarly-sized Jenkins
controller with Instance B (17 GB heap):

Their settings:

16 GB max heap, 0.5 GB initial size

Java flags (mostly defaults, except for G1): -XX:+UseG1GC -XX:+UseCompressedClassPointers -XX:+UseCompressedOops

And the GC log analysis:

Key stats:

Throughput: 98.76%  (not great, but still only slowing things down a bit)

Average GC time: 128 ms

GC cycles over 2 seconds: 11, 0.27%

Minor/Full GC average time: 122 ms / 1 sec 232 ms

Object creation &amp; promotion rate: 132.53 MB/s &amp; 522 KB/s

Okay, much better : some improvement may be expected from a 30% smaller
heap, but not as much as we’ve seen.  Most of the GC pauses are well
under 2 seconds, but we have 11 outliers - long Full GC pauses of 2-12 seconds.
Those are troubling; we’ll take a deeper dive into their causes in a second.
First, let’s look at the big picture and at how Jenkins behaves with G1 GC for
a second instance.

G1 Garbage Collection with Instance C (24 GB heap):

Their settings:

24 GB max heap, 24 GB initial heap, 2 GB max metaspace

Some custom flags: `-XX:+UseG1GC -XX:+AlwaysPreTouch -XX:+UseStringDeduplication  -XX:+UseCompressedClassPointers -XX:+UseCompressedOops `

Clearly they’ve done some garbage collection tuning and optimization.  The
AlwaysPreTouch pre-zeros allocated heap pages, rather than waiting until
they’re first used. This is suggested especially for large heap sizes, because
it trades slightly slower startup times for improved runtime performance.  Note
also that they pre-allocated the whole heap.  This is a common optimization.

They also enabled StringDeduplication, a G1 option introduced in Java 8 Update
20 that transparently replaces identical character arrays with pointers to the
original, reducing memory use (and improving cache performance).  Think of it
like String.intern() but it silently happens during garbage collection.  This
is a concurrent operation added on to normal GC cycles, so it doesn’t pause the
application.  We’ll look at its impacts later.

Looking at the basics:

Similar picture to Instance B, but it’s hidden by the sheer number of points
(this is a longer period here, 1 month).  Those same occasional Full GC
outliers are present!

Key stats:

Throughput: 99.93%

Average GC time: 127 ms

GC cycles over 2 seconds: 235 (1.56%)

Minor/Full GC average time: 56 ms / 3.97 sec

Object creation &amp; promotion rate: 34.06 MB/s &amp; 286 kb/s

Overall fairly similar to Instance B: ~100 ms GC cycles, all the minor GC
cycles are very fast.  Object promotion rates sound similar.

Remember those random long pauses?

Let’s find out what caused them and how to get rid of them.  Instance B had 11
super-long pause outliers.  Let’s get some more detail, by opening GC Logs in
GCViewer.
This tool gives a tremendous amount of information.  Too much, in fact —  I
prefer to use
GCEasy.io
except where needed.  Since GC logs do not contain compromising information
(unlike heap dumps or some stack traces), web apps are a great tool for
analysis.

What we care about are at the Full GC times in the middle (highlighted).  See
how much longer they are vs. the young and concurrent GC cycles up top (2
seconds or less)?

Now, I lied a bit earlier - sorry!  For concurrent garbage collectors, there
are actually 3 modes: young GC, concurrent GC, and full GC.  Concurrent GC
replaces the Full GC mode in Parallel GC with a faster concurrent operation
that runs in parallel with the application.  But in a few cases, we are
forced to fall back to a non-concurrent Full GC operation, which will use the
serial  (single-threaded) garbage collector.  That means that even if we have
30+ CPU cores, only one is working. This is what is happening here, and on a
large-heap, multicore system it is S  L  O  W.  How slow?  280 MB/s vs. 12487
MB/s for Instance B (for instance C, the difference is also about 50:1).

What triggers a full GC instead of concurrent:

Explicit calls to System.gc() (most common culprit, often tricky to trace down)

Metadata GC Threshold: Metaspace (used for Class data mostly) has hit the
defined size to force garbage collection or increase it.  Documentation is
terrible for this,
Stack Overflow
will be your friend.

Concurrent mode failure: concurrent GC can’t complete fast enough to keep up
with objects the application is creating (there are JVM arguments to trigger
concurrent GC earlier)

How do we fix this?

For explicit GC:

-XX:+DisableExplicitGC will turn off Full GC triggered by System.gc().  Often set in production, but the below option is safer.

We can trigger a concurrent GC in place of a full one with -XX:+ExplicitGCInvokesConcurrent - this will take the explicit call as a hint to do deeper cleanup, but with less performance cost.

Gotcha for people who’ve used CMS: if you have used CMS in the past, you
may have used the option -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses — which does what it says.  This option will silently fail in G1, meaning you
still see the very long pauses from Full GC cycles as if it wasn’t set (no
warning is generated).  I have logged a JVM bug for this issue.

For the Metadata GC threshold:

Increase your initial metaspace to the final amount to avoid resizing. For example: -XX:MetaspaceSize=500M

Instance C also suffered the same problem with explicit GC calls, with almost
all our outliers accounted for (230 out of 235) by slow, nonconcurrent Full GC
cycles (all from explicit System.gc() calls, since they tuned metaspace):

Here’s what GC pause durations look like if we remove the log entries for the
explicit System.gc() calls, assuming that they’ll blend in with the other
concurrent GC pauses (not 100% accurate, but a good approximation):

Instance B:

The few long Full GC cycles at the start are from metaspace expansion — they
can be removed by increasing initial Metaspace size, as noted above. The
spikes?  That’s when we’re about to resize the Java heap, and memory pressure
is high. You can avoid this by setting the minimum/initial heap to at least
half of the maximum, to limit resizing.

Stats:

Throughput: 98.93%

Average GC time: 111 ms

GC cycles over 2 seconds: 3

Minor &amp; Full or concurrent GC average time: 122 ms / 25 ms (yes, faster than minor!)

Object creation &amp; promotion rate: 132.07 MB/s &amp; 522 kB/s

Instance C:

Stats:

Throughput: 99.97%

Average GC time: 56 ms

GC cycles over 2 seconds: 0 (!!!)

Minor &amp; Full or concurrent GC average time: 56 ms &amp; 10 ms (yes, faster than minor!)

Object creation &amp; promotion rate: 33.31 MB/s &amp; 286 kB/s

Side point: GCViewer is claiming GC performance of 128 GB/s (not unreasonable, we clear ~10 GB of young generation in under 100 ms usually)

Okay, so we’ve tamed the long worst-case pauses!

But What About Those Long Minor GC Pauses We Saw?

Okay, now we’re in the home stretch!  We’ve tamed the old-generation GC pauses
with concurrent collection, but what about those longer young-generation
pauses?  Lets look at stats for the different phases and causes again in
GCViewer.

Highlighted in yellow we see the culprit: the remark phase of G1 garbage
collection. This stop-the-world phase ensures we’ve identified all live
objects, and process references (
more info).

Let’s look at a sample execution to get more info:

2016-09-07T15:28:33.104+0000: 26230.652: [GC remark 26230.652: [GC ref-proc, 1.7204585 secs], 1.7440552 secs]

 [Times: user=1.78 sys=0.03, real=1.75 secs]

This turns out to be typical for the GC log: the longest pauses are spent in
reference processing. This is not surprising because Jenkins internally uses
references heavily for caching, especially weak references, and the default
reference processing algorithm is single-threaded.  Note that user (CPU) time
matches real time, and it would be higher if we were using multiple cores.

So, we add the GC flag -XX:+ParallelRefProcEnabled which enables us to use the multiple cores more effectively.

Tuning young-generation GC further based on Instance C:

Back to GCViewer we go, to see what’s time consuming with the GC for Instance C.

That’s good, because most of the time is just sweeping out the trash
(evacuation pause).  But the 1.8 second pause looks odd.  Let’s look at the raw
GC log for the longest pause:

2016-09-24T16:31:27.738-0700: 106414.347: [GC pause (G1 Evacuation Pause) (young), 1.8203527 secs]
[Parallel Time: 1796.4 ms, GC Workers: 8]
 [GC Worker Start (ms): Min: 106414348.2, Avg: 106414348.3, Max: 106414348.6, Diff: 0.4]
[Ext Root Scanning (ms): Min: 0.3, Avg: 1.7, Max: 5.7, Diff: 5.4, Sum: 14.0]
  [Update RS (ms): Min: 0.0, Avg: 7.0, Max: 19.6, Diff: 19.6, Sum: 55.9]
    [Processed Buffers: Min: 0, Avg: 45.1, Max: 146, Diff: 146, Sum: 361]
 [Scan RS (ms): Min: 0.2, Avg: 0.4, Max: 0.7, Diff: 0.6, Sum: 3.5]
 [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.2]
 [Object Copy (ms): Min: 1767.1, Avg: 1784.4, Max: 1792.6, Diff: 25.5, Sum: 14275.2]
 [Termination (ms): Min: 0.3, Avg: 2.4, Max: 3.5, Diff: 3.2, Sum: 19.3]
    [Termination Attempts: Min: 11, Avg: 142.5, Max: 294, Diff: 283, Sum: 1140]
 [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.4, Diff: 0.3, Sum: 0.8]
 [GC Worker Total (ms): Min: 1795.9, Avg: 1796.1, Max: 1796.2, Diff: 0.3, Sum: 14368.9]
 [GC Worker End (ms): Min: 106416144.4, Avg: 106416144.5, Max: 106416144.5, Diff: 0.1]

…​oh, well dang. Almost the entire time (1.792 s out of 1.820) is walking
through the live objects and copying them.  And wait, what about this line,
showing the summary statistics:

Eden: 13.0G(13.0G)-&gt;0.0B(288.0M) Survivors: 1000.0M-&gt;936.0M Heap: 20.6G(24.0G)-&gt;7965.2M(24.0G)]

Good grief, we flushed out 13 GB (!!!) of freshly-allocated garbage in one
swoop and compacted the leftovers!  No wonder it was so slow.  I wonder how we
accumulated so much…​

Oh, right…​ we set up for 24 GB of heap initially, and each minor GC clears
most of the young generation.  Okay, so we’ve set aside tons of space for trash
to collect, which means longer but less frequent GC periods.  This also gets
the best performance from Jenkins memory caches which are using WeakReferences
(survives until collected by GC) and SoftReferences (more long-lived). Those
caches boost performance a lot.

We could take actions to prevent those rare longer pauses. The best ways are to
limit total heap size or reduce the value of -XX:MaxGCPauseMillis=200 from
its default (200).  A more advanced way (if those don’t help enough) is to
explicitly set the maximum size of the young generation smaller (say
-XX:G1MaxNewSizePercent=45 instead of the default of 60).  We could also
throw more CPUs at the problem.

But if we look up, most pauses are around 100 ms (200 ms is the default value
for MaxGCPauseMillis).  For Jenkins on this hardware, this appears to work
just fine and a rare longer pause is OK as long as they don’t get too
big.  Also remember, if this happens often, G1 GC will try to autotune for
lower pauses and more predictable performance.

A Few Final Settings

We mentioned StringDeduplication was on with Instance C, what is the impact?
This only triggers on Strings that have survived a few generations (most of our
garbage does not), has limits on the CPU time it can use, and replaces
duplicate references to their immutable backing character arrays.
For more info, look here.
So, we should be trading a little CPU time for improved memory efficiently
(similarly to string interning).

At the beginning, this has a huge impact:

[GC concurrent-string-deduplication, 375.3K-&gt;222.5K(152.8K), avg 63.0%, 0.0     024966 secs]
[GC concurrent-string-deduplication, 4178.8K-&gt;965.5K(3213.2K), avg 65.3%, 0     .0272168 secs]
[GC concurrent-string-deduplication, 36.1M-&gt;9702.6K(26.6M), avg 70.3%, 0.09     65196 secs]
[GC concurrent-string-deduplication, 4895.2K-&gt;394.9K(4500.3K), avg 71.9%, 0     .0114704 secs]

This peaks at an average of about ~90%:

After running for a month, less of an impact - many of the strings that can be
deduplicated already are:

[GC concurrent-string-deduplication, 138.7K-&gt;39.3K(99.4K), avg 68.2%, 0.0007080 secs]
[GC concurrent-string-deduplication, 27.3M-&gt;21.5M(5945.1K), avg 68.1%, 0.0554714 secs]
[GC concurrent-string-deduplication, 304.0K-&gt;48.5K(255.5K), avg 68.1%, 0.0021169 secs]
[GC concurrent-string-deduplication, 748.9K-&gt;407.3K(341.7K), avg 68.1%, 0.0026401 secs]
[GC concurrent-string-deduplication, 3756.7K-&gt;663.1K(3093.6K), avg 68.1%, 0.0270676 secs]
[GC concurrent-string-deduplication, 974.3K-&gt;17.0K(957.3K), avg 68.1%, 0.0121952 secs]

However it’s cheap to use: in average, each dedup cycle takes 8.8 ms and
removes 2.4 kB of duplicates.  The median takes 1.33 ms and removes 17.66 kB
from the old generation.  A small change per cycle, but in aggregate it adds up
quickly — in periods of heavy load, this can save hundreds of megabytes of
data. But that’s still small, relative to multi-GB heaps.

Conclusion: turn string deduplication on string deduplication is fairly
cheap to use, and reduces the steady-state memory needed for Jenkins.  That
frees up more room for the young generation, and should overall reduce GC time
by removing duplicate objects.  I think it’s worth turning on.

Soft reference flushing: Jenkins uses soft references for caching build
records and in pipeline FlowNodes.  The only guarantee for these is that they
will be removed instead of causing an OutOfMemoryError…​ however Java
applications can slow to a crawl from memory pressure long before that happens.
There’s an option that provides a hint to the JVM based on time &amp; free memory,
controlled by -XX:SoftRefLRUPolicyMSPerMB (default 1000).  The SoftReferences
become eligible for garbage collection after this many milliseconds have
elapsed since last touch…​ per MB of unused heap (vs the maximum).  The
referenced objects don’t count towards that target.  So, with 10 GB of heap
free and the default 1000 ms setting, soft references stick around for ~2.8
hours (!).

If the system is continuously allocating more soft references, it may trigger
heavy GC activity, rather than clearing out soft references. See the open bug
JDK-6912889
for more details.

If Jenkins consumes excessive old generation memory, it may help to make soft
references easier to flush  by reducing -XX:SoftRefLRUPolicyMSPerMB from its
default (1000) to something smaller (say 10-200).  The catch is that
SoftReferences are often used for objects that are relatively expensive to
load, such lazy-loaded build records and pipeline FlowNode data.

Caveats

G1 vs. CMS:

G1 was available on later releases of JRE 7, but unstable and slow. If you
use it you absolutely must be using JRE 8, and the later the release the better
(it’s gotten a lot of patches).  Googling around will show horrible G1 vs CMS
benchmarks from around 2014: these are probably best ignored, since the G1
implementation was still immature then. There’s probably a niche for CMS use
still, especially on midsized heaps (1-3 GB) or where settings are already
tuned.  With appropriate tuning it can still perform generally well for
Jenkins (which mostly generates short-lived garbage), but CMS eventually suffer
from heap fragmentation and need a slow, non-concurrent Full GC to clear this.
It also needs considerably more tuning than G1.

General GC tuning caveats :

No single setting is perfect for everybody.  We avoid tweaking settings that we
don’t have strong evidence for here, but there are of course many additional
settings to tweak.  One shouldn’t change them without evidence though, because
it can cause unexpected side effects.  The GC logs we enabled earlier will
collect this evidence.  The only setting that jumps out as a likely candidate
for further tuning is G1 region size (too small and there are many humungous
object allocations, which hurt performance).  Running on smaller systems,
I’ve seen evidence that regions shouldn’t be smaller than 4 MB because
there are 1-2 MB objects allocated somewhat regularly — but it’s not
enough to make solid guidance without more data.

What Should I Do Before Tuning Jenkins GC:

If you’ve seen
Stephen Connolly’s excellent Jenkins World talk,
you know that most Jenkins instances can and should get by with 4 GB or less of
allocated heap, even up to very large sizes.  You will want to turn on GC
logging (suggested above) and look at stats over a few weeks (remember
GCeasy.io).
If you’re not seeing periodic longer pause times, you’re probably okay.

For this post we assume we’ve already done the basic performance work for Jenkins:

Jenkins is running on fast, SSD-backed storage.

We’ve set up build rotation for your Jobs, to delete old builds so they don’t pile up.

The weather column is already disabled for folders.

All builds/deploys are running on build agents not on the controller. If the controller has executors allocated, they are exclusively used for backup tasks.

We’ve verified that Jenkins really does need the large heap size and can’t easily be split into separate controllers.

If not, we need to do that FIRST before looking at GC tuning, because those will have larger impacts.

Conclusions

We’ve gone from:

Average 350 ms pauses (bad user experience) including less frequent 2+ second generation pauses

To an average pause of ~50 ms, with almost all under 250 ms

Reduced total memory footprint from String deduplication

How:

Use Garbage First (G1) garbage collection, which performs generally very well for Jenkins.  Usually there’s enough spare CPU time to enable concurrent running.

Ensure explicit System.gc() and metaspace resizing do not trigger a Full GC because this can trigger a very long pause

Turn on parallel reference processing for Jenkins to use all CPU cores fully.

Use String deduplication, which generates a tidy win for Jenkins

Enable GC logging, which can then be used for the next level of tuning and diagnostics, if needed.

There’s still a little unpredictability, but using appropriate settings gives a
much more stable, responsive CI/CD server…​ even up to 20 GB heap sizes!

Further Reading:

G1GC fundamentals

MechanicalSympathy: Garbage Collection Distilled

Oracle Garbage First Garbage Collector Tuning

One additional thing

I’ve added -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20 to our
options above.  This is covering a complex and usually infrequent case where G1
self-tuning can trigger bad performance for Jenkins — but that’s material for
another post…​<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/svanoort/">Sam Van Oort</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/administration">administration</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/11/22/what-jvm-versions-are-running-jenkins-the-return/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">22</div></div><h5 class="title">What JVM versions are running Jenkins? 2016 Update!</h5></div><p class="teaser">Like for last year’s article about the same subject, yet another recent discussion about finally requiring Java 8 to run future versions Jenkins pushed me to gather some more factual data around it.

What follows contains some opinions or statements which may not be seen as purely factual or neutral. Note that this represents by no mean the general position of the Jenkins governance board. This is solely my opinion as a contributor based on the data I gathered, and what I feel from the feedback of the community at large.

Java 8 now the most used version, and growing

If we look at the global numbers, Java 8 runtimes now represent 52.8% of the Jenkins instances running, which have not opted out of anonymous usage statistics.

And if you look at the trend, Java 8 is clearly growing fast.

Zooming into the Jenkins 2.x instances subset

Now, if you look at that picture, though already interesting and showing a clear trend towards Java 8 runtime adoption, some might argue it’s being too nice to older JREs.
The reasoning could be: instances running (very) old Jenkins versions may not be the ones you want to look at when trying to plan the future of an opensource project:
those are indeed probably not going to upgrade in general anyway, or when they do, upgrading the JRE would be a small thing compared to the rest to be tested with such a gap.

So, if we only keep the instances running Jenkins 2.x, then the proportion of Java 8 goes to almost 70% compared to Java 7 (Jenkins 2.x requires Java 7)
[ 1 ] :

Conclusion

Java 8 adoption numbers are getting bigger, while every other JREs are going down.

If you are still using a JRE 7 to run Jenkins, it is seriously time to think
about upgrading to 8.  Knowing that it’s definitely not a bleeding-edge path
might help you go that way, especially if you generally do not like upgrades.
Also, as a reminder, the most used JDK,
Oracle JDK 7 now got end-of-lifed more than 18 months ago.

Contrary to the past attempts the previous years, the discussion on the Jenkins
development mailing list did not trigger strong rebutals by many people.

Perhaps it’s finally time for Mr. Jenkins to upgrade to Java 8!

All numbers shown below are derived from the new jvms.json file now generated automatically every month, after the two related pull-requests 1 and 2 got merged.
[ 2 ]

1. 69% for October, 67% in September

2. You are more than welcome to review those Pull-Requests and shout if you see something wrong in the calculations.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/statistics">statistics</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/12/09/december-jenkins-events/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 9</div></div><h5 class="title">Upcoming December Jenkins Events</h5></div><p class="teaser">Happy Holidays! A special shout out to all JAM leaders who continue to keep
local activities going in December.

Online JAM

December 14 | Live Demos: Pipeline, Git, and Blue Ocean

North America

December 7 | Seattle JAM: Jenkins at Microsoft

December 14 | Los Angeles JAM: Jenkins Days

December 14 | Guadalajara JAM: Jenkins &amp; Docker

Australia

December 14 | Melbourne JAM: Meeting at AWS Office

Links

Start a JAM in your city if there isn’t one already.

Become a JAM member

Become an online JAM member

Speak or sponsor at a JAM. Contact us at jenkinsci-jam@googlegroups.com

Become a Jenkins project contributor<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/12/10/monthly-jam-recap-november/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">10</div></div><h5 class="title">Monthly JAM Recap - November 2016</h5></div><p class="teaser">As we near the end of the year, the number of November JAMs show that the
Jenkins community isn’t slowing down for holiday season. We had a number of
excellent events hosted around the world this November with plenty of great
stories and presentations shared by the various members of the world-wide
Jenkins community.

Melbourne, Australia JAM

Melbourne JAM leaders,
Raisa
and
Bhuva
hosted Blue Ocean for the inaugural meeting. Attendees learned the values of
Blue Ocean, a project that rethinks the user experience of Jenkins, modeling
and presenting the process of software delivery by surfacing information that
is important to development teams with as few clicks as possible, while still
staying true to the extensibility that Jenkins always has had as a core value.
Thank you James Dumay for stopping by to take part in
the inauguration.

Singapore, Singapore JAM

One of the members  who had several years of experience using Jenkins (since
Hudson days in fact) to present some basics on Continuous Integration with
GitHub. It was targeted at new members who are starting out with Jenkins. We
understand that we cannot always serve advanced topics to cater to the
experienced users and neglect the newbies so this session was targeted to help
give new users an introduction to Jenkins. It went well with about 15-20
attendees and we hope to run some hands-on workshops in 2017. Some members were
looking forward to freebies like stickers and T-shirts too!

Moscow, Russia JAM

Moscow JAM leaders,
Kirill Tolkachev
and
Oleg Nenashev
led the inaugural meeting with
a packed full agenda. Oleg began the meeting with an update on Jenkins 2 what improvements users can expect and what
enhancements are in the works within the Jenkins project. Following Oleg, Kirill shared
how his team in Alfa Laboratory used Jenkins to improve CD/DevOps in their
projects (with Jenkins Pipeline, Job DSL and
Blue Ocean), the problems they experienced and how they fixed them. Then Oleg talked
about Jenkins Pipeline internals, main features and recent changes in the
ecosystem. It was followed up by a discussion of large-scale Jenkins instances
at the after-party.

The recording of the event can be found
on YouTube.

Milan, Italy JAM

The first meetup was a great opportunity to meet local Jenkins fans to learn
and share Jenkins experiences at a local cafe.

San Francisco, California JAM

R. Tyler Croy
performed a 30 minutes live Pipeline coding demo to a relatively novice
audience (though all had used Jenkins). A good amount of questions from the
audience  which conveyed an appetite for the content being presented.
Ryan Wallner,
presenter from ClusterHQ, also gave a demo based around Pipeline talking about
ClusterHQ’s &quot;Fli&quot; integration with a delivery pipeline.

Washington, DC JAM

There was a fantastic 90% showup rate at this month’s meetup - 58 RSVPs and 52
in attendance was pretty impressive. All this may be due to Fannie Mae’s story
- the success of how they used Jenkins for CI/CD as part of their DevOps
adoption. Afterwards, there was a lot of interests and further discussions
taking place. Next month’s host will be Freddie Mac.

Seattle, Washington JAM

Long time Jenkins community member and Seattle JAM leader,
Khai Do showed how OpenStack uses &quot;Jenkins Job
Builder&quot; to manage and run thousands of Jenkins jobs per day in their
multi-controller CI/CD system.  He also compared
Jenkins Job Builder
with other Jenkins &quot;Infrastructure-as-code&quot; technologies - Jenkins Pipeline and
Jenkins JobDSL. It was followed by an in-depth Q&amp;A and discussion session.

Dallas/Forth Worth, Texas (DFW) JAM

The November DFW JAM was the most strongly attended of the year! DFW JAM leader,
Eric Smalling discussed the benefits of
dynamic build agents and demonstrated various ways to implement them such as
the EC2 and Docker plugins. There was a lot of interest and discussion,
especially around Docker and the ability it provides to have ephemeral agents
with very little provisioning time.

The recording can be downloaded from
Gooel Drive.

Links

Start a JAM in your city if there isn’t one already.

Become a JAM member.

Become an online JAM member

Be a JAM speaker or sponsor. Let us know jenkinsci-jam@googlegroups.com

Become a Jenkins project contributor<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/12/19/declarative-pipeline-beta/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">19</div></div><h5 class="title">Announcing the beta of Declarative Pipeline Syntax</h5></div><p class="teaser">Last week we released version 0.7.1 of the
Pipeline-Model-Defintion
plugin and wanted to crown it as the official Beta version of the Declarative
Pipeline syntax. Although it has been available in the update center
since August,
we continue to solidify the syntax. We feel this release is getting
very close to the final version and should not change much before 1.0. However,
it is still a Beta so further tweaks are possible.

A release (0.8.0) is planned for early January 2017 which will finalize the
syntax with the following changes:
JENKINS-40524,
JENKINS-40370,
JENKINS-40462,
JENKINS-40337

What is Declarative Pipeline?

All the way back at Jenkins World in September, Andrew Bayer presented a
sneak peak
of a new syntax for constructing Pipelines. We are calling this new syntax
Declarative Pipeline to differentiate it from the existing Scripted Pipeline
syntax that has always been a part of Pipeline.

After listening to many Jenkins users over the last year we felt that, while
Pipeline Script provides tremendous power, flexibility, and extensibility, the
learning curve for Scripted Pipeline was steep for users new to either Jenkins
or Pipeline. Beginning users wanting to take advantage of all the features
provided by Pipeline and Jenkinsfiles were required to learn Scripted Pipeline
or remain limited to the functionality provided by Freestyle jobs.

Declarative Pipeline does not replace Scripted Pipeline but extends Pipeline it
with a pre-defined structure to let users focus entirely on the steps
required at each stage without needing to worry about scripting every aspect
of the pipeline. Granular flow-control is extremely powerful and Scripted
Pipeline syntax will always be part of Pipeline but it’s not for everyone.

Declarative Pipeline enables all users to connect simple, declarative blocks
that define agents (including Docker), post actions, environment
settings, credentials and all stages that make up the pipeline. Best of all,
because this Declarative syntax is part of Pipeline, all build steps and build
wrappers available in Plugins or loaded from Shared Libraries are also
available as steps in Declarative.

Example

Below is an example of a pipeline in Declarative syntax. You can also switch the view to show the same pipeline in Scripted syntax.
 The Declarative syntax has a more straightforward structure that is easier to grok by users not versed in Groovy.

// Declarative //
pipeline {
  agent  label:&#x27;has-docker&#x27;, dockerfile: true
  environment {
    GIT_COMMITTER_NAME = &quot;jenkins&quot;
    GIT_COMMITTER_EMAIL = &quot;jenkins@jenkins.io&quot;
  }
  stages {
    stage(&quot;Build&quot;) {
      steps {
        sh &#x27;mvn clean install -Dmaven.test.failure.ignore=true&#x27;
      }
    }
    stage(&quot;Archive&quot;){
      steps {
        archive &quot;*/target/**/*&quot;
        junit &#x27;*/target/surefire-reports/*.xml&#x27;
      }
    }
  }
  post {
    always {
      deleteDir()
    }
    success {
      mail to:&quot;me@example.com&quot;, subject:&quot;SUCCESS: ${currentBuild.fullDisplayName}&quot;, body: &quot;Yay, we passed.&quot;
    }
    failure {
      mail to:&quot;me@example.com&quot;, subject:&quot;FAILURE: ${currentBuild.fullDisplayName}&quot;, body: &quot;Boo, we failed.&quot;
    }
  }
}

// Script //
withEnv([&quot;GIT_COMMITTER_NAME = jenkins&quot;,&quot;GIT_COMMITTER_EMAIL = jenkins@jenkins.io&quot;]) {
  node(&#x27;has-docker&#x27;) {
    try {
      checkout scm // checks out Dockerfile and source code
      def myImage = docker.build &#x27;my-environment:snapshot&#x27;
      myImage.inside {
        stage(&#x27;Build&#x27;) {
          sh &#x27;mvn clean install -Dmaven.test.failure.ignore=true&#x27;
        }
        stage(&#x27;Archive&#x27;) {
          archive &quot;*/target/**/*&quot;
          junit &#x27;*/target/surefire-reports/*.xml&#x27;
        }
      }
      if (currentBuild.result == null || currentBuild.result == &#x27;SUCCESS&#x27;) {
        mail to:&quot;me@example.com&quot;, subject:&quot;SUCCESS: ${currentBuild.fullDisplayName}&quot;, body: &quot;Yay, we passed.&quot;
      }
    }
    catch (exc) {
      mail to:&quot;me@example.com&quot;, subject:&quot;FAILURE: ${currentBuild.fullDisplayName}&quot;, body: &quot;Boo, we failed.&quot;
    }
    finally {
      deleteDir()
    }
  }
}

How can you help?

Install the lastest version of the
Pipeline-Model-Defintion plugin.

Read the documentation:
Getting Started and
Syntax overview.
(These documents will be incorporated into the Jenkins.io documentation.)

Convert some of your existing Pipeline scripts into Declarative

Log any issues or enhancements you have
here
for the syntax, the execution, or the documentation.

Ask questions. You can send questions to the
users mailing list
or visit the #jenkins channel on IRC.

How will this work with Blue Ocean?

Blue Ocean is all about Pipelines in Jenkins. Running, displaying, and soon,
creating Pipelines.  Blue Ocean will be able to run and display Pipelines
written in this new syntax just like any other Pipeline works today. However,
because Declarative Pipeline includes a pre-defined structure, or model, it is
now possible to create and edit pipelines with a GUI editor.

Although we plan to launch 1.0 of Declarative Pipeline before Blue Ocean 1.0 is
officially available, we expect to have a working Beta of the Editor available
to play with. The combination of a simple syntax and an intuitive editor
should make creating Jenkins Pipelines a breeze.

Happy Holidays

I hope everyone has a great end of the year and a Happy New Year. With
Declarative Pipeline and
Blue Ocean
we expect great things for Jenkins in 2017!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hrmpw/">Patrick Wolf</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/12/20/jenkins-puppet-enterprise-plugin/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">20</div></div><h5 class="title">Continuous Delivery with Jenkins and Puppet Enterprise</h5></div><p class="teaser">This is a guest post by Carl Caum,
who works at Puppet and created the
Puppet Enterprise Pipeline plugin.

During PuppetConf 2016, myself and Brian Dawson from CloudBees announced the
plugin:puppet-enterprise-pipeline[Puppet Enterprise
plugin for Jenkins Pipeline].
Let’s take a look at how the plugin makes it trivial to use Puppet to perform
some or all of the deployment tasks in continuous delivery pipelines.

Jenkins Pipeline introduced an amazing world where the definition for a
pipeline is managed from the same version control repository as the code
delivered by the pipeline. This is a powerful idea, and one I felt complemented
Puppet’s automation strengths. I wanted to make it trivial to control Puppet
Enterprise’s orchestration and infrastructure code management capabilities, as
well as set hierarchical configuration data and use Puppet’s inventory data
system as a source of truth – all from a Pipeline script. The result was the
Puppet Enterprise plugin, which fully buys into the Pipeline ideals by
providing methods to control the different capabilities in Puppet Enterprise.
The methods provide ways to query
PuppetDB, set
Hiera key/value pairs, deploy
Puppet code environments with
Code Management, and kick off orchestrated Puppet runs with the
Orchestrator.

The Puppet Enterprise for Jenkins Pipeline plugin

The Puppet Enterprise for Jenkins Pipeline plugin itself has zero system
dependencies. You need only to install the plugin from the update center. The
plugin uses APIs available in Puppet Enterprise to do its work. Since the
PuppetDB query, Code Management, and Orchestrator APIs are all
backed by Puppet Enterprise’s role-based access control (RBAC) system, it’s
easy to restrict what pipelines are allowed to control in Puppet Enterprise. To
learn more about RBAC in Puppet Enterprise,
read the docs here.

Configuring

Configuring the plugin is fairly straight forward. It takes three simple steps:

Set the address of the Puppet server

Create a Jenkins credential with a Pupppet Enterprise RBAC authentication token

Configure the Hiera backend

Set the Puppet Enterprise Server Address

Go to Jenkins &gt; Manage Jenkins &gt; Puppet Enterprise page. Put the DNS address of
the Puppet server in the Puppet Master Address text field. Click the Test
Connection button to verify the server is reachable, the Puppet CA certificate
is retrievable, and HTTPS connections are successful. Once the test succeeds,
Click Save.

Create a Jenkins Credentials Entry

The plugin uses the Jenkins built-in credentials system (the plain-credentials
plugin) to store and refer RBAC tokens to Puppet Enterprise for authentication
and authorization. First, generate an RBAC token in Puppet Enterprise by
following
the
instructions on the docs site. Next, create a new Jenkins Credentials item
with Kind Secret text and the Secret value the Puppet Enterprise RBAC
token. It’s highly recommended to give the credential an ID value that’s
descriptive and identifiable. You’ll use it in your Pipeline scripts.

In your Jenkinsfile, use the puppet.credentials method to set all future Puppet
methods to use the RBAC token. For example:

puppet.credentials &#x27;pe-team-token&#x27;

Configure the Hiera Backend

The plugin exposes an HTTP API for performing Hiera data lookups for key/value
pairs managed by Pipeline jobs. To configure Hiera on the Puppet compile
master(s) to query the Jenkins Hiera data store backend, use the
hiera-http backend. On the
Puppet Enterprise compile master(s), run the following commands:

/opt/puppetlabs/puppet/bin/gem install hiera-http
/opt/puppetlabs/bin/puppetserver gem install hiera-http

Now you can configure the /etc/puppetlabs/puppet/hiera.yaml file. The following
configuration instructs Hiera to first look to the Hiera yaml files in the
Puppet code’s environment, then fall back to the http backend. The http backend
will first query the Hiera data store API looking for the key in the scope with
the same name as the node. If nothing’s found, look for the key in the node’s
environments. You can use any Facter fact to match scope names.

:backends:
  - yaml
  - http

:http:
  :host: jenkins.example.com
  :port: 8080
  :output: json
  :use_auth: true
  :auth_user:
:auth_pass:
:cache_timeout: 10
  :failure: graceful
  :paths:
    - /hiera/lookup?path=%{clientcert}&amp;key=%{key}
    - /hiera/lookup?path=%{environment}&amp;key=%{key}

Finally, restart the pe-puppetserver process to pick up the new configs:

/opt/puppetlabs/bin/puppet resource service pe-puppetserver ensure=stopped
/opt/puppetlabs/bin/puppet resource service pe-puppetserver ensure=running

Hiera HTTP Authentication

If Jenkins&#x27; Global Security is configured to allow unauthenticated read-only
access, the &#x27;use_auth&#x27;, &#x27;auth_pass&#x27;, and &#x27;auth_user&#x27; parameters are
unnecessary. Otherwise, create a local Jenkins user that has permissions to
view the Hiera Data Lookup page and use that user’s credentials for the
hiera.yaml configuration.

Querying the infrastructure

PuppetDB is an extensive data store that holds every bit of information Puppet
generates and collects across every system Puppet is installed on. PuppetDB
provides a sweet query language called
PQL. With PQL,
you can ask complex questions of your infrastructure such as &quot;How many
production Red Hat systems are there with the openssl package installed?&quot; or
&quot;What us-west-2c nodes with the MyApp role that were created in the last 24
hours?&quot;

This can be a powerful tool for parts of your pipeline where you need to
perform specific operations on subsets of the infrastructure like draining a
loadbalancer.

Here’s an example using the puppet.query method:

results = puppet.query &#x27;&#x27;&#x27;
  inventory[certname] {
    facts.os.name = &quot;RedHat&quot; and
    facts.ec2_metadata.placement.availability-zone = &quot;us-west-2c&quot; and
    facts.uptime_hours &lt; 24
  }&#x27;&#x27;&#x27;

The query returns an array of matching items. The results can be
iterated on, and even passed to a series of puppet.job calls. For example, the
following code will query all nodes in production that experienced a failure on
the last Puppet run.

results = puppet.query &#x27;nodes { latest_report_status = &quot;failed&quot; and catalog_environment = &quot;production&quot;}&#x27;

Note that once you can use closures in Pipeline scripts, doing the above
example will be much simpler.

Creating an orchestrator job

The orchestration service in Puppet Enterprise is a tool to perform
orchestrated Puppet runs across as broad or as targeted an infrastructure as
you need at different parts of a pipeline. You can use the orchestrator to
update applications in an environment, or update a specific list of nodes, or
update nodes across a set of nodes that match certain criteria. In each
scenario, Puppet will always push distributed changes in the correct order by
respecting the cross-node dependencies.

To create a job in the Puppet orchestrator from a Jenkins pipeline, use the
puppet.job method. The puppet.job method will create a new orchestrator job,
monitor the job for completion, and determine if any Puppet runs failed. If
there were failures, the pipeline will fail.

The following are just some examples of how to run Puppet orchestration jobs against the infrastructure you need to target.

Target an entire environment:

puppet.job &#x27;production&#x27;

Target instances of an application in production:

puppet.job &#x27;production&#x27;, application: &#x27;Myapp&#x27;

Target a specific list of nodes:

puppet.job &#x27;production&#x27;, nodes: [&#x27;db.example.com&#x27;,&#x27;appserver01.example.com&#x27;,&#x27;appserver02.example.com&#x27;]

Target nodes matching a complex set if criteria:

puppet.job &#x27;production&#x27;, query: &#x27;inventory[certname] { facts.os.name = &quot;RedHat&quot; and facts.ec2_metadata.placement.availability-zone = &quot;us-west-2c&quot; and uptime_hours &lt; 24 }&#x27;

As you can see, the puppet.job command means you can be as broad or as targeted
as you need to be for different parts of your pipeline. There are many other
options you can add to the puppet.job method call, such as setting the Puppet
runs to noop, or giving the orchestrator a maximum concurrency limit.
Learn
more about the orchestrator here.

Updating Puppet code

If you’re using Code Management in Puppet Enterprise (and you should), you can
ensure that all the modules, site manifests, Hiera data, and roles and profiles
are staged, synced, and ready across all your Puppet masters, direct from your
Jenkins pipeline.

To update Puppet code across all Puppet masters, use the puppet.codeDeploy method:

puppet.codeDeploy &#x27;staging&#x27;

Learn more Code Management in Puppet Enterprise here.

Setting Hiera values

The plugin includes an experimental feature to set Hiera key/value pairs. There
are many cases where you need to promote information through a pipeline, such
as a build version or artifact location. Doing so is very difficult in Puppet,
since data promotion almost always involves changing Hiera files and committing
to version control.

The plugin exposes an HTTP API endpoint that Hiera can query using the
hiera-http backend. With the backend configured on the Puppet master(s),
key/value pairs can be set to scopes. A scope is arbitrary and can be anything
you like, such as a Puppet environment, a node’s certname, or the name of a
Facter fact like operatingsystem or domain.

To set a Hiera value from a pipeline, use the puppet.hiera method.

puppet.hiera scope: &#x27;staging&#x27;, key: &#x27;build-version&#x27;, value: env.BUILD_ID

Now you can set the same key with the same value to the production scope later
in the pipeline, followed by a call to puppet.job to push the change out.

Examples

The
plugin’s
Github repository contains a set of example Pipeline scripts. Feel free to
issue pull requests to add your own scripts!

What’s next

I’m pretty excited to see how this is going to help simplify continuous
delivery pipelines. I encourage everyone to get started with continuous
delivery today, even if it’s just a simple pipeline. As your practices evolve,
you can begin to add automated tests, automate away manual checkpoints, start
to incorporate InfoSec tests, and include phases for practices like patch
management that require lots of manual approvals, verifications and rollouts.
You’ll be glad you did.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ccaum/">Carl Caum</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/continuousdelivery">continuousdelivery</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/puppet">puppet</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/puppetenterprise">puppetenterprise</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2016/12/31/what-a-year/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">31</div></div><h5 class="title">Thank you for an amazing 2016</h5></div><p class="teaser">I do not think it is an exaggeration to say: 2016 was the best year yet for the
Jenkins project. Since the first commit in 2006, the project has reached a
number of significant milestones in its ten years but we have never experienced
the breadth of major milestones in such a short amount of time. From
Jenkins 2
and
Blue Ocean
to the
Google Summer of Code
and
Jenkins World,

I wanted to take a moment and celebrate the myriad of accomplishments which
couldn’t have happened without the help from everybody who participates in the
Jenkins project. The 1,300+ contributors to the
jenkinsci GitHub organization,
the 4,000+ members of the
developers mailing list,
the 8,000+ members of the
users mailing list,
and countless others who have reported issues, submitted pull requests, and
presented at meetups and conferences.

Jenkins 2

Through the course of 2016, the Jenkins project published 16
LTS releases
and 54
Weekly releases.
Of those 70 releases, the most notable may have been the
Jenkins 2.0 release
which was published in April.

Jenkins 2 made Pipeline as Code front-and-center in the user experience,
introduced a new &quot;Getting Started&quot; experience, and included a number of other
small UI improvements, all while maintaining backwards compatibility with
existing Jenkins environments.

Since April, we have released a number of LTS
releases using Jenkins 2 as a baseline, meaning the Jenkins project no longer
maintains any 1.x release lines.

The
Pipeline
efforts have continuted to gain steam since April, covered on this blog with a
number of
posts tagged &quot;pipeline&quot;. Closing out 2016 with the
announcement of the beta for
Declarative Pipeline syntax
which is expected in early 2017.

Blue Ocean

Hot on the heels of Jenkins 2 announcement&quot;Blue Ocean, a new user experience for Jenkins&quot;,
was
open sourced in May.
Blue Ocean is a new project that rethinks the user experience of Jenkins.
Designed from the ground up for Jenkins Pipeline and compatible with Freestyle
jobs. The goal for the project is to reduce clutter and increase clarity for
every member of a team using Jenkins.

The Blue Ocean beta can be installed from the Update Center and can be run in
production Jenkins environments alongside the existing UI. It adds the new user experience under
/blue in the environment but does not disturb the existing UI.

Blue Ocean is expected to reach &quot;1.0&quot; in the first half of 2017.

Azure

Also in May of 2016, the Jenkins project announced an exciting
Partnership with Microsoft
to run our project infrastructure on
Azure. While the migration of Jenkins project
infrastructure into Azure is still on-going, there have been some notable
milestones reached already:

End-to-end TLS encrypted delivery for Debian/openSUSE/Red Hat repositories which are
configured to use https://pkg.jenkins.io by the end-user.

Major capacity improvements to
ci.jenkins.io
providing on-demand Ubuntu and Windows build/test infrastructure.

A full continuous delivery Pipeline for all Azure-based infrastructure using
Terraform from Jenkins.

The migration to Azure is expected to complete in 2017.

Google Summer of Code

For the first time in the history of the project, Jenkins was accepted into
Google Summer of Code
2016. Google Summer of Code (GSoC) is an annual, international, program
which encourages college-aged students to participate with open source projects
during the summer break between classes. Students accepted into the program
receive a stipend, paid by Google, to work well-defined projects to improve or
enhance the Jenkins project.

In exchange, numerous Jenkins community members volunteered as &quot;mentors&quot; for
students to help integrate them into the open source community and succeed in
completing their summer projects.

A lot was learned during the summer which we look forward to applying to Google
Summer of Code 2017

Jenkins World

In September, over one thousand people attended
Jenkins World,
in Santa Clara, California.

Following the event,
Liam
posted a series of blog posts which highlight some of the fantastic content
shared by Jenkins users and contributors from around the world, such as:

The demos from the &quot;Experts&quot;

Sessions on Scaling Jenkins

Using Jenkins Pipeline

The Contributor Summit

Jenkins World was the first global event of its kind for Jenkins, it brought users
and contributors together to exchange ideas on the current state of the
project, celebrate accomplishments of the past year, and look ahead at all the
exiting enhancements coming down the pipe(line).

It was such a smashing success that
Jenkins World 2017
is already scheduled for August 30-31st in San Francisco, California.

JAM

Finally, 2016 saw tremendous growth in the number of
Jenkins Area Meetups
(JAMs) hosted around the world. JAMs are local meetups intended to bring
Jenkins users and contributors together for socializing and learning. JAMs are
organized by local Jenkins community members who have a passion for sharing new
Jenkins concepts, patterns and tools.

Driven by current Jenkins Events Officer,
Alyssa Tong,
and the dozens of passionate organizers, JAMs have become a great way to meet
other Jenkins users near you.

While we don’t yet have JAMs on each of the seven continents, you can always join the
Jenkins Online Meetup.
Though we’re hoping more groups will be founded near you in 2017!

I am personally grateful for the variety and volume of contributions made by
thousands of people to the Jenkins project this year. I believe I can speak for
project founder,
Kohsuke Kawaguchi,
in stating that the Jenkins community has grown beyond our anything we could
have imagined five years ago, let alone ten!

There are number of ways to
participate
in the Jenkins project, so if you didn’t have an opportunity to join in during
2016, we hope to see you next year!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins2">jenkins2</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/new-year-blogpost">new-year-blogpost</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/10/jenkins-lifx-notifier-plugin/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">10</div></div><h5 class="title">Learning plugin development by improving the LIFX notifier plugin</h5></div><p class="teaser">This is a
cross
post by Veaceslav Gaidarji, open source
developer and contributor to the Jenkins and Bitrise projects.

Some time ago I encountered a LIFX smart bulbs.
These are the bulbs with a chip inside - 50% bulb, 50% chip. There are mobile
applications for easy configuration and remote control of the bulb. Nothing
special here, it simply works and is very convenient to have such bulbs in
dormitory.

Brilliant idea time

99% of ideas which come to our minds either were already implemented by someone
else or they are useless.

— Veaceslav Gaidarji

And as it always happens, the developer inside me generated an idea which, as
it always happens, was implemented by someone else already.

The idea was: to connect a LIFX bulb to Jenkins server and update the color
according to a job’s state.

Before starting to work on such Jenkins plugin, I searched for similar projects
on Google and the first links pointed me to existing
LIFX notifier plugin
and a
blog post
from
Michael Neale
who created the plugin. Michael’s post describes exactly what I had in mind.

At this point I had 2 options:

forget about building something new and just use the plugin

improve existing plugin

First option is always easy and effortless, but second one is more challenging.

Improving an existing plugin

The existing LIFX notifier plugin
did its job really well and I was able to connect my bulb to Jenkins and test
it. But it wasn’t complete and had no configurable at all, therefore no
possibility to change the colors.

First, I read Jenkins contribution guidelines, which
encourage
developers to improve existing plugins (if any) and not create other versions
of plugins with similar functionality. Then I contacted the plugin author, Michael Neale,
via email and kindly asked for the contributor access in GitHub
for the existing plugin version. After a short discussion about my plans on this
plugin, Michael added me as a contributor to GitHub
repo and wished me
good luck. Thanks Michael!

I wanted to improve the LIFX notifier plugin to add the ability
customize the colors ( in progress, build success and build failure). This
is not a hard task actually.
A 1000+ plugins were
developed for Jenkins by the hackers like me, which means that I should have no
problem to do it as well.
Fortunately for me, I have used some plugins already which had a UI similar to
that I had planned to add to the LIFX notifier, such as:

HockeyApp plugin

Fabric Beta publisher plugin

Different Build notifiers plugins

Reviewing the code for these plugins, plus Jenkins
plugin
development documentation, and of course looking over
Jelly components helped
me to:

Better understand the Jenkins architecture.

Learn how Jenkins plugins work in general.

Learn how to create the UI components for a plugin.

Learn how to subscribe to Jenkins job state changes using appropriate
extension points.

In a few weeks I’ve finished my plugin modifications and added unit tests for
its major parts.  As a result, the plugin now has a UI configuration section in
Post-build Actions which is self descriptive:

The last step was to prepare new plugin version and publish it to the world!
The Jenkins&quot;Hosting
plugins&quot; document describes step by step process of how to publish a plugin.

This includes many steps which should be respected very carefully.

Demo

What I’ve learned

It was my first experience in Jenkins plugins development. I should say that
steep learning curve is high enough, and sometimes is really hard to find
answers on appearing questions. But in general it’s all about Java, XML,
Maven and it’s a lot of fun developing Jenkins plugins.

Check out the LIFX notifier page
for more information about the latest releases!

Bonus : bitrise.io users, I’ve developed step LIFX notifier for bitrise as well.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/vgaidarji/">Veaceslav Gaidarji</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/lifx">lifx</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/10/security-warnings/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">10</div></div><h5 class="title">Security warnings in Jenkins</h5></div><p class="teaser">Jenkins 2.40 was released earlier this week, and readers of the
changelog
will have noticed that it now includes the ability to show security warnings
published by the configured update site.  But what does that mean?

In the past, we’ve notified users about security issues in Jenkins and in
plugins through various means: Emails to the
jenkinsci-advisories mailing list
(which I recommend you subscribe to), blog posts, and, recently, emails to the
oss-security mailing list.  But I still wanted to increase the reach of our
notifications, to make sure Jenkins admins are informed quickly about possible
security problems on their instances.  The logical next step was to include
these notifications in Jenkins itself, and that feature has been added in
Jenkins 2.40.

Today we enabled the publication of warnings on our update sites: Once Jenkins
2.40 (or newer) refreshes its cache of update site metadata, it may now inform
you that you’re using a vulnerable plugin that should be updated or removed.
Right now, these aren’t previously unknown warnings, but reference security
advisories for plugin vulnerabilies that have been published over the past few
years.

We will of course continue to publish security advisories using the mailing
list of the same name, as well other means.

Stay safe!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/11/jenkins-world-2017-cfp/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">11</div></div><h5 class="title">Jenkins World 2017 Call for Papers is Open</h5></div><p class="teaser">The largest Jenkins event, Jenkins
World is coming to San Francisco, California on August 28 - 31, 2017, at the
Marriott Marquis.  This conference will feature two days of hands-on training,
workshops, and certification exams followed by two more days with five tracks
of technical sessions from Jenkins and DevOps experts from around the world.

Inspire your peers and colleagues by sharing your expertise and experience as
one of the Jenkins World speakers.
The Call for Papers is open, last
day for submitted a proposal is March 5th, 2017.

Compared to Jenkins World 2016, what’s new for
2017?  Two tracks are now dedicated to &quot;show and tell.&quot; These sessions are
technically advanced with code sharing, heavy on demos, and only a few slides.
If you are like most of us - driven to learn, share, and collaborate…​we’d
like to hear from you!

Looking forward to your amazing proposal(s)!

Submit your proposal here!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/12/declarative-pipeline-beta-2/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">12</div></div><h5 class="title">Declarative Pipeline Syntax Beta 2 release</h5></div><p class="teaser">This week, we released the second beta of the new
Declarative Pipeline syntax,
available in the Update Center now as version 0.8.1 of Pipeline: Model Definition.
You can read more about Declarative Pipeline
in the blog post introducing the first beta
from December, but we wanted to update you all on the syntax changes in the
second beta. These syntax changes are the last compatibility-breaking changes to
the syntax before the 1.0 release planned for February, so you can safely start
using the 0.8.1 syntax now without needing to change it when 1.0 is released.

A full syntax reference is available on the wiki as well.

Syntax Changes

Changed &quot;agent&quot; configuration to block structure

In order to support more detailed and clear configuration of agents, as well as
making agent syntax more consistent with the rest of the Declarative Pipeline
syntax, we’ve moved the agent configuration into blocks. The agent any and
agent none configurations work the same as previously, but label, docker
and dockerfile now look like the following:

Just specifying a label is simple.

// Declarative //
agent {
    label &quot;some-label&quot;
}
// Script //

If you’re just specifying a Docker image, you can use this simple syntax.

// Declarative //
agent {
    docker &quot;ubuntu:16.04&quot;
}
// Script //

When you are specifying a label or other arguments, docker looks like this:

// Declarative //
agent {
    docker {
        image &quot;ubuntu:16.04&quot;
        label &quot;docker-label&quot;
        args &quot;-v /tmp:/tmp -p 8000:8000&quot;
    }
}
// Script //

When you’re building an image from &quot;Dockerfile&quot; in your repository and
don’t care what node is used or have additional arguments, you can again
use a simple syntax.

// Declarative //
agent {
    dockerfile true
}
// Script //

When you’re building an image from a different file, or have a label or other
arguments, use the following syntax:

// Declarative //
agent {
    dockerfile {
        filename &quot;OtherDockerfile&quot;
        label &quot;docker-label&quot;
        args &quot;-v /tmp:/tmp -p 8000:8000&quot;
    }
}
// Script //

Improved &quot;when&quot; conditions

We introduced the when section a couple releases ago, but have made some
changes to its syntax here in 0.8.1. We wanted to add some simpler ways to
specify common conditions, and that required we re-work the syntax accordingly.

Branch

One of the most common conditions is running a stage only if you’re on a
specific branch. You can also use wildcards like &quot;*/master&quot;.

// Declarative //
when {
    branch &quot;master&quot;
}
// Script //

Environment

Another built-in condition is the environment condition, which checks to see
if a given environment variable is set to a given value.

// Declarative //
when {
    environment name: &quot;SOME_ENV_VAR&quot;, value: &quot;SOME_VALUE&quot;
}
// Script //

Expression

Lastly, there’s the expression condition, which resolves an arbitrary
Pipeline expression. If the return value of that expression isn’t false or
null, the stage will execute.

// Declarative //
when {
    expression {
        echo &quot;Should I run?&quot;
        return &quot;foo&quot; == &quot;bar&quot;
    }
}
// Script //

&quot;options&quot; replaces &quot;properties&quot; and &quot;wrappers&quot;

We’ve renamed the properties section to options, due to needing to add new
Declarative-specific options and to cut down on confusion. The options section
is now where you’ll put general Pipeline options like buildDiscarder,
Declarative-specific options like skipDefaultCheckout, and block-scoped steps
that should wrap the execution of the entire build, like timeout or
timestamps.

// Declarative //

options {
    buildDiscarder(logRotator(numToKeepStr:&#x27;1&#x27;))
    skipDefaultCheckout()
    timeout(time: 5, unit: &#x27;MINUTES&#x27;)
}
// Script //

Heading towards 1.0!

While we may still add more functionality to the Declarative Pipeline syntax,
we won’t be making any changes to existing syntax for the 1.0 release. This
means that any pipelines you write against the 0.8.1 syntax will keep working
for the foreseeable future without any changes. So if you’re already using
Declarative Pipelines, make sure to update your `Jenkinsfile`s after upgrading
to 0.8.1, and if you haven’t been using Declarative Pipelines yet, install the
Pipeline: Model Definition plugin and
give them a try!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/13/blueocean-dev-log-jan/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">13</div></div><h5 class="title">Blue Ocean Dev Log: January Week #2</h5></div><p class="teaser">As we get closer to
Blue Ocean
1.0, which is planned for the end of March, I figured it would be great to
highlight some of the good stuff that has been going on. It’s been a
busy-as-usual week as everyone comes back from vacation.  A couple of new betas
went out this week. Of note:

input to Pipelines is now supported, a much asked for feature (see below)

A new French translation

Some optimisations (especially around reducing number of HTTP calls). We
have started using
gtmetrix.com
to measure changes on&quot;dogfood&quot;
to get some numbers around optimisations on the web tier.

And a grab bag of other great bug fixes.

Also a bunch of work has been done to support parametrized pipelines, as
well as creation of new multibranch pipelines (both are much asked for).

There is also now an &quot;official&quot; Docker image being published to
Docker Hub. The Pipeline
building the container is run weekly and will be picking up newly tagged
releases of Blue Ocean.

Running the latest can be as simple as:

docker run -p 8888:8080 jenkinsci/blueocean:latest

This is built on the incredibly popular
official &quot;jenkins&quot; image
(10M pulls can’t all be wrong!). The container also has tags available (e.g.
jenkinsci/blueocean:1.0.0-b16) for grabbing a specific released version.

Up next for Blue Ocean development as we march towards 1.0:

Support for parametrized jobs. For which a bunch of api work has already been
done.

Creation of the new Pipeline GUI

Preview release of the Visual Editor for
Declarative Pipeline.

The new header design will be applied

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/17/Jenkins-is-upgrading-to-Java-8/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">17</div></div><h5 class="title">Jenkins Upgrades To Java 8</h5></div><p class="teaser">In the next few months, Jenkins will require Java 8 as its runtime.

Back in
last November,
we discussed interesting statistics showing that Jenkins was now running Java 8
on a majority of its running instances.

Timeline

Here is how we plan to roll that baseline upgrade in the next few months.

Now: Announce the intention publicly.

April, 2017: Drop support for Java 7 in Jenkins weekly.
With the current rhythm, that means 2.52 will most likely be the first weekly to require Java 8.

June 2017: First LTS version requiring Java 8 is published.
This should be something around 2.60.1.

If you are still running Java 7, you will not be able to upgrade to the latest LTS version after some date probably around May 2017.

Why Upgrade to Java 8

Balancing those numbers with many other criteria:

Java 7 has been now end-of-lifed for 18+ months

People are already moving away from Java 7, as show the numbers

52.8% of instances were already running Java 8 back in last November, and now reaching 58% two months later.

If we only look at Jenkins 2.x, then we reach 72%.

Java 8 runtime is known from the field to be more stable

Many developers have been wanting to be allowed to leverage the improvements that Java 8 provides to the language and platform
(lambdas, Date/Time API…​ just to name a few).
Being also a developer community, we want Jenkins to be appealing to contributors.

If you have questions or feedback about this announcement, please feel free to post it to the Jenkins developers mailing list.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java8">java8</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/upgrade">upgrade</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/17/scm-api-2.0-release/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">17</div></div><h5 class="title">SCM API turns 2.0 and what that means for you</h5></div><p class="teaser">The regressions
discovered after release have now been resolved and this post has been updated with the correct plugin version numbers.

See this post for more details.

We are announcing the
SCM API
2.0.x and
Branch API
2.0.x release lines.

Downstream of this there are also some great improvements to a number of popular plugins including:

GitHub Branch Source

BitBucket branch source

Git

Mercurial

Pipeline Multibranch

GitHub Organization Folders

There are some gotcha’s that Jenkins administrators will need to be aware of.

Always take a backup of your JENKINS_HOME before upgrading any plugins.

We want to give you the whole story, but the take home message is this:

When updating the
SCM API
and/or
Branch API
plugins to the 2.0.x release lines, if you have any of the
GitHub Organization Folders,
GitHub Branch Source
and/or
BitBucket branch source
plugins installed then you must upgrade them all to 2.0.x at the same time or Bad Things™ will happen.

— A Jenkins Administrator

Do NOT upgrade some of these plugins but not others!
Doing so may cause your jobs to fail to load.

If you don’t care about the hows and whys, you can just skip down to this section but if you are curious…​ here we go!

The back-story

Way back in September 2013 we announced the
Literate plugin,
as an experimental new way of modeling branch development in Jenkins.

When you are performing an experiment, the recommendation is to do just enough work to let you perform the test.
However, the culture in Jenkins is to always try and produce reusable components that others can use in ways you have not anticipated.

So when releasing the initial version of the
Literate plugin
we also separated the Literate specific bits from the SCM specific concepts and multi-branch concepts.
These were lower level concepts were organized into the following plugins:

SCM API -
which was intended to be a plugin to hold a next generation API for interacting with source control systems.

Branch API -
which was intended to be a plugin to hold the multi-branch functionality that was abstracted from the usage by the Literate plugin.

In addition, we released updates to three of the more common SCM plugins which included implementations of the SCM API:

Git plugin

Subversion plugin

Mercurial plugin

While there was some interest in the Literate plugin, it did not gain much traction - there are only 39 Jenkins instances running the Literate plugin as of December 2016.

In terms of the reusable components, we had only made a minimal implementation with some limitations:

Very basic event support - events can only trigger a re-scan of the entire repository.
This was acceptable at the time because the only three implementations use a local cache of the remote state so re-scanning is quick.

No implementation of the SCMFileSystem API.
As a result it is not possible for plugins like
Pipeline Multibranch
to get the Jenkinsfile from the remote repository without needing to checkout the repository into a workspace.

No documentation on how plugin developers are supposed to implement the SCM API

No documentation on how plugin developers are supposed to consume the SCM API (if they wanted to do something like Branch API but not the same way as Branch API)

No documentation on how plugin developers are supposed to implement the Branch API to create their own multi-branch project types

No documentation on for users on how the Branch API based project types are expected to work.

Roll forward to November 2015 and Jenkins Pipeline got a release of the
Pipeline Multibranch.
It seems that pairing Pipeline with Branch API style multi-branch is much more successful than Literate - there are close to 60,000 instances running the pipeline multi-branch plugin as of December 2016.

There also were two new SCM plugins implementing the SCM API:

GitHub Branch Source Plugin

BitBucket Branch Source Plugin

Unlike the previous implementations of the SCM API, however, these plugins do not maintain a local cache of the repository state.
Rather they make queries via the GitHub / BitBucket REST APIs on demand.

The above design decision exposed one of the initial MVP compromises of the SCM API plugin: very basic event support.
Under the SCM API 1.x model, the only event that an SCMSource can signal is something changed, go look at everything again.
When you are accessing an API that only allows 5,000 API calls per hour, performing a full scan of the entire repository just to pick up a change in one branch does not make optimum usage of that 5,000 calls/hour rate limit.

So we decided that perhaps the SCM API and Branch API plugins have left their Minimum Viability Experiment state and the corresponding limitations should be addressed.

Enter SCM API 2.0.x and Branch API 2.0.x

So what has changed in the
SCM API
2.0.x and
Branch API
2.0.x release lines?
These plugin releases include:

documentation on how plugin developers are supposed to
implement the SCM API

documentation on how plugin developers are supposed to
consume the SCM API
(if they wanted to do something like Branch API but not the same way as Branch API)

documentation on how plugin developers are supposed to
implement the Branch API
to create their own multi-branch project types

generic documentation for users on
how Branch API based project types are intended to work

a full featured
event system
that allows implementers to provide fine grained notifications to consumers

lots
and
lots
of new automated tests

a mock implementation
of the SCM API to help consumers of the SCM API test their usage.

In addition, we have upgraded the following plugins to include the new fine-grained event support:

Git Plugin

Mercurial Plugin

Ok, that was the good news.
Here is the bad news.

We found out that the GitHub Branch Source and BitBucket Branch Source plugins had made invalid assumptions about how to implement the SCM API.
To be clear, this was not the plugin developers fault: at the time there was no documentation on how to implement the SCM API.

But fixing the issues that we found means that you have to be careful about which specific combinations of plugin versions you have installed.

SCM API Plugin

Technically, the 2.0.x line of this plugin is both API and on-disk compatible with plugins compiled against older version lines.

However, the 1.x lines of both the GitHub Branch Source and BitBucket Branch Source plugins have hard-coded assumptions about internal implementation of the SCM API that are no longer valid in the 2.0.x line.

If you upgrade to SCM API 2.0.x and you have either the GitHub Branch Source or the BitBucket Branch Source plugins and you do not upgrade those instances to the 2.0.x line then your Jenkins instance will fail to start-up correctly.

The solution is just to upgrade the GitHub Branch Source or the BitBucket Branch Source plugin (as appropriate) to the 2.0.x line.

If you upgrade the SCM API plugin to the 2.0.x line and do not upgrade the Branch API plugin to the 2.0.x line then you will not get any of the benefits of the new version of the SCM API plugin.

Branch API Plugin

The 2.0.x line of this plugin makes on-disk file format changes that mean you will be unable to roll back to the 1.x line after an upgrade without restoring the old data files from a back-up.
Technically, the API is compatible with plugins compiled against older version lines.

The 1.x lines of both the GitHub Branch Source and BitBucket Branch Source plugins have implemented hacks that make assumptions about internal implementation of the Branch API that are no longer valid in the 2.0.x line.

The Pipeline Multibranch plugin made a few minor invalid assumptions about how to implement a Multibranch project type.
For example, if you do not upgrade the Pipeline Multibranch plugin in tandem then you will be unable to manually delete an orphaned item before the orphaned item retention strategy runs, which should be significantly less frequently with the new event support.

If you upgrade to Branch API 2.0.x and you have either the GitHub Branch Source or the BitBucket Branch Source plugins and you do not upgrade those instances to the 2.0.x line then your Jenkins instance will fail to start-up correctly.

The solution is just to upgrade the GitHub Branch Source or the BitBucket Branch Source plugin (as appropriate) to the 2.0.x line.

Git Plugin

The new releases of this plugin are both API and on-disk compatible with plugins compiled against the previous releases.

The 2.0.x lines of both the GitHub Branch Source and BitBucket Branch Source plugins require that you upgrade your Git Plugin to one of the versions that supports SCM API 2.0.x.
In general, the required upgrade will be performed automatically when you upgrade your GitHub Branch Source and BitBucket Branch Source plugins.

Mercurial Plugin

The new release of this plugin is both API and on-disk compatible with plugins compiled against the previous releases.

The 2.0.x line of the BitBucket Branch Source plugins require that you upgrade your Mercurial Plugin to the 2.0.x line.
In general, the required upgrade will be performed automatically when you upgrade your  BitBucket Branch Source plugins.

BitBucket Branch Source Plugin

The 2.0.x line of this plugin makes on-disk file format changes that mean you will be unable to roll back to the 1.x line after an upgrade without restoring the old data files from a back-up.

GitHub Branch Source Plugin

The 2.0.x line of this plugin makes on-disk file format changes that mean you will be unable to roll back to the 1.x line after an upgrade without restoring the old data files from a back-up.

If you upgrade to GitHub Branch Source 2.0.x and you have the GitHub Organization Folders plugin installed, you must upgrade that plugin to the tombstone release.

GitHub Organization Folders Plugin

The functionality of this plugin has been migrated to the GitHub Branch Source plugin.
You will need to upgrade to the tombstone release in order to ensure all the data has been migrated to the classes in the GitHub Branch Source plugin.

Once you have upgraded to the tombstone version and all GitHub Organization Folders have had a full scan completed successfully, you can disable and uninstall the GitHub Organization Folders plugin.
There will be no more releases of this plugin after the tombstone.
The tombstone is only required for data migration.

Summary for busy Jenkins Administrators

Upgrading should make multi-branch projects much better.
When you are ready to upgrade you must ensure that you upgrade all the required plugins.
If you miss some, just upgrade them and restart to fix the issue.

Folders Plugin

5.16 5.17 or newer

SCM API Plugin

2.0.1 2.0.2 or newer

Branch API Plugin

2.0.0 2.0.2 or newer

Git Plugin

Either 2.6.2 2.6.4 or newer in the 2.6.x line or 3.0.2 3.0.4 or newer

Mercurial Plugin

2.0.0 or newer

GitHub Branch Source Plugin

2.0.0 2.0.1 or newer

BitBucket Branch Source Plugin

2.0.0 2.0.2 or newer

GitHub Organization Folders Plugin

1.6

Pipeline Multibranch Plugin

2.10 2.12 or newer

If you are using the Blue Ocean plugin

Blue Ocean Plugin

1.0.0-b22 or newer

Other plugins that may require updating:

GitHub API Plugin

1.84 or newer

GitHub Plugin

1.25.0 or newer

After an upgrade you will see the data migration warning (see the screenshot in JENKINS-41608 for an example) this is normal and expected.
The unreadable data will be removed by the next scan / index or can be removed manually using the Discard Unreadable Data button.
The warning will disappear on the next restart after the unreadable data has been removed.

Summary for busy Jenkins users

SCM API 2.0.x adds fine-grained event support.
This should significantly improve the responsiveness of multi-branch projects.
This should significantly reduce your GitHub API rate limit usage.

If you are using the
GitHub Branch Source
or
GitHub Organization Folders
plugins then upgrading will significantly reduce the API calls made by Jenkins to GitHub.

If you are using any of the upgraded SCM plugins (e.g. Git, Mercurial, GitHub Branch Source, BitBucket Branch Source) then upgrading will significantly improve the responsiveness to push event notifications.

Summary for busy SCM plugin developers

You should read the new
documentation
on how plugin developers are supposed to implement the SCM API

Where to now dear Literate Plugin

The persistent reader may be wondering what happens now to the Literate plugin.

For me, the logical heir of the Literate Plugin is the
Pipeline Model Definition plugin.
This new plugin has the advantage of an easy to read pipeline syntax with the extra functionality that I suspect was preventing people from adopting Literate.

The good news is that the Pipeline Model Definition already has 5000 installations as of December 2016 and I expect up-take to keep on growing.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stephenc/">Stephen Connolly</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/19/converting-conditional-to-pipeline/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">19</div></div><h5 class="title">Converting Conditional Build Steps to Jenkins Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Introduction

With all the new developments in
Jenkins Pipeline (and
Declarative Pipeline on the horizon),
it’s easy to forget what we did to create &quot;pipelines&quot; before
Pipeline.
There are number of plugins, some that have been around since the very beginning,
that enable users to create &quot;pipelines&quot; in Jenkins.
For example, basic job chaining worked well in many cases, and the
Parameterized Trigger plugin
made chaining more flexible.
However, creating chained jobs with conditional behavior was
still one of the harder things to do in Jenkins.

The
Conditional BuildStep plugin
is a powerful tool that has allowed Jenkins users to write Jenkins jobs with complex conditional logic.
In this post, we’ll take a look at how we might converting Freestyle jobs that
include conditional build steps to Jenkins Pipeline.
Unlike Freestyle jobs, implementing conditional operations in Jenkins Pipeline is trivial,
but matching the behavior of complex conditional build steps will require a bit more care.

Graphical Programming

The Conditional BuildStep plugin lets users add conditional logic to Freestyle
jobs from within the Jenkins web UI.  It does this by:

Adding two types of Conditional BuildStep (&quot;Single&quot; and &quot;Multiple&quot;) -
these build steps contain one or more other build steps to be run when the configured
condition is met

Adding a set of Condition operations -
these control whether the Conditional BuildStep execute the contained step(s)

Leveraging the Token Macro facility -
these provide values to the Conditions for evaluation

In the example below, this project will run the shell script step when the value of the
REQUESTED_ACTION token equals &quot;greeting&quot;.

Here’s the output when I run this project with REQUESTED_ACTION set to &quot;greeting&quot;:

Run condition [Strings match] enabling prebuild for step [Execute shell]
Strings match run condition: string 1=[greeting], string 2=[greeting]
Run condition [Strings match] enabling perform for step [Execute shell]
[freestyle-conditional] $ /bin/sh -xe /var/folders/hp/f7yc_mwj2tq1hmbv_5n10v2c0000gn/T/hudson5963233933358491209.sh
+ echo &#x27;Hello, bitwiseman!&#x27;
Hello, bitwiseman!
Finished: SUCCESS

And when I pass the value &quot;silence&quot;:

Run condition [Strings match] enabling prebuild for step [Execute shell]
Strings match run condition: string 1=[silence], string 2=[greeting]
Run condition [Strings match] preventing perform for step [Execute shell]
Finished: SUCCESS

This is a simple example but the conditional step can contain any regular build step.
When combined with other plugins, it can control whether to send notifications,
gather data from other sources, wait for user feedback, or call other projects.

The Conditional BuildStep plugin does a great job of leveraging strengths of
the Jenkins web UI, Freestyle jobs, and UI-based programming,
but it is also hampered by their limitations.
The Jenkins web UI can be clunky and confusing at times.
Like the steps in any Freestyle job, these conditional steps are only
stored and viewable in Jenkins.
They are not versioned with other product or build code and can’t be code reviewed.
Like any number of UI-based programming tools, it has to make trade-offs between clarity
and flexibility: more options or clearer presentation.
There’s only so much space on the screen.

Converting to Pipeline

Jenkins Pipeline, on the other hand, enables users to implement their pipeline as code.
Pipeline code can be written directly in the Jenkins Web UI or in any text editor.
It is a full-featured programming language,
which gives users access to much broader set of conditional statements
without the restrictions of UI-based programming.

So, taking the example above, the Pipeline equivalent is:

// Declarative //
pipeline {
    agent any
    parameters {
        choice(
            choices: [&#x27;greeting&#x27; , &#x27;silence&#x27;],
            description: &#x27;&#x27;,
            name: &#x27;REQUESTED_ACTION&#x27;)
    }

    stages {
        stage (&#x27;Speak&#x27;) {
            when {
                // Only say hello if a &quot;greeting&quot; is requested
                expression { params.REQUESTED_ACTION == &#x27;greeting&#x27; }
            }
            steps {
                echo &quot;Hello, bitwiseman!&quot;
            }
        }
    }
}
// Script //
properties ([
    parameters ([
        choice (
            choices: [&#x27;greeting&#x27;, &#x27;silence&#x27;],
            description: &#x27;&#x27;,
            name : &#x27;REQUESTED_ACTION&#x27;)
    ])
])

node {
    stage (&#x27;Speak&#x27;) {
        // Only say hello if a &quot;greeting&quot; is requested
        if (params.REQUESTED_ACTION == &#x27;greeting&#x27;) {
            echo &quot;Hello, bitwiseman!&quot;
        }
    }
}

When I run this project with REQUESTED_ACTION set to &quot;greeting&quot;, here’s the output:

[Pipeline] node
Running on osx_mbp in /Users/bitwiseman/jenkins/agents/osx_mbp/workspace/pipeline-conditional
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Speak)
[Pipeline] echo
Hello, bitwiseman!
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
Finished: SUCCESS

When I pass the value &quot;silence&quot;, the only change is &quot;Hello, bitwiseman!&quot; is not printed.

Some might argue that the Pipeline code is a bit harder to understand on first reading.
Others would say the UI is just as confusing if not more so.
Either way, the Pipeline representation is considerably more compact than the Jenkins UI presentation.
Pipeline also lets us add helpful comments, which we can’t do in the Freestyle UI.
And we can easily put this Pipeline in a Jenkinsfile to be code-reviewed, checked-in, and versioned
along with the rest of our code.

Conditions

The previous example showed the &quot;Strings match&quot; condition and its Pipeline equivalent.
Let’s look at couple more interesting conditions and their Jenkins Pipeline equivalents.

Boolean condition

You might think that a boolean condition would be the simplest condition, but it isn’t.
Since it works with string values from tokens, the Conditional BuildStep plugin offers
a number of ways to indicate true or false.
Truth is a case insensitive match of one of the following:
1 (the number one), Y, YES, T, TRUE, ON or RUN.

Pipeline can duplicate these, but depending on the scenario we might consider
whether a simpler expression would suffice.

Pipeline

// Declarative //
when {
    // case insensitive regular expression for truthy values
    expression { return token ==~ /(?i)(Y|YES|T|TRUE|ON|RUN)/ }
}
steps {
    /* step */
}

// Script //
// case insensitive regular expression for truthy values
if (token ==~ /(?i)(Y|YES|T|TRUE|ON|RUN)/) {
    /* step */
}

Logical &quot;OR&quot; of conditions

This condition wraps other conditions.
It takes their results as inputs and performs a logical &quot;or&quot; of the results.
The AND and NOT conditions do the same, performing their respective operations.

Pipeline

// Declarative //
when {
    // A or B
    expression { return A || B }
}
steps {
    /* step */
}

// Script //
// A or B
if (A || B) {
    /* step */
}

Tokens

Tokens can be considerably more work than conditions.
There are more of them and they cover a much broader range of behaviors.
The previous example showed one of the simpler cases, accessing a build parameter,
where the token has a direct equivalent in Pipeline.
However, many tokens don’t have direct equivalents,
some take a parameters (adding to their complexity),
and some provide information that is simply not exposed in Pipeline yet.
So, determining how to migrate tokens needs to be done on case-by-case basis.

Let’s look at a few examples.

&quot;FILE&quot; token

Expands to the contents of a file. The file path is relative to the build workspace root.

${FILE,path=&quot;PATH&quot;}

This token maps directly to the readFile step.
The only difference is the file path for readFile is relative to the
current working directory on the agent, but that is the workspace root by default.
No problem.

Pipeline

// Declarative //
when {
    expression { return readFile(&#x27;pom.xml&#x27;).contains(&#x27;mycomponent&#x27;) }
}
steps {
    /* step */
}

// Script //
if (readFile(&#x27;pom.xml&#x27;).contains(&#x27;mycomponent&#x27;)) {
    /* step */
}

GIT_BRANCH

Expands to the name of the branch that was built.

Parameters (descriptions omitted): all, fullName.

This information may or may not be exposed in Pipeline.  If you’re using the
Pipeline Multibranch plugin
env.BRANCH_NAME will give similar basic information, but doesn’t offer the parameters.
There are also
several
issues
filed around GIT_* tokens in Pipeline.
Until they are addressed fully, we can follow the pattern shown in
pipeline-examples,
executing a shell to get the information we need.

Pipeline

GIT_BRANCH = sh(returnStdout: true, script: &#x27;git rev-parse --abbrev-ref HEAD&#x27;).trim()

CHANGES_SINCE_LAST_SUCCESS

Displays the changes since the last successful build.

Parameters (descriptions omitted):
reverse, format, changesFormat, showPaths, pathFormat,
showDependencies, dateFormat, regex, replace, default.

Not only is the information provided by this token not exposed in Pipeline,
the token has ten optional parameters, including format strings and regular expression
searches. There are a number of ways we might get similar information in Pipeline.
Each have their own particular limitations and ways they differ from the token output.
Then we’ll need to consider how each of the parameters changes the output.
If nothing else, translating this token is clearly beyond the scope of this post.

Slightly More Complex Example

Let’s do one more example that shows some of these conditions and tokens.
This time we’ll perform different build steps depending on what branch we’re building.
We’ll take two build parameters: BRANCH_PATTERN and FORCE_FULL_BUILD.
Based on BRANCH_PATTERN, we’ll checkout a repository.
If we’re building on the master branch or the user checked FORCE_FULL_BUILD,
we’ll call three other builds in parallel
( full-build-linux, full-build-mac, and full-build-windows),
wait for them to finish, and report the result.
If we’re not building on the master branch and the user did not check FORCE_FULL_BUILD,
we’ll print a message saying we skipped the full builds.

Freestyle

Here’s the configuration for Freestyle version.
(It’s pretty long.  Feel free to skip down to the Pipeline version):

The Pipeline version of this job determines the GIT_BRANCH branch by
running a shell script that returns the current local branch name.
This means that the Pipeline version must checkout to a local branch (not a detached head).

Freestyle version of this job does not require a local branch, GIT_BRANCH is set automatically.
However, to maintain functional parity, the Freestyle version of this job includes
&quot;Checkout to Specific Local Branch&quot; as well.

Pipeline

Here’s the equivalent Pipeline:

Freestyle version of this job is not stored in source control.

In general, the Pipeline version of this job would be stored in source control,
would checkout scm, and would run that same repository.
However, to maintain functional parity, the Pipeline version shown does a checkout
from source control but is not stored in that repository.

Pipeline

// Script //
properties ([
    parameters ([
        string (
            defaultValue: &#x27;*&#x27;,
            description: &#x27;&#x27;,
            name : &#x27;BRANCH_PATTERN&#x27;),
        booleanParam (
            defaultValue: false,
            description: &#x27;&#x27;,
            name : &#x27;FORCE_FULL_BUILD&#x27;)
    ])
])

node {
    stage (&#x27;Prepare&#x27;) {
        checkout([$class: &#x27;GitSCM&#x27;,
            branches: [[name: &quot;origin/${BRANCH_PATTERN}&quot;]],
            doGenerateSubmoduleConfigurations: false,
            extensions: [[$class: &#x27;LocalBranch&#x27;]],
            submoduleCfg: [],
            userRemoteConfigs: [[
                credentialsId: &#x27;bitwiseman_github&#x27;,
                url: &#x27;https://github.com/bitwiseman/hermann&#x27;]]])
    }

    stage (&#x27;Build&#x27;) {
        GIT_BRANCH = &#x27;origin/&#x27; + sh(returnStdout: true, script: &#x27;git rev-parse --abbrev-ref HEAD&#x27;).trim()
        if (GIT_BRANCH == &#x27;origin/master&#x27; || params.FORCE_FULL_BUILD) {

            // Freestyle build trigger calls a list of jobs
            // Pipeline build() step only calls one job
            // To run all three jobs in parallel, we use &quot;parallel&quot; step
            // https://jenkins.io/doc/pipeline/examples/#jobs-in-parallel
            parallel (
                linux: {
                    build job: &#x27;full-build-linux&#x27;, parameters: [string(name: &#x27;GIT_BRANCH_NAME&#x27;, value: GIT_BRANCH)]
                },
                mac: {
                    build job: &#x27;full-build-mac&#x27;, parameters: [string(name: &#x27;GIT_BRANCH_NAME&#x27;, value: GIT_BRANCH)]
                },
                windows: {
                    build job: &#x27;full-build-windows&#x27;, parameters: [string(name: &#x27;GIT_BRANCH_NAME&#x27;, value: GIT_BRANCH)]
                },
                failFast: false)

        } else {
            echo &#x27;Skipped full build.&#x27;
        }
    }
}
// Declarative //
pipeline {
    agent any
    parameters {
        string (
            defaultValue: &#x27;*&#x27;,
            description: &#x27;&#x27;,
            name : &#x27;BRANCH_PATTERN&#x27;)
        booleanParam (
            defaultValue: false,
            description: &#x27;&#x27;,
            name : &#x27;FORCE_FULL_BUILD&#x27;)
    }

    stages {
        stage (&#x27;Prepare&#x27;) {
            steps {
                checkout([$class: &#x27;GitSCM&#x27;,
                    branches: [[name: &quot;origin/${BRANCH_PATTERN}&quot;]],
                    doGenerateSubmoduleConfigurations: false,
                    extensions: [[$class: &#x27;LocalBranch&#x27;]],
                    submoduleCfg: [],
                    userRemoteConfigs: [[
                        credentialsId: &#x27;bitwiseman_github&#x27;,
                        url: &#x27;https://github.com/bitwiseman/hermann&#x27;]]])
            }
        }

        stage (&#x27;Build&#x27;) {
            when {
                expression {
                    GIT_BRANCH = &#x27;origin/&#x27; + sh(returnStdout: true, script: &#x27;git rev-parse --abbrev-ref HEAD&#x27;).trim()
                    return GIT_BRANCH == &#x27;origin/master&#x27; || params.FORCE_FULL_BUILD
                }
            }
            steps {
                // Freestyle build trigger calls a list of jobs
                // Pipeline build() step only calls one job
                // To run all three jobs in parallel, we use &quot;parallel&quot; step
                // https://jenkins.io/doc/pipeline/examples/#jobs-in-parallel
                parallel (
                    linux: {
                        build job: &#x27;full-build-linux&#x27;, parameters: [string(name: &#x27;GIT_BRANCH_NAME&#x27;, value: GIT_BRANCH)]
                    },
                    mac: {
                        build job: &#x27;full-build-mac&#x27;, parameters: [string(name: &#x27;GIT_BRANCH_NAME&#x27;, value: GIT_BRANCH)]
                    },
                    windows: {
                        build job: &#x27;full-build-windows&#x27;, parameters: [string(name: &#x27;GIT_BRANCH_NAME&#x27;, value: GIT_BRANCH)]
                    },
                    failFast: false)
            }
        }
        stage (&#x27;Build Skipped&#x27;) {
            when {
                expression {
                    GIT_BRANCH = &#x27;origin/&#x27; + sh(returnStdout: true, script: &#x27;git rev-parse --abbrev-ref HEAD&#x27;).trim()
                    return !(GIT_BRANCH == &#x27;origin/master&#x27; || params.FORCE_FULL_BUILD)
                }
            }
            steps {
                echo &#x27;Skipped full build.&#x27;
            }
        }
    }
}

Conclusion

As I said before, the Conditional BuildStep plugin is great.
It provides a clear, easy to understand way to add conditional logic to any Freestyle job.
Before Pipeline, it was one of the few plugins to do this and it remains one of the most popular plugins.
Now that we have Pipeline, we can implement conditional logic directly in code.

This is blog post discussed how to approach converting conditional build steps to Pipeline
and showed a couple concrete examples.  Overall, I’m pleased with the results so far.
I found scenarios which could not easily be migrated to Pipeline, but even those
are only more difficult, rather than impossible.

The next thing to do is add a section to the
Jenkins Handbook documenting the Pipeline
equivalent of all of the Conditions and the most commonly used Tokens.
Look for it soon!

Links

Conditional BuildStep plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/freestyle">freestyle</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/conditional-build-step">conditional-build-step</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/20/blueocean-dev-log-jan2/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">20</div></div><h5 class="title">Blue Ocean Dev Log: January Week #3</h5></div><p class="teaser">As we get closer to
Blue Ocean
1.0, which is planned for the end of March, I have started
highlighting
some of the good stuff that has been going on, and this week was a very busy week.

A new Blue Ocean beta ( b18) was released with:

Parametrized pipelines are now supported!

i18n improvements

Better support for matrix and the evil (yet somehow still used) Maven project type (don’t use it!)

SSE fixes for IE and Edge browsers

An alpha release of the Visual Editor for Jenkinsfiles on top of
Declarative Pipeline
has snuck into the &quot;experimental&quot; update center. Andrew will be talking
about Declarative Pipelines at
FOSDEM next week.

Parametrized Pipelines

You would know this if you followed
Thorsten’s twitter account.

That twitter account is mostly pics of Thorsten in running gear, but
occasionally he announces new features as they land.

When you run a pipeline that requires parameters, it will popup a dialog
like this no matter where you run it from. Most input types are supported
(similar to input), with a planned extension point for custom input types.

Editor

A very-very early version of the
Blue Ocean Pipeline Editor plugin
that will set your hair on fire of the editor is in the experimental update
center.

Declarative pipelines are still not at version 1.0 status, but will be
shortly. This editor allows you to roundtrip Jenkinsfiles written in this
way, so they can be edited as text, or visually. The steps available are
discovered form the installed plugins. One to watch.

So, what’s next?

Creation of Git Pipelines, and likely GitHub too.

Show parallel branches that aren’t in a stage visually

Show stderr/out in test reports

Show more information when Jenkins is &quot;busy&quot;, such as when agents are coming online, in the Pipeline view

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/01/27/blueocean-dev-log-jan4/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">27</div></div><h5 class="title">Blue Ocean Dev Log: January Week #4</h5></div><p class="teaser">As we get closer to
Blue Ocean
1.0, which is planned for the end of March, I have
started
highlighting
some of the good stuff that has been going on. This week was 10 steps forward, and about 1.5 backwards…​

There were two releases this week, b19 and b20. Unfortunately, b20 had to
be released shortly after b19 hit the Update Center as an incompatible API
change in a 3rd party plugin was discovered.

Regardless, the latest b20 has a lot of important improvements, and some
very nice new features.

A first cut of the &quot;Create Pipeline&quot; UX, seen above, allowing you to create Git
based Multibranch Pipelines like you have never seen before.

Handling network disconnections from the browser to server (eg server
restart, network etc) gracefully with a nice UI.

More precise time information for steps and running Pipelines.

More information when a Pipeline is blocked on infrastructure, such as when
the Pipeline is waiting for an agent to become available.

Fixed a really embarrassing typo (a prize if you spot it).

Test reports now include stdout and stderr

Better support for parallel visualisation, such as when a parallel step exists outside of a stage.

The Visual Editor also had another release, with the &quot;sheets&quot; visual component
and better validation.

Creation

Currently this is hidden behind a
feature toggle,
to access append?blueCreate to the URL in you browser, and then press the
&quot;New Pipeline&quot; button. Currently it lets you quickly create a Pipeline from
Git, add credentials, etc, in a very nice UX. More SCM types are being added to
support this.

Reconnect/disconnect

As Blue Ocean is a very &quot;live&quot; style of UX, if your network becomes
unavailable, or the server is restarted, it is good to know in case you
were staring at the screen waiting for something to happen (don’t you have
anything better to do??). When this happens, now you get a polite message,
and then when the connection is restored, even if you are waiting for a
Pipeline run to finish, it will then notice this, and refresh things for
you:

Note the opacity changes to make it clear even if you don’t see the little
message. Very nice addition for those of us who work on a train far to often.

Up next

What is up next:

SCM Api changes should land, making things much better for users of
GitHub, Bitbucket, and many more.

Creating Pipelines from GitHub (including automatic discovery).

Lots of fixes and enhancements in the Pipeline from all over the place

More ATH [ 1 ] coverage against regressions

More Visual Editor releases as Declarative Pipeline reaches version 1.0

Improvements to i18n

There was also a couple of &quot;alternative beta&quot; releases in the &quot;Experimental
Update Center&quot; to help test the new SCM API improvements for better use of
GitHub APIs (based on
this branch)
I do not recommend trying this branch unless you know what you are doing,
as this will migrate some data, but help testing it would be appreciated!

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!

1. Acceptance Test Harness<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/01/pipeline-scalability-best-practice/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 1</div></div><h5 class="title">Best Practices for Scalable Pipeline Code</h5></div><p class="teaser">This is a guest post by Sam Van Oort,
Software Engineer at CloudBees and contributor to
the Jenkins project.

Today I’m going to show you best practices to write scalable and robust Jenkins Pipelines. This is drawn from a
combination of work with the internals of Pipeline and observations with large-scale users.

Pipeline code works beautifully for its intended role of automating
build/test/deploy/administer tasks.  As it is pressed into more complex roles
and unanticipated uses, some users hit issues.  In these cases, applying the
best practices can make the difference between:

A single controller running
hundreds
of concurrent builds on low end hardware (4 CPU cores and 4 GB of
heap)

Running a couple dozen builds and bringing a controller to its knees or
crashing it…​even with 16+ CPU cores and 20+ GB of heap!

This has been seen in the wild.

Fundamentals

To understand Pipeline behavior you must understand a few points about
how it executes.

Except for the steps themselves, all of the Pipeline logic, the Groovy conditionals, loops, etc execute on the controller. Whether simple or complex! Even inside a node block!

Steps may use executors to do work where appropriate, but each
step has a small on-controller overhead too.

Pipeline code is written as Groovy but the execution model is
radically transformed at compile-time to Continuation Passing Style
(CPS).

This transformation provides valuable safety and durability
guarantees for Pipelines, but it comes with trade-offs:

Steps can invoke Java and execute fast and efficiently, but Groovy
is much slower to run than normal.

Groovy logic requires far more memory, because an object-based
syntax/block tree is kept in memory.

Pipelines persist the program and its state frequently to be able to
survive failure of the controller.

From these we arrive at a set of best practices to make pipelines more
effective.

Best Practices For Pipeline Code

Think of Pipeline code as glue: just enough Groovy code to connect
together the Pipeline steps and integrate tools, and no more.

This makes code easier to maintain, more robust against bugs, and
reduces load on controllers.

Keep it simple: limit the amount of complex logic embedded in the
Pipeline itself (similarly to a shell script) and avoid treating it as a
general-purpose programming language.

Pipeline restricts all variables to Serializable types, so keeping
Pipeline logic simple helps avoid a NotSerializableException - see
appendix at the bottom.

Use @NonCPS -annotated functions for slightly more complex work.
This means more involved processing, logic, and transformations. This
lets you leverage additional Groovy &amp; functional features for more
powerful, concise, and performant code.

This still runs on controllers so be mindful of complexity, but is much
faster than native Pipeline code because it doesn’t provide durability
and uses a faster execution model. Still, be mindful of the CPU cost and
offload to executors for complex work (see below).

@NonCPS functions can use a much broader subset of the Groovy
language, such as iterators and functional features, which makes them
more terse and fast to write.

@NonCPS functions should not use Pipeline steps internally, however
you can store the result of a Pipeline step to a variable and use it
that as the input to a @NonCPS function.

Gotcha: It’s not guaranteed that use of a step will generate an
error (there is an open RFE to implement that), but you should not rely
on that behavior. You may see improper handling of exceptions, in
particular.

While normal Pipeline is restricted to serializable local variables
(see appendix at bottom), @NonCPS functions can use more complex,
nonserializable types internally (for example regex matchers, etc). Parameters
and return types should still be Serializable, however.

Gotcha: improper usages are not guaranteed to raise an error with
normal Pipeline (optimizations may mask the issue), but it is unsafe to
rely on this behavior.

Prefer external scripts/tools for complex or CPU-expensive
processing rather than Groovy language features. This offloads work
from the controller to external executors, allowing for easy scale-out of
hardware resources. It is also generally easier to test because these
components can be tested in isolation without the full on-controller
execution environment.

Many software vendors will provide easy command-line clients for
their tools in various programming languages. These are often robust,
performant, and easy to use. Plugins offer another option (see below).

Shell or batch steps are often the easiest way to integrate these
tools, which can be written in any language. For example: sh “java -jar
client.jar $endPointUrl $inputData” for a Java client, or sh “python
jiraClient.py $issueId $someParam” for a Python client.

Gotcha: especially avoid Pipeline XML or JSON parsing using Groovy’s XmlSlurper and JsonSlurper!  Strongly prefer command-line tools or scripts.

The Groovy implementations are complex and as a result more brittle in Pipeline use.

XmlSlurper and JsonSlurper can carry a high memory and CPU cost in pipelines

xmllint and xmlstartlet are command-line tools offering XML extraction via xpath

jq offers the same functionality for JSON

These extraction tools may be coupled to curl or wget for fetching information from an HTTP API

Examples of other places to use command-line tools:

Templating large files

Nontrivial integration with external APIs (for bigger vendors,
consider a Jenkins plugin if a quality offering exists)

Simulations/complex calculations

Business logic

Consider existing plugins for external integrations. Jenkins has a
wealth of plugins, especially for source control, artifact management,
deployment systems, and systems automation. These can greatly reduce the
amount of Pipeline code to maintain. Well-written plugins may be
faster and more robust than Pipeline equivalents.

Consider both plugins and command-line clients (above) — one may be
easier than the other.

Plugins may be of widely varying quality. Look at the number of installations and how frequently and recently updates appear in the changelog. Poorly-maintained plugins
with limited installations may actually be worse than writing a little
custom Pipeline code.

As a last resort, if there is a good-quality plugin that is not
Pipeline-enabled, it is fairly easy to write a Pipeline wrapper to
integrate it or write a custom step that will invoke it.

Assume things will go wrong: don’t rely on workspaces being clean
of the remnants from previous executions, clean explicitly where needed.
Make use of timeouts and retry steps (that’s what they’re there for).

Within a git repository, git clean -fdx is a good way to
accomplish this and reduces the amount of SCM cloning

DO use parameterized Pipelines and variables to make your Pipeline
scripts more reusable. Passing in parameters is especially helpful for
handling different environments and should be preferred to applying
conditional lookup logic; however, try to limit parameterized pipelines invoking each other.

Try to limit business logic embedded in Pipelines. To some extent
this is inevitable, but try to focus on tasks to complete instead,
because this yields more maintainable, reusable, and often more
performant Pipeline code.

One code smell that points to a problem is many hard-coded
constants. Consider taking advantage of the options above to refactor
code for better composability.

For complex cases, consider using Jenkins integration options
(plugins, Jenkins API calls, invoking input steps externally) to offload
implementation of more complex business rules to an external system if
they fit more naturally there.

Please, think of these as guidelines, not strict rules – Jenkins
Pipeline provides a great deal of power and flexibility, and it’s there
to be used.

Breaking enough of these rules at scale can cause controllers to fail by
placing an unsustainable load on them.

For additional guidance, I also recommend
this
Jenkins World talk
on how to engineer Pipelines for speed and performance:

Appendix: Serializable vs. Non-Serializable Types:

To assist with Pipeline development, here are common serializable and
non-serializable types, to assist with deciding if your logic can be CPS
or should be in a @NonCPS function to avoid issues.

Common Serializable Types (safe everywhere):

All primitive types and their object wrappers: byte, boolean, int,
double, short, char

Strings

enums

Arrays of serializable types

ArrayLists and normal Groovy Lists

Sets: HashSet

Maps: normal Groovy Map, HashMap, TreeMap

Exceptions

URLs

Dates

Regex Patterns (compiled patterns)

Common non-Serializable Types (only safe in @NonCPS functions):

Iterators: this is a common problem. You need to use C-style loop, i.e.
for(int i=0; i

Regex Matchers (you can use the
built-in functions in String, etc, just not the Matcher itself)

Important: JsonObject, JsonSlurper, etc in Groovy 2+ (used in some 2.x+
versions of Jenkins).

This is due to an internal implementation change — earlier versions may serialize.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/svanoort/">Sam Van Oort</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/01/security-updates/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 1</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.44 and 2.32.2, that fix a high severity and several medium and low severity issues.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.
I strongly recommend you read these documents, as there are a few possible side effects of these fixes.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/03/blueocean-devlog-feb/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 3</div></div><h5 class="title">Blue Ocean Dev Log: February Week #1</h5></div><p class="teaser">With only a couple of months left before
Blue Ocean
1.0, which is planned for the end of March, I have
been
highlighting
some of the good work being finished up by the developers hacking on Blue
Ocean.

This week was a grab bag of important behind-the-scenes features and finalising
the preview of the editor. The merge of the SCM API changes also made it in.
The editor has the new sheets style of editing (there will be blogs and more on
this in the next few weeks):

Some highlights:

Fix to async loading of resources like translations, so screens don’t
&quot;flash&quot; when they are loaded (i18n improvement)

Links in notifications can be configured to point to classic or
Blue Ocean screens

Time reporting works better when browser clock is out of sync with
server

SECURITY-380 was backported into a small fix for those that aren’t
running the latest LTS (but you should ideally be running it)

SCM API changes finally landed - this will be in beta 22 which should
hit the update centers soon. This should make things work better with
GitHub rate limits.

Beta 21 was released

The editor reached &quot;preview&quot; release state ready for use with the newly
announced Declarative Pipeline stuff.

Also, a reference to Australian pop culture had to be removed, sadly.

Up Next:

Some cosmetic changes around headers to make it much nicer and clearer

Favorite improvements

GitHub Org-based Pipeline creation

Editor available in the general update center

Beta 22 with SCM improvements and no more GitHub rate limit hassles

Many fixes

Improvements to the Acceptance Test Harness to reduce the number of false-positives.

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/03/declarative-pipeline-ga/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 3</div></div><h5 class="title">Declarative Pipeline Syntax 1.0 is now available</h5></div><p class="teaser">This is a guest post by
Patrick Wolf,
Director of Product Management at
CloudBees
and contributor to
the Jenkins project.

I am very excited to announce the addition of
Declarative Pipeline syntax
1.0 to
Jenkins Pipeline.
We think this new syntax will enable everyone involved in DevOps, regardless of expertise,
to participate in the continuous delivery process. Whether creating, editing or reviewing
a pipeline, having a straightforward structure helps to understand and predict the
flow of the pipeline and provides a common foundation across all pipelines.

Pipeline as Code

Pipeline as Code was one of the pillars of the Jenkins 2.0 release and an
essential part of implementing continuous delivery (CD). Defining all of the
stages of an application’s CD pipeline within a Jenkinsfile and checking it
into the repository with the application code provides all of the benefits
inherent in source control management (SCM):

Retain history of all changes to Pipeline

Rollback to a previous Pipeline version

View diffs and merge changes to the Pipeline

Test new Pipeline steps in branches

Run the same Pipeline on a different Jenkins server

Getting Started with Declarative Pipeline

We recommend people begin using it for all their Pipeline definitions in Jenkins.
The plugin has been available for use and testing starting with the 0.1 release that was debuted at
Jenkins World
in September. Since then, it has already been installed in over 5,000 Jenkins
environments.

If you haven’t tried Pipeline or have considered Pipeline in the past, I
believe this new syntax is much more approachable with an easier adoption curve
to quickly realize all of the benefits of Pipeline as Code. In addition, the
pre-defined structure of Declarative makes it possible to create and edit
Pipelines with a graphical user interface (GUI). The Blue Ocean team is
actively working on a
Visual Pipeline Editor
which will be included in an upcoming release.

If you have already begun using Pipelines in Jenkins, I believe that this new
alternative syntax can help expand that usage.

The original syntax for defining Pipelines in Jenkins is a Groovy DSL that
allows most of the features of full
imperative programming.

This syntax is still fully supported and is now
referred to as &quot;Scripted Pipeline Syntax&quot; to distinguish it from &quot;Declarative
Pipeline Syntax.&quot; Both use the same underlying execution engine in Jenkins and
both will generate the same results in
Pipeline Stage View
or Blue Ocean visualizations. All existing
Pipeline steps,
Global Variables, and
Shared Libraries
can be used in either. You can now create more cookie-cutter Pipelines and
extend the power of Pipeline to all users regardless of Groovy expertise.

Declarative Pipeline Features

Syntax Checking

Immediate runtime syntax checking with explicit error messages.

API endpoint for linting a Jenkinsfile.

CLI command to lint a Jenkinsfile.

Docker Pipeline integration

Run all stages in a single container.

Run each stage in a different container.

Easy configuration

Quickly define parameters for your Pipeline.

Quickly define environment variables and credentials for your Pipeline.

Quickly define options (such as timeout, retry, build discarding) for your Pipeline.

Round trip editing with the Visual Pipeline Editor (watch for preview release shortly).

Conditional actions

Send notifications or take actions depending upon success or failure.

Skip stages based on branches, environment, or other Boolean expression.
release shortly)

Where Can I Learn More?

Be on the lookout for future blog posts detailing specific examples of
scenarios or features in Declarative Pipeline. Andrew Bayer, one of the primary
developers behind Declarative Pipeline, will be presenting at
FOSDEM
in Brussels, Belgium this weekend. We have also scheduled an online
Jenkins Meetup (JAM)
later this month to demo the features of Declarative Pipeline and give a sneak
peek at the upcoming Blue Ocean Pipeline Editor.

In the meantime, all the
Pipeline documentation
has been updated to incorporate a
Guided Tour,
and a
Syntax Reference
with numerous examples to help you get on your way to using Pipeline.  Simply
upgrade to the latest version, 2.5 or later of the Pipeline in Jenkins to
enable all of these great features.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hrmpw/">Patrick Wolf</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/06/scm-api-2-take2/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 6</div></div><h5 class="title">SCM API 2.0 Release Take 2</h5></div><p class="teaser">In January we
announced the release of SCM API 2.0.
After the original release was published we identified four new high-impact
issues.  We decided to remove the new versions of the plugins from the update
center until those issues could be resolved. The issues have now been resolved
and the plugins are now available from the update center.

Summary for busy Jenkins Administrators

Upgrading should make multi-branch projects much better.  When you are ready to
upgrade you must ensure that you upgrade all the required plugins.  If you miss
some, just upgrade them and restart to fix the issue. And of course, it’s
always a good idea to take a backup of your JENKINS_HOME before upgrading any
plugins.

In the list below, version numbers in bold indicate a change from the
original version in the
original announcement

Folders Plugin

5.17 or newer

SCM API Plugin

2.0.2 or newer

Branch API Plugin

2.0.2 or newer

Git Plugin

This depends on the exact release line of the Git plugin that you are using.

Following the 2.6.x release line: 2.6.4 or newer

Following the 3.0.x release line ( recommended): 3.0.4 or newer

Mercurial Plugin

1.58 or newer

GitHub Branch Source Plugin

2.0.1 or newer

BitBucket Branch Source Plugin

2.0.2 or newer

GitHub Organization Folders Plugin

1.6

Pipeline Multibranch Plugin

2.12 or newer

If you are using the Blue Ocean plugin

Blue Ocean Plugin

1.0.0-b22 or newer

Other plugins that may require updating:

GitHub API Plugin

1.84 or newer

GitHub Plugin

1.25.0 or newer

If you upgrade to Branch API 2.0.x and you have either the GitHub Branch Source or the BitBucket Branch Source plugins and you do not upgrade those instances to the 2.0.x line then your Jenkins instance will fail to start-up correctly.

The solution is just to upgrade the GitHub Branch Source or the BitBucket Branch Source plugin (as appropriate) to the 2.0.x line.

After an upgrade you will see the data migration warning (see the screenshot in
JENKINS-41608 for an
example) this is normal and expected.  The unreadable data will be removed by
the next scan / index or can be removed manually using the Discard Unreadable
Data button.  The warning will disappear on the next restart after the
unreadable data has been removed.

Please update to the versions listed above. If you want to know more about the
issues and how they were resolved, see the next section.

Analysis of the issues

The issues described below are resolved with these plugin releases:

Folders Plugin: 5.17

SCM API Plugin: 2.0.2

Branch API Plugin: 2.0.2

Git Plugin: Either 2.6.4 or 3.0.4

GitHub Branch Source Plugin: 2.0.1

BitBucket Branch Source Plugin: 2.0.2

Pipeline Multibranch Plugin: 2.12

JENKINS-41121: GitHub Branch Source upgrade can cause a lot of rebuilds :

Migration of GitHub branches from 1.x to 2.x resulted in a change of the
implementation class used to identify branches.  Some other other bugs in
Branch API had been fixed and the combined effect resulted in a rebuild of all
GitHub Branches (not PRs) after an upgrade to GitHub Branch Source Plugin
2.0.0.  This rebuild was referred to as a &quot;build storm&quot;.

Resolution:

The SCM API plugin was enhanced to add an extension point that allows for a second round of data migration when upgrading.

The second round of data migration allows plugins implementing the SCM API contract to fix implementation class issues in context.

The Branch API plugin was enhanced to use this new extension point.

The GitHub Branch Source plugin was enhanced to provide an implementation of this extension point.

JENKINS-41255: Upgrading from a navigator that did not assign consistent source ids to a version that does assign consistent source ids causes a build storm on first scan :

The GitHub Branch Source and BitBucket Branch Source plugins in 1.x were not
assigning consistent IDs to multi-branch projects discovered in an Organization
Folder.  Both plugins were fixed in 2.0.0 to assign consistent IDs as a change
of ID would result in a rebuild of all projects.  What was missed is that the
very first scan of an Organization Folder after an upgrade will change the
randomly assigned ID assigned by the 1.x plugins into the consistent ID
assigned by the 2.0.0 plugins and consequently trigger a rebuild of all
branches. This rebuild was referred to as a &quot;build storm&quot;.

Resolution:

The Branch API plugin was enhanced to detect the case where a branch source has
been changed but the change is only changing the ID.  When such changes are
identified, the downstream references of the ID are all updated which will
prevent a build storm.

JENKINS-41313: On first index after upgrade to 2.0.0 all open PRs are rebuilt :

The BitBucket Branch Source 1.x did not store all the information about PRs
that is required by the SCM API 2.0.x model.  This could well have resulted in
subtle effects when manually triggering a rebuild of a merge PR if the PR’s
target branch has been modified after the PR branch was first detected by
Jenkins. Consequently, as the information is required, BitBucket Branch Source
plugin 2.0.0 populated the information with dummy values which would force the
correct information to be retrieved.  The side-effect is that all PR branches
would be rebuilt.

Resolution:

The changes in SCM API 2.0.2 introduced to resolve JENKINS-41121 provided a path to resolve this issue without causing a rebuild of all PR branches.

The BitBucket Branch Source plugin was enhanced to provide an implementation of the new SCM API extension point that connects to BitBucket and retrieves the missing information.

JENKINS-41124: Can’t get a human readable job name anymore :

During initial testing of the Branch API 2.0.0 release an issue was identified
with how Organization Folders handled unusual names.  None of the existing
implementations of the SCMNavigator API could generate such unusual names due
to form validation on GitHub / BitBucket replacing unusual characters with -
when creating a repository.

It would be irresponsible to rely on external services sanitizing their input
data for the correct operation of Organization Folders.  Consequently, in
Branch API 2.0.0 the names were all transformed into URL safe names, with the
original URLs still resolving to the original projects so that any existing
saved links would remain functional.

Quite a number of people objected to this change of URL scheme.

Resolution:

There has been a convention in Jenkins that the on-disk storage structure for
jobs mirrors the URL structure. This is only a convention and there is nothing specific in the code that
mandates following the convention.

The Folders Plugin was enhanced to allow for computed folders (where the item
names are provided by an external source) to provide a strategy to use when
generating the on-disk storage names as well as the URL component names for
the folder’s child items.

The Branch API plugin was enhanced to use this new strategy for name transformation.

The net effect of this change is that the URLs remain the same as for 1.x but
the on-disk storage uses transformed names that are future proofed against
any new SCMNavigator implementations where the backing service allows names
that are problematic to use as filesystem directory names.

Side-effect:

The Branch API 2.0.0 approach handled the transformation of names by renaming the items using the Jenkins Item rename API.

The Branch API 2.0.2 approach does not rename the child items as it is only the on-disk storage location that is moved.

This means that the Jenkins Item rename API cannot be used.

At this time, the only known side-effect is in the Job Configuration History plugin.
The configuration history of each child item will still be tracked going
forward after the upgrade.  The pre-upgrade configuration history is also
retained.  Because the Jenkins Item rename API cannot be used to flag the
configuration file location change, there is no association between the
pre-upgrade history chain and the post-upgrade history chain.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stephenc/">Stephen Connolly</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/07/declarative-maven-project/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 7</div></div><h5 class="title">Declarative Pipeline for Maven Projects</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Declare Your Pipelines!
Declarative Pipeline 1.0 is here!
This is first in a series of blog posts that will show some of the cool features of
Declarative Pipeline.
For several of these posts, I’ll be revisiting some of my
previous posts
on using various plugins with (Scripted) Pipeline,
and seeing how those are implemented in Declarative Pipeline.

To start though, let’s get familiar with the basic structure of a Declarative Pipeline
by creating a simple Pipeline for a Maven-based Java project - the
Jenkins JUnit plugin.
We’ll create a minimal Declarative Pipeline,
add the settings needed to install Maven and the JDK,
and finally we’ll actually run Maven to build the plugin.

Set up

With Declarative, it is still possible to run Pipelines edited directly in the
Jenkins web UI, but one of the key features of &quot;Pipeline as Code&quot; is
checking-in and being able to track changes.  For this post, I’m going to use
the
blog/add-declarative-pipeline
branch of
my fork of the JUnit plugin.
I’m going to set up a Multi-branch Pipeline and point it at my repository.

I’ve also set this Pipeline’s Git configuration to automatically &quot;clean after
checkout&quot; and to only keep the ten most recent runs.

Writing a Minimal Pipeline

As has been said before, Declarative Pipeline provides a more structured,
&quot;opinionated&quot; way to create Pipelines. I’m going to start by creating a minimal
Declarative Pipeline and adding it to my branch.  Below is a minimal Pipeline
(with annotations) that just prints a message:

// Declarative //
pipeline { (1)
agent any // &lt;2&gt; (3)
stages { (4)
stage(&#x27;Build&#x27;) { (5)
steps { (6)
echo &#x27;This is a minimal pipeline.&#x27; (7)
}
        }
    }
}
// Scripted //
node { (2)
checkout scm (3)
stage (&#x27;Build&#x27;) { (5)
echo &#x27;This is a minimal pipeline.&#x27; (6)
}
}

1
All Declarative Pipelines start with a pipeline section.

2
Select where to run this Pipeline, in this case &quot;any&quot; agent, regardless of label.

3
Declarative automatically performs a checkout of source code on the agent,
whereas Scripted Pipeline users must explicitly call checkout scm,

4
A Declarative Pipeline is defined as a series of stages.

5
Run the &quot;Build&quot; stage.

6
Each stage in a Declarative Pipeline runs a series of steps.

7
Run the echo step to print a message in the Console Output.

If you are familiar with Scripted Pipeline, you can toggle the above
Declarative code sample to show the Scripted equivalent.

Once I add the Pipeline above to my Jenkinsfile and run &quot;Branch Indexing&quot;, my
Jenkins will pick it up and run run it.  We see that the Declarative Pipeline
has added stage called &quot;Declarative: Checkout SCM&quot;:

This a &quot;dynamic stage&quot;, one of several the kinds that Declarative Pipeline adds
as needed for clearer reporting.  In this case, it is a stage in which the
Declarative Pipeline automatically checkouts out source code on the agent.

As you can see above, we didn’t have to tell it do any of this,

Console Output

[Pipeline] node
Running on osx_mbp in /Users/bitwiseman/jenkins/agents/osx_mbp/workspace/blog_add-declarative-pipeline
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Declarative: Checkout SCM)
[Pipeline] checkout
Cloning the remote Git repository
{ ... truncated 20 lines ... }
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Build)
[Pipeline] echo
This is a minimal pipeline
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
Finished: SUCCESS

Declarative Pipeline syntax is a little more verbose than the equivalent Scripted Pipeline,
but the added detail gives a clearer, more consistent view of what the Pipeline is supposed to do.
It also gives us a structure into which we can add more configuration details about this Pipeline.

Adding Tools to Pipeline

The next thing we’ll add in this Pipeline is a tools section to let us use
Maven.  The tools section is one of several sections we can add under
pipeline, which affect the configuration of the rest of the Pipeline.  (We’ll
look at the others, including agent, in later posts.) Each tool entry will
make whatever settings changes, such as updating PATH or other environment
variables, to make the named tool available in the current pipeline.  It will
also automatically install the named tool if that tool is configured to do so
under &quot;Managing Jenkins&quot; → &quot;Global Tool Configuration&quot;.

// Declarative //
pipeline {
    agent any
    tools { (1)
maven &#x27;Maven 3.3.9&#x27; (2)
jdk &#x27;jdk8&#x27; (3)
}
    stages {
        stage (&#x27;Initialize&#x27;) {
            steps {
                sh &#x27;&#x27;&#x27;
                    echo &quot;PATH = ${PATH}&quot;
                    echo &quot;M2_HOME = ${M2_HOME}&quot;
                &#x27;&#x27;&#x27; (4)
}
        }

        stage (&#x27;Build&#x27;) {
            steps {
                echo &#x27;This is a minimal pipeline.&#x27;
            }
        }
    }
}
// Scripted Not Defined //

1
tools section for adding tool settings.

2
Configure this Pipeline to use the Maven version matching &quot;Maven 3.3.9&quot;
(configured in &quot;Managing Jenkins&quot; → &quot;Global Tool Configuration&quot;).

3
Configure this Pipeline to use the Maven version matching &quot;jdk8&quot;
(configured in &quot;Managing Jenkins&quot; → &quot;Global Tool Configuration&quot;).

4
These will show the values of PATH and M2_HOME environment variables.

When we run this updated Pipeline the same way we ran the first, we see that
the Declarative Pipeline has added another stage called &quot;Declarative: Tool
Install&quot;: In the console output, we see that during this particular stage &quot;Maven 3.3.9&quot; gets installed,
and the PATH and M2_HOME environment variables are set:

Console Output

{ ... truncated lines ... }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Declarative: Tool Install)
[Pipeline] tool
Unpacking https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/3.3.9/apache-maven-3.3.9-bin.zip
to /Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9
on osx_mbp
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] }
[Pipeline] // stage
{ ... }
PATH = /Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/bin:/Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9/bin:...
M2_HOME = /Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9
{ ... }

Running a Maven Build

Finally, running a Maven build is trivial.  The tools section already added
Maven and JDK8 to the PATH, all we need to do is call mvn install.  It
would be nice if I could split the build and the tests into separate stages,
but Maven is famous for not liking when people do that, so I’ll leave it alone
for now.

Instead, let’s load up the results of the build using the JUnit plugin,
however the version that was just built, sorry.

// Declarative //
pipeline {
    agent any
    tools {
        maven &#x27;Maven 3.3.9&#x27;
        jdk &#x27;jdk8&#x27;
    }
    stages {
        stage (&#x27;Initialize&#x27;) {
            steps {
                sh &#x27;&#x27;&#x27;
                    echo &quot;PATH = ${PATH}&quot;
                    echo &quot;M2_HOME = ${M2_HOME}&quot;
                &#x27;&#x27;&#x27;
            }
        }

        stage (&#x27;Build&#x27;) {
            steps {
                sh &#x27;mvn -Dmaven.test.failure.ignore=true install&#x27; (1)
}
            post {
                success {
                    junit &#x27;target/surefire-reports/**/*.xml&#x27; (2)
}
            }
        }
    }
}
// Scripted //
node {
    checkout scm

    String jdktool = tool name: &quot;jdk8&quot;, type: &#x27;hudson.model.JDK&#x27;
    def mvnHome = tool name: &#x27;mvn&#x27;

    /* Set JAVA_HOME, and special PATH variables. */
    List javaEnv = [
        &quot;PATH+MVN=${jdktool}/bin:${mvnHome}/bin&quot;,
        &quot;M2_HOME=${mvnHome}&quot;,
        &quot;JAVA_HOME=${jdktool}&quot;
    ]

    withEnv(javaEnv) {
    stage (&#x27;Initialize&#x27;) {
        sh &#x27;&#x27;&#x27;
            echo &quot;PATH = ${PATH}&quot;
            echo &quot;M2_HOME = ${M2_HOME}&quot;
        &#x27;&#x27;&#x27;
    }
    stage (&#x27;Build&#x27;) {
        try {
            sh &#x27;mvn -Dmaven.test.failure.ignore=true install&#x27;
        } catch (e) {
            currentBuild.result = &#x27;FAILURE&#x27;
        }
    }
    stage (&#x27;Post&#x27;) {
        if (currentBuild.result == null || currentBuild.result == &#x27;SUCCESS&#x27;) {
            junit &#x27;target/surefire-reports/**/*.xml&#x27; (2)
}
    }
}

1
Call mvn, the version configured by the tools section will be first on the path.

2
If the maven build succeeded, archive the JUnit test reports for display in the Jenkins web UI.
We’ll discuss the
post section in detail in the next blog post.

If you are familiar with Scripted Pipeline, you can toggle the above
Declarative code sample to show the Scripted equivalent.

Below is the console output for this last revision:

Console Output

{ ... truncated lines ... }
+ mvn install
[INFO] Scanning for projects...
[WARNING] The POM for org.jenkins-ci.tools:maven-hpi-plugin:jar:1.119 is missing, no dependency information available
[WARNING] Failed to build parent project for org.jenkins-ci.plugins:junit:hpi:1.20-SNAPSHOT
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] Building JUnit Plugin 1.20-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO]
[INFO] --- maven-hpi-plugin:1.119:validate (default-validate) @ junit ---
[INFO]
[INFO] --- maven-enforcer-plugin:1.3.1:display-info (display-info) @ junit ---
[INFO] Maven Version: 3.3.9
[INFO] JDK Version: 1.8.0_92 normalized as: 1.8.0-92
[INFO] OS Info: Arch: x86_64 Family: mac Name: mac os x Version: 10.12.3
[INFO]
{ ... }
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 03:25 min
[INFO] Finished at: 2017-02-06T22:43:41-08:00
[INFO] Final Memory: 84M/1265M
[INFO] ------------------------------------------------------------------------

Conclusion

The new Declarative syntax is a significant step forward for Jenkins Pipeline.
It trades some verbosity and constraints for much greater clarity and
maintainability.  In the coming weeks, I’ll be adding new blog posts
demonstrating various features of the Declarative syntax along with some recent
Jenkins Pipeline improvements.

Links

Declarative Pipeline

Declarative Pipeline Syntax Reference

Jenkins JUnit plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/maven">maven</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java">java</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/07/gsoc2017-announcement/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 7</div></div><h5 class="title">Google Summer Of Code 2017: Call for mentors</h5></div><p class="teaser">On behalf of the GSoC Org Admin team I am happy to announce that we are going to apply to
Google Summer of Code (GSoC) again this year.
In GSoC high-profile students work in open-source projects for several months under mentorship of organization members.

We are looking for mentors and project ideas.
So yes, we are looking for you :)

Conditions

As a mentor, you will be asked to:

lead the project in the area of their interest

actively participate in the project during student selection, community bonding and coding phases (March - August)

work in teams of 2+ mentors per 1 each student

dedicate a consistent and significant amount of time, especially during the coding phase ( ~5 hours per week in the team of two mentors)

Mentorship does not require strong expertise in Jenkins plugin development.
The main objective is to guide students and to get them involved into the Jenkins community.
If your mentor team requires any specific expertise, GSoC org admins will do their best in order to find advisors.

What do you get?

A student, who works within the area of your interest on full-time for several months

Joint projects with Jenkins experts, lots of fun and ability to study something together

Limited edition of swags from Google and Jenkins project

Maybe: Participation in GSoC Mentor Summit in California with expense coverage (depends on project results and per-project quotas)

Requirements

You are:

passionate about Jenkins

interested in being a mentor or advisor

ready to dedicate time &amp;&amp; have no major unavailability periods planned to this summer

We expect mentors to be available by email during 75% of working days in the May-August timeframe

Your project idea is:

about code (though it may and likely should include some documentation and testing work)

about Jenkins (plugins, core, infrastructure, etc.)

potentially doable by a student in 3-4 months

How to apply

If you are interested, drop the Email to the Jenkins Developer mailing list with the GSoC2017 prefix.

Briefly describe your project idea (a couple of sentences) and required qualifications from students. Examples: GSoC2016, GSoC2017 - current project ideas

If you already have a co-mentor(s), please mention them

Having several project ideas is fine. Having no specific ideas is also fine.

Disclaimer: We cannot guarantee that all projects happen, it depends on student application results and the number of project slots.

Links

Google Summer of Code page

Jenkins GSoC Page

GSoC2016 project ideas

GSoC2016 page (project results and more info)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2017">gsoc2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/08/jenkins-datadog-plugin/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 8</div></div><h5 class="title">Monitor Jenkins jobs with the Datadog plugin</h5></div><p class="teaser">This is a guest post by Emily Chang, Technical Author at Datadog. A modified version of this article was originally posted on the
Datadog blog.

If you’re using Jenkins to continuously integrate changes into your projects, it’s helpful to be able to quickly identify build failures and assess their impact on other components of your stack.

Datadog’s plugin helps users monitor and alert on the performance of their Jenkins builds, right alongside the rest of their infrastructure and applications.

As shown in the out-of-the-box dashboard below, the Datadog plugin provides a bird’s-eye view of job history and trends. You can use Datadog to:

Set alerts for important build failures

Identify trends in build durations

Correlate Jenkins events with performance metrics from other parts of your infrastructure in order to identify and resolve issues

Track Jenkins build status in real-time

Once you install the Datadog plugin, Jenkins activities (when a build starts, fails, or succeeds) will start appearing in your Datadog event stream. You will also see what percentage of builds failed within the same job, so that you can quickly spot which jobs are experiencing a higher rate of failure than others.

Remember to blacklist any jobs you don’t want to track by indicating them in your plugin configuration.

Datadog’s out-of-the-box Jenkins dashboard includes a status widget that displays the count of all jobs that have run in the past day, grouped by success or failure. To explore further, you can also click on the widget to view the individual jobs that have failed or succeeded in the past day.

The dashboard also displays the proportion of successful vs. failed builds, along with the total number of job runs completed over the past four hours.

Datadog enables you to correlate Jenkins events with application performance metrics to investigate the root cause of an issue. For example, the screenshot below shows that average CPU on the app servers increased sharply after a Jenkins build was completed and deployed (indicated by the pink bar). Your team can use this information as a starting point to investigate if code changes in the corresponding release may be causing issues.

Visualize job duration metrics

Every time a build is completed, the plugin collects the build duration as a metric that you can aggregate by job name or any other tag, and graph over time. In the screenshot below, we can view the average job durations in the past four hours, sorted in decreasing order:

You can also graph and visualize trends in build durations for each job by using Datadog’s robust_trend() linear regression function, as shown in the screenshot below. This graph indicates which jobs&#x27; durations are trending longer over time, so that you can investigate if there appears to be a problem. If you’re experimenting with changes to your CI pipeline, consulting this graph can help you track the effects of those changes over time.

Use tags to monitor your Jenkins jobs

Tags add custom dimensions to your monitoring, so you can focus on what’s important to you right now.

Every Jenkins event, metric, and service check is auto-tagged with job, result, and branch (if applicable). You can also enable the optional node tag in the plugin settings.

As of version 0.5.0, the plugin supports custom tags. This update was developed by one of our open source contributors, Mads Nielsen. Many thanks to Mads for helping us implement this feature!

You can create custom tags for the name of the application you’re building, your particular team name (e.g. team=licorice), or any other info that matters to you. For example, if you have multiple jobs that perform nightly builds, you might want to create a descriptive tag that distinguishes them from other types of jobs.

As shown in the configuration settings above, you can add custom tags, formatted as key=value, in two ways:

in a text file (saved in the workspace for the job)

in a list of properties in the text box

Set up the Datadog plugin

The Datadog plugin requires Jenkins 1.580.1 or newer.

In Jenkins, navigate to Manage Jenkins &gt; Manage Plugins.

Search for Datadog Plugin and check the box to install it.

In Jenkins, go to Manage Jenkins &gt; Configure System.

Scroll down to the Datadog Plugin section, and paste your API key in the text box. You can copy this from the API Keys page of your Datadog account. Click Test Key to confirm that the plugin recognizes your API key.

Save your changes, and you’re all set!

Get started

If you’re already using Datadog, you can start monitoring Jenkins jobs by following the instructions here to download the Datadog plugin. If you’re not using Datadog yet, here’s a 14-day free trial.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/echang26/">Emily Chang</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/monitoring">monitoring</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/10/blueocean-devlog-feb2/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">10</div></div><h5 class="title">Blue Ocean Dev Log: February Week #2</h5></div><p class="teaser">We’re counting down the weeks until
Blue Ocean
1.0, which is planned for the end of March. If you hadn’t picked up on the hint
in my
previous post,
most of the Blue Ocean development team is in Australia, where it is currently
the middle of summer. As I write this it is about 1000 degrees outside.
Emergency measures such as air-conditioning and beer have been deployed in
order to continue Blue Ocean development.

This week featured a new beta with the
SCM API
changes; many bug fixes, and some version bumps went out in beta 22. We also
got some fresh new designs coming soon, though not in time for beta 22.

Some development highlights:

Beta 22 went out featuring the new
SCM API
with better use of GitHub API rate limits.

A fix for publishing of
Server Side Events
that made one CPU spin up to 100% was fixed (not good unless you want to heat up
your room)

Some new refinements to the design merged to the master branch (see images below).

Beta 22 featured the 1.0 version of
Declarative Pipeline

An
Australian translation
was added; really critical stuff, I know..

The Acceptance Test Harness (ATH) was stabilised a bit and it now covers
creating Pipelines from Git, which we talked about in
late January.

The Visual Pipeline Editor was released to the main Update Center
as a preview release, ready to play with!

Some small performance improvements

I’m looking forward to those fancy new designs making their way into an
upcoming release too.

Lovely! Hopefully you see more green than I do…​

Anyways, up next for Blue Ocean:

Creation of Pipelines from GitHub, including auto-discovery of new Pipelines.

Closer to a &quot;release candidate&quot;

Working on filtering the activity view for &quot;per branch&quot; views

Better reporting of durations of stages, steps, and runs

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/10/declarative-html-publisher/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">10</div></div><h5 class="title">Declarative Pipeline: Publishing HTML Reports</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Declare Your Pipelines!
Declarative Pipeline 1.0 is here!
This is the second post in a series showing some of the cool features of
Declarative Pipeline.

In the
previous blog post,
we created a simple Declarative Pipeline.
In this blog post, we’ll go back and look at the Scripted Pipeline for the
Publishing HTML Reports in Pipeline blog post.
We’ll convert that Pipeline to Declarative syntax (including properties), go
into more detail on the post section, and then we’ll use the agent
directive to switch our Pipeline to run in Docker.

Setup

For this post, I’m going to use the
blog/add-declarative/html
branch of
my fork of the
hermann project.
I’ve set up a Multibranch Pipeline and pointed it at my repository
the same as did it previous post.
Also the same as before, I’ve set this Pipeline’s Git configuration to
automatically &quot;Clean after checkout&quot;.

This time we already have a Pipeline checked in.
I’ll run it a few times to get a baseline.

Converting to Declarative

Let’s start by converting the Scripted Pipeline straight to Declarative.

// Declarative //
pipeline {
  agent any // &lt;1&gt; (2)
options {
    // Keep the 10 most recent builds
    buildDiscarder(logRotator(numToKeepStr:&#x27;10&#x27;)) (3)
}
  stages {
    stage (&#x27;Build&#x27;) { (4)
steps {
        // install required gems
        sh &#x27;bundle install&#x27;

        // build and run tests with coverage
        sh &#x27;bundle exec rake build spec&#x27;

        // Archive the built artifacts
        archive includes: &#x27;pkg/*.gem&#x27;

        // publish html
        publishHTML target: [
            allowMissing: false,
            alwaysLinkToLastBuild: false,
            keepAll: true,
            reportDir: &#x27;coverage&#x27;,
            reportFiles: &#x27;index.html&#x27;,
            reportName: &#x27;RCov Report&#x27;
          ]
      }
    }
  }
}
// Scripted //
properties([[$class: &#x27;BuildDiscarderProperty&#x27;,
                strategy: [$class: &#x27;LogRotator&#x27;, numToKeepStr: &#x27;10&#x27;]]]) (3)

node { (1)
stage (&#x27;Build&#x27;) { (4)

// Checkout
    checkout scm (2)

// install required gems
    sh &#x27;bundle install&#x27;

    // build and run tests with coverage
    sh &#x27;bundle exec rake build spec&#x27;

    // Archive the built artifacts
    archive includes: &#x27;pkg/*.gem&#x27;

    // publish html
    publishHTML [
        allowMissing: false,
        alwaysLinkToLastBuild: false,
        keepAll: true,
        reportDir: &#x27;coverage&#x27;,
        reportFiles: &#x27;index.html&#x27;,
        reportName: &#x27;RCov Report&#x27;
      ]

  }
}

1
Select where to run this Pipeline, in this case &quot;any&quot; agent, regardless of label.

2
Declarative automatically performs a checkout of source code on the agent,
whereas Scripted Pipeline users must explicitly call checkout scm.

3
Set the Pipeline option to preserve the ten most recent runs.
This overrides the default behavior from the Multibranch parent of this Pipeline.

4
Run the &quot;Build&quot; stage.

Now that we have this Pipeline in Declarative form, let’s take a minute to do a
little clean up.  We’ll split out the bundle actions a little more and move
steps into logically grouped stages.  Rather than having one monolithic &quot;Build&quot;
stage, we’ll have details for each stage.  As long as we’re prettying things
up, let’s switch to using Blue Ocean to view our
builds, as well.

// Declarative //
pipeline {
  agent any
  options {
    // Keep the 10 most recent builds
    buildDiscarder(logRotator(numToKeepStr:&#x27;10&#x27;))
  }
  stages {
    stage (&#x27;Install&#x27;) {
      steps {
        // install required gems
        sh &#x27;bundle install&#x27;
      }
    }
    stage (&#x27;Build&#x27;) {
      steps {
        // build
        sh &#x27;bundle exec rake build&#x27;

        // Archive the built artifacts
        archive includes: &#x27;pkg/*.gem&#x27;
      }
    }
    stage (&#x27;Test&#x27;) {
      steps {
        // run tests with coverage
        sh &#x27;bundle exec rake spec&#x27;

        // publish html
        publishHTML target: [
            allowMissing: false,
            alwaysLinkToLastBuild: false,
            keepAll: true,
            reportDir: &#x27;coverage&#x27;,
            reportFiles: &#x27;index.html&#x27;,
            reportName: &#x27;RCov Report&#x27;
          ]
      }
    }
  }
}
// Scripted //

Using post sections

This looks pretty good, but if we think about it
the archive and publishHTML steps are really post-stage actions.
They should only occur when the rest of their stage succeeds.
As our Pipeline gets more complex we might need to add actions that always happen
even if a stage or the Pipeline as a whole fail.

In Scripted Pipeline, we would use try-catch-finally,
but we cannot do that in Declarative.
One of the defining features of the Declarative Pipeline
is that it does not allow script-based control structures
such as for loops, if-then-else blocks, or try-catch-finally blocks.
Of course, internally Step implementations can still contain whatever conditional logic they want,
but the Declarative Pipeline cannot.

Instead of free-form conditional logic,
Declarative Pipeline provides a set of Pipeline-specific controls:
when directives, which we’ll look at in
a later blog post in this series, control whether to execute the steps in a stage,
and
post sections
control which actions to take based on result of a single stage
or a whole Pipeline. post supports a number of
run conditions,
including always (execute no matter what) and changed
(execute when the result differs from previous run).
We’ll use success to run archive and publishHTML when their respective stages complete.
We’ll also use an always block with a placeholder for sending notifications,
which I’ll implement in the next blog post.

// Declarative //
pipeline {
  agent any
  options {
    // Only keep the 10 most recent builds
    buildDiscarder(logRotator(numToKeepStr:&#x27;10&#x27;))
  }
  stages {
    stage (&#x27;Install&#x27;) {
      steps {
        // install required gems
        sh &#x27;bundle install&#x27;
      }
    }
    stage (&#x27;Build&#x27;) {
      steps {
        // build
        sh &#x27;bundle exec rake build&#x27;
      }

      post {
        success {
          // Archive the built artifacts
          archive includes: &#x27;pkg/*.gem&#x27;
        }
      }
    }
    stage (&#x27;Test&#x27;) {
      steps {
        // run tests with coverage
        sh &#x27;bundle exec rake spec&#x27;
      }

      post {
        success {
          // publish html
          publishHTML target: [
              allowMissing: false,
              alwaysLinkToLastBuild: false,
              keepAll: true,
              reportDir: &#x27;coverage&#x27;,
              reportFiles: &#x27;index.html&#x27;,
              reportName: &#x27;RCov Report&#x27;
            ]
        }
      }
    }
  }
  post {
    always {
      echo &quot;Send notifications for result: ${currentBuild.result}&quot;
    }
  }
}
// Scripted //

Switching agent to run in Docker

agent can actually accept
several other parameters instead of any.
We could filter on label &quot;some-label&quot;, for example,
which would be the equivalent of node (&#x27;some-label&#x27;) in Scripted Pipeline.
However, agent also lets us just as easily switch to using a Docker container,
which replaces a more complicated set of changes in Scripted Pipeline:

pipeline {
  agent {
    // Use docker container
    docker {
      image &#x27;ruby:2.3&#x27;
    }
  }
  /* ... unchanged ... */
}

If I needed to, I could add a label filter under docker
to select a node to host the Docker container.
I already have Docker available on all my agents, so I don’t need label -
this works as is.
As you can see below, the Docker container spins up at the start of the run
and the pipeline runs inside it.  Simple!

Conclusion

At first glance, the Declarative Pipeline’s removal of control structures seems
like it would be too constrictive.  However, it replaces those structures with
facilities like the post section, that give us reasonable control over the
flow our our Pipeline while still improving readability and maintainability.
In the next blog post, we’ll add notifications to this pipeline
and look at how to use Shared Libraries with Declarative
Pipeline to share code and keep Pipelines easy to understand.

Links

Declarative Pipeline plugin

Declarative Pipeline Syntax Reference

Pipeline source for this post<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ruby">ruby</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/15/declarative-notifications/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">15</div></div><h5 class="title">Declarative Pipeline: Notifications and Shared Libraries</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Declare Your Pipelines!
Declarative Pipeline 1.0 is here!
This is the third post in a series showing some of the cool features of
Declarative Pipeline.

In the
previous post,
we converted a Scripted Pipeline to a Declarative Pipeline, adding descriptive stages
and post sections.  In one of those post blocks, we included a placeholder for
sending notifications.

In this blog post, we’ll repeat what I did in
&quot; Sending Notifications in Pipeline
but this time in Declarative Pipeline.
First we’ll integrate calls to notification services Slack, HipChat, and Email into our Pipeline.
Then we’ll refactor those calls into a single Step in a Shared Library, which
we’ll reuse as needed, keeping our Jenkinsfile concise and understandable.

Setup

The setup for this post is almost the same as
my previous Declarative Pipeline post.
I’ve used a new branch in
my fork of the
Hermann project :
blog/declarative/notifications .
I’d already set up a Multibranch Pipeline and pointed it at my repository,
so the new branch will be picked up and built automatically.

I still have my notification targets (where we’ll send notifications) that I created for the
&quot; Sending Notifications in Pipeline&quot; blog post.
Take a look at that post to review how I setup the
Slack,
HipChat,
and Email-ext
plugins to use those channels.

Adding Notifications

We’ll start from the same Pipeline we had at the end of the previous post.

This Pipeline works quite well, except it doesn’t print anything at the start of
the run, and that final always directive only prints a message to the console log.
Let’s start by getting the notifications working like we did in the original post.
We’ll just copy-and-paste the three notification steps (with different parameters)
to get the notifications working for started, success, and failure.

pipeline {
  /* ... unchanged ... */
  stages {
    stage (&#x27;Start&#x27;) {
      steps {
        // send build started notifications
        slackSend (color: &#x27;#FFFF00&#x27;, message: &quot;STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;)

        // send to HipChat
        hipchatSend (color: &#x27;YELLOW&#x27;, notify: true,
            message: &quot;STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;
          )

        // send to email
        emailext (
            subject: &quot;STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;,
            body: &quot;&quot;&quot; STARTED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;,
            recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
          )
      }
    }
    /* ... unchanged ... */
  }
  post {
    success {
      slackSend (color: &#x27;#00FF00&#x27;, message: &quot;SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;)

      hipchatSend (color: &#x27;GREEN&#x27;, notify: true,
          message: &quot;SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;
        )

      emailext (
          subject: &quot;SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;,
          body: &quot;&quot;&quot; SUCCESSFUL: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;,
          recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
        )
    }

    failure {
      slackSend (color: &#x27;#FF0000&#x27;, message: &quot;FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;)

      hipchatSend (color: &#x27;RED&#x27;, notify: true,
          message: &quot;FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27; (${env.BUILD_URL})&quot;
        )

      emailext (
          subject: &quot;FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;,
          body: &quot;&quot;&quot; FAILED: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;,
          recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
        )
    }
  }
}

Moving Notifications to Shared Library

This new Pipeline works and our Declarative Pipeline sends notifications; however,
it is extremely ugly. In the original post using Scripted Pipeline,
I defined a single method that I called at both the start and end of the pipeline.
I’d like to do that here as well, but Declarative doesn’t support creating methods
that are accessible to multiple stages.
For this, we’ll need to turn to
Shared Libraries.

Shared Libraries, as the name suggests,
let Jenkins Pipelines share code instead of copying it to each new project.
Shared Libraries are not specific to Declarative; they were released in their
current form several months ago and were useful in Scripted Pipeline.
Due to Declarative Pipeline’s lack of support for defining methods,
Shared Libraries take on a vital role.  They are the only supported way within
Declarative Pipeline to define methods or classes that we want to use in more than one stage.

The lack of support for defining methods that are accessible in multiple stages,
is a known issue, with at least two JIRA tickets:
JENKINS-41335 and
JENKINS-41396.
For this series, I chose to stick to using features that are fully supported
in Declarative Pipeline at this time.
The internet has plenty of hacked together solutions that happen to work today,
but I wanted to highlight current best practices and dependable solutions.

Setting up a Shared Library

I’ve created a simple shared library repository for this series of posts, called
jenkins-pipeline-shared.
The shared library functionality has too many configuration options to cover in one post.
I’ve chosen to configure this library as a &quot;Global Pipeline Library,&quot;
accessible from any project on my Jenkins controller.
To setup a &quot;Global Pipeline Library,&quot; I navigated to &quot;Manage Jenkins&quot; → &quot;Configure System&quot;
in the Jenkins web UI.
Once there, under &quot;Global Pipeline Libraries&quot;, I added a new library.
I then set the name to bitwiseman-shared, pointed it at my repository,
and set the default branch for the library to master,
but I’ll override that in my Jenkinsfile.

Moving the Code to the Library

Adding a Step to a library involves creating a file with the name of our Step,
adding our code to a call() method inside that file,
and replacing the appropriate code in our Jenkinsfile with the new Step calls.
Libraries can be set to load &quot;implicitly,&quot;
making their default branch automatically available to all Pipelines,
or they can be loaded manually using a @Library annotation.
The branch for implicitly loaded libraries can also be overridden using the @Library annotation.

The minimal set of dependencies for sendNotifications means we can
basically copy-and-paste the code from the original blog post.
We’ll check this change into a branch in the library named
blog/declarative/notifications, the same as my branch in the hermann repository.
This will let us make changes on the master branch later without breaking this example.
We’ll then use the @Library directive to tell Jenkins to use that branch’s version
of the library with this Pipeline.

Jenkinsfile

// Declarative //
#!groovy
@Library(&#x27;bitwiseman-shared@blog/declarative/notifications&#x27;) _ (1)

pipeline {
  agent {
    // Use docker container
    docker {
      image &#x27;ruby:2.3&#x27;
    }
  }
  options {
    // Only keep the 10 most recent builds
    buildDiscarder(logRotator(numToKeepStr:&#x27;10&#x27;))
  }
  stages {
    stage (&#x27;Start&#x27;) {
      steps {
        // send build started notifications
        sendNotifications &#x27;STARTED&#x27;
      }
    }
    stage (&#x27;Install&#x27;) {
      steps {
        // install required bundles
        sh &#x27;bundle install&#x27;
      }
    }
    stage (&#x27;Build&#x27;) {
      steps {
        // build
        sh &#x27;bundle exec rake build&#x27;
      }

      post {
        success {
          // Archive the built artifacts
          archive includes: &#x27;pkg/*.gem&#x27;
        }
      }
    }
    stage (&#x27;Test&#x27;) {
      steps {
        // run tests with coverage
        sh &#x27;bundle exec rake spec&#x27;
      }

      post {
        success {
          // publish html
          publishHTML target: [
              allowMissing: false,
              alwaysLinkToLastBuild: false,
              keepAll: true,
              reportDir: &#x27;coverage&#x27;,
              reportFiles: &#x27;index.html&#x27;,
              reportName: &#x27;RCov Report&#x27;
            ]
        }
      }
    }
  }
  post {
    always {
      sendNotifications currentBuild.result
    }
  }
}
// Scripted //

1
The _ here is intentional.
Java/Groovy Annotations
such as @Library must be applied to an element.
That is often a using statement, but that isn’t needed here so by convention we use an \_.

vars/sendNotifications.groovy

#!/usr/bin/env groovy

/**
 * Send notifications based on build status string
 */
def call(String buildStatus = &#x27;STARTED&#x27;) {
  // build status of null means successful
  buildStatus = buildStatus ?: &#x27;SUCCESS&#x27;

  // Default values
  def colorName = &#x27;RED&#x27;
  def colorCode = &#x27;#FF0000&#x27;
  def subject = &quot;${buildStatus}: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;&quot;
  def summary = &quot;${subject} (${env.BUILD_URL})&quot;
  def details = &quot;&quot;&quot; ${buildStatus}: Job &#x27;${env.JOB_NAME} [${env.BUILD_NUMBER}]&#x27;:
Check console output at &quot; ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;&quot;&quot;&quot;

  // Override default values based on build status
  if (buildStatus == &#x27;STARTED&#x27;) {
    color = &#x27;YELLOW&#x27;
    colorCode = &#x27;#FFFF00&#x27;
  } else if (buildStatus == &#x27;SUCCESS&#x27;) {
    color = &#x27;GREEN&#x27;
    colorCode = &#x27;#00FF00&#x27;
  } else {
    color = &#x27;RED&#x27;
    colorCode = &#x27;#FF0000&#x27;
  }

  // Send notifications
  slackSend (color: colorCode, message: summary)

  hipchatSend (color: color, notify: true, message: summary)

  emailext (
      to: &#x27;bitwiseman@bitwiseman.com&#x27;,
      subject: subject,
      body: details,
      recipientProviders: [[$class: &#x27;DevelopersRecipientProvider&#x27;]]
    )
}

Conclusion

In this post we added notifications to our Declarative Pipeline.
We wanted to move our repetitive notification code into a method;
however, Declarative Pipeline prevented us from defining a method in our Jenkinsfile.
Instead, with the help of the Shared Library feature,
we were able to define a sendNotifications Step that we could call from our Jenkinsfile.
This maintained the clarity of our Pipeline and will let us easily reuse this Step in other projects.
I was pleased to see how little the resulting Pipeline differed from where we started.
The changes were restricted to the start and end of the file with no reformatting elsewhere.

In the next post, we’ll cover more about shared libraries and how to
run Sauce OnDemand with xUnit Reporting in Declarative Pipeline.

Links

Declarative Pipeline plugin

Declarative Pipeline Syntax Reference

Shared Library reference

Pipeline source for this post

Pipeline Shared Library source for this post<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/notifications">notifications</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/slack">slack</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hipchat">hipchat</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/emailext">emailext</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/15/pipeline-editor-preview/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">15</div></div><h5 class="title">Say Hello to the Blue Ocean Pipeline Editor</h5></div><p class="teaser">Back in September 2016 we announced the availability of the Blue Ocean beta
and the forthcoming Visual Pipeline Editor. We are happy to announce that you can try
the Pipeline Editor preview release today.

What is it?

The Visual Pipeline Editor is the simplest way for anyone wanting to get started with
creating Pipelines in Jenkins. It’s also a great way for advanced Jenkins users
to start adopting pipeline. It allows developers to break up their pipeline into different
 stages and parallelize tasks that can occur at the same time - graphically.
 The rest is up to you.

A pipeline you create visually will produce a Declarative Pipeline Jenkinsfile for you and
 the Jenkinsfile is stored within a Git repository where it is versioned with your application code.

If you are not sure what a Jenkins Pipeline or a Jenkinsfile is, why not check out the new guided tour to learn more about it?

What are we doing next?

We are working hard to provide feature parity between the Declarative Pipeline syntax and the visual editor. The next phase is to integrate the editor into Blue Ocean so that you don’t have to leave the UI and commit the Jenkinsfile to your repository to complete authoring your pipeline.

In Blue Ocean, you will be able to edit a Jenkinsfile
for a branch directly from within the user interface using the Visual Pipeline Editor. When you are done authoring your pipeline, the pipeline definition will be saved back to your repository as a Jenkinsfile. You can edit the Pipeline again using the Visual Editor or from your favorite text editor.

We are hoping to deliver this level of integration into Blue Ocean and the
Visual Pipeline Editor over the next few months, so be sure to check regularly for updates in
the Jenkins plugin manager.

Get the Preview

The Visual Pipeline Editor is available in preview today.

To try it out today:

Install the Blue Ocean beta and Blue Ocean Pipeline Editor from the Jenkins plugin manager

Click on the Open Blue Ocean button and then the Pipeline Editor in the main navigation

We are looking forward to your feedback to help make the Visual Pipeline Editor
the easiest way to get started with Jenkins Pipeline. To report bugs or to
request features please follow the instructions on the project page.

And don’t forget to join us on our Gitter community chat
- drop by and say hello!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/i386/">James Dumay</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/editor">editor</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/23/declarative-saucelabs-xunit/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">23</div></div><h5 class="title">Browser testing and conditional logic in Declarative Pipeline</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Declare Your Pipelines!
Declarative Pipeline 1.0 is here!
This is the fourth post in a series showing some of the cool features of
Declarative Pipeline.

In the
previous post,
we integrated several notification services into a Declarative Pipeline.
We kept our Pipeline clean and easy to understand
by using a shared library to make a custom step called sendNotifications
that we called at the start and end of our Pipeline.

In this blog post, we’ll start by translating the Scripted Pipeline in the sample project I worked with
in
&quot; Browser-testing with Sauce OnDemand and Pipeline&quot;
and
&quot; xUnit and Pipeline&quot;
to Declarative.
We’ll make our Pipeline clearer by adding an environment directive
to define some environment variables, and then moving some code to a shared library.
Finally, we’ll look at using the when directive to add simple conditional behavior to our Pipeline.

Setup

The setup for this post uses the same repository as the two posts above,
my fork
of the
JS-Nightwatch.js sample project.
I’ve once again created a branch specifically for this blog post,
this time called
blog/declarative/sauce .

Like the two posts above, this Pipeline will use the
xUnit and
Sauce OnDemand plugins.
The xUnit plugin only needs to be installed, the Sauce OnDemand needs additional configuration.
Follow
Sauce Labs&#x27; configuration instructions
to create an account with Sauce Labs and add your Sauce Labs credentials to Jenkins.
The Sauce OnDemand plugin will automatically install
Sauce Connect
for us when we call it from our Pipeline.

Be sure to you have the latest version of the
Sauce OnDemand plugin (1.160 or newer).
It has several fixes required for this post.

For a shared library, I’ve still got the one from the
previous post.
To set up this &quot;Global Pipeline Library,&quot; navigate to &quot;Manage Jenkins&quot; → &quot;Configure System&quot;
in the Jenkins web UI.
Once there, under &quot;Global Pipeline Libraries&quot;, add a new library.
Then set the name to bitwiseman-shared, point it at my repository,
and set the default branch for the library to master.

Reducing Complexity with Declarative

If you’ve been following along through this series,
this first step will be quite familiar by now.
We’ll start from the Pipeline we had at the end of the xUnit post
and translate it to Declarative.

// Declarative //
pipeline {
    agent any
    options {
        // Nightwatch.js supports color ouput, so wrap add his option
        ansiColor colorMapName: &#x27;XTerm&#x27;
    }
    stages {
        stage (&quot;Build&quot;) {
            steps {
                // Install dependencies
                sh &#x27;npm install&#x27;
            }
        }
        stage (&quot;Test&quot;) {
            steps {
                // Add sauce credentials
                sauce(&#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;) {
                    // Start sauce connect
                    sauceconnect() {
                        // Run selenium tests using Nightwatch.js
                        // Ignore error codes. The junit publisher will cover setting build status.
                        sh &quot;./node_modules/.bin/nightwatch -e chrome,firefox,ie,edge --test tests/guineaPig.js || true&quot;
                    }
                }
            }
            post {
                always {
                    step([$class: &#x27;XUnitBuilder&#x27;,
                        thresholds: [
                            [$class: &#x27;SkippedThreshold&#x27;, failureThreshold: &#x27;0&#x27;],
                            // Allow for a significant number of failures
                            // Keeping this threshold so that overwhelming failures are guaranteed
                            //     to still fail the build
                            [$class: &#x27;FailedThreshold&#x27;, failureThreshold: &#x27;10&#x27;]],
                        tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

                    saucePublisher()
                }
            }
        }
    }
// Scripted //
node {
    stage &quot;Build&quot;
    checkout scm

    // Install dependencies
    sh &#x27;npm install&#x27;

    stage &quot;Test&quot;
    // Add sauce credentials
    sauce(&#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;) {
        // Start sauce connect
        sauceconnect() {

            // List of browser configs we&#x27;ll be testing against.
            def platform_configs = [
                &#x27;chrome&#x27;,
                &#x27;firefox&#x27;,
                &#x27;ie&#x27;,
                &#x27;edge&#x27;
            ].join(&#x27;,&#x27;)

            // Nightwatch.js supports color ouput, so wrap this step for ansi color
            wrap([$class: &#x27;AnsiColorBuildWrapper&#x27;, &#x27;colorMapName&#x27;: &#x27;XTerm&#x27;]) {
                // Run selenium tests using Nightwatch.js
                // Ignore error codes. The junit publisher will cover setting build status.
                sh &quot;./node_modules/.bin/nightwatch -e ${platform_configs} --test tests/guineaPig.js || true&quot;
            }

            step([$class: &#x27;XUnitBuilder&#x27;,
                thresholds: [
                    [$class: &#x27;SkippedThreshold&#x27;, failureThreshold: &#x27;0&#x27;],
                    // Allow for a significant number of failures
                    // Keeping this threshold so that overwhelming failures are guaranteed
                    //     to still fail the build
                    [$class: &#x27;FailedThreshold&#x27;, failureThreshold: &#x27;10&#x27;]],
                tools: [[$class: &#x27;JUnitType&#x27;, pattern: &#x27;reports/**&#x27;]]])

            saucePublisher()
        }
    }
}

Blue Ocean doesn’t support displaying SauceLabs test reports yet
(see JENKINS-42242).
To view the report above, I had to switch back to the stage view of this run.

Elevating Settings using environment

Each time we’ve moved a project from Scripted Pipeline to Declarative,
we’ve found the cleaner format of Declarative Pipeline highlights the less
clear parts of the existing Pipeline.
In this case, the first thing that jumps out at me is that the parameters of the
Saucelabs and Nightwatch execution are hardcoded and buried down in the middle of our Pipeline.
This is a relatively short Pipeline, so it isn’t terribly hard to find them,
but as this pipeline grows and changes it would be better if those values were kept separate.
In Scripted, we’d have defined some variables,
but Declarative doesn’t allow us to define variables in the usual Groovy sense.

The environment directive let’s us set some environment variables
and use them later in our pipeline.
As you’d expect, the environment directive is just a set of name-value pairs.
Environment variables are accessible in Pipeline via env.variableName (or just variableName)
and in shell scripts as standard environment variables, typically $variableName.

Let’s move the list of browsers, the test filter, and the sauce credential string to environment variables.

Jenkinsfile

environment {
        saucelabsCredentialId = &#x27;f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a&#x27;
        sauceTestFilter = &#x27;tests/guineaPig.js&#x27;
        platformConfigs = &#x27;chrome,firefox,ie,edge&#x27;
    }
    stages {
        /* ... unchanged ... */
        stage (&quot;Test&quot;) {
            steps {
                // Add sauce credentials
                sauce(saucelabsCredentialId) {
                    // Start sauce connect
                    sauceconnect() {
                        // Run selenium tests using Nightwatch.js
                        // Ignore error codes. The junit publisher will cover setting build status.
                        sh &quot;./node_modules/.bin/nightwatch -e ${env.platformConfigs} --test ${env.sauceTestFilter} || true&quot; (1)
}
                }
            }
            post { /* ... unchanged ... */ }
        }
    }
}

1
This double-quoted string causes Groovy to replace the variables with their
literal values before passing to sh.
This could also be written using singe-quotes:
sh &#x27;./node_modules/.bin/nightwatch -e $platformConfigs --test $sauceTestFilter || true&#x27;.
With a single quoted string, the string is passed as written to the shell,
and then the shell does the variable substitution.

Moving Complex Code to Shared Libraries

Now that we have settings separated from the code, we can do some code clean up.
Unlike the previous post, we don’t have any repeating code,
but we do have some distractions.
The nesting of sauce, sauceconnect, and sh nightwatch seems excessive,
and that xUnit step is a bit ugly as well.
Let’s move those into our shared library as custom steps with parameters.
We’ll change the Jenkinsfile in our main project,
and add the custom steps to a branch named
blog/declarative/sauce in our library repository.

Jenkinsfile

@Library(&#x27;bitwiseman-shared@blog/declarative/sauce&#x27;) _

/* ... unchanged ... */

stage (&quot;Test&quot;) {
    steps {
        sauceNightwatch saucelabsCredentialId,
            platformConfigs,
            sauceTestFilter
    }
    post {
        always {
            xUnitPublishResults &#x27;reports/**&#x27;,
                /* failWhenSkippedExceeds */ 0,
                /* failWhenFailedExceeds */ 10

            saucePublisher()
        }
    }
}

vars/sauceNightwatch.groovy

def call(String sauceCredential, String platforms = null, String testFilter = null) {
    platforms = platforms ? &quot;-e &#x27;&quot; + platforms + &quot;&#x27;&quot; : &#x27;&#x27;
    testFilter = testFilter ? &quot;--test &#x27;&quot; + testFilter + &quot;&#x27;&quot; : &#x27;&#x27;

    // Add sauce credentials
    sauce(sauceCredential) {
        // Start sauce connect
        sauceconnect() {
            // Run selenium tests using Nightwatch.js
            // Ignore error codes. The junit publisher will cover setting build status.
            sh &quot;./node_modules/.bin/nightwatch ${platforms} ${testFilter} || true&quot; (1)
}
    }
}

1
In this form, this could not be written using a literal single-quoted string.
Here, platforms and testFilter are groovy variables, not environment variables.

vars/xUnitPublishResults.groovy

def call(String pattern, Integer failWhenSkippedExceeds,
        Integer failWhenFailedExceeds) {
    step([$class: &#x27;XUnitBuilder&#x27;,
        thresholds: [
            [$class: &#x27;SkippedThreshold&#x27;, failureThreshold: failWhenSkippedExceeds.toString()],
            // Allow for a significant number of failures
            // Keeping this threshold so that overwhelming failures are guaranteed
            //     to still fail the build
            [$class: &#x27;FailedThreshold&#x27;, failureThreshold: failWhenFailedExceeds.toString()]],
        tools: [[$class: &#x27;JUnitType&#x27;, pattern: pattern]]])
}

Running Conditional Stages using when

This is a sample web testing project.
We probably wouldn’t deploy it like we would production code,
but we might still want to deploy somewhere,
by publishing it to an artifact repository, for example.
This project is hosted on GitHub and uses feature branches and pull requests to make changes.
I’d like to use the same Pipeline for feature branches, pull requests, and the master branch,
but I only want to deploy from master.

In Scripted, we’d wrap a stage in an if-then and check if the branch for
the current run is named &quot;master&quot;.
Declarative doesn’t support that kind of general conditional behavior.
Instead, it provides a
when directive
that can be added to stage sections.
The when directive supports several types of conditions, including a branch condition,
where the stage will run when the branch name matches the specified pattern.
That is exactly what we need here.

Jenkinsfile

stages {
    /* ... unchanged ... */
    stage (&#x27;Deploy&#x27;) {
        when {
            branch &#x27;master&#x27;
        }
        steps {
             echo &#x27;Placeholder for deploy steps.&#x27;
        }
    }
}

When we run our Pipeline with this new stage, we get the following outputs:

Log output for &#x27;feature/test&#x27; branch

...
Finished Sauce Labs test publisher
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Deploy)
Stage &#x27;Deploy&#x27; skipped due to when conditional
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
...

Log output for &#x27;master&#x27; branch

...
Finished Sauce Labs test publisher
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Deploy)
[Pipeline] echo
Placeholder for deploy steps.
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
...

Conclusion

I have to say, our latest Declarative Pipeline turned out extremely well.
I think someone coming from Freestyle jobs, with little to no experience with Pipeline or Groovy,
would still be able to look at this Declarative Pipeline and make sense of what it is doing.
We’ve added new functionality to our Pipeline while making it easier to understand
and maintain.

I hope you’ve learned as much as I have during this blog series.
I’m excited to see that even in the the short time since Declarative 1.0 was released,
teams are already using it in make improvements similar to what those we’ve covered in this series.
Thanks for reading!

Links

xUnit

Sauce OnDemand

Declarative Pipeline plugin

Declarative Pipeline Syntax Reference

Pipeline source for this post

Pipeline Shared Library source for this post<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/xunit">xunit</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/nightwatch">nightwatch</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/saucelabs">saucelabs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/selenium">selenium</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/02/24/blueocean-devlog-feb4/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">24</div></div><h5 class="title">Blue Ocean Dev Log: February Week #4</h5></div><p class="teaser">We’re counting down the weeks until Blue Ocean 1.0.
In all the excitement I forgot to post
a dev log last week, so I will make up for it this week.

In the last 10 days, 2 betas went out: b22 and b23, and a preview release of
the editor. We expect the next release will be named a release candidate (we
know there is still more to go in, but want to signal that things are getting
into the final stages!). The
Gitter chat room is
getting busier, so join in!

Also last week, the Blue Ocean Pipeline Editor was presented at the
Jenkins Online Meetup,
embedded below.

Feature Highlights

You can now create Pipelines from GitHub in Blue Ocean. Either one
Pipeline at a time, or let it discover all your Pipelines for a GitHub Organization.

When you press the &quot;Create&quot; button, it will open the new creation flow
by default now; the feature was previously hidden behind a feature switch.

You can filter the activity screen by branch! That way you can see a
history of Pipeline runs for just one branch.

If you like long names for stages - it now won’t pollute the screen
when space is at a premium (truncated names on screen).

Blue Ocean events ( SSE) should now work on Microsoft Edge again

You can see durations when you hover the mouse over indicators

Up next:

A release candidate is expected soon

Integration work with the Editor to save to branches

Some updates to the design around tables

Bundling of the Editor with Blue Ocean

Don’t forget, there is also a Blue Ocean Docker image published weekly with
usually the latest released version. If you have Docker installed, this can
be as simple as:

docker run -p 8080:8080 jenkinsci/blueocean*

Then browse to localhost:8080/blue - possibly
the quickest way to try things.

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/03/blueocean-devlog-mar1/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 3</div></div><h5 class="title">Blue Ocean Dev Log: March Week #1</h5></div><p class="teaser">We’re counting down the weeks until Blue Ocean 1.0.
This week was relatively quiet with a few people away for a few days, and
mostly about consolidation. There was a beta late last week, so this week we
thought we would let people have a rest from the upgrade treadmill for once.

One notable feature that has recently landed is &quot;escaping to Classic&quot; When you
see the exit symbol (door with arrow) it will take you to an equivalent page in
classic Jenkins (if one exists). You will notice this in a few places in the
app now.

Some other things that made it to master branch which have not yet been
released in a beta:

An API to save/branch to GitHub was finished, and tested with &quot;round
tripping&quot; with the Editor in some form

New compact form of duration reporting (old style was too verbose for
most screens)

Fixed a bug with input submissions with concurrent browser sessions which was
quite a tricky bug to chase down!

Only show Admin link when appropriate.

Many many bug fixes and polishing.

There has also been an uptick in activity on the
Gitter channel with an
increased number of questions about usage and Pipelines. But also questions
from people starting to extend, or add features, to Blue Ocean, which is very
nice to see.

Gavin Mogan has been looking at integrating
the Sauce OnDemand plugin into Blue Ocean for better
browser-test reporting. Tangentially related, we also are planning to improve
browser-testing in Blue Ocean as well. What is perhaps more exciting is that
more people, like Paul Dragoonis and
other folks, are starting to contribute some
fixes which have been lingering around for a while.

Up Next:

Round trip Blue Ocean Pipeline Editor changes with load/save

Bundling the Blue Ocean Pipeline Editor with the &quot;aggregator&quot; Blue Ocean
plugin.

Some release candidates!

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/10/blueocean-devlog-mar2/"><div class="header"><div class="date"><div class="month">March</div><div class="day">10</div></div><h5 class="title">Blue Ocean Dev Log: March Week #2</h5></div><p class="teaser">We’re counting down the weeks until Blue Ocean 1.0.
This week was one of continuing consolidation and polish. We also released b25
(beta #25), a collectors edition. The next version we will likely release will
be a release candidate (RC). The b25 release however contained a number of
fixes and features, such as branch filtering.

Some other updates of note from this past week:

Updated a bunch of dependencies around Pipeline and fixed a whole lot
of long standing bugs.

Some work went on to make acceptance tests run on varied browsers via
Sauce Labs thanks to
@halkeye!

The Blue Ocean Pipeline Editor had its
Save to SCM/GitHub functionality
merged to master branch.  It won’t be released to the Update Center until the
next Blue Ocean release, there are a few more things to iron out.

As the Blue Ocean Pipeline Editor is now considered to be part of Blue Ocean
now, more people are kicking the tires, and starting to
contribute
fixes to improve it!

The swishy &quot;Blue Ocean&quot; logo is gone, Jenkins branding is back (mixed feelings!)

Fixes for concurrent users of input

Fixes for handling errors around favoriting of Pipelines and more.

Speeding up creation of Multibranch Pipelines via the new &quot;Creation&quot; flow.

And of course, a nice pretty screenshot of editing and saving a Multibranch
Pipeline with the Blue Ocean Pipeline Editor:

Up next for the Blue Ocean project:

More consolidation and polish.

A first release candidate out the door (!)

New, sleeker, favorite card design, possibly a table design too.

Also note that there are changelogs maintained and visible on the
Blue Ocean plugin page.

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/16/fosdem-event-report/"><div class="header"><div class="date"><div class="month">March</div><div class="day">16</div></div><h5 class="title">FOSDEM 2017 Wrap-up</h5></div><p class="teaser">In early February numerous free and open source developers from around the
world traveled to Brussels, Belgium, for arguably the largest event of its
kind:
FOSDEM. Among the thousands of hackers in attendance
were a dozen or so Jenkins contributors. We have attended the event in the
past, but this year we had a blizzard of activity spanning four days around the FOSDEM
weekend.

Figure 1. City Hall, photo by Kohsuke Kawaguchi

One of our &quot;accidental traditions&quot; has become a
happy hour
the Friday night before FOSDEM truly begins at Cafe Le Roy d’Espagne on Grand
Place right in the middle of Brussels. Conveniently located a few hundred meters away from the
FOSDEM Beer Event
at Delirium Cafe, each year we are inevitably joined by friends from other open
source projects who know they’re welcome to join us for a few drinks.

Figure 2. Cafe Le Roy, photo by Kohsuke Kawaguchi

After dinner and drinks, a few of us decided it would be a good idea (it
wasn’t) to walk over to check out the FOSDEM Beer Event and maybe have just
one more beer. For the uninitiated, Belgian beers tend to be strong, as the FOSDEM organizers warn:

Unlike some other beers, Belgian beer is not just coloured water. Some beers
contain significant quantities of alcohol and will give you a pounding
hangover.

Unfortunately, some of us seem to re-learn this lesson each year at FOSDEM!

Bright and early the following day, FOSDEM really kicked off with keynotes and
the project tables lining a number of corridors.

Figure 3. A busy hall at FOSDEM, photo by Kohsuke Kawaguchi

At the Jenkins project’s table we typically spend two full days answering questions,
showing off the latest and greatest Jenkins features, and of course handing out
Jenkins stickers. The table is where many contributors, myself included, have
a rare opportunity to talk with dozens of enthusiastic Jenkins users from
across the broader open source community. This year we were very fortunate to have a
tremendous number of contributors available at the table to answer hundreds of
questions throughout the two days of FOSDEM.

I would like to thank everybody by name, but the entire weekend was such a blur
that I’m not sure I would be able to remember everybody who helped! We couldn’t have
had a successful event without their support, so many thanks to all the
contributors who helped!

In addition to the Jenkins project table, we had two contributors present in
the
Testing and Automation
devroom, which I helped organize in between answering Jenkins questions.

Declarative Pipelines in Jenkins

The first presentation was a stellar introduction to
Declarative Pipelines
in Jenkins, by long-time contributor and primary developer of Declarative
Pipeline support,
Andrew Bayer.

Using Containers for Building and Testing

Later in the day,
Carlos Sanchez,
another long-time contributor, maintainer of the
Kubernetes plugin and a number of Jenkins- and Maven-related
Docker containers, provided a great overview of the current state of using
containers for building and testing in Jenkins.

After a very busy two days at FOSDEM, a few contributors remained in Brussels
for a day-long
Post-FOSDEM Contributor Hackathon
sponsored by CloudBees, Inc. and
Betacowork Brussels. Trying to cram lots of
hacking into a single day is challenging, so the day was mostly filled with
discussions, some light prototyping, and a bit of recovery from the hectic
weekend at FOSDEM. :)

Figure 4. Daniel Beck presenting on CLI prototyping, photo by Kohsuke Kawaguchi

Thanks

Of course I would like to extend many thanks to all the contributors who
participated in the various FOSDEM related events, but I would call special
attention to the logistics and planning work done by contributors Alyssa Tong,
Damien Duportal, and Olivier Vernin. Thanks to their work coordinating all the
plans, reservations, and schedules, we had a flawless weekend
of high-intensity Jenkins discussion, advocacy, and hacking.

I hope to see everybody back in Brussels next year for FOSDEM 2018!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/fosdem">fosdem</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/17/blueocean-devlog-mar3/"><div class="header"><div class="date"><div class="month">March</div><div class="day">17</div></div><h5 class="title">Blue Ocean Dev Log: March Week #3</h5></div><p class="teaser">We’re counting down the weeks until Blue Ocean 1.0,
and we’re getting close!  In this past week, the first release candidate
has gone out to the Update Center, along with a new
Pipeline Editor plugin. The Blue Ocean
Pipeline Editor is its own plugin which integrates into Blue Ocean, so this was
a coordinated release with Blue Ocean 1.0 rc1.

Noteworthy this week:

RC1 includes the Blue Ocean Pipeline Editor, which is integrates support for
branch editing and saving the Pipeline back to GitHub (also referred to as
&quot;round-tripping&quot;).

Many dependencies have been upgraded

Per-stage raw logs can be downloaded, this will be included in the next
release.

Editor design improvements

Fixes for overflowing text

The new sleeker favorite card design has been released, so you can fit
more favorites on your screen!

The Blue Ocean Pipeline Editor is better integrated into a few different
screens in Blue Ocean. For example, you can open the editor from the results
screen (top right):

Or open the editor from branch listings:

Up next:

More bug-bashing! Please join us in testing the release candidate.
Instructions for trying Blue Ocean can be found on
our project page.

Another release candidate

Enjoy!

If you’re interested in helping to make Blue Ocean a great user experience for
Jenkins, please join the Blue Ocean development team on
Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/20/security-updates/"><div class="header"><div class="date"><div class="month">March</div><div class="day">20</div></div><h5 class="title">Security updates for multiple Jenkins plugins</h5></div><p class="teaser">Multiple Jenkins plugins received updates today that fix several security vulnerabilities:

Active Directory

Distributed Fork

Email Extension (Email-ext)

Mailer

SSH Build Agents

For an overview of what was fixed, see the security advisory.

Additionally, we also published a security notice for the following plugin and recommend that users disable and uninstall it:

Pipeline: Classpath Step

This plugin is not part of the Pipeline suite of plugins, despite its name. It’s installed on just several hundred instances.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/21/toulousejam-pipeline-workshop/"><div class="header"><div class="date"><div class="month">March</div><div class="day">21</div></div><h5 class="title">Pipeline Workshop &amp; Hackergarten @ ToulouseJAM Feedback</h5></div><p class="teaser">Earlier this month, a full-day event about Jenkins Pipeline was organized in Toulouse, France with the Toulouse JAM.

After a warm-up on the previous Tuesday where Michaël Pailloncy had given a talk at the local Toulouse Devops user group about Jenkins Pipeline ecosystem, we were ready for more digging :-).

The agenda

We had planned the day in two parts:

Morning would be a more driven workshop with slides &amp; exercises to be completed

Pizzas &amp; beverages to split the day :-)

Afternoon would be somehow like an Unconference, where people basically decide by themselves what they want to work on.

We planned to have 30 attendees. We ended up having 25.
We considered having more people, but finally decided that for a first time it would be better to start not too big.

Infrastructure

Infrastructure was sponsored by DigitalOcean.

For each attendee, we provisioned :

One Controller, preconfigured to be able to dynamically provision agents.

One staging environment

One production environment
[ 1 ]

One SonarQube instance

Workshop content &amp; infrastructure

After an initial quick presentation to settle context and remind some general things about Continuous Delivery and Jenkins, we started the workshop per se.

It is composed of 3 parts, which are readable here [ 2 ], but very few people were able to start the part 3.

Hackergarten / Unconference

So we let people decide what they wanted to work on during the afternoon.

We decided to use post-its: each attendee would write down what they wanted to work on, one idea per post-it (max 2 per person).
Then, we dropped those onto a white-board and tried grouping those by theme.

In the end, overall, the following themes went out:

Hack on Jenkins development &amp; Contribute to Jenkins

Complete the workshops

Work on use-case oriented things

Work on Docker &amp; Pipeline join usages

Hackergarten

Many Jenkins accounts were created, and many JIRA and pull requests were filed.
It was nice to see people asking questions like: &quot;so, should I create a JIRA issue for this?&quot; or &quot;how do I interact with people&quot;.
Pretty generic &quot;how do I work on open source software&quot; questions sometimes, but important because you felt like people were genuinely interested and needed not much to start contributing.

Here are the pull requests filed during this afternoon:

blueocean-pipeline-editor-plugin#30

jenkins#2785

jenkins#2786

jenkins#2787

jenkins#2788

You can see that though most of the PRs were typo-related, the one that got merged first was the one about code :-).

So, Jeremie Violas wins the Bobble Head as promised!

Why so many typo-related PRs?

Simply because people were somehow encouraged to find some to get used to the
round trip of: fixing an issue and filing the associated pull request, rinse &amp;
repeat.

I do think this is also a pretty nice and simple first step to understand how
to build Jenkins and start interacting with the community.

The result

People seemed pretty happy and we got some nice comments like &quot;now I have a clearer vision of what this Pipeline thing is about&quot;.
Some attendees also dropped nice comments on the meetup page.
So it’s cool because when you’re doing such things on your free time, it’s the main reward you can get.

If you’re an attendee to such events, don’t forget to thank people organizing
those, and more importantly to provide constructive feedback.  We are generally
eager to know what could be done better for next time.

Conclusion

Overall we are very happy with the energy of that day, and we definitely plan to set up a new session in the next few months, probably with a bit more people.

Some thoughts:

Infrastructure: when you plan to have many VM per attendee, double-check the limits your Cloud Provider may have by default. I had bumped it to 250 the day before the workshop, and asked for another one to 500 during the workshop (though in the end, 250 was probably enough, but this’ll give room for the next time with more people :-)).

Logistics: warning, secret ahead: this is very time consuming.
Not necessarily the amount of work itself, more that it implies very big latency.
For instance, give it 2 to 3 weeks minimum to have answers about sponsoring in general. Pinging again in case of no answer after 2 days would probably be seen as rude, and possibly lead to make things worse for obvious reasons, so plan ahead.

Thank you

DigitalOcean for sponsoring the Infrastructure

We got way more than 100 VMs running at the same time during the day thanks to their help!

HarryCow Coworking for hosting the event

To CloudBees for sponsoring the food for all the participants

Also for providing a bunch of goodies: stickers and T-Shirts for everybody

GitHub for providing stickers

1. For the sake of the simplicity of the workshop, those environments were actually a single VM: the goal was here to illustrate what we could do using Jenkins Pipeline, discussing scalability or more involved deployment techniques was obviously out of scope.

2. in French only for now, but translating it into English to make it possibly shared and reusable among JAMs is being discussed<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hackergarten">hackergarten</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/meetup">meetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/06/welcome-to-blue-ocean-editor/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 6</div></div><h5 class="title">Getting Started with Blue Ocean&#x27;s Visual Pipeline Editor</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Blue Ocean is a new user experience for Jenkins,
and version 1.0 is now live!
Blue Ocean makes Jenkins, and continuous delivery, approachable to all team members.
In my previous post,
I explained how to install Blue Ocean on your local Jenkins instance and switch to using Blue Ocean.
As promised, here’s a screencast that picks up where that post left off.
Starting from a clean Jenkins install, the video below will guide you through
creating and running your first Pipeline in Blue Ocean with the Visual Pipeline Editor.

Please Enjoy! In my next video, I’ll go over the
Blue Ocean Pipeline Activity View.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/10/jenkins-has-upgraded-to-java-8/"><div class="header"><div class="date"><div class="month">April</div><div class="day">10</div></div><h5 class="title">Starting with 2.54, Jenkins now requires Java 8</h5></div><p class="teaser">We announced in January
that Jenkins would be upgrading its Java runtime dependency to Java 8 this
year. After a sizable amount of preparation, this week’s release of
Jenkins 2.54 is the first weekly release to require
a Java 8 runtime.

For users of the weekly release, this means that Jenkins 2.54 must have
a Java 8 runtime installed on the system in order to
run. Those using the
jenkinsci/jenkins:latest
Docker container won’t need to take any action, as the Java runtime environment
is already bundled in the container.

In addition to upgrading the Java Runtime Environment for the controller, any
connected agents must upgrade to a Java 8 runtime environment.

The Long-Term Support (LTS) release line however, has
not yet been updated to require Java 8. We are expecting the first LTS release
to require Java 8 in June.

Compatibility Notes

Using the Maven project type with Java 7

Users with jobs configured with the &quot;Maven project&quot; type may not be able to use
Java 7 for their Maven jobs. The correct behavior is not guaranteed so
proceed at your own risk. The Maven Project uses Jenkins Remoting to establish
&quot;interceptors&quot; within the Maven executable. Because of this, Maven uses
Remoting and other Jenkins core classes, and this behavior may break an update.

See also:
JENKINS-40990.

Java 9 compatibility

At this point, Jenkins does not yet support Java 9 development releases.

As always, if you have questions please ask on the
jenkinsci-users@ mailing list or
report
an issue in JIRA.

References

JVM statistics post back in November 2016.

Official announcement blog post.

Original JIRA ticket for this upgrade.

The 6 months, 82 messages, thread on the Jenkins developers mailing list

The announcement on the Jenkins users mailing list

The Pull request on Jenkins core<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java8">java8</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/10/security-advisory/"><div class="header"><div class="date"><div class="month">April</div><div class="day">10</div></div><h5 class="title">Important Scripting-related Security Advisory</h5></div><p class="teaser">These are not security fixes you can apply blindly. We strongly recommend you read this post, as well as the security advisory to understand what the vulnerabilities are, whether and how they affect you, and what to expect when upgrading plugins.

Multiple Jenkins plugins received updates today that fix several security vulnerabilities or other security-related issues:

Email Extension (Email-ext)

Environment Injector (EnvInject)

Extensible Choice Parameter

Groovy

Job DSL

Lockable Resources

Matrix Authorization

Role Strategy

Warnings

We also included some plugins that received security fixes in the past that haven’t been mentioned in a security advisory before:

Active Choices (uno-choice)

Extended Choice Parameter

Groovy Postbuild

Groovy Label Assignment

Additionally, we included other plugins in the advisory that are not getting updated today, but whose vulnerabilities are similar to those of plugins getting fixed.
In total, over 30 plugins are part of the advisory.

While there are fixes for other vulnerabilities as well, the majority of the advisory (and the rest of this blog post) is about arbitrary code execution vulnerabilities in Jenkins plugins.

Background

Jenkins administrators have long been able to use the Groovy script console and related functionality to execute arbitrary code in Jenkins for diagnostic or otherwise administrative purposes.
Rather than having to rely on plugins implementing the desired functionality, experienced Jenkins admins were able to run a number of scripts as needed to implement various administrative features.

This bled over into plugins:
It’s just easy for a plugin developer to build on top of Groovy and let the users figure out exactly what they want to do.
Unfortunately, for a long time, there was no technology in Jenkins to limit what could be done in Groovy scripts, so anywhere Groovy would be executed, arbitrary code could be executed.

We were treating this as a security issue for the first time in the fix for SECURITY-125, about two years ago, something that first required splitting off the Matrix Project type from core into a plugin, and making use of Script Security Plugin.

Unfortunately, other plugins weren’t integrating with Script Security plugin.
And even diligent administrators who understand the problem of arbitrary code execution via Groovy scripts may not be able to tell whether a given plugin is affected:
In some cases, you’d need to dive into the source code to see whether, and how, it uses Groovy in a way that can be exploited by regular users to perform actions they otherwise wouldn’t be allowed to do.

About the advisory

Broadly speaking, there are three levels of severity for scripting related vulnerabilities in Jenkins:

The lowest severity ones are those that confuse Overall/Administer and Overall/Run Scripts permissions.
These are irrelevant for most Jenkins instances.
More on that later.

The next level up are vulnerabilities that effectively grant the ability to run arbitrary scripts to users who are able to configure jobs.
While these users aren’t administrators, they have a nontrivial level of permissions, so are somewhat trusted.
This is often a difficult configuration to adequately secure, but it’s a supported configuration, and any plugin that undermines the security of this configuration will be treated as having a vulnerability.

The most severe ones are those that require little or no access to Jenkins to successfully exploit.
This typically does require the Overall/Read permission to access certain endpoints, but Pipeline as Code may allow people with SCM commit access to exploit scripting related weaknesses as well.

Arbitrary code execution is a serious enough issue that publishing a security advisory for just a few plugins would actually be detrimental to overall security:
Malicious users would be able to review the fixes we do publish, and try to find other plugins affected by a similar vulnerability.

The advisory issued today lists all plugins we could find that implement any arbitrary code execution vulnerability (i.e. all three levels described above).
As this affects over 30 plugins, many of them not actively maintained, the problem exceeds the capacity of the Jenkins security team to address them all.

For that reason, the Jenkins security team decided that we would fix as many of the plugins as we can handle, and leaving the others to their maintainers.

How to proceed

We strongly advise administrators to review the list of affected plugins in the advisory, and look for any plugins that are installed on their instances.
It is very likely there’s at least one plugin installed that is affected by this.
If you’re on Jenkins 2.40 or newer, or Jenkins LTS 2.32.2 or newer, a warning will appear that informs you about vulnerable plugins you currently have installed.

Once you’ve determined which plugins you use are included in the advisory, you need to determine whether it is something that affects your particular setup.

If the vulnerability confuses Overall/Administer and Overall/Run Scripts, but all administrators of your Jenkins instance are able to run scripts anyway, this vulnerability is not a problem for you.
This is the case in the vast majority of Jenkins instances.
Only custom setups, typically to allow for hosted Jenkins services, don’t grant Overall/Run Scripts permission to administrators.

If the vulnerability allows users with the permission to e.g. configure jobs to execute arbitrary code, it is only a problem if there are users that have the lower permission (e.g. Item/Configure) but not the higher ( Overall/Run Scripts).
Simple authorization strategies like Logged in users can do anything are therefore not affected by this issue.

Even vulnerabilities that require no notable permissions in Jenkins may have prerequisites to be exploitable.
For example, Overall/Read access may be required, but only granted to users who are also administrators, or in Pipeline as Code setups, everyone with SCM commit access may also be a Jenkins administrator.

The above should guide your decision how urgently you should upgrade affected plugins with a fix, or disable affected plugins without a fix.
Remember that you may decide in the future to reconfigure Jenkins in a way that makes previously irrelevant permission distinctions a huge problem, so it is not a good idea to continue using vulnerable plugin versions indefinitely.

After deciding to upgrade a plugin, review the advisory and the plugin documentation for information about the migration.
The scripts provided in this GitHub repository may help you in determining whether you’re using affected features.
If you’re not using any of the affected features, it’s likely that there won’t be any problems and you can just upgrade.
If you are using affected features, you should carefully read the documentation on how the upgrade works: Affected plugin features may effectively be disabled until an administrator approves the scripts in use, potentially resulting in build failures.

Distributing vulnerable plugins

Finally, there’s the issue of distribution:
The Jenkins project historically has performed little to no oversight over the plugins that are being published.
This is a direct consequence of the governance document, which gives plugin maintainers a lot of control over their plugins.

That said, in exceptional circumstances, the Jenkins project can, and should, protect its users:
If a plugin maintainer were to upload a clearly malicious plugin, we wouldn’t stand by the side and continue distributing it.
In the case of plugins with known (unintended) vulnerabilities, this obviously becomes more difficult.
This has been discussed in the abstract a while back on the jenkinsci-dev mailing list, and the majority of participants in that discussion agreed that we should suspend distribution of vulnerable plugins if the security team doesn’t have the capacity to address the problem, and the vulnerability would remain unfixed otherwise.

We decided to temporarily suspend distribution of plugins via the Jenkins project update sites if they allow users with lower privileges (no Overall/Administer) to execute arbitrary code.
Users who really need to download these plugins can do so via our Artifactory Maven repository.
Once an affected plugin receives a fix, we’d of course resume distribution via the update sites.

Plugins that mistake Overall/Administer and Overall/Run Scripts continue being distributed, albeit with a warning shown to Jenkins administrators, as the setup required for this to make a difference is pretty rare.

Unfortunately, we were unable to adequately inform all plugin maintainers before publication of the advisory, so there are several plugins with fewer than 500 installations that are actively maintained but whose maintainers we didn’t contact prior to this advisory.
For that, I am really sorry, and can only ask for understanding from the maintainers of affected plugins.
The number of affected plugins and the coordination and review required simply exceeded our capabilities.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/11/new-cli/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">New, safer CLI in 2.54</h5></div><p class="teaser">In response to the zero-day vulnerability we fixed in November, I wrote the following:

Moving forward, the Jenkins security team is revisiting the design of the Jenkins CLI over the coming weeks to prevent this class of vulnerability in the future.
If you are interested in participating in that discussion, please join in on the jenkinsci-dev@ mailing list.

In early February, several project contributors met after FOSDEM for a one day hackathon.
I looked into the feasibility of a purely SSH-based CLI.
While I considered the experiment to be a success, it was far from ready to be used in a production environment.

A few weeks later, long-time contributor and Jenkins security team member Jesse Glick took over, and published a detailed proposal for a new, simple CLI protocol without remoting.

In just a month, he implemented his proposal, and I’m very happy to announce that this new implementation of the Jenkins CLI has now made it into 2.54!

Existing jenkins-cli.jar clients should continue working as before, unless an administrator disables the remoting connection mode in Configure Global Security.
That said, we recommend you download the new jenkins-cli.jar in Jenkins, and use its new -http mode.
With few (now deprecated) exceptions, CLI commands work like before.
This will allow you to disable the remoting mode for the CLI on the Jenkins controller to prevent similar vulnerabilities in the future.

SSH-based CLI use should be unaffected by this change.
Note that new Jenkins instances now start with the SSH server port disabled, and the configuration option for that was moved into Configure Global Security.

You can learn all about the CLI and its new behavior in the Jenkins handbook.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/11/welcome-to-blue-ocean-pipeline-activity/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">Getting Started with Blue Ocean&#x27;s Activity View</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Blue Ocean is a new user experience for Jenkins,
and version 1.0 is now live!
Blue Ocean makes Jenkins, and continuous delivery, approachable to all team members.
In my previous post,
I showed how easy it is to create and edit Declarative Pipelines using the Blue Ocean Visual Pipeline Editor.
In this video, I’ll use the Blue Ocean Activity View to track the
state of branches and Pull Requests in one project.
Blue Ocean makes it so much easier to find the logs I need to triage failures.

Please Enjoy!  In my
next video,
I’ll switch from looking at a single project to monitoring multiple projects with
the Blue Ocean Dashboard.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/12/jenkinsworld-agenda-announced/"><div class="header"><div class="date"><div class="month">April</div><div class="day">12</div></div><h5 class="title">Jenkins World 2017 Agenda is Live!</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

I am excited to announce the agenda for
Jenkins World 2017. This
year’s event promises to have something for everyone - whether you are a
novice, intermediate, or advanced user…​you are covered.  Jenkins World 2017
consists of 6 tracks, 60+ Jenkins and DevOps sessions, 40+ industry speakers,
16+ training and workshops.

Here is a sneak peek at Jenkins World 2017:

Show &#x27;n Tell

It’s all about that demo. These sessions are technically advanced with some code sharing, heavy on demos and just a tad bit of slides.

Plugin Development for Pipeline

Extending Blue Ocean

How to Use Jenkins Less: How and Why You Can Minimize Your Jenkins Footprint

Jenkins Pipeline on your Local Box to Reduce Cycle Time

War Stories

These are first-hand Jenkins experience and lessons learned. These stories will inspire your innovative solutions.

Pipelines At Scale: How Big, How Fast, How Many?

JenkinsPipelineUnit: Test Your Continuous Delivery Pipeline

Codifying the Build and Release Process with a Jenkins Pipeline Shared Library

Jumping on the Continuous Delivery Bandwagon: From 100+ FreeStyle Jobs to Pipeline(s) - Tactics, Pitfalls and Woes

Trainings and Workshops

(additional fees apply to certain trainings/workshops)

Introduction to Jenkins

Introduction to Plugin Development

Let’s Build a Jenkins Pipeline!

Fundamentals of Jenkins and Docker

The Jenkins World agenda is packed
with even more sessions, it will be a very informational event.

Convince your Boss

We know that attending Jenkins World needs little convincing but just in case
you need a little help to justify your attendance, we’ve created a
Justify your Trip
document to help speed up the process.

Register for Jenkins World
2017 with the code JWATONG for a 20% discount off your pass.

Hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/12/welcome-to-blue-ocean-dashboard/"><div class="header"><div class="date"><div class="month">April</div><div class="day">12</div></div><h5 class="title">Getting Started with the Blue Ocean Dashboard</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Blue Ocean is a new user experience for Jenkins,
and version 1.0 is now live!
Blue Ocean makes Jenkins, and continuous delivery, approachable to all team members.
In my previous post,
I used the Blue Ocean Activity View to track the state of branches and
Pull Requests in one project.
In this video, I’ll use the Blue Ocean Dashboard get a personalized view of the
areas that of my project that are most important to me,
and also to monitor multiple projects.
Please Enjoy!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/screencast">screencast</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/18/continuousdelivery-devops-sonarqube/"><div class="header"><div class="date"><div class="month">April</div><div class="day">18</div></div><h5 class="title">Delivery Pipelines, with Jenkins 2, SonarQube, and Artifactory</h5></div><p class="teaser">This is a guest post by Michael Hüttermann. Michael is an expert
in Continuous Delivery, DevOps and SCM/ALM. More information about him at huettermann.net, or
follow him on Twitter: @huettermann.

Continuous Delivery and DevOps are well known and widely spread practices nowadays. It is commonly accepted that it
is crucial to form great teams and define shared goals first and then choose and integrate the tools fitting best to
given tasks. Often it is a mashup of lightweight tools, which are integrated to build up Continuous Delivery pipelines
and underpin DevOps initiatives. In this blog post, we zoom in to an important part of the overall pipeline, that is the discipline
often called Continuous Inspection, which comprises inspecting code and injecting a quality gate on that, and show how artifacts can
be uploaded after the quality gate was met. DevOps enabler tools covered are Jenkins, SonarQube, and Artifactory.

The Use Case

You already know that quality cannot be injected after the fact, rather it should be part of the process and product from the very beginning.
As a commonly used good practice, it is strongly recommended to inspect the code and make findings visible, as soon as possible.
For that SonarQube is a great choice. But SonarQube is not just running on any isolated
island, it is integrated in a Delivery Pipeline. As part of the pipeline, the code is inspected, and only if the code is fine according to defined
requirements, in other words: it meets the quality gates, the built artifacts are uploaded to the binary repository manager.

Let’s consider the following scenario. One of the busy developers has to fix code, and checks in changes to the central
version control system. The day was long and the night short, and against all team commitments the developer
did not check the quality of the code in the local sandbox. Luckily, there is the build engine Jenkins
which serves as a single point of truth, implementing the Delivery Pipeline with its native pipeline features, and as a handy coincidence
SonarQube has support for Jenkins pipeline.

The change triggers a new run of the pipeline. Oh no! The build pipeline broke, and the change is not further processed.
In the following image you see that a defined quality gate was missed. The visualizing is done with Jenkins Blue Ocean.

SonarQube inspection

What is the underlying issue? We can open the SonarQube web application and drill down to the finding. In the Java code, obviously a string literal is not placed on the right side.

During a team meeting it was decided to define this to be a Blocker, and SonarQube was configured accordingly. Furthermore, a SonarQube quality gate was created to break any build, if a blocker was identified. Let’s now quickly look into the code.
Yes, SonarQube is right, there is the issue with the following code snippet.

We do not want to discuss in detail all used tools, and also covering the complete Jenkins build job would be out of scope.
But the interesting extract here in regard of the inspection is the following stage defined in Jenkins pipeline DSL:

config.xml: SonarQube inspection

stage(&#x27;SonarQube analysis&#x27;) { (1)
withSonarQubeEnv(&#x27;Sonar&#x27;) { (2)
sh &#x27;mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.3.0.603:sonar &#x27; + (3)
&#x27;-f all/pom.xml &#x27; +
          &#x27;-Dsonar.projectKey=com.huettermann:all:master &#x27; +
          &#x27;-Dsonar.login=$SONAR_UN &#x27; +
          &#x27;-Dsonar.password=$SONAR_PW &#x27; +
          &#x27;-Dsonar.language=java &#x27; +
          &#x27;-Dsonar.sources=. &#x27; +
          &#x27;-Dsonar.tests=. &#x27; +
          &#x27;-Dsonar.test.inclusions=**/*Test*/** &#x27; +
          &#x27;-Dsonar.exclusions=**/*Test*/**&#x27;
        }
    }

1
The dedicated stage for running the SonarQube analysis.

2
Allow to select the SonarQube server you want to interact with.

3
Running and configuring the scanner, many options available, check the docs.

Many options are available to integrate and configure SonarQube. Please consult the documentation for alternatives. Same applies to the other covered tools.

SonarQube Quality Gate

As part of a Jenkins pipeline stage, SonarQube is configured to run and inspect the code. But this is just the first part,
because we now also want to add the quality gate in order to break the build. The next stage is covering exactly that, see
next snippet. The pipeline is paused until the quality gate is computed, specifically the waitForQualityGate step will pause the
pipeline until SonarQube analysis is completed and returns the quality gate status. In case a quality gate was missed, the build breaks.

config.xml: SonarQube Quality Gate

stage(&quot;SonarQube Quality Gate&quot;) { (1)
timeout(time: 1, unit: &#x27;HOURS&#x27;) { (2)
def qg = waitForQualityGate() (3)
if (qg.status != &#x27;OK&#x27;) {
             error &quot;Pipeline aborted due to quality gate failure: ${qg.status}&quot;
           }
        }
    }

1
The defined quality gate stage.

2
A timeout to define when to proceed without waiting for any results for ever.

3
Here we wait for the OK. Underlying implementation is done with SonarQube’s webhooks feature.

This blog post is an appetizer, and scripts are excerpts. For more information, please consult the respective documentation, or a good book, or the great community, or ask your local expert.

Since they all work in a wonderful Agile team, the next available colleague just promptly fixes the issue. After checking in
the fixed code, the build pipeline runs again.

The pipeline was processed successfully, including the SonarQube quality gate, and as the final step, the packaged and tested artifact was
deployed to Artifactory. There are a couple of different flexible ways how to upload the artifacts,
the one we use here is using an upload spec to actually collect and upload the artifact which was built at the very beginning of the pipeline.
Also meta information are published to Artifactory, since it is the context which matters and thus we can add valuable labels to the artifact for further processing.

config.xml: Upload to Artifactory

stage (&#x27;Distribute binaries&#x27;) { (1)
def SERVER_ID = &#x27;4711&#x27; (2)
def server = Artifactory.server SERVER_ID
    def uploadSpec = (3)&quot;&quot;&quot;
    {
    &quot;files&quot;: [
        {
            &quot;pattern&quot;: &quot;all/target/all-(*).war&quot;,
            &quot;target&quot;: &quot;libs-snapshots-local/com/huettermann/web/{1}/&quot;
        }
      ]
    }
    &quot;&quot;&quot;
    def buildInfo = Artifactory.newBuildInfo() (4)
buildInfo.env.capture = true (5)
buildInfo=server.upload(uploadSpec) (6)
server.publishBuildInfo(buildInfo) (7)
}

1
The stage responsible for uploading the binary.

2
The server can be defined Jenkins wide, or as part of the build step, as done here.

3
In the upload spec, in JSON format, we define what to deploy to which target, in a fine-grained way.

4
The build info contains meta information attached to the artifact.

5
We want to capture environmental data.

6
Upload of artifact, according to upload spec.

7
Build info are published as well.

Now let’s see check that the binary was deployed to Artifactory, successfully. As part of the context information, also a reference to the
producing Jenkins build job is available for better traceability.

Summary

In this blog post, we’ve discovered tips and tricks to integrate Jenkins with SonarQube, how to define
Jenkins stages with the Jenkins pipeline DSL, how those stages are visualized with Jenkins Blue Ocean, and how the artifact
was deployed to our binary repository manager Artifactory.
Now I wish you a lot of further fun with your great tools of choice to implement your Continuous Delivery pipelines.

References

Jenkins 2

Sonarqube

Sonarqube Jenkins plugin

Artifactory

Jenkins Artifactory plugin

&#x27;DevOps for Developers&#x27;, Apress, 2012

&#x27;Agile ALM&#x27;, Manning, 2011<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelhuettermann/">Michael Hüttermann</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/quality">quality</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/sonarqube">sonarqube</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/artifactory">artifactory</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/20/secure-jenkins-on-azure/"><div class="header"><div class="date"><div class="month">April</div><div class="day">20</div></div><h5 class="title">Securing a Jenkins instance on Azure</h5></div><p class="teaser">This is a guest post by Claudiu Guiman and Eric Jizba,
Software Engineers in the Azure DevOps team at Microsoft. If you have any questions, please email us at azdevopspub@microsoft.com.

One of the most frequently asked questions for managing a Jenkins instance is
&quot;How do I make it secure?&quot; Like any other web application, these issues must be
solved:

How do I securely pass secrets between the browser and the server?

How do I hide certain parts from unauthorized users and show other parts to anonymous users?

This blog post details how to securely connect to a Jenkins instance and how to
setup a read-only public dashboard.  We’ll cover topics like: setting up a
reverse proxy, blocking inbound requests to certain URLs and ports, enabling
project-based authorization, and making the Jenkins agents accessible through
the JNLP protocol.

Deploy Jenkins

The simplest way to deploy a secure Jenkins instance is by using the Azure Marketplace offer. If you have an existing Jenkins instance or want to setup your instance manually, follow the steps below.

Securely log in to Jenkins

After you’ve deployed your new virtual machine with a hosted Jenkins instance, you will notice that by default the instance listens on port 8080 using &#x27;HTTP&#x27;. If you want to set up &#x27;HTTPS&#x27; communication, you will need to provide an SSL certificate. Unfortunately, most certificate authorities are not cheap and other free services like Let’s Encrypt have a very small quota (about 20 certificates per week for the entire &#x27;azure.com&#x27; subdomain). The only other option is to use a self-signed certificate, but then users must explicitly verify and mark your certificate as trusted, which is not recommended.

If you do not setup &#x27;HTTPS&#x27; communication, the best way to make sure the sign-in credentials are not leaked due to a Man-in-the-middle attack is to only log in using SSH tunneling.
An SSH tunnel is an encrypted tunnel created through an SSH protocol connection, which can be used to transfer unencrypted traffic over an unsecured network. Simply run this command:

Linux or Mac

ssh -L 8080:localhost:8080 @

Windows ( using PuTTY)

putty.exe -ssh -L 8080:localhost:8080 @

This command will open an SSH connection to your remote host and bind remote port 8080 to listen to requests coming from your local machine. Navigate to http://localhost:8080 on your local machine to view your Jenkins dashboard and you’ll be able to log in securely.

Setup a reverse proxy

Now that you can securely log in to your Jenkins instance, you should prevent people from accidentally authenticating through the public (unsecured) interface. To achieve this, you can setup a reverse proxy on the Jenkins hosting machine that will listen on a different port (80 is the best candidate) and redirect only certain requests to port 8080.

Specifically, it is recommended to block the login and the CLI requests. Some CLI versions fall back to unsecure HTTP connections if they have problems establishing the secured connection. In most cases, users don’t need the CLI and it should be enabled on an as-needed basis.

Install Nginx:

sudo apt-get update
sudo apt-get install nginx

Open the Nginx config file:

sudo nano /etc/nginx/sites-enabled/default

Modify the file to configure Nginx to work as a reverse proxy (you’ll need to update):

server {
    listen 80;
    server_name;
    # Uncomment the line bellow to change the default 403 error page
    # error_page 403 /secure-jenkins;
    location / {
        proxy_set_header        Host \$host:\$server_port;
        proxy_set_header        X-Real-IP \$remote_addr;
        proxy_set_header        X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header        X-Forwarded-Proto \$scheme;
        proxy_pass              http://localhost:8080;
        proxy_redirect          http://localhost:8080 http://;
        proxy_read_timeout      90;
    }
    #block requests to /cli
    location /cli {
        deny all;
    }
    #block requests to /login
    location ~ /login* {
        deny all;
    }
    # Uncomment the lines bellow to redirect /secure-jenkins
    #location /secure-jenkins {
    #  alias /usr/share/nginx/secure-jenkins;
    #}
}

The first section tells the Nginx server to listen to any requests that come from port 80. It also contains a commented redirect of the 403 error to a custom location (we’ll get back to this later).

listen 80;
    server_name;
    # error_page 403 /secure-jenkins;

The next section describes the reverse proxy configuration. This tells the Nginx server to take all incoming requests and proxy them to the Jenkins instance that is listening to port 8080 on the local network interface.

location / {
        proxy_set_header        Host \$host:\$server_port;
        proxy_set_header        X-Real-IP \$remote_addr;
        proxy_set_header        X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header        X-Forwarded-Proto \$scheme;
        proxy_pass              http://localhost:8080;
        proxy_redirect          http://localhost:8080 http://;
        proxy_read_timeout      90;
    }

The last section filters out specific URLs (login, cli) and denies access to them.

location /cli {
        deny all;
    }
    location ~ /login* {
        deny all;
    }

Restart Nginx:

sudo service nginx restart

Go to http:// and verify you can access your Jenkins instance.

Verify clicking &#x27;login&#x27; returns a &#x27;403 Forbidden&#x27; page. If you want to customize that page, update the Nginx configuration and remove the comments around /secure-jenkins. This will redirect all 403 errors to the file /usr/share/nginx/secure-jenkins. You can add any content to that file, for example:

sudo mkdir /usr/share/nginx/secure-jenkins
echo &quot;Access denied! Use SSH tunneling to log in to your Jenkins instance!&quot; | sudo tee /usr/share/nginx/secure-jenkins/index.html

If restart fails or you cannot access your instance, check the error log: cat /var/log/nginx/error.log

Secure your Jenkins dashboard

If you go to http:// :8080 you’ll notice you can still
bypass the reverse proxy and access the Jenkins instance directly through an
unsecure channel. You can easily block all inbound requests on port 8080 on
Azure with a
Network
Security Group (NSG).

Create the NSG and add it to your existing network interface or to the subnet your Azure Virtual Machine is bound to.

Add 2 inbound security rules:

Allow requests to port 22 so you can SSH into the machine.

Allow requests to port 80 so the reverse proxy can be reached

By default, all other external traffic will be blocked

Navigate to http:// :8080 and verify you cannot connect.

If you don’t want to deploy an Azure Network Security Group, you can block port 8080 using the Uncomplicated Firewall (ufw)

Configure read-only access to your dashboard

After installing Jenkins, the default security strategy is &#x27;Logged-in users can do anything&#x27;. If you want to allow read-only access to anonymous users, you need to set up Matrix-based security. In this example, we’ll set up a project-based authorization matrix, so that you can make certain projects private and others public.

Install the Matrix Authorization Strategy Plugin and restart Jenkins.

Go to http://localhost:8080/configureSecurity/ (&#x27;Configure Global Security&#x27; page under &#x27;Manage Jenkins&#x27;) and select &#x27;Project-base Matrix Authorization Strategy&#x27; from the &#x27;Authorization&#x27; options.

As an example, you can grant read-only access to anonymous users (Overall/Read, Job/Discover and Job/Read should be enough) and grant all logged in users full access in a  group called &#x27;authenticated&#x27;:

Connect JNLP-based agents

Since your Jenkins instance is only accessible through the reverse proxy on port 80, any Jenkins agents that use the JNLP protocol will not be able to register to the controller anymore. To overcome this problem, all agents must be in the same virtual network as the Jenkins controller and must connect using their private IP (by default, the NSG allows all internal traffic).

Make sure that the Jenkins virtual machine will always be assigned the same private IP by going to the Azure Portal, opening the Network Interface of your virtual machine, opening &#x27;IP configuration&#x27;, and clicking on the configuration.

Make sure the Private IP has a static assignment and restart the virtual machine if necessary.

Copy the static IP Address and go to http://localhost:8080/configure (&#x27;Configure System&#x27; page under &#x27;Manage Jenkins&#x27;) and update the &#x27;Jenkins URL&#x27; to point to that private IP ( https://10.0.0.5:8080/ in this example)

Now agents can communicate through JNLP. If you want to streamline the process,
you can use the
Azure VM Agents plugin,
which automatically deploys agents in the same virtual network
and connects them to the controller.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/clguiman/">Claudiu Guiman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud">cloud</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/26/security-advisory/"><div class="header"><div class="date"><div class="month">April</div><div class="day">26</div></div><h5 class="title">Important security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.57 and 2.46.2, that fix several security vulnerabilities, including a critical one.

That critical vulnerability is an unauthenticated remote code execution via the remoting-based CLI.
When I announced the fix for the previous vulnerability of this kind, I announced our plans to revisit the design of the CLI that enabled this class of vulnerabilities.

Since Jenkins 2.54, we now have a new CLI implementation that isn’t based on remoting, and deprecated its remoting mode.
Despite it being a major feature, we decided to backport it to 2.46.2, so LTS users can also disable the unsafe remoting mode while retaining almost all of the CLI’s existing functionality.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.
I recommend you read these documents, especially if you’re using the CLI with Jenkins LTS, as there are possible side effects of these fixes.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/27/colombia/"><div class="header"><div class="date"><div class="month">April</div><div class="day">27</div></div><h5 class="title">Calling for Colombian Jenkins users!</h5></div><p class="teaser">The Jenkins project has learned that a company is trying to register &quot;Jenkins&quot; as a trademark in Colombia. This is alarming for us, and we are trying to oppose it. In order to do this effectively, we need to hear from Colombian users of Jenkins.

Figure 1. South American visitors to jenkins.io for 2017

The Jenkins project owns a trademark &quot;Jenkins&quot; in the U.S., through a non-profit entity SPI Inc. According to experts on the subject citing the &quot;Washington Convention&quot;, our trademark registration in the U.S. does give us some strength in the argument to oppose this. To successfully mount this argument however, we need to be able to show that Jenkins has significant usage and awareness in Colombia. Users, installations, meetups, conference talks, anything of that nature will help.

Those of you with the project for a long time might recall that the name &quot;Jenkins&quot; was born because of a trademark issue with Oracle. So we are particularly sensitive to the issue is trademarks. We want to make sure the same tragedy won’t happen again.

If you know anything about the usage and the name recognition of Jenkins in Colombia, please let us know by submitting the information here . We know that Jenkins is popular in Colombia, because our website traffic shows that Colombian Jenkins users are the third most frequent visitors to jenkins.io in South America after Brazil and Argentina.

This information will be only shared with the Jenkins project board and those involved in the defense, and for the sole purpose of defending the trademark and nothing more.

Please help us spread the word. Thanks!

El proyecto Jenkins se ha enterado de que una compañía está intentando registrar &quot;Jenkins&quot; como marca registrada en Colombia. Esto es alarmante y estamos tratando de oponernos. Para hacerlo de manera efectiva, necesitamos escuchar a los usuarios colombianos de Jenkins.

El proyecto Jenkins posee una marca registrada &quot;Jenkins&quot; en los Estados Unidos, a través de una entidad sin ánimo de lucro SPI Inc. Según los expertos en la materia citando la &quot;Convención de Washington&quot;, nuestro registro de marca en los EE.UU. nos da algo de fuerza para oponernos. Sin embargo, para argumentar con éxito, tenemos que ser capaces de demostrar que Jenkins tiene un uso significativo y es conocido en Colombia. Usuarios, instalaciones, encuentros, conferencias, cualquier cosa de ese tipo ayudará.

Aquellos que llevan mucho tiempo con el proyecto pueden recordar que el nombre &quot;Jenkins&quot; nació debido a un problema de marca con Oracle. Por lo tanto, estamos especialmente sensibles al tema de las marcas registradas. Queremos asegurarnos de que el mismo problema no vuelva a ocurrir.

Si sabe algo sobre el uso y el reconocimiento del nombre Jenkins en Colombia, por favor háganoslo saber enviando la información aquí . Sabemos que Jenkins es popular en Colombia, porque nuestro sitio web de tráfico muestra que los usuarios colombianos de Jenkins son los terceros visitantes más frecuentes a jenkins.io en América del Sur después de Brasil y Argentina.

Esta información sólo se compartirá con el comité de proyecto de Jenkins y los involucrados en la defensa, y con el único propósito de defender la marca y nada más.

Por favor, ayúdenos a difundir la palabra. ¡Gracias!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/feedback">feedback</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/05/03/jenkinsworld-2017-awards/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 3</div></div><h5 class="title">Jenkins World 2017 Community Awards - Open for Nominations!</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

This year at Jenkins World 2017,
the Jenkins community will celebrate the Most Valuable Contributor, a Jenkins
Security MVP, and the Most Valuable Advocate.

This will be the first year we are commemorating community members who have
shown excellence through commitment, creative thinking, and contributions to
continue making Jenkins a great open source automation server. Special thanks
to CloudBees for the generous donations to make
this program possible.

With that said, the Jenkins
Community Award nomination is currently open. Nominate your story, or that
of a fellow contributor, for recognition at Jenkins World. Ee sure to join us at
Jenkins World 2017 in San
Francisco on August 28-31 to hear the winners announced.

Nominations will be accepted until June 16, 2017.
Nominate someone
today!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/05/15/kubernetes-journey-on-azure/"><div class="header"><div class="date"><div class="month">May</div><div class="day">15</div></div><h5 class="title">A journey to Kubernetes on Azure</h5></div><p class="teaser">With the
ongoing migration to Azure,
I would like to share my thoughts regarding one of the biggest challenges we
have faced thus far: orchestrating container infrastructure. Many of the
Jenkins project’s applications are run as Docker containers, making Kubernetes
a logical choice as far as running our containers, but it presents its own set
of challenges. For example, what would the workflow from development to
production look like?

Before going deeper into the challenges, let’s review the requirements we
started with:

Git

We found it mandatory to keep track of all the infrastructure changes in Git
repositories, including secrets, in order to facilitate reviewing,
validation, rollback, etc of all infra changes.

Tests

Infrastructure contributors are geographically distributed and in different
timezones.  Getting feedback can take time, so we heavily rely on a lot of
tests before any changes can be merged.

Automation

The change submitter is not necessarily the person who will deploy it.
Repetitive tasks are error prone and a waste of time.
For these reasons, all steps must be automated and stay as simple as possible.

A high level overview of our &quot;infrastructure as code&quot; workflow would look like:

Infrastructure as Code Workflow

__________       _________       ______________
  |         |      |        |      |             |
  | Changes | ----&gt;|  Test  |-----&gt;| Deployment  |
  |_________|      |________|  ^   |_____________|
                               |
                        ______________
                       |             |
                       | Validation  |
                       |_____________|

We identified two possible approaches for implementing our container
orchestration with Kubernetes:

The Jenkins Way: Jenkins is triggered by a Git commit, runs the tests, and
after validation, Jenkins deploys changes into production.

The Puppet Way: Jenkins is triggered by a Git commit, runs the tests, and
after validation, it triggers Puppet to deploy into production.

Let’s discuss these two approaches in detail.

The Jenkins Way

Workflow

_________________       ____________________       ______________
  |                |      |                   |      |             |
  |    Github:     |      |     Jenkins:      |      |   Jenkins:  |
  | Commit trigger | ----&gt;| Test &amp; Validation | ----&gt;|  Deployment |
  |________________|      |___________________|      |_____________|

In this approach, Jenkins is used to test, validate, and deploy our Kubernetes
configuration files. kubectl can be run on a directory and is idempotent.
This means that we can run it as often as we want: the result will not change.
Theoretically, this is the simplest way. The only thing needed is to run
kubectl command each time Jenkins detects changes.

The following Jenkinsfile gives an example of this workflow.

Jenkinsfile

pipeline {
    agent any
    stages {
      stage(&#x27;Init&#x27;){
        steps {
          sh &#x27;curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl&#x27;
        }
      }
      stage(&#x27;Test&#x27;){
        steps {
          sh &#x27;Run tests&#x27;
        }
      }
      stage(&#x27;Deploy&#x27;){
        steps {
          sh &#x27;./kubectl apply -R true -f my_project&#x27;
        }
      }
    }
  }

The devil is in the details of course, and it was not as easy as it looked at
first sight.

Order matters

Some resources needed to be deployed before others. A workaround was to use
numbers as file names. But this added extra logic at file name level, for
example:

project/00-nginx-ingress
project/09-www.jenkins.io

Portability

The deployment environments needed to be the same across development machines
and the Jenkins host. Although this a well-known problem, it was not easy to
solve.  The more the project grew, the more our scripts needed additional tools
( make, bats, jq gpg, etc).  The more tools we used, the more issues
appeared because of the different versions used.

Another challenge that emerged when dealing with different environments was:
how should we manage environment-specific configurations (dev, prod, etc)?
Would it be better to define different configuration files per environment?
Perhaps, but this means code duplication, or using file templates which would require
more tools ( sed, jinja2, erb), and more work.

There wasn’t a golden rule we discovered, and the answer is probably somewhere in between.

In any case, the good news is that a Jenkinsfile provides an easy way to
execute tasks from a Docker image, and an image can contain all the necessary
tools in our environment. We can even use different Docker images for each
stage along the way.

In the following example, I use the my_env Docker image. It contains all the
tools needed to test, validate, and deploy changes.

Jenkinsfile

pipeline{
  agent {
    docker{
      image &#x27;my_env:1.0&#x27;
    }
  }
  options{
    buildDiscarder(logRotator(numToKeepStr: &#x27;10&#x27;))
    disableConcurrentBuilds()
    timeout(time: 1, unit: &#x27;HOURS&#x27;)
  }
  triggers{
    pollSCM(&#x27;* * * * *&#x27;)
  }
  stages{
    stage(&#x27;Init&#x27;){
      steps{
        // Init everything required to deploy our infra
        sh &#x27;make init&#x27;
      }
    }
    stage(&#x27;Test&#x27;){
      steps{
       // Run tests to validate changes
       sh &#x27;make test&#x27;
      }
    }
    stage(&#x27;Deploy&#x27;){
      steps{
       // Deploy changes in production
       sh &#x27;make deploy&#x27;
      }
    }
  }
  post{
    always {
      sh &#x27;make notify&#x27;
    }
  }
}

Secret credentials

Managing secrets is a big subject and brings with it many different
requirements which are very hard to fulfill.  For obvious reasons, we couldn’t
publish the credentials used within the infra project.  On the other hand, we
needed to keep track and share them, particularly for the Jenkins node that
deploys our cluster.  This means that we needed a way to encrypt or decrypt
those credentials depending on permissions, environments, etc.  We analyzed two
different approaches to handle this:

Storing secrets in a key management tool like Key Vault or Vault and use them like a Kubernetes &quot;secret&quot; type of resource.
→ Unfortunately, these tools are not yet integrated in Kubernetes. But we may come back to this option later.
Kubernetes issue: 10439

Publishing and encrypting using a public GPG key.
This means that everybody can encrypt credentials for the infrastructure project but only the owner of the private key can decrypt credentials.
This solution implies:

Scripting: as secrets need to be decrypted at deployment time.

Templates: as secret values will change depending on the environment.
→ Each Jenkins node should only have the private key to decrypt secrets associated to its environment.

Scripting

Finally, the system we had built was hard to work with.  Our initial
Jenkinsfile which only ran one kubectl command slowly become a bunch of
scripts to accommodate for:

Resources needing to be updated only in some situations.

Secrets needing to be encrypted/decrypted.

Tests needing to be run.

In the end, the amount of scripts required to deploy the Kubernetes resources
started to become unwieldy and we began asking ourselves: &quot;aren’t we
re-inventing the wheel?&quot;

The Puppet Way

The Jenkins project already uses Puppet, so we decided to look at using Puppet
to orchestrate our container deployment with Kubernetes.

Workflow

_________________       ____________________       _____________
  |                |      |                   |      |            |
  |    Github:     |      |     Jenkins:      |      | Puppet:    |
  | Commit trigger | ----&gt;| Test &amp; Validation | ----&gt;| Deployment |
  |________________|      |___________________|      |____________|

In this workflow, Puppet is used to template and deploy all Kubernetes
configurations files needed to orchestrate our cluster.
Puppet is also used to automate basic kubectl operations such as &#x27;apply&#x27; or
&#x27;remove&#x27; for various resources based on file changes.

Puppet workflow

______________________
|                     |
|  Puppet Code:       |
|    .                |
|    ├── apply.pp     |
|    ├── kubectl.pp   |
|    ├── params.pp    |
|    └── resources    |
|        ├── lego.pp  |
|        └── nginx.pp |
|_____________________|
          |                                        _________________________________
          |                                       |                                |
          |                                       |  Host: Prod orchestrator       |
          |                                       |    /home/k8s/                  |
          |                                       |    .                           |
          |                                       |    └── resources               |
          | Puppet generate workspace             |        ├── lego                |
          └--------------------------------------&gt;|        │   ├── configmap.yaml  |
            Puppet apply workspaces&#x27; resources on |        │   ├── deployment.yaml |
          ----------------------------------------|        │   └── namespace.yaml  |
          |                                       |        └── nginx               |
          v                                       |            ├── deployment.yaml |
 ______________                                   |            ├── namespace.yaml  |
 |     Azure:  |                                  |            └── service.yaml    |
 | K8s Cluster |                                  |________________________________|
 |_____________|

The main benefit of this approach is letting Puppet manage the environment and run
common tasks. In the following example, we define a Puppet class for Datadog.

Puppet class for resource Datadog

# Deploy datadog resources on kubernetes cluster
#   Class: profile::kubernetes::resources::datadog
#
#   This class deploy a datadog agent on each kubernetes node
#
#   Parameters:
#     $apiKey:
#       Contain datadog api key.
#       Used in secret template
class profile::kubernetes::resources::datadog (
    $apiKey = base64(&#x27;encode&#x27;, $::datadog_agent::api_key, &#x27;strict&#x27;)
  ){
  include ::stdlib
  include profile::kubernetes::params
  require profile::kubernetes::kubectl

  file { &quot;${profile::kubernetes::params::resources}/datadog&quot;:
    ensure =&gt; &#x27;directory&#x27;,
    owner  =&gt; $profile::kubernetes::params::user,
  }

  profile::kubernetes::apply { &#x27;datadog/secret.yaml&#x27;:
    parameters =&gt; {
        &#x27;apiKey&#x27; =&gt; $apiKey
    },
  }
  profile::kubernetes::apply { &#x27;datadog/daemonset.yaml&#x27;:}
  profile::kubernetes::apply { &#x27;datadog/deployment.yaml&#x27;:}

  # As secrets change do not trigger pods update,
  # we must reload pods &#x27;manually&#x27; in order to use updated secrets.
  # If we delete a pod defined by a daemonset,
  # this daemonset will recreate pods automatically.
  exec { &#x27;Reload datadog pods&#x27;:
    path        =&gt; [&quot;${profile::kubernetes::params::bin}/&quot;],
    command     =&gt; &#x27;kubectl delete pods -l app=datadog&#x27;,
    refreshonly =&gt; true,
    environment =&gt; [&quot;KUBECONFIG=${profile::kubernetes::params::home}/.kube/config&quot;] ,
    logoutput   =&gt; true,
    subscribe   =&gt; [
      Exec[&#x27;apply datadog/secret.yaml&#x27;],
      Exec[&#x27;apply datadog/daemonset.yaml&#x27;],
    ],
  }
}

→
More &quot;resources&quot; examples

Let’s compare the Puppet way with the challenges discovered with the Jenkins
way.

Order Matters

With Puppet, it becomes easier to define priorities as
Puppet provides relationship meta parameters and the function &#x27;require&#x27; (see
also:
Puppet
relationships).

In our Datadog example, we can be sure that deployment will respect the following order:

datadog/secret.yaml -&gt; datadog/daemonset.yaml -&gt; datadog/deployment.yaml

Currently, our Puppet code only applies configuration when it detects file
changes.  It would be better to compare local files with the cluster
configuration in order to trigger the required updates, but we haven’t found a
good way to implement this yet.

Portability

As Puppet is used to configure working environments, it becomes easier to be
sure that all tools are present and correctly configured.  It’s also easier to
replicate environments and run tests on them with tools like
RSpec-puppet, Serverspec or
Vagrant.

In our Datadog example, we can also easily change the Datadog API key depending
on the environment with Hiera.

Secret credentials

As we were already using Hiera GPG
with Puppet, we decided to continue to use it, making managing secrets for
containers very simple.

Scripting

Of course the Puppet DSL is used, and even if it seems harder at the beginning,
Puppet simplifies a lot the management of Kubernetes configuration files.

Conclusion

It was much easier to bootstrap the project with a full CI workflow within
Jenkins as long as the Kubernetes project itself stays basic. But as soon as
the project grew, and we started deploying different applications with
different configurations per environment, it became easier to delegate
Kubernetes management to Puppet.

If you have any comments feel free to send a message to
Jenkins Infra mailing list.

Thanks

Thanks to Lindsay Vanheyste, Jean Marc Meessen, and Damien Duportal for their feedback.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/puppet">puppet</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/05/18/pipeline-dev-tools/"><div class="header"><div class="date"><div class="month">May</div><div class="day">18</div></div><h5 class="title">Pipeline Development Tools</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

I’ve only been working with Pipeline for about a year.
Pipeline in and of itself has been a huge improvement over old-style Jenkins projects.
As a developer, it has been so great be able work with Jenkins Pipelines
using the same tools I use for writing any other kind of code.

I’ve also found a number of tools that are super helpful specifically
for developing pipelines. Some were easy to find like the
built-in documentation
and the
Snippet Generator.
Others were not as obvious or were only recently released.
In this post, I’ll show how a few of those tools make working with Pipelines
even better.

The Blue Ocean Pipeline Editor

The best way to start this list is with the most recent and coolest
arrival in this space: the Blue Ocean Pipeline Editor.  The editor only works
with Declarative Pipelines, but it brings a sleek new user experience to writing
Pipelines.  My recent screencast, released as part of the Blue Ocean Launch,
gives good sense of how useful the editor is:

Command-line Pipeline Linter

One of the neat features of the Blue Ocean Pipeline Editor is that it does basic
validation on our Declarative Pipelines before they are even committed or Run.
This feature is based on the
Declarative Pipeline Linter
which can be accessed from the command-line even if you don’t have Blue Ocean
installed.

When I was working on the
Declarative Pipeline: Publishing HTML Reports
blog post, I was still learning the declarative syntax and I made a lot lot of mistakes.
Getting quick feedback about the whether my Pipeline was in a sane state made writing that blog much easier.
I wrote a simple shell script that would run my Jenkinsfile through the Declarative Pipeline Linter.

pipelint.sh - Linting via HTTP POST using curl

# curl (REST API)
# User
JENKINS_USER=bitwisenote-jenkins1

# Api key from &quot;/me/configure&quot; on my Jenkins instance
JENKINS_USER_KEY=--my secret, get your own--

# Url for my local Jenkins instance.
JENKINS_URL=http://$JENKINS_USER:$JENKINS_USER_KEY@localhost:32769 (1)

# JENKINS_CRUMB is needed if your Jenkins controller has CRSF protection enabled (which it should)
JENKINS_CRUMB=`curl &quot;$JENKINS_URL/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\&quot;:\&quot;,//crumb)&quot;`
curl -X POST -H $JENKINS_CRUMB -F &quot;jenkinsfile=

1
This is not secure.  I’m running this locally only.
See Jenkins CLI for details on how to do this securely.

With this script, I was able to find the error in this this Pipeline without
having to take the time to run it in Jenkins: (Can you spot the mistake?)

#!groovy

pipeline {
  agent any

  options {
    // Only keep the 10 most recent builds
    buildDiscarder(logRotator(numToKeepStr:&#x27;10&#x27;))
  }
  stages {
    stage (&#x27;Install&#x27;) {
      steps {
        // install required bundles
        sh &#x27;bundle install&#x27;
      }
    }
    stage (&#x27;Build&#x27;) {
      steps {
        // build
        sh &#x27;bundle exec rake build&#x27;
      }

      post {
        success {
          // Archive the built artifacts
          archive includes: &#x27;pkg/*.gem&#x27;
        }
      }
    }
    stage (&#x27;Test&#x27;) {
      step {
        // run tests with coverage
        sh &#x27;bundle exec rake spec&#x27;
      }

      post {
        success {
          // publish html
          publishHTML target: [
              allowMissing: false,
              alwaysLinkToLastBuild: false,
              keepAll: true,
              reportDir: &#x27;coverage&#x27;,
              reportFiles: &#x27;index.html&#x27;,
              reportName: &#x27;RCov Report&#x27;
            ]
        }
      }
    }
  }
  post {
    always {
      echo &quot;Send notifications for result: ${currentBuild.result}&quot;
    }
  }
}

When I ran my pipelint.sh script on this pipeline it reported this error:

$ pipelint.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    46  100    46    0     0   3831      0 --:--:-- --:--:-- --:--:--  4181
Errors encountered validating Jenkinsfile:
WorkflowScript: 30: Unknown stage section &quot;step&quot;. Starting with version 0.5, steps in a stage must be in a steps block. @ line 30, column 5.
       stage (&#x27;Test&#x27;) {
       ^

WorkflowScript: 30: Nothing to execute within stage &quot;Test&quot; @ line 34, column 5.
       stage (&#x27;Test&#x27;) {
       ^

Doh. I forgot the &quot;s&quot; on steps on line 35. Once I added the &quot;s&quot; and ran
pipelint.sh again, I got an all clear.

$ pipelint.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    46  100    46    0     0   5610      0 --:--:-- --:--:-- --:--:--  5750
Jenkinsfile successfully validated.

This didn’t mean there weren’t other errors, but for a two second smoke test I’ll take it.

Replay

I love being able to use source control to track changes to my Pipelines
right alongside the rest of the code in a project.  There are also times,
when prototyping or debugging, that I need to iterate quickly on a series
of possible Pipeline changes.
The Replay feature let’s me do that and see the results,
without committing those changes to source control.

When I wanted to take the previous Pipeline from agent any to using Docker via
the docker { …​ } directive, I used the Replay feature to test it out:

Selected the previously completed run in the build history

Clicked &quot;Replay&quot; in the left menu

Made modifications and click &quot;Run&quot;. In this example, I replaced any with the docker { …​ } directive.

Checked the results of changes looked good.

Once I worked any bugs out of my Pipeline,
I used Replay to view the Pipeline for the last run and copy it back to my
Jenkinsfile and create a commit for that change.

Conclusion

This is far from a complete list of the tools out there for working with Pipeline.
There are many more and the number is growing.
For example, one tool  I just recently heard about and haven’t had a chance to delve into
is the
Pipeline Unit Testing Framework,
which promises the ability to test Pipelines before running them.
It’s been a fun year and I can’t wait to see what the next year holds for Pipeline.

How do you work with Pipeline?
Do you have a tool that you feel has greatly improved your development experience
with Pipeline?  I’m interested in hear about others Jenkins user’s favorite ways
of working with Pipeline.  Drop me a line via
email or on the
#jenkins IRC channel.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/06/13/blueocean-1-1/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">13</div></div><h5 class="title">Blue Ocean 1.1 - fast search for pipelines and much more</h5></div><p class="teaser">The Blue Ocean team are proud to announce the release of Blue Ocean 1.1.
 We’ve shipped a tonne of small improvements, features and bug fixes here that
 will make your day-to-day experience with Blue Ocean even smoother.

Today is also the first time we are promoting
our Public Roadmap.
We recognise that using JIRA can be a bit of a pain to track what we are working
 on at a macro level and the Public Roadmap makes it very easy for anyone to
 find out what we are working on. We’ve got some really cool stuff coming,
 so check back here soon!

It’s been an insane two months since the launch of Blue Ocean 1.0 and there
 are now officially over 10,000 teams using Blue Ocean  – so here’s a big
 “thank you” to all of you for your support.

Now, lets get to the goods!

Fast search

For those of you who have many pipelines we’ve introduced pipeline fast search
to the pipeline dashboard. Click the search icon to activate and just start
typing what you’re looking for.

Trigger reasons

Differentiate at a glance between pipeline runs that have been manually
triggered and by who, triggered automatically by a commit or triggered by any
other means.

Blockage reasons

Pipelines can be blocked from execution for a variety of reasons, including
waiting for executors or other resources to become free. You can see from the
Pipeline Activity, Branch and Result screen why the pipeline is blocked from
execution.

History jump

Developers can quickly jump from the branches tab to the run history for a
specific branch. This makes it more convenient to see historical runs for the
branch within the Pipeline which improves the your ability to trace down
problems.

Analyse 1,000s of tests

Now you can see more than 100 test results for a Pipeline run. This makes
Blue Ocean practical for teams who have invested heavily in testing.
We’ve also dramatically improved loading times for Pipelines with large
numbers of tests so theres no more waiting for the test tab to load.

Custom run names and descriptions

Developers authoring Pipeline using the scripted syntax can set a custom name
and description for Pipeline run. This feature is commonly used to name or
describe a pipeline run that is meaningful in their release management workflow.

For example, a developer can set the run name to the release version
1.1 and the description to something meaningful, like Final Release.

currentBuild.displayName = &#x27;1.1&#x27;
currentBuild.description = ‘Final Release’

Performance

We’ve been making optimisations for general page speed.
In Blue Ocean 1.1, plugin data was automatically sent to browser and we’ve made
a change so that this data is only sent on the request of plugins. The long and
short of it is that you shouldn’t notice a thing except those Blue Ocean pages
zipping faster into your browser.

48+ bug fixes

There have been a total of 48 bug improvements, with emphasis on how executing
pipelines behave, and we’ve  invested a large amount of time to improve
automated test coverage of Blue Ocean to ensure reliability in
production settings.

For a full list of bug fixes and improvements,
see the JIRA.

What are you waiting for? Try Blue Ocean 1.1 today<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/i386/">James Dumay</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/06/14/jenkinsworld-awards-lastcall/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">14</div></div><h5 class="title">Jenkins World 2017 Community Awards - Last Call for Nominations!</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

We have received a good number of nominations for the Jenkins World 2017 Community Awards. These nominations are indicative of the excellent work Jenkins members are doing for the betterment of Jenkins.

The deadline for nomination is this Friday, June 16.

This will be the first year we are commemorating community members who have
shown excellence through commitment, creative thinking, and contributions to
continue making Jenkins a great open source automation server. The award
categories includes:

Most Valuable Contributor -
This award is presented to the Jenkins contributor who has helped move the Jenkins project forward the most through their invaluable feature contributions, bug fixes or plugin development efforts.

Jenkins Security MVP -
This award is presented to the individual most consistently providing excellent security reports or who helped secure Jenkins by fixing security issues.

Most Valuable Advocate -
This award is presented to an individual who has helped advocate for Jenkins through organization of their local Jenkins Area Meetup.

Submit your story, or nominate someone today! Winners will be announced at Jenkins World 2017 in San Francisco on August 28-31.

We look forward to hearing about the great Jenkins work you are doing.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/06/26/share-jenkins-world-keynote-stage/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">26</div></div><h5 class="title">Come Share the Jenkins World Keynote Stage with Me!</h5></div><p class="teaser">Jenkins World is approaching fast,
and the event staff are all busy preparing.
I’ve decided to do something different this year as part of my keynote:
I want to invite a few Jenkins users like you come up on stage with me.

There have been amazing developments in Jenkins over the past year.
For my keynote, I want highlight how the new Jenkins
(Pipeline as code with the Jenkinsfile, no more creating jobs,
Blue Ocean)
is different and better than the old Jenkins (freestyle jobs, chaining jobs together, etc.).
All these developments have helped Jenkins users,
and it would be more meaningful to have fellow users, like you, share their stories
about how recent Jenkins improvements like Pipeline and Blue Ocean have positively impacted them.

If you’re interested sharing your story, please complete
this form
so that I can contact you.
This is a great opportunity to let
the rest of the world (and your boss!) hear about your accomplishments.
You’ll also get into Jenkins World for free and get to join me backstage.
If you concerns about traveling to Jenkins World,
I’m happy to discuss helping with that as well.

I look forward to hearing from you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/06/27/speaker-blog-SAS-jenkins-world/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">27</div></div><h5 class="title">Extending your Pipeline with Shared Libraries, Global Functions and External Code</h5></div><p class="teaser">This is a guest post by Brent Laster, Senior Manager, Research and Development at
SAS.

Jenkins Pipeline
has fundamentally changed how users can orchestrate their pipelines and workflows.
Essentially, anything that you can do in a script or program can now be done in a Jenkinsfile or in a pipeline script created within the application.
But just because you can do nearly anything directly in those mechanisms doesn’t mean you necessarily should.

In some cases, it’s better to abstract the functionality out separately from your main Pipeline.
Previously, the main way to do this in Jenkins itself was through creating plugins.
With Jenkins 2 and the tight incorporation of Pipeline, we now have another approach – shared libraries.

Brent will be
presenting
more of this topic at Jenkins World in
August, register with the code JWFOSS for a 30% discount off your pass.

Shared libraries
provide solutions for a number of situations that can be challenging or time-consuming to deal with in Pipeline.
Among them:

Providing common routines that can be accessed across a number of pipelines or within a designated scope (more on scope later)

Abstracting out complex or restricted code

Providing a means to execute scripted code from calls in declarative pipelines (where scripted code is not normally allowed)

Simplifying calls in a script to custom code that only differ by calling parameters

To understand how to use shared libraries in Pipeline, we first need to understand how they are constructed.
A shared library for Jenkins consists of a source code repository with a structure like the one below:

Each of the top-level directories has its own purpose.

The resources directory can have non-groovy resources that get loaded via the libraryResource step.
Think of this as a place to store supporting data files such as json files.

The src directory uses a structure similar to the standard Java src layout.
This area is added to the classpath when a Pipeline that includes this shared library is executed.

The vars directory holds global variables that should be accessible from pipeline scripts.
A corresponding.txt file can be included that defines documentation for objects here.
If found, this will be pulled in as part of the documentation in the Jenkins application.

Although you might think that it would always be best to define library functions in the src structure, it actually works better in many cases to define them in the vars area.
The notion of a global variable may not correspond very well to a global function, but you can think of it as the function being a global value that can be pulled in and used in your pipeline.
In fact, to work in a declarative style pipeline, having your function in the vars area is the only option.

Let’s look at a simple function that we can create for a shared library.
In this case, we’ll just wrap picking up the location of the Gradle installation from Jenkins and calling the corresponding executable with whatever tasks are passed in as arguments.
The code is below:

/vars/gbuild.groovy

def call(args) {
      sh &quot;${tool &#x27;gradle3&#x27;}/bin/gradle ${args}&quot;
}

Notice that we are using a structured form here with the def call syntax.
This allows us to simply invoke the routine in our pipeline (assuming we have loaded the shared library) based on the name of the file in the vars area.
For example, since we named this file gbuild.groovy, then we can invoke it in our pipeline via a step like this:

gbuild &#x27;clean compileJava&#x27;

So, how do we get our shared library loaded to use in our pipeline?
The shared library itself is just code in the structure outlined above committed/pushed into a source code repository that Jenkins can access.
In our example, we’ll assume we’ve staged, committed, and pushed this code into a local Git repository on the system at /opt/git/shared-library.git.

Like most other things in Jenkins, we need to first tell Jenkins where this shared library can be found and how to reference it &quot;globally&quot; so that pipelines can reference it specifically.

First, though, we need to decide at what scope you want this shared library to be available.
The most common case is making it a &quot;global shared library&quot; so that all Pipelines can access it.
However, we also have the option of only making shared libraries available for projects in a particular Jenkins Folder structure,
or those in a Multibranch Pipeline, or those in a GitHub Organization pipeline project.

To keep it simple, we’ll just define ours to be globally available to all pipelines.
Doing this is a two-step process.
We first tell Jenkins what we want to call the library and define some default behavior for Jenkins related to the library,
such as whether we wanted it loaded implicitly for all pipelines.
This is done in the Global Pipeline Libraries section of the Configure System page.

For the second part, we need to tell Jenkins where the actual source repository for the shared library is located.
SCM plugins that have been modified to understand how to work with shared libraries are called &quot; Modern SCM&quot;.
The git plugin in one of these updated plugin, so we just supply the information in the same Configure System page.

After configuring Jenkins so that it can find the shared library repository, we can load the shared library into our pipeline using the @Library(&#x27; &#x27;) annotation.
Since Annotations
are designed to annotate something that follows them,
we need to either include a specific import statement, or, if we want to include everything, we can use an underscore character as a placeholder.
So our basic step to load the library in a pipeline would be:

@Library(&#x27;Utilities2&#x27;) _

Based on this step, when Jenkins runs our Pipeline, it will first go out to the repository that holds the shared library and clone down a copy to use.
The log output during this part of the pipeline execution would look something like this:

Loading library Utilities2@master
 &gt; git rev-parse --is-inside-work-tree # timeout=10
Setting origin to /opt/git/shared-libraries
 &gt; git config remote.origin.url /opt/git/shared-libraries # timeout=10
Fetching origin...
Fetching upstream changes from origin
 &gt; git --version # timeout=10
using GIT_SSH to set credentials Jenkins2 SSH
 &gt; git fetch --tags --progress origin +refs/heads/*:refs/remotes/origin/*
 &gt; git rev-parse master^{commit} # timeout=10
 &gt; git rev-parse origin/master^{commit} # timeout=10
Cloning the remote Git repository
Cloning repository /opt/git/shared-libraries

Then Pipeline can call our shared library gbuild function and translate it to the desired Gradle build commands.

First time build.
Skipping changelog.
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Compile)
[Pipeline] tool
[Pipeline] sh
[gsummit17_lab2-4T357CUTJORMC2TIF7WW5LMRR37F7PM2QRUHXUNSRTWTTRHB3XGA]
Running shell script
+ /usr/share/gradle/bin/gradle clean compileJava -x test
Starting a Gradle Daemon (subsequent builds will be faster)

This is a very basic illustration of how using shared libraries work.
There is much more detail and functionality surrounding shared libraries, and extending your pipeline in general, than we can cover here.

Be sure to catch my talk on
Extending your Pipeline with Shared Libraries, Global Functions and External Code
at Jenkins World 2017.
Also, watch for my new book on
Jenkins 2 Up and Running
which will have a dedicated chapter on this – expected to be available later this year from O’Reilly.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/03/contributor-summit/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 3</div></div><h5 class="title">Jenkins World Contributor Summit</h5></div><p class="teaser">As in previous years, there’ll be a contributor summit at Jenkins World 2017 :

Let’s talk about the future of Jenkins and how you can help shape it! The contributor summit is the place where the current and future contributors of the Jenkins project get together. This year, the theme is “working together”. Traditionally, most contributors are plugin maintainers focusing on their own plugins, but it’s important to look at Jenkins as a whole, because that’s how users experience it. There is more to the project beyond writing plugins, and even for plugin developers, there are increasing number of common libraries and modules that plugins should rely on. In short, we should work better together.

A few contributors will prepare some presentations to help clarify what that means, and what all of us can do. And in the afternoon, there will be &quot;unconference&quot; sessions to brainstorm and discuss what we can do and how.

Whether you are already a contributor or just thinking about becoming one, please join us for this full day free event.

Details about this year’s agenda are available on the event’s meetup page.
Attending is free, and no Jenkins World ticket is needed, but RSVP if you’re going to attend to help us plan.

See you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/05/continuousdelivery-devops-artifactory/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 5</div></div><h5 class="title">Delivery pipelines, with Jenkins 2: how to promote Java EE and Docker binaries toward production.</h5></div><p class="teaser">This is a guest post by Michael Hüttermann. Michael is an expert
in Continuous Delivery, DevOps and SCM/ALM. More information about him at huettermann.net, or
follow him on Twitter: @huettermann.

In a past blog post Delivery Pipelines,
with Jenkins 2, SonarQube, and Artifactory, we talked about pipelines which result in binaries for development versions. Now, in this blog post, I zoom in to different parts of the
holistic pipeline and cover the handling of possible downstream steps once you have the binaries of development versions, in our example a Java EE WAR and a Docker image (which contains the WAR).
We discuss basic concept of staging software, including further information about quality gates, and show example toolchains. This contribution particularly examines the staging from binaries from
dev versions to release candidate versions and from release candidate versions to final releases from the perspective of the automation server Jenkins, integrating with the binary
repository manager JFrog Artifactory and the distribution management platform JFrog Bintray, and ecosystem.

Staging software

Staging (also often called promoting) software is the process of completely and consistently transferring a release with all its configuration items
from one environment to another. This is even more true with DevOps, where you want to accelerate the cycle time (see Michael Hüttermann, DevOps for Developers (Apress, 2012), 38ff).
For accelerating the cycle time, meaning to bring software to production, fast and in good quality, it is crucial to have fine processes and integrated tools to streamline the
delivery of software. The process of staging releases consists of deploying software to different staging levels, especially different test environments.
Staging also involves configuring the software for various environments without needing to recompile or rebuild the software. Staging is necessary
to transport the software to production systems in high quality. Many Agile projects make great experience with implementing a staging ladder in
order to optimize the cycle time between development software and the point when the end user is able to use the software in production.

Commonly, the staging ladder is illustrated on its side, with the higher rungs being the boxes further to the right. It’s good practice not to skip any rungs during staging.
The central development environment packages and integrates all respective configuration items and is the base for releasing. Software is staged over different environments by
configuration, without rebuilding. All changes go through the entire staging process, although defined exception routines may be in place,
for details see Michael Hüttermann, Agile ALM (Manning, 2012).

To make concepts clearer, this blog post covers sample tools. Please note, that there are also alternative tools available. As one example: Sonatype Nexus is also able to host the covered binaries and also offers scripting functionality.

We nowadays often talk about delivery pipelines. A pipeline is just a set of stages and transition rules between those stages. From a DevOps perspective, a pipeline bridges multiple
functions in organizations, above all development and operations. A pipeline is a staging ladder. A change enters the pipeline at the beginning and leaves it at the end. The processing
can be triggered automatically (typical for delivery pipelines) or by a human actor (typical for special steps at overall pipelines, e.g. pulling and thus cherry-picking specific
versions to promote them to be release candidates are final releases).

Pipelines often look different, because they strongly depend on requirements and basic conditions, and can contain further sub pipelines. In our scenario, we have two sub pipelines to
manage the promotion of continuous dev versions to release candidates and the promotion of release candidates to final release. A change typically waits at a stage for further processing
according to the transition rules, aligned with defined requirements to meet, which are the Quality Gates, explored next.

Quality Gates

Quality gates allow the software to pass through stages only if it meets their defined requirements. The next illustration shows a staging ladder with quality gates injected. You and
other engaged developers commit code to the version control system (please, use VCS as an abbreviation, not SCM, because the latter is much more) in order to update the central test
environment only if the code satisfies the defined quality requirements; for instance, the local build may need to run successfully and have all tests pass locally. Build, test, and
metrics should pass out of the central development environment, and then automated and manual acceptance tests are needed to pass the system test. In our case, the last quality gate
to pass is the one from the  production mirror to production. Here, for example, specific production tests are done or relevant documents must be filled in and signed.

It’s mandatory to define the quality requirements in advance and to resist customizing them after the fact, when the software has failed. Quality gates are different at lower and
higher stages; the latter normally consist of a more severe or broader set of quality requirements, and they often include the requirements of the lower gates. The binary repository
manager must underpin corresponding quality gates, while managing the binaries, what we cover next.

This blog post illustrates typical concepts and sample toolchains. For more information, please consult the respective documentation, good books or attend top notch conferences, e.g.
Jenkins World, powered by CloudBees.

Binary repository manager

A central backbone of the staging ladder is the binary repository manager, e.g. JFrog Artifactory. The binary repository manager manages all binaries including the self-produced
ones (producing view) and the 3rd party ones (consuming view), across all artifact types, in our case a Java EE WAR file and a Docker image. Basic idea here is that the repo manager serves
as a proxy, thus all developers access the repo manager, and not remote binary pools directly, e.g. Maven Central. The binary repository manager offers cross-cutting services,
e.g. role-based access control on specific logical repositories, which may correspond to specific stages of the staging ladder.

Logical repositories can be generic ones (meaning they are agnostic regarding any tools and platforms, thus you can also just upload the menu of your local canteen) or repos
specific to tools and platforms. In our case, we need a repository for managing the Java EE WAR files and for the Docker images. This can be achieved by

a generic repository (preferred for higher stages) or a repo which is aligned with the layout of the Maven build tool, and

a repository for managing Docker images, which serves as a Docker registry.

In our scenario, preparing the staging of artifacts includes the following ramp-up activities

Creating two sets of logical repositories, inside JFrog Artifactory, where each set has a repo for the WAR file and a repo for the Docker image, and one set is for managing dev
versions and one set is for release candidate versions.

Defining and implementing processes to promote the binaries from the one set of repositories (which is for dev versions) to the other set of repositories (which is for RC versions).
Part of the process is defining roles, and JFrog Artifactory helps you to implement role-based access control.

Setting up procedures or scripts to bring binaries from one set of repositories to the other set of repositories, reproducibly. Adding meta data to binaries is important if the degree of maturity
of the binary cannot be easily derived from the context.

The following illustration shows a JFrog Artifactory instance with the involved logical repos in place. In our simplified example, the repo promotions are supposed to go from
docker-local to docker-prod-local, and from libs-release-local to libs-releases-staging-local. In our use case, we promote the software in version 1.0.0.

Another type of binary repository manager is JFrog Bintray, which serves as a universal distribution platform for many technologies. JFrog Bintray can be an interesting choice
if you have strong requirements for scalability and worldwide coverage including IP restrictions and handy features around statistics. Most of the concepts and ramp up activities
 are similar compared to JFrog Artifactory, thus I do not want to repeat them here. Bintray is used by lot of projects e.g. by Groovy, to host their deliverables in the public.
 But keep in mind that you can of course also host your release binaries in JFrog Artifactory.
 In this blog post, I’d like to introduce different options, thus we promote our release candidates to JFrog Artifactory and our releases to JFrog Bintray.
 Bintray has the concept of products, packages and versions. A product can have multiple packages and has different versions. In our example, the product has two packages, namely the Java EE WAR and
 the Docker image, and the concrete version that will be processed is 1.0.0.

Some tool features covered in this blog post are available as part of commercial offerings of tool vendors. Examples include the Docker support of JFrog Artifactory or the Firehose Event API of JFrog Bintray.
Please consult the respective documentation for more information.

Now it is time to have a deeper look at the pipelines.

Implementing Pipelines

Our example pipelines are implemented with Jenkins, including its Blue Ocean and declarative pipelines facilities, JFrog Artifactory and JFrog Bintray. To derive your personal
pipelines, please check your individual requirements and basic conditions to come up with the best solution for your target architecture, and consult the respective documentation for
 more information, e.g. about scripting the tools.

In case your development versions are built with Maven, and have SNAPSHOT character, you need to either rebuild the software after setting the release version, as part of
your pipeline, or you solely use Maven releases from the very beginning. Many projects make great experience with morphing Maven snapshot versions into
release versions, as part of the pipeline, by using a dedicated Maven plugin, and externalizing it into a Jenkins shared library. This can look like the following:

sl.groovy (excerpt): A Jenkins shared library, to include in Jenkins pipelines.

#!/usr/bin/groovy
    def call(args) { (1)
echo &quot;Calling shared library, with ${args}.&quot;
       sh &quot;mvn com.huettermann:versionfetcher:1.0.0:release versions:set -DgenerateBackupPoms=false -f ${args}&quot; (2)
}

1
We provide a global variable/function to include it in our pipelines.

2
The library calls a Maven plugin, which dynamically morphs the snapshot version of a Maven project to a release version.

And including it into the pipeline is then also very straight forward:

pipeline.groovy (excerpt): A stage calling a Jenkins shared library.

stage(&#x27;Produce RC&#x27;) { (1)
releaseVersion &#x27;all/pom.xml&#x27; (2)
}

1
This stage is part of a scripted pipeline and is dedicated to morphing a Maven snapshot version into a release version, dynamically.

2
We call the Jenkins shared library, with a parameter pointing to the Maven POM file, which can be a parent POM.

You can find the code of the underlying Maven plugin here.

Let’s now discuss how to proceed for the release candidates.

Release Candidate (RC)

The pipeline to promote a dev version to a RC version does contain a couple of different stages, including stages to certify the binaries (meaning labeling it or adding context information) and stages to process the concrete promotion.
The following illustration shows the successful run of the promotion, for software version 1.0.0.

We utilize Jenkins Blue Ocean that is a new user experience for Jenkins based on a personalizable, modern design that allows users to graphically create, visualize and diagnose
delivery pipelines. Besides the new approach in general, single Blue Ocean features help to boost productivity dramatically, e.g. to provide log information at your fingertips
and the ability to search pipelines. The stages to perform the promote are as follows starting with the  Jenkins pipeline stage for promoting the WAR file. Keep in mind that all
scripts are parameterized, including variables for versions and Artifactory domain names, which are either injected to the pipeline run by user input or set system wide in the Jenkins admin panel,
and the underlying call is using the JFrog command line interface, CLI in short. JFrog Artifactory
as well as JFrog Bintray can be used and managed by scripts, based on a REST API. The JFrog CLI
is an abstraction on top of the JFrog REST API, and we show sample usages of both.

pipeline.groovy (excerpt): Staging WAR file to different logical repository

stage(&#x27;Promote WAR&#x27;) { (1)
steps { (2)
sh &#x27;jfrog rt cp --url=https://$ARTI3 --apikey=$artifactory_key --flat=true libs-release-local/com/huettermann/web/$version/ &#x27; + (3)
&#x27;libs-releases-staging-local/com/huettermann/web/$version/&#x27;
       }
    }

1
The dedicated stage for running the promotion of the WAR file.

2
Here we have the steps which make up the stage, based on Jenkins declarative pipeline syntax.

3
Copying the WAR file, with JFrog CLI, using variables, e.g. the domain name of the Artifactory installation. Many options available, check the docs.

The second stage to explore more is the promotion of the Docker image. Here, I want to show you a different way how to achieve the goal, thus in this use case we utilize the JFrog REST API.

pipeline.grovvy (excerpt): Promote Docker image

stage(&#x27;Promote Docker Image&#x27;) {
          sh &#x27;&#x27;&#x27;curl -H &quot;X-JFrog-Art-Api:$artifactory_key&quot; -X POST https://$ARTI3/api/docker/docker-local/v2/promote &#x27;&#x27;&#x27; + (1)
&#x27;&#x27;&#x27;-H &quot;Content-Type:application/json&quot; &#x27;&#x27;&#x27; + (2)
&#x27;&#x27;&#x27;-d \&#x27;{&quot;targetRepo&quot; : &quot;docker-prod-local&quot;, &quot;dockerRepository&quot; : &quot;michaelhuettermann/tomcat7&quot;, &quot;tag&quot;: &quot;\&#x27;$version\&#x27;&quot;, &quot;copy&quot;: true }\&#x27; (3)
&#x27;&#x27;&#x27;
    }

1
The shell script to perform the staging of Docker image is based on JFrog REST API.

2
Part of parameters are sent in JSON format.

3
The payload tells the REST API endpoint what to to, i.e. gives information about target repo and tag.

Once the binaries are promoted (and hopefully deployed and tested on respective environments before), we can promote them to become final releases, which I like to call GA.

General Availability (GA)

In our scenario, JFrog Bintray serves as the distribution platform to manage and provide binaries for further usage. Bintray can also serve as a Docker registry, or can just
provide binaries for scripted or manual download. There are again different ways how to promote binaries, in this case from the RC repos inside JFrog Artifactory to the GA storage in JFrog Bintray, and I summarize one of those possible ways. First, let’s look at the Jenkins pipeline, showed in the next illustration. The processing is on its way, currently, and we again have a list of linked stages.

Zooming in now to the key stages, we see that promoting the WAR file is a set of steps that utilize JFrog REST API. We download the binary from JFrog Artifactory, parameterized,
and upload it to JFrog Bintray.

pipeline.groovy (excerpt): Promote WAR to Bintray

stage(&#x27;Promote WAR to Bintray&#x27;) {
       steps {
          sh &#x27;&#x27;&#x27;
             curl -u michaelhuettermann:${bintray_key} -X DELETE https://api.bintray.com/packages/huettermann/meow/cat/versions/$version (1)
curl -u michaelhuettermann:${bintray_key} -H &quot;Content-Type: application/json&quot; -X POST https://api.bintray.com/packages/huettermann/meow/cat/$version --data &quot;&quot;&quot;{ &quot;name&quot;: &quot;$version&quot;, &quot;desc&quot;: &quot;desc&quot; }&quot;&quot;&quot; (2)
curl -T &quot;$WORKSPACE/all-$version-GA.war&quot; -u michaelhuettermann:${bintray_key} -H &quot;X-Bintray-Package:cat&quot; -H &quot;X-Bintray-Version:$version&quot; https://api.bintray.com/content/huettermann/meow/ (3)
curl -u michaelhuettermann:${bintray_key} -H &quot;Content-Type: application/json&quot; -X POST https://api.bintray.com/content/huettermann/meow/cat/$version/publish --data &#x27;{ &quot;discard&quot;: &quot;false&quot; }&#x27; (4)
&#x27;&#x27;&#x27;
       }
    }

1
For testing and demo purposes, we remove the existing release version.

2
Next we create the version in Bintray, in our case the created version is 1.0.0. The value was insert by user while triggering the pipeline.

3
The upload of the WAR file.

4
Bintray needs a dedicated publish step to make the binary publicly available.

Processing the Docker image is as easy as processing the WAR. In this case, we just push the Docker image to the Docker registry, which is served by JFrog Bintray.

pipeline.groovy (excerpt): Promote Docker image to Bintray

stage(&#x27;Promote Docker Image to Bintray&#x27;) { (1)
steps {
          sh &#x27;docker push $BINTRAYREGISTRY/michaelhuettermann/tomcat7:$version&#x27; (2)
}
    }

1
The stage for promoting the Docker image. Please note, depending on your setup, you may add further stages, e.g. to login to your Docker registry.

2
The Docker push of the specific version. Note, that also here all variables are parameterized.

We now have promoted the binaries and uploaded them to JFrog Bintray. The overview page of our product lists two packages: the WAR file and the Docker image. Both can be downloaded
now and used, the Docker image can be pulled from the JFrog Bintray Docker registry with native Docker commands.

As part of its graphical visualization capabilitites, Bintray is able to show the single layers of the uploaded Docker images.

Bintray can also display usage statistics, e.g. download details. Now guess where I’m sitting right now while downloading the binary?

Besides providing own statistics, Bintray provides the JFrog Firehose Event API. This API streams live usage data, which in turn can be integrated or aggregated with your ecosystem.
In our case, we visualize the data, particularly download, upload, and delete statistics, with the ELK stack, as part of a functional monitoring initiative.

Crisp, isn’t it?

Summary

This closes are quick ride through the world of staging binaries, based on Jenkins. We’ve discussed concepts and example DevOps enabler tools, which can help to implement
 the concepts. Along the way, we discussed some more options how to integrate with ecosystem, e.g. releasing Maven snapshots and functional monitoring with dedicated tools.
 After this appetizer you may want to now consider to double-check your staging processes and toolchains, and maybe you find some room for further adjustments.

References

&#x27;Agile ALM&#x27;, Manning, 2011

Binary Repository Manager Feature Matrix

&#x27;DevOps for Developers&#x27;, Apress, 2012

Docker

ELK

JFrog Artifactory

JFrog Bintray

JFrog CLI

JFrog REST API

Sonatype Nexus<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelhuettermann/">Michael Hüttermann</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devops">devops</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/artifactory">artifactory</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/bintray">bintray</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/07/jenkins-conan/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 7</div></div><h5 class="title">Continuous Integration for C/C++ Projects with Jenkins and Conan</h5></div><p class="teaser">This is a guest post by Luis Martínez de Bartolomé,
Conan Co-Founder

C and C++ are present in very important industries today, including Operating Systems, embedded systems, finances, research, automotive, robotics, gaming, and many more. The main reason for this is performance, which is critical to many of these industries, and cannot be compared to any other technology.
As a counterpart, the C/C++ ecosystem has a few important challenges to face:

Huge projects - With millions of lines of code, it’s very hard to manage your projects without using modern tools.

Application Binary Interface (ABI) incompatibility - To guarantee the compatibility of a library with other libraries and your application,  different configurations (such as the operating system, architecture, and compiler) need to be under control.

Slow compilation times - Due to header inclusion and pre-processor bloat, together with the challenges mentioned above, it requires special attention to optimize the process and rebuild only the libraries that need to be rebuilt.

Code linkage and inlining - A static C/C++ library can embed headers from a dependent library. Also, a shared library can embed a static library. In both cases, you need to manage the rebuild of your library when any of its dependencies change.

Varied ecosystem - There are many different compilers and build systems, for different platforms, targets and purposes.

This post will show how to implement DevOps best practices for C/C++ development, using Jenkins CI, Conan C/C++ package manager, and JFrog Artifactory the universal artifact repository.

Conan, The C/C++ Package Manager

Conan was born to mitigate these pains.

Conan uses python recipes, describing how to build a library by explicitly calling any build system, and also describing the needed information for the consumers (include directories, library names etc.).
To manage the different configurations and the ABI compatibility, Conan uses &quot;settings&quot; (os, architecture, compiler…). When a setting is changed, Conan generates a different binary version for the same library:

The built binaries can be uploaded to JFrog Artifactory or Bintray, to be shared with your team or the whole community. The developers in your team won’t need to rebuild the libraries again, Conan will fetch only the needed Binary packages matching the user’s configuration from the configured remotes (distributed model).
But there are still some more challenges to solve:

How to manage the development and release process of your C/C++ projects?

How to distribute your C/C++ libraries?

How to test your C/C++ project?

How to generate multiple packages for different configurations?
*How to manage the rebuild of the libraries when one of them changes?

Conan Ecosystem

The Conan ecosystem is growing fast, and DevOps with C/C++ is now a reality:

JFrog Artifactory manages the full development and releasing cycles.

JFrog Bintray is the universal distribution hub.

Jenkins automates the project testing, generates different binary configurations of your Conan packages, and automates the rebuilt libraries.

Jenkins Artifactory plugin

Provides a Conan DSL, a very generic but powerful way to call Conan from a Jenkins Pipeline script.

Manages the remote configuration with your Artifactory instance, hiding the authentication details.

Collects from any Conan operation (installing/uploading packages) all the involved artifacts to generate and publish the buildInfo to Artifactory. The buildInfo object is very useful, for example, to promote the created Conan packages to a different repository and to have full traceability of the Jenkins build:

Here’s an example of the Conan DSL with the Artifactory plugin.  First we configure the Artifactory repository, then retrieve the dependencies and finally build it:

def artifactory_name = &quot;artifactory&quot;
def artifactory_repo = &quot;conan-local&quot;
def repo_url = &#x27;https://github.com/memsharded/example-boost-poco.git&#x27;
def repo_branch = &#x27;master&#x27;

node {
   def server
   def client
   def serverName

stage(&quot;Get project&quot;){
    git branch: repo_branch, url: repo_url
}

stage(&quot;Configure Artifactory/Conan&quot;){
    server = Artifactory.server artifactory_name
    client = Artifactory.newConanClient()
    serverName = client.remote.add server: server, repo: artifactory_repo
}

stage(&quot;Get dependencies and publish build info&quot;){
    sh &quot;mkdir -p build&quot;
    dir (&#x27;build&#x27;) {
      def b = client.run(command: &quot;install ..&quot;)
      server.publishBuildInfo b
    }
}

stage(&quot;Build/Test project&quot;){
        dir (&#x27;build&#x27;) {
          sh &quot;cmake ../ &amp;&amp; cmake --build .&quot;
        }
    }
}

You can see in the above example that the Conan DSL is very explicit. It helps a lot with common operations, but also allows powerful and custom integrations. This is very important for C/C++ projects, because every company has a very specific project structure, custom integrations etc.

Complex Jenkins Pipeline operations: Managed and parallelized libraries building

As we saw at the beginning of this blog post, it’s crucial to save time when building a C/C++ project. Here are several ways to optimize the process:

Only re-build the libraries that need to be rebuilt. These are the libraries that  have been affected by a dependant library that has changed.

Build in parallel, if possible. When there is no relation between two or more libraries in the project graph, you can build them in parallel.

Build different configurations (os, compiler, etc) in parallel. Use different agents if needed.

Let’s see an example using Jenkins Pipeline feature

The above graph represents our project P and its dependencies (A-G). We want to distribute the project for two different architectures, x86 and x86_64.

What happens if we change library A?

If we bump the version to A(v1) there is no problem, we can update the B requirement and also bump its version to B(v1) and so on. The complete flow would be as follows:

Push A(v1) version to Git, Jenkins will build the x86 and x86_64 binaries. Jenkins will upload all the packages to Artifactory.

Manually change B to v1, now depending on A1, push to Git, Jenkins will build the B(v1) for x86 and x86_64 using the retrieved new A1 from Artifactory.

Repeat the same process for C, D, F, G and finally our project.

But if we are developing our libraries in a development repository, we probably depend on the latest A version or will override A (v0) packages on every git push, and we want to automatically rebuild the affected libraries in this case B, D, F, G and P.

How we can do this with Jenkins Pipelines?

First we need to know which libraries need to be rebuilt. The &quot;conan info --build_order&quot; command identifies the libraries that were changed in our project, and also tells us which can be rebuilt in parallel.

So, we created two Jenkins pipelines tasks:

The&quot;SimpleBuild&quot; task which builds every single library. Similar to the first example using Conan DSL with the Jenkins Artifactory plugin. It’s a parameterized task that receives the libraries that need to built.

The&quot;MultiBuild&quot; task which coordinates and launches the &quot; SimpleBuild&quot; tasks, in parallel when possible.

We also have a repository with a configuration yml. The Jenkins tasks will use it to know where the recipe of each library is, and the different profiles to be used. In this case they are x86 and x86_64.

leaves:
  PROJECT:
    profiles:
       - ./profiles/osx_64
       - ./profiles/osx_32

artifactory:
  name: artifactory
  repo: conan-local

repos:
 LIB_A/1.0:
   url: https://github.com/lasote/skynet_example.git
   branch: master
   dir: ./recipes/A

LIB_B/1.0:
 url: https://github.com/lasote/skynet_example.git
 branch: master
 dir: ./recipes/b

…

PROJECT:
 url: https://github.com/lasote/skynet_example.git
 branch: master
 dir: ./recipes/PROJECT

If we change and push library A to the repository, the &quot; MultiBuild&quot; task will be triggered. It will start by checking which libraries need to be rebuilt, using the &quot;conan info&quot; command.
Conan will return something like this:
[B, [D, F], G]

This means that we need to start building B, then we can build D and F in parallel, and finally build G. Note that library C does not need to be rebuilt, because it’s not affected by a change in library A.

The &quot; MultiBuild&quot; Jenkins pipeline script will create closures with the parallelized calls to the &quot; SimpleBuild&quot; task, and finally launch the groups in parallel.

//for each group
      tasks = [:]
      // for each dep in group
         tasks[label] = { -&gt; build(job: &quot;SimpleBuild&quot;,
                            parameters: [
                               string(name: &quot;build_label&quot;, value: label),
                               string(name: &quot;channel&quot;, value: a_build[&quot;channel&quot;]),
                               string(name: &quot;name_version&quot;, value: a_build[&quot;name_version&quot;]),
                               string(name: &quot;conf_repo_url&quot;, value: conf_repo_url),
                               string(name: &quot;conf_repo_branch&quot;, value: conf_repo_branch),
                               string(name: &quot;profile&quot;, value: a_build[&quot;profile&quot;])
                            ]
                     )
          }
     parallel(tasks)

Eventually, this is what will happen:

Two SimpleBuild tasks will be  triggered, both for building library B, one for x86 and another for x86_64 architectures

Once &quot;A&quot; and &quot;B&quot; are built, &quot;F&quot; and &quot;D&quot; will be triggered, 4 workers will run the &quot;SimpleBuild&quot; task in parallel, (x86, x86_64)

Finally &quot;G&quot; will be built. So 2 workers will run in parallel.

The Jenkins Stage View for the will looks similar to the figures below:

MultiBuild

SimpleBuild

We can configure the &quot; SimpleBuild&quot; task within different nodes (Windows, OSX, Linux…), and control the number of executors available in our Jenkins configuration.

Conclusions

Embracing DevOps for C/C++ is still marked as a to-do for many companies. It requires a big investment of time but can save huge amounts of time in the development and releasing life cycle for the long run. Moreover it increases the quality and the reliability of the C/C++ products. Very soon, adoption of DevOps for C/C++ companies will be a must!

The Jenkins example shown above that demonstrating how to control the library building in parallel is just Groovy code and a custom convenient yml file. The great thing about it is not the example or the code itself. The great thing is the possibility of defining your own pipeline scripts to adapt to your specific workflows, thanks to Jenkins Pipeline, Conan and JFrog Artifactory.

More on this topic will be presented at Jenkins Community Day Paris on
July 11, and Jenkins User Conference Israel on July 13.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-user-conference">jenkins-user-conference</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-community-day-paris">jenkins-community-day-paris</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/10/security-advisory/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">10</div></div><h5 class="title">Security updates for multiple Jenkins plugins</h5></div><p class="teaser">Multiple Jenkins plugins received updates today that fix several security vulnerabilities, including high severity ones:

Docker Commons Plugin

Git Plugin

GitHub Branch Source Plugin

Parameterized Trigger Plugin

Periodic Backup Plugin

Pipeline: Build Step Plugin

Pipeline: Groovy Plugin

Poll SCM Plugin

Role-based Authorization Strategy Plugin

Script Security Plugin

Sidebar Link Plugin

Subversion Plugin

Additionally, the SSH Plugin received a security update a few days ago.

For an overview of what was fixed, see the security advisory.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/13/speaker-blog-rosetta-stone/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">13</div></div><h5 class="title">Automated Software Maintenance</h5></div><p class="teaser">This is a guest post by Kevin Burnett, DevOps Lead at
Rosetta Stone.

Have you experienced that thing where you make a change in an app, and when you
go to check on the results of the build, you find an error that really doesn’t
seem relevant to your change? And then you notice that your build is the first
in over a year. And then you realize that you have accidentally become the
subject matter expert in this app.

You have no clue what change caused this failure or when that change occurred.
Did one Jenkins agent become a
snowflake server,
accruing cruft on the file system that is not cleaned up before each build?
Did some unpinned external dependency upgrade in a backwards-incompatible fashion?
Did the credentials the build plan was using to connect to source control get rotated?
Did a dependent system go offline?
Or - and I realize that this is unthinkable - did you legitimately break a test?

Not only is this type of archaeological expedition often a bad time for the
person who happened to commit to this app (&quot;No good deed goes unpunished&quot;), but
it’s also unnecessary. There’s a simple way to reduce the cognitive load it
takes to connect cause and effect: build more frequently.

One way we achieve this is by writing scripts to maintain our apps. When we
build, the goal is that an equivalent artifact should be produced unless there
was a change to the app in source control. As such, we pin all of our
dependencies to specific versions. But we also don’t want to languish on old
versions of dependencies, whether internal or external. So we also have an
auto-maintain script that bumps all of these versions and commits the result.

I’ll give an example. We use docker to build and deploy our apps, and each app
depends on a base image that we host in a docker registry. So a Dockerfile in
one of our apps would have a line like this:

FROM our.registry.example.com/rosettastone/sweet-repo:jenkins-awesome-project-sweet-repo-5

We build our base images in Jenkins and tag them with the Jenkins $BUILD_TAG,
so this app is using build 5 of the rosettastone/sweet-repo base image.
Let’s say we updated our sweet-repo base image to use ubuntu 16.04 instead of 14.04
and this resulted in build 6 of the base image. Our auto-maintain script takes
care of upgrading an app that uses this base image to the most recent version.
The steps in the auto-maintain script look like this:

Figure out what base image tag you’re using.

Find the newest version of that base image tag by querying the docker registry.

If necessary, update the FROM line in the app’s Dockerfile to pull in the most recent version.

We do the same thing with library dependencies.
If our Gemfile.lock is referencing an old library, running auto-maintain will update things.
The same applies to the Jenkinsfile for each app. If we decide to implement a new policy where we
discard old builds, we update auto-maintain so that it will bring each app into
compliance with the policy, by changing, for example, this Jenkinsfile :

Jenkinsfile (Before)

pipeline {
  agent { label &#x27;docker&#x27; }
  stages {
    stage(&#x27;commit_stage&#x27;) {
      steps {
        sh(&#x27;./bin/ci&#x27;)
      }
    }
  }
}

to this:

Jenkinsfile (After)

pipeline {
  agent { label &#x27;docker&#x27; }
  options {
    buildDiscarder(logRotator(numToKeepStr: &#x27;100&#x27;))
  }
  stages {
    stage(&#x27;commit_stage&#x27;) {
      steps {
        sh(&#x27;./bin/ci&#x27;)
      }
    }
  }
}

We try to account for these sorts of things (everything that we can) in our
auto-maintain script rather than updating apps manually, since this reduces the
friction in keeping apps standardized.

Once you create an auto-maintain script (start small), you just have to run it.
We run ours based on both &quot;actions&quot; and &quot;non-actions.&quot; When an internal library
changes, we kick off app builds, so a library’s Jenkinsfile might look like
this:

Jenkinsfile

pipeline {
  agent { label &#x27;docker&#x27; }
  stages {
    stage(&#x27;commit_stage&#x27;) {
      steps {
        sh(&#x27;./bin/ci&#x27;)
      }
    }
    stage(&#x27;auto_maintain_things_that_might_be_using_me&#x27;) {
      steps {
        build(&#x27;hot-project/auto-maintain-all-apps/master&#x27;)
      }
    }
  }
}

When auto-maintain updates something in an app, we have it commit the change
back to the app, which in turn triggers a build of that app, and—​if all is
well—​a production deployment.

The only missing link then for avoiding one-year build droughts is to get around
the problem where auto-maintain isn’t actually updating anything in a certain app.
If no dependencies are changing, or if the technology in question is not
receiving much attention, auto-maintain might not do anything for an
extended period of time, even if the script is run on a schedule using
cron . For those cases, putting
a cron trigger in the Pipeline for each app will ensure that builds still happen periodically:

Jenkinsfile

pipeline {
  agent { label &#x27;docker&#x27; }
  triggers {
    cron(&#x27;@weekly&#x27;)
  }
  stages {
    stage(&#x27;commit_stage&#x27;) {
      steps {
        sh(&#x27;./bin/ci&#x27;)
      }
    }
  }
}

In most cases, these periodic builds won’t do anything different from the last
build, but when something does break, this strategy will allow you to decide
when you find out about it (by making your cron @weekly, @daily, etc)
instead of letting some poor developer find out about it when they do
something silly like commit code to an infrequently-modified app.

Kevin will be
presenting
more on this topic at
Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2017">jenkinsworld2017</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/17/speaker-blog-care/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">17</div></div><h5 class="title">Indispensable, Disposable Jenkins</h5></div><p class="teaser">This is a guest post by Mandy Hubbard, Software Engineer/QA Architect at
Care.com.

Imagine this: It’s 4:30pm on a Friday,
you have a major release on Monday, and your Jenkins server goes down.
It doesn’t matter if it experienced a hardware failure,
fell victim to a catastrophic
fat-finger error,
or just got hit by a meteor - your Jenkins server is toast.
How long did it take to perfect your Pipeline,
all your Continuous Delivery jobs, plugins, and credentials?
Hopefully you at least have a recent backup of your Jenkins home directory,
but you’re still going have to work over the weekend with IT to procure a new server,
install it, and do full regression testing to be up and running by Monday morning.
Go ahead and take a moment, go to your car and just scream.
It will help …​ a little.

But what if you could have a Jenkins environment that is completely disposable,
one that could be easily rebuilt at any time?
Using Docker and Joyent’s
ContainerPilot, the team at
Care.com HomePay
has created a production Jenkins environment that is completely software-defined.
Everything required to set up a new Jenkins environment is stored in source control,
versioned, and released just like any other software.
At Jenkins World, I’ll do a developer deep-dive into this approach during my technical session,
Indispensable, Disposable Jenkins,
including a demo of bringing up a fully configured Jenkins server in a Docker container.
For now, let me give you a basic outline of what we’ve done.

Mandy will be
presenting
more on this topic at
Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.

First, we add ContainerPilot to our Jenkins image by including it in the Dockerfile.

Dockerfile

## ContainerPilot

ENV CONTAINERPILOT_VERSION 2.7.0
ENV CONTAINERPILOT_SHA256 3cf91aabd3d3651613942d65359be9af0f6a25a1df9ec9bd9ea94d980724ee13
ENV CONTAINERPILOT file:///etc/containerpilot/containerpilot.json

RUN curl -Lso /tmp/containerpilot.tar.gz https://github.com/joyent/containerpilot/releases/download/${CONTAINERPILOT_VERSION}/containerpilot-${CONTAINERPILOT_VERSION}.tar.gz &amp;&amp; \
    echo &quot;${CONTAINERPILOT_SHA256}  /tmp/containerpilot.tar.gz&quot; | sha256sum -c &amp;&amp; \
    tar zxf /tmp/containerpilot.tar.gz -C /bin &amp;&amp; \
rm /tmp/containerpilot.tar.gz

Then we specify containerpilot as the Docker command in the docker-compose.yml
and pass the Jenkins startup script as an argument.
This allows ContainerPilot to perform our preStart business before starting the Jenkins server.

docker-compose.yml

jenkins:
    image: devmandy/auto-jenkins:latest
    restart: always
    mem_limit: 8g
    ports:
      - 80
      - 22
    dns:
      - 8.8.8.8
      - 127.0.0.1
    env_file: _env
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - CONSUL=consul
    links:
      - consul:consul
    ports:
      - &quot;8080:80&quot;
      - &quot;2222:22&quot;
    command: &gt;
      containerpilot
      /usr/local/bin/jenkins.sh

Configuration data is read from a Docker Compose _env file,
as specified in the docker-compose.yml file,
and stored in environment variables inside the container.
This is an example of our _env file:

_env

GITHUB_TOKEN=
GITHUB_USERNAME=DevMandy
GITHUB_ORGANIZATION=DevMandy
DOCKERHUB_ORGANIZATION=DevMandy
DOCKERHUB_USERNAME=DevMandy
DOCKERHUB_PASSWORD=
DOCKER_HOST=
SLACK_TEAM_DOMAIN=DevMandy
SLACK_CHANNEL=jenkinsbuilds
SLACK_TOKEN=
BASIC_AUTH=
AD_NAME=
AD_SERVER=
PRIVATE_KEY=

Jenkins stores its credentials and plugin information in various xml files.
The preStart script modifies the relevant files,
substituting the environment variables as appropriate,
using a set of command line utilities called xmlstarlet.
Here is an example method from our preStart script that configures Github credentials:

github_credentials_setup() {
    ## Setting Up Github username in credentials.xml file
    echo
    echo -e &quot;Adding Github username to credentials.xml file for SSH key&quot;
    xmlstarlet \
        ed \
        --inplace \
        -u &#x27;//com.cloudbees.jenkins.plugins.sshcredentials.impl.BasicSSHUserPrivateKey[id=&quot;github&quot;]/username&#x27; \
        -v ${GITHUB_USERNAME} \
        ${JENKINS_HOME}/credentials.xml

    echo -e &quot;Adding Github username to credentials.xml file for Github token&quot;
    xmlstarlet \
        ed \
         --inplace \
        -u &#x27;//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=&quot;github_token&quot;]/username&#x27; \
        -v ${GITHUB_USERNAME} \
        ${JENKINS_HOME}/credentials.xml

    PASSWORD=${GITHUB_TOKEN}
    echo -e &quot;Adding Github token to credentials.xml&quot;
    xmlstarlet \
        ed \
        --inplace \
        -u &#x27;//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=&quot;github_token&quot;]/password&#x27; \
        -v ${PASSWORD} \
        ${JENKINS_HOME}/credentials.xml
}

This approach can be used to automate all things Jenkins.
These are just a few of the things I’ll show you in my Jenkins World session,
which you can build on to automate anything else your Jenkins environment needs.

Creation of credentials sets for interacting with third party services
like Github, Docker Hub and Slack

Configuration of the Active Directory plugin
and setup of matrix-based security

Configuration of the Github Organization plugin,
which results in the automatic creation of all Jenkins pipeline jobs
by scanning the organization for all repositories containing a Jenkinsfile

Configuration of the
Docker Pipeline plugin, including creating templates for all custom build agents

Configuration of the Global Pipeline Libraries plugin

Configuration of the Slack Notifier plugin

With software-defined Jenkins, pipeline infrastructure
gains the same flexibility and resiliency as the rest of the development pipeline.
If we decide to change our Jenkins configuration in any way –
for example installing a new plugin or upgrading an existing one,
adding a new global library, or adding new Docker images for build agents –
we simply edit our preStart script to include these changes, build a new Docker image,
and the Jenkins environment is automatically reconfigured when we start a new container.
Because the entire configuration specification lives in a Github repository,
changes are merged to the &quot;master&quot; branch using pull requests,
and our Jenkins Docker image is tagged using
semantic versioning just like any other component.
Jenkins can be both indispensable and completely disposable at the same time.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/JenkinsWorld">JenkinsWorld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/21/scaling-jenkins-with-kubernetes-on-google-container-engine/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">21</div></div><h5 class="title">Scaling Jenkins with Kubernetes on Google Container Engine</h5></div><p class="teaser">This is a guest post by Guillaume Laforge,
Developer Advocate for Google Cloud

Last week, I had the pleasure to speak at the
Jenkins Community Day conference, in Paris,
organized by my friends from JFrog,
provider of awesome tools for software management and distribution.
I covered how to scale Jenkins with Kubernetes on
Google Container Engine.

For the impatient, here are the slides of the presentation I’ve given:

But let’s step back a little. In this article, I’d like to share with you why you would want to run Jenkins in the cloud,
as well as give you some pointers to interesting resources on the topic.

Why running Jenkins in the cloud?

So why running Jenkins in the cloud? First of all, imagine your small team, working on a single project.
You have your own little server, running under a desk somewhere, happily building your application on each commit,
a few times a day. So far so good, your build machine running Jenkins isn’t too busy, and stays idle most of the day.

Let’s do some bottom of the napkin calculations. Let’s say you have a team of 3 developers,
committing roughly 4 times a day, on one single project, and the build takes roughly 10 minutes to go.

3 developers * 4 commits / day / developer * 10 minutes build time * 1 project = 1 hour 20 minutes

So far so good, your server indeed stays idle most of the day. Usually, at most,
your developers will wait just 10 minutes to see the result of their work.

But your team is growing to 10 persons, the team is still as productive, but the project becoming bigger,
the build time goes up to 15 minutes:

10 developers * 4 commits / day / developer * 15 minutes build time * 1 project = 10 hours

You’re already at 10 hours build time, so your server is busy the whole day, and at times,
you might have several build going on at the same time, using several CPU cores in parallel.
And instead of building in 15 minutes, sometimes, the build might take longer, or your build might be queued.
So in theory, it might be 15 minutes, but in practice, it could be half an hour because of the length of the queue
or the longer time to build parallel projects.

Now, the company is successful, and has two projects instead of one (think a backend and a mobile app).
Your teams grow further up to 20 developers per project. The developers are a little less productive
because of the size of the codebase and project, so they only commit 3 times a day.
The build takes more time too, at 20 minutes (in ideal time). Let’s do some math again:

20 developers * 3 commits / day / developer * 20 minutes build time * 2 projects = 40 hours

Woh, that’s already 40 hours of total build time, if all the builds are run serially.
Fortunately, our server is multi-core, but still, there are certainly already many builds that are enqueued,
and many of them, perhaps up to 2-3 or perhaps even 4 could be run in parallel.
But as we said, the build queue increases further, the real effective time of build is certainly longer than 30 minutes.
Perhaps at times, developers won’t see the result of their developments before at least an hour, if not more.

One last calculation? With team sizes of 30 developers, decreased productivity of 2 commits, 25 build time,
and 3 projects? And you’ll get 75 hours total build time. You may start creating a little build farm,
with a controller and several build agents. But you also increase the burden of server management.
Also, if you move towards a full Continuous Delivery or Continuous Deployment approach,
you may further increase your build times to go up to deployment, make more but smaller commits, etc.
You could think of running builds less often, or even on a nightly basis, to cope with the demand, but then,
your company is less agile, and the time-to-market for fixes of new features might increase,
and your developers may also become more frustrated because they are developing in the blind,
not knowing before the next day if their work was successful or not.

With my calculations, you might think that it makes more sense for big companies, with tons of projects and developers.
This is quite true, but when you’re a startup, you also want to avoid taking care of local server management,
provisioning, etc. You want to be agile, and use only compute resources you need for the time you need them.
So even if you’re a small startup, a small team, it might still make sense to take advantage of the cloud.
You pay only for the actual time taken by your builds as the build agent containers are automatically provisioned
and decommissioned. The builds can scale up via Kubernetes, as you need more (or less) CPU time for building everything.

And this is why I was happy to dive into scaling Jenkins in the cloud. For that purpose,
I decided to go with building with containers, with Kubernetes, as my app was also containerized as well.
Google Cloud offers Container Engine, which is basically just Kubernetes in the cloud.

Useful pointers

I based my presentation and demo on some great solutions that are published on the Google Cloud documentation portal.
Let me give you some pointers.

Overview of Jenkins on Container Engine

Setting up Jenkins on Container Engine

Configuring Jenkins for Container Engine

Continuous Deployment to Container Engine using Jenkins

Lab: Build a Continuous Deployment Pipeline with Jenkins and Kubernetes

The latter one is the tutorial I actually followed for the demo that I presented during the conference.
It’s a simple Go application, with a frontend and backend.
It’s continuously build, on each commit (well, every minute to check if there’s a new commit),
and deployed automatically in different environments: dev, canary, production.
The sources of the project are stored in Cloud Source Repository (it can be mirrored from Github, for example).
The containers are stored in Cloud Container Registry.
And both the Jenkins controller and agents, as well as the application are running inside Kubernetes clusters in Container Engine.

Summary and perspective

Don’t bother with managing servers! Quickly, you’ll run out of CPU cycles,
and you’ll have happier developers with builds that are super snappy!

And for the record, at Google, dev teams are also running Jenkins!
There was a presentation ( video and
slides
available) given last year by David Hoover at Jenkins World
talking about how developers inside Google are running hundreds of build agents to build projects on various platforms.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/glaforge/">Guillaume Laforge</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-community-day-paris">jenkins-community-day-paris</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/26/powershell-pipeline/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">26</div></div><h5 class="title">Microsoft PowerShell Support for Pipeline</h5></div><p class="teaser">I am pleased to announce Microsoft PowerShell support for Jenkins Pipeline!
As of Durable Task 1.14 and
Pipeline Nodes and Processes Plugin 2.12, you will now be able to run Microsoft PowerShell scripts
directly in your Jenkins Pipeline projects.  This blog post covers the basics
of getting started with Microsoft PowerShell in Pipeline and provides some
basic examples.

Introduction to Microsoft PowerShell

PowerShell is Microsoft’s open source and cross platform command line shell, as
well as an automation and configuration tool/framework which has a broad user
base. PowerShell can be used to perform common system administration tasks in
Windows, macOS, and Linux environments. It can also be used as a general
purpose scripting language. Now that Jenkins Pipeline supports PowerShell, you
can enjoy the rich set of features in PowerShell for your daily DevOps work.

Before diving into using PowerShell in your Pipeline, I recommend reading the
Windows
PowerShell Reference as well as the
PowerShell Team Blog for an
introduction to PowerShell features, utilities, and as a quick look into the
PowerShell language.  Microsoft also has an active
PowerShell community on GitHub,
which I highly recommend visiting to submit feature requests and bug
reports as you see fit. Jenkins Pipeline currently supports Microsoft
PowerShell 3.0 or higher, so also be sure to check which version of PowerShell
is installed on your system in order to take advantage of PowerShell in your
Pipeline.  Please note that we recommend that you upgrade to the latest stable
version of PowerShell available, which as of this writing is version 5.1.14393.

The powershell step

node {
    powershell &#x27;Write-Output &quot;Hello, World!&quot;&#x27;
}

Using Microsoft PowerShell in Pipeline

Writing PowerShell code as part of your pipeline is incredibly simple. The step that you will use is
simply powershell, and it includes the same optional parameters as the
Windows Batch ( bat) step, including:

returnStdout: Returns the standard output stream with a default encoding of UTF-8 (alternative encoding is optional)

returnStatus: Returns the exit status (integer) of the PowerShell script

Examples

Capture exit status of a PowerShell script

node {
    def status = powershell(returnStatus: true, script: &#x27;ipconfig&#x27;)
    if (status == 0) {
        // Success!
    }
}

Capture and print the output of a PowerShell script

node {
    def msg = powershell(returnStdout: true, script: &#x27;Write-Output &quot;PowerShell is mighty!&quot;&#x27;)
    println msg
}

Which streams get returned when I use returnStdout?

Until the release of PowerShell 5, there were five distinct output streams. PowerShell 5 introduced a sixth stream for pushing &quot;informational&quot; content,
with the added benefit of being able to capture messages sent to Write-Host. Each row of the following table describes a PowerShell stream along with
the corresponding Cmdlet used for writing to the stream for that particular row. Please keep in mind that stream 6 and associated cmdlets either
do not exist or exhibit alternate behavior in versions of PowerShell earlier than version 5.

Stream
Description
Cmdlet

1
Output stream (e.g. stdOut)
Write-Output

2
Error stream (e.g. stdErr)
Write-Error

3
Warning stream
Write-Warning

4
Verbose stream
Write-Verbose

5
Debug stream
Write-Debug

6
Information stream
Write-Information (or Write-Host with caveats)

If you are using the returnStdout option of the powershell Pipeline step
then only stream 1 will be returned, while streams 2-6 will be redirected to
the console output. For example:

Write to all available streams and return the standard output

node {
    def stdout = powershell(returnStdout: true, script: &#x27;&#x27;&#x27;
        # Enable streams 3-6
        $WarningPreference = &#x27;Continue&#x27;
        $VerbosePreference = &#x27;Continue&#x27;
        $DebugPreference = &#x27;Continue&#x27;
        $InformationPreference = &#x27;Continue&#x27;

        Write-Output &#x27;Hello, World!&#x27;
        Write-Error &#x27;Something terrible has happened!&#x27;
        Write-Warning &#x27;Warning! There is nothing wrong with your television set&#x27;
        Write-Verbose &#x27;Do not attempt to adjust the picture&#x27;
        Write-Debug &#x27;We will control the horizontal.  We will control the vertical&#x27;
        Write-Information &#x27;We can change the focus to a soft blur or sharpen it to crystal clarity.&#x27;
    &#x27;&#x27;&#x27;)
    println stdout
}

Console output:

[Pipeline] {
[Pipeline] powershell
[TestStreams] Running PowerShell script
\workspace\TestStreams@tmp\durable-4d924c2d\powershellScript.ps1 : Something terrible has
happened!
At \workspace\TestStreams@tmp\durable-4d924c2d\powershellMain.ps1:2 char:1
+ &amp; &#x27; \workspace\TestStreams@tmp\durable-4d924c ...
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : NotSpecified: (:) [Write-Error], WriteErrorException
    + FullyQualifiedErrorId : Microsoft.PowerShell.Commands.WriteErrorException,powershellScript.ps1

Warning! There is nothing wrong with your television set
Do not attempt to adjust the picture
We will control the horizontal.  We will control the vertical
We can change the focus to a soft blur or sharpen it to crystal clarity.
Hello, World!
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
ERROR: script returned exit code 1
Finished: FAILURE

Note that &quot;Hello, World!&quot; gets printed last even though it is the first output
statement in my script.  Another interesting aspect of this example is that the
powershell step failed, which ultimately caused the job to fail. The failure
in this example is due to the PowerShell error stream being non-empty, which
therefore caused the step to result in a non-zero exit status. However, as you
will soon discover, there are a variety of causes for a failing powershell
step.

What causes a failing exit status?

When you execute a powershell step, it may produce a non-zero exit code and
fail your pipeline build.  This is very similar to other shell steps with some
interesting caveats. Your powershell step may produce a failing exit status
in the following instances:

Something in your PowerShell script has thrown an exception

Your PowerShell script explicitly calls exit with a non-zero exit code

Your PowerShell script calls a native application that produces a non-zero $LastExitCode

$LastExitCode is an automatic variable that is set after executing a native application

Your PowerShell script results in a non-empty error stream (with or without throwing an exception)

Overriding the exit status behavior of your powershell step can be achieved
by explicitly exiting from your script as long as the failure was not caused by
an unhandled exception. For example:

Unavoidable failure caused by an unhandled exception

node {
    powershell &#x27;&#x27;&#x27;
        throw &#x27;Error! Problem Exists Between Keyboard And Chair&#x27;
        exit 0  # Unreachable code
    &#x27;&#x27;&#x27;
}

Failed step caused by a non-empty error stream

node {
    powershell &#x27;&#x27;&#x27;
        Write-Error &#x27;Error! Problem Exists Between Keyboard And Chair&#x27;
    &#x27;&#x27;&#x27;
}

Failure prevented by an explicit exit

node {
    powershell &#x27;&#x27;&#x27;
        Write-Error &#x27;Error! Problem Exists Between Keyboard And Chair&#x27;
        exit 0
    &#x27;&#x27;&#x27;
}

Scripts vs. Cmdlets

A Cmdlet is a small lightweight utility written in either C#, and compiled, or
written in PowerShell directly. Depending on what your goal is in your pipeline
you can make use of Cmdlets directly in your pipeline code, call a self
contained PowerShell script, or some mixture of the two. If your strategy is to
keep each powershell step as short and succinct as possible then it may make
sense for you to write a library of Cmdlets, but if you have monolithic scripts
then it may make sense for you to call those scripts directly from your
pipeline. The choice is entirely up to you, as both scenarios are supported.

Thanks for reading, and have fun!

I sincerely hope that this post has encouraged you to try using PowerShell in
your Jenkins Pipeline. Please do not hesitate to file an issue against the
durable-task
plugin on
JIRA
if you have discovered any problem that you suspect is related to the
powershell step.  For general PowerShell related issues or inquiries
please route your questions to the
PowerShell community.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/gabloe/">Gabriel Loewen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/durable-task">durable-task</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/powershell">powershell</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/07/27/standardizing-builds-with-shared-libraries/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">27</div></div><h5 class="title">Codifying the Build and Release Process with a Pipeline Shared Library</h5></div><p class="teaser">This is a guest post by Alvin Huang, DevOps Engineer at
FireEye.

As a security company, FireEye relentlessly protects our customers from cyber attacks. To act
quickly on intelligence and expertise learned, the feedback loop from the front lines to features
and capabilities in software must be small. Jenkins helps us achieve this by allowing us to build,
test, and deploy to our hardware and software platforms faster, so we can stop the bad guys
before they reach our customers.

More capabilities and functionalities in our product offerings means more applications and
systems, which means more software builds and jobs in Jenkins. Within the FaaS (FireEye as a
Service) organization, the tens of Jenkins jobs that were manageable manually in the web GUI
quickly grew to hundreds of jobs that required more automation. Along the way, we outgrew
our old legacy datacenter and were tasked with migrating 150+ Freestyle jobs on an old 1.x
Jenkins instance to a newer 2.x instance in the new datacenter in 60 days.

Copying Freestyle job XML configuration files to the new server would leave
technical debt.  Using Freestyle job templates would be better but for
complicated jobs that require multiple templates, this would still create large
dependency chains that would be hard to trace in the log output. Finally,
developers were not excited about having to replicate global changes, such as
add an email recipient when a new member joins the team, across tens of jobs
manually or using the
Configuration
Slicer. We needed a way to migrate the jobs in a timely fashion while getting
rid of as much technical debt as possible.

Jenkins Pipeline to the rescue! In 2.0, Jenkins added the capability to create pipelines as first-
class entities. At FireEye, we leveraged many of the features available in pipeline to aid in the
migration process including the ability to:

create Pipeline as Code in a Jenkinsfile stored in SCM

create Jenkins projects automatically when new branches or repos get added with a Jenkinsfile

continue jobs after the Jenkins controller or build agent crashes

and most importantly, build a Pipeline
Shared Library that keeps projects
DRY and
allows new applications to be on boarded into Jenkins within seconds

However, Jenkins Pipeline came with a DSL that our users would have to learn to translate their
Freestyle jobs to pipeline jobs. This would be a significant undertaking across multiple teams
just to create Jenkins jobs. Instead, the DevOps team identified similarities across all the
Freestyle jobs that we were migrating, learned the Jenkins DSL to become SMEs for the
organization, and built a shared library of functions and wrappers that saved each Dev/QA
engineer hours of time.

Below is an example function we created to promote builds in Artifactory:

vars/promoteBuild.groovy

def call(source_repo, target_repo, build_name, build_number) {
    stage(&#x27;Promote to Production repo&#x27;) {
        milestone label: &#x27;promote to production&#x27;
        input &#x27;Promote this build to Production?&#x27;

        node {
            Artifactory.server(getArtifactoryServerID()).promote([
                &#x27;buildName&#x27;   : build_name,
                &#x27;buildNumber&#x27; : build_number,
                &#x27;targetRepo&#x27;  : target_repo,
                &#x27;sourceRepo&#x27;  : source_repo,
                &#x27;copy&#x27;        : true,
            ])
    }
}

def call(source_repo, target_repo) {
    buildInfo = getBuildInfo()

    call(source_repo, target_repo, buildInfo.name, buildInfo.number)
}

Rather than learning the Jenkins DSL and looking up how the Artifactory Plugin worked in
Pipeline, users could easily call this function and pass it parameters to do the promotion work
for them. In the Shared Library, we can also create build wrappers of opinionated workflows,
that encompasses multiple functions, based on a set of parameters defined in the Jenkinsfile.
In addition to migrating the jobs, we also had to migrate the build agents. No one knew the
exact list of packages, versions, and build tools installed on each build server, so rebuilding
them would be extremely difficult. Rather than copying the VMs or trying to figure out what
packages were on the build agents, we opted to use Docker to build containers with all
dependencies needed for an application.

I hope you will join me at my Jenkins World session:
Codifying the Build and Release Process with a Jenkins
Pipeline Shared Library, as I deep dive into the inner workings of our Shared
Pipeline Library and explore how we integrated Docker into our CI/CD pipeline.
Come see how we can turn a Jenkinsfile with just a set of parameters like this:

Jenkinsfile

standardBuild {
    machine          = &#x27;docker&#x27;
    dev_branch       = &#x27;develop&#x27;
    release_branch   = &#x27;master&#x27;
    artifact_apttern = &#x27;*.rpm&#x27;
    html_pattern     = [keepAll: true, reportDir: &#x27;.&#x27;, reportFiles: &#x27;output.html&#x27;, reportName: &#x27;OutputReport&#x27;]
    dev_repo         = &#x27;pipeline-examples-dev&#x27;
    prod_repo        = &#x27;pipeline-examples-prod&#x27;
    pr_script        = &#x27;make prs&#x27;
    dev_script       = &#x27;make dev&#x27;
    release_script   = &#x27;make release&#x27;
}

and a Dockerfile like this:

Dockerfile

FROM faas/el7-python:base

RUN yum install -y python-virtualenv \
        rpm-build &amp;&amp; \
        yum clean all

Into a full Jenkins Pipeline like this:

As we look ahead at FireEye, I will explore how the Shared Library sets us up for easier future
migrations of other tools such as Puppet, JIRA, and Artifactory, and easier integration with new
tools like Openshift. I will also cover our strategies for deployments and plans to move to
Declarative Pipeline.

Alvin will be
presenting
more on this topic at
Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/JenkinsWorld">JenkinsWorld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/03/jenkinsworld-ask-the-experts/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 3</div></div><h5 class="title">Ask the Experts at Jenkins World 2017</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

There are less than four weeks left until Jenkins World 2017. As usual, Jenkins
World would not be complete without the Jenkins projects&#x27; &quot;Ask the Experts&quot;. If
you are new to Jenkins World, the Jenkins project booth will be located on the
expo floor where contributors to the project hang out, share demos, and
help users via the &quot;Ask the Experts&quot; program. I hope you will be pleasantly
surprised at the amount of 1-on-1 learning to be had in the booth!

We have a great list of experts who have volunteered to help staff the booth,
including many frequent contributors, JAM organizers, and board members:

Daniel Beck - Core, security, Jenkins supporting infra and developer supporting infra, project processes and governance

Steven Christou - Plugins

R. Tyler Croy - Pipeline, Docker,  governance

Nicolas De Loof - Docker

James Dumay - Blue Ocean, Pipeline, Jenkins future

Damien Duportal - Docker, Infra/Virtualization, Provisioning Systems (ansible,chef, etc.), Pipeline

Tom Fennelly - Blue Ocean, general frontend stuff, general Jenkins stuff

Jesse Glick - Core, Pipeline, security, Jenkins dev infra, Mercurial, …

Michael Hutterman - DevOps

Baptiste Mathus - Governance, infra, Pipeline, HOSTING

Michael Neale - Docker, Blue Ocean

Oleg Nenashev - Jenkins core, Jenkins administration, remoting

Liam Newman - Pipeline, Jenkins 2

James Nord - Maven, plugins

Sam Van Oort - Pipeline, performance/scalability, Linux, Docker

Chris Orr -  Android development, Jenkins dev infra

Carlos Sanchez - Docker, Mesos, Kubernetes

Bobby Sandell - Gerrit, Declarative Pipeline, core

Thorsten Scherler - Blue Ocean, front-end

Eric Smalling - Docker, config management (Puppet, some Ansible), VMware solutions, running Jenkins at large scale and general enterprise SDLC

Olivier Vernin - Infra, Docker

Mark Waite - Git, Git plugin, Git client plugin

Owen Mehegan - GitLab plugin

Don’t have questions? Stop by anyways to say ‘hello’ and pick up some stickers.

If you are an active member of the Jenkins community and/or a contributor,
consider taking part in the &quot;Ask the Experts&quot; program. It’s a great opportunity
to bond with other contributors and talk with fellow Jenkins users.

Join the Jenkins project at
Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/07/intro-to-plugin-development/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 7</div></div><h5 class="title">Plugin Development Tutorials, Videos, and More</h5></div><p class="teaser">This is a guest post by Mark Waite, who maintains
the git plugin,
the git client plugin,
and is a technical evangelist for CloudBees, Inc.

While developing the &quot; Intro to Plugin Development&quot;
workshop for Jenkins World 2017, I was impressed by the many Jenkins plugin development videos, tutorials, and guides.
Here are some of my favorite plugin development topics and links.

Plugin tutorial videos

Jenkins Online Meetup Plugin Development Part 1 - Basics - Steven Christou and Jesse Glick

Jenkins Online Meetup Plugin Development Part 2 - Web UI - Daniel Beck and Tom Fennelly

Writing your third plugin - Justin Ryan

Jenkins Hackathon session at TNG Technology Consulting - Kohsuke Kawaguchi

Plugin tutorial pages

Tutorial on jenkins.io

Install a Java Development kit, for example AdoptOpenJDK 8 or 11

Install the latest maven release

Install your IDE (I like Netbeans, has the Jenkins/Stapler plugin to make plugin creation as easy as menu:File[New Project &gt; Maven &gt; Jenkins Plugin])

More details

Many of the Jenkins plugin development topics have dedicated pages of their own, including user interface, plugin testing, and javadoc.

User interface

UI samples plugin (bars, boxes, buttons, lists, notification, and syntax highlighting)

Understanding Jelly Tags from the Jenkins wiki

Form Validation from the Jenkins wiki

Jelly Form Controls from the Jenkins wiki

Jelly Tag Library Reference from jenkins.io

DataBoundConstructor in Basic Guide to Jelly usage

DataBoundSetter in google groups

Testing a plugin

Unit test from the Jenkins wiki

Jenkins test objects like JenkinsRule and the WithoutJenkins annotation

DataBoundConstructor in Basic Guide to Jelly usage

DataBoundSetter in google groups

Java unit testing tools like Hamcrest and AssertJ (and JenkinsMatchers)

Java unit testing rules like TemporaryFolder, Timeout, and DisableOnDebug

Java unit testing classes like Assume and Parameterized

Java unit testing mock frameworks like mockito and powermock

Javadoc

Jenkins core javadoc

Jenkins plugins javadoc

Extension Points

List of Jenkins core extension points and all Jenkins extension points

Custom build steps

Adding a custom build step

Actions

Jenkins Action and its subtypes

Mark will be presenting
Intro to Plugin Development
at
Jenkins World in August.
Register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/07/security-advisory/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 7</div></div><h5 class="title">Important security updates for multiple Jenkins plugins</h5></div><p class="teaser">Multiple Jenkins plugins received updates today that fix several security vulnerabilities, including multiple high severity ones.

We strongly recommend updating the following plugins as soon as possible:

Blue Ocean

Pipeline: Groovy Plugin

Script Security Plugin

Less severe security updates have been released for these plugins:

Config File Provider Plugin

Datadog Plugin

Deploy to container Plugin

DRY Plugin

Pipeline: Input Step Plugin

Static Analysis Utilities Plugin

Additionally, the OWASP Dependency-Check Plugin recently also received a security update.

For an overview of what was fixed, see the security advisory.

Subscribe to the jenkinsci-advisories mailing list to receive important future notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/08/introducing-jenkins-minute/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 8</div></div><h5 class="title">Introducing the Jenkins Minute video series</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

There are less than three weeks left until
Jenkins World 2017.
Like last year, I’ll be at the
&quot; Ask the Experts&quot;
booth to answer questions about all things Jenkins.
In preparation, I’ve started a continuing series of quick tutorial videos that answer
some of the most common questions I’ve seen asked in the community forums.
These  are by no means exhaustive - they’re basic answers, which we can build upon.
Each video give a takes a simple example, shows how to create a working solution,
and includes links in the description to related Jenkins documentation pages.

I hope you find them useful.  Look for more of them coming soon!

Liam will be at the
&quot; Ask the Experts&quot;
booth at
Jenkins World in August.
Register with the code JWFOSS for a 30% discount off your pass.

Creating Your First Pipeline in Blue Ocean

Using a Dockerfile with Jenkins Pipeline

Adding Parameters to Jenkins Pipeline

Recording Test Results and Archiving Artifacts<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-minute">jenkins-minute</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/10/kubernetes-with-pipeline-acs/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">10</div></div><h5 class="title">CI/CD with Jenkins Pipeline and Azure</h5></div><p class="teaser">This is a guest post by Pui Chee Chen,
Product Manager at Microsoft working on
Azure
DevOps open source integrations.

Recently, we improved the Azure Credential plugin by
adding a custom binding for Azure Credentials which allows you to use an
Azure
service principal (the analog to a service or system account) via  the
Credentials Binding plugin. This means it’s now trivial to run Azure CLI
commands from a Jenkins Pipeline. We also recently published the first version
of the Azure App Service plugin which makes it very
easy to deploy
Azure Web
Apps directly from Jenkins Pipeline. While we’ll have
much more to discuss in our Jenkins World presentation on
Azure
DevOps open source integrations, in this blog post I wanted to share some good
snippets of what is possible today with Jenkins Pipeline and Azure.

First, a simple example using the Azure CLI to list resources in the
subscription:

// Scripted //
node {
    /* .. snip .. */
    stage(&#x27;Deploy&#x27;) {
        withCredentials([azureServicePrincipal(&#x27;principal-credentials-id&#x27;)]) {
            sh &#x27;az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID&#x27;
            sh &#x27;az account set -s $AZURE_SUBSCRIPTION_ID&#x27;
            sh &#x27;az resource list&#x27;
        }
    }
}
// Declarative //

azureServicePrincipal() cannot be used in Declarative Pipeline until
JENKINS-46103 is
resolved.

Once a Pipeline can interact with Azure, there are countless ways one could
implement continuous delivery with Jenkins and Azure. From a deploying a simple
webapp with the
Azure
App Service plugin and the azureWebAppPublish step, or a more advanced
container-based delivery pipeline to deliver new containers to
Kubernetes
via Azure Container Service.

With the Docker Pipeline plugin and a little bit of
extra scripting, a Jenkins Pipeline can also build and publish a Docker
container to an
Azure
Container Registry :

// Scripted //
import groovy.json.JsonSlurper

node {
    def container
    def acrSettings

    withCredentials([azureServicePrincipal(&#x27;principal-credentials-id&#x27;)]) {
        stage(&#x27;Prepare Environment&#x27;) {
            sh &#x27;az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID&#x27;
            sh &#x27;az account set -s $AZURE_SUBSCRIPTION_ID&#x27;
            acrSettings = new JsonSlurper().parseText(
                                            sh(script: &quot;az acs show -o json -n my-acr&quot;, returnStdout: true))
        }

        stage(&#x27;Build&#x27;) {
            container = docker.build(&quot;${acrSettings.loginServer}/my-app:${env.BUILD_ID}&quot;)
        }

        stage(&#x27;Publish&#x27;) {
            /* https://issues.jenkins.io/browse/JENKINS-46108 */
            sh &quot;docker login -u ${AZURE_CLIENT_ID} -p ${AZURE_CLIENT_SECRET} ${acrSettings.loginServer}&quot;
            container.push()
        }

        stage(&#x27;Deploy&#x27;) {
            echo &#x27;Orchestrating a new deployment with kubectl is a simple exercise left to the reader ;)&#x27;
        }
    }
}
// Declarative //

If you have been following our
Azure Blog, you may
have noticed we have shipped a lot of updates to provide better support for
Azure on Jenkins, and vice versa, such as:

Hosted Jenkins. New
Solution
Template in Azure Marketplace lets you spin up a
Jenkins Controller on Azure in minutes. Not only is it easy and fast, the solution
template gives you option to scale up by selecting the VM disk type and size.
And guess what? You can even select the Jenkins release type you want to use -
LTS, weekly build or Azure verified - all under your control.

Continuous integration experience. In the latest version of our
Azure VM Agents plugin, we improved the user
experience and added the option to let you to select Managed Disk for disk
type (which is currently used extensively on
ci.jenknis.io. You no longer need to worry about
exceeding the number of VMs on your subscription.

Continuous deployment experience. Now, if
Azure CLI is not your cup of tea, we released our first plugin to provide
continuous deployment support to Azure App Service. The plugin supports all
languages Azure App Service supports. We even have a walkthrough
here in the
brand new Jenkins Hub where you can find all Jenkins on Azure resources.

Pipeline readiness. Also, all Azure plugins are and will be pipeline ready.
Have you been leveraging our
Azure Storage plugin in your Pipeline?

So, what’s next? We have a big surprise in store at Jenkins World! :)

We are serious about supporting open source and the open source community.
Be sure to catch our talk on
Azure
DevOps open source integrations.
See you at
Jenkins World 2017!

Join the Azure DevOps team at
Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/11/remoting-update/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">11</div></div><h5 class="title">Remoting Update. Protocols deprecation, Java 8 requirement and plans</h5></div><p class="teaser">Updated on Jan 10, 2019: The deprecated protocols were removed in Remoting 3.40+ and Jenkins 2.214+.
See jira:JENKINS-60381[Remove old, deprecated Remoting protocols] for more information and links.

There are upcoming changes in Jenkins &quot;core&quot; which may require extra steps
when upgrading Jenkins.  If you use configuration management for Jenkins
agents, please read this announcement carefully.

If you have ever seen messages like &quot;Channel is already closed&quot; or &quot;Remote call failed&quot; in your build logs,
you have already met Jenkins Remoting.

Remoting is an agent executable and a library implementing the communication layer between Jenkins controllers and their agents (including communication protocols, distributed calls and classloading).
It is also used in several other cases: Maven Integration Plugin, Remoting-based CLI, etc.

In order to make it clear what’s changing in Jenkins Remoting, I have documented the various components on
the Remoting’s sub-project page, and will try to publish regular updates about the status of
Remoting to this site and the developer mailing list.

In this post I would like to provide an update on the Remoting roadmap and to announce two major incoming changes: deprecation of old protocols and upgrade to Java 8.
Both changes will take place in one of the next Weekly releases.
ETA is Jenkins 2.75 on Aug 20, 2017.

Below are details on the incoming changes and compatibility notes.

Old Remoting Protocols Deprecation

It has been almost one year since the release of JNLP4-connect protocol in Remoting 3.0.
This protocol has been enabled by default since 2.46.x, and so far it demonstrates good stability being compared to JNLP2 and JNLP3 protocols.

At the governance meeting
we decided to disable old Remoting protocols (JNLP/JNLP2 + CLI1) in new installations by default.
There are 3 reasons for it:

Maintenance of multiple protocols takes a lot of extra effort.
The JNL2 NIO engine is complex and barely diagnosable.

There are known issues in JNLP2 connection management (see the protocol’s Errata). In many cases update to JNLP4 was a resolution

JNLP1/JNLP2/CLI1 are unencrypted, and it is not something Jenkins users may expect in 2017

It is tracked as JENKINS-45841 in Jenkins JIRA.

How?

When Jenkins is started in the new installation mode with enabled Installation Wizard, old protocols will be disabled

Jenkins shows an administrative warning when obsolete protocols are enabled

Compatibility notes

Older instances won’t be affected by the disabling of the older JNLP1/JNLP2 protocols, which will still be enabled for them.
Newly created instances which skip, or disable, the Setup Wizard will not be affected either.

&quot;New&quot; Jenkins instances installed via setup wizard may be affected in edge cases. For example:

Agents with Remoting older than 3.0 will be unable to connect.

Mitigation: Before updating make sure Remoting is not bundled custom Docker images, AMIs, etc.

Swarm Plugin: old versions of Swarm Client (before 3.3) will be unable to connect to Jenkins, because Remoting 2.x is bundled

Mitigation : Update Swarm Client

Very old jenkins-cli.jar without CLI2 support will be unable to connect.

Mitigation : Do not use Remoting-based CLI on new instances (see this blogpost)

Upgrade to Java 8

Starting with version 2.54, Jenkins requires Java 8 to run
( announcement blog post).
This version is also required for Jenkins LTS 2.60.1.

Remoting continued to support Java 7 for a while for backporting purposes,
but it will be also upgraded to Java 8 in the Remoting 3.11 release.
This Rremoting version is expected to be available in Jenkins 2.75 (ETA: Aug 20, 2017).
This change is tracked as JENKINS-43985.

Compatibility notes

The update does not cause compatibility issues in common use-cases.
However, there may be issues in custom Jenkins core builds and packaging.
There are several examples below.

Jenkins instances with built-in Remoting versions will NOT be affected, Java 8 is already required there

Users of community-provided Docker packages ( docker-agent,
docker-inbound-agent) will NOT be affected,
Java 8 is already required there

Custom Jenkins WAR file builds targeting Java 7 may fail to build/run if they bundle Remoting 3.11 or later

Custom Jenkins agent instances (manually installed hosts, VM snapshots, Docker packages, AMIs, etc.) may fail if they download the latest Remoting version and use Java 7

Java 9 support

As with Jenkins core, Java 9 not supported and not tested in Remoting.
It may work in some configurations, but it is not guaranteed.

As a consequence, it is not recommended to run Remoting with Java 9 right now.
It is also not recommended to use Maven Integration Plugin to run builds on Java 9.

What’s next?

There are some ongoing activities in the Remoting sub-project:

Stability and Diagnosability improvements
( JENKINS-38833)

Why? When it comes to Remoting issues, it is really hard to diagnose them

Recently I have published some slides about preventing and diagnosing issues, but I want the behavior to be more stable by default

This Epic lists my plans about Remoting issues and papercuts I would like to fix this year

Remoting Work Directories
( JENKINS-44108)

For a long time logging was disabled by default in Java Web Start (JNLP) and SSH agents, because Remoting had no option to determine where to store such data before connecting to the controller

The new Remoting Work Directory feature (since Remoting 3.8) offers such storage, which is also used for storing JAR caches and for checking workspace writeability before accepting builds.

This Epic is about enabling Remoting work directories by default in common Agent launcher types.

Remoting Upgradeability
( JENKINS-44099)

Right now Remoting is not being upgraded automatically on JNLP agents, it is supported only for Windows service agents starting from Jenkins 2.50

On the Jenkins controller side it is required to upgrade the Jenkins core in order to pick Remoting fixes.

This Epic aims simplifying the upgrade procedure for most common cases.

If you are interested in contributing to these tasks, or others in the Remoting
sub-project, please feel free to reach out via the issue tracker or
#jenkins IRC channel.

If you are coming to Jenkins World, you can also find me at the &quot;Ask the Experts&quot; booth there.
See more info about Ask the Experts here.

Useful links

Remoting Sub-Project on Jenkins website

Remoting Release Notes

Remoting documentation on GitHub

My slides about Remoting issues troubleshooting<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/agents">agents</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/upgrade">upgrade</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/17/speaker-blog-blazemeter/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Running load tests in Jenkins Pipeline with Taurus</h5></div><p class="teaser">This is a guest post by Guy Salton, Sr. Professional Services Engineer for
CA BlazeMeter.

Jenkins
Pipeline is an important Jenkins feature for creating and managing a project
in Jenkins. This is opposed to the traditional way of creating a Jenkins
project by using the Jenkins GUI. When running your open-source load test,
Jenkins Pipeline enables resilience, execution control, advanced logic and
Version Control management.  This blog post will explain how to run any
open-source load test with Jenkins Pipeline, through Taurus.

Taurus is an open source test automation framework
that enables running and analyzing tests from 9 open source load and functional
testing tools: JMeter,
Selenium, Gatling, The Grinder, Locust, Tsung, Siege, Apache Bench, and PBench.
Test results can be analyzed in Taurus. For advanced analyses or running tests
in the cloud, Taurus integrates with
BlazeMeter.

Guy will be
presenting
more on this topic at
Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.

Getting started with Taurus

Install Taurus.

Create the following Taurus configuration in YAML. Learn more about YAML in Taurus from
this tutorial.

## execution:
- concurrency: 100
  hold-for: 10m
  ramp-up: 120s
  scenario: Thread Group
scenarios:
  Thread Group:
    requests:
    - label: blazedemo
      method: GET
      url: http://blazedemo.com/

This script runs 100 concurrent users, holds the load for 10 minutes, the
ramp-up is 120 seconds and the thread group runs one GET request to
blazedemo.com.

You can specify an executor by adding executor: to the
script. Otherwise, the default executor will be JMeter. In the background,
Taurus will create an artifact directory with a jmx file (or a Scala file if
you run Gatling, a Python file if you are running Selenium, etc.).

Open a terminal and run: bzt.yml

View the test results:

If you want to conduct an in-depth analysis of your test results, run your
tests on BlazeMeter. You will be able to monitor KPIs through advanced and
colorful reports, evaluate system health over time, and run your tests from
multiple geo-locations.

Run the following command from the terminal:

bzt.yml -report

Integrate Taurus With Pipeline

To run Taurus through Pipeline, you can also go
straight to Jenkins after creating your Taurus script.

Open Jenkins → New Item → Fill in an item name → Click on ‘Pipeline’

Now create a Pipeline script. You can include all parts of
your CI/CD process in this script: Commit, Build, Unit Test, Performance Test,
etc., by creating different stages.

This Pipeline has three stages: The first is called “build”. In this example it
is empty, but you can add commands that will build your code. The second,
called “Performance Tests”, creates a folder called “Taurus-Repo” and runs the
Taurus script that we created. At the same time (note the “parallel” command),
there is a “sleep” command for 60 seconds. Obviously it makes no sense to put
those two commands together, this is just to show you the option of running 2
commands in parallel. The third stage called “Deploy” is also empty in this
example. This is where you could deploy your new version.

node {
   stage(&#x27;Build&#x27;) {
      // Run the Taurus build
   }
   stage(&#x27;Performance Tests&#x27;) {
    parallel(
        BlazeMeterTest: {
            dir (&#x27;Taurus-Repo&#x27;) {
                sh &#x27;bzt.yml -report&#x27;
            }
        },
        Analysis: {
            sleep 60
        })
   }

   stage(‘Deploy’) {
   }
}

Note that you can either add the Pipeline inline, or choose the “Pipeline
script from SCM” option and add the URL to the script on GitHub (in this case
you need to upload a Jenkinsfile to GitHub). With &quot;Pipeline from SCM&quot;,
whenever you need to update the tests, you can just add new commits to the
Jenkinsfile.

Save the Pipeline

Click on ‘Build Now’ to run the Pipeline

Click on the new Build that is running now (build #6 in this example).

Click on ‘Console Output’ to see the test results:

In the Console Output you can see the test results and also the link to the report in BlazeMeter.

That’s it! Jenkins Pipeline is now running open-source load testing tools via Taurus.

Come to
my
free hands-on workshop “Learn to Release Faster by Load Testing With Jenkins”
at Jenkins World 2017 on Tuesday August 29th from 1-5pm.  You will learn how to
test continuously with Jenkins, JMeter, BlazeMeter and Taurus, including how to
run JMeter with Jenkins, run the BlazeMeter plugin for Jenkins and how to use
open-source Taurus.

To learn more about BlazeMeter,
click here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/hinman/">Hannah Inman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/18/declarative-pipelines-at-jenkinsworld/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">18</div></div><h5 class="title">Declarative Pipeline at Jenkins World</h5></div><p class="teaser">This is a guest post by Andrew Bayer, who is
one of the authors of the
Declarative Pipeline plugin,
and is a software engineer on the Pipeline team at
CloudBees, Inc.

A year ago at Jenkins World 2016, we unveiled Declarative Pipeline, a
structured way to define your Pipeline. It’s been a great year for Declarative
and Pipeline in general, with the release of Declarative Pipeline 1.0 in
February, multiple releases since then, the introduction of
documentation on Pipeline at jenkins.io,
with a focus on Declarative, and more. Given everything that’s happened over
the last year, we thought it’d be good to let you all know what you can expect
to see and hear about Declarative Pipeline at this year’s Jenkins World.

First, on Thursday, August 31, I’ll be giving a talk on Declarative Pipeline
with Robert Sandell, one of my coworkers
here at CloudBees and another author of Declarative Pipeline. We’ll be
covering what’s happened with Declarative over the last year, new features
added since the 1.0 release, such as the libraries directive and more when
conditions, what’s planned for the upcoming 1.2 release (which is planned for
shortly after Jenkins World!), including parallel stage s, and what’s on the
roadmap for the future. In addition, we’ll be demoing some of the features in
1.2, and providing some pointers on best practices for writing your Declarative
Pipeline.

Also on Thursday, Stephen Donner from Mozilla
will be giving a demo showing Mozilla’s usage of Declarative Pipeline and
shared libraries at the Community Booth - Mozilla has been doing great work
with Declarative, and I’m excited to see their usage in more detail and hear
Stephen talk about their experience!

In addition, Robert, Stephen, and myself will all be at Jenkins World both days
of the main sessions, and Robert and myself will also be at the
Contributor Summit
on Tuesday. We’d love to hear your thoughts on Declarative and will be happy to
answer any questions that we can. Looking forward to seeing you all!

Andrew Bayer and Robert Sandell will be talking about the latest on
Declarative Pipeline in Jenkins
at Jenkins World in August,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/21/jenkins-world-demos/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">21</div></div><h5 class="title">Demos at Jenkins World 2017</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

Jenkins World 2017 is a week
away. Like last year, we are bringing back the lunch-time demos in the Jenkins
project’s booth.
These are quick 15 minute How-to demos by Jenkins
experts.
These demos will not be live streamed, nor recorded, so come early to get the
front row seat, we are expecting a large crowd!

Wednesday, August 30th

Time
Session
Details
Presenter

12:15 - 12:30
Delivery Pipelines with Jenkins
How to set up holistic Delivery Pipelines with the DevOps enabler tool Jenkins.
Michael Hutterman

12:30 - 12:45
Developing Pipeline Libraries Locally
If you have ever tried developing Pipeline Libraries, you may have noticed how long it takes to deploy a new version to server to discover just another syntax error. I will show how to edit and test Pipeline libraries locally before committing to the repository (with Configuration-as-Code and Docker).
Oleg Nenashev

12:45 - 13:00
Securing a Jenkins Instance
A set of minimum steps every Jenkins Admin should follow so his public-facing Jenkins instance doesn’t turn into a Bitcoin mine.
Claudiu Guiman

13:00 - 13:15
Git Tips and Tricks
Latest capabilities in the git plugin, like large file support, reference repositories and some reminders of existing tips that can reduce server load, decrease job time, and decrease disc use.
Mark Waite

13:15 - 13:30
Delivery Pipelines with Jenkins 2
How to promote Java EE and Docker binaries toward production.
Michael Hutterman

13:30 - 13:45
Delivery Pipelines, with Jenkins 2, SonarQube, and Artifactory
The nuts and bolts of setting up a scalable, high-end delivery pipeline.
Michael Hutterman

13:45 - 14:00
Visual Pipeline Creation in Blue Ocean
We will show how to use Blue Ocean to build a real-world continuous delivery pipeline using the visual pipeline editor. We will coordinate multiple components of a web application across test and production environments, simulating a modern development and deployment workflow.
Keith Zantow

Thursday, August 31st

Time
Session
Details
Presenter

12:30 - 12:45
Docker Based Build Executor Agents
How using Docker based build agents can simplify your Jenkins management duties.
Eric Smalling

12:45 - 13:00
Pimp my Blue Ocean
How to customize Blue Ocean, where I create a custom plugin and extending Blue Ocean with custom theme and custom components.
Thorsten Scherler

13:00 - 13:15
Deliver Blue Ocean Components at the Speed of Light
Using storybook.js.org for Blue Ocean frontend to speed up the delivery process - validate with PM and designer the UX. Showing how quickly you develop your components.
Thorsten Scherler

13:15 - 13:30
Mozilla’s Declarative + Shared Libraries Setup
How Mozilla is using Declarative Pipelines and shared libraries together.
Stephen Donner

Join the Jenkins project at
Jenkins World on August 30-31,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/23/pull-requests-and-more/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">23</div></div><h5 class="title">Jenkins Needs You - Pull Request Corner at Jenkins World 2017</h5></div><p class="teaser">This is a guest post by Mark Waite, who maintains
the git plugin,
the git client plugin,
and is a technical evangelist for CloudBees, Inc.

The Jenkins project booth at Jenkins World 2017
will include the &quot;Pull Requests Corner&quot;, recruiting new Jenkins contributors.
We think there are many people who will attend the conference without realizing how easy it is
to help the Jenkins project, and how much the help is appreciated.

Meet us in the &quot;Pull Requests Corner&quot; and we’ll help you find a way to help Jenkins.
Here are some areas where we can use your help.
Most of them do not require coding, and do not require a large time commitment.

One Minute Feedback on Your Version

The Jenkins changelog pages ( LTS and weekly) gather user experiences with specific Jenkins versions.
You can help other Jenkins users by clicking one of the weather icons in the LTS changelog (or the weekly changelog) for the release you’re using.
Changelog feedback from weekly releases helps the release team select the long term support version.
Changelog feedback from LTS releases helps other users prepare to upgrade.

It takes less than a minute, and helps the community (which will ultimately help you).

Five Minutes to Answer a Question

In five minutes or less, you can help other Jenkins users.

For example:

Answer a question on the #jenkins channel of internet relay chat (IRC)

Answer a question on the Jenkins users mailing list

Answer a question on stackoverflow jenkins, jenkins plugins, or jenkins pipeline

Answer a question on reddit

Ten Minutes to Learn and Share

If you have ten minutes, you can learn something new and share what you learned.

Read a Jenkins community blog post and tweet it with the hashtag #jenkinsci

Read a devops.com blog post and share it on LinkedIn

Read a CloudBees blog post and test drive an idea from it

Find another Jenkins blog and share it (I recently discovered Matt Bajor’s ci/cd life blog)

Fifteen Minutes for Pipeline

Liam Newman has created the &quot; Jenkins Minute&quot; video series.
They are brief video segments focusing on specific Jenkins functionality.
Choose a video, watch it, and share what you learned on social media.

Twenty Minutes for a Bug

The Jenkins bug tracker contains thousands of bugs.
Reviewing, duplicating, and clarifying bug reports takes time.
When maintainers are reviewing, duplicating, and clarifying bug reports, they are not fixing bugs, and they are not adding new capabilities.

You can help maintainers by reviewing and duplicating a bug report that matters to you.
A comment on a bug report is especially helpful when it confirms you’ve been able to duplicate the bug.
It is even more helpful if your verification includes the steps you took and how they differ from the original report.

A bug report which has been duplicated, and includes clear instructions, is much more likely to receive maintainer attention.
Help yourself and others by duplicating bugs that matter to you.

Thirty Minutes for Documentation

The Jenkins documentation includes
user documentation ( guided tour and handbook) and
developer documentation ( tutorial, how-to guides, and reference).
You can help the documentation by describing something important to you clearly and completely.

Refer to the instructions for documentation contributors to see how easy it is to help.

Forty Five Minutes for Translation

If English is not your native language, you can help with Jenkins localization.
Jenkins is used worldwide, and many users will benefit from translations.
Considering the rapid and continuing evolution of Jenkins, it is no surprise that there is plenty to translate.
Refer to the internationalization guide for instructions to help you contribute translations.

Sixty Minutes for a Meetup

Local groups around the world meet often for Jenkins presentations, discussions, and demonstrations.
Organizing a Jenkins Area Meetup will introduce you to other users, and will let you explore new ways to benefit from Jenkins.
The team at jenkinsci-jam@googlegroups.com is ready to support your JAM with stickers, t-shirts, and more.

Week or More - Adopt a Plugin

The Jenkins plugin ecosystem covers a wide range of areas.
Jenkins plugin maintainers come from many different backgrounds, with many different interests.
Often, a plugin maintainer may find that they want to do something different on the project, or they may leave the project.
When a plugin maintainer is no longer able to maintain a plugin, they can place it for adoption.

Plugins placed for adoption range from very specific use cases (node stalker plugin) to very general use cases (Subversion plugin).

Maintaining an orphan plugin is a great way to contribute to the project.
Follow the instructions to &quot; Adopt a Plugin&quot;.

See You There!

All those techniques (and more) are available on the Jenkins participate page.

Look for the &quot;Jenkins Needs You&quot; poster at Jenkins World, and come talk
to us about the ways you can learn new things, address your concerns,
and help Jenkins.

Join the Jenkins project at
Jenkins World on August 30-31,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/08/29/2017-community-survey/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">29</div></div><h5 class="title">Take the 2017 Jenkins Survey!</h5></div><p class="teaser">This is a guest post by Brian
Dawson on behalf of CloudBees, where he works as a DevOps Evangelist
responsible for developing and sharing continuous delivery and DevOps best
practices. He also serves as the CloudBees Product Marketing Manager for
Jenkins.

Once again it’s that time of year when CloudBees sponsors the
Jenkins Community Survey to
assist the community with gathering objective insights into how jenkins is
being used and what users would like to see in the Jenkins project.

Your personal information (name, email address and company) will NOT be used by CloudBees for
sales or marketing.

As an added incentive to take the survey, CloudBees will enter participants
into a drawing for a free pass to Jenkins World 2018 (1st prize) and a $100
Amazon Gift Card (2nd prize). The survey will close at the end of September, so
click the link at the end of the blog post to get started!

All participants will be able to access reports summarizing survey results. If
you’re curious about what insights your input will provide, see the results of
last year’s 2016 survey:

2016 Community Survey Results

Your feedback helps capture a bigger picture of
community trends and needs. There are laws that govern prize giveaways and
eligibility; CloudBees has compiled all those fancy
terms and conditions here.

Please take the survey and let your voice be heard - it will take less than 10
minutes.

Take me to the survey<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/bvdawson/">Brian Dawson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/09/08/enumerators-in-pipeline/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 8</div></div><h5 class="title">Closure on enumerators in Pipeline</h5></div><p class="teaser">While at Jenkins World, Kohsuke Kawaguchi
presented two long-time Jenkins contributors with a
&quot; Small Matter of Programming&quot;
award: Andrew Bayer and
Jesse Glick. &quot;Small Matter of Programming&quot;
being:

a phrase used to ironically indicate that a suggested feature or design change
would in fact require a great deal of effort; it often implies that the person
proposing the feature underestimates its cost.

— Wikipedia

In this context the &quot;Small Matter&quot; relates to Jenkins
Pipeline and a very simple snippet of Scripted Pipeline:

[1, 2, 3].each { println it }

For a long time in Scripted Pipeline, this simply did not work as users would
expect it. Originally filed as
JENKINS-26481 in 2015,
it became one of the most voted for, and watched, tickets in the entire issue
tracker until it was ultimately fixed earlier this year.

At least some closures are executed only once inside of Groovy CPS DSL scripts
managed by the workflow plugin.

— Original bug description by Daniel Tschan

At a high level, what has been confusing for many users is that Scripted
Pipeline looks like a Groovy, it quacks like a Groovy, but it’s not exactly
Groovy. Rather, there’s an custom Groovy interpreter
( CPS) that executes the
Scripted Pipeline in a manner which provides the durability/resumability that
defines Jenkins Pipeline.

Without diving into too much detail, refer to the pull requests linked to
JENKINS-26481 for that, the code snippet above was particularly challenging to
rectify inside the Pipeline execution layer. As one of the chief architects for
Jenkins Pipeline, Jesse made a number of changes around the problem in 2016,
but it wasn’t until early 2017 when Andrew, working on Declarative Pipeline,
started to identify a number of areas of improvement in CPS and provided
multiple patches and test cases.

As luck would have it, combining two of the sharpest minds in the Jenkins
project resulted in the &quot;Small Matter of Programming&quot; being finished, and
released in May of this year with Pipeline: Groovy 2.33.

Please join me in congratulating, and thanking, Andrew and Jesse for their
diligent and hard work smashing one of the most despised bugs in Jenkins
history :).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/09/25/declarative-1.2-released/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">25</div></div><h5 class="title">Parallel stages with Declarative Pipeline 1.2</h5></div><p class="teaser">After a few months of work on its key features, I’m happy to announce the
1.2 release of
Declarative Pipeline!
On behalf of the contributors developing Pipeline, I thought it would be
helpful to discuss three of the key changes.

Parallel Stages

First, we’ve added syntax support for parallel stages. In earlier versions of
Declarative Pipeline, the only way to run chunks of Pipeline code in parallel
was to use the parallel step inside the steps block for a stage, like this:

/* .. snip .. */
stage(&#x27;run-parallel-branches&#x27;) {
  steps {
    parallel(
      a: {
        echo &quot;This is branch a&quot;
      },
      b: {
        echo &quot;This is branch b&quot;
      }
    )
  }
}
/* .. snip .. */

While this works, it doesn’t integrate well with the rest of the Declarative
Pipeline syntax. For example, to run each parallel branch on a different agent,
you need to use a node step, and if you do that, the output of the parallel
branch won’t be available for post directives (at a stage or pipeline
level). Basically the old parallel step required you to use Scripted Pipeline
within a Declarative Pipeline.

But now with Declarative Pipeline 1.2, we’ve introduced a true Declarative
syntax for running stages in parallel:

Jenkinsfile

pipeline {
    agent none
    stages {
        stage(&#x27;Run Tests&#x27;) {
            parallel {
                stage(&#x27;Test On Windows&#x27;) {
                    agent {
                        label &quot;windows&quot;
                    }
                    steps {
                        bat &quot;run-tests.bat&quot;
                    }
                    post {
                        always {
                            junit &quot;**/TEST-*.xml&quot;
                        }
                    }
                }
                stage(&#x27;Test On Linux&#x27;) {
                    agent {
                        label &quot;linux&quot;
                    }
                    steps {
                        sh &quot;run-tests.sh&quot;
                    }
                    post {
                        always {
                            junit &quot;**/TEST-*.xml&quot;
                        }
                    }
                }
            }
        }
    }
}

You can now specify either steps or parallel for a stage, and within
parallel, you can specify a list of stage directives to run in parallel,
with all the configuration you’re used to for a stage in Declarative
Pipeline. We think this will be really useful for cross-platform builds and
testing, as an example. Support for parallel stages will be in the
soon-to-be-released Blue Ocean Pipeline Editor 1.3 as well.

You can find more documentation on parallel stages in the
User Handbook.

Defining Declarative Pipelines in Shared Libraries

Until the 1.2 release, Declarative Pipelines did not officially support
defining your pipeline blocks in a shared library. Some of you may have tried
that out and found that it could work in some cases, but since it was never an
officially supported feature, it was vulnerable to breaking due to necessary
changes for the supported use cases of Declarative. But with 1.2, we’ve added
official support for defining pipeline blocks in src/.groovy files in your
shared libraries. Within your src/.groovy file’s call method, you can
call pipeline { …​ }, or possibly different pipeline { …​ } blocks
depending on if conditions and the like. Note that only one pipeline { …​ }
block can actually be executed per run - you’ll get an error if a second one
tries to execute!

Major Improvements to Parsing and Environment Variables

Hopefully, you’ll never actually care about this change, but we’re very happy
about it nonetheless. The original approach used for actually taking the
pipeline { …​ } block and executing its contents was designed almost two
years ago, and wasn’t very well suited to how you all are actually using
Declarative Pipelines. In our attempts to work around some of those limitations,
we made the parsing logic even more complicated and fragile, resulting in an
impressive
number of bugs, mainly relating to inconsistencies and bad behavior with
environment variables.

In Declarative 1.2, we’ve replaced the runtime parsing logic completely with a
far more robust system, which also happens to fix most of those bugs at the
same time! While not every issue has been resolved, you may find that you can
use environment variables in more places, escaping is more consistent,
Windows paths are no longer handled incorrectly, and a lot more. Again, we’re
hoping you’ve never had the misfortune to run into any of these bugs, but if
you have, well, they’re fixed now, and it’s going to be a lot easier for us to
fix any future issues that may arise relating to environment variables, when
expressions, and more. Also, the parsing at the very beginning of your build
may be about 0.5 seconds faster. =)

More to Come!

While we don’t have any concrete plans for what will be going into Declarative
Pipelines 1.3, rest assured that we’ve got some great new features in mind, as
well as our continuing dedication to fixing the bugs you encounter and report.
So please do keep opening tickets for
issues and feature requests. Thanks!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/09/27/sept-jenkins-online-meetup/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">27</div></div><h5 class="title">Pipeline and Blue Ocean Demos from Jenkins World</h5></div><p class="teaser">At Jenkins World last month, we continued the tradition of &quot;lunch-time demos&quot;
in the Jenkins project’s booth which we started in 2016.  We invited a number
of Jenkins contributors to present brief 10-15 minute demos on something they
were working on, or considered themselves experts in. Continuing the
post-Jenkins World tradition, we also just hosted a &quot;Jenkins Online Meetup&quot;
featuring a selection of those lunch-time demos.

I would like to thank Alyssa Tong for organizing this online meetup, Liam Newman for acting as the host, and our speakers:

Oleg Nenashev

Michael Hüttermann

Thorsten Scherler

Stephen Donner

Mark Waite

Keith Zantow

Below are some links from the sample projects demonstrated and the direct links
to each session.

Developing Pipeline Libraries Locally

Video link

If you have ever tried developing Pipeline Libraries, you may have noticed how
long it takes to deploy a new version to server to discover just another syntax
error. I will show how to edit and test Pipeline libraries locally before
committing to the repository (with Configuration-as-Code and Docker).

Slides

Source Code

Demo container

Delivery Pipelines with Jenkins

Video link

Showing off how to set up holistic Delivery Pipelines with the DevOps enabler tool Jenkins.

Demo application

Pimp my Blue Ocean

Video link

How to customize Blue Ocean, where I create a custom plugin and extending Blue
Ocean with custom theme and custom components.

Presentation and demo code

Deliver Blue Ocean Components at the Speed of Light

Video link

Using storybook.js.org for Blue Ocean frontend to speed up the delivery process
- validate with PM and designer the UX. Showing how quickly you develop your
components.

Presentation and demo code

Mozilla’s Declarative + Shared Libraries Setup

Video link

How Mozilla is using Declarative Pipelines and shared libraries together.

Google Doc with links

Shared Library source code

Documentation for the shared library

See also the #fx-test IRC channel on irc.mozilla.org

Git Tips and Tricks

Video link

Latest capabilities in the git plugin, like large file support, reference
repositories and some reminders of existing tips that can reduce server load,
decrease job time, and decrease disc use.

Visual Pipeline Creation in Blue Ocean

Video link

We will show how to use Blue Ocean to build a real-world continuous delivery
pipeline using the visual pipeline editor. We will coordinate multiple
components of a web application across test and production environments,
simulating a modern development and deployment workflow.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jam">jam</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsonlinemeetup">jenkinsonlinemeetup</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/09/29/jenkins-contributor-awards-at-jenkins-world/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">29</div></div><h5 class="title">Jenkins Contributors Awarded Top Honors at Jenkins World 2017</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

For the first time at Jenkins World, the Jenkins project honored the
achievement of three Jenkins contributors in the areas of Most Valuable
Contributor, Jenkins Security MVP, and most Valuable Advocate. These three
individuals has consistently demonstrated excellence and proven value to the
project. With gratitude and congratulations, below are the well deserved
winners:

Alex Earl - Most Valuable Contributor

Alex is the current or previous maintainer of some of the most used Jenkins
plugins and has been for years. He’s a regular contributor to project policy
discussions, and helps to keep the project running by improving the Jenkins
project infrastructure, moderating the mailing lists and processing requests
for hosting new plugins.

Steve Marlowe - Jenkins Security MVP

Steve is one of the most prolific reporter of security vulnerabilities in
Jenkins. His reports are well-written, clearly identify the problematic
behavior, and provide references that help quickly resolve the reported issue.
On top of that, Steve is always responsive when asked for clarification.

Tomonari Nakamura - Most Valuable Advocate

Tomonari leads the Jenkins User Group in Tokyo, which is one of the largest and
the most active with a long history. The group has been organizing meet-ups for
more than 10 times now, and every meet-up fills up to 100% very quickly with
regular turn-out of 100-200 people. At one point the group under his leadership
organized a fully volunteer-run &quot;Jenkins User Conference&quot; in Tokyo that
commanded 1000+ attendees.

Congratulations to our winners.

We can’t wait to recognize more contributors at Jenkins World 2018!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/10/02/pipeline-templates-with-shared-libraries/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 2</div></div><h5 class="title">Share a standard Pipeline across multiple projects with Shared Libraries</h5></div><p class="teaser">This is a guest post by Philip Stroh, Software Architect at
TimoCom.

When building multiple microservices - e.g. with Spring Boot - the integration
and delivery pipelines of your services will most likely be very similar.
Surely, you don’t want to copy-and-paste Pipeline code from one Jenkinsfile
to another if you develop a new service or if there are adaptions in your
delivery process. Instead you would like to define something like a pipeline
&quot;template&quot; that can be applied easily to all of your services.

The requirement for a common pipeline that can be used in multiple projects does not only emerge in microservice architectures. It’s valid for all areas where applications are
built on a similar technology stack or deployed in a standardized way (e.g. pre-packages as containers).

In this blog post I’d like to outline the possibility to create such a pipeline &quot;template&quot; using Jenkins Shared Libraries. If
you’re not yet familiar with Shared Libraries I’d recommend having a look at
the documentation.

The following code shows a (simplified) integration and delivery Pipeline for a
Spring Boot application in declarative syntax.

JenkinsFile

pipeline {
    agent any
    environment {
        branch = &#x27;master&#x27;
        scmUrl = &#x27;ssh://git@myScmServer.com/repos/myRepo.git&#x27;
        serverPort = &#x27;8080&#x27;
        developmentServer = &#x27;dev-myproject.mycompany.com&#x27;
        stagingServer = &#x27;staging-myproject.mycompany.com&#x27;
        productionServer = &#x27;production-myproject.mycompany.com&#x27;
    }
    stages {
        stage(&#x27;checkout git&#x27;) {
            steps {
                git branch: branch, credentialsId: &#x27;GitCredentials&#x27;, url: scmUrl
            }
        }

        stage(&#x27;build&#x27;) {
            steps {
                sh &#x27;mvn clean package -DskipTests=true&#x27;
            }
        }

        stage (&#x27;test&#x27;) {
            steps {
                parallel (
                    &quot;unit tests&quot;: { sh &#x27;mvn test&#x27; },
                    &quot;integration tests&quot;: { sh &#x27;mvn integration-test&#x27; }
                )
            }
        }

        stage(&#x27;deploy development&#x27;){
            steps {
                deploy(developmentServer, serverPort)
            }
        }

        stage(&#x27;deploy staging&#x27;){
            steps {
                deploy(stagingServer, serverPort)
            }
        }

        stage(&#x27;deploy production&#x27;){
            steps {
                deploy(productionServer, serverPort)
            }
        }
    }
    post {
        failure {
            mail to: &#x27;team@example.com&#x27;, subject: &#x27;Pipeline failed&#x27;, body: &quot;${env.BUILD_URL}&quot;
        }
    }
}

This Pipeline builds the application, runs unit as well as integration tests and deploys the application to
several environments. It uses a global variable &quot;deploy&quot; that is provided within a Shared Library. The deploy method
copies the JAR-File to a remote server and starts the application. Through the handy REST endpoints of Spring Boot
Actuator a previous version of the application is stopped beforehand. Afterwards the deployment is verified via the
health status monitor of the application.

vars/deploy.groovy

def call(def server, def port) {
    httpRequest httpMode: &#x27;POST&#x27;, url: &quot;http://${server}:${port}/shutdown&quot;, validResponseCodes: &#x27;200,408&#x27;
    sshagent([&#x27;RemoteCredentials&#x27;]) {
        sh &quot;scp target/*.jar root@${server}:/opt/jenkins-demo.jar&quot;
        sh &quot;ssh root@${server} nohup java -Dserver.port=${port} -jar /opt/jenkins-demo.jar &amp;&quot;
    }
    retry (3) {
        sleep 5
        httpRequest url:&quot;http://${server}:${port}/health&quot;, validResponseCodes: &#x27;200&#x27;, validResponseContent: &#x27;&quot;status&quot;:&quot;UP&quot;&#x27;
    }
}

The common approach to reuse pipeline code is to put methods like &quot;deploy&quot; into
a Shared Library. If we now start developing the next application of the same
fashion we can use this method for deployments as well. But often there are
even more similarities within projects of one company. E.g. applications are
built, tested and deployed in the same way into the same environments
(development, staging and production). In this case it is possible to define
the whole Pipeline as a global variable within a Shared Library. The next code
snippet defines a Pipeline &quot;template&quot; for all of our Spring Boot applications.

vars/myDeliveryPipeline.groovy

def call(Map pipelineParams) {

    pipeline {
        agent any
        stages {
            stage(&#x27;checkout git&#x27;) {
                steps {
                    git branch: pipelineParams.branch, credentialsId: &#x27;GitCredentials&#x27;, url: pipelineParams.scmUrl
                }
            }

            stage(&#x27;build&#x27;) {
                steps {
                    sh &#x27;mvn clean package -DskipTests=true&#x27;
                }
            }

            stage (&#x27;test&#x27;) {
                steps {
                    parallel (
                        &quot;unit tests&quot;: { sh &#x27;mvn test&#x27; },
                        &quot;integration tests&quot;: { sh &#x27;mvn integration-test&#x27; }
                    )
                }
            }

            stage(&#x27;deploy developmentServer&#x27;){
                steps {
                    deploy(pipelineParams.developmentServer, pipelineParams.serverPort)
                }
            }

            stage(&#x27;deploy staging&#x27;){
                steps {
                    deploy(pipelineParams.stagingServer, pipelineParams.serverPort)
                }
            }

            stage(&#x27;deploy production&#x27;){
                steps {
                    deploy(pipelineParams.productionServer, pipelineParams.serverPort)
                }
            }
        }
        post {
            failure {
                mail to: pipelineParams.email, subject: &#x27;Pipeline failed&#x27;, body: &quot;${env.BUILD_URL}&quot;
            }
        }
    }
}

Now we can setup the Pipeline of one of our applications with the following method call:

Jenkinsfile

myDeliveryPipeline(branch: &#x27;master&#x27;, scmUrl: &#x27;ssh://git@myScmServer.com/repos/myRepo.git&#x27;,
                   email: &#x27;team@example.com&#x27;, serverPort: &#x27;8080&#x27;,
                   developmentServer: &#x27;dev-myproject.mycompany.com&#x27;,
                   stagingServer: &#x27;staging-myproject.mycompany.com&#x27;,
                   productionServer: &#x27;production-myproject.mycompany.com&#x27;)

The Shared library documentation mentions the ability to encapsulate
similarities between several Pipelines with a global variable. It shows how we
can enhance our template approach and build a higher-level DSL step:

vars/myDeliveryPipeline.groovy

def call(body) {
    // evaluate the body block, and collect configuration into the object
    def pipelineParams= [:]
    body.resolveStrategy = Closure.DELEGATE_FIRST
    body.delegate = pipelineParams
    body()

    pipeline {
        // our complete declarative pipeline can go in here
        ...
    }
}

Now we can even use our own DSL-step to set up the integration and deployment Pipeline of our project:

Jenkinsfile

myDeliveryPipeline {
    branch = &#x27;master&#x27;
    scmUrl = &#x27;ssh://git@myScmServer.com/repos/myRepo.git&#x27;
    email = &#x27;team@example.com&#x27;
    serverPort = &#x27;8080&#x27;
    developmentServer = &#x27;dev-myproject.mycompany.com&#x27;
    stagingServer = &#x27;staging-myproject.mycompany.com&#x27;
    productionServer = &#x27;production-myproject.mycompany.com&#x27;
}

The blog post showed how a common Pipeline template can be developed using the
Shared Library functionality in Jenkins. The approach allows to create a
standard Pipeline that can be reused by applications that are built in a
similar way.

It works for Declarative and Scripted Pipelines as well. For declarative
pipelines the ability to define a Pipeline block in a Shared Library is
official supported since version 1.2 (see the recent blog post on
Declarative Pipeline 1.2).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/pstrh/">Philip Stroh</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/microservices">microservices</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/10/06/hacktoberfest/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 6</div></div><h5 class="title">Hacktoberfest. Contribute to Jenkins!</h5></div><p class="teaser">Once again it’s October in our calendars.
It means that the regular Hacktoberfest event is back!
During this one-month hackathon you can support open source and earn a limited edition T-shirt.
Jenkins project offers an opportunity to participate in the project
and to get reviews and help from Jenkins contributors.

How do I sign up?

Sign-up to Hacktoberfest on the event website.

Everything is set, just start coding!

What can I do?

There are lots of ways to contribute to Jenkins during Hacktoberfest.
You can…​

Write code

Improve documentation,
write blogposts

Automate Tests

Translate and internationalize components

Design - artwork and UI improvements also count!

See the Contribute and Participate page for for information.

Where can I contribute?

The project is located in several organizations in GitHub.
Core and plugins are located in the jenkinsci org,
infrastructure - in jenkins-infra.
You can contribute to any component within these organizations.

For example, you could contribute to the following components:

Jenkins Core
( contributing)

Project Website
( contributing)

Packaging (
Docker,
native packages)

Plugins ( existing plugins,
plugin tutorial)

You can also create
new Jenkins plugins and get them
hosted
in the organization.

What can I do?

Our issue tracker contains lots of issues you could work on.
If you are new to Jenkins,
you could start by fixing some easier issues.
In the issue tracker we mark such issues with the newbie-friendly label
( search query).
You can also submit your own issue and propose a fix.

How do I label issues and pull requests?

Hacktoberfest project requires issues and/or pull requests to be labeled with the hacktoberfest label.
You may have no permissions to set labels on your own, but do not worry!
Just mention @jenkinsci/hacktoberfest or @jenkins-infra/hacktoberfest in the repository,
and we will set the labels for you.

How do I get reviews?

All examples above are being monitored by the Jenkins contributors,
and you will likely get a review within few days.
Reviews in other repositories and plugins may take longer.
In the case of delays, ping @jenkinsci/code-reviewers in your pull request
or send a message to the mailing list.

Where can I find info?

Jenkins project contains lots of materials about contributing to the project.
Here are some entry links:

Participate and Contribute

Plugin Development Tutorials

Developer Documentation

Need help?

You can reach out to us using IRC Channels
and the Jenkins Developer Mailing List.
In the case of mailing lists it is recommended to mention Hacktoberfest
in the email subject.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hacktoberfest">hacktoberfest</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/10/11/security-updates/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">11</div></div><h5 class="title">Important security updates for Jenkins core and plugins</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.84 and 2.73.2, that fix several security vulnerabilities.
Additionally, we published a new release of Swarm Plugin whose client contains a security fix, and Maven Plugin 3.0 was recently released to resolve a security issue.
Users of Swarm Plugin and Maven Plugin should update these to their respective newest versions.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

We also published information about a vulnerability in Speaks! Plugin.
There is no fix available and we recommend it be uninstalled.
Its distribution has been suspended.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/10/16/jenkins-world-session-videos-are-available/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">16</div></div><h5 class="title">Jenkins World 2017 Session Videos are Available</h5></div><p class="teaser">This is a guest post by Alyssa Tong, who runs
the Jenkins Area Meetup program and is also responsible for
Marketing &amp; Community Programs at CloudBees, Inc.

Jenkins World 2017 keynotes and breakout session videos are now available HERE. Photos from the conference can be seen HERE.

Save the date for Jenkins World 2018 :

Conference dates are September 16-19, 2018 in San Francisco.

Registration will open on October 16, 2017.

Call for Papers will open on December 1, 2017.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/10/23/security-updates/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">23</div></div><h5 class="title">Security updates for multiple Jenkins plugins</h5></div><p class="teaser">Multiple Jenkins plugins received updates today that fix several security vulnerabilities.

Active Choices (uno-choice)

Build-Publisher

Dependency Graph Viewer

global-build-stats

Additionally, the Multijob Plugin also received a security update several weeks ago.

For an overview of these security fixes, see the security advisory.

Active Choices Plugin distribution had been suspended since April due to its mandatory dependency on the suspended Scriptler Plugin.
That dependency has been made optional, so Active Choices can be used without having Scriptler installed.
This means we are able to resume distribution of Active Choices Plugin again.
It should be available on update sites later today.

We also announced a medium severity security vulnerability in SCP publisher plugin that does not have a fix at this time.

Subscribe to the jenkinsci-advisories mailing list to receive important future notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/10/25/jenkins-user-conference-china/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">25</div></div><h5 class="title">Jenkins User Conference China</h5></div><p class="teaser">This is a guest post by Forest Jing, who runs
the Shanghai Jenkins Area Meetup

I am excited to announce the inaugural
Jenkins User Conference China
will be taking place on November 19, 2017 in Shanghai, China.
The theme of JUC China is “Jenkins Driven CD and DevOps”.
Much like in the US, CD and DevOps are big topics of interest in China.
We are honored to have Kohsuke Kawaguchi join us as one of the keynote speakers at this inaugural Jenkins event.
We will also have sessions from many of China’s big named companies like Baidu, Tencet, Pinterest, Ctrip, Huawei, Microsoft, and more.
Below are some highlights of the event.

Sunday Nov 19th Agenda

Morning keynote sessions

There will be 4 keynote speeches:

Kohsuke Kawaguchi, creator of Jenkins will introduce Jenkins Past, Present &amp; Future.

Le Zhang, a very famous DevOps and CD expert will show pipeline driven CD and DevOps.

Engineering Director from Huawei will show the CD and DevOps practice in Huawei.

Xu Zheng from Pinterest will present Run Jenkins infrastructure as service in Kubernetes.

In the Afternoon, we have set up 3 tracks

CD &amp; DevOps user stories from Microsoft, Tencent, Ctrip and JinDong - all are big companies in China.

Enterprise Jenkins experience the use of Jenkins as an enterprise tool not only for teams.

Workshop to lead engineers to practice CloudBees Jenkins and open source Jenkins features.

If you’re in the neighborhood, we sincerely
invite you to join us
at Jenkins User Conference China.

Follow us on Twitter @china_juc<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/Jenkins User Conference">Jenkins User Conference</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/11/08/security-updates/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 8</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.89 and 2.73.3, that fix two low-severity security vulnerabilities.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/11/27/tutorials-in-the-jenkins-user-documentation/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">27</div></div><h5 class="title">Introducing Tutorials in the Jenkins User Documentation</h5></div><p class="teaser">Regular perusers of the Jenkins User Documentation may have noticed
the presence of the Tutorials part (between the Guided Tour and User
Handbook) that appeared in the last couple of months and gradually began to get
populated with much of my recent work, writing Jenkins tutorials.

My name’s Giles and I’ve been a technical writer in the software development
field for several years now. I’ve always been passionate about technical writing
and more recently, the technologies that go into developing written content and
automating its generation - like Jenkins! I was a former Atlassian and recently
joined CloudBees as a Senior Technical Writer, working remotely from the &quot;Sydney
Office&quot;, with my current focus on the Jenkins User Documentation.

Why tutorials?

My exposure to Jenkins and its usage over the years has been patchy at best.
During this time, however, I’ve had some degree of experience as a user of
various continuous delivery (CD) tools like Jenkins and am reasonably familiar
with the advantages these tools can offer software development teams.

I’ve also found that while many software developers are familiar with the
broader concept of &quot;developer operations&quot; (or simply &quot;devops&quot;), fewer seem
familiar with the concepts of CD and related tools to facilitate devops within
organizations.

The CD process is based on the fundamental flow of building the application
testing it delivering it, where typically:

The building part involves compiling the application and/or ensuring all
necessary libraries and dependencies are in place for the application to run
as intended.

The testing part involves testing the built application with automated tests
to ensure that changes implemented by developers function as expected.

The delivering part involves packaging or presenting the application in a
way that can be delivered to customers or other users for any kind of purpose.

Now, as one of the major contributors to the Jenkins User Documentation (and
faced with a reasonably steep learning curve), it quickly became apparent about
the lack of accessible documentation to hand-hold people relatively new to
Jenkins through this CD process. I couldn’t find anything in the Jenkins User
Documentation to demonstrate how Jenkins implements this process on a simple
app that delivers an end result.

With the guidance and assistance of helpful colleagues, I therefore decided to
embark on creating a series of Jenkins tutorials to help fill these
documentation and knowledge gaps. These tutorials are based on Daniele Procida’s
description of how tutorials should be presented in his blog post
&quot; What nobody tells you about
documentation&quot;).

Introductory tutorials

The first set of tutorials on the Tutorials overview page
demonstrate how to implement this fundamental CD process in Jenkins on a simple
application for a given technology stack.

So far, there’s one for
Java with Maven and another
for Node.js and
React with npm. Another for Python will be added to this list in the near
future.

These tutorials define your application’s entire CD process (i.e. your Pipeline)
in a Jenkinsfile, whose Groovy-like Declarative Pipeline syntax is checked in
to your Git source repository. Managing your Pipeline with your application’s
source code like this forms the fundamentals of &quot;Pipeline as code&quot;.

The Introductory tutorials also cover how to use some powerful features of
Jenkins, like Blue Ocean,
which makes it easy to connect to an existing cloud, web or locally hosted Git
repository and create your Pipeline with limited knowledge of Pipeline syntax.

Advanced tutorials

Also soon to be released will be the first Advanced tutorial on building
multibranch Pipelines in Jenkins. This tutorial takes the &quot;Pipeline as code&quot;
concept to a new level, where a single Jenkinsfile (defining the entire CD
process across all branches of your application’s Git repository) consists of
multiple stages which are selectively executed based on the branch that Jenkins
is building.

Additional tutorials that demonstrate more advanced features of Jenkins and how
to manage your Pipelines with greater sophistication and flexibility will be
added to this section in future.

Summing up

You can access all currently available tutorials from the
Tutorials overview page in the Jenkins User Documentation.
It’s worthwhile checking that page from time to time as it’ll be updated
whenever a new tutorial is published.

Also, if you have any suggestions for tutorials or other content you’d like to
see in the documentation, please post your suggestions in the
Jenkins
Documentation Google Group, which you can also post (and reply) to by emailing
jenkinsci-docs@googlegroups.com.

The Sydney Office team meeting at Carriageworks - from left to right, Giles
Gaskell, Nicholae Pascu, Michael Neale and James Dumay<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/gilesgas/">Giles Gaskell</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/12/04/jenkins-user-conference-china-recap/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 4</div></div><h5 class="title">Jenkins User Conference China Recap</h5></div><p class="teaser">This is a guest post by Forest Jing, who runs
the Shanghai Jenkins Area Meetup

The first Jenkins User Conference China was held on November 19, 2017 in
Shanghai, China. It was an amazing conference for Jenkins users in China. There were
almost 450 attendees to enjoy a lovely day with Jenkins creator, Kohsuke Kawaguchi.

There were 12 wonderful presentations, 1 workshop and 1 open space to set the stage for JUC China.
The day began with Kohsuke, welcomed to the stage by all the attendees here with their warm
applauses. All of them are fans of Jenkins and Kohsuke.  Thanks to Kohsuke, he made a wonderful presentation to show the past, present and future of Jenkins for Chinese Jenkins users.

The co-founder of DevOps Times community, Le Zhang released a report of adoption of Deployment Pipeline in Chinese IT organization.
The report shows that Jenkins is the most popular tool for DevOps and CD in China.

It also has proven that “If it hurts, do it more often!” is right because the IT organization who deploy more frequently, deployment  failure would be less.

The Three Musketeers of DevOps in China (Le Zhang, Xuefeng Shi,Forest Jing) have demonstrated a DevOps pipeline based on Jenkins and many open-source software such as Kubernetes, Gitlab, etc.

After the presentation, lots of fans waited in line to take pictures with Kohsuke.

Here are some photos of the JUC China. We really enjoyed it.

Lastly, as an organizer for JUC China, I would like to thank Kohsuke Kawaguchi, Alyssa Tong, Sam Van Oort and so many friends from CloudBees and Jenkins community to have given us so many help to make the first JUC China an amazing and successful conference for Jenkins users in China. We look forward to organizing many more JUC China.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/12/14/security-update/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">14</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.95 and 2.89.2, that fix two security vulnerabilities.
For an overview of what was fixed, see the security advisory.

We usually announce core security updates well in advance on the jenkinsci-advisories mailing list, to give Jenkins administrators time to schedule a maintenance.
Additionally, we try to align security updates with the regular LTS schedule.
We have chosen not to do so in this case for two reasons:

The random failure to set up Jenkins is very noticeable, and given that we’ve seen automated exploits for unprotected Jenkins instances in the past we consider it important to fix that issue as soon as possible, so that users setting up new instances of Jenkins can be confident they won’t start up insecurely.

The CSRF issue appears to only affect instances for a very short (seconds at most, if at all) time period immediately after startup, so administrators could apply the fix during the next scheduled Jenkins downtime, rather than immediately.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/12/15/auto-convert-freestyle-jenkins-jobs-to-coded-pipeline/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">15</div></div><h5 class="title">Auto-Convert Freestyle Jobs to Jenkins Pipeline</h5></div><p class="teaser">This is a guest post by Sanil Pillai, Director of Labs &amp; Strategic Insights, Infostretch

Infostretch has created a
plugin for teams
upgrading from Freestyle Jobs to Pipelines as code with Jenkins Pipeline.
This new plugin streamlines the process and accelerates
pipeline on-boarding for any new set of applications. Previously, when
upgrading to Jenkins Pipeline, converting Freestyle Jobs required developers
to drill down on each one of those hundreds (or thousands!)  of jobs to understand
tools, configurations, URLs, parameters, and more before rewriting them in
Pipeline syntax. This process is very manual,
error-prone, lengthy, and not cost-effective. Beyond saving time, the new
plugin also assures adherence to proper coding standards and separates complex
business logic and standards declaration from execution flow.

Key features:

Convert single freestyle job to pipeline

Convert chain of freestyle jobs to single pipeline

Works with both Jenkins and CloudBees Jenkins Enterprise

Plugin can be customized to support any Freestyle plugin and an
organization’s Pipeline Shared Library,
or Groovy coding standards.

Works with CloudBees&#x27; Role-based Access Control to help the new Pipelines
comply with existing security policies.

Direct migration of properties such as &quot;Build with Parameters&quot; to newly
created Pipelines.

Direct migration of Agent on which job is to be run with support for multiple agent labels across different downstream jobs

Environment properties: JDK, NodeJS

Supports Git SCM.

Build steps: Maven, Ant, Shell, Batch, and Ansible Playbook.

Post build actions: artifact archiver, simple mailer, TestNG reports, JUnit reports, checkstyle publisher

Now, let’s take a look at how to get started:

Click on a link at Root level or Folder level or Job level.

Select the job from the drop-down list that is the beginning point of the
&quot;chain&quot;. If job level link is clicked, this drop-down list will not be visible.

Provide the new pipeline job name. If this is not specified, the plugin will
attempt to create a new pipeline job with the naming convention of
&quot;oldname-pipeline&quot;.

Check &quot;Recursively convert downstream jobs if any?&quot; if you wish to have all the
downstream jobs converted into this new pipeline. The plugin will write all the
logic of current and downstream jobs into a single pipeline.

Check &quot;Commit Jenkinsfile?&quot; if you would like the plugin to create a
Jenkinsfile and commit it back to the SCM. The plugin will commit the
Jenkinsfile at the root of the SCM repository it finds in the first job
(selected in step 1 above). It will attempt to commit to this repo using the
credentials it finds in the first job.

Do note that the plugin will checkout the repo in to a temporary workspace on
the controller (JENKINS_HOME/plugins/convert-to-    pipeline/ws). Once the
conversion is complete and Jenkinsfile is committed back to the repo, the
workspace will be deleted.

Click &quot;Convert&quot; to convert the Freestyle job configurations to a single
scripted pipeline job. Once the conversion is complete and the new job is
created, you will be redirected to the newly created pipeline job.

That’s it!

To learn more about plugin usage, customization and to see a demo
click here
to watch the webinar replay on-demand.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/spillai/">Sanil Pillai</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/freestyle">freestyle</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/12/31/new-year/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">31</div></div><h5 class="title">Happy New Year!</h5></div><p class="teaser">Jenkins project congratulates all users and contributors with the New Year!
Let’s take a look at some changes this year.

Highlights

We released major features like BlueOcean
and Declarative Pipeline

These features offer a new user experience in Jenkins Web UI, powered by Jenkins Pipeline.

In Jenkins 2.54 we updated the Java minimal requirement to Java 8 ( announcement).

Plugin CI has been moved to our Jenkins-on-Jenkins instance.
All plugins are being built by Jenkins Pipeline with a special pipeline library

We adopted the Jenkins Enhancement Proposal (JEP) process for major changes in Jenkins.
There are already JEPs under review:

JEP-2: Criteria for selecting &quot;Suggested Plugins&quot;

JEP-200: Switch Remoting/XStream blacklist to a whitelist

JEP-201: Jenkins Configuration as Code

Some stats

In 2017 we had 60 weekly and 13 LTS releases with 305 fixes/enhancements only in the core.
Next week Jenkins is going to hit the 2.100 version, and the core changed greatly since the 2.0 release in April 2016.
Jenkins Security was one of the hottest areas this year, there were 7 security advisories for the core and 15 - for plugins.
For comparison, in 2016 there were only 6 security releases in total.

There were 2605 plugin releases, and 215 NEW plugins have been hosted in the Update Center.
In particular Jenkins ecosystem has greatly expanded into the Cloud space
by offering dozens of new plugins (e.g. for Azure and Kubernetes).
We also got many new plugins providing integrations with various Development and DevOps tools.

Other subprojects and Jenkins components also got major updates.
For example,
Jenkins Remoting got 15 releases with stability improvements.
Stapler Framework also got 6 releases.

Keep updating, Jenkins 2 is not only about Pipeline as Code!

Events

This year we got many new Jenkins Area Meetups.
Currently there are 77 meetups with more than 20,000 members in total ( full map).
More than 100 meetups have been organized around the globe.

There were also several Jenkins-focused conferences including the following ones:

Jenkins World in San-Francisco

Jenkins User Conferences in Israel and Shanghai

Days Of Jenkins in Gothenburg and Oslo

Jenkins Community Day in Paris

Jenkins Days in Amsterdam

CloudBees | Jenkins Automotive and Embedded Day in Stuttgart

What’s next?

Next year we will have traditional contributor meeting at FOSDEM
and at Jenkins World 2018.
If you are interested in Jenkins, stop by at our community booths and join the contributor summits/hackathons.
We also want to participate in Google Summer of Code 2018,
and currently we are looking for mentors.

Stay tuned, there is much more to come next year!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/new-year-blogpost">new-year-blogpost</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/03/fosdem-2018/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 3</div></div><h5 class="title">FOSDEM 2018!</h5></div><p class="teaser">FOSDEM 2018 is a free event for software developers to meet, share ideas and collaborate.
It is an annual event that brings open source contributors from around the world for two days of presentations, discussions, and learning.

Jenkins will be well-represented at FOSDEM 2018.

Happy Hour before FOSDEM

We’ll have a happy hour Friday evening before FOSDEM at Cafe Le Roy d’Espagne.
See the meetup page for details.

Jenkins table at FOSDEM

A Jenkins table will be staffed by volunteers at FOSDEM to answer questions, discuss topics, and help users.
See the meetup page for details.

Presentations at FOSDEM

Automated Linux Containers deployment for fun and profit by David Negreira

Advanced testing in action on a Java project by Vincent Massol

Deployment vs Provisioning vs Orchestration vs Configuration Management by Peter Souter

Jenkins Hackfest after FOSDEM

A Jenkins Hackfest will be held the day after FOSDEM 2018.
Those who would like to join us for the hackfest 5 Feb 2018 should register for the meetup.

Meals, snacks, and beverages will be provided for the hackfest.  Come join us, and let’s write some code!

Questions? feel free to contact Alyssa Tong or Mark Waite.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/06/gsoc2018-call-for-mentors/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 6</div></div><h5 class="title">Google Summer Of Code 2018: Call for mentors</h5></div><p class="teaser">This year the Jenkins project is interested in participating in
Google Summer of Code (GSoC).
As in 2016/2017, we are looking for mentors.
So yes, we are looking for you :)

What is GSoC?

GSoC is an annual international program which encourages
college-aged students to participate with open source projects during the summer
break between classes.

Students accepted into the program receive a stipend,
paid by Google, to work on well-defined projects to improve or enhance the Jenkins
project.
In exchange, numerous Jenkins community members volunteer as mentors
for students to help integrate them into the open source community and succeed
in completing their summer projects.

What do mentors get?

A student who works full-time in the area of your interest for several months

Joint projects with Jenkins experts, lots of fun and ability to study something together

Limited-edition of swags from Google and Jenkins project

Maybe: Participation in GSoC Mentor Summit and other GSoC events/meetups

Conditions

Mentors are expected to…​

Be passionate about Jenkins

Lead the project in the area of their interest

Actively participate in the project during student selection, community bonding and coding phases (March - August)

Work in teams of 2+ mentors per 1 each student

Dedicate a consistent and significant amount of time, especially during the coding phase ( ~5 hours per week in a team of two mentors)

Mentorship does NOT require strong expertise in Jenkins plugin development.
The main objective is to guide students and to get them involved into the Jenkins community.
GSoC org admins will help to find advisors if a special expertise is needed.

Disclaimer: We cannot guarantee that the Jenkins organization gets accepted to GSoC.
Even if it gets accepted, we may need to select projects depending on student applications
and the number of allocated project slots.

Timeline

Dec 2017 - started collecting project ideas

Jan 17 - Status review at the Jenkins Governance Meeting.
Outcome: decision whether we apply to GSoC in 2018.

Jan 21 - Application to GSoC (deadline - Jan 23)

Feb 12 - List of accepted mentoring organizations published

Mar 05 - Deadline for project idea proposals

Next - GSoC Timeline

How to apply?

If you are interested in proposing a project or joining an existing one, please respond to
this thread
in the Jenkins Developer mailing list.
We aggregate/review proposals in
this document
where you just need to describe the idea and introduce yourself.

Please propose new project ideas for discussion until March 05.
You can join an existing project at any time, including community bonding and coding periods.

Project requirements

GSoC is about code (though it may and likely should include some documentation and testing work)

Projects should be about Jenkins (plugins, core, infrastructure, integrations, etc.)

Projects should be potentially doable by a student in 3-4 months

You can find more information about requirements and practices in the
GSoC Mentor Guide.

Links

Jenkins GSoC subproject page

Information for mentors

Google Summer of Code page

GSoC Mentor Guide

GSoC Timeline<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/08/moving-from-buddybuild-for-android/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 8</div></div><h5 class="title">Moving from buddybuild to Jenkins for Android Developers</h5></div><p class="teaser">Last week, buddybuild — a hosted continuous integration service focused on mobile apps — announced that it had been acquired by Apple, and consequently its complete Android offering, along with its free tier for iOS users, will be discontinued at the beginning of March.

This was a fairly undesirable way to start 2018 for buddybuild’s Android users and, with less than two months to find an alternative, many took to Twitter to simultaneously congratulate buddybuild on their acquisition, and commiserate with others who have to find a new way to build and test their app.

While Jenkins is usually deployed as a self-hosted solution (with over 150k installs), rather than a hosted service like buddybuild, we thought this would be a good time to highlight — thanks to the rich plugin ecosystem of Jenkins — some of the possibilities offered to Android developers by Jenkins.

Common workflows

Android projects are fundamentally no different from how other types of software development projects might make use of a Continuous Integration &amp; Continuous Delivery system (CI/CD) such as Jenkins: Android developers will collaborate using a source control management system (SCM) such as Git or Mercurial; they will create Pull Requests, which should be automatically verified; they expect to get feedback on test failures and code quality (e.g. via email or Slack); and they should be able to easily deploy new versions of their app to beta testers or end users.

To this end, Jenkins lets you define your build and deployment pipelines in a structured and auditable fashion (via Jenkinsfile), supports a multitude of SCMs, while the multibranch Pipeline feature automatically creates new Jenkins jobs for every new Pull Request in your repository, and cleans them up as branches get merged.  The Blue Ocean user interface ties these features together in a clean, modern UI.

Building Android Apps

To build an Android app, you need the Java development tools (JDK), which Jenkins can automatically install for you, plus the Android SDK, which you can also install on individual build agents using a tool installer, or you can use a Docker container with the Android SDK Tools preinstalled, for example.

Then, you can use your SCM plugin of choice to fetch your source code, and build the app using the Android Gradle Plugin via the Gradle Wrapper — in most cases this is as simple as running./gradlew assembleDebug.

Once your app has been built and packaged into a.apk file, you can use the archiveArtifacts build step, storing the APK, enabling colleagues to download APKs directly from Jenkins, so that they can try out the latest build.

Testing Android Apps

The Android SDK supports two types of test: unit tests, which run on the JVM, and instrumentation tests, which have to run on an Android device or emulator.  Both types of test can be executed using Jenkins and, since the Android Gradle Plugin writes the test results to disk in JUnit XML format, the JUnit Plugin for Jenkins can be used to parse the results, enabling you see a test report, and to be notified of test failures.

Compiling and executing the unit tests for your app is as simple as adding another build step which runs./gradlew testDebugUnitTest.

Similarly, instrumentation tests can be compiled and executed via the connectedDebugAndroidTest task in Gradle.  However, before you do this, you should ensure that an Android device is connected to your Jenkins build agent, or you can make use of the Android Emulator Plugin to automatically download, create, and start an emulator for you during a build.  There are also plugins for cloud testing services such as AWS Device Farm.

Once you have finished executing the tests, you can use the junit step to analyse the results: junit &#x27;**/TEST-*.xml&#x27;.

Static Analysis

Similar to other Java or Kotlin projects, you can scan your codebase using static analysis tools like FindBugs or Checkstyle.  Once again, Jenkins has analysis plugins which can parse the output of these tools, and present you with the results and trend graphs, or optionally flag the build as unstable or failed if too many problems have been detected.

The Android SDK provides a further useful static analysis tool called Lint.  The output of this tool can be parsed by the Warnings Next Generation Plugin, which will analyse the issues found, and provide you with a detailed report within Jenkins.  This functionality was demonstrated by the Android Tools Team at the Google I/O conference a few years back.

Securely signing and deploying Android apps

In order to distribute an Android app, it needs to be signed with a private key, which you should keep safe (losing it means you won’t be able to publish updates to your app!), and as secure as possible.

Instead of developers having to keep the signing keystore on their development machines, you can securely store the keystore and/or its passphrase on Jenkins using the Credentials Plugin.  This avoids having to hardcode the passphrase into your build.gradle, or have it otherwise checked into your SCM.

The Credentials Plugin allows you to store secrets in Jenkins — which will be stored encrypted on disk when not in use — and those secrets can temporarily be made available during a build, either as a file in the build workspace, or exposed as an environment variable.

You can use such environment variables in a signingConfig block within your build.gradle, or you can make use of the Android Signing Plugin to sign your APK for you.

Once you have your production-ready APK built and signed, you can automatically upload it to Google Play using the Google Play Android Publisher plugin.  The benefit of using this plugin is that it supports multiple APK upload, expansion files, uploading of ProGuard mapping files, promotion of builds from alpha, to beta, to production — and once again, your Google Play credentials are securely stored on Jenkins thanks to integration with the Credentials Plugin.

Sample Pipeline

Here’s a straightforward example of a Jenkinsfile defining a pipeline to build, test, and optionally deploy an Android app, from a multibranch Pipeline job.
It requires the Pipeline, JUnit, Android Lint, Google Play Android Publisher, and Mailer plugins to be installed.

Jenkinsfile

pipeline {
  agent {
    // Run on a build agent where we have the Android SDK installed
    label &#x27;android&#x27;
  }
  options {
    // Stop the build early in case of compile or test failures
    skipStagesAfterUnstable()
  }
  stages {
    stage(&#x27;Compile&#x27;) {
      steps {
        // Compile the app and its dependencies
        sh &#x27;./gradlew compileDebugSources&#x27;
      }
    }
    stage(&#x27;Unit test&#x27;) {
      steps {
        // Compile and run the unit tests for the app and its dependencies
        sh &#x27;./gradlew testDebugUnitTest&#x27;

        // Analyse the test results and update the build result as appropriate
        junit &#x27;**/TEST-*.xml&#x27;
      }
    }
    stage(&#x27;Build APK&#x27;) {
      steps {
        // Finish building and packaging the APK
        sh &#x27;./gradlew assembleDebug&#x27;

        // Archive the APKs so that they can be downloaded from Jenkins
        archiveArtifacts &#x27;**/*.apk&#x27;
      }
    }
    stage(&#x27;Static analysis&#x27;) {
      steps {
        // Run Lint and analyse the results
        sh &#x27;./gradlew lintDebug&#x27;
        androidLint pattern: &#x27;**/lint-results-*.xml&#x27;
      }
    }
    stage(&#x27;Deploy&#x27;) {
      when {
        // Only execute this stage when building from the `beta` branch
        branch &#x27;beta&#x27;
      }
      environment {
        // Assuming a file credential has been added to Jenkins, with the ID &#x27;my-app-signing-keystore&#x27;,
        // this will export an environment variable during the build, pointing to the absolute path of
        // the stored Android keystore file.  When the build ends, the temporarily file will be removed.
        SIGNING_KEYSTORE = credentials(&#x27;my-app-signing-keystore&#x27;)

        // Similarly, the value of this variable will be a password stored by the Credentials Plugin
        SIGNING_KEY_PASSWORD = credentials(&#x27;my-app-signing-password&#x27;)
      }
      steps {
        // Build the app in release mode, and sign the APK using the environment variables
        sh &#x27;./gradlew assembleRelease&#x27;

        // Archive the APKs so that they can be downloaded from Jenkins
        archiveArtifacts &#x27;**/*.apk&#x27;

        // Upload the APK to Google Play
        androidApkUpload googleCredentialsId: &#x27;Google Play&#x27;, apkFilesPattern: &#x27;**/*-release.apk&#x27;, trackName: &#x27;beta&#x27;
      }
      post {
        success {
          // Notify if the upload succeeded
          mail to: &#x27;beta-testers@example.com&#x27;, subject: &#x27;New build available!&#x27;, body: &#x27;Check it out!&#x27;
        }
      }
    }
  }
  post {
    failure {
      // Notify developer team of the failure
      mail to: &#x27;android-devs@example.com&#x27;, subject: &#x27;Oops!&#x27;, body: &quot;Build ${env.BUILD_NUMBER} failed; ${env.BUILD_URL}&quot;
    }
  }
}

Not just for Android

While buddybuild concentrated on Android and iOS apps, thanks to the distributed build agent architecture of Jenkins, you can automate any type of project.

For example, you can expand the capabilities of Jenkins by adding macOS (or Windows, Linux, BSD…) agents; you can dynamically spin up agents on AWS EC2 instances, Microsoft Azure VMs, or Azure Container Instances; you can create agents using VMware, and so on.

Conclusion

Thousands of Jenkins instances are already using the various Android-related plugins, and Pipeline along with the Blue Ocean User Interface make using Jenkins simpler than it’s ever been.

Give Jenkins a try for building your Android projects, check out the tutorials, and get in touch via the users&#x27; mailing list, or IRC.

Finally, as with Jenkins itself, all plugins distributed are open-source, so feel free to contribute!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/orrc/">Christopher Orr</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/android">android</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/13/jep-200/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">13</div></div><h5 class="title">JEP-200: Remoting / XStream whitelist integrated into Jenkins core</h5></div><p class="teaser">There is a newer version of the announcement for Jenkins administrators.
Please see this blogpost.

Overview

JEP-200 has been integrated into Jenkins weekly builds
and (if all goes well) will be a part of the next LTS line.
In a nutshell, this change is a security hardening measure
to be less permissive about deserializing Java classes defined in the Java Platform or libraries bundled with Jenkins.
For several years now, Jenkins has specifically blacklisted certain classes and packages according to known or suspected exploits;
now it will reject all classes not explicitly mentioned in a whitelist, or defined in Jenkins core or plugins.

For Jenkins administrators

Before upgrade

Back up your Jenkins instance prior to upgrade so you have any easy way of rolling back.
If you are running any of the plugins listed in
Plugins affected by fix for JEP-200,
update them after taking the backup but before upgrading Jenkins core.

If you have a way of testing the upgrade in an isolated environment before applying it to production,
do so now.

Using backups and a staging server is good advice before any upgrade but especially this one,
with a relatively high risk of regression.

After upgrade

To the extent that advance testing of the impact of this change on popular plugins has been completed,
most users (and even plugin developers) should not notice any difference.
If you do encounter a java.lang.SecurityException: Rejected: some.pkg.and.ClassName in the Jenkins UI or logs,
you may have found a case where an unusual plugin, or an unusual usage mode of a common plugin,
violates the existing whitelist.
This will be visible in the Jenkins system log as a message from jenkins.security.ClassFilterImpl like the following:

some.pkg.and.ClassName in file:/var/lib/jenkins/plugins/some-plugin-name/WEB-INF/lib/some-library-1.2.jar might be dangerous, so rejecting; see https://jenkins.io/redirect/class-filter/

where the link would direct you here.

If you find such a case, please report it in the Jenkins issue tracker, under the appropriate plugin component.
Link it to JENKINS-47736 and add the JEP-200 label.
If at all possible, include complete steps to reproduce the problem from scratch.
Jenkins developers will strive to evaluate the reason for the violation and offer a fix in the form of a core and/or plugin update.
For more details and current status, see
Plugins affected by fix for JEP-200.

Assuming you see no particular reason to think that the class in question has dangerous deserialization semantics, which is rare,
it is possible to work around the problem in your own installation as a temporary expedient.
Simply make note of any class name(s) mentioned in such log messages,
and run Jenkins with this startup option (details will depend on your installation method):

-Dhudson.remoting.ClassFilter=some.pkg.and.ClassName,some.pkg.and.OtherClassName

For plugin developers

Testing plugins against Jenkins 2.102 and above

As a plugin developer encountering this kind of error,
your first task is to ensure that it is reproducible in a functional ( JenkinsRule) test
when running Jenkins 2.102 or newer to reproduce the error.

mvn test -Djenkins.version=2.102 -Denforcer.skip=true

The above assumes you are using a recent 2.x or 3.x parent Plugin POM.
For certain cases you may need to use Plugin Compat Tester (PCT)
to run tests against Jenkins core versions newer than your baseline.

Running PCT against the latest Jenkins core:

java -jar pct-cli.jar -reportFile $(pwd)/out/pct-report.xml \
    -workDirectory $(pwd)/work -skipTestCache true -mvn $(which mvn) \
    -includePlugins ${ARTIFACT_ID} -localCheckoutDir ${YOUR_PLUGIN_REPO}

You may need to run tests using an agent or force saves of plugin settings.

For maven plugins you can also specify custom Jenkins versions in Jenkinsfile to run tests against JEP-200:

buildPlugin(jenkinsVersions: [null, &#x27;2.102&#x27;])

(again picking whatever version you need to test against)
so that the test is included during CI builds, even while your minimum core baseline predates JEP-200.

If your plugins are built with Gradle, your mileage may vary.

Making plugins compatible with Jenkins 2.102 or above

If you discover a compatibility issue in your plugin,
you then have several choices for fixing the problem:

Ideally, simplify your code so that the mentioned class is not deserialized via Jenkins Remoting or XStream to begin with:

If the problem occurred when receiving a response from an agent, change your Callable (or FileCallable) to return a plainer type.

If the problem occurred when saving an XML file (such as a config.xml or build.xml), use a plainer type in non- transient fields in your persistable plugin classes.

If the class(es) are defined in the Java Platform or some library bundled in Jenkins core, propose a pull request adding it to core/src/main/resources/jenkins/security/whitelisted-classes.txt in jenkinsci/jenkins.

If the class(es) are defined in a third-party library bundled in your plugin, create a resource file META-INF/hudson.remoting.ClassFilter listing them. ( example)

You may also do this for Java or Jenkins core library classes, as a hotfix until your core baseline includes the whitelist entry proposed above.

If the class(es) are defined in a JAR you build and then bundle in your plugin’s *.jpi, add a Jenkins-ClassFilter-Whitelisted: true manifest entry. This whitelists every class in the JAR. ( example)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/upgrade">upgrade</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/17/jenkins-world-cfp-open/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">17</div></div><h5 class="title">Jenkins World 2018: Call for Papers is Open</h5></div><p class="teaser">Happy 2018! The Jenkins World train is ready to take off once again. As usual, the sign of festivities looming begins with the Call for Papers.  Those who attended Jenkins World 2017 know that Jenkins World 2018 is coming back to San Francisco. But what they did not know is that Jenkins World will also be coming to Europe. You read that right, Jenkins World is taking place in two locations in 2018:

Jenkins World USA | San Francisco | September 16 - 19, 2018

Jenkins World Europe | October - date and location TBA

To encourage open collaboration and stimulate discussions that will help advance Jenkins adoption and drive it forward, we invite Jenkins users, developers and industry experts to submit a speaking proposal to Jenkins World San Francisco and or Europe.  Submissions for both locations are being accepted now and will close on March 18, 2018 @ 11:59PM Pacific.

Where do I go to submit my proposal?

Submissions for both Jenkins World USA and Europe are accepted at:

Jenkins World USA

Jenkins World Europe

Can I make proposal(s) to both conferences?

Yes, you can! Once you’ve created an account on the CFP website you will be given the option to make submission(s) to one conference or both conferences.

When is the deadline Jenkins World USA?

Sunday March 18, 2018 @ 11:59PM Pacific

When is the deadline for Jenkins World Europe?

Sunday March 18, 2018 @ 11:59PM Pacific

Important Dates:

CFP Opens: January 17, 2018

CFP Closes: March 18, 2018 @ 11:59pm Pacific

CFP Notifications: April

Agenda Announcement: April

Event Dates:

Jenkins World USA | San Francisco | September 16 - 19, 2018

Jenkins World Europe | October - exact date TBA<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/21/overhaul-of-manage-jenkins-page/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">21</div></div><h5 class="title">Overhaul of Manage Jenkins page</h5></div><p class="teaser">Overview

Recently some UI improvements around the Manage Jenkins page have been introduced. The visual changes are very subtle but behind them, there are interesting benefits.

Some of the goals that we have tried to achieve:

Applying a semantic HTML

Removing the tag usage for implementing layouts and content structures. Read this article if you want to know reasons and/or arguments.

Small re-styling focused on spacing, margins, composition, etc..

Accessibility

In order to provide a quick overview of the visual changes, let’s take a look at these screenshots.

System tray with administrative messages (before)

System tray with administrative messages (after)

Manage Jenkins page (before)

Manage Jenkins page (after)

Information about how this change can affect the current implementations of Administrative Monitors can be found in the following section

For core developers

Let’s use a real example for showing how this proposal works.

This is the original UI implementation of HudsonHomeDiskUsageMonitor.java :

${%blurb(app.rootDir)}

And this is the proposed change:

${%blurb(app.rootDir)}

Some highlights:

No more ad hoc UI compositions

No more custom CSS classes when Jenkins project is already using Bootstrap for many different things

Based on Bootstrap Alert

All administrative monitors defined in Jenkins core have been adapted as part of this proposal.

For plugin developers

No changes are really needed, but we do recommend you to adapt your plugins to this proposal so Jenkins users have a better user experience.

Taking into account that you want to keep backward compatibility, you will need some changes.

In your implementation of Administrative Monitor, add this helper method:

/**
 * This method can be removed when the baseline is updated to 2.103
 *
 * @return If this version of the plugin is running on a Jenkins version where JENKINS-43786 is included.
 */
 @Restricted(DoNotUse.class)
 public boolean isTheNewDesignAvailable() {
    if (Jenkins.getVersion().isNewerThan(new VersionNumber(&quot;2.103&quot;))) {
        return true;
    }
    return false;
}

In your view (a.k.a. Jelly file or Groovy file):

SSH Host Key Verifiers are not configured for all SSH agents on this Jenkins instance. This could leave these agents open to man-in-the-middle attacks. Update your agent configuration to resolve this.

SSH Host Key Verifiers are not configured for all SSH agents on this Jenkins instance. This could leave these agents open to man-in-the-middle attacks. Update your agent configuration to resolve this.

If you don’t want to keep a strict backward compatibility, the impact is minimal. In fact, you can see an example on GitHub Plugin.

Some helpful references:

JIRA issue where the proposal was tracked

Pull Request with the change in Jenkins core. You can find several screenshots

Pull Request for adapting SSH Agent Plugin

Do not hesitate to ping me if you decide to adapt your Administrative Monitors.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/recena/">Manuel Recena</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ui">ui</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/restyling">restyling</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/upgrade">upgrade</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/01/26/fosdem-hackaton/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">26</div></div><h5 class="title">You are invited to the Post-FOSDEM 2018 Jenkins Hackfest</h5></div><p class="teaser">On the first weekend in February, numerous free and open source developers from around the
world will travel to Brussels, Belgium, for arguably the largest event of its kind:
FOSDEM.
Among the thousands of hackers in attendance will be a number of Jenkins contributors.

On the Monday after FOSDEM,
you are invited to join a group of those contributors for a full day of hacking on Jenkins.
Folks of all experience levels are welcome;
there will be sessions for everyone from seasoned hackers to new contributors.

All-day Jenkins Hackfest

The Hackfest will start at 9:30am on Monday with general introductions and gathering of potential topics/projects.
Bring suggestions for topics that interest you, or just come and choose from the topics others suggest.
There will be plenty of topics from which to choose.
All the topic suggestions will all be added to a backlog and we will identify and cluster around popular topics.
Then we’ll divide into smaller groups and work on individual topics in timeboxed sessions.

Meals, snacks, and beverages will be provided throughout the day, wrapping up with dinner around 5pm.

Something for everyone

Hackfests like this one are a great opportunity for contributors of all levels to get invovled, learn from each other, and
work together on interesting and high impact areas of the project.

Some long-time contributors already know what areas they’ll work on and are looking for people interested in joining them.
Mark Waite (maintainer of the Jenkins Git and Git Client plugins) and Christian Halstrick (SAP) will be spending the day improving the way Git client plugin uses JGit.
R. Tyler Croy (Jenkins community concierge) and Olivier Vernin (Jenkins infrastructure engineer) will work on infrastructure improvements.

Others contributors, such as Jesse Glick and Andrew Bayer
(recipients of the  &quot; A Small Matter of Programming&quot; award), will arrive without a set plan.
They will, of course, have some topics to propose, so you might get a chance to work with them.
Or if you have an area you’d like to work on, they and many other experts will be on hand for discussion and code review.

This is also a great opportunity for new contributors to join the project.
Baptiste Mathus, long time contributor and all-around nice guy, will host a &quot;New Contributor Hackergarten&quot; covering the basics of contributing to Jenkins and submitting fixes via GitHub Pull requests.
Even those with minimal coding experience can contribute by improving documentation and making typo fixes via this same process.

Fun!

More than anything else, Hackfests like this are great fun.
No matter what your level of exerience, there will be plenty to do and great people with whom to do it.
Reserve a space by
joining the meetup here.
Then bring your own laptop and passion for improving Jenkins.

Details

Date : Monday, February 5, 2018

Time : 9:30 AM to 5:00 PM

Location : BeCentral sprl/bvba
Cantersteen 12
1000 Brussel
Belgium
Room: Studio C (1st floor)

RSVP Required

Meals, snacks, and beverages will be provided.
Bring your own computer.

Ask for &quot;Jenkins&quot; at the front desk if you get lost.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/fosdem">fosdem</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/02/05/security-updates/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 5</div></div><h5 class="title">Security updates for multiple Jenkins plugins</h5></div><p class="teaser">Multiple Jenkins plugins received updates today that fix several security vulnerabilities.

Android Lint

CCM

Credentials Binding

JUnit

Pipeline: Supporting APIs

For an overview of these security fixes, see the security advisory.

Subscribe to the jenkinsci-advisories mailing list to receive important future notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/02/14/security-updates/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">14</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.107 and 2.89.4, that fix multiple security vulnerabilities.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

While the severity score works out as medium for all the vulnerabilities, we strongly recommend that anyone operating publicly accessible Jenkins instances update as soon as possible, as their secrets on disk might be at risk by SECURITY-705.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/02/19/gsoc2018-announcement/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">19</div></div><h5 class="title">Jenkins is accepted to Google Summer Of Code 2018, join us!</h5></div><p class="teaser">We are happy to announce that Jenkins project has been accepted to
Google Summer of Code 2018.
This year we invite students and mentors to join the Jenkins community and work together
on various initiatives: core, plugins, development tools and infrastructure.

Our mentors have already created some project ideas.
For example, you are welcome to work on the new Configuration-as-Code initiative or
to help creating standard API for Code Coverage plugins.
If you like test automation, there is a proposal to
Jenkins Acceptance Test Harness.
Over the next weeks we plan to extend this list by new even more project ideas.

All information about the Jenkins GSoC is available on its subproject page.

I am a student. How do I apply?

See Information for students for application guidelines.

First step is to join discussions in the mailing lists in order to introduce yourself, establish connections with the community and potential mentors.
The application period starts on March 12 and ends on March 27, but don’t let it misguide you!
Use time before application to discuss project ideas/proposals with mentors and to process their feedback.
To create a better proposal, we also recommend to study Jenkins and to do some contributions in the area of your project proposal.

Not satisfied by the current project ideas?
You can propose your own idea
in the developer mailing list.

I want to be a mentor. Is it too late?

It’s not!
If you are passionate about open-source and Jenkins, we invite you to join the mentors team.
You can either propose a new project idea or join an existing one.
See Call for Mentors and Information for mentors for details.

This year mentorship does NOT require strong expertise in Jenkins development.
The objective is to guide students and to get involved into the Jenkins community.
GSoC org admins will help to find advisers if special expertise is required.

Important dates

Mar 05 - deadline for new GSoC project idea proposals

Mar 12 - student application period starts

Mar 27 - deadline for student applications

Apr 23 - accepted projects announced, community bonding starts

May 14 - coding period starts

Aug 06 - end of the coding period

See the GSoC Timeline for more info.
In the Jenkins project we will also organize special events during and after GSoC (e.g. at Jenkins world).

P.S: I am going to create a special GSoC 2018 edition of swags for mentors and students. Do not miss them ;)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/02/22/cheetah/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">22</div></div><h5 class="title">Project Cheetah - Faster, Leaner Pipeline That Can Keep Up With Demand</h5></div><p class="teaser">Table of Contents

Introducing &quot;Project Cheetah&quot;
Yes, but what does it DO?
How Do I Set Speed/Durability Settings?

1. Globally, you can choose a global default durability setting:
2. Each Pipeline can get a custom Durability Setting:
3. Multibranch Projects can use a new BranchProperty to customize the Durability Setting.

Will Performance-Optimized Mode Help Me?
Other Goodies
How Did You Do It?
What Next?

Since it launched, Pipeline has had a bit of a Dr. Jekyll and Mr. Hyde performance problem.  In certain circumstances, Pipeline can turn from a mild-mannered CI/CD assistant into a monster.  It will happily eat storage read/write capacity like popcorn without caring about the other concerns of our friendly butler.  When combined with other additional factors, this can result in real-world stability problems.  For example, combining slow storage with a spike in running Pipelines has brought down production Jenkins at more than one organization.  Similarly, users see issues if a busy controller gets hit with an extra source of stress; past culprits have been heavy automated (ab)use of Jenkins APIs, now-solved user lookup bugs, backup jobs, and plugins run crazy that load excessive numbers of builds.  Symptoms ranged from visible slowdowns in the UI to unresponsive jobs and &quot;hung&quot; controllers.

Now I’m not saying this to scare people or to criticize the technology we’ve built. Implementing Pipeline scalability best practices coupled with SSD storage keeps Jenkins in a happy place.  We just need context on the weaknesses to see why it’s important to address them.

Introducing &quot;Project Cheetah&quot;

Today we’re announcing the first major results of &quot;Project Cheetah&quot;, our long-running effort to address these challenges and improve Pipeline scalability.  More broadly, Cheetah aims to help in 3 places:

Small-scale containers: Pipeline needs to run leanly in resource-constrained containers, to enable easy scale-out without consuming excessive resources on shared container hosts.

Enterprise systems: Pipeline needs to effectively serve high-scale Jenkins instances that are central to many large companies.

General case: run Pipelines a bit more quickly on average, and allow users to get much-stronger performance in worst-case scenarios.

These changes are implemented across many of the Pipeline plugins.

Yes, but what does it DO?

Project Cheetah offers several things, but the most important is Durability Settings for all Pipelines, and especially the Performance-Optimized setting.  This setting avoids several potentially unexpected performance &quot;surprises&quot; that may strike users.  In the general case, it greatly reduces the disk IO needs for Pipeline.  How much?  Below is a graph of storage utilization with legacy Pipeline versions (think early 2017) and with the latest version using the Performance-Optimized mode.  These are tested on an AWS instance backed by an EBS volume provisioned with 300 IOPs.

Before and After:

As you can see, storage utilization goes down by a lot.  While the exact number will vary, across the benchmark testcases this results in Pipeline throughput of 2x to 6x the previous before becoming IO-bound. This also increases stability of Jenkins controllers because they will tolerate unexpected load.

This comes with a major drop in CPU IOWait as well:

And of course the rate at which data is written to disk and number of writes/s is also reduced:

For enterprise users, timing stats often show 10-20% of normal builds is serializing the Program and writing the record of steps run (&quot;FlowNodes&quot;) - the performance optimized durability setting will cut this to almost nothing (for standard pipelines, 1/100 or less) - so builds will complete faster, especially complex ones.

Please see the Pipeline Scalability documentation for deeper information on the new Durability Settings, how to use them, and which plugin versions are required to gain these features.

Also, users may see a reduction in hung Pipelines because new test utilities made it possible to identify and correct a variety of bugs.

How Do I Set Speed/Durability Settings?

There are 3 ways to configure the durability setting:

1. Globally, you can choose a global default durability setting:

Under &quot;Manage Jenkins&quot; &gt; &quot;Configure System&quot;, labelled &quot;Pipeline Speed/Durability Settings&quot;.  You can override these with the more specific settings below.

2. Each Pipeline can get a custom Durability Setting:

This is one of the job properties located at the top of the job configuration, labelled &quot;Custom Pipeline Speed/Durability Level.&quot; This overrides the global setting. Or, use a &quot;properties&quot; step - the setting will apply to the NEXT run after the step is executed (same result).

// Script //
properties([durabilityHint(&#x27;PERFORMANCE_OPTIMIZED&#x27;)])
// Declarative //
pipeline {
    agent any
    stages {
        stage(&#x27;Example&#x27;) {
            steps {
                echo &#x27;Hello World&#x27;
            }
        }
    }
    options {
        durabilityHint(&#x27;PERFORMANCE_OPTIMIZED&#x27;)
    }
}

3. Multibranch Projects can use a new BranchProperty to customize the Durability Setting.

Under the SCM you can configure a custom Branch Property Strategy and add a property for Custom Pipeline Speed/Durability Level.  This overrides the global Durability Setting and will apply to each branch at the next run.  You can also use a &quot;properties&quot; step to override the setting, but remember that you may have to run the step again to undo this.

Durability settings will take effect with the next applicable Pipeline run, not immediately.  The setting will be displayed in the log.

There is a slight durability trade-off for using the Performance-Optimized mode — the appropriate section of the Pipeline Scalability documentation has the specifics.
For most uses we do not expect this to be important, but there are a few specific cases where users may wish to use a slower/higher-durability setting. The Best Practices are documented.

We recommend using Performance-Optimized by default, but because it does represent a slight behavioral change the initial &quot;Cheetah&quot; plugin releases defaults to maintain previous behavior. We expect to switch this default in the future with appropriate notice once people have a chance to get used to the new settings.

Will Performance-Optimized Mode Help Me?

Yes, if your Jenkins instance uses NFS, magnetic storage, runs many Pipelines at once, or shows high iowait (above 5%)

Yes, if you are running Pipelines with many steps (more than several hundred).

Yes, if your Pipeline stores large files or complex data to variables in the script, keeps that variable in scope for future use, and then runs steps.  This sounds oddly specific but happens more than you’d expect.

For example: readFile step with a large XML/JSON file, or using configuration information from parsing such a file with One of the Utility Steps.

Another common pattern is a &quot;summary&quot; object containing data from many branches (logs, results, or statistics). Often this is visible because you’ll be adding to it often via an add/append or Map.put() operations.

Large arrays of data or Maps of configuration information are another common example of this situation.

No, if your Pipelines spend almost all their time waiting for a few shell/batch steps to finish.  This ISN’T a magic &quot;go fast&quot; button for everything!

No, if Pipelines are writing massive amounts of data to logs (logging is unchanged).

No, if you are not using Pipelines, or your system is loaded down by other factors.

No, if you don’t enable higher-performance modes for pipelines.  See above for how!

Other Goodies

Users can now set an optional job property so that individual Pipelines fail cleanly rather than resuming upon restarting the controller.  This is useful for niche cases where some Pipelines are considered disposable and users would value a clean restart over Pipeline durability.

We’ve reduced classloading and reflection quite significantly, which improves scaling and reduces CPU use:

Script Security (as of version 1.41) has gotten optimizations to reduce the performance overhead of Sandbox mode and eliminate lock contention so Pipeline multithreads better.

Pipeline Step data uses up less space on disk (regardless of the durability setting) - this should be 30% smaller.  Assume it’s a few MB per 1000 steps - but for every build after the change.

Even in the low-performance/high-durability modes, some redundant writes have been removed, which decreases the number of writes by 10-20%.

How Did You Do It?

That’s probably material for another blog post or Jenkins World talk.

The short answer is: first we built a tool to simulate a full production environment and provide detailed metrics collection at scale.  Then we profiled Jenkins to identify bottlenecks and attacked them.  Rinse and repeat.

What Next?

The next big change, which I’m calling Cheetah Part 2 is to address Pipeline’s logging. For every Step run, Pipeline writes one or more small log files. These log files are then copied into the build log content, but are retained to make it possible to easily fetch logs for each step.

This copying process means every log line is written twice, greatly reducing performance, and writing to many small files is orders of magnitude slower than appending to one big log file.

We’re going to remove this duplication and data fragmentation and use a more efficient mechanism to find per-step logs. This should further improve the ability to run Pipelines on NFS mounts and hard-drive-backed storage, and should significantly improve performance at scale.

Besides this, there’s a variety of different tactical improvements to improve scaling behavior and reduce resource needs.

The Project Cheetah work doesn’t free users to completely ignore Pipeline scaling best practices and previous suggestions.  Nor does it eliminate the need for efficient GC settings.  But this and other enhancements from the last year can significantly improve the storage situation for most users and reduce the penalties for worst-case behaviors.  When you add all the pieces together, the result is a faster, leaner, more reliable Pipeline experience.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/svanoort/">Sam Van Oort</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/03/05/jenkins-world-talk-proposal-tips/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 5</div></div><h5 class="title">5 tips for improving your Jenkins World 2018 talk proposals</h5></div><p class="teaser">You’ve marked your calendar to alert you weeks in advance of the CFP deadline.
You’ve spent your nights and weekends to skillfully craft your abstract and you
are convinced this is THE one.  You confidently clicked the &#x27;submit&#x27; button
only to find out weeks later you’ve received an automated declined email. On
top of feeling disappointed, you probably wondered why your proposal was turned
down.

As Jenkins World CFP
is still open, we hope to demystify the selection process by offering a few
tips to help increase the chance of your proposal getting accepted.

Tip 1: Make your title concise and attention-grabbing

There’s only a few seconds to make an impression with your proposal. Your title
and abstract should be succinct and attention grabbing. Think about what makes
your Jenkins proposal exceptional over others. What value will it bring to
attendees?

Tip 2: Know your audience

Jenkins World audiences want to learn and adopt the newest development
practices, process, languages and frameworks. They are highly technical and are
interested in deep technical talks that are original and offers valuable
information.

Tip 3: Transformational user stories

Share your unique Jenkins project experiences, challenges, strategies, lessons
learned, and outcome. What can you share with your audience that will
facilitate knowledge transfer and development of new and innovative techniques?

Tip 4: Topic should be relevant and applicable

Consider how to make the topic more broadly applicable to the attendees, such
as with a hands-on demo explaining the concept. By showcasing innovative
methods that draw out relevant and compelling knowledge to the audience,
everybody is likely to more thoroughly absord the content of the talk. Also,
who doesn’t love a cool demo?

Tip 5: Got Tips &amp; Tricks?

Jenkins is used tons of different ways.  Sharing novel approaches, tips, or
tricks for increased efficiency and proficiency with Jenkins is almost always
well received!

Important Dates:

CFP Closes: March 18, 2018 @ 11:59pm Pacific

CFP Notifications: April

Agenda Announcement: April

Event Dates:

Jenkins World USA | San Francisco | September 16 - 19, 2018

Jenkins World Europe | Nice, France | October 23 - 25, 2018

Register for Jenkins World
2018 with the code JWATONG for a 20% discount off your pass.

Good Luck!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/03/12/browser-usage/"><div class="header"><div class="date"><div class="month">March</div><div class="day">12</div></div><h5 class="title">Browser Market Share on jenkins.io</h5></div><p class="teaser">Over the last year, several efforts were done on jenkins.io like
security advisories or documentation
and I wanted to understand the impact it had on its traffic.

I had a look to the Google Analytics account used for jenkins.io and it was
interesting to discover which browsers are used by Jenkins visitors and how
this compares with other websites. So I decided to analyze one year of data
from January 2017 to January 2018. Then I selected
statcounter
as an external data source in order to compare results from jenkins.io.

First, let’s talk about numbers:

During that period, 3,496,245 users across the world visited this website.

This is a growth of 52.69% visitors compared to the year before.

92.28% of them used a desktop, 6.63% were on mobile and only 1.10% on a tablet.

Table 1. Browser Usage

Browser
Percentage

Chrome
69.82%

Firefox
14.75%

Safari
6.44%

IE
5.84%

Edge
1.59%

We clearly see that 91% of Jenkins.io visitors only use three browsers. Chrome
is by far the leader followed by Firefox and Safari.

Obviously those numbers taken alone don’t mean anything, so let’s try to put
them in perspective with another data source.

Netscape 4.8 was still used by 15 visitors over the year.

6 visitors used their Nintendo DS.

StatCounter

Let’s now compare our previous results with the same time period from
statcounter who argues to collect data from
2million websites.  Statcounter allow us to display browsers stats based on 4
different categories, &#x27;All platform&#x27;, &#x27;Desktop&#x27;, &#x27;Tablet&#x27; or &#x27;Mobile&#x27;. + For
this comparison, I am interested by &#x27;All platform&#x27; and of course &#x27;Desktop&#x27; as
92.28% of Jenkins.io visitors use a desktop.

Table 2. Browser Market Share Across All Platforms

Browser
Percentage

Chrome
54.13%

Safari
14.50%

UC Browser
8.25%

Firefox
6.15%

IE
3.89%

Excepted Chrome who still leads the ranking with &quot;only&quot; 54%, all the others
actors are totally shuffled.  Safari moved to the 2nd place with 14.50% &#x27;UC
Browser&#x27; appeared in the top 3 with 8.25% where only 0.10% of Jenkins.io
visitors were using UC browser.  Firefox moved to the 4th places with only
6.15%.  It’s interesting how this &quot;All platform&quot; browser market share from
statcounter doesn’t reflect Jenkins.io visitors&#x27; habits.
( Source )

Now at a first glance, results look more similar to the Jenkins.io visitors;
excepted for Chrome and Firefox which shed some percentages in favor of
Internet Explorer and Edge.  This promotes IE to the 3rd place with 8.86% of
usage, and downgrade Safari to the 4th place with 6,44%.  Compared to
Jenkins.io results, Edge is still at the 5th position.  It’s very interesting
to see how this ranking is so different from the &quot;All platform&quot; one but follows
the same pattern coming from Jenkins.io visitors.  This highlights how browser
choices are strongly influenced by the platform used and contrary to a general
trend,
Jenkins.io visitors remain desktop users.  This absence of mobile users
probably explains why some browsers are so under represented within Jenkins
visitors.
( Source )

Table 3. Browser Market Share on the Desktop

Browser
Usage

Chrome
63.59%

Firefox
13.75%

IE
8.86%

Safari
5.50%

Edge
4.35%

Conclusion

These observations should be carefully interpreted as it may be overestimated or underestimated (depending on various factors)  and doesn’t take into consideration local specificities.

Jenkins.io visitors are a majority of desktop users.
They are aligned with the world trends when we talk about desktop browsers however only a minority of them come from a mobile.
This is probably because jenkins.io is not (yet) mobile friendly and obsiously this would be a nice improvement to have.

All contributions are welcomed and especially for mobile user experience.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/stats">stats</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/03/15/jep-200-lts/"><div class="header"><div class="date"><div class="month">March</div><div class="day">15</div></div><h5 class="title">Security hardening: Jenkins LTS 2.107.1 switches XStream / Remoting blacklists to whitelists (JEP-200)</h5></div><p class="teaser">This is a post about a major change in Jenkins, which is available starting
from Jenkins 2.102 and Jenkins LTS 2.107.1.
This is a change with a serious risk of regressions in plugins.
If you are a Jenkins administrator, please read this blogpost and
upgrade guidelines
BEFORE upgrading.

I would like to provide some heads-up about the
JEP-200 change,
which is included into the new Jenkins LTS 2.107.x baseline.

Background

For many years Jenkins used to specifically blacklist certain classes and packages according to known or suspected exploits.
This approach has been proven unsustainable due to the risk of deserialization attacks via unknown classes
from 3rd-party components, after the
SECURITY-429/CVE-2017-1000353 fix in 2.46.2
it was decided to replace blacklists by more restrictive whitelists.
In October 2017 Jesse Glick proposed a Jenkins Enhancement Proposal,
which finally got accepted as JEP-200.

The change implies a risk of regressions in plugins serializing non-whitelisted Java-internal and 3rd-party classes,
and that’s why it is so important to follow the upgrade guidelines for this release.

Current state

JEP-200 was first integrated in Jenkins 2.102 (released in January 2018), and it has got a lot of testing since that.
See this blogpost for the original announcement.

Over the last two months we received more than 75 issues from users of Jenkins weekly releases.
All these issues have been triaged, and we have released most of the fixes.
More than 50 plugins were fixed in total, and many more plugins were updated in order to enable compatibility testing.
A significant part of the discovered regressions were caused by real defects which were causing performance and stability
issues in plugins.
Thanks a lot to all the Jenkins contributors and plugin maintainers who helped deliver timely changes for this effort!

Over last 6 weeks Jenkins weekly releases had positive community ratings,
the overall JEP-200 adoption reached ~12% of all Jenkins installations on March 01.
All major plugins have been also tested directly or verified in the wild on weekly releases.
So we are confident that the change is ready to be released in LTS.

On the other hand, we continue to receive JEP-200 regression reports.
They are mostly caused by niche plugins which are not widely used in weekly releases,
and unfortunately not all fixes have been released yet (see the Wiki page for up-to-date info).
We anticipate more regressions to be reported after the LTS release and broader adoption.

In order to simplify the upgrade to the new LTS baseline,
I have prepared some helpful materials together with Liam Newman
and Jesse Glick.
Below you can find the embedded slide deck and video, or scroll down to see the key information
in the text form.

Video:

For Jenkins administrators

Upgrading to a core with JEP-200 requires a special update procedure, which is described below.

Upgrading Jenkins

JEP-200 is not the only major change in 2.107.1, please read
the full upgrade guide carefully

If you have a way of testing the upgrade before applying it to production, do it

Back up your instance so you have any easy way of rolling back

Update all affected plugins.
See this Wiki page for the list of affected plugins,
fix statuses and workarounds

Apply workarounds for non-released patches if needed (see below)

Update to the new version of the Jenkins core

Using backups and staging servers is good advice before any upgrade but especially this one,
given the relatively high risk of regression.
Due to the nature of the changes, some plugins may refuse to load after the upgrade and cause your Jenkins service to fail to start.

After the upgrade

To the extent that advance testing of the impact of this change on popular plugins has been completed,
most users (and even plugin developers) should not notice any difference.
Still, it is highly advised to monitor your system after the upgrade, especially the following:

Jenkins System log (especially during the startup)

Job/Build logs

If you do encounter a log message referencing the https://jenkins.io/redirect/class-filter/ URL,
most likely it is a JEP-200 regression.
Example:

some.pkg.and.ClassName in file:/var/lib/jenkins/plugins/some-plugin-name/WEB-INF/lib/some-library-1.2.jar might be dangerous, so rejecting; see https://jenkins.io/redirect/class-filter/

If you see this kind of message, we highly recommend reporting it so that it can be investigated and probably fixed quickly.

Reporting JEP-200 issues

Starting from May 01, JEP-200 issues are triaged by plugin and core maintainers.
JEP-200 maintainers are available for code reviews if needed,
but they will not be reviewing cases in JIRA and searching for miscategorized issues on a daily basis.
If you experience new JEP-200 regressions, please follow the guidelines below.

Please report any issues you encounter matching the above pattern in the
Jenkins issue tracker, under the appropriate plugin component.
Before reporting please check whether this issue has already been reported.

Add the JEP-200 label

Include the stacktrace you see in the log

If possible, include complete steps to reproduce the problem from scratch

You can find examples of previously reported issues using this query.

Jenkins developers will evaluate issues and strive to offer a fix in the form of a core and/or plugin update.
Right after the feature release there was be a special team triaging the reports.
Starting from May 01 the issues will be triaged by plugin and core maintainers.
See JEP-200 Maintenance plan for more info.

For more details and current status, see
Plugins affected by fix for JEP-200.

Applying workarounds

Assuming you see no particular reason to think that the class in question has dangerous deserialization semantics, which is rare,
it is possible to work around the problem in your own installation as a temporary expedient.
Note the class name(s) mentioned in the JEP-200 log messages,
and run Jenkins with the hudson.remoting.ClassFilter startup option, e.g.:

java -Dhudson.remoting.ClassFilter=some.pkg.and.ClassName,some.pkg.and.OtherClassName -jar jenkins.war ...

This workaround process may require several iterations, because classes whitelisted in the workaround may also
include fields with types requiring whitelisting.

For plugin developers

If you are a plugin developer, please see the original JEP-200 announcement.
That blog post provides guidelines for testing and fixing plugin compatibility after the JEP-200 changes.
The presentation above also provides some information about what needs to be tested.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/upgrade">upgrade</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/03/19/introducing-jenkins-x/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Introducing Jenkins X: a CI/CD solution for modern cloud applications on Kubernetes</h5></div><p class="teaser">We are excited to share and invite the community to join us on a project we’ve been thinking about over the last few months called Jenkins X which extends the Jenkins ecosystem to solve the problem of automating CI/CD in the cloud.

Background

The last few years have seen massive changes in the software industry:

use of immutable container images for distributing software which are smaller, easier to work with and lead to cheaper infrastructure costs than VMs alone (approx 20% less on average)

Kubernetes has become the defacto way of installing, upgrading, operating and managing containers at scale on any public or hybrid cloud

2018 is the year all the major public clouds, operating system vendors and PaaS offerings support Kubernetes natively

we now have an open source industry standard for distributing, installing and managing applications on any cloud!

increased adoption of microservices and cloud native applications leading to massive increase in the number of components which require CI/CD along with increased release frequency

improvements in DevOps practices coming from the community such as the State of DevOps Report which show the approach of high performing teams

increasingly many businesses now realise that to compete you have to deliver value quickly via software

teams need to become high performing if the business is to succeed

All of this adds up to an increased demand for teams to have a solution for cloud native CI/CD with lots of automation!

Introducing Jenkins X

Jenkins X is a project which rethinks how developers should interact with CI/CD in the cloud with a focus on making development teams productive through automation, tooling and DevOps best practices.

Jenkins X is open source and we invite you to give us feedback and to contribute to the project.

Whats the big deal?

For many years Jenkins has been capable of doing pretty much anything in the CI/CD space; the challenge has always been figuring out how to get the right plugins, configuration and code to work together in your Jenkinsfile.

For me the big deal about Jenkins X is as a developer you can type one command jx create or jx import and get your source code, git repository and application created, automatically built and deployed to Kubernetes on each Pull Request or git push with full CI/CD complete with Environments and Promotion via GitOps!

Developers and teams don’t have to spend time figuring out how to package software as docker images, create the Kubernetes YAML to run their application on kubernetes, create Preview environments or even learn how to implement CI/CD pipelines with declarative pipeline-as-code Jenkinsfiles. It’s all automated for you out of the box! So you can focus instead on delivering value!

At the same time, Jenkins X doesn’t hide anything. If you do want to hack the Dockerfile, Jenkinsfile or Helm charts for your apps or their environments then go right ahead - those are all available versioned in git with the rest of your source code with full CI/CD on it all. GitOps FTW!

Jenkins X automates CI/CD and DevOps best practices for you - so you can become a faster performing team! Let your butler do more work for you!

Demo

Here’s a demonstration of Jenkins X running on GKE:

You can check out more demos here.

Jenkins X Features

Now lets walk through the features of Jenkins X that we showed in the demo:

Automated CI/CD Pipelines

Create new Spring Boot projects, new quickstarts or import existing source code quickly into Jenkins X via the jx command line tool and:

get a Pipeline automatically setup for you that implements best practice CI/CD features:

creates a Jenkinsfile for defining the CI/CD pipelines through declarative pipeline-as-code

creates a Dockerfile for packaging the application up as an immutable container image (for applications which generate images)

creates a Helm chart for deploying and running your application on Kubernetes

ensures your code is in a git repository (e.g. GitHub) with the necessary webhooks to trigger the Jenkins CI/CD pipelines on push events

triggers the first release pipeline to promote your application to your teams Staging Environment

Then on each Pull Request:

a CI pipeline is triggered to build your application and run all the tests ensuring you keep the master branch in a ready to release state

your Pull Request is deployed to a Preview Environment (more on this later)

When a Pull Request is merged to the master branch the Release pipeline is triggered to create a new release:

a new semantic version number is generated

the source code is modified for the new version (e.g. pom.xml files get their elements modified) and then tagged in git

new versioned artifacts are published including:

docker image, helm chart and any language specific artifacts (e.g. pom.xml and jar files for Java, npm packages for node or binaries for go etc)

the new version is promoted to Environments (more on this later)

Environment Promotion via GitOps

In Jenkins X each team gets their own environments. The default environments are Staging and Production but teams can create as many environments as they wish and call them whatever they prefer.

An Environment is a place to deploy code and each Environment maps to a separate namespace in Kubernetes so they are isolated from each other and can be managed independently.

We use something called GitOps to manage environments and perform promotion. This means that:

Each environment gets its own git repository to store all the environment specific configuration together with a list of all the applications and their version and configuration.

Promotion of new versions of applications to an environment results in:

a Pull Request is created for the configuration change that triggers the CI pipeline tests on the Environment along with code review and approval

once the Pull Request is merged the release pipeline for the environment which updates the applications running in that environment by applying the helm chart metadata from the git repository.

Environments can be configured to either promote automatically as part of a release pipeline or they can use manual promotion.

The defaults today are for the Staging environment to use automatic promotion; so all merges to master are automatically promoted to Staging. Then the Production environment is configured to use manual promotion; so you choose when do promote.

However it is easy to change the  configuration of how many environments you need and how they are configured via the jx create environment and jx edit environment commands

Preview Environments

Jenkins X lets you create Preview Environments for Pull Requests. Typically this happens automatically in the Pull Request Pipelines when a Pull Request is submitted but you can also perform this manually yourself via the jx preview command.

The following happens when a Preview Environment is created:

a new Environment of kind Preview is created along with a kubernetes namespace which show up the jx get environments command along with the jx environment and jx namespace commands so you can see which preview environments are active and switch into them to look around

the Pull Request is built as a preview docker image and chart and deployed into the preview environment

a comment is added to the Pull Request to let your team know the preview application is ready for testing with a link to open the application. So in one click your team members can try out the preview!

This is particularly useful if you are working on a web application or REST endpoint; it lets your team interact with the running Pull Request to help folks approve changes.

Feedback

If the commit comments reference issues (e.g. via the text fixes #123) then Jenkins X pipelines will generate release notes like those of the jx releases.

Also, as the version associated with those new commits is promoted to Staging or Production, you will get automated comments on each fixed issue that the issue is now available for review in the corresponding environment along with a link to the release notes and a link to the app running in that environment. e.g.

Getting started

Hopefully you now want to give Jenkins X a try. One of the great features of Jenkins is that it’s super easy to get started: install Java, download a war and run via java -jar jenkins.war.

With Jenkins X we’ve tried to follow a similarly simple experience. One complication is that Jenkins X has more moving pieces than a single JVM; it also needs a Kubernetes cluster :)

First you need to download and install the jx command line tool so its on your PATH.

Then you need to run a single command to create a new Kubernetes cluster and install Jenkins X (in this example, on GKE).

jx create cluster gke

Today we support creating Kubernetes clusters and installing Jenkins X on Amazon (AWS), Google (GKE), Microsoft Azure, and even locally using minikube.
We plan to support AWS EKS soon.

At the time of this writing the easiest cloud to get started with is Google’s GKE so we recommend you start there unless you already use AWS or Azure. Amazon and Microsoft are working hard to make Kubernetes clusters as easy to create and manage as they are on GKE.

All the public clouds have a free tier so you should be able to spin up a Kubernetes cluster and install Jenkins X for a few hours then tear it down and it should be cheaper than a cup of coffee (probably free!). Just remember to tear down the cluster when you are done!

Here’s a demo of creating a kuberentes cluster and installing Jenkins X :

If you really don’t want to use the public cloud, you can install Jenkins X on an existing kubernetes cluster (if it has RBAC enabled!). Or, if you can install and run minikube, then you should be able to install Jenkins X on it as well.

Relationship between Jenkins and Jenkins X

Jenkins is the core CI/CD engine within Jenkins X. So Jenkins X is built on the massive shoulders of Jenkins and its awesome community.

We are proposing Jenkins X as a sub project within the Jenkins foundation as Jenkins X has a different focus: automating CI/CD for the cloud using Jenkins plus other open source tools like Kubernetes, Helm, Git, Nexus/Artifactory etc.

Over time we are hoping Jenkins X can help drive some changes in Jenkins itself to become more cloud native, which will benefit the wider Jenkins community in addition to Jenkins X.

Please join us!

So I hope the above has given you a feel for the vision of where we are heading with Jenkins X and to show where we are today. The project is still very young, we have lots to do and we are looking for more input on where to go next and what to focus on. We’re also working on high level roadmap.

To make Jenkins X a success we’d love you to get involved, try it out and give us feedback in the community! We love contributions whether its email, chat, issues or even better Pull Requests ;).

If you’re thinking of contributing here’s some ideas:

Give us feedback. What could we improve? Anything you don’t like or you think is missing?

Help improve the documentation so its more clear how to get started and use Jenkins X

Add your own quickstarts so the Jenkins X community can easily bootstrap new projects using your quickstart. If you work on an open source project is there a good quickstart we could add to Jenkins X?

If you’d like to contribute to the code then try browse the current issues.

we have marked issues help wanted or good first issue to save you hunting around too much

in particular we would love help on getting Jenkins X working well on windows or the integrations with cloud services, git providers and issues trackers

for more long term goals we’ve the roadmap

we could always use more test cases and to improve test coverage!

To help get faster feedback we are using Jenkins X as the CI/CD platform to develop Jenkins X itself. For example Jenkins X creates all the releases and release notes. We’ll talk more about UpdateBot in a future blog post but you can see all the automated pull requests generated in the various Jenkins X pipelines via UpdateBot pushing version changes from upstream dependencies into downstream repositories.

Note that the Jenkins community tends to use IRC for chat and the Kubernetes community uses Slack, so Jenkins X has rooms for both IRC and slack depending on which chat technology you prefer - as the Jenkins X community will be working closely with both the Jenkins community and the various Kubernetes communities (Kubernetes, Helm, Skaffold, Istio et al).

One of the most rewarding things about open source is being able to learn from others in the community. So I’m hoping that even if you are not yet ready to use Kubernetes in your day job or are not yet interested in automating your Continuous Delivery - that you’ll at least consider taking a look at Jenkins X, if for no other reason than to help you learn more about all these new ideas, technologies and approaches!

Thanks for listening and I’m looking forward to seeing you in the community.

Links

Jenkins X JEP proposal

Jenkins X website

Getting Started Guide

Demos<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jstrachan/">James Strachan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/03/19/password-audit/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Jenkins community account password audit</h5></div><p class="teaser">Last year, news of compromised passwords being used for accounts able to distribute NPM packages made the rounds.

Their system looks similar to how publishing of plugins works in the Jenkins project:

Accounts are protected by passwords chosen by users.

Individual contributors have permission to release the components they maintain.

The components they release are used by millions of developers around the world to deliver their software.

In other words, weak passwords are a problem for us just as much as for NPM, and what happened to them could happen to us.

To address this problem, the Jenkins security and infra teams have recently collaborated on a password audit.
The audit covered all accounts with permissions to upload plugins and components, and on accounts with other levels of privileged infrastructure access.
We ran brute force tools on salted password hashes of those accounts looking for &quot;weak&quot; passwords — passwords present in a set of publicly available password lists we chose for this audit.

We checked the password of every qualifying account for every unsafe password rather than trying to match them to any previous password leaks&#x27; email/password pairs.
Users with weak account passwords were notified via email a few weeks ago and were asked to change their password to something stronger.

We performed the same checks over the previous weekend, but this time we only checked the passwords of accounts whose passwords were deemed weak during our first check.
We then invalidated the password of any account whose password was still not considered &quot;strong&quot; (i.e. their password was unchanged or had been changed to another weak password).
Users of those accounts will need to request a password reset before signing in again.

We plan to implement further safeguards, including improving the account management app at https://accounts.jenkins.io to reject weak passwords.
If you’re interested in helping the security team make Jenkins more secure, let us know on the jenkinsci-dev mailing list, or request to join the security team.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/03/20/evolving-mission-of-jenkins/"><div class="header"><div class="date"><div class="month">March</div><div class="day">20</div></div><h5 class="title">Evolving Mission of Jenkins</h5></div><p class="teaser">Lately, perhaps subtle but exciting changes are starting to happen in the Jenkins project.

The past few weeks have seen the birth of two new initiatives in Jenkins:
Jenkins Essentials and
Jenkins X.  Each is
exciting in its own right, and I encourage interested parties to take a look at
their goals and missions and participate in them.  But in this post, I want to
discuss why together these two dots form an important arc, which actually
started in the introduction of Jenkins 2 and continued with Blue Ocean.

In Jenkins 2, we changed Jenkins so that it starts with richer functionality
and more sensible security setup, among other things.  This was the first step
in a new direction for Jenkins.  We changed our focus from “we’ll write plugins
and you figure out the rest” to “we’ll write plugins, we’ll assemble them, and
we’ll help you be more productive.”

Blue Ocean was another step on this journey.  We focused on important
continuous delivery use cases in Jenkins, and aimed to provide a great
user-experience for those use cases.  Aside from obvious productivity boost for
users, it also decidedly blended together feature areas that are internally
provided by a whole bunch of different plugins, but users see much less seam
between them.

Jenkins Essentials, which R Tyler Croy proposed in
recent weeks, is another step forward.  That project aims to take an even
bigger responsibility in keeping people’s Jenkins instances up and running.
Like Blue Ocean, Jenkins Essentials focuses on delivering a comprehensive
Jenkins user experience rather than a collection of unrelated plugins which
users have to figure out how to wire together.  It also creates an exciting
vehicle for contributors, in which we can develop and deliver features quite
differently, and more rapidly, than how we deliver them today.

Jenkins X, which was proposed by James Strachan a
few weeks after Jenkins Essentials, is the latest point on this same arc.
Jenkins X brings a different aspect to building a solution — it focuses on a
specific vertical area, namely Kubernetes application development, and
drastically simplifies the software development in that domain by bringing
together Jenkins, a whole bunch of plugins, and an opinionated best practice of
how one should use Kubernetes.

Collectively, the arc that these efforts form aims to solve the most important
and consistent concerns for Jenkins users — ease of use, plugin complexity,
fear of upgrade, etc.

In the early days of Jenkins, it was up to each and every Jenkins admin to find
the right way to assemble pieces into a solution for their organizations, but
this hard work remained largely private.  Now, these newer projects are
bringing this back into the community.  They are making Jenkins more valuable
to existing users, and more approachable and useful to a whole new set of users
who are not currently using Jenkins.

From that perspective, I hope more projects like them will follow, pushing us
beyond “just writing plugins”, taking even bigger steps to make users
productive.  This is a little bit like how I watched Eclipse evolve from just a
Java IDE to an umbrella of projects.

Exciting times!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/06/jenkins-essentials/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 6</div></div><h5 class="title">Jenkins Essentials: five minutes, five clicks</h5></div><p class="teaser">Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.

In his presentation at the 2017 Jenkins World Contributor Summit,
Kohsuke
challenged us to continue the work started with Jenkins 2 of making Jenkins
easier to install and easier to use. &quot;A user should be successful with Jenkins
in under five minutes and five clicks.&quot; At that same Contributor Summit, a few
of us discussed the idea of a distribution which had &quot;batteries
included&quot;, which
Andrew
proudly named &quot;Jenkins Essentials.&quot; At the time I was certainly not as excited
about the project as I am now, I thought to myself &quot;we built a Setup Wizard in
Jenkins 2, nobody needs a Setup Wizard++.&quot;

As Kohsuke and I continued to discuss the idea, more and more ideas came up.
Towards the end of 2017 the picture became much clearer: Jenkins Essentials
would be a comprehensive, low-maintenance distribution to help new and
existing users be successful with Jenkins, without needing to be Jenkins
experts. This will of course not replace the existing distribution of Jenkins core and
its plugins, which allow many of us large amounts of flexibility, but rather it
will make Jenkins easier for users who don’t want to &quot;build it themselves.&quot;

The more I thought about it, the more excited about the idea I became: Jenkins
Essentials could open the door to new improvements and features in Jenkins
which had been left in the &quot;idea and design&quot; phase going back almost two
years! Really, I checked, some of the concepts adopted into the design of
Jenkins Essentials were first conceived of in early 2016!

Kohsuke briefly discussed the project in
his previous blog post
but in post I wanted to expand on what Jenkins Essentials is, and our
progress has been in its development.

What’s in Jenkins Essentials

A few months ago I prepared
this presentation
for the
FOSDEM 2018
Jenkins Contributor Summit, which outlines the following &quot;pillars&quot; or Jenkins
Essentials, which are also described in
JEP-300 :

Automatically Updated Distribution

Automatic Sane Defaults

Connected

Obvious Path to User Success

Automatically Updated Distribution

In order to provide an easier-to-use and easier-to-manage Jenkins environment,
Jenkins Essentials will be distributed as an automatically self-updating
distribution, containing Jenkins core and a version-locked set of plugins
considered &quot;essential.&quot; Rather than attempting to mirror the existing Weekly
and LTS release lines for core, plus some plugin version matrix, Jenkins
Essentials will update in a manner similar to Google Chrome.

This automatically updating distribution will mean that Jenkins Essentials will
require significantly less overhead to manage, receiving improvements and bug
fixes without any user involvement. From the user perspective, their Jenkins
will appear to automatically improve over time.

There is really interesting work being pioneered by
Baptiste Mathus
with
JEP-302
to ensure that these automatic upgrades can be performed safely.

Automatic Sane Defaults

Providing a core along with &quot;essential&quot; plugins is a good first step to helping
Jenkins users successfully automate their CI/CD workloads, but requires
additional &quot;smoothing&quot; over some of the numerous options and configurations
plugins. Jenkins Essentials will perform some amount of &quot;automatic
environment-based self-configuration.&quot;

For example, clicking a &quot;Launch Stack&quot; button from the Download
page would launch an AWS-flavored Jenkins Essentials which, out of the box
attempts to set up AWS-specific configuration with S3 and EC2 services.

Connected

In order to provide a more seamless experience for end-users, and ensure that
Jenkins project developers receive useful error and usage telemetry to drive
further improvements in Jenkins, Jenkins Essentials must necessarily be viewed
as a &quot; Connected&quot; application. This means some yet-to-be-specified number of
server-side applications to coordinate updates, receive and process telemetry,
broker 3rd-party service authentications, relay webhooks, etc.

Obvious Path to User Success

The final pillar in Jenkins Essentials, is to ensure that Jenkins provides an
obvious path for a user to configure and use it successfully. This largely
entails in-application documentation, examples, and disabling legacy
functionality within the application. All with the end goal of preventing users
from inadvertently choosing legacy, or poorly supported, options when
configuring their CI/CD workloads.

Progress thus far

Suffice it to say, Jenkins Essentials is a hugely ambitious project! We have
been making steady progress however, as you can see in the
jenkins-infra/evergreen
repository on GitHub. We have been adamantly following the
Jenkins Enhancement Proposal
process, and have been making sure our designs and implementations are clear as
we build them. Thus far we’ve written designs and implemented:

JEP-300: Jenkins Essentials

JEP-301: Evergreen packaging for Jenkins Essentials

JEP-302: Evergreen snapshotting data safety system

JEP-303: Evergreen Client Registration and Authentication

JEP-304: Essentials Client Error Telemetry Logging

Unfortunately we don’t yet have the first parts of the Automatically Updated Distribution working,
which means you cannot download Jenkins Essentials today and get started with
it. We’re still building the Jenkins-side and server-side components necessary
to make the full feedback loop operate, without which we would not be able to
safely deliver new upgrades to Jenkins Essentials installations.

If you’re interested in getting involved, you can check out our
Gitter channel
or our
Jira issues board.

Jenkins Essentials is just one major initiative going on in the Jenkins project
this year, so I hope you’re as excited as I am for the future of Jenkins!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/09/whats-in-declarative/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 9</div></div><h5 class="title">The new things arriving in Declarative Pipeline!</h5></div><p class="teaser">Last week we released the latest version of Declarative Pipelines, version
1.2.8. With that out, we thought now would be a good time to introduce you to
the new features and options that have been added to Declarative since the
beginning of 2018. These are all available now in the Update Center, with
version 1.2.8.

Declarative Directive Generator

This is something we’re really happy about - if you go to the &quot;Pipeline Syntax&quot;
link from your Pipeline’s page in Jenkins, you’ll see a couple new links on the
left, including &quot;Declarative Directive Generator&quot;. The Directive Generator is
much like the Snippet Generator that’s been in Pipeline for a couple years now,
but where the Snippet Generator is just for filling out a form for a step and
generating the Pipeline code that configuration maps to, the Directive
Generator is built to help you write your Declarative Pipeline directives, like
agent, options, stage, and more!

This is the first release to include the Directive Generator, and it’s
definitely going to see more polish going forward, but we think it should be
quite helpful for you already. We’ll be putting up another blog post looking at
the Directive Generator in more detail in the near future.

New when conditions

We’ve added a number of new when conditions, providing you more control over
whether your stages get executed.

equals - Compares two values - strings, variables, numbers, booleans - and
returns true if they’re equal. I’m honestly not sure how we missed adding
this earlier! You can do &quot;not equals&quot; comparisons using the not { equals …​
} combination too.

changeRequest - In its simplest form, this will return true if this
Pipeline is building a change request, such as a GitHub pull request. You can
also do more detailed checks against the change request, allowing you to ask
&quot;is this a change request against the master branch?&quot; and much more.

buildingTag - A simple condition that just checks if the Pipeline is
running against a tag in SCM, rather than a branch or a specific commit
reference.

tag - A more detailed equivalent of buildingTag, allowing you to check
against the tag name itself.

In addition, we’ve added a new option to when : beforeAgent. This allows you
to specify that the when conditions should be evaluated before entering the
agent for the stage, rather than the normal behavior of evaluating when
conditions after entering the agent. When beforeAgent true is specified,
you will not have access to the agent’s workspace, but you can avoid
unnecessary SCM checkouts and waiting for a valid `agent to be available. This
can speed up your Pipeline’s execution in some cases.

New post conditions

The changed condition has always been a bit confusing, and to be
honest, it wasn’t our best work. changed will fire any time the current run’s
status is different than the previous run’s status - whether the current run is
healthier than the previous one, or the other way around. That’s…​not actually
very useful. So now we’ve added two new post conditions that should provide
you with a lot more value than changed has.

fixed - This will check to see if the current run is successful, and if the
previous run was either failed or unstable.

regression - This will check to see if the current run’s status is worse
than the previous run’s status. So if the previous run was successful, and
the current run is unstable, this will fire and its block of steps will
execute. It will also run if the previous run was unstable, and the current
run is a failure, etc.

New options

The options directive in Declarative can contain a number of different kinds
of configuration: traditional Jenkins job properties, like buildDiscarder,
wrapper steps to execute the entire Pipeline within, like timeout, and
Declarative-specific options that can switch from some default behaviors of
Declarative execution. We’ve added two new Declarative-specific options in the
last few releases.

checkoutToSubdirectory - Allows you to override the location that the
automatic SCM checkout will use. Using checkoutToSubdirectory(&quot;foo&quot;), your
Pipeline will checkout your repository to&quot;$WORKSPACE/foo&quot;, rather than the
default of&quot;$WORKSPACE&quot;.

newContainerPerStage - If you’re using a top-level docker or dockerfile
agent, and want to ensure that each of your stages run in a fresh container
of the same image, you can use this option. Any stage without its own
agent specified will run in a new container using the image you’ve
specified or built, on the same computer and with access to the same
workspace.

Stage options

Sometimes, you may only want to disable automatic checkout of your repository,
using the skipDefaultCheckout(true) option, for one specific stage in your
Pipeline. Or perhaps you want to have a timeout that covers an entire
stage, including time spent waiting for a valid agent, post condition
execution, or the new input directive for stages (see further down for more
details on that!). To make those things possible, we’ve added a new options
direction to stage. You can use a subset of the top-level options content
in a stage’s `options - wrapper steps, and Declarative-specific options that
are marked as legal in a stage.

Input

You’ve always been able to run the input step inside a stage’s `steps
block, but we’ve found that approach can lose out on some of the value that the
input step provides.

To help with that, we’ve added a new input directive
to stage, with the same parameters as the input step. When you use the
stage input directive rather than using the step directly, any parameters
you’ve specified for the input will be made available in the stage’s
environment, meaning you can reference parameters from the `input in when
conditions, or in environment variables.

// Declarative //
pipeline {
    agent none
    stages {
        stage(&#x27;Example&#x27;) {
            input {
                message &quot;Should we continue?&quot;
                ok &quot;Yes, we should.&quot;
                submitter &quot;alice,bob&quot;
                parameters {
                    string(name: &#x27;PERSON&#x27;, defaultValue: &#x27;Mr Jenkins&#x27;, description: &#x27;Who should I say hello to?&#x27;)
                }
            }
            agent any
            steps {
                echo &quot;Hello, ${PERSON}, nice to meet you.&quot;
            }
        }
    }
}
// Script //

Also, the input directive is evaluated before you enter any agent specified
on this stage, so if you are using a top-level agent none and each stage
has its own agent specified, you can avoid consuming an executor while
waiting for the input to be submitted.

Lastly, you can use timeout in the stage options, as
mentioned above, to time-out the input if too much time has passed without a
response.

I hope you find these new features and options for Declarative Pipelines
helpful, and I look forward to the rest of 2018 as we continue to invest and
improve in Jenkins Pipeline!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/10/opinionated-cd-jenkins-x/"><div class="header"><div class="date"><div class="month">April</div><div class="day">10</div></div><h5 class="title">Opinionated Kubernetes and Jenkins X</h5></div><p class="teaser">I
recently wrote
about how all the cloud platforms are all in Kubernetes and so are developers.
It is an exciting time, but the problem for many is that this is
a huge blank sheet of paper for how to build and deploy applications.
A white space, a void, a limitless canvas of possibilities.
Insert metaphors here.

The problem, as you may guess, is that few people really like or are able to start with a blank canvas.
I know I prefer to start with something working and iterate towards a solution,
or be given some rails to stay on (again with the metaphors).

That’s where the Jenkins X project comes in.
Jenkins X is a Kubernetes-native continuous integration and continuous delivery platform
for developing cloud native applications that was recently introduced as a
Jenkins Enhancement Proposal,
sponsored by James Strachan.

There is a lot to take in but at it’s heart,
this is an open source opinionated way to do continuous delivery with Kubernetes,
natively, without necessarily having to learn all the things I talked about in my last blog post.
I shall attempt to explain what this is all about and why it matters to developers.
As someone said on the jenkins-dev mailing list
“We have the two glued together with baling wire and twine” -
Jenkins X aims to simplify how to work with continuous delivery and Kubernetes.

First and most importantly, let’s see the logo:

You can see the nautical theme leaking through (and Kubernetes).
Whilst it is called Jenkins X, it is about quite a lot more than Jenkins.

Jenkins X makes decisions for you

Jenkins X presents itself to you initially as a handy sleek command line
(a native binary you can install called jx - the debate is on as to how pronounce it).
Let’s take a tour (sail?):

jx import my-app

If you have an existing project, this will detect what type of project it is, build a pipeline for you (and a bunch of Kubernetes things, like Helm Charts), add it to your project and set it up in GitHub, WebHooks and all, build the project (run the pipeline) and deploy a version to a “staging” environment.

If it looks ok, you can promote it to production:

jx promote --env production --version 1.0.1 my-app

If something went wrong in production, you can roll back an app to any version (the version numbers are made for you):

jx promote --env production --version 1.0.0 my-app
&gt; jx get apps # list versions

An environment is a well-established concept for web developers using
continuous delivery: out of the box Jenkins X makes three of them for you
(dev, staging and production), but you can make as many as you like.
Environments have rules around how things are promoted into them
(and they also have their own extensible pipelines,
but you can just use them as-is to start).

You can also create a Spring Boot microservice app:

jx create spring

Answer a few questions and it will set everything up for you.

Any changes you make to your app automatically are built,
and if the build looks good, they go through to the staging environment.
WebHooks are setup for you (if you are using GitHub) to smooth this over.

For those looking at starting from pre-made apps, there are &quot;quickstarts&quot;:

jx create quickstart

They are based on a growing set of starter apps, in a variety of languages and tech stacks.

Review apps for your changes: Each pull request is built/tested,
and a “review app” is made available in a temporary environment.
That means each proposed change, before it goes to the default branch (master),
has an environment made (temporary) that it can be tried out in.
In GitHub, this shows up as a comment in the pull request:

Project type detection

As you can see, so far there is no editing or manual creation of pipelines,
or scripting or setup, just importing or creating your app and go.
This is powered by
Draft “packs”
(a handy project that came out of Azure).
 What you end up with is a Jenkinsfile in your project repository.
 You may want to edit it one day, or you may be happy with it as is!
 Jenkins is famous for being un-opinionated in what you do,
 but Jenkins X has strong opinions (but you can extend and customise).

image::/images/jenkins-x/draft-logo.png[Draft Logo, width=300]

Deploying or promoting to environments

Deploying happens via pipelines behind the scenes -
when a change is pushed, or a version promoted.
You don’t need to directly interact with Kubernetes if you don’t need to.
A tool called Helm does the heavy lifting:
Helm is used to package and perform installations and upgrade for your apps.

There is a little more magic going on here with environments, which you don’t see at first.
Each environment, for a team, is represented by a Git repository behind the scenes.
Configuration as code is a well-established best practice these days,
so why not use it to track deployments and initiate deployments.
I also mentioned in my previous post how declarative Kubernetes is:
it is perfect for keeping all config in a repository, of the desired system state.

Each promotion is actually a pull request to a per-environment repository.
This repository is made and managed for you (and kept outside of the
main application code repository), you don’t have to look at it,
but you can extend things there should you need to.
Specific environment repositories may have different access rules,
or be controlled by a different team (perhaps even deploy to a different cluster).
Some have coined the term for this as “GitOps.”
I first came across this concept on a
WeaveWorks blog.

I’ll try and explain this one with a diagram:

The pipeline is actually split in the middle.
On the left is the more familiar continuous integration pipeline.
This works on pull requests, pre-release version of things
and is all about testing(automated and manual review).
The source of truth for this is the configuration in the
applications repository: branches, pull requests and so on.

The right-hand side is the continuous delivery pipeline.
This kicks in when the application is ready to be updated with a new release.
This is the “GitOps” repo behind the scenes that controls the state of things in Kubernetes.
A promotion on this side is a pull request, and then a merge,
from the staging repository to the production repository.

Installing Jenkins X

The jx command line has a jx install command that installs it into a Kubernetes cluster.

The best experience initially is using Google’s excellent GKE service:

jx create cluster gke

This will ask a few questions, and go and set it all up for you in a
cluster set aside for Jenkins X (recommended).
Jenkins X runs entirely as services on top of a Kubernetes cluster.

jx install

Is designed to work with a Kubernetes cluster (if it already exists,
recommendation is to have a cluster put aside for Jenkins X if possible).
Amazon EKS support is coming (mostly it is around testing),
that service is in beta/early access so it is still a work in progress,
as is Microsoft Azures excellent AKS service.

So where is Jenkins?

Good question, thanks for asking. Well, it is behind the scenes.
As you have seen, there was no direct interaction with Jenkins,
but it is there, running the pipelines for continuous integration and
continuous delivery of the respective repositories, and orchestrating things with Kubernetes.

If you run jx get pipelines you can see URLs to the various pipelines
that have been setup for you are part of interacting with Jenkins X.

By the way,
James Strachan has written an extensive blog on jenkins.io
that really explores the Jenkins X project in-depth.
Once you finish reading this blog, take a stroll on over there and read James&#x27;.
He also provides several ways you can get involved in the project.

What else can I do with the command line?

Lots, the jx command line has built in help:

jx open

open apps, services or pipelines in your browser

jx activity

explains how things got to where they are, a history

jx get environments

list environments

jx get apps

show the state of applications, what versions are in what environments.

What’s next

There is a whole lot more to this, and lots more moving parts and services
that are set up for you that are very useful, but it is best to head over
to jenkins-x.io and have a look.

This project is obviously in early stages (it is stll a Draft JEP after all) and there is lots happening.
Check out the Jenkins X community
if you want to chat on slack, IRC, issues or email.
Also, read the
Jenkins Enhancement Proposal doc.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/11/security-updates/"><div class="header"><div class="date"><div class="month">April</div><div class="day">11</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.116 and 2.107.2, that fix two security vulnerabilities.

For an overview of what was fixed, see the security advisory.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/13/jenkins-x-23-days-later/"><div class="header"><div class="date"><div class="month">April</div><div class="day">13</div></div><h5 class="title">Jenkins X making awesome progress after 24 days</h5></div><p class="teaser">Its been 24 days since we
announced Jenkins X,
a CI/CD solution for modern cloud applications on Kubernetes.
I’m truly blown away by the response and feedback from the community - thank you!

We’ve also had lots of folks report they’ve successfully used Jenkins X
on a number of clouds including GKE, AWS and AKS along with on-premises clusters which is great to hear!

Here’s a brief overview of the changes in the last 24 days from the
Roadmap :

we now fully support GitHub and GitHub enterprise. BitBucket cloud and gitea is almost there too.
Hopefully BitBucketServer and Gitlab are not too far away either. For more detail see
supporting different git servers

For issue tracking we support GitHub, GitHub Enterprise and JIRA. For more detail see
supporting issue trackers

Gradle support is now available from jx create spring
or by importing gradle apps

Go, Node and Rust build packs are now available with more planned

New addons for anchore and kubeless

Also we’ve made it a little bit easier to keep your jx binary up to date continuously. Just type one of the following:

jx version will prompt you if there is a new version available
and if prompted, it will upgrade itself

jx upgrade cli will upgrade the jx binary if its available or
jx upgrade platform for the platform

For more detail on the changes over the last 24 days with metrics please see the
changelog generated by Jenkins X

We’d love to hear your feedback what you think of
Jenkins X and the
Roadmap - please
join the community.

Links

Jenkins X website

Demos

Jenkins X JEP proposal<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jstrachan/">James Strachan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/16/jenkins-x-explained-part1/"><div class="header"><div class="date"><div class="month">April</div><div class="day">16</div></div><h5 class="title">Jenkins X Explained Part 1 - an integrated CI/CD solution for Kubernetes</h5></div><p class="teaser">Jenkins X is an opinionated platform for providing CI / CD on top of
Kubernetes.
We’ve chosen a set of core applications that we install and wire together so things work out-of-the-box, providing a
turn key experience. This blog aims to build on previous introductions to Jenkins X and provide a deeper
insight to what you get when you install Jenkins X.

So what happens? After downloading the jx CLI you will now be able to create clusters with public cloud providers
or install onto an existing Kubernetes cluster.

This command will create a cluster on your cloud provider of choice.

jx create cluster

Alternatively you can bring your own Kubernetes cluster and install Jenkins X on it:

jx install

That said, we’ve found that creating a new cluster on a public cloud such as GKE
is a lot way easier to start as we can be sure of the state of the cluster.
For example we know that storage, networking and loadbalancers will be working as expected.
Creating a cluster on GKE takes only a few minutes so it’s a great way to try things out as well as run your
enterprise workloads.

For now lets assume we are using GKE. When jx create cluster has finished you will see some output in the
terminal that also includes the default admin password to use when logging into the core applications below.
There is a flag --default-admin-password you can use to set this password yourself.

Accessing applications

We automatically install an Nginx ingress controller running with an external loadbalancer pointing at it’s
Kubernetes service. We also generate all the Kubernetes Ingress rules using a golang library called
&quot; exposecontroller&quot;.
This runs as a Kubernetes Job triggered by a
Helm hook once any application is installed to the cluster.

Using &quot;exposecontroller&quot; means we can control all the ingress rules for an environment using a single set of
configurations, rather than each application needing to know how to expose the kubernetes service to the outside world.
This also means we can easily switch between HTTP and HTTPS plus support intregration with projects like
cert-manager for auto generation of signed TLS certificates.

Environments

One important point to make is Jenkins X aims to use terminology that developers are familiar with. That’s not
to say we are changing Kubernetes fundamentals, it’s more that if you don’t know Kubernetes concepts then we aim
to help you still adopt the cloud technology and pull back the curtain as you gain confidence and experience.
To that point, a core part of Jenkins X are &quot;environments&quot;. An environment can have one or more applications running
in it. In Kubernetes term an &quot;environment&quot; maps to the concept of a &quot;namespace&quot; in code.

The installation by default created three environments, this is customisable but by default we have a &quot;dev&quot;, a &quot;staging&quot;
and a &quot;production environment&quot;. To list, select, or switch between these environments run:

jx env

Jenkins X core applications

In the &quot;dev&quot; environment we have installed a number of core applications we believe are required at a minimum
to start folks off with CI/CD on Kubernetes. We can easily add to these core apps using Jenkins X addons but
for now lets focus on the core apps. Jenkins X comes with configuration that wires these services together,
meaning everything works together straight away. This dramatically reduces the time to get started with Kubernetes
as all the passwords, environment variables and config files are all setup up to work with each other.

Jenkins — provides both CI and CD automation. There is an effort to decompose Jenkins over time to
become more cloud native and make use of Kubernetes concepts around CRDs, storage and scaling for example.

Nexus — acts as a dependency cache for Nodejs and Java applications to dramatically improve build
times. After an initial build of a SpringBoot application the build time is reduced from 12 mins to 4. We
have not yet but intend to demonstrate swapping this with Artifactory soon.

Docker Registry — an in cluster docker registry where our pipelines push application images, we will
soon switch to using native cloud provider registries such as Google Container Registry, Azure Container
Registry or Amazon Elastic Container Registry (ECR) for example.

Chartmuseum — a registry for publishing Helm charts

Monocular — a UI used for discovering and running Helm charts

Helm

We learned a lot in our early days with fabric8 on Kubernetes and there were some projects from the ecosystem
that either weren’t around or (at the time) didn’t work with OpenShift, therefore we were restricted when
making some design decisions. A couple of years on and now with Jenkins X we were able to look at other OSS
projects that have been flourishing, so I was very happy to start looking at Helm.
Helm is a package manager for Kubernetes and allows easy installation and upgrades of applications.

It was pretty clear that for Jenkins to evolve and include deployments to the cloud we should embrace Helm
and provide an opinionated experience that helps teams and developers. The core applications mentioned above
means Jenkins X provides an out of the box integrated CI/CD solution for Helm.

We know that helm has limitations but with the work on
Helm 3, the focus of the Kubernetes
sig-apps group, the Kubernetes community and investment we see from key organisations such as Microsoft, we feel Helm
is currently the best way to install and upgrade applications on Kubernetes.

GitOps

We mentioned earlier that we setup three environments by default. What this means is for the staging and production
environments we created:

Kubernetes namespace

An environment resource ( CustomResourceDefinition)
in the dev environment which includes details of how applications are promoted to it and includes various team
settings.

A git repository that we store what applications and their versions should be present in that environment.
These are stored in a Helm requirements.yaml file

A Jenkins Pipeline job: explained in more detail below

CI/CD for Environments

Having a Jenkins Pipeline Job for each environment means that Pull Requests to the git repo trigger a CI
job.  For now that job performs basic validation but in the future will include ‘gates’ to ensure a change to that
environment has passed expected checks such as QA tasks, gain enough approvals from the correct people, etc -
YES CI for environments!

Once CI checks have passed the new application or version change can be merged. Only users that have karma
can merge the Pull Request and therefore we get RBAC plus traceability for our environment deployments.

This means every application manifest, their version and configuration including storage requirements, resource
needs and secrets for your environments are stored in Git repositories. Given a disaster recovery scenario this
is exactly what you want.

Did I just say secrets in Git? Yes! We will be providing a nicer experience to helps folks get set up but we
ourselves encrypt our secrets and  store them in Git, then decrypt them when we come to install and upgrade.

Here’s our Git repo https://github.com/jenkins-x/cloud-environments/blob/a1edcc6/env-jx-infra/secrets.yaml.

We do all this with the help of a Helm wrapper called helm secrets.
I’m working on a followup blog post with examples, better explanations and how to guides + add better integration
with JX in the coming weeks.

Fancy getting involved?

We mainly hangout in the jenkins-x Kubernetes slack channels and for tips on
being more involved with Jenkins X take a look at our contributing docs

If you’ve not already seen it here’s a video showing the create cluster explained in this blog.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jrawlings/">James Rawlings</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/18/blueocean-1-5-0/"><div class="header"><div class="date"><div class="month">April</div><div class="day">18</div></div><h5 class="title">Faster sailing on Blue Ocean 1.5.0</h5></div><p class="teaser">Hello, I am Jenn, the new Product Manager for Blue Ocean and Jenkins
Pipeline at CloudBees. I am based out of the Seattle area and am excited to be
working on Jenkins. :D We released version 1.5.0 of the Blue Ocean plugin late last week. If you’re
using Blue Ocean, you’ll want to grab this update since it includes many
improvements and bug fixes!

New Features

Blue Ocean now includes a user interface update to show the downstream jobs
launched with the &#x27;build&#x27; step
(link: JENKINS-38339)

With Blue Ocean 1.5.0, users can now Reorder Steps in the Blue Ocean Pipeline
Editor simply by dragging and dropping steps to reorder them in the list of
steps.
( JENKINS-38323)

The &quot;Artifacts&quot; tab also now supports pagination, which allows developers to
paginate through the Artifacts tab. Previously, this list
was cut off at 100 entries.
( JENKINS-43588)

Improvements

We were able to include two performance improvements in 1.5.0 which reduce the
Dashboard loading time in Blue Ocean:

JENKINS-44995

JENKINS-48868

Support for viewing output for failed runs with no stages is also included in
this release. For developers who have no stages/steps defined in their
pipelines, they can now see the full log output for failed runs. This update
helps with Pipeline debugging in Jenkins.
( JENKINS-48074)

Further improving the log output for Pipeline Runs, 1.5.0 also improves viewing
of long log output lines with wrapping.  Previously, a single, long line of
output in the log wouldn’t be fully visible in the log window.
( JENKINS-49036)

Fixes

One notable bug fix we addressed in this release was that input steps in
post directives would not properly prompt for input. By fixing
JENKINS-49297
users of Declarative Pipeline with Blue Ocean can include input steps in
their post directives.

The full detailed change log can be viewed on the
Blue Ocean plugin page

Update Your Plugin

Plugin updates in Jenkins are available in the Plugin Manager Update Center. This page includes instructions for using the UI and CLI to update your plugins: https://jenkins.io/doc/book/managing/plugins/.

If you are using the Blue Ocean UI, click Administration in the page’s header to open Plugin Manager.

Installing the primary Blue Ocean plugin will update its dependencies as well.

Providing Feedback

Chat with us at Gitter: https://gitter.im/jenkinsci/blueocean-plugin

Report issues at https://issues.jenkins.io/<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jennbriden/">Jenn Briden</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/25/configuring-jenkins-pipeline-with-yaml-file/"><div class="header"><div class="date"><div class="month">April</div><div class="day">25</div></div><h5 class="title">Configuring a Jenkins Pipeline using a YAML file</h5></div><p class="teaser">A few years ago our CTO wrote about building a
Continuous Integration server for Ruby On Rails using Jenkins and docker.
The solution has been our CI pipeline for the past years until we recently decided to
make an upgrade. Why?

Jenkins version was way out of date and it was getting difficult to
upgrade

Wolox has grown significantly over the past years
and we’ve been experiencing scaling issues

Very few people knew how to fix any issues with the server

Configuring jobs was not an easy task and that made our project
kickoff process slower

Making changes to the commands that each job runs was not easy and not
many people had permissions to do so. Wolox has a wide range of
projects, with a wide variety of languages which made this problem even
bigger.

Taking into account these problems, we started digging into the newest
version of Jenkins to see how we could improve our CI. We needed to
build a new CI that could, at least, address the following:

Projects must be built using Docker. Our projects depend on one or
multiple docker images to run (app, database, redis, etc)

Easy to configure and replicate if necessary

Easy to add a new project

Easy to change the building steps. Everyone working on the project
should be able to change if they want to run npm install or yarn
install.

Installing Jenkins and Docker

Installing Jenkins is straightforward. You can visit
Jenkins Installation page and choose the
option that best suits your needs.

Here are the steps we followed to install Jenkins in AWS:

sudo rpm — import https://pkg.jenkins.io/debian/jenkins.io.key
sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo
sudo yum install java-1.8.0 -y
sudo yum remove java-1.7.0-openjdk -y
sudo yum install jenkins -y
sudo yum update -y
sudo yum install -y docker

Automatically adding projects from Github

Adding projects automatically from Github can be achieved using the
GitHub Branch Source Plugin.
It allows Jenkins to scan a GitHub organization
for projects that match certain rules and add them to Jenkins
automatically. The only constraint that all branches must meet in order
to be added is that they contain a Jenkinsfile that explains how to
build the project.

Easy to change configuration

Not so easy to change configuration

One of the biggest pains we had with our previous Jenkins was the
difficulty of changing the steps necessary to build the project. If you
looked at a project’s build steps, you would find something like this:

#!/bin/bash +x
set -e

# Remove unnecessary files
echo -e &quot;\033[34mRemoving unnecessary files...\033[0m&quot;
rm -f log/*.log &amp;&gt; /dev/null || true &amp;&gt; /dev/null
rm -rf public/uploads/* &amp;&gt; /dev/null || true &amp;&gt; /dev/null

# Build Project
echo -e &quot;\033[34mBuilding Project...\033[0m&quot;
docker-compose --project-name=${JOB_NAME} build

# Prepare test database
COMMAND=&quot;bundle exec rake db:drop db:create db:migrate&quot;
echo -e &quot;\033[34mRunning: $COMMAND\033[0m&quot;
docker-compose --project-name=${JOB_NAME} run  \
	-e RAILS_ENV=test web $COMMAND

# Run tests
COMMAND=&quot;bundle exec rspec spec&quot;
echo -e &quot;\033[34mRunning: $COMMAND\033[0m&quot;
unbuffer docker-compose --project-name=${JOB_NAME} run web $COMMAND

# Run rubocop lint
COMMAND=&quot;bundle exec rubocop app spec -R --format simple&quot;
echo -e &quot;\033[34mRunning: $COMMAND\033[0m&quot;
unbuffer docker-compose --project-name=${JOB_NAME} run -e RUBYOPT=&quot;-Ku&quot; web $COMMAND

And some post build steps that cleaned up the docker:

#!/bin/bash +x
docker-compose --project-name=${JOB_NAME} stop &amp;&gt; /dev/null || true &amp;&gt; /dev/null
docker-compose --project-name=${JOB_NAME} rm --force &amp;&gt; /dev/null || true &amp;&gt; /dev/null
docker stop `docker ps -a -q -f status=exited` &amp;&gt; /dev/null || true &amp;&gt; /dev/null
docker rm -v `docker ps -a -q -f status=exited` &amp;&gt; /dev/null || true &amp;&gt; /dev/null
docker rmi `docker images --filter &#x27;dangling=true&#x27; -q --no-trunc` &amp;&gt; /dev/null || true &amp;&gt; /dev/null

Although these commands are not complex, changing any of them required
someone with permissions to modify the job and an understanding ofwhat
needed to be done.

Jenkinsfile to the rescue…​ or not

With the current Jenkins version, we can take advantage of
Jenkins Pipeline and model our build
flow in a file. This file is checked into the repository and, therefore,
anyone with access to it can change the build steps. Yay!

Jenkins Pipeline even has support for:

Docker and
multiple
images can be used for a build!

Setting environment variables with withEnv and many other built -in
functions that can be found
here.

This makes a perfect case for Wolox. We can have
our build configuration in a file that’s checked into the repository and
can be changed by anyone with write access to it. However, a Jenkinsfile
for a simple rails project would look something like this:

# sample Jenkinsfile. Might not compile
node {
    checkout scm
    withEnv([&#x27;MYTOOL_HOME=/usr/local/mytool&#x27;]) {
        docker.image(&quot;postgres:9.2&quot;).withRun() { db -&gt;
            withEnv([&#x27;DB_USERNAME=postgres&#x27;, &#x27;DB_PASSWORD=&#x27;, &quot;DB_HOST=db&quot;, &quot;DB_PORT=5432&quot;]) {
                docker.image(&quot;redis:X&quot;).withRun() { redis -&gt;
                    withEnv([&quot;REDIS_URL=redis://redis&quot;]) {
                        docker.build(imageName, &quot;--file .woloxci/Dockerfile .&quot;).inside(&quot;--link ${db.id}:postgres --link ${redis.id}:redis&quot;) {
                            sh &quot;rake db:create&quot;
                            sh &quot;rake db:migrate&quot;
                            sh &quot;bundle exec rspec spec&quot;
                        }
                    }
                }
            }
        }
    }
}

This file is not only difficult to read, but also difficult to change.
It’s quite easy to break things if you’re not familiar with Groovy and
even easier if you know nothing about how Jenkins’ pipeline works.
Changing or adding a new Docker image isn’t straightforward and might
lead to confusion.

Configuring Jenkins Pipeline via YAML

Personally, I’ve always envied simple configuration files for CIs and
this time it was our chance to build CI that could be configured using a
YAML file. After some analysis we concluded that a YAML like this one
would suffice:

config:
  dockerfile: .woloxci/Dockerfile
  project_name: some-project-name

services:
  - postgresql
  - redis

steps:
  analysis:
    - bundle exec rubocop -R app spec --format simple
    - bundle exec rubycritic --path ./analysis --minimum-score 80 --no-browser
  setup_db:
    - bundle exec rails db:create
    - bundle exec rails db:schema:load
  test:
    - bundle exec rspec
  security:
    - bundle exec brakeman --exit-on-error
  audit:
    - bundle audit check --update


environment:
  RAILS_ENV: test
  GIT_COMMITTER_NAME: a
  GIT_COMMITTER_EMAIL: b
  LANG: C.UTF-8

It outlines some basic configuration for the project, environment
variables that need to be present during the run, dependentservices, and
our build steps.

Jenkinsfile + Shared Libraries = WoloxCI

After investigating for a while about Jenkins and the pipeline, we found
that we could extend it with
shared libraries.
Shared libraries are written in groovy and can be imported
into the pipeline and executed when necessary.

If you look carefully at this Jenkinsfile,
we see that the code is a chain of methods calls that receive a
closure, where we execute another method passing a new closure to it.

# sample Jenkinsfile. Might not compile
node {
    checkout scm
    withEnv([&#x27;MYTOOL_HOME=/usr/local/mytool&#x27;]) {
        docker.image(&quot;postgres:9.2&quot;).withRun() { db -&gt;
            withEnv([&#x27;DB_USERNAME=postgres&#x27;, &#x27;DB_PASSWORD=&#x27;, &quot;DB_HOST=db&quot;, &quot;DB_PORT=5432&quot;]) {
                docker.image(&quot;redis:X&quot;).withRun() { redis -&gt;
                    withEnv([&quot;REDIS_URL=redis://redis&quot;]) {
                        docker.build(imageName, &quot;--file .woloxci/Dockerfile .&quot;).inside(&quot;--link ${db.id}:postgres --link ${redis.id}:redis&quot;) {
                            sh &quot;rake db:create&quot;
                            sh &quot;rake db:migrate&quot;
                            sh &quot;bundle exec rspec spec&quot;
                        }
                    }
                }
            }
        }
    }
}

Groovy is flexible enough to allow this same declarative code to be
created at runtime, making our dream of using a YAML to configure our
job come true!

Introducing Wolox-CI

That’s how wolox-ci was born- our
shared library for Jenkins!

With wolox-ci, our Jenkinsfile is now
reduced to:

@Library(&#x27;wolox-ci&#x27;) _

node {

  checkout scm

  woloxCi(&#x27;.woloxci/config.yml&#x27;);
}

Now it simply checks out the code and then calls wolox-ci. The library
reads yaml file like this one

config:
  dockerfile: .woloxci/Dockerfile
  project_name: some-project-name

services:
  - postgresql
  - redis

steps:
  analysis:
    - bundle exec rubocop -R app spec --format simple
    - bundle exec rubycritic --path ./analysis --minimum-score 80 --no-browser
  setup_db:
    - bundle exec rails db:create
    - bundle exec rails db:schema:load
  test:
    - bundle exec rspec
  security:
    - bundle exec brakeman --exit-on-error
  audit:
    - bundle audit check --update


environment:
  RAILS_ENV: test
  GIT_COMMITTER_NAME: a
  GIT_COMMITTER_EMAIL: b
  LANG: C.UTF-8

and builds the Jenkinsfile to get your job running on the fly.

The nice part about having a shared library is that we can extend and
fix our library in a centralized way. Once we add new code, the library
is automatically updated in Jenkins which will notify all of our jobs
with the update.

Since we have projects in different languages we use Docker to build the
testing environment. WoloxCI assumes there is a Dockerfile to build and
will run all the specified commands inside the container.

Woloxci config.yml

Config

The first part of the config.yml file specifies some basic
configuration: project’s name and Dockerfile location. The Dockerfile is
used to build the image where the commands will be run.

Services

This section describes which services will be exposed to the container.
Out of the box, WoloxCI has support for postgresql, mssql and
redis. You can also specify the docker image version you want! It is
not hard to add a new service. You just need to add the corresponding
file at

https://github.com/Wolox/wolox-ci/tree/development/vars

and modify how the services are parsed

https://github.com/Wolox/wolox-ci/blob/development/src/com/wolox/parser/ConfigParser.groovy#L76

Steps

The listed commands in this section will run inside the Docker
container. As a result, you’ll see each of the steps on the Jenkins UI.

Environment

If you need some environment variables during your build, you can
specify them here. Whatever variable you set will be available inside
the Docker container when your commands listed in the steps section
described above.

Wrapping up

WoloxCI is still being tested with a not-so-small sample of our
projects. The possibility of changing the build steps through a YAML
file makes it accessible for everyone and that is a great improvement in
our CI workflow.

Docker gives us the possibility of easily changing the programming
language without making any changes to our Jenkins installation and
Jenkins’ Github Organization feature automatically adds new projects
when a new repository with a Jenkinsfile is detected.

All of these improvements have reduced the time we spend maintaining
Jenkins significantly and give us the possibility of easily scaling
without any extra configuration.

This library is working in our CI but it still can be improved.
If you would like to add features, feel free to
contribute!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/mdesanti/">Matias De Santi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipelines">pipelines</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/yaml">yaml</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/sharedlibrary">sharedlibrary</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/27/essentials-versions-are-numbered/"><div class="header"><div class="date"><div class="month">April</div><div class="day">27</div></div><h5 class="title">Jenkins Essentials: The days of versions are numbered</h5></div><p class="teaser">Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.

A couple weeks ago, I
wrote about the Jenkins Essentials
effort, on which we’ve been making steady progress. Personally, the most
exciting challenge of this project is defining the machinery to drive
automatic updates
of Jenkins Essentials, which viewed from a high level, are classic continuous
delivery challenges.

In this post, I wanted to dive into a bit of the gritty details of how we’re
going to be delivering Jenkins Essentials with automatic updates, which has
some really interesting requirements for the development of Jenkins itself.

The traditional Jenkins core and plugin development workflow involves a
developer working on changes for some amount of time, then when they’re ready,
they &quot;create a release&quot; which typically involves publishing artifacts to our
Artifactory, and then on a timer (typically every 15 minutes) the Update Center will
re-generate a file called update-center.json. Once the new Update Center has
been generated, it is published and consumed by Jenkins installations within
24 hours. Of course, only after Jenkins administrators recognize that there is
an update available, can they install it. All in all, it can take quite a long
time from when a developer publishes a release, to when it is successfully used
by an end-user.

With our desire to make Jenkins Essentials updates seamless and automatic, the
status quo clearly was not going to work. Our shift in thinking has required a
couple simultaneous efforts to make this more continuously delivered approach
viable.

Developer Improvements

Starting from the developer’s workflow,
Jesse Glick
has been working on publishing &quot;incremental builds&quot; of artifacts into a
special Maven repository
in Artifactory. Much of his work is described in the very thorough
Jenkins Enhancement Proposal 305.
This support, which is now live on
ci.jenkins.io
allows plugin developers to publish versioned changes from pull requests and
branches to the incrementals repository. Not only does this make it much
easier for Jenkins Essentials to deliver changes closer to the HEAD of
master branches, it also unlocks lots of flexibility for Jenkins developers
who coordinate changes across matrices of plugins and core, as occasionally is
necessary for Jenkins Pipeline, Credentials, Blue Ocean, and a number of other
foundational components of a modern Jenkins install.

In a follow-up blog post, Jesse is going to go into much more detail on some of
the access control and tooling changes he had to solve to make this
incrementals machinery work.

Of course, incremental builds are only a piece of the puzzle, with those
artifacts, Jenkins Essentials has to be able to do something useful with them!

Update Improvements

The number one requirement, from my perspective, for the automatically updated
distribution is that it is safe. &quot;Safe&quot; means that a user doesn’t need to
be involved in the update process, and if something goes wrong, the
instance recovers without the user needing to do anything to remediate a
&quot;bad code deploy.&quot;

In my previous post on the subject, I mentioned Baptiste’s work on
Jenkins Enhancement
Proposal 302 which describes the &quot;data safety&quot; system for safely applying
updates, and in case of failure, rolling back.

The next obvious question is &quot;what’s failure?&quot; which Baptiste spent some time
exploring and implementing in two more designs:

JEP-304: Essentials Client Error Telemetry Logging

JEP-306: Essentials Instance Client Health Checking

On the server side, of which there is substantial work for Jenkins Essentials,
these concepts integrate with the concept of an
Update Lifecycle
between the server and client. In essence, the server side must be able to
deliver the right updates to the right clients, and avoid delivering tainted
updates (those with known problems) to clients. While this part of the work is
still on-going, tremendous progress has been made over the past couple weeks
in ensuring that updates can be safely, securely, and automatically delivered.

With the ability to identify &quot;bad code deploys&quot;, and having a mechanism for
safely rolling back, not only does Jenkins Essentials allow seamless
updates, but it enables Jenkins developers to deliver features and bugfixes
much more quickly than our current distribution model allows.

While Jenkins Essentials does not have a package ready for broad consumption
yet, we’re rapidly closing in on the completion of our first milestone which
ties all of these automatic update components together and builds the
foundation for continuous delivery of all subsequent improvements.

You can follow our progress in the
jenkins-infra/evergreen
repository, or join us in our
Gitter chat!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/04/30/using-the-beta-annotation/"><div class="header"><div class="date"><div class="month">April</div><div class="day">30</div></div><h5 class="title">Using new core APIs with the Beta annotation</h5></div><p class="teaser">This sort of slid under the radar in the middle of some bigger changes
for the JEP-202
reference implementation, so I wanted to call it out now. Arguably this could
deserve a retroactive JEP, though I would rather fold it into a JEP for
JENKINS-49651 (see below).

As of Jenkins 2.118, or plugin parent POM 3.7, you can mark any Java member
( class, method, constructor, field, or I suppose also interface,
enum, or annotation) with API visibility ( protected or public) with an
annotation :

@Restricted(Beta.class)

The idea is to announce to potential users of the member that the API
may still be in flux and only code prepared to keep up should be using
it. For an example, 2.118 added a VirtualFile.toExternalURL() method
that is being implemented in artifact-manager-s3 and (pending some
PR merges) called in copyartifact and workflow-basic-steps. We do
not necessarily want this to be called yet by unknown parties out
there in the Jenkins ecosystem. To enforce that, any attempt to call
or implement toExternalURL will produce a build failure, unless you
add this property to your plugin POM, as these plugins have done:

true

Why? Because there is a chance the design is wrong and it might need
to be changed—perhaps some upcoming bug fix would demand a boolean
parameter be added, for example.

Under the conventional notion of Jenkins API deprecation and compatibility
policy, once an API like this makes it into a release version, that is it—we
might mark it @Deprecated but we need to maintain compatibility indefinitely,
and find some way to migrate existing implementations / call sites.

With the @Beta annotation, that promise is not being made. If it needs
a boolean parameter for some reason, that will be added and those
three plugins updated to match; we are not going to bother retaining
the original overload and somehow delegating to the new one. This
simplification of the developer workflow is important to the use cases
of Essentials (JEP-3xx), and I would expect the useBeta mark to
become widespread among plugins included in Essentials. Such as the situation
where one team needs to feel
comfortable refactoring code under its aegis freely, and the refactored result
should be deliverable as a unit to production via the Evergreen distribution
system.

So that leaves two important questions:

First, is the annotation
permanent, and if not, when should it be removed? I do not think there
is any hard policy, but the intention is that it should be removed
once the API is in more or less widespread use and has held up. For
this example, if people start using S3 artifacts, and especially if
someone successfully writes an implementation of artifact storage in
Azure that uses the API, the concept will have been reasonably proven.
At that point we want the API to be used wherever it would make sense,
and if there is some very belated realization that the design is not
quite right, we accept the burden of deprecating the original and
migrating callers compatibly.

Second, it is fine and well to say that someone changing the signature
of a beta toExternalURL is on the hook to update the three plugins
using it, but what if a Jenkins admin ( not running Essentials, for
shame) upgrades to (say) Jenkins 2.125 with the new signature but
declines to accept the updates to those plugins (say,
workflow-basic-steps 2.9) which adapt to the change? It is not
enough to say that it is their fault for holding back on the updates
arbitrarily; the plugin manager offers you updates but does nothing
to tell you when they are required, so suddenly throwing
NoSuchMethodError is not a helpful response.

The solution needs to be ironed out, but my expectation is to use
JENKINS-49651
for this. For example, workflow-basic-steps 2.8,
using toExternalURL(), would have declared itself compatible with
Jenkins-Version: 2.118, and thus implicitly anything newer. The
developer doing the refactoring would also amend some 2.125 (and
newer) core metadata to say that it conflicts with anything older than
the 2.9 release of the plugin. The plugin manager would therefore
block the 2.8 plugin from even being loaded on the 2.125 core; the
admin would need to update before using it. In the case of an
incompatible change made to a plugin API, rather than a core API, the
UX is a little smoother since the plugin manager could just refuse to
let you update one without the other.

If you’re a plugin or core developer who is interested in using the @Beta
annotations, or have questions about our motiviations, please join the
discussion on
this mailing list thread.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/05/01/gsoc2018-projects-announcement/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 1</div></div><h5 class="title">Welcome Google Summer of Code 2018 students!</h5></div><p class="teaser">On behalf of the Jenkins GSoC team and mentors,
I would like to welcome
Shenyu Zheng,
Udara De Silva,
Pham Vu Tuan and
Abhishek Gautam.
They will be working on Google Summer of Code projects in the Jenkins organization,
and they have already done some contributions.

This year we have the following projects:

Code Coverage API Plugin -
create a new API Plugin to unify existing Code Coverage plugins and provide new features.

Student: Shenyu Zheng from Henan University, Kaifeng, China

Mentors: Steven Christou and Supun Wanniarachchi

Electronic Design Automation Plugins -
create plugins for open-source Electronic Design Automation tools for synthesis, simulation and coverage analysis (iVerilog, covered, Yosys).

Student: Udara De Silva from University of Akron, Ohio, USA

Mentors: Martin d’Anjou and Oleg Nenashev

Jenkins Remoting over Message Bus/Queue -
add support of a popular message queue/bus technology (RabbitMQ or Kafka) as a fault-tolerant communication layer in Jenkins.

Student: Pham Vu Tuan from Nanyang Technological University, Singapore

Mentors: Oleg Nenashev and Supun Wanniarachchi

Simple Pull-Request Job Plugin -
add ability to define Jenkins jobs as YAML files stored in SCM, integrate it with existing plugin ecosystem.

Student: Abhishek Gautam from Visvesvaraya National Institute of Technology, Nagpur, India

Mentors: Jeff Knurek, Kristin Whetstone and
Willy Aguirre

During next 4 weeks project teams will be reaching out to potential stakeholders in order to establish connections and
to get comments regarding their project designs.
If you are interested in the projects, please join discussions in the
Developer mailing lists and project meetings once they get scheduled.
Please also expect expect more detailed blogposts about the projects soon.

If you are interested to know more about GSoC in Jenkins, you can find information, timeline and communication channels
here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/05/08/jenkins-x-anchore/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 8</div></div><h5 class="title">Jenkins X: Announcing CVE docker image analysis with Anchore</h5></div><p class="teaser">Anchore provides docker image analysis for user defined acceptance policies to allow automated image validation and acceptance.

As developers we would like to know if a change we are proposing introduces a
Common Vulnerability and Exposure (CVE).
As operators we would like to know what running applications are affected if a new CVE is discovered.

Now in Jenkins X pipelines, if we find an
Anchore engine service running we will add the preview and release images to be analyzed.
This means we can look at any environment including previews (created from Pull Requests)
to see if your application contains a CVE.

Upgrade

Start by checking your current Jenkins X version:

jx version

If your Jenkins X platform is older than 0.0.903, then first you will need to upgrade to at least 0.0.922:

jx upgrade cli
jx upgrade platform

Install addon

You can install the
Anchore engine addon
when you are in your Jenkins X team home environment.

jx env dev
jx create addon anchore

This will install the engine in a seperate anchore namespace
and create a service link in the current team home environment
so our pipeline builds can add docker images to Anchore for analysis.

Create an application

You can now create a new quickstart:

jx create quickstart

List any CVEs

Once the build has run you will be able to check for CVEs in any environment incluing previews created for pull requests.

jx get cve --environment staging

Demo

Here’s a 4 minute video that demonstrates the steps above:

Upgrading existing pipelines

If you have an existing application pipeline and and want enable image analysis you can update your Jenkinsfile,
in the preview stage after the skaffold step add the line

sh &quot;jx step validate --min-jx-version 1.2.36&quot;
sh &quot;jx step post build --image \$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:$PREVIEW_VERSION&quot;

In the master stage the add this line after the skaffold step

sh &quot;jx step validate --min-jx-version 1.2.36&quot;
sh &quot;jx step post build --image \$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:\$(cat VERSION)&quot;

For any questions please find us - we mainly hang out on Slack at
#jenkins-x-dev - or see
jenkins-x.io/community for other channels.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jrawlings/">James Rawlings</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/05/09/security-advisory/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 9</div></div><h5 class="title">Security updates for Jenkins core and plugins</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.121 and 2.107.3, that fix multiple security vulnerabilities.

Additionally, we announce previously published security issues and corresponding fixes in these plugins:

Black Duck Hub

Groovy Postbuild

Gitlab Hook (fix unreleased)

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/05/15/incremental-deployment/"><div class="header"><div class="date"><div class="month">May</div><div class="day">15</div></div><h5 class="title">Automatic deployment of “incremental” commits to Jenkins core and plugins</h5></div><p class="teaser">A couple of weeks ago, Tyler mentioned some
developer improvements in Essentials
that had been recently introduced:
the ability for
ci.jenkins.io
builds to get deployed automatically to an “Incrementals” Maven repository,
as described in
JEP-305.
For a plugin maintainer, you just need to
turn on this support
and you are ready to both deploy individual Git commits from your repository
without the need to run heavyweight traditional Maven releases,
and to depend directly on similar commits of Jenkins core or other plugins.
This is a stepping stone toward continuous delivery, and ultimately deployment, of Jenkins itself.

Here I would like to peek behind the curtain a bit at how we did this,
since the solution turns out to be very interesting for people thinking about security in Jenkins.
I will gloss over the Maven arcana required to get the project version to look like 1.40-rc301.87ce0dd8909b
(a real example from the
Copy Artifact plugin)
rather than the usual 1.40-SNAPSHOT, and why this format is even useful.
Suffice it to say that if you had enough permissions, you could run

mvn -Dset.changelist -DskipTests clean deploy

from your laptop to publish your latest commit.
Indeed as
mentioned in the JEP,
the most straightforward server setup would be to run more or less that command
from the buildPlugin function called from a typical Jenkinsfile,
with some predefined credentials adequate to upload to the Maven repository.

Unfortunately, that simple solution did not look very secure.
If you offer deployment credentials to a Jenkins job,
you need to trust anyone who might configure that job (here, its Jenkinsfile)
to use those credentials appropriately.
(The withCredentials step will mask the password from the log file, to prevent accidental disclosures.
It in no way blocks deliberate misuse or theft.)
If your Jenkins service runs inside a protected network and works with private repositories,
that is probably good enough.

For this project, we wanted to permit incremental deployments from any pull request.
Jenkins will refuse to run Jenkinsfile modifications from people
who would not normally be able to merge the pull request or push directly,
and those people would be more or less trustworthy Jenkins developers,
but that is of no help if a pull request changes pom.xml
or other source files used by the build itself.
If the server administrator exposes a secret to a job,
and it is bound to an environment variable while running some open-ended command like a Maven build,
there is no practical way to control what might happen.

The lesson here is that the unit of access control in Jenkins is the job.
You can control who can configure a job, or who can edit files it uses,
but you have no control over what the job does or how it might use any credentials.
For JEP-305, therefore, we wanted a way to perform deployments from builds considered as black boxes.
This means a division of responsibility:
the build produces some artifacts, however it sees fit;
and another process picks up those artifacts and deploys them.

This worked was tracked in
INFRA-1571.
The idea was to create a “serverless function” in Azure
that would retrieve artifacts from Jenkins at the end of a build,
perform a set of validations to ensure that the artifacts follow an expected repository path pattern,
and finally deploy them to Artifactory using a trusted token.
I prototyped this in Java, Tyler
rewrote it in JavaScript,
and together we brought it into production.

The crucial bit here is what information (or misinformation!) the Jenkins build can send to the function.
All we actually need to know is the build URL, so the
call site from Jenkins
is quite simple.
When the function is called with this URL,
it starts off by performing input validation:
it knows what the Jenkins base URL is,
and what a build URL from inside an organization folder is supposed to look like:
https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/ , for example.

The next step is to call back to Jenkins and ask it for some metadata about that build.
While we do not trust the build, we trust the server that ran it to be properly configured.
An obstacle here was that the ci.jenkins.io server had been configured to disable the Jenkins REST API;
with Tyler’s guidance I was able to amend this policy to permit API requests from registered users
(or, in the case of the Incrementals publisher, a bot).

If you want to try this at home, get an
API token,
pick a build of an “incrementalified” plugin or Jenkins core,
and run something like

curl -igu : &#x27;https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/api/json?pretty&amp;tree=actions[revision[hash,pullHash]]&#x27;

You will see a hash or pullHash corresponding to the main commit of that build.
(This information was added to the Jenkins REST API to support this use case in
JENKINS-50777.)
The main commit is selected when the build starts
and always corresponds to the version of Jenkinsfile in the repository for which the job is named.
While a build might checkout any number of repositories,
checkout scm always picks “this” repository in “this” version.
Therefore the deployment function knows for sure which commit the sources came from,
and will refuse to deploy artifacts named for some other commit.

Next it looks up information about the Git repository at the folder level (again from JENKINS-50777):

curl -igu : &#x27;https://ci.jenkins.io/job/Plugins/job/git-plugin/api/json?pretty&amp;tree=sources[source[repoOwner,repository]]&#x27;

The Git repository now needs to be correlated to a list of Maven artifact paths that this component is expected to produce.
The
repository-permissions-updater
(RPU) tool already had a list of artifact paths used to perform permission checks on regular release deployments to Artifactory; in
INFRA-1598
I extended it to also record the GitHub repository name, as can be seen
here.
Now the function knows that the CI build in this example may legitimately create artifacts in the org/jenkins-ci/plugins/git/ namespace
including 38c569094828 in their versions.
The build is expected to have produced artifacts in the same structure as mvn install sends to the local repository,
so the function downloads everything associated with that commit hash:

curl -sg &#x27;https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/artifact/**/*-rc*.38c569094828/*-rc*.38c569094828*/*zip*/archive.zip&#x27; | jar t

When all the artifacts are indeed inside the expected path(s),
and at least one POM file is included (here org/jenkins-ci/plugins/git/3.9.0-rc1671.38c569094828/git-3.9.0-rc1671.38c569094828.pom),
then the ZIP file looks good—ready to send to Artifactory.

One last check is whether the commit has already been deployed (perhaps this is a rebuild).
If it has not, the function uses the Artifactory REST API to atomically upload the ZIP file
and uses the GitHub Status API to associate a message with the commit
so that you can see right in your pull request that it got deployed:

One more bit of caution was required.
Just because we successfully published some bits from some PR does not mean they should be used!
We also needed a tool which lets you select the newest published version of some artifact
within a particular branch, usually master.
This was tracked in
JENKINS-50953
and is available to start with as a Maven command operating on a pom.xml :

mvn incrementals:update

This will check Artifactory for updates to relevant components.
When each one is found, it will use the GitHub API to check whether the commit has been merged to the selected branch.
Only matches are offered for update.

Putting all this together, we have a system for continuously delivering components
from any of the hundreds of Jenkins Git repositories
triggered by the simple act of filing a pull request.
Securing that system was a lot of work
but highlights how boundaries of trust interact with CI/CD.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/05/16/pipelines-with-git-tags/"><div class="header"><div class="date"><div class="month">May</div><div class="day">16</div></div><h5 class="title">When using tags in Jenkins Pipeline</h5></div><p class="teaser">One common pattern for automated releases I have seen and used relies on Git
tags as the catalyst for a release process. The immutable nature of releases
and the immutable nature of tags can definitely go hand in hand, but up until
few months ago Jenkins Pipeline was not able to trigger effectively off of Git
tags.

In this post I want to briefly share how to use tags to drive behaviors in
Jenkins Pipeline. Consider the following contrived Jenkinsfile, which
contains the three basic stages of Build, Test, and Deploy:

pipeline {
    agent any
    stages {
        stage(&#x27;Build&#x27;) {
            steps {
                sh &#x27;make package&#x27;
            }
        }
        stage(&#x27;Test&#x27;) {
            steps {
                sh &#x27;make check&#x27;
            }
        }
        stage(&#x27;Deploy&#x27;) {
            when { tag &quot;release-*&quot; }
            steps {
                echo &#x27;Deploying only because this commit is tagged...&#x27;
                sh &#x27;make deploy&#x27;
            }
        }
    }
}

Of particular note is the
when
condition on the &quot;Deploy&quot; stage which is applying the tag criteria. This
means the stage would only execute when the Pipeline has been triggered from a
tag in Git matching the release-* Ant-style wildcard.

In practice, this means that all pull requests, and branch-based Pipeline Runs
result in the stage being skipped:

When I push a release-1.0 tag, the Pipeline will then be triggerd and run the
&quot;Deploy&quot; stage:

Out of the box, Pipelines won’t trigger off of the presence of tags, which
means that a Multibranch Pipeline must have a configuration update to know that
it must Discover Tags.

Configuring

From the configuration screen of a Multibranch Pipeline (or GitHub Organization
Folder), Discovering tags can be enabled by adding the appropriate &quot;Behavior&quot;
to the Branch Source configuration:

With these changes, the Jenkinsfile in the tagged versions of my source
repository can now drive distinct deployment behavior which is not otherwise
enabled in the Pipeline.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/git">git</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/05/17/tracymiranda-intro/"><div class="header"><div class="date"><div class="month">May</div><div class="day">17</div></div><h5 class="title">Introducing Tracy Miranda as the CloudBees Open Source Program Lead</h5></div><p class="teaser">I’m Tracy Miranda, and I’m really excited to have joined CloudBees this month leading the open source program. CloudBees’ contributions to Jenkins include developing Pipeline and Blue Ocean, staffing the infrastructure team, advocacy and events work, as well as security efforts. My focus is on making sure there is a great relationship between the Jenkins community and CloudBees, which means strong communication, help get traction on things the community wants, and generally working to make Jenkins and the community thrive and stay awesome in an ever-changing tech landscape.

Here’s a little background on me: I come from an electronics/EDA background but switched to software early in my career when I first got involved with open source software. I’ve been part of the Eclipse community for around 15 years, definitely from before git was even a thing. I love being involved with all levels: project committer, conference chair, steering committee for working groups and more recently board of directors.

On a personal note, I …

Live in the UK with my husband and 2 young kids

Grew up in Kenya

Enjoy playing badminton, love good food &amp; am always first at any buffets

I am looking forward to getting to know the Jenkins community well, and really getting a feel for your Jenkins stories, good and bad. Please feel free to let me know:

What you love about the Jenkins community &amp; how you are using Jenkins

What you’re working on doing with Jenkins

What you don’t like and want improved

You can find me on the mailing lists or via:

Twitter @tracymiranda

Email: tmiranda@cloudbees.com

IRC: tracymiranda

Also I’ll be at the upcoming events: DevOps World - Jenkins World in San Francisco, California and Nice, France so if you plan to attend do come and say hi. The Jenkins community is the real force behind Jenkins. And in turn Jenkins powers so much of the software out there. It is an honour to be joining this wonderful community.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/08/jenkins-java10-hackathon/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 8</div></div><h5 class="title">Jenkins &amp; Java 10+ Online Hackathon (Jun 18-22)</h5></div><p class="teaser">On behalf of the Jenkins Events Team,
I would like to invite you to the “Jenkins &amp; Java 10 Online Hackathon” which will take place from June 18th to 22nd.
We will be working together on Jenkins core and plugins in order
to find and fix compatibility issues, share experiences and have some fun.
Everybody is welcome to join, independently of their Jenkins experience and amount of time they have available.

If you are interested in participating in the hackathon, please sign-up in
this form.

Background

Java 9 has recently been end-of-lifed, Java 10 is in GA, and Java 11 is in early beta.
Jenkins project currently requires Java 8 to run reliably,
and there are some known compatibility issues with higher Java versions.

During the Jenkins World 2017 Hackathon,
Mark Waite and
Baptiste Mathus spent some time exploring Java 9 compatibility in Jenkins.
We are currently tracking compatibility issues in the
JENKINS-40689 EPIC,
but there are likely many unknown issues in Jenkins core, plugins and in libraries we use in the project.
We would like to continue their effort and work on Java 10+ support.

Objectives and Scope

As I have said above,
the goals are to explore/fix compatibility issues, share experiences and have fun.
We DO NOT plan to make Jenkins fully compatible with Java 10+
during the hackathon,
but we will try to integrate fixes and make them available.

Since the announcement of the Hackathon in the mailing list,
we have got a number of registrations from contributors working on several project areas.
We will split our work to several areas:

Jenkins core and Remoting

Pipeline Engine

Plugins (e.g. Git plugin or any plugin you want to work on)

Exploratory testing for Java 10 and beyond

In order to organize the effort, we have created a
java10_hackathon label
in Jenkins JIRA.
If you are interested in particular tasks,
please assign them to yourself and add the label.

Organization

Currently the event is in the planning stage.
We will be using the Developer mailing list
for synchronization before the event.

What will we have?

Communications in #jenkins-hackhouse IRC and in the
Jenkins Gitter channel

Daily recorded sync-up calls in Hangouts

Knowledge transfer sessions during the event

We also want to prepare some special swag for active participants.
If you have reached this part of the blogpost,
you have probably seen the logo ;)

Links

Registration

Developer mailing list

Hackathon sync-up document

Running Jenkins with Java 10 and 11

JIRA: Java 10 compatibility

JIRA: Java 11 compatibility

JIRA: Hackathon tasks<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java10">java10</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java11">java11</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/13/code-coverage-api-plugin/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">13</div></div><h5 class="title">GSoC Project Intro: Code Coverage API Plugin</h5></div><p class="teaser">About me

My name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.

I am very excited that I can participate in GSoC to work on Code Coverage API plugin with the Jenkins community and to contribute to the open source world. It is my greatest pleasure to write a plugin that many developers will use.

My mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.

Abstract

There are a lot of plugins which currently implement code coverage, however, they all use similar config, charts, and content. So it will be much better if we can have an API plugin which does the most repeated work for those plugins and offers a unified APIs which can be consumed by other plugins and external tools.

This API plugin will mainly do these things:

Find coverage reports according to the user’s config.

Use adapters to convert reports into the our standard format.

Parse standard format reports, and aggregate them.

Show parsed result in a chart.

So, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing — convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.

Current Progress - Alpha Version

I have developed an alpha version for this plugin. It currently integrates two different coverage tools - Cobertura and Jacoco. Also, it implements many basic functionalities like threshold, auto-detect, trend chart and so on.

Configuration Page

config plugin

We can input the path pattern for auto detect, so that plugin will automatically find reports and group them using a corresponding converter. That makes config simpler and the user doesn’t need to fully specify the report name. Also, if we want, we can manually specify each coverage report.

We also have global and per-report threshold configurations, which makes the plugin more flexible than existing plugins (e.g. global threshold for a multi-language project that has several reports).

Pipeline Support

In addition to configuring the Code Coverage API plugin from the UI page, we also have pipeline support.

node {
   publishCoverage(autoDetectPath: &#x27;**/*.xml&#x27;, adapters: [jacoco(path: &#x27;jacoco.xml&#x27;)], globalThresholds: [[thresholdTarget: &#x27;GROUPS&#x27;, unhealthyThreshold: 20.0, unstableThreshold: 0.0]])
}

Report Defects

As we can see in Configuration page, we can set healthy threshold and stable threshold for each metric. The Code Coverage API plugin will report healthy score according to the healthy threshold we set.

threshold config

result

Also, we have a group of options which can fail the build if coverage falls below a particular threshold.

Coverage Result Page

The coverage result page now has a modernized UI which shows coverage results more clearly.
The result page includes three parts - Trend chart, Summary chart, Child Summary chart.

Trend Chart

In the Trend chart, we can see the coverage trend of the selected coverage metrics.

Summary Chart

In the summary chart we can see the coverage summary of current coverage metric.

Child Summary Chart

In the Child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size.

By using those more modernized chart components, we can easily focus on the information we want to know.

Extensibility

We provide several extension points to make our plugin more extensible and flexible. Also, we have a series of abstract layers to help us implementing these extension points much easier.

CoverageReportAdapter

We can implement a coverage tool by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement Jacoco simple like this:

public final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {

    @DataBoundConstructor
    public JacocoReportAdapter(String path) {
        super(path);
    }

    @Override
    public String getXSL() {
        return &quot;jacoco-to-standard.xsl&quot;;
    }

    @Override
    public String getXSD() {
        return null;
    }

    @Symbol(&quot;jacoco&quot;)
    @Extension
    public static final class JacocoReportAdapterDescriptor extends CoverageReportAdapterDescriptor {

        public JacocoReportAdapterDescriptor() {
            super(JacocoReportAdapter.class, &quot;jacoco&quot;);
        }
    }
}

All we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our Java standard format. There are also other extension points which are under development.

Other Extension points

We also plan to provide extension points for coverage threshold and report detector. Once it completed, we can have more control over our coverage report process.

Next Phase Plan

The Alpha version now has many parts which still need to be implemented before the final release. So in next phase, I will mainly do those things.

APIs which can be used by others

Integrate Cobertura Plugin with Code Coverage API (JENKINS-51424).

Provide API for getting coverage information. E.g. summary information about coverage (percentages, trends) (JENKINS-51422), (JENKINS-51423).

Implementing abstract layer for other report formats like JSON. (JENKINS-51732).

Supporting converters for non-Java languages. (JENKINS-51924).

Supporting combining reports within a build(e.g. after parallel() execution in Pipeline) (JENKINS-51926).

Adding source code navigation in Coverage Result Page (JENKINS-51988).

Refactoring the configuration page to make it more user-friendly (JENKINS-51927).

How to Try It Out

Also, I have released the Alpha version in the Experimental Update Center. If you can give me some of your valuable advice about it, I will very appreciate.

Links

JIRA Component

Project Page

Project Repository

Phase 1 Presentation Video

Phase 1 Presentation Slides<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/shenyu_zheng/">Shenyu Zheng</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/15/simple-pull-request-plugin/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">15</div></div><h5 class="title">GSoC Project Intro: Pipeline as YAML</h5></div><p class="teaser">About me

I am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of
technology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my
college. I am passionate about automation.

Mentors

Oleg Nenashev (Org Admin)

Martin d’Anjou

Kristin Whetstone

Jeff Knurek

Project Summary

This is a GSoC 2018 project.

This project aims to develop a pull request Job Plugin. Users should be able to
configure job type using YAML file placed in root directory of the
Git repository being the subject of the pull request. The plugin should interact with various
platforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.

Plugin detects the presence of certain types of the report at conventional locations,
and publish them automatically. If the reports are not present at conventional location,
can specify the location using the YAML file.

Benefits to the community

Project administrators will be able to handle builds for pull requests more easily.

Build specifications for pull request can be written in a concise declarative format.

Build reports will be automatically published to Github, Bitbucket, etc.

Build status updates will be sent to git servers automatically.

Users will not have to deal with pipeline code.

If there will be no merge conflicts or build failures, the PR can be merged into target branch.

Prior work

Travis YML Plugin :
Designed to run .travis.yml as Jenkins pipeline job.
Travis-CI does not support external pull requests. Jenkins environment
is different than Travis and does not always make sense to use configurations
defined for other environment in Jenkins. Also maintenance of this is slowed
down and last commit for this plugin was on 14 Nov 2016.
Click here to check.

CodeShip Plugin :
This plugin is designed to convert codeship &quot;steps.yaml&quot; and
&quot;services.yaml&quot; to scripted pipeline code. This plugin has never been released.

Jenkins pipeline builder :
This is a external non-Java-based tool, which cannot be easily converted to a Jenkins plugin.

Design

This plugin will be developed on the top of the MultiBranch Pipeline plugin.

For now the plugin is bulding branches and Pull request both using Jenkinsfile.yaml,
but this plugin is inclined to use for pull requests. This will be fixed in next coding phase.

This plugin is following below steps for now:

clone target repo

checkout to target branch

fetch the source branch

merge source-branch

call user call user script to build the repo.

push changes of pull request to target branch

publish test reports

Plugin will start above steps if and only if the pull request is
mergeable, to avoid merge conflicts while merging the source branch to target
branch. Pull request’s payload contains information if the pull request changes
are mergeable or not hence, the pull request is mergebale or not can also be
decided by the payload of webhook also.

How to run the Plugin

See How to run the demo
and set credentials, owner and repository on your own and you will be good to go.

Example branch-source configuration.

Phase 1 features

Users are able to select the Jenkinsfile.yaml file as the source for the Pipeline configuration.

Git Push step

harvest results and reports (and post in the pull request)

junit()

findbugs()

archiveArtifacts()

Basic interface to parse and get build specifications from YAML file.

Things decided

To build the plugin on the top of multibranch pipeline plugin. As that plugin has implementation of

Nice interface to show different branch and pull requests build separately with use of suitable plugins like Github, Bitbucket.

Detect trusted revisions in a repository.

Publishing of build status to the repository.

Convert the YAML configuration to declarative pipeline.

User will provide path to the script relative to the root directory of the repository
without extension (.sh or .bat) in the YAML file. The plugin will generate pipeline script to detect the
platform and call .sh or .bat script.

Example:
  Path provided: ./scripts/hello
  a. On UNIX machine “./scripts/hello.sh” will be called
  b. On non-UNIX machine “./scripts/hello.bat” will be called.

Implementations till now

A first prototype of the plugin is ready. It supports all features of Multi-Branch Pipeline and offers the following features.

Build description is defined via YAML file stored within the SCM repo. This plugin
will depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be
using respective paltfroms for their repositories.

Basic conversion of YAML to Declarative Pipeline: A class YamlToPipeline
is written which will load the &quot;Jenkinsfile.yaml&quot; and make use of PipelineSnippetGenerator class
to generate Declarative pipeline code.

Reporting of results.

Plugin is using Yaml from target branch right now. (Maybe this needs some discussion, example:
what if pull request contains changes in Jenkinsfile.yaml)

Git Push step: To push the changes of pull request to the target branch. This is implemented
using git-plugin, PushCommand is used for this from git-plugin. credentialId,
branch name and repository url for intracting with Github, Bitbucket, etc
will be taken automatically from &quot;Branch-Source&quot; (Users have to fill thes
details of branch source in job configuration UI). (You can see
How to run the demo)

Jenkinsfile.yaml example

For the phase 1 prototype demonstration, the following yaml file was used.
Note that this format is subject to change in the next phases of the project,
as we formalise the yaml format definition.

agent:
    dockerImage: maven:3.5.3-jdk-8
    args: -v /tmp:/tmp

testResultPaths:
    - target/surefire-reports/*.xml

findBugs: target/*.xml

stages:
    - name: First
      scripts:
        -   ./scripts/hello
    - name: Build
      scripts:
        -   ./scripts/build
    - name: Tests
      scripts:
        -   ./scripts/test

archiveArtifacts:
    - Jenkinsfile.yaml
    - scripts/hello.sh

From the yaml file shown above, the plugin generates the following pipeline code:

pipeline {
  agent {
    docker {
      image &#x27;maven:3.5.3-jdk-8&#x27;
      args &#x27;-v /tmp:/tmp&#x27;
      alwaysPull false
      reuseNode false
    }
  }
  stages {
    stage(&#x27;First&#x27;) {
      steps {
        script {
          if (isUnix()) {
            sh &#x27;./scripts/hello.sh&#x27;
          } else {
            bat &#x27;./scripts/hello.bat&#x27;
          }
        }
      }
    }
    stage(&#x27;Build&#x27;) {
      steps {
        script {
          if (isUnix()) {
            sh &#x27;./scripts/build.sh&#x27;
          } else {
            bat &#x27;./scripts/build.bat&#x27;
          }
        }pipeline
      }
      post {
        success {
          archiveArtifacts artifacts: &#x27;**/target/*.jar&#x27;
          archiveArtifacts artifacts: &#x27;Jenkinsfile.yaml&#x27;
          archiveArtifacts artifacts: &#x27;scripts/hello.sh&#x27;
        }
      }
    }
    stage(&#x27;Tests&#x27;) {
      steps {
        script {
          if (isUnix()) {
            sh &#x27;./scripts/test.sh&#x27;
          } else {
            bat &#x27;./scripts/test.bat&#x27;
          }
        }
      }
      post {
        success {
          junit &#x27;target/surefire-reports/*.xml&#x27;
        }
        always {
          findbugs pattern: &#x27;target/*.xml&#x27;
        }
      }
    }
  }
}

Pipeline view in Jenkins instance

Coding Phase 2 plans

Decide a proper YAML format to use for Jenkinsfile.yaml

Create Step Configurator for SPRP plugin. Jenkins-51637.
This will enable users to use Pipeline steps in Jenkinsfile.yaml.

Automatic indentation generation in the generated Pipeline SnipperGenerator class.

Write tests for the plugin.

Jira Epic

How to reach me

Email: gautamabhishek46@gmail.com

Gitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin

References

Initial proposal of the project

Project repository

Project page

Gitter chat

Bug Tracker

Demo Repository

Phase 1 Presentation video (June 14, 2018)

Phase 1 Presentation Slides (June 14, 2018)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhishek_gautam/">Abhishek Gautam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/yaml">yaml</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/17/running-jenkins-with-java10-11/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">17</div></div><h5 class="title">Running Jenkins with Java 10 and 11 (experimental support)</h5></div><p class="teaser">Please refer to Running Jenkins on Java 11 documentation to have the up-to-date details on how to run Jenkins on Java 11.

Guidelines in this blogpost are rendered obsolete by the Java 11 Support Preview Availability
announcement on Dec 13, 2018 and by the Java 11 GA release on Sep 25, 2018.
See the Java support page
for up-to-date information about running Jenkins with Java 11.
The Jenkins project also no longer ships preview versions for Java 10.

As you probably know, we will have a
Jenkins and Java 10+ online hackathon this week.
In order to enable early adopters to try out Jenkins with new Java versions,
we have updated Jenkins core and Docker packages.
Starting from Jenkins 2.127,
weekly releases can be launched with Java 10 and Java 11 (preview).
Although there are some known compatibility issues,
the packages are ready for evaluation and exploratory testing.

This article explains how to run Jenkins with Java 10 and 11 using Docker images and WAR files.
It also lists known issues and provides contributor guidelines.

Running in Docker

In order to simplify testing, we have created a new
jenkins/jenkins-experimental
repository on DockerHub.
This repository includes various Jenkins Core images, including Java 10 and Java 11 images.
We have also set up development branches and continuous delivery flows for Jenkins core,
so now we can deliver patches for these images without waiting for weekly releases.

You can run the image simply as:

docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins-experimental:latest-jdk11

The following tags are available:

2.127-jdk10, 2.128-jdk10 - Weekly releases packaged with Java 10

2.127-jdk11, 2.128-jdk11 - Weekly releases packaged with Java 11

latest-jdk10 - Jenkins core build from the java10-support branch

latest-jdk11 - Automatic build from the core’s java11-support branch.

blueocean-jdk10, blueocean-jdk11 - Experimental build, which bundles all Jenkins Pipeline and
Blue Ocean patches required to run on Java 11.
If you want to try Pipeline, use this image

Java 10/11 images are fully compatible with the official
jenkins/jenkins
Docker image documentation,
e.g. you can use plugins.txt to install plugins, mount volumes and pass extra options via environment variables.

Running Jenkins without Docker

Java 10

Download Jenkins WAR for 2.127 or above
(or build the experimental branch)

Run WAR with the following command:

${JAVA10_HOME}/bin/java --add-modules java.xml.bind -jar jenkins.war \
    --enable-future-java --httpPort=8080 --prefix=/jenkins

Java 11

Download Jenkins WAR for 2.127 or above
(or build the experimental branch)

Download the following libraries to the same directory as jenkins.war

jaxb-api-2.3.0.jar (save as jaxb-api.jar)

jaxb-core-2.3.0.1.jar (save as jaxb-core.jar)

jaxb-impl-2.3.0.1.jar (save as jaxb-impl.jar)

javax.activation v.1.2.0 (save as javax.activation.jar)

Run the following command:

Run Jenkins with ${JAVA11_HOME}/bin/java \
    -p jaxb-api.jar:javax.activation.jar --add-modules java.xml.bind,java.activation \
    -cp jaxb-core.jar:jaxb-impl.jar \
    -jar jenkins.war --enable-future-java --httpPort=8080 --prefix=/jenkins

Current state

As of June 17, we have achieved the following state:

Jenkins 2.127+ starts up successfully with
OpenJDK 10.0.1 and
OpenJDK 11+17-Debian-2 (preview)

It is possible to configure and run simple Freestyle jobs

Jenkins agents are able to start on Java 10, to connect to the controller and to execute Freestyle jobs

Agents can be connected using Docker Plugin and Yet Another Docker Plugin

Job DSL plugin works well on demo projects

Maven Integration plugin can build
plugin-pom -based
Jenkins plugins when running on agents with JDK 8

It is possible to create Folders and manage items in them

It is possible to configure Jenkins using Configuration-as-Code plugin

Jenkins is able to execute Groovy scripts in Script Console and
Groovy Hooks

Known issues

So far we know about the following issues:

Pipeline crashes immediately on Java 10 and 11 ( JENKINS-46602)

Workaround: Pipeline: Support plugin should be updated to version 3.0-java11-alpha-1-rc684.d802f5d9aeed from the Incrementals repo
( download)

FIXED - Git Client plugin 2.7.2 cannot be installed when running with Java 11 build 18ea

There are many warnings about Illegal reflective access during execution
(linked in JENKINS-40689).

In current Java 10 and 11 releases it does not lead to failures,
but we want to cleanup these warnings anyway

FIXED - Configuration-as-Code plugin fails to export configurations on Java 10
( JENKINS-51991)

We anticipate to discover and report more issues during the hackathon this week.

Contributing

If you discover incompatibilities in plugins, please
report issues in our bugtracker.
We have java10 and java11 labels for such issues.

If you are interested to try out Jenkins with Java 10 and 11 before June 22nd,
you may be interested to sign-up to the Jenkins and Java 10+ online hackathon.
Everybody is welcome to join, independently of their Jenkins experience and amount of time they have available.
Exploratory testing is also within the hackathon’s scope.
During this event, please also use the java10_hackathon label.
It will help us to track contributions and send folks some small &quot;thank you&quot; gifts for participating (details will be figured out during the hackathon).

If you want to contribute patches to the core,
please submit pull requests to java10-support or
java11-support branches.
If the patches are compatible with Java 8, we will try to upstream them to weekly releases.
For plugin patches please create pull requests against main branches and then follow guidelines from plugin maintainers.
If you need additional reviews and you are a member of the jenkinsci organization,
feel free to mention the @jenkinsci/java10-support team in your PRs.

Links:

Docker: jenkins/jenkins-experimental images

JIRA: Java 10 compatibility

JIRA: Java 11 compatibility

Jenkins and Java 10+ online hackathon<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java10">java10</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java11">java11</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/18/remoting-over-message-bus/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">18</div></div><h5 class="title">GSoC Project Intro: Jenkins Remoting over Message Bus/Queue</h5></div><p class="teaser">About me

My name is Pham Vu Tuan, I am a final year undergraduate student from Singapore. This is the first time I participate in Google Summer of Code and contribute to an open-source organization. I am very excited to contribute this summer.

Mentors

I have GSoC mentors who help me in this project Oleg Nenashev and Supun Wanniarachchi. Besides that, I also receive great support from developers in remoting project Devin Nusbaum and Jeff Thompson.

Overview

Current versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.

This project aims to develop a plugin in order to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins.

Why Kafka?

When planning for this project, we want to use traditional message queue system such as ActiveMQ or RabbitMQ. However, after some discussion, we decided to have a try with Kafka with more suitable features with this project:

Kafka itself is not a queue like ActiveMQ or RabbitMQ, it is a distributed, replicated commit log. This helps to remove message delivery complexity we have in traditional queue system.

We need to support data streaming as a requirement, and Kafka is good at this aspect, which RabbitMQ is lack of.

Kafka is said to have a better scalability and good support from the development community.

Current State

The project is reaching the end of the first phase and here are things we have achieved so far:

Setup project as a set of Docker Compose components: Kafka cluster, Jenkins controller (with plugin) and a custom agent (JAR).

Create a PoC with new command transport implementation to support Kafka, which involves of command invocation, RMI, classloading and data streaming.

Make neccessary changes in Remoting and Jenkins core to make them extensible for the use of this project.

Decide to use Kafka as a suitable final implementation.

We planned to release an alpha version of this plugin by the end of this phase, but decided to move this release to the second phase because we need to wait for remoting and core patches to be released.

Architecture Overview

The project consists of multiple components:

Kafka Client Library - new command transport implementation, producer and consumer client logic.

Remoting Kafka Plugin - plugin implementation with KafkaGlobalConfiguration and KafkaComputerLauncher.

Remoting Kafka Agent - A custom JAR agent with remoting JAR packaged together with a custom Engine implementation to setup a communication channel with Kafka.

All the components are packaged together with Docker Compose.

The below diagram is the overview of the current architecture:

With this design, controller is not communicating with agent using direct TCP communication anymore, all the communication commands are transfered with Kafka.

Features

1. Kafka Global Configuration

2. Custom agent start up as a JAR

User can start running an agent with the following command:

3. Launch agents with Kafka

4. Commands transferred between controller and agent over Kafka

Remoting operations are being executed over Kafka. In the log you may see:

Classloading (Classloader.fetch())

Log streaming (Pipe.chunk())

5. Run jobs with remoting Kafka

It is possible to run jobs on Agents connected over Kafka

Next Phase Plan

Here are the tasks planned for the next phase:

Support security for controller-agent connection:

Kafka authentication/authorization ( JENKINS-51472, JENKINS-51473).

Agent secrets ( JENKINS-51470).

Improve Kafka producer-consumer model to ensure reliability ( JENKINS-51942).

Bug fixing.

Release alpha version and address feedback ( JENKINS-51713).

How to run demo

You can try to run a demo of the plugin by following the instruction.

Links

GitHub Repository

Project Page

Phase 1 Presentation Video

Phase 1 Presentation Slides<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/pvtuan10/">Pham Vu Tuan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/19/jenkins-java10-hackathon-day2/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">19</div></div><h5 class="title">Jenkins &amp; Java 10+ Online Hackathon. Day 2 Update</h5></div><p class="teaser">This week we have a
Jenkins &amp; Java 10 Online Hackathon.
This is an open online event, where we work together on Jenkins core and plugins in order
to find and fix compatibility issues, share experiences and have some fun.
Everybody is welcome to join, independently of their Jenkins experience and amount of time they have available.

After the kick off on Monday
Jenkins contributors have been working on Java 10 and Java 11 support in Jenkins.
We have already received contributions from 12 hackathon participants, and the number keeps growing.
There are still 3 days ahead, but we have already achieved some important results we want to share.

Jenkins Pipeline

One of our major efforts over last 2 days was to get Jenkins Pipeline working on
Java 10+.
When the hackathon started Jenkins Pipeline was not working at all,
and it was a major blocker for Java support and for exploratory testing in particular.
We’ve been working together with Sam van Oort and Devin Nusbaum to fix the libraries in
the Jenkins core, Pipeline: Support plugin and Docker packaging.

Just to summarize the result of two days in one screenshot…​

Yes, we have got it running!
Over two days we have got from the &quot;Pipeline Crashes Immediately&quot;
state to the situation when the most of key Pipeline features are operational,
including Scripted and Declarative Pipeline, Blue Ocean, shared libraries and
dozens of plugins being used in the Jenkins plugin build flow.

There is still a lot of work to do to get the changes finalized,
but Jenkins Pipeline is available for testing on Java 10 and 11 now.
If you want to try it out, you can use a new jenkins/jenkins-experimental:blueocean-jdk10
image we have created.
It bundles all the required patches, so you can just run the following command to get started:

docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins-experimental:blueocean-jdk10

If you want to try more complex scenarions, see the
Running Jenkins with Java 10 and 11 blogpost
and List of Required patches.

What else?

Although Pipeline is the most visible change,
there are other ongoing activities:

Devin Nusbaum explored plugin startup issues we had with JDK 11ea+17
and confirmed that we need to upgrade our images to JDK 11ea+18

Gianpaolo Macario is working on adopting the Java 10 experimental images in his
easy-jenkins project

Sam van Oort and Devin Nusbaum are working on getting plugin build and test flows
when using JDK 10 with Maven

Nicolas de Loof is working on cleaning up Illegal reflective access warnings in Jenkins components,
using the new Fields micro-library

Olivier Lamy and Nicolas de Loof are updating the
Animal Sniffer plugin for Maven
to make it compatible with Java 9 and above

Kohsuke Kawaguchi has released a repackaged version of ASM 6.2 we use in the project

Last but not least, Liam Newman and Tracy Miranda helped us a lot to run the meetings
and to get this hackathon organized

There are also other contributors working on exploratory testing and reporting
defects they discover.
See our status doc
for the full list.

What’s next?

Tomorrow we will have 2 sessions:

At 8AM UTC we will have a sync-up.
According to the requests from hackathon paticipants, we will have an intro session to Jenkins development for newcomers

YouTube link

At 4PM UTC we will have a meeting with key JDK Project Jigsaw committers

Mark Reinhold, Mandy Chung and Paul Sandoz will join us to talk about
Java 10/11 adoption

YouTube link

We will also post participant links in our Gitter channel
15 minutes before the meetings.
If you have any questions, please join the meetings or raise questions in the chat during the call.

Can I still join the hackathon?

Yes, you can!
It is possible to hop in and hop off at any time.
Just respond to the registration form,
join our Gitter channel and start hacking/testing.

We also have a number of
newbie-friendly issues
you can start from.
See our Kick-off session and
slides for quick start guidelines.

Links

Developer mailing list

Hackathon sync-up document

Running Jenkins with Java 10 and 11

Jenkins Online Meetup page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java10">java10</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java11">java11</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/20/anchore-image-scanning/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">20</div></div><h5 class="title">Securing your Jenkins CI/CD Container Pipeline with Anchore (in under 10 minutes)</h5></div><p class="teaser">(adapted from this blog post by Daniel Nurmi)

As more and more Jenkins users ship docker containers, it is worth thinking about the security implications of this model, where the variance in software being included by developers has increased dramatically from previous models. Security implications in this context include what makes up the image, but also the components of the app that get bundled into your image. Docker images are increasingly becoming a “unit of deployment”, and if you look at a typical app (especially if it is a microservice), much of the components, libraries, and system are someone else’s code.

Anchore exists to provide technology to act as a last line of defense, verifying the contents of these new deployable units against user specified policies to enforce security and compliance requirements. In this blog you will get a quick tour of this capability, and how to add the open-source Anchore Engine API service into your pipeline to validate that the flow of images you are shipping comply with your specific requirements, from a security point of view.

Key among the fundamental tenets of agile development is the notion of “fail fast, fail often”, which is where CI/CD comes in: A developer commits code into the source code repository, such as git, that automatically triggers Jenkins to perform a build of the application that is then run through automated tests. If these tests fail the developer is notified immediately and can quickly correct the code. This level of automation increases the overall quality of code and speeds development.

While some may feel that “fail fast” sounds rather negative (especially regarding security), you could better describe this process as “learn fast” as mistakes are found earlier in the development cycle and can be easily corrected. The increased use of CI/CD platforms such as Jenkins has helped to improve the efficiency of development teams and streamlined the testing process. We can leverage the same CI/CD infrastructure to improve the security of our container deployments.

For many organizations the last step before deploying an application is for the security team to perform an audit. This may entail scanning the image for vulnerable software components (like outdated packages that contain known security vulnerabilities) and verifying that the applications and OS are correctly configured. They may also check that the organization’s best practices and compliance policies have been correctly implemented.

In this post we walk through adding security and compliance checking into the CI/CD process so you can “learn fast” and correct any security or compliance issues early in the development cycle. This document will outline the steps to deploy Anchore’s open source security and compliance scanning engine with Jenkins to add analytics, compliance and governance to your CI/CD pipeline.

Anchore has been designed to plug seamlessly into the CI/CD workflow, where a developer commits code into the source code management system, which then triggers Jenkins to start a build that creates a container image. In the typical workflow this container image is then run through automated testing. If an image does not meet your organization’s requirements for security or compliance then it makes little sense to invest the time required to perform automated tests on the image, it would be better to “learn fast” by failing the build and returning the appropriate reports back to the developer to allow the issue to be addressed.

Anchore has published a plugin for Jenkins which, along with Anchore’s open source engine or Enterprise offering, allows container analysis and governance to be added quickly into the CI/CD process.

Requirements

This guide presumes the following prerequisites have been met:

Jenkins 2.x installed and running on a virtual machine or physical server.

Anchore-Engine installed and running, with accessible engine API URL (later referred to as) and credentials (later referred to as and) available - see Anchore Engine overview and installation.

Anchore’s Jenkins plugin can work with single node installations or installations with multiple worker nodes.

Step 1: Install the Anchore plugin

The Anchore plugin has been published in the Jenkins plugin registry and is available for installation on any Jenkins server. From the main Jenkins menu select Manage Jenkins, then Manage Plugins, select the Available tab, select and install Anchore Container Image Scanner.

Step 2: Configure Anchore Plugin.

Once the Anchore Container Image Scanner plugin is installed - select Manage Jenkins menu click Configure System, and locate the Anchore Configuration section.  Select and enter the following parameters in this section:

Click Enable Anchore Scanning

Select Engine Mode

Enter your in the Engine URL text box - for example: http://your-anchore-engine.com:8228/v1

Enter your and in the Engine Username and Engine Password fields, respectively

Click Save

An example of a filled out configuration section is below, where we’ve used “http://192.168.1.3:8228/v1” as, “admin” as and “foobar” as :

At this point the Anchore plugin is configured on Jenkins, and is available to be accessed by any project to perform Anchore security and policy checks as part of your container image build pipeline.

Step 3: Add Anchore image scanning to a pipeline build.

In the Pipeline model the entire build process is defined as code. This code can be created, edited and managed in the same way as any other artifact of your software project, or input via the Jenkins UI.

Pipeline builds can be more complex including forks/joins and parallelism. The pipeline is more resilient and can survive the controller node failure and restarts. To add an Anchore scan you need to add a simple code snippet to any existing pipeline code that first builds an image and pushes it to a docker registry. Once the image is available in a registry accessible by your installed Anchore Engine, a pipeline script will instruct the Anchore plugin to:

Send an API call to the Anchore Engine to add the image for analysis

Wait for analysis of the image to complete by polling the engine

Send an API call to the Anchore Engine service to perform a policy evaluation

Retrieve the evaluation result and potentially fail the build if the plugin is configured to fail the build on policy evaluation STOP result (by default it will)

Provide a report of the policy evaluation for review

Below is an example end-to-end script that will make a Dockerfile, use the docker plugin to build and push the a docker container image to dockerhub, perform an Anchore image analysis on the image and the result, and cleanup the built container.  In this example, we’re using a pre-configured docker-exampleuser named dockerhub credential for dockerhub access, and exampleuser/examplerepo:latest as the image to build and push.  These values would need to be changed to reflect your own local settings, or you can use the below example to extract the analyze stage to integrate an anchore scan into any pre-existing pipeline script, any time after a container image is built and is available in a docker registry that your anchore-engine service can access.

pipeline {
    agent any
    stages {
        stage(&#x27;build&#x27;) {
            steps {
                sh&#x27;&#x27;&#x27;
                    echo &#x27;FROM debian:latest’ &gt; Dockerfile
                    echo ‘CMD [&quot;/bin/echo&quot;, &quot;HELLO WORLD....&quot;]&#x27; &gt;&gt; Dockerfile
                &#x27;&#x27;&#x27;
                script {
                    docker.withRegistry(&#x27;https://index.docker.io/v1/&#x27;, &#x27;docker-exampleuser&#x27;) {
                        def image = docker.build(&#x27;exampleuser/examplerepo:latest&#x27;)
                        image.push()
                    }
                }
            }
        }
        stage(&#x27;analyze&#x27;) {
            steps {
                sh &#x27;echo &quot;docker.io/exampleuser/examplerepo:latest `pwd`/Dockerfile&quot; &gt; anchore_images&#x27;
                anchore name: &#x27;anchore_images&#x27;
            }
        }
        stage(&#x27;teardown&#x27;) {
            steps {
                sh&#x27;&#x27;&#x27;
                    for i in `cat anchore_images | awk &#x27;{print $1}&#x27;`;do docker rmi $i; done
                &#x27;&#x27;&#x27;
            }
        }
    }
}

This code snippet writes out the anchore_images file that is read by the plugin to determine which image is to be added to Anchore Engine for scanning.

This code snippet can be crafted by hand or built using the Jenkins UI, for any Pipeline project. In the project configuration, select Pipeline Syntax from the Project.

This will launch the Snippet Generator where you can enter the available plugin parameters and press the Generate Pipeline Script button which will produce a snippet that you can use as a starting point.

Using our example from above, next we save the project:

Note that once you are happy with your script, you could also check it into a Jenkinsfile, alongside the source code.

Step 4: Run the build and review the results.

Finally, we run the build, which will generate a report.  In the below screenshots, we’ve scanned the image docker.io/library/debian:latest to demonstrate some example results.  Once the build completes, the final build report will have some links that will take you to a page that describes the result of the Anchore Engine policy evaluation and security scan:

In this case, since we left the Fail build on policy STOP result as its default (True), the build has failed due to anchore-engine reporting a policy violation.  In order to see the results, click the Anchore Report (STOP) link:

Here, we can see that there is a single policy check that has generated a ‘STOP’ action, which triggered due to a high severity vulnerability being found against a package installed in the image.  If there were only ‘WARN’ or ‘GO‘ check results here, they would also be displayed, but the build would have succeeded.

With the combination of Jenkins pipeline project capabilities, plus the Anchore scanner plugin, it’s quick and easy to add container image security scanning and policy checking to your Jenkins project.  In this example, we provide the mechanism for adding scanning to a Jenkins pipeline project using a simple policy that is doing an OS package vulnerability scan, but there are many more policy options that can be configured and loaded into Anchore Engine ranging from security checks to your own site-specific best practice checks (software licenses, package whitelist/blacklist, dockerfile checks, and many more).  For more information about the breadth of Anchore policies, you can find information about Anchore Engine configuration and usage here.

For more information on Jenkins Pipelines and Anchore Engine, check out the following information sources:

https://anchore.com/

https://anchore.com/opensource/

https://github.com/anchore/anchore-engine

https://anchore.freshdesk.com/support/home

Chat on Anchore open source slack<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/21/jenkins-x-devpods/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">21</div></div><h5 class="title">Using Jenkins X DevPods for development</h5></div><p class="teaser">I use macOS day to day, and often struggle to keep my devtools up to date.
This isn’t any fault of packaging or tools, more just that I get tired of seeing the beachball:

The demands on dev machines grow, developers are now working across a more diverse
set of technologies than just a JVM or a single scripting language these days.

This keeping up to date is a drag on time (and thus money).
There are lots of costs involved with development, and I
have written about
about the machine cost for development (how using something like GKE can be much
cheaper than buying a new machine) but there is also the cost of a developer’s time.
Thankfully, there are ways to apply the same smarts here to save time as well as money.
 And time is money, or money is time?

Given all the work done in automating the detection and installation of required
tools, environments, and libraries that goes on when you run ‘jx import’ in
Jenkins X,
it makes sense to also make those available for development time,
and the concept of “DevPods” was born.

The pod part of the name comes from the Kubernetes concept of pods (but you don’t have to know about Kubernetes or pods to use Jenkins X. There is a lot to Kubernetes but Jenkins X aims to provide a developer experience that doesn’t require you to understand it).

Why not use Jenkins X from code editing all the way to production,
before you even commit the code or open a pull request?
All the tools are there, all the environments are there, ready to use (as they are used at CI time!).

This rounds out the picture: Jenkins X aims to deal with the whole lifecycle for you,
from ideas/issues, change requests, testing, CI/CD, security and compliance verification,
rollout and monitoring. So it totally makes sense to include the actual dev time tools.

If you have an existing project, you can create a DevPod by running (with the jx command):

jx create devpod

This will detect what type of project is (using build packs) and create a DevPod
for you with all the tools pre-installed and ready to go.

Obviously, at this point you want to be able to make changes to your app and try it out.
Either run unit tests in the DevPod, or perhaps see some dev version of the app running in your browser (if it is a web app).
Web-based code editors have been a holy grail for some time, but never have quite taken off in the mainstream of developers (despite there being excellent ones out there, most developers prefer to develop on their desktop).
Ironically, the current crop of popular editors are based around
“electron” which is actually a web technology stack,
but it runs locally (Visual Studio Code is my personal favourite at the moment),
in fact Visual Studio Code has a Jenkins X extension (but you don’t have to use it):

To get your changes up to the Dev Pod, in a fresh shell run (and leave it running):

jx sync

This will watch for any changes locally (say you want to edit files locally on your desktop)
and sync them to the Dev Pod.

Finally, you can have the Dev Pod automatically deploy an “edit” version of the
app on every single change you make in your editor:

jx create devpod --sync --reuse
./watch.sh

The first command will create or reuse an existing Dev Pod and open a shell to it,
then the watch command will pick up any changes, and deploy them to your “edit” app.
You can keep this open in your browser, make a change, and just refresh it.
You don’t need to run any dev tools locally, or any manual commands in the Dev Pod to do this, it takes care of that.

You can have many DevPods running (jx get devpods), and you could stop them at the end of the day (jx delete devpod), start them at the beginning, if you like (or as I say: keep them running in the hours between coffee and beer). A pod uses resources on your cluster, and as the Jenkins X project fleshes out its support for dev tools (via things like VS Code extensions) you can expect even these few steps to be automated away in the near future, so many of the above instructions will not be needed!

End-to-end experience

So bringing it all together, let me show a very wide (you may need to zoom out) screen shot of this workflow:

From Left to Right :

I have my editor (if you look closely, you can see the Jenkins X extension showing the state of apps,
pipelines and the environments it is deployed to).

In the middle I have jx sync running, pushing changes up to the cloud from the editor,
and also the ‘watch’ script running in the DevPod. This means every change I make in my editor,
a temporary version of the app (and its dependencies are deployed).

On the right is my browser open to the “edit” version of the app.
Jenkins X automatically creates an “edit” environment for live changes,
so if I make a change to my source on the left, the code is synced,
build/tested and updated so I can see the change on the right
(but I didn’t build anything locally, it all happens in the DevPod on Jenkins X).

On visual studio code: The Jenkins X extension for visual studio code can automate the creation of devpods and syncing for you. Expect richer support soon for this editor and others.

Explaining things with pictures

To give a big picture of how this hangs together:

In my example, GitHub is still involved, but I don’t push any changes back to it until I am happy with the state of my “edit app” and changes.
I run the editor on my local workstation and jx takes care of the rest.
This gives a tight feedback loop for changes. Of course, you can use any editor you like,
and build and test changes locally (there is no requirement to use DevPods to make use of Jenkins X).

Jenkins X comes with some ready to go environments: development, staging and production (you can add more if you like).
These are implemented as Kubernetes namespaces to avoid the wrong app things talking to the wrong place.
The development environment is where the dev tools live: and this is also where the DevPods can live!
This makes sense as all the tools are available, and saves the hassle of you having slightly different
versions of tools on your local workstation than what you are using in your pipeline.

DevPods are an interesting idea, and at the very least a cool name!
There will be many more improvements/enhancements in this area, so keep an eye out for them.
They are a work in progress, so do check the documentation page for better ways to use them.

Some more reading:

Docs on DevPods on jenkins-x.io

The Visual Studio Code extension
for Jenkins X (what a different world: an open source editor by Microsoft!)

James Strachan’s great intro
to Jenkins X talk at Devoxx-UK also   includes a DevPod demo<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsx">jenkinsx</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/26/jenkins-essentials-at-eclipsecon-france/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">26</div></div><h5 class="title">Presenting Jenkins Essentials at EclipseCon France</h5></div><p class="teaser">Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.

It’s been far too long since we posted an update on
Jenkins Essentials. While it’s not
quite ready for users to start trying it out, we
continue hacking away on all
manner of changes to support the safe and automatic upgrades of a running
Jenkins environment. In the meantime, Jenkins contributor
Baptiste Mathus took some time to introduce and
demonstrate Jenkins Essentials at the recently held
EclipseCon France,

From the talk’s abstract:

The Jenkins Project is working on providing its users with a brand new,
strongly opinionated, and continuously delivered distribution of Jenkins:
Jenkins Essentials. Constantly self-updating, including auto-rollback, with
an aggressive subset of verified plugins.

In this talk, we will detail how this works: how we run and upgrade Jenkins
itself. How instances are continuously sending health data back to help
automated decision-making about the quality of given new release, and decide to
generalize a given version of Jenkins to the whole fleet, or roll it back.

We will end giving an overview of the status of the project: how it’s managed
in a fully open manner, from design to code and its infrastructure, and all the
radical solutions to imagine and the upcoming challenges for the next months.

I hope you enjoy the video

You can learn more about Jenkins Essentials from
GitHub repository, or join us
on our
Gitter channel.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsevergreen">jenkinsevergreen</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/27/lessons-java10-hackathon/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">27</div></div><h5 class="title">What I learned from the Jenkins &amp; Java 10+ Hackathon</h5></div><p class="teaser">Last week I participated in the
Jenkins &amp; Java 10 Online Hackathon.
It was my first Jenkins hackathon and I roped in
Jonah Graham to do some pair-programming.
The hackathon featured JDK Project Jigsaw committers Mandy Chung and Paul Sandoz,
as well as Jenkins creator Kohsuke Kawaguchi.
It was a great opportunity for me to learn a lot about Jenkins and Java 10.

Why Java 10?

With the
Java 8 EoL data looming,
the focus was on the current available version of Java, Java 10.
Java 10 offers some nice new features and APIs, not least
improved docker container integration.
We learned from Paul of a number of projects with Java 10 migration success stories including Elasticsearch, Kafka &amp; Netty.

At the beginning of the hackathon week, the Jenkins Pipeline feature would crash out when using Java 10.
This was resolved with a number of fixes including the upgrade of the
ASM library.
Then it was nice to see things
up and running with Java 10.

Getting up &amp; running

The first steps were to do some exploratory testing using
Jenkins with Java 10 via Docker, thanks to
Oleg for providing clear instructions.
This was boringly straightforward as most things worked and we only found one
issue to report.
Next to try to get some patches in, we needed to set-up a dev environment.
The live session gave us what we needed to set up a
plugin or
core dev environment.
One open question we had was whether Jenkins has semantic versioning and
API tools
to help identify when you might be breaking backwards compatibility.
Overall it was straightforward to get a dev environment up and running.

Java 10 New APIs

The next step was to find an issue which we could help resolve.
Many of the Java 10 issues were related to &#x27;Illegal reflective access&#x27; from various plugins or third-party libraries.
However after investigating a couple, removing these warnings required a good architectural knowledge of the plugin or core code itself.
In the end we decided that messing around with classloaders or attempting to upgrade version of jdom was not one for the newbies.

Instead we looked at
removing reflection
in cases of isAccessible calls.
We found the
ProcessHandle
api very useful and a good replacement for some misuse of reflection, and even better it made the code work on Windows too.
Mandy also pointed us to look at the
Lookup api
as possible alternate to findClass calls.

Multi-Release JAR Builds

Using new APIs is all well and good but presents a problem when you want to maintain backwards compatibility with Java 8.
Hence the need for some sort of multi-jar solution -
Nicolas De loof proposed one such solution for
multi-release jars with Maven for this case.

sun.misc.Signal

The Java Signal API is being deprecated, but so far no replacement APIs
are available for signal handling.
Jenkins makes use of the Signal APIs so a big question for the Jigsaw team was whether this would be replaced going forward.
Kohsuke pointed out how it is important for Java to maintain this UNIX like behaviour as it shouldn’t matter to end users that Jenkins is written in Java.
It seems these APIs will be replaced in due course, they just
aren’t there right now.

Collaboration, Collaboration, Collaboration

It was great to have the discussions with the Jigsaw team.
They reminded us how they need to know the Java use cases out there and how their team uses these to feed into their development process.
In turn, the hackathon had Jenkins community members participate, for instance
easy-jenkins was up and running with Java 10 by the end of the week.
The hackathon had a great feeling of community spirit and was a reminder why collaborations with communities and also between different communities can be powerful and fun for all involved.

At the end of the week Jonah and I were both happy that we made our first Jenkins contributions (which were reviewed and merged quickly).
Thanks to all who participated and made it highly enjoyable, especially Oleg for great organization.
I look forward to the next one!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java10">java10</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java11">java11</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/06/27/new-login-page/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">27</div></div><h5 class="title">New design, UX and extensibility digest for login page et. al.</h5></div><p class="teaser">This blog post gives an introduction to the new design for the login and signup forms and Jenkins is (re)starting pages introduced in Jenkins 2.128.
The first part of the blog post is an introduction to the new design and UX for Jenkins users.
The later part is talking about extensibility in a more technical manner, aimed at plugin developers.

Overview

The recent changes to some core pages provide new design and UX and further dropping all external dependencies to prevent
any possible malicious javascript introduced by third party libraries.
To be clear, this never was an issue with previous releases of Jenkins, but having read this article, this author believes that the article has good points and leading by example may raise awareness of data protection.

This meant to drop the usage of the jelly layout lib (aka xmlns:l=&quot;/lib/layout&quot;) and as well the page decorators it
supported. However there is a new SimplePageDecorator extension point (discussed below) which can be used to modify the look and feel for the login and sign up page.

The following pages have given a new design:

Jenkins is (re)starting pages

Login

Sign up

UX enhancement

Form validation has changed to give inline feedback about data validation errors in the same form.

Login

Sign up

The above image shows that the validation is now done on all input fields instead of before breaking on the
first error found, which should lead to fewer retry cycles.

Instead of forcing the user to repeat the password, the new UX introduces the possibility to display the password in
clear text. Further a basic password strength meter indicates password strength to the user while she enters the password.

Customizing the UI

The re-/starting screens do not support the concept of decorators very well, hence the decision to not support them for these pages.

The SimplePageDecorator is the key component for customization and uses three different files to
allow overriding the look and feel of the login and signup pages.

simple-head.jelly

simple-header.jelly

simple-footer.jelly

All of the above SimplePageDecorator Jelly files are supported in the login page. The following snippet is a minimal excerpt
of the login page, showing how it makes use of SimplePageDecorator.

The sign-up page only supports the simple-head.jelly:

SimplePageDecorator - custom implementations

Have a look at Login Theme Plugin, which allows you to
configure your own custom content to be injected into the new login/sign-up page.

To allow easy customisation the decorator only implements one instance by the principal &quot;first-come-first-serve&quot;.
If jenkins finds an extension of the SimplePageDecorator it will use the Jelly files provided by that plugin.
Otherwise Jenkins will fall back to the default implementation.

@Extension
public class MySimplePageDecorator extends SimplePageDecorator {
   public String getProductName() {
     return &quot;MyJenkins&quot;;
   }
}

The above will take override over the default because the default implementation has a very low ordinal ( @Extension(ordinal=-9999))
If you have competing plugins implementing SimplePageDecorator, the implementation with the highest ordinal will be used.

As a simple example, to customize the logo we display in the login page, create a simple-head.jelly with the following content:

To customize the login page further, create a simple-header.jelly like this:

Welcome to ${it.productName}!

For example, I used this technique to create a prototype of a login page for a CloudBees product I am working on:

Conclusion

We hope you like the recent changes to some core pages and as well the new design and UX. We further hope you feel enabled to
customize the look and feel to adopt your needs with the SimplePageDecorator.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/scherler/">Thorsten Scherler</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/02/new-api-token-system/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 2</div></div><h5 class="title">Security Hardening: New API token system in Jenkins 2.129+</h5></div><p class="teaser">About API tokens

Jenkins API tokens are an authentication mechanism that allows a tool (script, application, etc.) to impersonate a user
without providing the actual password for use with the Jenkins API or CLI.
This is especially useful when your security realm is based on a central directory, like Active Directory or LDAP,
and you don’t want to store your password in scripts.
Recent versions of Jenkins also make it easier to use the remote API when using API tokens to authenticate,
as no CSRF tokens need to be provided even with CSRF protection enabled.
API tokens are not meant to — and cannot — replace the regular password for the Jenkins UI.

Previous problems

We addressed two major problems with the existing API token system in Jenkins 2.129:

First, reported in JENKINS-32442,
user accounts in Jenkins have an automatically generated API token by default.
As these tokens can be used to authenticate as a given user, they increase the attack surface of Jenkins.

The second problem was reported in JENKINS-32776 :
The tokens were previously stored on disk in an encrypted form.
This meant that they could be decrypted by unauthorized users by leveraging another security vulnerability,
or obtained, for example, from improperly secured backups, and used to impersonate other users.

New approach

The main objective of this new system is to provide API tokens that are stored in a unidirectional way on the disk,
i.e. using a hashing algorithm (in this particular case SHA-256).

While this means that you will not be able to see the actual API tokens anymore after you’ve created them,
several features were added to mitigate this potential problem:

You can have multiple active API tokens at the same time.
If you don’t remember an API token’s value anymore, just revoke it.

You can name your tokens to know where they are used (and rename them after creation if desired).
We recommend that tokens use a name that indicates where (for example the application, script, or host) where it will be used.

You can track the usage of your tokens.
Every token keeps a record of the number of uses and the date of the last use.
This will allow you to better know which tokens are really used and which are no longer actively required.
Jenkins also encourages users to rotate old API tokens by highlighting their creation date in orange after six months, and in red after twelve months.
The goal is to remind the user that tokens are more secure when you regenerate them often:
The longer a token is around, perhaps passed around in script files and stored on shared drives,
the greater the chance it’s going to be accessed by someone not authorized to use it.

Figure 1. Token usage tracking

You can revoke API tokens.
When you know that you are not using a given token anymore, you can revoke it to reduce the risk of it getting used by unauthorized users.
Since you can have multiple API tokens, this allows fine-grained control over which scripts, hosts, or applications are allowed to use Jenkins as a given user.

Migrating to new API tokens

To help administrators migrate their instances progressively, the legacy behavior is still available, while new system is also usable.

On the user configuration page, the legacy token is highlighted with a warning sign,
explaining that users should revoke it and generate a new one (if needed) to increase security.

Figure 2. Legacy token renewal still possible

New options for administrators

In order to let administrators control the pace of migration to the new API token system,
we added two global configuration options in the &quot;Configure Global Security&quot; page in the brand new &quot;API Token&quot; section:

An option to disable the creation of legacy API tokens on user creation.

An option to disable the recreation of legacy API tokens by users, forcing them to only use the new, unrecoverable API tokens.

Both options are disabled by default for new installations (the safe default), while they’re enabled when Jenkins is upgraded from before 2.129.

Figure 3. Security Configuration options

Figure 4. Remove legacy token and disable the re-creation

New administrator warnings

When upgrading to Jenkins 2.129, an administrative monitor informs admins about the new options described above, and recommend disabling them.

Another administrative warnings shows up if at least one user still has a legacy API token.
It provides central control over legacy tokens still configured in the Jenkins instance, and allows revoking them all.

Figure 5. Legacy token monitoring page

Summary

Jenkins API tokens are now much more flexible: They allow and even encourage better security practices.
We recommend you revoke legacy API tokens as soon as you can, and only use the newly introduced API tokens.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/wadeck/">Wadeck Follonier</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/upgrade">upgrade</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/02/whats-new-declarative-piepline-13x-sequential-stages/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 2</div></div><h5 class="title">What&#x27;s New in Declarative Pipeline 1.3: Sequential Stages</h5></div><p class="teaser">We recently released version 1.3 of Declarative Pipelines, which includes a couple significant new features. We’re
going to cover these features in separate blog posts. The next post will show the new ability to restart a completed
Pipeline run starting from a stage partway through the Pipeline, but first, let’s look at the new sequential stages
feature.

Sequential Stages

In Declarative 1.2, we added the ability to define stages to run in parallel
as part of the Declarative syntax. Now in Declarative 1.3, we’ve added another way to specify stages nested within other
stages, which we’re calling &quot;sequential stages&quot;.

Running Multiple Stages in a Parallel Branch

One common use case is running build and tests on multiple platforms. You could already do that with parallel stages,
but now you can run multiple stages in each parallel branch giving you more visibility into the progress of your
Pipeline without having to check the logs to see exactly which step is currently running where, etc.

You can also
use stage directives, including post, when, agent, and all the others covered in the
Pipeline Syntax reference
in your sequential stages, letting you control behavior for different parts of each parallel branch.

In the example below, we are running builds on both Windows and Linux, but only want to deploy if we’re on the master branch.

pipeline {
    agent none

    stages {
        stage(&quot;build and deploy on Windows and Linux&quot;) {
            parallel {
                stage(&quot;windows&quot;) {
                    agent {
                        label &quot;windows&quot;
                    }
                    stages {
                        stage(&quot;build&quot;) {
                            steps {
                                bat &quot;run-build.bat&quot;
                            }
                        }
                        stage(&quot;deploy&quot;) {
                            when {
                                branch &quot;master&quot;
                            }
                            steps {
                                bat &quot;run-deploy.bat&quot;
                            }
                        }
                    }
                }

                stage(&quot;linux&quot;) {
                    agent {
                        label &quot;linux&quot;
                    }
                    stages {
                        stage(&quot;build&quot;) {
                            steps {
                                sh &quot;./run-build.sh&quot;
                            }
                        }
                        stage(&quot;deploy&quot;) {
                             when {
                                 branch &quot;master&quot;
                             }
                             steps {
                                sh &quot;./run-deploy.sh&quot;
                            }
                        }
                    }
                }
            }
        }
    }
}

Running Multiple Stages with the Same agent, or environment, or options

While the sequential stages feature was originally driven by users wanting to have multiple stages in parallel branches,
we’ve found that being able to group multiple stages together with the same agent, environment, when, etc has a lot
of other uses. For example, if you are using multiple agents in your Pipeline, but would like to be sure that stages using
the same agent use the same workspace, you can use a parent stage with an agent directive on it, and then all the stages
inside its stages directive will run on the same executor, in the same workspace. Another example is that until now, you
could only set a timeout for the entire Pipeline or an individual stage. But by using a parent stage with nested stages,
you can define a timeout in the parent’s options directive, and that timeout will be applied for the execution of the
parent, including its nested stages. You may also want to conditionally control the execution of multiple stages. For example,
your deployment process may be spread across multiple stages, and you don’t want to run any of those stages unless you’re on
a certain branch or some other criteria is satisified. Now you can group all those related stages together in a parent
stage, within its stages directive, and have a single when condition on that parent, rather than having to copy an
identical when condition to each of the relevant stages.

One of my favorite use cases is shown in the example below. In Declarative 1.2.6, we added the input directive for stages.
This will pause the execution of the Pipeline until a user confirms that the Pipeline should continue, using the Scripted
Pipeline input step. The input directive is evaluated before the stage enters its agent, if it has one specified, and
before the stage’s when condition, if specified, is evaluated. But if you’re using a top-level agent for most of your
stages, you’re still going to be using that agent’s executor while waiting for input, which can be a waste of resources.
With sequential stages, you can instead use agent none at the top-level of the Pipeline, and group the stages using a common
agent and running before the stage with the input directive together under a parent stage with the required agent
specified. Then, when your Pipeline reaches the stage with input, it will no longer be using an agent’s executor.

pipeline {
    agent none

    stages {
        stage(&quot;build and test the project&quot;) {
            agent {
                docker &quot;our-build-tools-image&quot;
            }
            stages {
               stage(&quot;build&quot;) {
                   steps {
                       sh &quot;./build.sh&quot;
                   }
               }
               stage(&quot;test&quot;) {
                   steps {
                       sh &quot;./test.sh&quot;
                   }
               }
            }
            post {
                success {
                    stash name: &quot;artifacts&quot;, includes: &quot;artifacts/**/*&quot;
                }
            }
        }

        stage(&quot;deploy the artifacts if a user confirms&quot;) {
            input {
                message &quot;Should we deploy the project?&quot;
            }
            agent {
                docker &quot;our-deploy-tools-image&quot;
            }
            steps {
                sh &quot;./deploy.sh&quot;
            }
        }
    }
}

These are just a few example of the power of the new sequential stages feature in Declarative 1.3.
This new feature adds another set of significant use cases that can be handled smoothly using Declarative Pipeline.
In my next post, I’ll show the another highly requested feature - the new ability to restart a Pipeline run from any stage in that Pipeline.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abayer/">Andrew Bayer</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/05/remoting-over-message-bus-alpha-release/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 5</div></div><h5 class="title">GSoC Project Update: Alpha release of Remoting Kafka Plugin</h5></div><p class="teaser">I am happy to announce that we have recently released an alpha version of Remoting Kafka Plugin to the Experimental Update Center. You can check the CHANGELOG to see the features included in this initial release.

Overview

Current versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.

Remoting Kafka Plugin is a plugin developed under Jenkins Google Summer of Code 2018. The plugin is developed to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins. A quick introduction of the project can be found in this introduction blogpost.

How to use the plugin?

The instructions to run the plugin in alpha version are written here. Feel free to have a try and let us know your feedback on Gitter or the mailing list.

Links

Alpha Changelog

Introduction Blogpost

GitHub Repository

Project Page

Phase 1 Presentation Video

Phase 1 Presentation Slides<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/pvtuan10/">Pham Vu Tuan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/alpha-release">alpha-release</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/10/jenkins-essentials-on-aws/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">10</div></div><h5 class="title">Jenkins Essentials flavor for AWS</h5></div><p class="teaser">Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.

Jenkins Essentials is about providing a distribution of Jenkins in less than five minutes and five clicks.
One of the main ideas to make this a reality is that Jenkins will be autoconfigured with sane defaults for the environment it is running in.

We are happy to report we recently merged the change that provides this feature for AWS.
We use an AWS CloudFormation template to provision a working version of Jenkins Essentials, automatically configured to:

dynamically provision EC2 agents, using the EC2 plugin;

use the Artifact Manager on S3 plugin, so that artifacts are not stored anymore on the controller’s file system, but directly in an S3 bucket.

I recorded a short demo video last week showing the basics of this:

While there are still many items to complete to provide a usable version for end-users, we are making steady progress towards it.

You can learn more about Jenkins Essentials from the
GitHub repository, or join us
on our
Gitter channel.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsevergreen">jenkinsevergreen</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/13/jenkins-user-conference-china.adoc/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">13</div></div><h5 class="title">Jenkins User Conference China Beijing Recap</h5></div><p class="teaser">On June 30, 2018 in sunny Beijing, the capital of China, we welcomed over 200 attendees to Jenkins User Conference China (JUCC). This is the first JUCC in Beijing and we are overwhelmed by the interest and love for Jenkins. The conference had sessions in DevOps, Continuous Delivery, Jenkins X, Pipeline, and Container. The GreatOps community, event host, invited John Willis, a thought leader of DevOps to deliver the keynote speech. John’s topic was &quot;DevOps: Almost 10 years - What A  Strange Long Trip It’s Been.&quot; It was very insightful to learn of the history of DevOps and John’s point of view on the practice.

Lily Lin from Micro Focus presented, &quot;How to practice CI/CD for large-scale micro service based on Jenkins Pipeline.&quot;

James Rawlings, one of the core Jenkins X contributors traveled from the United Kingdom to present, &quot;Jenkins X for the future, Easy CI/CD for Kubernetes.&quot;

After James’ presentation, there were many questions about Jenkins X, Jenkins users in China are very interested in Jenkins X. We all posed Jenkins &quot;X&quot; gesture.

We also invite Shuwei Hao from Alibaba, Michael Hüttermann who is the author of DevOps for Developers, Xiang Lu from CPI.

Mr Huaqiang Li and Xiaojie Zhao ran a workshop for help attendees master Jenkins Pipeline and Jenkins X in the cloud environment.

Here are additional pictures from our event

Special THANKS to BC who is the co-organizer of JUCC to host the main track and Alyssa and Maxwell for your help with our event.

Next up, Jenkins User Conference China Shenzhen in November.
Let’s Jenkins X and DevOps!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/fjing/">Forest Jing</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/juc">juc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/17/simple-pull-request-plugin/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">17</div></div><h5 class="title">Pipeline as YAML: Alpha release</h5></div><p class="teaser">About me

I am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of
technology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my
college. I am passionate about automation.

Project Summary

This is a GSoC 2018 project.

This project aims to develop a pull request Job Plugin. Users should be able to
configure job type using YAML file placed in root directory of the
Git repository being the subject of the pull request. The plugin should interact with various
platforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.

Plugin detects the presence of certain types of reports at conventional locations,
and publish them automatically. If the reports are not present at their respective conventional
location, the location of the report can be configured in the YAML file.

My mentors are
Oleg Nenashev (Org Admin),
Martin d’Anjou,
Kristin Whetstone,
Jeff Knurek

Benefits to the community

Project administrators will be able to handle pull request builds more easily.

Build specifications for pull requests can be written in a concise declarative format.

Build reports will be automatically published to Github, Bitbucket, etc.

Build status updates will be sent to git servers automatically.

Users will not have to deal with pipeline code.

If there will be no merge conflicts or build failures, the PR can be merged into target branch.

Phase 1 blog post

Please see Phase 1 blog post

Implementations till now

Alpha version of the plugin is released. It supports all features of Multi-Branch Pipeline and offers the following features.

Build description is defined via YAML file stored within the SCM repo. This plugin
will depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be
using respective platforms for their repositories.

Conversion of YAML to Declarative Pipeline: A class YamlToPipeline
is written which will load the &quot;Jenkinsfile.yaml&quot; and make use of PipelineSnippetGenerator class
to generate Declarative pipeline code.

Reporting of results, only xml report types is supported for now.

Use of Yaml file (Jenkinsfile.yaml) from target branch.

Git Push step: To push the changes of pull request to the target branch. This is implemented
using git-plugin, PushCommand is used for this from git-plugin. credentialId,
branch name and repository url for interacting with Github, Bitbucket, etc
will be taken automatically from &quot;Branch-Source&quot; (Users have to fill this
details of branch source in job configuration UI). (You can see
How to run the demo)

StepConfigurator: To generate pipeline code for all supported steps in Jenkins. This is using
Jenkins configuration-as-code plugin (JCasC plugin) to configure a particular step object and
then that step object is passed to Snippetizer.object2Groovy() method to generate the script of that step.

Jenkinsfile.yaml example

For the phase 1 prototype demonstration, the following yaml file was used.
Note that this format is subject to change in the next phases of the project,
as we formalise the yaml format definition.

#  Docker image agent example
agent:
 label: my_label
 customWorkspace: path_to_workspace
 dockerImage: maven:3-alpine
 args: -v /tmp:/tmp

  tools:
    maven : maven_3.0.1
    jdk : jdk8

configuration:
  # Push PR changes to the target branch if the build succeeds.
  # default value is false
  pushPrOnSuccess: false

  # Trusted user to approve pull requests
  prApprovers:
    - username1
    - username2
    - username3

environment:
  variables:
    variable_1: value_1
    variable_2: value_2

  # Credentials contains only two fields. credentialId must be present in the Jenkins Credentials
  credentials:
    - credentialId : fileCredentialId
      variable : FILE

      # In user scripts Username and Password can be accessed by LOGIN_USR and LOGIN_PSW
      # respectively as environment variales
    - credentialId : dummyGitRepo
      variable : LOGIN

stages:
  - name: stage1
    agent: any
    steps:
      - sh: &quot;scripts/hello&quot;
      - sleep:
          time: 2
          unit: SECONDS
      - sleep: 2
      - junit:
          testResults: &quot;target/**.xml&quot;
          allowEmptyResults: true
          testDataPublishers:
            - AutomateTestDataPublisher
            - JunitResultPublisher:
                urlOverride: &quot;urlOverride&quot;
    # Post section for &quot;stage1&quot;. All Conditions which are available in Jenkins
    # declarative pipeline are supported
    post:
      failure:
        - sh: &quot;scripts/hello&quot;

# Outer post section. Just like declarative pipeline.
post:
  always:
    - sh: &quot;scripts/hello&quot;

Coding Phase 2 plans (Completed)

Decide a proper YAML format to use for Jenkinsfile.yaml

Create Step Configurator for SPRP plugin. JENKINS-51637.
This will enable users to use Pipeline steps in Jenkinsfile.yaml.

Automatic indentation generation in the generated PipelineSnippetGenerator class.

Write tests for the plugin.

Coding Phase 3 plans

Test Multi-Branch Pipeline features support:

Support for webhooks ( JENKINS-51941)

Check if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)

Finalize documentation ( JENKINS-52518)

Release 1.0 ( JENKINS-52519)

Plugin overview blog post

Coding Phase 3 plans after release

Support the “when” Declarative Pipeline directive ( JENKINS-52520)

Nice2have: Support hierarchical report types ( JENKINS-52521)

Add unit tests, JenkinsRule tests, and ATH tests ( JENKINS-52495, JENKINS-52496)

Automatic Workspace Cleanup when PR is closed ( JENKINS-51897)

Refactor snippet generator to extensions ( JENKINS-52491)

Phase 3 Jira Epic

Phase 2 evaluation presentation video

Video:

Phase 2 evaluation presentation slides

How to reach me

Email: gautamabhishek46@gmail.com

Gitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin

References

Project repository

Project page

Gitter chat

Bug Tracker

Demo Repository

Phase 2 Presentation video (July 12, 2018)

Phase 2 Presentation Slides (July 12, 2018)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhishek_gautam/">Abhishek Gautam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/yaml">yaml</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/18/security-updates/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">18</div></div><h5 class="title">Security updates for Jenkins core</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.133 and 2.121.2, that fix multiple security vulnerabilities.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/19/jenkins-x-accelerate/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">19</div></div><h5 class="title">Accelerate with Jenkins X</h5></div><p class="teaser">Jenkins X uses Capabilities identified by the &quot;Accelerate:  The Science Behind Devops&quot;

Jenkins X is a reimagined CI/CD implementation for the Cloud which is heavily influence by the
State of DevOps reports and more recently the book
&quot;Accelerate: The Science Behind Devops&quot; by
Nicole Forsgren,
Jez Humble and
Gene Kim

Years of gathering data from real world teams and organisations which has been analyzed by inspiring thought leaders and data
scientists from the DevOps world, &quot;Accelerate&quot; recommends a number of capabilities that Jenkins X is implementing so
users gain the scientifically proven benefits, out of the box. We’ve started documenting the capabilities that are available
today and will continue as more become available.

Credit: thanks to tracymiranda for the image

Use version control for all artifacts

The Weaveworks folks coined the term GitOps which we love.  Any change to an environment, whether it be a new application,
version upgrade, resource limit change or simple application configuration should be raised as a Pull Request to Git, have
checks run against it like a form of CI for environments and approved by a team that has control over what goes into the
related environment.  We can now enable governance and have full traceability for any change to an environment.

Related Accelerate capability:  Use version control for all production artifacts

Automate your deployment process

Environments

Jenkins X will automatically create Git backed environments during installation and makes it easy to add new ones using
jx create environment.  Additionally when creating new applications via a quickstart ( jx create quickstart), Java based
SpringBoot ( jx create spring) or importing existing applications ( jx import), Jenkins X will both automatically add
CI / CD pipelines and setup the jobs, git repos and webhooks to enable an automated deployment process.

Out of the box Jenkins X creates Staging and Production (this is customisable) permanent environments as well as temporary
environments for preview applications from Pull Requests.

Previews Environments

We are trying to move as much testing, security, validation and experimentation for a change before it’s merged to master.
With the use of temporary dynamically created Preview Environments any pull request can have a preview version built and
deployed, including libraries that feed into a downstream deployable application.  This means we can code review, test,
collaborate better with all teams that are involved in agreeing that change can go live.

Ultimately Jenkins X wants to provide a way that developers, testers, designers and product managers can be as sure as they
can that when a change is merged to master it works as expected.  We want to be confident the proposed change does not
negatively affect any service or feature as well as deliver the value it is intended to.

Where Preview Environments get really interesting is when we are able to progress a PR through various stages of maturity and
confidence where we begin to direct a percentage of real production traffic like beta users to it.  We can then analyse the
value of the proposed change and possible run multiple automated experiments over time using Hypothesis Driven Development.
This helps give us better understanding of how the change will perform when released to all users.

Related Accelerate capability: Foster and enable team experimentation

Using preview environments is a great way to introduce better test automation.  While Jenkins X enables this we don’t yet
have examples of automated tests being run against a preview environment.  A simple test would be to ensure the application
starts ok and Kubernetes liveness check pass for an amount of time. This relates to

Related Accelerate capability: Implement Test Automation
Related Accelerate capability: Automate your deployment process

Permanent Environments

In software development we’re used to working with multiple environments in the lead up to a change being promoted to a live
production environment.  Whilst this seems business as usual it can cause significant delays to other changes if for any
reason that it is deemed not fit via some process that didn’t happen pre merge to master.  Subsequent commits then become
blocked and can cause delay of urgent changes being promoted to production.

As above Jenkins X wants any changes and experiments to be validated before it is merged to master.  We would like changes in
a staging environment to be held there for a short amount of time before being promoted, ideally in an automated fashion.

The default Jenkins X pipelines provide deployment automation via environments.  These are customisable to suite your own
CI / CD pipeline requirements.

Jenkins X recommends Staging should act as a near as possible reflection on production, ideally with real production data
shadowed to it using a service mesh to understand the behaviour.  This also helps when developing changes in preview where we
can link to non production services in staging.

Related Accelerate capability: Automate your deployment process

Use trunk-based development

The Accelerate book found that teams which use trunk based development with short lived branches performed better.  This has
always worked for the Jenkins X core team members so this was an easy capability for Jenkins X to implement when setting up
Git repositories and CI/CD jobs.

Implement Continuous Integration

Jenkins X sees CI as the effort of validating a proposed change via pull requests before it is merged to controller.  Jenkins X
will automatically configure source code repositories, Jenkins and Kubernetes to provide Continuous Integration of the box.

Implement Continuous Delivery

Jenkins X sees CD as the effort of taking that change after it’s been merged to controller through to running in a live
environment.  Jenkins X automates many parts in a release pipeline:

Jenkins X advocates the use of semantic versioning.  We use git tags to calculate the next release version which means we
don’t need to store the latest release version in the controller branch.  Where release systems do store the last or next version
in Git repos it means CD becomes hard, as a commit in a release pipeline back to controller triggers a new release.  This results
in a recursive release trigger.  Using a Git tag helps avoid this situation which Jenkins X completely automates.

Jenkins X will automatically create a released version on every merge to master which can then potentially progress
through to production.

Use loosely coupled architecture

By targeting Kubernetes users of Jenkins X can take advantage of many of the cloud features that help design and develop
loosely coupled solutions.  Service discovery, fault tolerance, scalability, health checks, rolling upgrades, container
scheduling and orchestration to name just a few examples of where Kubernetes helps.

Architect for empowered teams

Jenkins X aims to help polyglot application developers.  Right now Jenkins X has quickstarts and automated CI/CD setup with
language detection for Golang, Java, NodeJS, .Net, React, Angular, Rust, Swift and more to come.  What this also does is
provide a consistent Way of Working so developers can concentrate on developing.

Jenkins X also provides many addons, for example Grafana and Prometheus for automated metrics collection and visualisation.
In this example centralised metrics help understand how your applications behave when built and deployed on Kubernetes.

DevPods are another feature which enables developers to edit source code in their
local IDE, behind the scenes it is then synced to the cloud and rapidly built and redeployed.

Jenkins X believes providing developers automation that helps them experiment in the cloud, with different technologies and
feedback empowers them to make the best decisions - faster.

Fancy a closer look?

Myself, James Strachan and
Rob Davies are going to be presenting and running workshops at
DevOps World  | Jenkins World.  We’ll also be hanging out at the Jenkins X demo
area so come and say hello and see what’s the latest cool and exiting things to come out of Jenkins X.  Use JWFOSS for 30%
discount off registration

Want to get involved?

Jenkins X is open source, the community mainly hangs out in the
Jenkins X Kubernetes slack channels and for tips on being more involved with Jenkins X
take a look at our contributing docs.  We’ve been helping lots of folks get into open source, learn
new technoligies and languages like golang.  Why not get involved?

Demo

If you’ve not already seen it here’s a video showing a spring boot quickstart with automatic CI/CD pipelines and preview environments.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jrawlings/">James Rawlings</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsx">jenkinsx</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/20/devops-world-jenkins-world-2018-agenda-is-live/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">20</div></div><h5 class="title">DevOps World-Jenkins World 2018 Agenda is Live</h5></div><p class="teaser">This year the Jenkins project introduced a few exciting efforts:
Configuration as Code, Jenkins X, Jenkins Evergreen, Blue Ocean and Pipeline.
With DevOps World-Jenkins World San Francisco and Nice only a few short months away,
we’ve made sure to include plenty of sessions related to these exciting efforts on the agenda.
With that said, the agenda for both cities is now live and will include workshops and deep dive
sessions on these efforts and much more.
Project contributors for these efforts will be present at both conferences as well, come say ‘hello’.
Here’s a glimpse of what’s on the agenda:

Workshops

Building Continuous Delivery for Microservices with Jenkins X

Creating a Deployment Pipeline with Jenkins 2

Jenkins Administration Fundamentals

Jenkins Pipeline Fundamentals

And more

Sessions

Common Pitfalls in Jenkins Security and How to Avoid Them –
Oleg Nenashev

Habits, Tips and Tricks to Efficiently Automate Tasks with Jenkins -
Michael Paillloncy

Safely Upgrading Jenkins Everyday - Baptiste Mathus -
Baptiste Mathus

Running Jenkins at Scale on Kubernetes – Guillermo Palacio -
Guillermo Palacio

Continuously Delivering an Easy-to-Use Jenkins with Jenkins Evergreen –
Tyler Croy

“Look ma, no hands” – Manage Configuration as Code
Ewelina Wilkosz &amp;
Nicolas De Loof

Automate Testing in Your Container Platform with Jenkins –
Eleanor Mehlenbacher

much more

See the full agenda for both cities here:

DevOps World – Jenkins World 2018 San Francisco Agenda

DevOps World – Jenkins World 2018 Nice Agenda

You can plan on this to be highly educational, wildly engaging… overall an excellent space for collaborative conversations with project maintainers, contributors, and active community members.

See you there!

If you need more persuasion, use the code JWFOSS to get 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-world">jenkins-world</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/23/javadoc-service-improvements/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">23</div></div><h5 class="title">Jenkins Javadoc: Service Improvements</h5></div><p class="teaser">Jenkins infrastructure is continuously improving.
The latest service to get some attention and major improvement is the Jenkins javadoc.

There were a number of issues affecting that service:

Irregular updates -
Developers wouldn’t find the latest java documentation because of inadequate update frequence.

Broken HTTPS support -
when users would go to the Javadoc site they would get an unsafe site warning and then an incorrect redirection.

Obsolete content - Javadoc was not cleaned up correctly and plenty of obsolete pages remained which confused end users.

As Jenkins services
migrate to Azure infrastructure,
something that needed to be done was to move the javadoc service there as a standalone service.
I took the same approach as jenkins.io, putting data on an azure file storage, using a nginx proxy in front of it and running on kubernetes.
This approach brings multiple benefits:

We store static files on an azure file storage which brings data reliability, redundancy, etc.

We use Kubernetes Ingress to configure HTTP/HTTPS endpoint

We use Kubernetes Service to provide load balancing

We use Kubernetes deployment to deploy default nginx containers with azure file storage volume.

HTTP/HTTPS workflow

+----------------------+     goes on     +------------------------------+
  |  Jenkins Developer   |----------------&gt;+  https://javadoc.jenkins.io  |
  +----------------------+                 +------------------------------+
                                                                      |
  +-------------------------------------------------------------------|---------+
  | Kubernetes Cluster:                                               |         |
  |                                                                   |         |
  | +---------------------+     +-------------------+     +-----------v------+  |
  | | Deployment: Javadoc |     | Service: javadoc  &lt;-----| Ingress: javadoc |  |
  + +---------------------+     +-------------------+     +------------------+  |
  |                                           |                                 |
  |                          -----------------+                                 |
  |                          |                |                                 |
  |                          |                |                                 |
  | +------------------------v--+    +--------v------------------+              |
  | | Pod: javadoc              |    | Pod: javadoc              |              |
  | | container: &quot;nginx:alpine&quot; |    | container: &quot;nginx:alpine&quot; |              |
  | | +-----------------------+ |    | +-----------------------+ |              |
  | | | Volume:               | |    | | Volume:               | |              |
  | | | /usr/share/nginx/html | |    | | /usr/share/nginx/html | |              |
  | | +-------------------+---+ |    | +----+------------------+ |              |
  | +---------------------|-----+    +------|--------------------+              |
  |                       |                 |                                   |
  +-----------------------|-----------------|-----------------------------------+
                          |                 |
                          |                 |
                       +--+-----------------+-----------+
                       |   Azure File Storage: javadoc  |
                       +--------------------------------+

The javadoc static files are now generated by a Jenkins
job regularly and then published from a trusted jenkins instance.
We only update what has changed and remove obsolete documents.
More information can be find
here

The next thing in continuously improving is also to look at the user experience of the javadoc to make it easier to discover javadoc for other components or versions.
( Help Needed)

These changes all go towards improving the developer experience for those using javadocs and making life easier for core and plugin developers.
See the new and improved javadoc service here
Jenkins Javadoc.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/javadoc">javadoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/23/remoting-kafka-plugin-1.0-release/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">23</div></div><h5 class="title">Remoting Kafka Plugin 1.0: A new method to connect agents</h5></div><p class="teaser">I am very excited to announce that we have recently released 1.0 version of Remoting Kafka Plugin under Jenkins Plugin. You can check the CHANGELOG to see the features included in this release.

About me

My name is Pham Vu Tuan, I am a final year undergraduate student from Singapore. This is the first time I participate in Google Summer of Code and contribute to an open-source organization.

Mentors

I have GSoC mentors who help me in this project Oleg Nenashev and Supun Wanniarachchi. Besides that, I also receive great support from developers in remoting project Devin Nusbaum and Jeff Thompson.

Overview

Current versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.

This project aims to develop a plugin in order to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins.

Benefits to the community

Provide a new method to connect agent to controller using Kafka besides existing methods such as JNLP or SSH Build Agents plugin.

Help to resolve the existing issues with the TCP protocol between controller and agent communication in Jenkins.

Help to resolve traffic prioritization and multi-agent communications issue in Jenkins.

Why Kafka?

When planning for this project, we want to use traditional message queue system such as ActiveMQ or RabbitMQ. However, after some discussion, we decided to have a try with Kafka with more suitable features with this project:

Kafka itself is not a queue like ActiveMQ or RabbitMQ, it is a distributed, replicated commit log. This helps to remove message delivery complexity we have in traditional queue system.

We need to support data streaming as a requirement, and Kafka is good at this aspect, which RabbitMQ is lack of.

Kafka is said to have a better scalability and good support from the development community.

Architecture Overview

The project consists of multiple components:

Kafka Client Library - new command transport implementation, producer and consumer client logic.

Remoting Kafka Plugin - plugin implementation with KafkaGlobalConfiguration, KafkaComputerLauncher and KafkaSecretManager.

Remoting Kafka Agent - A custom JAR agent with remoting JAR packaged together with a custom Engine implementation to setup a communication channel with Kafka. The agent is also packaged as a Docker image in DockerHub.

All the components are packaged together with Docker Compose.

The below diagram is the overview of the current architecture:

With this design, controller is not communicating with agent using direct TCP communication anymore, all the communication commands are transfered with Kafka.

Features

The project is now under the third coding phase and we have some features available in 1.0 release.

1. Kafka Global Configuration with support of credentials plugin to store secrets.

2. Launch agent with Kafka Launcher.

3. Launch agent from CLI using agent JAR with secret provided to ensure security.

4. Run jobs, pipeline using Kafka agent.

5. Kafka communication between controller and agent.

Remoting operations are being executed over Kafka. In the log you may see:

Command execution (SlaveInstallerFactoryImpl.isWindows())

Classloading (Classloader.fetch())

Log streaming (Pipe.chunk())

How to run demo

We have setup a ready-to-fly demo for this plugin. You can try to run a demo of the plugin by following this instruction.
Features in the demo:

Docker Compose starts preconfigured controller and agent instance, they connect automatically using Kafka launcher.

Kafka is secured and encrypted with SSL.

There few demo jobs in the instance so that a user can launch a job on the agent.

Kakfa Manager supported in localhost:9000 to support monitoring of Kafka cluster.

Phase 2 Presentation Slides

Phase 2 Presentation Video

Links

GitHub Repository

Wiki

Plugin Site

Project Info

Introduction Blogpost

Phase 1 Evaluation Slides

Phase 2 Evaluation Slides

Phase 1 Evaluation Video

Phase 2 Evaluation Video<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/pvtuan10/">Pham Vu Tuan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kafka">kafka</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/25/contributor-summit/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">25</div></div><h5 class="title">Join us at the Jenkins Contributor Summit San Francisco, Monday 17 September 2018</h5></div><p class="teaser">The Jenkins Contributor summit is where the current and future contributors of the Jenkins project get together.
This summit will be on Monday, September 17th 2018 in San Francisco, just before DevOps World | Jenkins World.
The summit brings together community members to learn, meet and help shape the future of Jenkins.
In the Jenkins commmunity we value all types and sizes of contributions and love to welcome new participants.
Register here.

Topics

There are plenty of exciting developments happening in the Jenkins community.
The summit will feature a &#x27;State of the Project&#x27; update including updates from the Jenkins officers.
We will also have updates on the &#x27;Big 5&#x27; projects in active development:

Jenkins Evergreen

Jenkins X

Configuration as Code

Jenkins Pipeline

Cloud Native Jenkins Architecture

Plus we will feature a Google Summer of Code update, and more!

Agenda

The agenda is shaping up well and here is the outline so far.

9:00am Kickoff &amp; Welcome with coffee/pastries

10:00am Project Updates

12:00pm Lunch

1.00pm BoF/Unconference

3.00pm Break

3.30pm Ignite Talks

5.00pm Wrap-up

6.00pm Contributor Dinner

The BoF (birds-of-a-feather) session will be an opportunity for in depth discussions, hacking or learning more about any of the big 5.
Bring your laptop, come prepared with questions and ideas, and be ready for some hacking too if you want.
Join in, hear the latest and get involved in any project during the BoF sessions.
If you want to share anything there will be an opportunity to do a 5-min ignite talk at the end.
Attending is free, and no DevOps World | Jenkins World ticket is needed, but RSVP if you are going to attend to help us plan.
See you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-world">jenkins-world</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/07/30/introducing-cloud-native-sig/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">30</div></div><h5 class="title">Introducing Jenkins Cloud Native SIG</h5></div><p class="teaser">On large-scale Jenkins instances controller disk and network I/O become bottlenecks in particular cases.
Build logging and artifact storage were one for the most intensive I/O consumers,
hence it would be great to somehow redirect them to an external storage.
Back in 2016 there were active discussions about such Pluggable Storage for Jenkins.
At that point we created several prototypes, but then other work took precedence.
There was still a high demand in Pluggable Storage for large-scale instances,
and these stories also become a major obstacle for cloud native Jenkins setups.

I am happy to say that the Pluggable Storage discussions are back online.
You may have seen changes in the Core for Artifact Storage
( JEP-202)
and a new Artifact Manager for S3 plugin.
We have also created a number of JEPs for External Logging
and created a new Cloud Native Special Interest Group (SIG)
to offer a venue for discussing changes and to keep them as open as possible.

Tomorrow Jesse Glick and I will be
presenting the current External Logging designs at the
Cloud Native SIG online meeting,
you can find more info about the meeting here.
I decided that it is a good time to write about the new SIG.
In this blogpost I will try to provide my vision of the SIG and its purpose.
I will also summarize the current status of the activities in the group.

What are Special Interest Groups?

If you follow the developer mailing list,
you may have seen the discussion about introducing SIGs
in the Jenkins project.
The SIG model has been proposed by
R. Tyler Croy,
and it largely follows the successful
Kubernetes SIG model.
The objective of these SIGs is to make the community more transparent to contributors
and to offer venues for specific discussions.
The idea of SIGs and how to create them is documented in
JEP-4.
JEP-4 is still in Draft state, but a few SIGs have been already created using that process:
Platform SIG, GSoC SIG and, finally,
Cloud Native SIG.

SIGs are a big opportunity to the Jenkins project,
offering a new way to onboard contributors who are interested only in particular aspects of Jenkins.
With SIGs they can subscribe to particular topics without
following the entire Developer mailing list which can become pretty buzzy nowadays.
It also offers company contributors a clear way how to join community and participate in specific areas.
This is great for larger projects which cannot be done by a single contributor.
Like JEPs, SIGs help focus and coordinate efforts.

And, back to major efforts…​
Lack of resources among core contributors was one of the reasons
why we did not deliver on Pluggable Storage stories back in 2016.
I believe that SIGs can help fix that in Jenkins,
making it easier to find groups with the same interests and
reach out to them in order to organize activity.
Regular meetings are also helpful to get such efforts moving.

Points above are the main reasons why I joined the Cloud Native SIG.
Similarly, that’s why I decided to create a Platform SIG
to deliver on major efforts like Java 10+ support in Jenkins.
I hope that more SIGs get created soon so that contributors could focus on areas of their interest.

Cloud Native SIG

In the original proposal Carlos Sanchez,
the Cloud Native SIG chair, has described the purpose of the SIG well.
There has been great progress this year in cloud-native-minded projects like Jenkins X and Jenkins Evergreen,
but the current Jenkins architecture does not offer particular
features which could be utilized there:
Pluggable Storage, High Availability, etc.
There are ways to achieve it using Jenkins plugins and some infrastructure tweaks,
but it is far from the out-of-the-box experience.
It complicates Jenkins management and slows down development of new cloud-native solutions for Jenkins.

So, what do I expect from the SIG?

Define roadmap towards Cloud-Native Jenkins architecture
which will help the project to stay relevant for Cloud Native installations

Provide a venue for discussion of critical Jenkins architecture changes

Act as a steering committee for Jenkins Enhancement Proposals in the area of
Cloud-Native solutions

Finally, coordinate efforts between contributors and get new
contributors onboard

What’s next in the SIG?

The SIG agenda is largely defined by the SIG participants.
If you are interested to discuss particular topics,
just propose them in the SIG mailing list.
As the current SIG page describes,
there are several areas defined as initial topics:
Artifact Storage,
Log Storage,
Configuration Storage

All these topics are related to the Pluggable Storage Area,
and the end goal for them is to ensure that all data is externalized
so that replication becomes possible.
In addition to the mentioned data types,
discussed at the Jenkins World 2016 summit,
we will need to externalize other data types:
Item and Run storage,
Fingerprints,
Test and coverage results,
etc.
There is some foundation work being done for that.
For example, Shenyu Zheng is working on a
Code Coverage API plugin
which would allow to unify the code coverage storage formats in Jenkins.

Once the Pluggable Storage stories are done the next steps are true High Availability, rolling or canary upgrades and zero downtime.
At that point other foundation stories like Remoting over Kafka
by Pham Vu Tuan
might be integrated into the Cloud Native architecture to make Jenkins more robust against outages within the cluster.
It will take some time to get to this state, but it can be done incrementally.

Let me briefly summarize current state of the 3 focuses listed in the Cloud Native SIG.

Artifact Storage

There are many existing plugins allowing to upload and download artifacts from external storage
(e.g. S3, Artifactory, Publish over SFTP, etc., etc.),
but there are no plugins which can do it transparently without using
new steps.
In many cases the artifacts also get uploaded through the controller,
and it increases load on the system.
It would be great if there was a layer which would allow storing artifacts externally
when using common steps like Archive Artifacts.

Artifact storage work was started this spring by Jesse Glick, Carlos Sanchez and
Ivan Fernandez Calvo
before the Cloud Native SIG was actually founded.
Current state:

JEP-202 &quot;External Artifact Storage&quot;
has been proposed in the Jenkins community.
This JEP defines API changes in the Jenkins core which are needed to
support External artifact managers

Jenkins Pipeline has been updated to support external artifact storages
for archive / unarchive and stash / unstash

New Artifact Manager for S3 plugin
reference implementation of the new API.
The plugin is available in main Jenkins update centers

A number of plugins has been updated in order to support
external artifact storage

The Artifact Manager API is available in Jenkins LTS starting from 2.121.1,
so it is possible to create new implementations using the provided API and
existing implementations.
This new feature is fully backward compatible with the default Filesystem-based storage,
but there are known issues for plugins explicitly relying on artifact locations in JENKINS_HOME
(you can find a list of such plugins
here).
It will take a while to get all plugins supported,
but the new API in the core should allow migrating plugins.

I hope we will revisit the External Artifact Storage at the SIG meetings at some point.
It would be a good opportunity to do a retrospective and to understand how to improve the process
in SIG.

Log storage

Log storage is a separate big story.
Back in 2016 External logging was one of the key Pluggable Storage stories we defined at the contributor summit.
We created an EPIC for the story ( JENKINS-38313)
and after that created a number of prototypes together with
Xing Yan and Jesse Glick.
One of these prototypes for Pipeline has recently been updated and published
here.

Jesse Glick and Carlos Sanchez
are returning to this story and plan to discuss it within the Cloud Native SIG.
There are a number of Jenkins Enhancement proposals which have been submitted recently:

jep:207[] -
External Build Logging support in the Jenkins Core

jep:210[] -
External log storage for Pipeline

jep:212[] -
External Logging API Plugin

jep:206[] -
Use UTF-8 for Pipeline build logs

In the linked documents you can find references to current reference implementations.
So far we have a working prototype for the new design.
There are still many bits to fix before the final release,
but the designs are ready for review and feedback.

This Tuesday (Jul 31) we are going to have a SIG meeting in order to present the current state and to discuss the proposed designs and JEPs.
The meeting will happen at 3PM UTC.
You can watch the broadcast using this link.
Participant link will be posted in the SIGs Gitter channel 10 minutes before the meeting.

Configuration storage

This is one of the future stories we would like to consider.
Although configurations are not big, externalizing them is a critical task
for getting highly-available or disposable Jenkins controllers.
There are many ways to store configurations in Jenkins,
but 95% of cases are covered by the XmlFile layer which
serializes objects to disk and reads them using the XStream library.
Externalizing these XmlFile s would be a great step forward.

There are several prototypes for externalizing configurations,
e.g. in DotCI.
There are also other implementations which could be upstreamed to the Jenkins core:

Alex Nordlund has recently proposed a
pull request
to Jenkins Core, which should make the XML Storage pluggable

James Strachan has implemented similar engine
for Kubernetes in the kubeify prototype

I also did some experiments with externalizing XML Storages back in 2016

The next steps for this story would be to aggregate implementations into a single JEP.
I have it in my queue, and I hope to write up a design once we get more clarity on the External logging stories.

Conclusions

Special Interest Groups are a new format for collaboration and disucssion in the Jenkins community.
Although we have had some work groups before (Infrastructure, Configuration-as-Code, etc.),
introduction of SIGs sets a new bar in terms of the project transparency and consistency.
Major architecture changes in Jenkins are needed to ensure its future in the new environments,
and SIGs will help to boost visibility and participation around these changes.

If you want to know more about the Cloud Native SIG,
all resources are listed on the SIG’s page on jenkins.io.
If you want to participate in the SIG’s activities, just do the following:

Subscribe to the mailing list

Join our Gitter channel

Join our public meetings

I am also working on organizing a face-to-face Cloud Native SIG meeting at the
Jenkins Contributor Summit,
which will happen on September 17 during
DevOps World | Jenkins World in San Francisco.
If you come to DevOps World | Jenkins World,
please feel free to join us at the contributor summit or to meet us at the community booth.
Together with Jesse and Carlos we are also going to present some bits of our work at the
A Cloud Native Jenkins talk.

Stay tuned for more updates and demos on the Cloud-Native Jenkins fronts!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/sig">sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native-sig">cloud-native-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/06/serverless-cicd-jenkins/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 6</div></div><h5 class="title">Building a Serverless CI/CD Pipeline with Jenkins</h5></div><p class="teaser">Everyone is talking about serverless.

As with any new hyped-technology the term &#x27;serverless&#x27; is often overloaded with different meanings.
Sometimes serverless is oversimplified to mean function-as-a-service(faas).
But there is more to it than that.
Also, not many people are talking about doing CI/CD with serverless,
even though where there is code there still in need of continuous integration and continuous delivery.
So I was excited to hear about this talk by
Anubhav Mishra on
Building a CI/CD Pipeline for Serverless Applications.

In the talk Anubhav proposes a new definition for serverless:

&quot;&quot;
Serverless is a technology pattern that provides services and concepts to minimize operational overhead that comes with managing servers.
It is a powerful abstraction when used can result in an increased focus on business value.
&quot;&quot;

The talk then goes on to demo Jenkins on AWS Fargate (a platform for running containers without managing servers or clusters).
The main focus is on increased elasticity/scaling.

The advantages of this approach are:

No nodes/servers to manage

Launch 10,000+ builds/containers in seconds

No cost for idle time

The real headline is the cost saving, which is 2 orders of magnitude better with serverless.
A cost comparison is done based on 1 vCPU &amp; 2GB memory:

With Jenkins on Fargate: 100 builds * 5 mins = $0.633/month

With Jenkins on EC2 Instances: ~50/month

This huge potential cost saving is one of the things that makes serverless incredibly compelling.
Not to mention you don’t have to think much upfront about scaling the system.

But there are drawbacks with this approach, noted as:

Cold starts - slower boot times for clients

Large container images (~1G)

No root access

Ephemeral storage (default)

This is an area where Jenkins can continue to evolve to make the most of serverless architectures.
I highly recommend you check out the
slides for yourself.
The best part is that, in the true spirit of open source, Anubvha shared the code
here.
So you can give it a try yourself and build your own serverless CI/CD pipeline with Jenkins.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/serverless">serverless</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/14/simple-pull-request-plugin-final-evaluation/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">14</div></div><h5 class="title">alpha-3 release Pipeline as YAML (Simple pull request plugin)</h5></div><p class="teaser">About me

I am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of
technology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my
college. I am passionate about automation.

Project Summary

This is a GSoC 2018 project.

This project aims to develop a pull request Job Plugin. Users should be able to
configure job type using YAML file placed in root directory of the
Git repository being the subject of the pull request. The plugin should interact with various
platforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.

Plugin detects the presence of certain types of reports at conventional locations,
and publish them automatically. If the reports are not present at their respective conventional
location, the location of the report can be configured in the YAML file.

My mentors are
Oleg Nenashev (Org Admin),
Martin d’Anjou,
Kristin Whetstone,
Jeff Knurek

Project Repository

Project repository

Code changes

All the pull requests made can be found here

List of major pull requests.

Phase 1

PR-5 : Git wrappers like clone, pull, checkout,
pullChangesOfPullrequest, merge, deleteBranch and merge added.

PR-6 : Yaml to Declarative Pipeline code generation.

Please see Phase 1 blog post

Phase 2

PR-11 : Implemented StepConfigurator
using Jenkins configuration as code plugin.

PR-19 : Unit tests created for agent and yaml to pipeline generation.

Please see Phase 2 blog post

Phase 3

PR-25 : Declarative pipeline code generator code
exported to extensions for extensibility and support of custom sections

Jenkinsfile.yaml example

Documentation of Jenkinsfile.yaml and yaml format can be found here

Tasks completed in Coding Phase 3

Add unit tests, JenkinsRule tests JENKINS-52495

Refactor snippet generator to extensions ( JENKINS-52491)

Plugin overview (Present in README.md)

Future tasks

Phase 3 Jira Epic

Release 1.0 ( JENKINS-52519)

Support the “when” Declarative Pipeline directive ( JENKINS-52520)

Nice2have: Support hierarchical report types ( JENKINS-52521)

Acceptance Test Harness tests JENKINS-52496

Automatic Workspace Cleanup when PR is closed ( JENKINS-51897)

Test Multi-Branch Pipeline features support:

Support for webhooks ( JENKINS-51941)

Check if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)

Finalize documentation ( JENKINS-52518)

Test the integration with various platforms Bitbucket, Gitlab, Github.

Phase 3 evaluation presentation video

Video: Link to video evaluation

Phase 3 evaluation presentation slides

Link to presentation slides

My GSoC experience

Student applications started on March 12 16:00 UTC and ended on March 27 16:00 UTC. Application period allowed me to explore
many new technology and platforms that are making peoples life easy.

Before starting of the application
period I did not know anything about Jenkins. I found Jenkins organisation on the GSoC organisations page
and came to know that I is a CI/CD platform that is used automate various things related to software development. I studied
about Jenkins online and went through the problem statements provided by some mentors.

I decided that to work on Simple Pull-Request Job Plugin project.
Then I wrote a draft proposal for this project and received many comments to refactor the proposal and enhance its quality from the mentors,
then finally I submitted my final proposal to Google.

I was able to complete most of the tasks decided in Phase 1 and 2. After Phase 2 I was not able to give time to the project because
of the placement season in the my college. I modified the code so that other plugin developers can contribute to it by Jenkins extensions.

All the mentors made themselves available for most of the weekly calls and provided many valuable suggestions during the
entire period of GSoC. Sometimes I was not able to communicate effectively. As communication is the key while working remotely, mentors
suggested to communicate more thorough gitter chat.

My overall experience of GSoC was good and all the mentors helped me as they can all times. This project allowed me to explore
Jenkins and the services offered by it. I am allowed to work on the project after GSoC ends (This is a good thing).

How to reach me

Email: gautamabhishek46@gmail.com

Gitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin

References

Project repository

Project page

Gitter chat

Bug Tracker

Demo Repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhishek_gautam/">Abhishek Gautam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/yaml">yaml</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/15/security-updates/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">15</div></div><h5 class="title">Jenkins 2.121.3 and 2.138 security updates</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.138 and 2.121.3, that fix multiple security vulnerabilities.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

Subscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/16/dwjw-2018-is-almost-here/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">16</div></div><h5 class="title">DevOps World | Jenkins World 2018 is Almost Here</h5></div><p class="teaser">DevOps World | Jenkins World 2018 in San Francisco is only a month away.
It is shaping up to be a great event including the Contributor Summit,
the &quot;Ask the Experts&quot; desk at the Jenkin booth, several days of training and certifications,
and tons of informative presentation and demos.

To give you a taste of what you’ll see this year at DevOps World | Jenkins World 2018,
we’ve lined up a series of guest blog posts by a number of this years speakers,
starting in the next week with posts from Tracy Miranda, Brent Laster, and Nicholas De Loof.
For now, let’s take a look at last year’s keynote from Kohsuke Kawaguchi.

Stay tuned!

Join the Jenkins project at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/17/code-coverage-api-plugin-1.0-release/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Code Coverage API plugin: 1.0 Release</h5></div><p class="teaser">I am happy to announce availability of Code Coverage API. These plugins have been recently released as 1.0, and they are now available in the Jenkins Update Center. In this blogpost I will introduce the features and project structure of Code Coverage API plugin.

My name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.

Overview

Code Coverage API plugin is one of GSoC 2018 Jenkins projects.

There are a lot of plugins which currently implement code coverage; however, they all use similar config, charts, and content. So it would be much better if we could have an API plugin which does the most repeated work for those plugins and offers a unified API which can be consumed by other plugins and external tools.

My mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.

Supported Coverage Formats

Embedded

JaCoCo

Other plugins as an Extension of Code Coverage API plugin

Cobertura ( Cobertura Plugin)

llvm-cov ( llvm-cov Plugin)

Features

Modernized coverage chart

Coverage trend

Source code navigation

Parallel pipeline support

Reports combining

REST API

Failed conditions and flexible threshold setting

Other small features

Modernized Coverage Chart

In the summary chart we can see the coverage summary of current coverage metric.

In the child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size. If we want to see coverage details of the child, we can click the child name to see more information.

Coverage Trend

We also support coverage trend to show coverage metrics changing between builds.

Source Code Navigation

You can enable source code navigation by specifying Source File Storing Level to save last build source files (enable source files navigation in current and last build) or save all build source files (enable source files navigation in all builds).

You can see source file with coverage information on File level coverage page.

Parallel Pipeline Support

We support parallel pipeline. You can call the Code Coverage API plugin in different branches like this:

node {
    parallel firstBranch: {
        publishCoverage adapters: [jacocoAdapter(&#x27;target/site/jacoco/jacoco.xml&#x27;)]
}, secondBranch: {
        publishCoverage adapters: [jacocoAdapter(&#x27;jacoco.xml&#x27;)]
    }
}

Reports Combining

You can add tag on publishCoverage and Code Coverage API plugin will combine reports have same tag

node {
    parallel firstBranch: {
        publishCoverage adapters: [jacocoAdapter(&#x27;target/site/jacoco/jacoco.xml&#x27;)], tag: ‘t’
}, secondBranch: {
        publishCoverage adapters: [jacocoAdapter(&#x27;jacoco.xml&#x27;)], tag: ‘t’
    }
}

REST API

We provide a REST API to retrieve coverage data:

Coverage result:…​/{buildNumber}/coverage/…​/result/api/\{json|xml\}

Trend result:…​/{buildNumber}/coverage/…​/trend/api/\{json|xml\}

Coverage result of last build:…​/{buildNumber}/coverage/…​/last/result/api/\{json|xml\}

Trend result of last build:…​/{buildNumber}/coverage/…​/last/trend/api/\{json|xml\}

Failed Conditions and Flexible Threshold Setting

You can set different failed conditions and threholds to control build result.

If the thresholds satisfy the failed conditions, it will fail the build.

Other Small Features

We also have other small features like auto detecting reports, coverage filters, etc. You can find more information about these features in the plugin documentation.

Architecture

This API plugin will mainly do these things:

Find coverage reports according to the user’s config.

Use adapters to convert reports into the our standard format.

Parse standard format reports, and aggregate them.

Show parsed result in a chart.

So, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing - convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.

The below diagram show the architecture of Code Coverage API plugin

Implementing a New Coverage Plugin

We can implement a coverage plugin by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement JaCoCo simple like this:

public final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {

    @DataBoundConstructor
    public JacocoReportAdapter(String path) {
        super(path);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public String getXSL() {
        return &quot;jacoco-to-standard.xsl&quot;;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public String getXSD() {
        return null;
    }

    @Symbol(&quot;jacoco&quot;)
    @Extension
    public static final class JacocoReportAdapterDescriptor extends JavaCoverageReportAdapterDescriptor {

        public JacocoReportAdapterDescriptor() {
            super(JacocoReportAdapter.class);
        }

        @NonNull
        @Override
        public String getDisplayName() {
            return Messages.JacocoReportAdapter_displayName();
        }
    }
}

All we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our standard format. There are also other extension points which are under development.

If you want implement a new coverage format that we did not provide abstract layer, you need to register `CoverageElement`s and implement an simple parser. See llvm-cov Plugin to get more details.

Future Tasks

Support more coverage tools ( JENKINS-52467, JENKINS-52469 and etc.)

Make the UI extensible ( JENKINS-51738)

Improve performance ( JENKINS-52982)

Phase 3 Presentation Slides

Phase 3 Presentation Video

Links

JIRA Component

Project Page

Project Repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/shenyu_zheng/">Shenyu Zheng</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/17/speaker-blog-brent-laster/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Using the Docker Global Variable in Your Jenkins Pipeline</h5></div><p class="teaser">More and more today, continuous delivery (CD) pipelines are making use of containers.
In many implementations, the primary workflow/orchestration tool for CD pipelines is Jenkins.
And the primary container orchestration tool is Docker.
Together these two applications provide a powerful, yet simple to understand and use, model for leveraging containers in your CD pipeline.

When creating a pipeline script in Jenkins, there are multiple ways to incorporate Docker into your CD pipeline.
They include:

Manually running a predefined Docker image as a separate Jenkins agent

Automatically provisioning a Docker image, when needed, as a part of a “cloud” configuration

Referencing a “docker” global variable that can be invoked via the Jenkins DSL

Calling the Docker executable directly via a shell call in the Jenkins DSL

For this article, we’ll focus on the third item in this list given that it provides the most flexibility and convenience for Docker use in the pipeline.
More details on the other three can be found in the upcoming “Continuous Delivery and Containerization” workshop at Jenkins World/DevOps World 2018.

First, we’ll provide some background on a couple of terms for those who may not be familiar with Jenkins 2.
If you already are familiar with it, feel free to skip ahead to the Global Variables section.

Background

When we talk about Jenkins here, we’re referring to “Jenkins 2” - a name we use to generally refer to the 2.0 and beyond versions of Jenkins.
Jenkins 2 offers a powerful evolution of Jenkins over prior versions.
In particular, it provides full integration for “pipeline-as-code” (PAC).
PAC refers to being able to write your pipeline in a scripting language, much like source code for any program.
The code you write becomes the program that defines your pipeline.
It is also the code that gets executed when your pipeline is initiated.
Listing 1 shows a simple example pipeline.
Notice that this is very different from the classic way of creating pipelines in Jenkins.
Here you are writing code - rather than the more traditional approaches, such as filling in web forms to configure a Freestyle job.

// Scripted Pipeline //
node(&#x27;worker&#x27;) {
    stage(&#x27;Source&#x27;) { // Get code
        // Get code from our git repository
        git &#x27;git@diyvb2:/home/git/repositories/workshop.git&#x27;
    }
    stage(&#x27;Compile&#x27;) { // Compile and do unit testing
        // Run gradle to execute compile and unit testing
        sh &quot;gradle clean compileJava test&quot;
    }
}
// Declarative //

Listing 1: Example Jenkins 2 pipeline

The language that we write the Jenkins pipeline code in is a Domain-Specific Language (DSL).
You can think of it as the “programming language” for Jenkins pipelines.
There are two variants of it.
The style we saw in figure 1 is called “scripted syntax”.
It is a mixture of elements from the Groovy programming language and special Jenkins “steps”.
The Jenkins steps are provided by the plugins that are installed in the current system.
A built-in tool called the Snippet Generator provides a wizard interface to allow users to pick the step and options they want.
Then, the user can click on a button to have Jenkins automatically generate the correct DSL code in the large text box (figure 1).
The DSL code can be copied from there and pasted into the pipeline script.

Figure 1. The Snippet Generator

A second type of syntax is called “declarative syntax.”  We won’t go into detail on it here.
But it is a much more structured syntax that focuses on having users declare what they want in a pipeline, rather than writing the logic to make it happen.

Global Variables

In addition to the steps that are provided by plugins, additional functionality for pipelines can be provided by global variables.
The simplest way to think of a global variable is as an object with methods that can be invoked on it.
Several of these are built in to Jenkins, such as the Docker global variable.
Others can be created by users as part of the structure of a shared source code repository called a “shared pipeline library.”

To get a list of the global variables that are currently available to your Jenkins instance, you can go to the Snippet Generator screen.
Immediately below the box for the generated pipeline script is a section titled Global Variables.
There, within the small print, is a link to get to the actual section (figure 2).

Figure 2. Link to Global Variables Reference section.

Clicking on that link takes us to a list of currently available Global Variables.
If you have the Docker Pipeline Plugin installed, you will see one at the top for Docker. (Figure 3).

Figure 3. Docker global variable specifics.

Broadly, the docker global variable includes methods that can be applied to the Docker application, Docker images, and Docker containers.

We’ll focus first on a couple of the Docker image methods as shown in figure 4.

Figure 4. Key methods for getting a Docker image.

There are multiple ways you can use these methods to create a new image.
Listing 2 shows a basic example of assigning and pulling an image using the image method.

myImage = docker.image(&quot;bclaster/jenkins-node:1.0&quot;)
myImage.pull()

Listing 2: Assigning a image to a variable and pulling it down.

This can also be done in a single statement as shown in listing 3.

docker.image(&quot;bclaster/jenkins-node:1.0&quot;).pull()

Listing 3: Shorthand version of previous call.

You can also download a Dockerfile and build an image based on it.(See listing 4.)

node() {
    def myImg
    stage (&quot;Build image&quot;) {
        // download the dockerfile to build from
        git &#x27;git@diyvb:repos/dockerResources.git&#x27;

        // build our docker image
        myImg = docker.build &#x27;my-image:snapshot&#x27;
    }
}

Listing 4: Pipeline code to download a Dockerfile and build an image from it.

Figure 5 shows the actual output from running that “Build image” stage.
Note that the docker.build step was translated into an actual Docker build command.

Figure 5. Actual Docker output from running the download and build

The Inside Command

Another powerful method available for the Docker global variable is the inside method.
When executed, this method will do the following:

Get an agent and a workspace to execute on

If the Docker image is not already present, pull it down

Start the container with that image

Mount the workspace from Jenkins

Execute the build steps

Mounting the workspace means that the Jenkins workspace will appear as a volume inside the container.
And it will have the same file path.
So, things running in the container will have direct access to the same location.
However, this can only be done if the container is running on the same underlying system - such that it can directly access the path.

In terms of executing the build steps, the inside method acts as a scoping method.
This means that the environment it sets up is in effect for any statement that happens within its scope (within the block under it bounded by {}).
The practical application here is that any pipeline “sh” steps (a call to the shell to execute something) are automatically run in the container.
Behind the scenes, this is done by wrapping the calls with “docker exec”.

When executed, the calls with the global variable are translated (by Jenkins) into actual Docker call invocations.
Listing 5 shows an example of using this in a script, along with the output from the first invocation of the “inside” method.
You can see in the output the docker commands that are generated from the inside method call.

stage (&quot;Get Source&quot;) {
        // run a command to get the source code download
        myImg.inside(&#x27;-v /home/git/repos:/home/git/repos&#x27;) {
            sh &quot;rm -rf gradle-greetings&quot;
            sh &quot;git clone --branch test /home/git/repos/gradle-greetings.git&quot;
        }
    }
    stage (&quot;Run Build&quot;) {
        myImg.inside() {
            sh &quot;cd gradle-greetings &amp;&amp; gradle -g /tmp clean build -x test&quot;
        }
    }

Listing 5: Example inside method usage.

Figure 6. Example inside method Docker command output.

Once completed, the inside step will stop the container,
get rid of the storage, and create a record that this image was used for the build.
That record facilitates image traceability, updates, etc.

As you can see, the combination of using the Docker “global variable” and its “inside” method provide a simple and powerful way to spin up and work with containers in your pipeline.
In addition, since you are not having to make the direct Docker calls, you can invoke steps like sh within the scope of the inside method, and have them executed by Docker transparently.

As we mentioned, this is only one of several ways you can interact with Docker in your pipeline code.
To learn about the other methods and get hands-on practice, join me at DevOps World/Jenkins World in San Francisco or Nice for the workshop
&quot; Creating a Deployment Pipeline with Jenkins 2&quot;.
Hope to see you there!

Join the Jenkins project at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/brentlaster/">Brent Laster</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/21/contributor-summit-nice/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">21</div></div><h5 class="title">Join us at the Jenkins Contributor Summit Nice, Tuesday 23 October 2018</h5></div><p class="teaser">The Jenkins Contributor summit is where the current and future contributors of the Jenkins project get together.
This summit will be on Tuesday, October 23rd 2018 in Nice, France just before Jenkins World.
The summit brings together community members to learn, meet and help shape the future of Jenkins.
In the Jenkins commmunity we value all types and sizes of contributions and love to welcome new participants.
It is free to join, just register here.

Topics

There are plenty of exciting developments happening in the Jenkins community.
The summit will feature a &#x27;State of the Project&#x27; update including updates from the Jenkins officers.
We will also have updates on the &#x27;Big 5&#x27; projects in active development:

Jenkins Evergreen

Jenkins X

Configuration as Code

Jenkins Pipeline

Cloud Native Jenkins

Plus we will feature a Google Summer of Code update, Special Interest Group updates and more!

Agenda

The agenda is shaping up well and here is the outline so far.

9:00am Kickoff &amp; Welcome with coffee/pastries

10:00am Project Updates

12:00pm Lunch

1.00pm BoF/Unconference

3.00pm Break

3.30pm Ignite Talks

5.00pm Wrap-up

6.00pm Contributor Dinner

The BoF (birds-of-a-feather) session will be an opportunity for in depth discussions, hacking or learning more about any of the big 5.
Bring your laptop, come prepared with questions and ideas, and be ready for some hacking too if you want.
Join in, hear the latest and get involved in any project during the BoF sessions.
If you want to share anything there will be an opportunity to do a 5-min ignite talk at the end.
Attending is free, and no DevOps World | Jenkins World ticket is needed, but RSVP if you are going to attend to help us plan.
See you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-world">jenkins-world</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/23/speaker-blog-casc-part-1/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">23</div></div><h5 class="title">Jenkins Configuration-as-Code: Look ma, no hands</h5></div><p class="teaser">This blog post is part 1 of a Configuration-as-Code series

Jenkins is highly flexible and is today the de facto standard for implementing CI/CD, with an active community to maintain plugins for almost any combination of tools and use-cases.
But flexibility has a cost: in addition to Jenkins core, many plugins require some system-level configuration to be set so they can do their job.

In some circumstances, &quot;Jenkins Administrator&quot; is a full time position.
One person is responsible for both maintaining the infrastructure, and also pampering a huge Jenkins controller with hundred installed plugins and thousands hosted jobs.
Maintaining up-to-date plugin versions is a challenge and failover is a nightmare.

This is like years ago when system administrators had to manage dedicated machines per service.
In 2018, everything is managed as code using infrastructure automation tools and virtualization.
Need a fresh new application server as staging environment for your application? Just deploy a Docker container.
Infrastructure is missing resources? Apply a Terraform recipe to allocate more on your favourite Cloud.

What about the Jenkins administrator role in this context? Should they still spend hours in the web UI, clicking checkboxes on web forms? Maybe they already adopted some automation, relying on Groovy script voodoo, or some home-made XML templating?

Early this year we announced the first alpha release of “Jenkins Configuration-as-Code” (JCasC), a fresh new approach to Jenkins configuration management, based on YAML configuration files and automatic model discovery.
“JCasC” has been promoted as a
top-level Jenkins project, and the corresponding
Jenkins Enhancement Proposal has been accepted.

What can JCasC do for our Jenkins Administrator?

JCasC allows us to apply a set of YAML files on our Jenkins controller at startup or on-demand via the web UI.
Those configuration files are very concise and human readable compared to verbose XML files the Jenkins uses to actually store configuration.
The files also have user-friendly naming conventions making it easy for administrators to configure all Jenkins components.

Here’s an example:

jenkins:
 systemMessage: &quot;Jenkins managed by Configuration as Code&quot;

 securityRealm:
   ldap:
     configurations:
       - server: ldap.acme.com
         rootDN: dc=acme,dc=fr
         managerPasswordSecret: ${LDAP_PASSWORD}
     cache:
       size: 100
       ttl: 10
     userIdStrategy: CaseInsensitive
     groupIdStrategy: CaseSensitive

As you can see, you don’t need long explanation to understand how this YAML file will setup your Jenkins controller.

Benefits

The most immediate benefit of JCasC is reproducibility.
An administrator can now bootstrap a new Jenkins controller with the exact same configuration with a trivial setup.
This allows them to create a test instance and check the impact of plugin upgrades in a sandboxed environment.
This also lets them be more confident with failover and disaster recovery scenarios.

Further benefits come when administrators start managing their Jenkins’ YAML configuration files in source control, like they do with Terraform configuration.
Doing so gives them auditing and reversibility of their Jenkins controller configuration.
Theycan establish a sane configuration change workflow that runs a test Jenkins instance and ensures configuration is healthy before actually applying any change to their production Jenkins controller.

Last but not least, with ability to quickly setup Jenkins controllers and control them from a set of shared YAML configuration files, administrators can now offer per-team Jenkins instances, with more flexibility on installed plugins.
A controller becomes more or less a transient piece of infrastructure for your team, as long as they also manage build definition with Jenkinsfiles.

With Configuration-as-Code we can stop having to treat our Jenkins controller like a pet we need to pamper, and start managing Jenkins controllers as cattle you can replace without effort nor impacts.
Welcome in the “as-code” world.

Figure 1. They are still cute though, right?

Ok, so what’s next?

You can read more about the Jenkins Configuration-as-Code plugin on the project’s
github repository.
To chat with the community and contributors join our
gitter channel,
or come see us in person at
link: Jenkins World to discuss the JCasC project and its future!

Also don’t miss next post from the Configuration-as-Code series, where we’ll look at how JCasC works with sensitive data like passwords and other credentials.

Come meet the Configuration as Code contributors, Nicolas de Loof and Ewelina Wilkosz at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ndeloof/">Nicolas De Loof</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/configuration-as-code">configuration-as-code</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/29/day-of-jenkins-and-other-chances-to-meet-jcasc/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">29</div></div><h5 class="title">Day of Jenkins, and other chances to meet JCasC</h5></div><p class="teaser">The Jenkins Configuration as Code plugin is reaching a stage when it is almost ready to be used in a production environment.
As a matter of fact, I know some living-on-the-edge users are already doing that.
The first release candidates are out and the official 1.0 is just around the corner.

I’d like to use this chance to invite you to meet us and contribute to the plugin.
There will be plenty of opportunities this autumn.

Jenkins Configuration as Code (also called &quot;JCasC&quot;) is a Jenkins plugin that allows you to store and maintain all your Jenkins configuration in yaml file.
It’s like Pipeline or Job DSL but for managing Jenkins.

In one of my blogposts,
Jenkins Configuration as Code - Automating an automation server,
I provide a longer explanation of the plugin, and answer questions like
“why did we decided to develop it?” and “why you may want to use it?”.
I recommend you to read that one if you’re not familiar with the project yet.

The plugin has been presented at a number of meetups - by me but also other contributors.
This is the first open source project that I’ve actively participated in and I’m quite shocked - positively - to see how many people decided to join the effort and actively develop the plugin with us.
Now it’s time to take it to the bigger stage and broader audience.
So together with Nicolas de Loof I’m gonna present the plugin at DevOps World | Jenkins World in San Francisco (19th of September)  and in Nice (24th of October) - yes, Jenkins World is coming to Europe.

But that’s not all!
Praqma - the company I work for -
has organised a number of “Day of Jenkins” events around Scandinavia in past years.
This October they have decided to bring the events back with a theme: Day of Jenkins 2018 is
Day of Jenkins [as code] .
It’s a two track one day event with presentations and hands-on sessions for users and a hackathon for contributors - in that specific case Configuration as Code Plugin’s contributors.

Detailed agenda is available on the
event page -
Jenkins X, Jenkins Evergreen, Jenkins Configuration as Code and more waiting for you!

I really can’t wait to hear what Kohsuke has to say and to introduce you to the plugin during the hands-on session I’ll run.

Hope to see you at least at one of those events!

Come meet the Configuration as Code contributors, Nicolas de Loof and Ewelina Wilkosz at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ewelinawilkosz/">Ewelina Wilkosz</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jcasc">jcasc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/configuration as code">configuration as code</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/30/speaker-blog-kubernetes-plugin/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">30</div></div><h5 class="title">Effectively using Kubernetes plugin with Jenkins</h5></div><p class="teaser">This is a guest blog by Niklas Tanskanen, consultant at
Eficode.

Kubernetes, the container orchestration platform is rapidly becoming popular. There are more and more workloads that you can run on top of Kubernetes. It’s becoming an enabling layer of your Hyper-convergenced infrastructure.

If you set up Kubernetes as a Cloud provider in Jenkins, you’ll get a very powerful couple for running your workloads.
To do that, you can simply install
Kubernetes plugin.
Kubernetes is able to run your Jenkins workloads as long as they are run in container.
And containers are an awesome way if your workload is a build, because you can pack all your application and OS dependencies in a container and then run it anywhere!

Let’s imagine that you have been running a Kubernetes cluster setup in your organisation for a while now.
First it was all about proof of concept but now its becoming more popular within your developers and you have to think about scaling and orchestration.
Resource quotas are a part of that and every responsible operator should set those up both in both development and production clusters.
Otherwise people will be lazy and just reserve all the resources of your cluster without actually using those resources for anything.
By introducing quotas into your cluster, you can control how many resources should each namespace have.

Quotas are a mature feature of Kubernetes already.
You have the possibility to create very fine grained quotas for different hardware resources, whenever it’s fast disk, GPUs or CPU time.
You can also specify multiple scopes of quota per one namespace.
For example, you can have a quota for workloads that are to be run to the infinity like web servers or databases.
Or have quota for workloads that are short lived like builds or test automation runs.

Table 1. Scopes

Scope
Description

Terminating
Match pods where.spec.activeDeadlineSeconds &gt;= 0

NotTerminating
Match pods where.spec.activeDeadlineSeconds is nil

BestEffort
Match pods that have best effort quality of service.

NotBestEffort
Match pods that do not have best effort quality of service.

Different scopes of Kubernetes quota

Since Jenkins is all about running short workloads, you should aim for the Terminating scope of quota.
But how do you specify workloads in Jenkins so that correct scope is used?

If you were to do this in Kubernetes, you have to specify.spec.activeDeadlineSeconds.
The same field can also be specified by the Kubernetes plugin when you are specifying a Pod Template.

Figure 1. Specifying.spec.activeDeadlineSeconds in the Kubernetes plugin

Same configuration is available in the Jenkinsfile as well if you don’t like static configurations.

podTemplate(label: &#x27;maven&#x27;, activeDeadlineSeconds: 180, containers: [
    containerTemplate(name: &#x27;maven&#x27;, image: &#x27;maven:3.5.4-jdk-10-slim&#x27;)
  ]) {
  // maven magic
}

This was just a small sample of features of the Kubernetes plugin in Jenkins. For more, be sure to check out our
talk where we share more of how you can utilise Kubernetes with Jenkins!

Come see Niklas Tanskanen and many other Jenkins experts and contributors at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tanskann/">Niklas Tanskanen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/08/31/shifting-gears/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">Jenkins: Shifting Gears</h5></div><p class="teaser">Kohsuke here. This is a message for my fellow Jenkins developers.

Jenkins has been on an amazing run, but I believe we are trapped in a local optimum, and losing appeal to people who fall outside of our traditional sweet spot.
We need to take on new efforts to solve this. One is “cloud native Jenkins” that creates a flavor of Jenkins that runs well on Kubernetes.
The other is “gear shift”, where we take an evolutionary line from the current Jenkins 2, but with breaking changes in order to gain higher development speed.

I say it’s time we tackle these problems head on. I’ve been talking to various folks, and I think we need to take on two initiatives.
One is what I call &quot;Cloud Native Jenkins,&quot; and the other is to insert a jolt in Jenkins.

Some of you have already seen the presentation I posted on the Jenkins YouTube channel.  In this post, I’ll expand on that with some additional details.

Jenkins: Shifting Gears Presentation ( Slides)

Come hear more in Kohsuke’s keynote at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.

Our Amazing Success

Our project has been an amazing success over the past 10+ years, thanks to you all. What started as my hobby project became a huge community that boasts thousands of contributors and millions of users.
When I think about what enabled this amazing journey, I can think of several magic sauces:

Extensible:
the ability to take the system, or a portion of the system, then build on top of it to achieve what you need, without anyone else’s permission.
Here, I’m not talking about the specific technical mechanism of Guice, extension point, etc, but rather I’m talking more broadly about the governance, culture, distribution mechanism, and so on.

General purpose:
At the base level, Jenkins can be used for any kind of automation around the area of software development.
This matched the reality of the software engineering world well.
Combined with extensibility, this general purpose system that is Jenkins can specialize into any domain, much like Linux and JetBrains IDEs.

Community:
Together we created a community where different people push envelopes in different directions and share the fruits with others.
This meant everyone can benefit from somebody else’s work, and great ideas and best practices spread more quickly.

Our Challenges

The way we set up our community meant that collectively we were able to work toward solving certain kinds of problems locally and organically, such as Android application development, new UX, more expressive pipeline description language, …​

But at the same time, the incremental, autonomous nature of our community made us demonstrably unable to solve certain kinds of problems.
And after 10+ years, these unsolved problems are getting more pronounced, and they are taking a toll — segments of users correctly feel that the community doesn’t get them, because we have shown an inability to address some of their greatest difficulties in using Jenkins.
And I know some of those problems, such as service instability, matter to all of us.

In a way, we are stuck in a local optimum, and that is a dangerous place to be when there is growing competition from all sides.
So we must solve these problems to ensure our continued relevance and popularity in the space.

Solving those problems starts with correctly understanding them, so let’s look at those.

Service Instability

CI/CD service was once a novelty and a nice-to-have.
Today, it is very much a mission critical service, in no small part because of us!
Increasingly, people are running bigger and bigger workloads, loading up more and more plugins, and expect higher and higher availability.

Admins today are unable to meet that heightened expectation using Jenkins easily enough.
A Jenkins instance, especially a large one, requires too much overhead just to keep it running.
It’s not unheard of that somebody restarts Jenkins every day.

Admins expect errors to be contained and not impact the entire service.
They expect Jenkins to defend itself better from issues such as pipeline execution problems, run-away processes, over resource consumption so that they don’t have to constantly babysit the service.

Every restart implies degraded service for the software delivery teams where they have to wait longer for their builds to start or complete.

Brittle Configuration

Every Jenkins admin must have been burnt at least once in the past by making changes that have caused unintended side effects.
By “changes,” I’m talking about installing/upgrading plugins, tweaking job settings, etc.

As a result, too many admins today aren’t confident that they can make changes safely.
They fear that their changes might cause issues for their software delivery teams, that those teams will notice regressions before they do, and that they may not be able to back out somes changes easily.
It feels like touching a Jenga tower for them, even when a change is small.

Upgrading Jenkins and plugins is an important sub case of this, where admins often do not have understanding of the impact.
This decreases the willingness to upgrade, which in turn makes it difficult for the project to move forward more rapidly, and instead we get trapped with the long tail of compatibility burden.

Assembly Required

I’ve often described Jenkins as a bucket full of LEGO blocks — you can build any car you want, but everyone first has to assemble their own car in order to drive one.

As CI/CD has gone mainstream, this is no longer OK.
People want something that works out of the box, something that gets people to productivity within 5 clicks in 5 minutes.
Too many choices are confusing users, and we are not helping them toward “the lit path.”
Everyone feels uncertain if they are doing the right thing, contributors are spread thin, and the whole thing feels a bit like a Frankenstein.

This is yet another problem we can’t solve by “writing more plugins.”

Reduced Development Velocity

This one is a little different from others that our users face, but nonetheless a very important one, because it impacts our ability to expand and sustain the developer community, and influences how fast we can solve challenges that our users face.

Some of these problems are not structural and rather just a matter of doing it (for example, Java 11 upgrade), but there are some problems here that are structural.

I think the following ones are the key ones:

As a contributor, a change that spans across multiple plugins is difficult.
Tooling gets in the way, users might not always upgrade a group of changes together, reviewing changes is hard.

As a contributor, the tests that we have do not give me enough confidence to ship code.
Not enough of them run automatically, coverage is shallow, and there just isn’t anything like production workload of real users/customers.

These core problems create other downstream problems, for example:

As a non-regular contributor, what I think of as a small and reasonable change takes forever and a 100 comments going back &amp; forth to get in. I get discouraged from ever doing it again.

As a regular contributor, I feel people are throwing crap over the wall, and if they cause problems after a release, I’m on the hook to clean up that mess.

As a user, I get a half-baked change that wreaks havoc, which results in loss of their confidence to Jenkins, an even slower pace of change, etc. This is a vicious cycle as it makes us even more conservative, and slow down the development velocity.

Path Forward

In the past, my frustration and regret is that we couldn’t take on an effort of this magnitude.
But that is NO MORE!
As CTO of CloudBees, I’m excited that these challenges are important enough for CloudBees now that we want to solve these efforts within the Jenkins project.

I’ve been talking to many of you, and there are a number of existing efforts going on that touch this space already.
From there, the vision emerged is that we organize around two key efforts:

Cloud Native Jenkins: a general purpose CI/CD engine that runs on Kubernetes, and embraces a fundamentally different architecture and extensibility mechanism.

Jolt in Jenkins: continue the incremental trajectory of Jenkins 2 today, but with renegotiated “contract” with users to gain what we really need, such as faster pace of development and better stability.

Cloud Native Jenkins

In order to solve these problems that we can’t solve incrementally,
I’m proposing the “Cloud Native Jenkins” sub-project in the context of the
Cloud Native SIG
with Carlos, who is the leader of this SIG.

We don’t have all the answers, that’s something we’ll discuss and figure out collectively, but based on numerous conversations with various folks, I think there are many clear pieces of puzzles.

Kubernetes as the Runtime

Just like Java was the winning server application platform in the early 2000s, today, Kubernetes is the dominant, winning platform.
Cloud Native Jenkins should embrace the paradigm this new platform encourages. For example,

Serverless / function-as-a-service build execution (ala
Jenkinsfile runner)
that are isolated.

Various pieces of functionalities deployed as separate microservices.

Services interacting through
Kubernetes CRDs
in order to promote better reuse and composability.

These are the design principles that enable highly desirable properties like infinite scalability, pay-as-you-go cost model, immutability, zero down time operability, etc.

New Extensibility Mechanism

We need to introduce a new mechanism of extensibility in order to retain the magic sauces, and continue our incredible ecosystem.

For example, microservice or container-based extensibility avoids the service instability problem (ala
Knative builder
and the
userspace-scm work.)
Pipeline shared libraries is another example that concretely shows how extensibility mechanism can go beyond plugin, though it hasn’t fully flourished as one just yet.

Data on Cloud Managed Data Services

The long-term data storage must be moved from the file system to data services backed by cloud managed services, in order to achieve high availability and horizontal scalability, without burdening admins with additional operational responsibilities.

Configuration as Code

Jenkins Configuration as Code
has been incredibly well received, in part because it helps to solve some of the brittle configuration problems.
In Cloud Native Jenkins, JCasC must play a more central role, which in turn also helps us reduce the surface area for Blue Ocean to cover by eliminating many configuration screens.

Evergreen

Jenkins Evergreen
is another well received effort that’s already underway, which aims to solve the brittleness problem and developer velocity problem. This is a key piece of the puzzle that allows us to move faster without throwing users under the bus.

Secure by Default Design

Over the past years, we’ve learned that several different areas of Jenkins codebase, such as Remoting, are inherently prone to security vulnerabilities because of their design. Cloud Native Jenkins must address those problems by flipping those to “secure by design.”

Following Footsteps of Jenkins X

Jenkins X
has been pioneering the use of Jenkins on Kubernetes for a while now, and it has been very well received, too.
So naturally, part of the aim of Cloud Native Jenkins is to grow and morph Jenkins into a shape that really works well for Jenkins X.
Cloud Native Jenkins will be the general purpose CI/CD engine that runs on Kubernetes, which Jenkins X uses to create an opinionated CD experience for developing cloud native apps.

All The Same Good Things, with New Foundation

And then on top of these foundations, we need to rebuild or transplant all the good things that people love about Jenkins today, and all the good things people expect, such as:

Great “batteries included” onboarding experience for new users, where we are present in all the marketplaces, 5 clicks to get going and easy integration with key services.

Modern lovable UX in the direction of front-end web apps that Blue Ocean pioneered.

General purpose software that is useful for all sorts of software development.

Cloud Native Jenkins MVP

As I wrote, a number of good efforts are already ongoing today. Thus in order to get this effort off the ground, I believe the first MVP that we aim toward is pretty clear, which is to build a function-as-a-service style Jenkins build engine  that can be used underneath Jenkins X.

Cloud Native Jenkins MVP combines the spirits of Jenkins Pipeline, Jenkins Evergreen, Jenkinsfile Runner, and Jenkins Configuration as Code.
It consists of:

Webhook receiver:
a service that receives webhooks from GitHub and triggers a build engine.

Build Engine:
take Jenkinsfile Runner and evolve it so that it can run as a “function” that carries out a pipeline execution, with some CasC sprinkled together in order to control Jenkins configuration and plugins  used.
This way, Jenkinsfile works as-is for the most part.

Continuously delivered through Evergreen:
It allows us to solve the combinatorial version explosion problem, allow us to develop changes that span multiple plugins faster, and develop changes more confidently.
Of all the projects out there, ours should be the community that believes in the value of Continuous Delivery and Evergreen is how we bring continuous delivery to the development of Cloud Native Jenkins itself.

This solves some of the key challenges listed above that are really hard to achieve today, so it’s already incredibly useful.

The catch is that this MVP has no GUI. There’s no Blue Ocean UI to look at. No parsing of test reports, no build history. It uses no persistent volumes, it keeps no record of builds. The only thing permanent at the end of a build is whatever data is pushed out from Jenkins Pipeline, such as images pushed to a Docker registry, email notifications, and GitHub commit status updates.  Load of other features in Jenkins will not be available here.

This is not that far from how some sophisticated users are deploying Jenkins today. All in all, I think this is the right trade off for the first MVP. As you can see, we have most of the pieces already.

From here, the build engine will get continuously more polished and more cloud native, other services will get added to regain features that were  lost, new extensibility will get introduced to reduce the role of current in-VM plugins, and so on.

Jolt in Jenkins

Cloud Native Jenkins is a major effort and in particular initially it’s not usable for everyone; it only targets a subset of Jenkins functionalities, and it requires a platform whose adoption is still limited today.
So in parallel, we need to continue the incremental evolution of Jenkins 2, but in an accelerated speed. Said differently, we need to continue to serve the majority of production workload on Jenkins 2 today, but we are willing to break some stuff to gain what we really need, such as faster pace of development and better stability, in ways that were previously not possible. This requires us injecting a jolt in Jenkins.

Release Model Change

The kind of jolts that we need will almost certainly means we need to renegotiate the expectation around new releases with our users.
My inspiration source is what happened to the development of Java SE. It changed the release model and started moving faster, by shedding off more pieces faster, in ways that they haven’t done before.
Again, Jenkins Evergreen is the key piece that achieves this without throwing users under a bus, for the reasons I described in the Cloud Native MVP above.

Compatibility

This jolt is aimed to put us on a different footing, one where our current “forever compatibility” expectation does not hold. If that requires us to use a new major version number, such as Jenkins 3, or new major version number every N months, I’m open to that.

Of course, whatever move we do has to make sense to users. The accelerated pace of value delivery needs to justify any inconvenience we put on users, such as migration, breaking changes, and so on.

In practice, what that means is that we need to be largely compatible. We have to protect users’ investment into their existing job definitions as much as possible. We continue to run freestyle jobs, etc…​

Ingredients

Other proposals CloudBees is putting forward with the intent to staff the effort are:

Configuration as Code: accelerate that and make it a more central  part of Jenkins.

Developer experience improvements through buildpack style auto-detection of project types.

Continued evolution of Jenkins Pipeline

There’s an effort going on to remove CPS execution of Pipeline and isolate any failures during pipeline execution.

Continue to evolve Jenkins Pipeline toward the sweet spot that works well with the Cloud Native Jenkins effort.

Continued tactical bug-by-bug improvements of Pipeline.

Evergreen: I already talked about this above.

Plugin spring cleaning: let’s actively guide users more toward the sweet spot of Jenkins and reduce our feature surface area, so that we can focus our contributors’ effort to important parts of Jenkins. I expect this to be a combination of governance and technical efforts.

Table stakes service integration: let’s look at what kind of tablestake tool/service integrations today’s user need, and
see if we are meeting/exceeding the competition.
Where we fall short, let’s add/reimplement what are needed.

UI Effort

The Web UI will be likely done differently in Cloud Native Jenkins, as its own app and not a plugin in Jenkins. JCasC will also play a bigger role in Cloud Native Jenkins, reducing UI surface area from Jenkins.

Given that, CloudBees will reconsider where to spend its effort in Blue Ocean. The current work where parts of Blue Ocean are made reusable as NPM modules is one example that aligns well with this new vision.

Conclusion

This document lays out the key directions and approaches in a broad stroke, which I discussed with a number of you in the past. Hopefully, this gives you the big picture of how I envision where to move Jenkins forward, not just as the creator of Jenkins but as the CTO of CloudBees, who employs a number of key contributors to the Jenkins project.

Come meet Kohsuke and chat with him about the direction of Jenkins at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/10/scaling-network-connections/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">10</div></div><h5 class="title">Scaling Network Connections from the Jenkins Controller</h5></div><p class="teaser">Oleg Nenashev and I will be speaking at DevOps World | Jenkins World in San Francisco this year about
Scaling Network Connections from the Jenkins Controller.
Over the years there have been many efforts to analyze, optimize, and fortify the “Remoting channel”
that allows a controller to orchestrate agent activity and receive build results.
Techniques such as tuning the agent launcher can improve service,
but qualitative change can only come from fundamentally reworking what gets transmitted and how.

In March, jira:27035[] introduced a framework for inspecting the traffic on a Remoting channel at a high level.
Previously, developers could only use generic low-level tools such as Wireshark,
which cannot identify the precise piece of Jenkins code responsible for traffic.

Over the past few months, the
Cloud Native SIG
has been making progress in addressing root causes.
The
Artifact Manager on S3 plugin
has been released and integrated with Jenkins Evergreen,
allowing upload and download of large artifacts to happen entirely between the agent and Amazon servers.
Prototype plugins allow all build log content generated by an agent (such as in sh steps)
to be streamed directly to external storage services such as AWS CloudWatch Logs.
Work has also begun on uploading JUnit-format test results, which can sometimes get big,
directly from an agent to database storage.
All these efforts can reduce the load on the Jenkins controller and local network
without requiring developers to touch their Pipeline scripts.

Other approaches are on the horizon.
While “one-shot” agents run in fresh VMs or containers greatly improve reproducibility,
they suffer from the need to transmit megabytes of Java code for every build,
so Jenkins features will need to be built to precache most or all of it.
Work is underway to use Apache Kafka to make channels more robust against network failures.
Most dramatically, the proposed
Cloud Native Jenkins MVP
would eliminate the bottleneck of a single Jenkins controller service handling hundreds of builds.

Come meet Jesse, Oleg, and other Cloud Native SIG members at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/11/speaker-blog-warnings-plugin/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">11</div></div><h5 class="title">Warnings Plugin 5.0 (White Mountain) Public Beta</h5></div><p class="teaser">Jenkins&#x27; Warnings plugin collects compiler warnings or issues reported by static analysis tools and visualizes the
results. The plugin (and the associated static analysis plugin suite) has been part of the Jenkins plugin eco-system
for more than ten years now. In order to optimize user experience and support Pipeline, a major rewrite of
the whole set of plugins was necessary. This new version (code name White Mountain) is now available as a public
beta. Please download and install this new version and help us to identify problems before the API is sealed.

The new release is available in the
experimental update center.
It has built-in support for almost hundred static analysis tools (including several compilers), see the list of
supported report formats.

Features overview

The Warnings plugin provides the following features when added as a post build action (or step) to a job:

The plugin scans the console log of a Jenkins build or files in the workspace of your job for any kind of issues.
There are almost one hundred
report formats supported.
Among the problems it can detect:

errors from your compiler (C, C#, Java, etc.)

warnings from a static analysis tool (CheckStyle, StyleCop, SpotBugs, etc.)

duplications from a copy-and-paste detector (CPD, Simian, etc.)

vulnerabilities

open tasks in comments of your source files

The plugin publishes a report of the issues found in your build, so you can navigate to a summary report from the
main build page. From there you can also dive into the details:

distribution of new, fixed and outstanding issues

distribution of the issues by severity, category, type, module, or package

list of all issues including helpful comments from the reporting tool

annotated source code of the affected files

trend charts of the issues

In the next sections, I’ll show the new and enhanced features in more detail.

One plugin for all tools

Previously the warnings plugin was part of the static analysis suite that provided the same set of features through
several plugins (CheckStyle, PMD, Static Analysis Utilities, Analysis Collector etc.).
In order to simplify the user experience and the development process, these
plugins and the core functionality have been merged into the warnings plugin. All other plugins are not required
anymore and will not be supported in the future. If you currently use one of these plugins you should migrate
to the new recorders and steps as soon as possible. I will still maintain the old code for a while,
but the main development effort will be spent into the new code base.

The following plugins have been integrated into the beta version of the warnings plugin:

Android-Lint Plugin

CheckStyle Plugin

CCM Plugin

Dry Plugin

PMD Plugin

FindBugs Plugin

All other plugins still need to be integrated or need to be refactored to use the new API.

New pipeline support

Requirements for using the Warnings plugin in Jenkins Pipeline can be complex and sometimes controversial.
In order to be as flexible as possible I decided to split the main step into two individual parts,
which could then be used independently from each other.

Simple pipeline configuration

The simple pipeline configuration is provided by the step recordIssues. This step is automatically derived from the
FreeStyle job recorder: it scans for issues in a given set of files (or in the console log) and reports these issues
in your build. You can use the snippet generator to create a working snippet that calls this step. A typical example
of this step is shown in the following example:

recordIssues
    enabledForFailure: true,
    tools: [[pattern: &#x27;*.log&#x27;, tool: [$class: &#x27;Java&#x27;]]],
    filters: [includeFile(&#x27;MyFile.*.java&#x27;), excludeCategory(&#x27;WHITESPACE&#x27;)]

In this example, the files &#x27;*.log&#x27; are scanned for Java issues. Only issues with a file name matching the
pattern &#x27;MyFile.*.java&#x27; are included. Issues with category &#x27;WHITESPACE&#x27; will be excluded. The
step will be executed even if the build failed. The recorded report of warnings will be published under the fixed
URL &#x27;https://[ your-jenkins ]/job/[ your-job ]/java&#x27;. URL or name of the report can be changed if required.

Advanced Pipeline Configuration

Sometimes publishing and reporting issues using a single step is not sufficient. For instance, if you build your
product using several parallel steps and you want to combine the issues from all of these steps into
a single result. Then you need to split scanning and aggregation. Therefore, the plugin  provides the following
two steps that are combined by using an intermediate result object:

scanForIssues : this step scans a report file or the console log with a particular parser and creates an
intermediate report object that contains the report.

publishIssues : this step publishes a new report in your build that contains the aggregated results
of one or several scanForIssues steps.

You can see the usage of these two steps in the following example:

def java = scanForIssues tool: [$class: &#x27;Java&#x27;]
def javadoc = scanForIssues tool: [$class: &#x27;JavaDoc&#x27;]

publishIssues issues:[java, javadoc], filters:[includePackage(&#x27;io.jenkins.plugins.analysis.*&#x27;)]

def checkstyle = scanForIssues tool: [$class: &#x27;CheckStyle&#x27;], pattern: &#x27;**/target/checkstyle-result.xml&#x27;
publishIssues issues:[checkstyle]

def pmd = scanForIssues tool: [$class: &#x27;Pmd&#x27;], pattern: &#x27;**/target/pmd.xml&#x27;
publishIssues issues:[pmd]

publishIssues id:&#x27;analysis&#x27;, name:&#x27;White Mountains Issues&#x27;, issues:[checkstyle, pmd],
    filters:[includePackage(&#x27;io.jenkins.plugins.analysis.*&#x27;)]

Filtering issues

The created report of issues can be filtered afterwards. You can specify an arbitrary number of include or exclude
filters. Currently, there is support for filtering issues by module name, package or namespace name, file name,
category or type.

An example pipeline that uses such a filter is shown in the following snippet:

recordIssues
    tools: [[pattern: &#x27;*.log&#x27;, tool: [$class: &#x27;Java&#x27;]]],
    filters: [includeFile(&#x27;MyFile.*.java&#x27;), excludeCategory(&#x27;WHITESPACE&#x27;)]

Quality gate configuration

You can define several quality gates that will be checked after the issues have been reported. These quality gates
let you to modify Jenkins&#x27; build status so that you immediately see if the desired quality of your product is met.
A build can be set to unstable or failed for each of these quality gates. All quality gates use a simple metric:
the maximum number of issues that can be found and still pass a given quality gate.

An example pipeline that enables a quality gate for 10 warnings in total or 1 new warning is shown in the
following snippet:

recordIssues
    tools: [[pattern: &#x27;*.log&#x27;, tool: [$class: &#x27;Java&#x27;]]], unstableTotalHigh: 10, unstableNewAll: 1

Issues history: new, fixed, and outstanding issues

One highlight of the plugin is the ability to categorize issues of subsequent builds as new, fixed and outstanding.

Using this feature makes it a lot easier to keep the quality of your project under control: you can focus
only on those warnings that have been introduced recently.

Note: the detection of new warnings is based on a complex algorithm that tries to track the same warning in
two two different versions of the source code. Depending on the extend of the modification of the source code
it might produce some false positives, i.e., you might still get some new and fixed warnings even if there should
be none. The accuracy of this algorithm is still ongoing research and will be refined in the next couple of months.

Severities

The plugin shows the distribution of the severities of the issues in a chart. It defines the
following default severities, but additional ones might be added by plugins that extend the warnings plugin.

Error : Indicates an error that typically fails the build

Warning (High, Normal, Low): Indicates a warning of the given priority. Mapping to the priorities
is up to the individual parsers.

Note that not every parser is capable of producing warnings with a different severity. Some of the parses simply
use the same severity for all issues.

Build Trend

In order to see the trend of the analysis results, a chart showing the number of issues per build is also
shown. This chart is used in the details page as well as in the job overview. Currently, type and configuration
of the chart is fixed. This will be enhanced in future versions of the plugin.

Issues Overview

You can get a fast and efficient overview of the reported set of issues in several aggregation views.
Depending on the number or type of issues you will see the distribution of issues by

Static Analysis Tool

Module

Package or Namespace

Severity

Category

Type

Each of these detail views are interactive, i.e. you can navigate into a subset of the categorized issues.

Issues Details

The set of reported issues is shown in a modern and responsive table. The table is loaded on demand using an Ajax
call. It provides the following features:

Pagination : the number of issues is subdivided into several pages which can be selected by using the provided page
links. Note that currently the pagination is done on the client side, i.e. it may take some time to obtain the whole table of
issues from the server.

Sorting : the table content can be sorted by clicking on ony of the table columns.

Filtering, Searching : you can filter the shown issues by entering some text in the search box.

Content Aware : columns are only shown if there is something useful to display. I.e., if a tool does not report an
issues category, then the category will be automatically hidden.

Responsive : the layout should adapt to the actual screen size.

Details : the details message for an issue (if provided by the corresponding static analysis tool) is shown as
child row within the table.

Remote API

The plugin provides two REST API endpoints.

Summary of the analysis result

You can obtain a summary of a particular analysis report by using the URL [tool-id]/api/xml
(or [tool-id]/api/json). The summary contains the number of issues, the quality gate status, and all
info and error messages.

Details of the analysis result

The reported issues are also available as REST API. You can either query all issues or only the
new, fixed, or outstanding issues. The corresponding URLs are:

[tool-id]/all/api/xml : lists all issues

[tool-id]/fixed/api/xml : lists all fixed issues

[tool-id]/new/api/xml : lists all new issues

[tool-id]/outstanding/api/xml : lists all outstanding issues

How You Can Help

I hope these new features are useful for everyone! Please download or install this new release and test it in your jobs:

Convert some of your jobs to the new API and test the new (and old) features (based on your requirements).

Read all labels carefully, I’m not a native speaker so some descriptions might be misleading or incorrect.

Check the new URLs and names of the parsers, see list of
supported report formats. These
can’t be changed after the beta testing.

If you find a problem, incorrect phrase, typo, etc. please report a bug in Jira (or even better: file a PR in GitHub).

This has been a brief overview of the new features of the Warnings plugin in Jenkins. For more, be sure to check out my
talk at &quot;DevOps World | Jenkins World&quot; where I show more details of the Warnings plugin!

Come see Ullrich Hafner and many other Jenkins experts and contributors at
DevOps World | Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/uhafner/">Ullrich Hafner</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/warnings">warnings</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/12/2018-community-survey/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">12</div></div><h5 class="title">2018 DevOps|Jenkins Community Survey Now Open</h5></div><p class="teaser">Take the 5th Annual DevOps and Jenkins Community Survey

With DevOps World | Jenkins World San Francisco right around the corner, CloudBees is excited to sponsor the 2018 DevOps and Jenkins Community Survey. We want to capture the details of your DevOps experience in order to provide valuable insights to the Jenkins Community and beyond. Our community is stronger together - and this look at our collective experience will reveal the big picture and shine a light on key trends. This year, as the Jenkins project continues to evolve with Jenkins X , Configuration as Code and more, your input is more critical than ever.

Let’s look at what we learned in 2016 and 2017:

In 2016 we found that:

Jenkins continued to hold the position as a company standard orchestration solution.

29% of respondents companies use Jenkins on more than 50 projects

In regards to SCM tools, Git continued the march to dominance:

Git usage increased to 85%

Subversion usage decreased to 35%

When it comes to practices, Agile and CI seemed to be the standard, and CD adoption still had a ways to go:

85% practiced Agile

82% practiced CI

61% practiced DevOps

46% practiced CD

In 2017 respondents reported that:

Jenkins Pipeline gained widespread adoption with 89% of survey takers used pipeline or planned to use in 6 months or less.

Container technology was cemented as a key part of the CD/DevOps ecosystem, yet Kubernetes usage was just starting gain momentum at 20.15%:

Jenkins, CD, and DevOps are getting more attention from Architects with 39% of respondents identified as Architects, nearly double the previous year

Git was the clear SCM of choice at 90%, increasing nearly 5% over last the previous year

What will you and the community tell us this year?  Are more people practicing DevOps?  Is Kubernetes the leader in container orchestration?  Is pipeline the standard for creating workflows?  Take the survey and let’s find out!

As always, your personal information (name, email address and company) will NOT be used by CloudBees for sales or marketing and the survey results will be made publicly available to the Jenkins Community. We will also be publishing a blog series analyzing trends over the last 5 years and offering  predictions on the evolution of DevOps. If you’re curious about what insights your input will provide, see the results of last year’s 2017 survey.

As an added incentive to participate, CloudBees will enter participants into a drawing for a free pass to DevOps World | Jenkins World 2019 (1st prize, $1,199.00 value) or a $100 Amazon gift card (2nd prize)!

The survey will close at the end of October so grab a cup of coffee get started. We promise the survey will be done before your latte is.

Take me to the survey.

There are laws that govern prize giveaways and eligibility; CloudBees has compiled all those fancy terms and conditions here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/bvdawson/">Brian Dawson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devops">devops</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/12/speaker-blog-a-cloud-native-jenkins/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">12</div></div><h5 class="title">Speaker blogpost: A Cloud Native Jenkins</h5></div><p class="teaser">A few months ago I published a
blog post about
Cloud Native Special Interest Group (SIG)
and ongoing projects related to Cloud Native Jenkins.
Next week we will be presenting at DevOps World | Jenkins World together with Carlos Sanchez and Jesse Glick,
so I would like to provide a heads up for
our talk: “A Cloud Native Jenkins”.

In our talk, we will focus on the following topics: Pluggable Storage,
our ephemeral Jenkins controllers experiments,
and tools which may be used to implement single-shot controllers.

Pluggable Storage

Pluggable storage is one of the major areas we have been working on over the last few months.
There are a number of parallel stories which are summarized on
this page.
There has been significant progress in the areas of artifact storage, build logging and configuration storage.
A number of Jenkins Enhancement Proposals were submitted and accepted,
and there are plugin releases and prototypes for these stories.

During our talk we will discuss the current status of these stories and future plans.
In particular, we will cover the following areas and reference implementations:

Storing all your artifacts transparently, e.g. in a cloud service blob store like AWS S3.

Artifact Manager for S3 Plugin is an implementation we have recently released

Providing credentials from an external location.

Kubernetes Credentials Provider is one of the existing implementations for Kubernetes secrets

Sending and retrieving the build logs from a cloud service.

We are working on reference implementations for AWS CloudWatch Logs and
Elasticsearch

Storing configuration data in external storage like Kubernetes Resources and SQL database

Storing test results externally, e.g. in an SQL database or a specialized Test Management System

There are existing plugins for the areas above, but there is a difference in approach we have taken.
Instead of creating new custom steps we extend Jenkins architecture in a way that the storage becomes transparent to users.
For example, with Artifact Manager for S3 Plugin common Archive Artifacts steps
work transparently with Remote storage, as well as Jenkins Pipeline’s stash() / unstash() steps.

The reference implementations intentionally use different technologies so that we cover more scenarios.
We regularly discuss the implementations in the Cloud Native SIG,
and we would appreciate your feedback.

Ephemeral Jenkins controllers research

Want something new?
Several days ago Kohsuke Kawaguchi, the creator of Jenkins, posted the
Jenkins: Shifting Gears article to summarize the plan for Jenkins evolution.
Cloud Native Jenkins is a critical part of this plan, and it is not “just Jenkins X”.
There are various architectural changes in Jenkins required to make this vision happen,
and we plan to work on these changes in the Cloud Native SIG.

In our presentation, we will talk about our experiment with ephemeral Jenkins and single-shot controllers.
In this story we are creating a headless single-shot controller which starts in a container,
executes a Pipeline build and pushes all the results to remote storage so that the container can just be deleted after completion.
Such a controller bundles plugins and self-configuration logic using “Configuration as Code”,
so that it can start executing Pipelines in just a few seconds.
Once packaged, it can be invoked from CLI as simply as…​

docker run --rm -v $PWD/demo/Jenkinsfile:/workspace/Jenkinsfile onenashev/cwp-jenkinsfile-runner-demo

or, in Kubernetes:

kubectl create configmap jenkinsfile --from-file=demo/Jenkinsfile
kubectl create -f demo/kubernetes.yaml

Such a single-shot controller could also be made a part of a Cloud Native Jenkins system.
Standard event handlers like Prow can invoke the builds on webhooks and report results back,
so that the single-shot controller can be used to build pull requests or to run Continuous Delivery flows.
Extra agents could also be connected to the controller on-demand, using the Kubernetes plugin or sidecar containers.

Tools

In order to make this experiment possible, we used a toolchain based on
Docker,
Jenkinsfile Runner,
Configuration as Code Plugin (JCasC), and a
Custom WAR Packager tool which glues all the things together.

Custom WAR Packager is a new tool which takes various configurations (YAML specification defining core version, list of plugins, system properties, Groovy Hooks, JCasC YAMLs)…​
and then bundles everything as a ready-to-fly WAR file or Docker image.
Starting from version 1.2, Custom WAR Packager also supports packaging Jenkinsfile Runner images as an experimental feature.
I will do a separate blogpost about this new tool later,
but there is already some documentation a number of demos in the project’s repo.

Our demo

Yes, we will have a demo! We will show a single-shot controller running with Pluggable storage implementations for AWS environments (Amazon S3, AWS CloudWatch, EKS, etc.),
which executes Jenkins Pipelines for Maven projects and provisions agents in Kubernetes on-demand.

The demo has to be published yes, but you can already find a more simple Jenkinsfile Runner demo
here.

Want to know more?

The upcoming DevOps World | Jenkins World conferences
are heavily packed with talks related to Cloud Native Jenkins,
including war stories and presentations on projects like Jenkins X and Jenkins Evergreen.
It is a great chance to get more information about using Jenkins in cloud environments.

If you are a Jenkins contributor or just want to become a contributor,
also join the Contributor Summit (Sep 17 in US and Oct 23 in Nice) or visit the Jenkins community booth in the Exhibition hall.
At the Contributor Summit on Sep 17 we will also have a face-to-face Cloud Native SIG meeting.
Feel free to contribute to the agenda here.

Come meet Carlos, Jesse, Oleg, and other Cloud Native SIG members at
Jenkins World on September 16-19th in San Francisco and on October 22-25 in Nice.
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pluggable-storage">pluggable-storage</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsfile-runner">jenkinsfile-runner</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/13/speaker-blog-evergreen-safely-upgrading/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">13</div></div><h5 class="title">Speaker blogpost: Jenkins Evergreen At DevOps World | Jenkins World 2018</h5></div><p class="teaser">Evergreen is a distribution of Jenkins we are working on that provides an easy to use and automatically upgrading experience.
This year at the conference, there will be not just one, but two talks to present Evergreen to the Jenkins community:

Continuously Delivering an Easy-to-Use Jenkins with Jenkins Evergreen, by R. Tyler Croy.

Safely Upgrading Jenkins Every Single Day, by Baptiste Mathus.

Tyler will present the overall Jenkins Evergreen architecture, its inception and how this aims at making it much simpler for people to just use Jenkins to build their projects, without having to become Jenkins admins.

On the last conference day, during my own talk I will focus on the improved developer experience, and zoom into how we implemented some important features.

We will dig together into the Error Telemetry system put in place, allowing us to actually fix errors and warnings people see in production environments.
How instances are automatically reporting errors to the Evergreen backend, and how we then centralize and analyze them using Sentry.
We will explain how the Incrementals system allows developers a very short roundtrip, between a merged pull-request and a release we can push out to all instances.
We will see concrete examples of issues we already fixed and released to Evergreen instances in just a few days after we opened an alpha version to the world.

I will show you how an instance starts up and gets upgraded by discussing with the backend it’s constantly connected to.
How the backend knows what it should instruct an instance to download and install, or how we trigger an automated data snapshot.

You will obviously see a demo of all this showing in particular how Evergreen can already run on a Docker host, or on AWS (more environments to come!), using some of the so-called flavors for Jenkins Evergreen.

Come meet us at
DevOps World | Jenkins World 2018 on September 16-19th in San Francisco.
We will be hanging out around the OSS space, eager to answer more questions.

Register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/14/kubernetes-and-secret-agents/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">14</div></div><h5 class="title">Jenkins and Kubernetes - Secret Agents in the Clouds</h5></div><p class="teaser">At long last, the way we build and deploy software is finally changing and significantly so.
The days of the persnickety, prima donna build machine where monolithic applications were built, tested, and deployed are numbered.
And that is a &quot;Good Thing (tm)&quot; - a consequence of how we will meet the transformation goals of our businesses.
Modern applications consist of distributed services, often with multiple microservices that are developed and deployed independent of other services.
However, the only way to build these services with their own dependencies and schedules is to bake in continuous integration and delivery from the beginning.
And as usual, your Jenkins platform is your friend.

But let’s take a moment and think about that in the context of microservices, especially if you’ve only used Jenkins for monolithic applications.
You’ll be creating a greater number of individual Jenkins jobs that each run multiple times a day.
This is a significant process change, and it’s important to acknowledge this and change our approach to managing Jenkins to accommodate these changes.
It’s well within Jenkins’ capabilities, but you will need to think a little differently, and invest to close those last-mile deployment gaps.

Evolution of my Jenkins Environment

One of the biggest challenges I’ve faced as a DevOps practitioner is a long and evolving set of options to manage my Jenkins agent infrastructure.
With only a few large jobs you don’t really need to worry too much about your agents.
But when you’re orchestrating the CI/CD pipelines for dozens or even hundreds of services, optimizing efficiency and minimizing cost becomes important.
And that journey has allowed me to consider and test many different Jenkins build agent architectures over the years.
This journey may be familiar to you as well.

These are the types of Jenkins environments I’ve run over the years.

Execute all the builds on the controller.
Concentrate all the moving parts on one instance.
(I call this Hello Jenkins)

Create a Jenkins EC2 agent with all the required tools for building every service, and then clone it if I need to “scale” Jenkins.
(I call this the Monster Agent.)

Create an individual Jenkins EC2 agent for each service I need to build.
(I call this the Snowflake Agent.)

Run build steps in containers.
For example, launching agents in containers using the
Docker Plugin or using multi-stage Dockerfiles to encapsulate all the logic for building, testing and packaging an application.
They are both good first steps in container abstraction and allow you to easily copy artifacts from one container to another.
Of course, access to a Docker engine is required for either approach, and I’ve managed my Docker host(s) for running Jenkins agents several different ways:

Run the Docker engine inside my Jenkins controller container - Docker in Docker (DinD)

Mount the Docker socket of the host on which my Jenkins controller container runs, allowing agents to run as sibling or sidecar containers - Docker outside of Docker (DooD)

Configure a single external EC2 Docker host for the Jenkins controller to use for launching builds in containers

Dynamically launch agents using the EC2 plugin with an AMI that contains the Docker Engine and then run all the steps in a multi-stage Dockerfile

All these approaches were attempts to get out of the business of curating and managing Jenkins agents and infrastructure, each with their own benefits and drawbacks.
But recently I begin working in a new Jenkins environment - Jenkins on Kubernetes.

Once you’ve come to view Jenkins, build agents and jobs as containerized services, migrating platforms becomes much more straightforward.
And total disclaimer here - I had never used Kubernetes in my life, not even for side projects - when I set out to do this.
That said, it was surprisingly simple to create a Kubernetes cluster in Google Cloud Platform’s (GCP) GKE, launch a Jenkins controller using a
Helm chart and begin running build steps in Jenkins agents running in containers on my new Kubernetes cluster.

Launch agents in Kubernetes from your pipeline scripts

The focus of this post and my Jenkins World talk for 2018, is to show you how to configure Jenkins to launch agents in Kubernetes from your pipeline scripts.
My examples assume you are launching your agents in the same Kubernetes cluster where your Jenkins controller is running, but there are other options.
You’ll begin by installing the
Kubernetes plugin.
As a bonus, when I installed Jenkins using the latest stable chart in the default Helm repository, the Kubernetes plugin was automatically installed for me.

Once you get the Jenkins controller running on your Kubernetes cluster, there are only a few configuration steps required and then you can begin launching ephemeral build agents on Kubernetes.

Configure the Jenkins controller

You’ll first need to create a credentials set for the Jenkins controller to access the Kubernetes cluster.
To do this, perform the following steps:

In the Jenkins UI, click the Credentials link in the left-hand navigation pane

Click the arrow next to (global) in the Stores scoped to Jenkins table (you have to hover next to the link to see the arrow)

Click Add Credentials

Under Kind, specify Kubernetes Service Account

Leave the scope set to Global

Click OK.

That’s it! This configuration allows the Jenkins controller to use a Kubernetes service account to access the Kubernetes API.

Create a Cloud Configuration on the Jenkins controller

The next step is to create a cloud configuration for your K8s cluster.
(When I use K8s instead of Kubernetes it’s because it is quicker to type, not just for coolness.)

In the Jenkins UI, go to Manage Jenkins → Configure System

Scroll down until you see Cloud settings and click the Add a new cloud box and select kubernetes

The following parameters must be set:

Name : - This defaults to kubernetes

Kubernetes URL : https://kubernetes.default - This was automatically configured from the service account.

Kubernetes Namespace : default - Unless you are running your controller in another namespace

Credentials :  Select the Kubernetes Service Account credentials you created in the previous step

Jenkins URL : http:// :8080

Jenkins tunnel : :5555 - This is the port that is used to communicate with an agent

These were the only parameters I had to set to launch an agent in my K8s cluster.
You can certainly modify other parameters to tweak your environment.

Now that you’ve configured your Jenkins controller so that it can access your K8s cluster, it’s time to define some pods.
A pod is the basic building block of Kubernetes and consists of one or more containers with shared network and storage.
Each Jenkins agent is launched as a Kubernetes pod.
It will always contain the default JNLP container that runs the Jenkins agent jar and any other containers you specify in the pod definition.
There are at least two ways to configure pod templates – in the Jenkins UI and in your pipeline script.

Configure a Pod Template in the Jenkins UI

In the Jenkins UI, go to Manage Jenkins → Configure Systems

Scroll down to the cloud settings you configured in the previous step

Click the Add Pod Template button and select Kubernetes Pod Template

Enter values for the following parameters:

Name :

Namespace : default - unless you configured a different namespace in the previous step

Labels : - this will be used to identify the agent pod from your Jenkinsfiles

Usage : Select &quot; Use this node as much as possible&quot; if you would like for this pod to be your default node when no node is specified.
Select &quot; Only build jobs with label matching expressions matching this node&quot; to use this pod only when its label is specified in the pipeline script

The name of the pod template to inherit from - you can leave this blank.
It will be useful once you gain experience with this configuration, but don’t worry about it for now.

Containers : The containers you want to launch inside this pod.
This is described in detail below.

EnvVars : The environment variables you would like to inject into your pod at runtime.
This is described in detail below.

Volumes :  Any volumes you want to mount inside your pod.
This is described further below.

Remember that a pod consists of one or more containers that live and die together.
The pod must always include a JNLP container, which is configured by default if you installed the controller using the Helm Chart.
However, you will want to add containers with the tool chains required to build your application.

Add Your Own Container Template

In the Jenkins UI, return to the pod template you created in the last step

Click the Add Container button and select Container Template

Enter values in the following fields:

Name :

Docker image : any Docker image you’d like
For example, if you are building an application written in Go, you can enter &#x27;golang:1.11-alpine3.8&#x27;

Label : Enter any label strings you’d like to use to refer to this container template in your pipeline scripts

Always pull image : - Select this option if you want the plugin to pull the image each time a pod is created.

You can leave the default values for the other parameters, but you can see that the plugin gives you fine-grained control over your pod and the individual containers that run within it.
Any values you might set in your Kubernetes pod configuration can be set via this plugin as well.
You can also inject your configuration data by entering raw YAML.
I encourage you not to get distracted by the sheer number of options you can configure in this plugin.
You only have to configure a small subset of them to get a working environment.

You can click the Add Environment Variable button in the container template to inject environment variables into a specific container.
You can click the Add Environment Variable button in the pod template to inject environment variables into all containers in the pod.
The following environment variables are automatically injected into the default JNLP container to allow it to connect automatically to the Jenkins controller:

JENKINS_URL : Jenkins web interface url

JENKINS_JNLP_URL : url for the jnlp definition of the specific agent

JENKINS_SECRET : the secret key for authentication

JENKINS_NAME : the name of the Jenkins agent

If you click the Add Volume button in the pod template, you’ll see several options for adding volumes to your pod.
I use the Host Path Volume option to mount the docker socket inside the pod.
I can then run a container with the Docker client installed and use the host Docker socket to build and push Docker images.

At this point, we’ve created a cloud configuration for our Kubernetes cluster and defined a pod consisting of one or more containers.
Now, how do we use this to run Jenkins jobs? We simply refer to the pod and containers by label in our Jenkins pipeline script.
We use the label we gave to the pod in the node block and the label for the container we wish to use in the container block.
The examples in this post use scripted pipeline, but you can achieve the same outcome using the declarative pipeline syntax:

node(&#x27;test-pod&#x27;) {
    stage(&#x27;Checkout&#x27;) {
        checkout scm
    }
    stage(&#x27;Build&#x27;){
        container(&#x27;go-agent&#x27;) {
            // This is where we build our code.
        }
    }
}

Defining the Pod in the Jenkinsfile

Configuring a plugin through the UI is perfectly fine in a proof of concept.
However, it does not result in a software-defined infrastructure that can be versioned and stored right alongside your source code.
Luckily, you can create the entire pod definition directly in your Jenkinsfile.
Is there anything you can’t do in a Jenkinsfile???

Any of the configuration parameters available in the UI or in the YAML definition can be added to the podTemplate and containerTemplate sections.
In the example below, I’ve defined a pod with two container templates.
The pod label is used in the node block to signify that we want to spin up an instance of this pod.
Any steps defined directly inside the node block but not in a container block with be run in the default JNLP container.

The container block is used to signify that the steps inside the block should be run inside the container with the given label.
I’ve defined a container template with the label &#x27;golang&#x27;, which I will use to build the Go executable that I will eventually package into a Docker image.
In the volumes definition, I have indicated that I want to mount the Docker socket of the host, but I still need the Docker client to interact with it using the Docker API.
Therefore, I’ve defined a container template with the label &#x27;docker&#x27; which uses an image with the Docker client installed.

podTemplate(
    name: &#x27;test-pod&#x27;,
    label: &#x27;test-pod&#x27;,
    containers: [
        containerTemplate(name: &#x27;golang&#x27;, image: &#x27;golang:1.9.4-alpine3.7&#x27;),
        containerTemplate(name: &#x27;docker&#x27;, image:&#x27;trion/jenkins-docker-client&#x27;),
    ],
    volumes: [
        hostPathVolume(mountPath: &#x27;/var/run/docker.sock&#x27;),
        hostPath: &#x27;/var/run/docker.sock&#x27;,
    ],
    {
        //node = the pod label
        node(&#x27;test-pod&#x27;){
            //container = the container label
            stage(&#x27;Build&#x27;){
                container(&#x27;golang&#x27;){
                    // This is where we build our code.
                }
            }
            stage(&#x27;Build Docker Image&#x27;){
                container(‘docker’){
                    // This is where we build the Docker image
                }
            }
        }
    })

In my Docker-based pipeline scripts, I was building Docker images and pushing them to a Docker registry, and it was important to me to replicate that exactly with my new Kubernetes setup.
Once I accomplished that, I was ready to build my image using gcloud, the Google Cloud SDK, and push that image to the Google Container Registry in anticipation of deploying to my K8s cluster.

To do this, I specified a container template using a gcloud image and changed my docker command to a gcloud command.
It’s that simple!

podTemplate(
    name: &#x27;test-pod&#x27;,
    label: &#x27;test-pod&#x27;,
    containers: [
        containerTemplate(name: &#x27;golang&#x27;, image: &#x27;golang:1.9.4-alpine3.7&#x27;),
        containerTemplate(name: &#x27;gcloud&#x27;, image:&#x27;gcr.io/cloud-builders/gcloud&#x27;),
    ],
    {
        //node = the pod label
        node(&#x27;test-pod&#x27;){
            //container = the container label
            stage(&#x27;Build&#x27;){
                container(&#x27;golang&#x27;){
                    // This is where we build our code.
                }
            }
            stage(&#x27;Build Docker Image&#x27;){
                container(‘gcloud’){
                    //This is where we build and push our Docker image.
                }
            }
        }
    })

Standing up a Jenkins controller on Kubernetes, running ephemeral agents, and building and deploying a sample application only took me a couple of hours.
I spent another weekend really digging in to better understand the platform.
You can be up and running in a matter of days if you are a quick study.
There are a wealth of resources available on running Jenkins on Kubernetes, and I hope this blog post helps to further that knowledge.
Even better, come to
my session at Jenkins World and let’s talk in person.

So, what else do you want to know?
Hit me up on Twitter.
I might even add your questions to my Jenkins World session.
I suppose next up is Mesos?

Come meet Mandy and other Jenkins and Kubernetes experts at
Jenkins World on September 16-19th,
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/devmandy/">Mandy Hubbard</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/14/speaker-blog-jenkins-builds-jenkins/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">14</div></div><h5 class="title">Want to know how Jenkins builds Jenkins? Catch this session at DevOps World | Jenkins World next week in San Francisco!</h5></div><p class="teaser">Next week Olivier Vernin from CloudBees and Brian Benz from Microsoft will be presenting a session at DevOps World | Jenkins World about how Microsoft has been working with Jenkins to build Jenkins plugins and produce Jenkins on Microsoft Azure.
These plugins run Jenkins on Azure Linux and Windows VMs, Kubernetes, azure App service, as well as deploy artifacts to those Azure platforms and more.
All are open source and available on GitHub.

Here’s our session, where we’ll be sharing successes and challenges of getting the infrastructure up and running:

Tuesday, September 18

Session: Developing and Delivering Jenkins in the cloud
11:15am - 12:00pm Brian Benz with Olivier Vernin, CloudBees

In this session, we’ll discuss the real-life implementation of Jenkins&#x27; development and delivery infrastructure in the cloud as it has evolved from a mix of platforms to Microsoft Azure.
Expect a frank discussion of how issues that were encountered along the way were overcome, how the architecture has evolved, and what’s on the roadmap.
We’ll share important tips and tricks for implementing your own Jenkins infrastructure on any cloud, based on Jenkins&#x27; own experience with their implementation.

See you in San Francisco!

Come meet us at
DevOps World | Jenkins World 2018 on September 16-19th in San Francisco.
We will be hanging out around the OSS space, eager to answer more questions.

Register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/17/jenkins-artwork/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">17</div></div><h5 class="title">Jenkins Artwork at the DevOps World | Jenkins World 2018 Community Booth</h5></div><p class="teaser">Hi all, this is my first blogpost on jenkins.io.
My name is Kseniia Nenasheva, I work as a Graphics Designer at CloudBees.
I have been using Jenkins since 2012 as a QA engineer, and I am happy to contribute to the project.
I have also submitted some patches to the core and plugins,
and probably you have seen some Jenkins logos created by me,
and some of you may even have them on your laptops.
By the way, Ron Burgundy is my favorite Jenkins logo.

This year I am going to DevOps World | Jenkins World in San Francisco.
During the conference I will be working at the Jenkins community booth
and creating exclusive pictures with conference visitors and one of the Jenkins heroes.
So, if you come to our booth and share your Jenkins story, you can get a special picture.

If you are interested to get a logo for your Jenkins Area Meetup
or an open-source project (including Jenkins plugins, of course),
please also stop by at the booth and share your ideas.
After the conference I will try to implement the most interesting proposals.

You can also meet me at the contributor summit on September 17.

Come meet Kseniia and other Jenkins contributors at
Jenkins World on September 16-19th in San Francisco and on October 22-25 in Nice.
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ksenia-nenasheva/">Ksenia Nenasheva</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/artwork">artwork</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/09/18/automatically-upgrading-with-evergreen/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">18</div></div><h5 class="title">Continuously delivering an easy-to-use Jenkins with Evergreen</h5></div><p class="teaser">When I first wrote about Jenkins
Evergreen, which was then referred to as &quot;Jenkins Essentials&quot;, I mentioned a
number of future developments which in the subsequent months have become
reality. At this year’s DevOps World - Jenkins World in San Francisco, I will
be sharing more details on the philosophy behind Jenkins Evergreen, show off
how far we have come, and discuss where we’re going with this radical
distribution of Jenkins.

As discussed in my first blog post, and
JEP-300,
the first two pillars of Jenkins Evergreen have been the primary focus of our
efforts.

Automatically Updated Distribution

Perhaps unsurprisingly, implementing the mechanisms necessary for safely and
automatically updating a Jenkins distribution, which includes core and plugins,
was and continues to be a sizable amount of work. In
Baptiste’s talk
he will be speaking about the details which make Evergreen &quot;go&quot; whereas
I will be speaking about why an automatically updating distribution is
important.

As continuous integration and continuous delivery have become more commonplace,
and fundamental to modern software engineering, Jenkins tends to live two
different lifestyles depending on the organization. In some organizations,
Jenkins is managed and deployed methodically with automation tools like Chef,
Puppet, etc. In many other organizations however, Jenkins is treated much more
like an appliance, not unlike the office wireless router. Installed and so
long as it continues to do its job, people won’t think about it too much.

Jenkins Evergreen’s distribution makes the &quot;Jenkins as an Appliance&quot; model much
better for everybody by ensuring the latest feature updates, bug and security
fixes are always installed in Jenkins.

Additionally, I believe Evergreen will serve another group we don’t adequately
serve at the moment: those who want Jenkins to behave much more like a
service. We typically don’t consider &quot;versions&quot; of GitHub.com, we receive
incremental updates to the site and realize the benefits of GitHub’s on-going
development without ever thinking about an &quot;upgrade.&quot;

I believe Jenkins Evergreen can, and will provide that same experience.

Automatic Sane Defaults

The really powerful thing about Jenkins as a platform is the broad variety of
patterns and practices different organizations may adopt. For newer users, or
users with common use-cases, that significant amount of flexibility can result
in a paradox of choice. With Jenkins Evergreen, much of the most common
configuration is automatically configured out of the box.

Included is Jenkins Pipeline and Blue Ocean, by default. We also removed some
legacy functionalities from Jenkins while we were at it.

We are also utilizing some of the fantastic
Configuration as Code
work, which recently had its 1.0 release, to automatically set sane defaults in
Jenkins Evergreen.

Status Quo

The effort has made significant strides thus far this year, and we’re really
excited for people to start trying out Jenkins Evergreen. As of today,
Jenkins Evergreen
is ready for early adopters. We do not yet recommend using Jenkins
Evergreen for a production environment.

If you’re at DevOps World - Jenkins World in San Francisco please come see
Baptiste’s talk Wednesday at 3:45pm in Golden Gate Ballroom A. Or
my talk at 11:15am in Golden Gate Ballroom B.

If you can’t join us here in San Francisco, we hope to hear your feedback and thoughts in our
Gitter channel!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2018">jenkinsworld2018</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/evergreen">evergreen</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/01/hacktoberfest/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 1</div></div><h5 class="title">Hacktoberfest 2018. Contribute to Jenkins!</h5></div><p class="teaser">Once again October has arrived.
That means the regular Hacktoberfest event is back!
This year it will be the fifth installment.
During this one-month hackathon you can support open-source and earn a limited edition swag.

On behalf of the Jenkins project,
we invite you to participate in Hacktoberfest and to work on the project.
We welcome all contributors, regardless of their background and Jenkins experience.

Quick start

Sign-up to Hacktoberfest on the event website.

Everything is set, just start creating pull-requests!

Contributing to Jenkins

There are many ways to
contribute to Jenkins during Hacktoberfest.
Generally, any pull requests in GitHub may qualify.
You can…​

Code - Contribute to the code or automated tests

Jenkins project codebase includes dozens of programming languages,
mostly Java, Groovy, and JavaScript + Go in Jenkins

You can also find components in Ruby/Kotlin, and even native components in C/C++

Document - Improve documentation

Blog - write blogposts about Jenkins

Localize - Localize Jenkins components

Design - artwork and UI improvements also count!

Organize - Organize a local meetup for Jenkins &amp; Hacktoberfest (see below)

See the Contribute and Participate page for more information.

Projects

The Jenkins project is spread across  several organizations on GitHub (jenkinsci, jenkins-x, jenkins-infra).
You are welcome contribute to any repository in any of those organizations,
however various components in Jenkins have differing review and delivery velocity.
Here is a list of Jenkins subprojects with maintainers who have committed to delivering quick reviews to Hackathon participants.

Project/component
Ideas and links

Jenkins Core
There is always something to improve in Jenkins core itself.
  You can address various issues, improve the codebase,
  and add new features there.
Contributing,
newbie-friendly issues

Jenkins Website
Extend and improve Jenkins documentation, add your own blogpost.
Contributing guidelines

Jenkins X
Try out the project and create new demos,
  extend documentation, and create new builders for your toolchains.
Contributing guidelines,
Quick start,
creating custom builders,
newbie-friendly issues

Jenkins Configuration-as-Code Plugin
Contribute to the fresh new plugin: improve the codebase,
  add demos and plugin integrations.
Contributing to JCasC

Jenkins Evergreen
Try and improve the recently released Evergreen project -
  an automatically updating rolling distribution system for Jenkins.
Quick start,
newbie-friendly issues.

Java 11 support (jep:211[])
Contribute to Jenkins core and plugins to enable Java 11 in future releases.
  You can help to create new packaging, new features, testing flows, or cleanup issues
Illegal Reflective Access in the code.
Gitter chat,
newbie-friendly issues

Docker Packaging
Add new features and improvements to Jenkins Docker packaging:
Jenkins controller,
Agents,
  and other components.

Chinese Localization SIG
Contribute to the new Website and
  the Simplified Chinese Localization plugin.

Jenkins Artwork
Create new images and logos for Jenkins area meetups,
subprojects, and plugins.
  You can also contribute new graphics to plugins.

Note that this is not a full list,
and the list will be extended depending on the interest from maintainers.
You are welcome to contribute to existing Jenkins plugins…​
and even to create new ones.

Local events

Hacktoberfest is an online event,
but there are many events being organized by open-source communities.
You can join one of these events.

We also encourage Jenkins Area Meetup organizers to
run Jenkins-specific events in October (workshops, hackergartens).
If you are not a meetup organizer but want to host a meetup,
you can reach out to the organizers via meetup.com resources
(you can find a JAM here).
Check out the Hacktoberfest Event Kit
for more info.

FAQ

You can find Hacktoberfest FAQ here.
Below you can find answer to some Jenkins-specific questions.

Q: I am new to Jenkins, how do I start?

If you are new to Jenkins,
you could start by fixing some small and well described issues.
There are lists of such newbie-friendly issues, see the links in the table above.
You can also submit your own issue and propose a fix.

Q: I want to work on my own plugin, is it fine?

Yes, it is fine!
Any contributions count, your role in a repository does not matter.
Just make sure you create pull requests instead of direct pushes
(hint: it’s a best practice if you have a CI configured for your repository).

Q: How to find documentation?

Jenkins project contains lots of materials about contributing to the project.
Here are some links which may help:

Participate - landing page for newcomer contributors

Plugin Development Tutorials

Developer Documentation

Gitter channel for Q&amp;A

Projects in the table above also have their own documentation to help newcomers.

Q: How do I get reviews?

All projects in the list above are monitored by their maintainers,
and you will likely get a review within few days.
Reviews in other repositories and plugins may take longer.
In the case of delays, ping us in the hacktoberfest-help channel in Gitter.
Unmerged pull-requests also count in Hacktoberfest,
so merge delays won’t block you from getting prizes.

Q: I am stuck. How do I get help?

For non-technical questions (process and general direction) use our hacktoberfest-help
channel in Gitter.

For technical questions please use the IRC chat,
Developer mailing lists,
or the main jenkinsci/jenkins channel.
Many subprojects also have their own chats.

Q: Does Jenkins project send special swag?

All participants will get swag from Hacktoberfest organizers if they create at least5 pull requests.
Jenkins project may also distribute some swag to top contributors,
depending on the budget and contributions.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hacktoberfest">hacktoberfest</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/newcomer">newcomer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/09/telemetry/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 9</div></div><h5 class="title">Improving Jenkins Release Quality using Uplink Telemetry
</h5></div><p class="teaser">One of the major strengths of Jenkins is its customizability and extensibility.
With its plugin ecosystem and long list of (possibly hidden) options, Jenkins can be used for a wide range of use cases.

The downside of all this flexibility is that, not knowing how people use Jenkins, we mostly rely on issues filed in our bug tracker to know when things go wrong.
And over the years, quite a few things have gone wrong.
The worst of these have been security fixes that have had unintended side effects.
Unlike regular changes, it’s not really feasible to roll back security fixes, so users have sometimes had to choose between security and functionality.
But even changes developed in the open, such as the introduction of JEP-200, haven’t gone as smoothly as we hoped.
With big changes in the works, it’s more important than ever for us to have a better idea how Jenkins is used, so that we can deliver major changes safely.

Jenkins Evergreen solves this to some degree by being always connected to the Jenkins project and reporting back telemetry (mostly errors) allowing us to quickly react and provide fixes.
But that project is still pretty new, and its goal of being a more standardized Jenkins does not represent the breadth of configurations of the general user base.

Uplink telemetry

So we recently extended the existing, very limited anonymous usage statistics by adding a simple, extensible telemetry reporting client.
We’re calling it Uplink telemetry, based on the name of the service it reports its data to.
It made its debut in Jenkins 2.143.

Uplink telemetry is designed to collect data in trials, which are defined as:

a well defined set of technical data with a specific purpose

a start and end date of the collection

Detailed information explaining the scope and purpose of currently active trials is available in the inline help for the usage statistics control in the global configuration.

Of course, opting out of anonymous usage statistics there also disables the submission of Uplink telemetry.
And while Uplink trials report a per-instance UUID to help with collation (e.g. removal of duplicate submissions), that UUID is exclusively used for this purpose, and independent of all other properties of an instance.
This prevents us from correlating reported data with specific instances.
These measures are in place to strike a balance between the need to understand how Jenkins is used and respecting users&#x27; privacy.

Improving Jenkins through real-world data

We’re already created our first trial.
Jenkins 2.143 includes a trial to gather information about how common it is for instances to use Java system properties to disable (parts of) security fixes.
When we publish a security fix and we’re not completely certain it is safe to apply for everyone, we add another of these options — just in case.
As you can imagine, quite a few of these hidden options exist.
Until now, user feedback in our issue tracker was the only way we could estimate the need for any of these options.
With Uplink, Jenkins will report that information to us.

The trial is scheduled to run for the next six weeks, enough to hopefully gather this information from a large number of users of both LTS and weekly releases.
Our hope is that we will be able to remove some of these options entirely, as they might not be needed after all.
For others, we might need to consider elevating them to supported features, or finding better solutions obviating the need for them.

In the future, I will publish of some of what we have learned from the first trial running through Uplink telemetry.
I look forward to Jenkins continuing to improve with real-world data informing our future decisions.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/10/security-updates/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">10</div></div><h5 class="title">Important security updates for Jenkins</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.146 and 2.138.2, that fix multiple security vulnerabilities.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.

Further improvements

In addition to the security fixes listed in the security advisory, we also applied multiple improvements that make future security vulnerabilities more difficult, or even impossible to exploit.

One such improvement concerns cross-site scripting vulnerabilities, and comes with a risk of regressions.

Jenkins uses a fork of Jelly for the vast majority of the views it renders.
Since 2011, it includes a feature that lets view authors opt in or out of automatic escaping of variable values for rendering in HTML, and since 2016, the plugin build tooling requires that views explicitly specify whether to apply this automatic escaping.
Details are available in the developer documentation.

Until now, if views do not declare whether to automatically escape, they were rendered without automatic escaping, and developers were expected to explicitly escape every variable reference that was not supposed to contain markup.
This has resulted in a number of cross-site scripting (XSS) vulnerabilities, most recently SECURITY-1130 in Job Config History Plugin.

For that reason, we have decided to enable this automatic escaping by default if plugins do not specify a preference.
This can result in problems with some plugins if they need their output to remain unescaped.
We expect that those plugins will adapt pretty quickly to this change, as the fix is typically straightforward.
We track known affected plugins and their status on the Jenkins wiki.

In the mean time, users can set the system property org.kohsuke.stapler.jelly.CustomJellyContext.escapeByDefault to false to disable this additional protection.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/12/hackathons-in-october/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">12</div></div><h5 class="title">Jenkins Hackathons in October</h5></div><p class="teaser">Traditionally there are a lot of events happening in the Jenkins organization in Autumn.
I would like to share some information about the upcoming hackathons.

Online Event: Hacktoberfest

As you probably know, there is an ongoing Hacktoberfest event.
The Jenkins project is participating in it and everybody is welcome to contribute to Jenkins as a part of this event.
The event lasts from October 01 to October 31,
and you can can join it at any time.

See this blogpost for more information about Hacktoberfest in the Jenkins project.

Onsite Hackathons

Hacktoberfest is not the only event happening in the Jenkins community this month,
there are also a number of upcoming on-site events:

Oct 19 - Copenhagen, Denmark

Jenkins Configuration as Code hackathon at
Day of Jenkins [as code ]

Registration: all conference participants can attend

Oct 22 - Nice, France - Hackathon at
DevOps World - Jenkins World Nice

RSVP here

Make sure to also attend the Jenkins Contributor Summit on Oct 23 ;)

Oct 27 - Beijing, China

RSVP here

Oct 30 - Neuchatel, Switzerland - Hacktoberfest: Jenkins &amp; Friends event (Swiss Jenkins Area meetup)

RSVP here

All contributions during these in-person events qualify as
Hacktoberfest contributions as well. :)
More events will also be announced later in the year,
e.g. we traditionally do a hackfest in Brussels after FOSDEM in February.
Follow our developer mailing lists and social media to receive announcements.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hacktoberfest">hacktoberfest</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/14/gsoc2018-results/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">14</div></div><h5 class="title">Jenkins in Google Summer of Code 2018 Results</h5></div><p class="teaser">It has been a while since the last blogpost about Google Summer of Code in Jenkins.
GSoC 2018 has officially finished on August 23, and we had a Jenkins Online Meetup where we had final presentations of the GSoC projects.
It is never late to provide more context, so I would like to summarize the results and provide updates of what was happening in Jenkins GSoC Special Interest Group over last 2 months.
In this blogpost you can find project status overviews and updates from the Jenkins GSoC SIG.

But first of all, I would like to thank all our students, their mentors
and to all other contributors who proposed project ideas, participated in student selection, community bonding and further reviews.
Google Summer of Code is a major effort which would not be possible without active participation of the Jenkins community

Summary

This year we started preparing for Google Summer of Code in early December.
14 project ideas and 12 potential mentors we published on our website,
and we got dozens of students reaching out to us during the application period.
After processing applications, we have selected 4 applications for GSoC.
Unfortunately one project got cancelled due to student eligibility issues.

So, we had the following projects:
Code Coverage API plugin, Remoting over Apache Kafka, and Simple Pull-Request Job Plugin
(also known as Pipeline as YAML).
All these projects have a significant value to the Jenkins community.
They were focused on areas which have been discussed in the community for a long time,
but which had no progress so far.
Google Summer of Code allowed us to kick-start these projects,
and to make significant progress there.
All projects have been released and made available in the Jenkins community (common or experimental update centers).

In total there were 9 blogposts about GSoC projects on jenkins.io,
and also 2 Jenkins Online Meetups.
GSoC results have been also presented at DevOps World - Jenkins World conference and the contributor summit.

Code Coverage API Plugin

Student: Shenyu Zheng, Henan University, China

Mentors:
Jeff Pearce,
Steven Christou,
Oleg Nenashev,
Supun Wanniarachchi

Project page

There are many code coverage plugins in Jenkins: Cobertura, JaCoCo, Emma, etc., etc.
The problem with these plugins is that each of them implements all code coverage features on their own.
So you get different feature sets, UIs, CLI commands and REST APIs.
The idea of this project was to unify the existing functionality and offer a new API plugin which other plugins could extend.
It would help to simplify existing plugin and to create new plugins for coverage tools.

The project has started really well, and we had the first demo after a week of coding.
Then Shenyu continued extending the plugin’s functionality over coding periods.
Here is the list of the key features offered by the plugin:

Flexible data structure for defining and storing coverage metrics within Jenkins

Coverage charts and trends

Source code navigation

REST API for retrieving coverage stats and trends

Report aggregation for parallel steps

Extension points which allow integrating other plugins

In addition to the Code Coverage API Plugin,
Shenyu added integration to the Cobertura Plugin and also created a new llvm-cov plugin which is expected to be released soon.

After GSoC Shenyu continued contributing to the Jenkins project.
He works on the Code Coverage API plugin and also participates in the Chinese Localization SIG.

Simple Pull-Request Job Plugin

Student: Abhishek Gautam, Visvesvaraya National Institute of technology, India

Mentors:
Martin d’Anjou,
Jeff Knurek,
Kristin Whetstone

Project page

This project focused on introducing a way to
easily define pull-request build job definitions in YAML.
This project has been shaped a lot during the application period and community bonding,
so that the project fit the existing Jenkins Ecosystem better.
Finally it was decided to build the new plugin on the top of Pipeline: Multi-Branch Plugin.
There was also an idea to offer extra syntax sugar, templating and automatic resolution for common flows,
so that users need less time to define Pipelines for common use-cases.

The plugin allows defining Pipeline jobs as YAML being stored in SCM.
Original design presumed a new job type,
but during community bonding and Phase 1 prototyping it was decided to build the plugin on the top of the existing Pipeline ecosystem and extension points.
Currently the plugin generates Declarative Pipeline code from YAML so that it gets a lot of Pipeline features out-of-the box.
In addition to that, Simple Pull Request Job Plugin uses a an engine provided by the Configuration as Code plugin to convert YAML snippets
to Pipeline step definitions.

The plugin has been well described by Abhishek in his Pipeline as YAML blogpost in August.
Currently it is available in the Experimental Update Center as an alpha version.
Pham Vu Tuan, one of our GSoC students, have also joined the plugin team.
At the DevOps World - Jenkins World hackfest we had discussions with the Jenkins Pipeline team,
and we have a plan towards making this plugin available as an Incubated Pipeline project.
The final implementation may change,
but in any case the project gave us a working prototype and a lot of information about  obstacles we need to resolve.

Remoting over Apache Kafka

Student: Pham Vu Tuan, Nanyang Technological University, Singapore

Mentors:
Oleg Nenashev,
Supun Wanniarachchi

Project page

Last but not least, Remoting over Kafka is another challenging project we had.
To implement communication between its controllers and agents, Jenkins widely uses home-grown protocol implementations based on TCP
( JNLP 1..4 protocols).
There are some performance and stability implementations,
and there have been discussions about using an industry-standard message bus or queue.
Pham Vu Tuan proposed to use Apache Kafka for it,
and after some experiments during community bonding and first coding phase we agreed to go forward with this implementation.

During his project Vu Tuan extended Jenkins Core and Remoting to allow implementing an agent communication channel in a plugin.
Then he has created a new Remoting over Kafka plugin
which is now available in the main Jenkins Update cente.
Once the plugin is installed, it is possible to connect to agents over Apache Kafka and execute all types of Jenkins jobs there.
There are also official jenkins/remoting-kafka-agent images available on DockerHub.

Vu Tuan continued contributing to the Jenkins project after GSoC, currently he maintains the Remoting over Kafka plugin.
He visited the DevOps World - Jenkins World US conference in September, presented his GSoC project at the
Jenkins Contributor Summit.
You can find his slides here.
After the conference he also participated in the hackfest where he helped to migrate Jenkins&#x27; DNS services to Microsoft Azure.

What could we do better?

After the end of GSoC we had a Retrospective with GSoC students and mentors.
We discussed the issues we encountered during the projects,
and ways to improve the student and mentor experience.

Main takeaways for us:

GSoC projects should be aligned with Jenkins Special Interest Groups (SIGs) or subprojects in order to get a wider list of stakeholders
Projects should be aligned with SIG priorities when possible

In addition to GSoC SIG meetings and Jenkins Online Meetups during student evaluation,
we should also run regular status updates within SIGs so that there more contributors involved in projects

We should invest more time into forming mentor teams before the application period starts.
This year there were changes in mentor teams after the community bonding started, and it complicated the work

We should pay more attention to student eligibility.
This year we started from 4 projects, but unfortunately one project (EDA plugins for Jenkins) got cancelled due to the visa limitations the student had.

We should do regular office hours for mentors/students so that it is possible to exchange information between GSoC projects within the organization.
This year we cancelled them at the end of phase and relied only on regular project meetings and mailing lists, but this is not enough.

For me personally the main takeaway is also to reduce direct involvement into the project as a mentor and technical advisor.
Doing org administration, logistics and mentorship is not good from a bus factor PoV,
and I believe I was pushing my vision too hard in few cases.
Will do my best to prevent it next year.

If you want to share your feedback and ideas,
please reach out to us using the GSoC mailing list.

What’s next?

In order to improve GSoC organization in Jenkins,
we have have created a GSoC Special Interest Group which will be running non-stop as other SIGs in Jenkins.
The objective of the SIG is to organize GSoC, work with potential students/mentors,
and to help students stay involved in the community after GSoC ends.
In this SIG we will have monthly meetings to sync-up on GSoC.
If you are interested to contribute, please join the SIG.

According to the Retrospective, next year we plan to invest more
into communication with mentors.
We will also try to tie new project proposals to Jenkins
Special Interest Groups so that the students become a part
of ongoing coordinated efforts.
This weekend Martin d’Anjou, Jeff Pearce and me are participating in the GSoC Mentor summit to share experiences and to study from other GSoC organizations.
On October 17 we will have a GSoC SIG meeting to discuss our experience and to discuss next steps.

In addition to that,
Jenkins Google Summer of Code will be presented at DevOps World - Jenkins World Nice and at the contributor summit.
If you plan to visit the conference and you are interested to participate in Google Summer of Code and other community activities,
please join us at the contributor summit or stop by at the community booth.

And, elephant in the room…​ GSoC 2019.
Of course we are going to apply, stay tuned for new announcements.
We have already started collecting project ideas for the next year.
If you are interested to participate as a student or mentor,
please reach out to us using the GSoC SIG mailing list.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/16/custom-war-packager/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">16</div></div><h5 class="title">Build your own Jenkins! Introducing Custom WAR/Docker Packager</h5></div><p class="teaser">I would like to introduce Custom WAR Packager -
a new tool for Jenkins administrators and developers.
This tool allows packaging custom Jenkins distributions as WAR files,
Docker images
and Jenkinsfile Runner bundles.
This tool allows packaging Jenkins, plugins, and configurations in a ready-to-fly distribution.
Custom WAR packager is a part of the Ephemeral Jenkins controller toolchain
which we presented in our A Cloud Native Jenkins blogpost.
This toolchain is already used in Jenkins X to package serverless images.

In this blogpost I will show some common use-cases for Custom WAR Packager.

History

As with Jenkins itself, Custom WAR Packager started as a small development tool.
For a long time it was a problem to run integration testing in Jenkins.
We have 3 main frameworks for it:
Jenkins Test Harness,
Acceptance Test Harness,
    and Plugin Compatibility Tester.
All these frameworks require a Jenkins WAR file to be passed to them to run tests.
What if you want to run Jenkins tests in a custom environment like AWS?
Or what if you want to reuse existing Jenkins Pipeline tests and to run them against
Pluggable Storage to ensure there are no regressions?

And it was not just an idle question.
There were major activities happening in the Jenkins project: Cloud-Native Jenkins, Jenkins Evergreen, and Jenkins X.
All these activities required a lot of integration testing  to enable Continuous Delivery flows.
In order to do this in existing test frameworks, we needed to package a self-configuring WAR file so that it would be possible to run integration tests in existing frameworks.
That is why Custom WAR Packager was created in April 2018.
Later it got support for packaging Docker images,
and in September 2018 it also got support for Jenkinsfile Runner
which was created by Kohsuke Kawaguchi
and then improved by Nicolas de Loof.

What’s inside?

Custom WAR packager is a tool which is available as CLI Executable, Maven Plugin, or Docker package.
This tool takes input definitions and packages them as requested by the user.
Everything is managed by a YAML configuration file:

The tool supports various types of inputs.
The list of plugins can be passed via YAML itself, pom.xml, or a BOM file from jep:309[].
Custom WAR Packager supports not only released versions,
but also builds deployed to the Incremental repository (CD flow for Jenkins core and plugins - jep:305[]) and
even direct builds by Git or directory path specifications.
It allows building packages from any source, without waiting for official releases.
The builds are also pretty fast, because the plugin does caching in the local Maven repository by using commit IDs.

Custom WAR packager also supports the following self-configuration options:

YAML files for Jenkins Configuration as Code

Groovy Hooks (e.g. init hooks for pre-configuration)

System properties

WAR Packaging

WAR packaging happens by default every time the repo is built.
Generally Custom WAR Packager repackages all inputs into a single WAR file by following conventions defined in the Jenkins core and the JCasC plugin.

Sample configuration:

bundle:
  groupId: &quot;io.jenkins.tools.war-packager.demo&quot;
  artifactId: &quot;blogpost-demo&quot;
  vendor: &quot;Jenkins project&quot;
  description: &quot;Just a demo for the blogpost&quot;
war:
  groupId: &quot;org.jenkins-ci.main&quot;
  artifactId: &quot;jenkins-war&quot;
  source:
    version: 2.138.2
plugins:
  - groupId: &quot;io.jenkins&quot;
    artifactId: &quot;configuration-as-code&quot;
    source:
      # Common release
      version: 1.0-rc2
  - groupId: &quot;io.jenkins&quot;
    artifactId: &quot;artifact-manager-s3&quot;
    source:
      # Incrementals
      version: 1.2-rc259.c9d60bf2f88c
  - groupId: &quot;org.jenkins-ci.plugins.workflow&quot;
    artifactId: &quot;workflow-job&quot;
    source:
      # Git
      git: https://github.com/jglick/workflow-job-plugin.git
      commit: 18d78f305a4526af9cdf3a7b68eb9caf97c7cfbc
  # etc.
systemProperties:
    jenkins.model.Jenkins.slaveAgentPort: &quot;9000&quot;
    jenkins.model.Jenkins.slaveAgentPortEnforce: &quot;true&quot;
groovyHooks:
  - type: &quot;init&quot;
    id: &quot;initScripts&quot;
    source:
      dir: src/main/groovy
casc:
  - id: &quot;jcasc&quot;
    source:
      dir: casc.yml

Docker packaging

In order to do the Docker packaging, Custom WAR Packager uses the official
jenkins/jenkins
Docker images or other images using the same format.
During the build the WAR file just gets replaced by the one built by the tool.
It means that ALL image features are available for such custom builds: plugins.txt, Java options, Groovy hooks, etc., etc.

## ...
## WAR configuration from above
## ...

buildSettings:
  docker:
    build: true
    # Base image
    base: &quot;jenkins/jenkins:2.138.2&quot;
    # Tag to set for the produced image
    tag: &quot;jenkins/custom-war-packager-casc-demo&quot;

For example, this demo
shows packaging of a Docker image with External Build Logging to Elasticsearch.
Although the implementations have been improved as a part of jep:207[] and jep:210[],
you can check out this demo to see how the Docker image does self-configuration, connects to a Elasicsearch, and then starts externally storing logs without changes in build log UIs.
A Docker Compose file for running the entire cluster is included.

Jenkinsfile Runner packaging

This is probably the most tricky mode of Jenkinsfile Runner.
In March a new Jenkinsfile Runner project
was announced in the developer mailing list.
The main idea is to support running Jenkins Pipeline in a single-shot controller mode when the instance just executes a single run and prints outputs to the console.
Jenkinsfile Runner runs as CLI or as a Docker image.
Custom WAR Packager is able to produce both, though only Docker run mode is recommended.
With Jenkinsfile Runner you can run Pipelines simply as…​

docker run --rm -v $PWD/Jenkinsfile:/workspace/Jenkinsfile acmeorg/jenkinsfile-runner

When we started working on Ephemeral (aka &quot;single-shot&quot;) controllers in the Cloud Native SIG,
there was an idea to use Custom WAR Packager and other existing tools (Jenkinsfile Runner, Jenkins Configuration as Code, etc.) to implement it.
It would be possible to just replace Jenkins core JAR and add plugins to Jenkinsfile Runner, but it is not enough.
To be efficient, Jenkinsfile Runner images should start up FAST, really fast.
In the build flow implementation we used some experimental options available in Jenkins and Jenkinsfile Runner, including classloader precaching, plugin unarchiving, etc, etc.
With such patches Jenkins starts up in few seconds with configuration-as-code and dozens of bundled plugins.

So, how to build custom Jenkinsfile Runner images?
Although there is no release so far, it is not something which can stop us as you see above.

##...
## WAR Configuration from above
##...

buildSettings:
  jenkinsfileRunner:
    source:
      groupId: &quot;io.jenkins&quot;
      artifactId: &quot;jenkinsfile-runner&quot;
      build:
        noCache: true
      source:
        git: https://github.com/jenkinsci/jenkinsfile-runner.git
        commit: 8ff9b1e9a097e629c5fbffca9a3d69750097ecc4
    docker:
      base: &quot;jenkins/jenkins:2.138.2&quot;
      tag: &quot;onenashev/cwp-jenkinsfile-runner-demo&quot;
      build: true

You can find a Demo of Jenkinsfile Runner packaging with Custom WAR Packager
here.

More info

There are many other features which are not described in this blogpost.
For example, it is possible to alter Maven build settings or to add/replace libraries within the Jenkins core (e.g. Remoting).
Please see the Custom WAR Packager documentation for more information.
There are a number of demos available in the repository.

If you are interested to contribute to the repository,
please create pull requests and CC @oleg-nenashev
and Raul Arabaolaza who is the second maintainer now working on Jenkins test automation flows.

What’s next?

There are still many improvements that could be made to the tool to make it more efficient:

Add upper bounds checks for transitive plugin dependencies so that the conflicts are discovered during the build

Allow passing all kinds of system properties and Java options via configuration YAML

Improve Jenkinsfile Runner to improve performance

Integrate the tool into Jenkins Integration test flows
(see essentialsTest()
in the Jenkins Pipeline library)

Many other tasks could be implemented in Custom WAR Packager,
but even now it is available to all Jenkins users so that they can build their own Jenkins bundles with it.

Want to know more?

If you are going to DevOps World - Jenkins World in Nice on Oct 22-25,
I will be presenting Custom WAR Packager at the Community Booth during the lunch demo sessions.
We will be also repeating our A Cloud Native Jenkins talk together with Carlos Sanchez where we will show how Ephemeral Jenkins works with Pluggable Storage.
Jenkins X team is also going to present their project using Custom WAR Packager.

Come meet Oleg and other Cloud Native SIG members at
DevOps World - Jenkins World on October 22-25 in Nice.
register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tools">tools</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/10/18/contributor-summit-summary/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">18</div></div><h5 class="title">What to Expect at the Jenkins Contributor Summit</h5></div><p class="teaser">The Jenkins Contributor summit is where the current and future contributors of the Jenkins project get together.
This summit will be on Tuesday, October 23rd 2018 in Nice, France just before Jenkins World.
What should those planning on joining expect at the event?
Earlier this year in September we had a contributor summit in San Francisco which gave us a pretty good outline of what to expect.
First of all it was one of the biggest contributor summits ever with lots of first-time attendees.

Morning

There are plenty of exciting developments happening in the Jenkins community, which meant there was a packed program.
One of the most anticipated updates was Kohsuke Kawaguchi speaking about Jenkins Shifting Gears.

There were also updates on the &#x27;5 Jenkins Superpower&#x27; projects in active development:

Jenkins Evergreen

Jenkins X

Configuration as Code

Jenkins Pipeline

Cloud Native Jenkins

As ever Jenkins is a community driven by its members so it was also great to get an update on Google Summer of Code.

Birds-of-a-feather (BoF)

After a packed morning of updates, it was time for a break and some lunch.
After lunch attendees divided up into groups and gathered around tables for unconference style discussions of specific areas.
Each table ran differently: some had demos, some did presentations, some hacked on code and others brainstormed ideas.
There was definitely alot of energy in the room and huge exchange of ideas.

Ignite Talks &amp; Wrap-up

To finish off the session we had a set of ignite talks.
Attendees were invited to volunteer on the day - no easy task given the pressure involved- and many did.
Hats off to Liam Newman, Mandy Hubbard, Eric Smalling, Pui Chee Chan, Martin d’Anjou and Vishal Raina for getting out of their comfort zone and doing talks.
There were two surprise ignite talks, one for James Strachan and one for Kohsuke Kawaguchi which were highly entertaining gave the audience lots of laughs.
Someone even captured KK’s talk on video.  The sound isn’t great but it was a truly visionary talk:

Finally the event finished with swag presentations and a fun Kahoot quiz to wrap things up.

Contributor Appreciation Event

After the summit, contributors were invited to join at the after party at Spin.
Spin was a unique venue in San Francisco where attendees could socialise and also play ping-pong!
While some took it seriously most enjoyed the relaxed way to get to know their fellow contributors.

See you in Nice

The event was a lot of fun and the contributor summit in Nice will follow a very similar structure.
All levels of contributor are welcome, there will be lots of opportunity for in-depth discussions and you can even do an ignite talk!
While we won’t be repeating the ping pong event there will be something equally unique to follow on from the summit.

Attending is free, and no DevOps World | Jenkins World ticket is needed, but RSVP if you are going to attend to help us plan.
See you there!

As long as you’re in Nice for the Contributor Summit,
join Tracy, Kohsuke, and hundreds of other Jenkins users at
DevOps World - Jenkins World on October 22-25.
Register with the code JWFOSS for a 30% discount off your pass.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-world">jenkins-world</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/11/13/martinda-gsoc-mentor-summit-experience/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">13</div></div><h5 class="title">Google Summer of Code Mentor Summit 2018</h5></div><p class="teaser">This year, the Jenkins organization participated in the Google Summer of Code Mentor Summit
at the Google office in Sunnyvale on Oct 12, 13 and 14, 2018.
The GSoC Mentor Summit is where mentors of all organizations participating in the GSoC program are invited each year
to learn and network with mentors from other organization, and make GSoC a better program.
This is the second time Jenkins mentors have participated in the summit, the first time was in 2016.

Exceptionally, three Jenkins GSoC mentors were invited to the summit this year.
Normally only two mentors are invited, but when there are cancellations, Google draws a name at random from the waiting list,
and the Jenkins organization was lucky enough and sent an extra mentor this year!
The mentors participating this year were Oleg Nenashev, Jeff Pearce and Martin d’Anjou.

It is worth mentioning that the Mentor Summit is not a typical conference where you go
sit and listen at what speakers have to say, quite the contrary. The Mentor Summit is an unconference
where participants are invited to fill empty time slots with their own topic of discussion.

Friday Oct 12

Pre-conference meeting

The mentors had a short pre-conference meeting to reflect on the Jenkins participation in the 2018 GSoC program,
and to plan for 2019.
We were joined at this meeting by Lloyd Chang, whom we had met at Jenkins World 2018.
Thank you Lloyd for joining us! A few ideas we had for 2019 are:

Move project proposals to individual Google Documents

Create a template for project proposed by potential mentors and by project champions

Create an Organization Administrator Guide for future Jenkins GSoC project admins

Other preparations we agreed to work on include a review of the 2018 feedback and the creation
of an Epic capturing the action items in preparation for 2019.
We are also planning on making progress on the GSoC Budget process described in JEP-8.

Summit Starts!

The summit started by a welcoming dinner at the Google Cafeteria and an evening session
where we were explained how the unconference would work. We proposed a few topics:
dealing with CPT lost slots, motivating mentors, and Open Source Hardware ASIC/FPGA.

On thing to say is that everyone at the conference had heard of Jenkins, or was already using Jenkins.
Lots of people came to tell us their Jenkins experience.

I noticed this too - made me feel proud to be part of the Jenkins project.

— Jeff Pearce
Jenkins GSoC mentor in 2018

Saturday Oct 13

The morning started with a couple of announcements from Google.
The first one was that Google is thinking of creating a program called &quot;Google Season of Docs&quot; (GSoD for short),
where technical writers would be paired with Open Source Organizations to help them write documentation such as:

High-impact tutorials

Set of How-To Guides

Contributor’s Guide

Documentation refactoring

Plain documentation

We have additional details regarding this in the
GSoC Mentor Summit Notes
and we quickly concluded that if this program comes to life, Jenkins should be a participating organization.

The other announcement made by the GSoC administrators is that GSoC may take a different form in 2020.
However, not much more information has been made available at this time.
The program has been operating for 13 years, and in 2020 it will have been 15 years.

The announcements were followed by a series of morning lightning talks.
This is where organizations showcase what their students accomplished during the program.
This is when we had a bit of a surprise…​

Oleg who had signed up for the evening lightning talks, was watching the talks while casually preparing slides for his evening presentation.
But something unusual happened: many talks were shorter than the 3-minute allotted, and suddenly we were ahead of schedule.
That’s when Oleg was called to the stage.
I had no idea whether his slides were ready or not since he had just leaned over to me to say that he wanted to talk about all 3 projects we had this year.
Not knowing how far he had gotten into refactoring the slides, this was going to be…​ interesting.
Being an experienced presenter, Oleg pulled it off brilliantly.
The slides were effectively ready (how he managed that I have no idea),
but you can see the slides of his lightning talk here:
Jenkins Remoting over Apache Kafka.

Then there were the unconference sessions. Some of the sessions we attended are:

Documentation

Attracting and retaining mentors (facilitated by Martin)

Organizing and motivating volunteers and mentors

Getting students from coding/boot camps involved in open source

Retaining students after GSoC

Open Event management System

GSoC Feedback

We have notes for all the session in the main document.
Some sessions were captured in separated documents which are linked from the main document, or from this blog post.

There were lots of good ideas in those sessions, and we will do what we can next year to implement some of them.

Some organizations have said that the key for student retention
is to give them responsibilities and tasks after the program is over.
We have certainly seen that this year, with one of our students asking for more responsibilities and wanting to know how
his plugin project could continue to grow within the Jenkins project (while at the same time help out on another GSoC plugin!).

In the evening was the second round of lightning talks.
Jeff Pearce presented the Code Coverage API Plugin lightning talk,
(he was not caught by surprise).

After the lightning talks, we were invited to hang out at the cafeteria and on the patio, to exchange stickers,
network with mentors of other organizations, and enjoy late evening snacks, music and of course the chocolate table!

Sunday Oct 14

On Sunday, the sessions continued. An interesting session was &quot;Beyond GSoC, What can Google do?&quot;.
One person got a big round of applause when he said: &quot;Cloud credits&quot;. It turns out the GSoC program admins
have been trying to get that for us for about 3 years. Google may be big and powerful, but some things
are hard and remain hard in the corporate world.

An interesting suggestion was made by Oleg, and it would be to have a program with smaller, shorter term
commitments, something that would encourage more granular contributions but would not require a 4-month
long commitment. This was noted by the GSoC program admins.

Then we attended a number of sessions:

Open Hardware ASIC/FPGA (facilitated by Martin)

Community Metrics

Outreachy (Jenkins is participating in this program)

Failing a student

Burnout (of mentors and org admins)

Then the day came to an end with some last words by Google thanking all the mentors and volunteers who
run this program in their organizations.

Return trip

I would now like to add a personal note. After the summit, like many others I fly back home,
so I spend the evening at the SFO international terminal waiting for my late night flight.
That is where I get to meet more mentors, as some of us still wear our badges and T-Shirts,
and also recognize each other from being at the conference.
And funny enough, there are so many geeks at that terminal
that we may have recruited, among the passengers, a mentor to another org for next year!

Want a GSoC student to work on your project in 2019?

We have already started the preparations for GSoC 2019.
And we cannot do this without the participation of the Jenkins community.
We are already looking for:

Mentors from the Jenkins Special Interest Groups

Mentors from any background and any provenance (being a Jenkins developer is NOT required)

Project proposals

Students and their proposals

Lots of people are afraid that mentoring a student will take a lot of their time.
If you feel that way, you are not alone. It does take some time. In my case, I spend 5 to 8 hours per week on mentor tasks (more at the start, less at the end).
To make it easier on mentors who likely have full time jobs and life commitments, we define different mentor roles:

Project champion co-mentor : this is the mentor who proposes the idea, but may not have all the Jenkins code expertise needed. This mentor works with the student to define the project and acts mostly as a &quot;customer&quot; of the project. This mentor usually know enough about coding to comment on pull-requests with regards to the over quality, style and features of the code.

Technical co-mentor : this is the mentor who knows enough about the Jenkins code to guide the student on coding, and to provide Jenkins specific code reviews on pull-requests, but has limited involvement outside the coding activity of the student.

There is a third role which is:

Subject Matter Expert : these individuals are not mentors, but we reach out to them 3-4 times during the project for advice and guidance, and sometimes complicated programming challenges.

If you have questions or are curious about the program,
contact us on the GSoC Gitter SIG chat.

We would like to emphasize that project proposals are not limited to &quot;big projects&quot;.
For example, it is perfectly fine to have a proposal that is a collection of related Jira issues that aim to improve your project,
or a list of tasks that need to be done for your project.
Writing documentation is outside the scope of GSoC, but automating
documentation generation, as long as it is mostly about writing code, is within the scope of GSoC.

We look forward working with the Jenkins community on GSoC 2019!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/martinda/">Martin d&#x27;Anjou</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2018">gsoc2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/11/07/Validate-Jenkinsfile/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 7</div></div><h5 class="title">Validate your Jenkinsfile from within VS Code</h5></div><p class="teaser">In my daily work I often have to create or modify Jenkinsfiles and more often than I would like, I make mistakes. It is a very tedious workflow when you make a change to your Jenkinsfile, create a commit, push the commit and wait for your Jenkins Server to tell you, that you have missed a bracket.

The Command-line Pipeline Linter ( https://jenkins.io/doc/book/pipeline/development/) does a great job of reducing the turnaround times when writing a Jenkinsfile, but its usage has its own inconveniences. You need tools like curl or ssh to make a connection to your Jenkins Server and you need to remember the correct command to validate your Jenkinsfile. I still did not like the solution.

As VS Code is my daily driver, I started to look at writing extensions for it and out of it came a little extension which makes validating Jenkinsfiles just a little bit more comfortable.

What the &#x27;Jenkins Pipeline Linter Connector&#x27; does is, that it takes the file that you have currently opened, pushes it to your Jenkins Server and displays the validation result in VS Code.

​You can find the extension from within the VS Code extension browser or at the following url: https://marketplace.visualstudio.com/items?itemName=janjoerke.jenkins-pipeline-linter-connector

The extension adds four settings entries to VS Code which you have to use to configure the Jenkins Server you want to use for validation.

jenkins.pipeline.linter.connector.url is the endpoint at which your Jenkins Server expects the POST request, containing your Jenkinsfile which you want to validate. Typically this points to /pipeline-model-converter/validate&quot; class=&quot;bare&quot;&gt;http:// /pipeline-model-converter/validate .

jenkins.pipeline.linter.connector.user allows you to specify your Jenkins username.

jenkins.pipeline.linter.connector.pass allows you to specify your Jenkins password.

jenkins.pipeline.linter.connector.crumbUrl has to be specified if your Jenkins Server has CRSF protection enabled. Typically this points to /crumbIssuer/api/xml?xpath=concat(//crumbRequestField,%22:%22,//crumb&quot; class=&quot;bare&quot;&gt;http:// /crumbIssuer/api/xml?xpath=concat(//crumbRequestField,%22:%22,//crumb).
​<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/janjoerke/">Jan Jörke</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsfile">jenkinsfile</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/validation">validation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/vscode">vscode</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline authoring">pipeline authoring</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/development">development</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/11/12/inspecting-binaries-with-jenkins/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">12</div></div><h5 class="title">The Silence of the Lambs: Inspecting binaries with Jenkins</h5></div><p class="teaser">In a past blog post,
Delivery Pipelines, with Jenkins 2, SonarQube, and Artifactory,
we talked about pipelines which result in binaries for development versions, and in
Delivery pipelines, with Jenkins 2: how to promote Java EE and Docker binaries toward production,
we examined ways to consistently promote applications toward production. In this blog post, I continue on both by discussing more details on security related quality gates
and bringing this together with the handling of Docker images.

Use case: Foster security on given, containerized business application

Security is an overloaded term with varying meaning in different contexts. For this contribution, I consider security as the sum of rules regarding vulnerabilities
(Common Vulnerability and Exposure, CVE), in binaries. In a past blog post, we’ve identified SonarQube already, as a very helpful tool to identify flaws
in source code, particularly concerning reliability (bugs), vulnerabilities (security, e.g. CWE, that is common weakness enumaration, and OWASP, that is the Open Web Application Security Project), and
maintainability (code smells). Now it is a good time to add another tool to the chain, that is Twistlock, for inspection binaries for security issues.
Features of Twistlock include

Compliance and vulnerability management, transitively

Runtime defense

Cloud-native CI/CD support

Broad coverage of supported artifact types and platforms

API, dashboards, and Jenkins integration, with strong configuration options

The underlying use case can be derived from several real-world security initiatives, in enterprises, based on given containerized applications. In practice, it is not a surprise that after adding such new
quality gates, you identify historically grown issues. However, there are many good reasons to do so. You don’t need any Word documents to check any governance criteria manually, rather
execution and reporting are done automatically and also part of the actions are taken automatically. And above all, of course, your application is quality assured regarding known vulnerability issues, aligned with
the DevOps approach: development is interested in quick feedback whether their change would introduce any vulnerabilities, and operations is interested in insights whether and
how running applications are affected if a new CVE is discovered.

The term DevSecOps was coined to explicitely add security concerns to DevOps.
In my opinion, security is already inherent part of DevOps.
Thus, there is no strong reason to introduce a new word. Surely, new words are catchy.
But they have limits.
Or have you ever experienced NoDev, the variant of DevOps where features are suddenly falling from the sky and deployed to production automatically?

Conceptually, container inspection is now part of the delivery pipeline and Twistlock processing is now triggered once we have produced our Docker images, see below, in order to get
fast feedback.

Software is staged over different environments by configuration, without rebuilding. All changes go through the entire staging process, although defined
exception routines may be in place, for details see Michael Hüttermann, Agile ALM (Manning, 2012). The staged software consists of all artifacts which
make up the release, consistently, including the business application, test cases, build scripts, Chef cookbooks, Dockerfiles, Jenkins files to build all
that in a self-contained way, for details see Michael Hüttermann, DevOps for Developers (Apress, 2012).

This blog post covers sample tools. Please note, that there are also alternative tools available, and the best target architecture is aligned with concrete requirements and given basic
conditions. Besides that, the sample toolchain is derived from couple of real world success stories, designed and implemented in the field. However, this blog post
simplifies and abstracts them in order to stay focussed while discussing the primitives of delivery units. For example, aggregating multiple Docker images with ASCII files, does not change the
underlying primitives and their handlings. For more information on all parts of the blog post, please consult the respective documentation, good books or attend fine conferences. Or go to the extremes: talk to your colleagues.

In our sample process, we produce a web application that is packaged in a Docker image. The produced Docker images are distributed only if the dedicated quality gate passes.
A quality gate is a stage in the overall pipeline and a sum of defined commitments, often
called requirements, the unit of work must pass. In our case, the quality gate comprises inspection of produced binaries and it fails if vulnerabilities of severity &#x27;critical&#x27; are found.
We can configure Twistlock according to our requirements. Have a look how we’ve integrated it into our Jenkins pipeline, with focus on detecting vulnerabilities.

Jenkinsfile (excerpt): Twistlock inspection triggered

stage(&#x27;Twistlock: Analysis&#x27;) { (1)
String version = readFile(&#x27;version.properties&#x27;).trim() (2)
println &quot;Scanning for version: ${version}&quot;
    twistlockScan ca: &#x27;&#x27;, cert: &#x27;&#x27;, compliancePolicy: &#x27;critical&#x27;, \
        dockerAddress: &#x27;unix:///var/run/docker.sock&#x27;, \
        ignoreImageBuildTime: false, key: &#x27;&#x27;, logLevel: &#x27;true&#x27;, \
        policy: &#x27;critical&#x27;, repository: &#x27;huttermann-docker-local.jfrog.io/michaelhuettermann/alpine-tomcat7&#x27;, \ (3)
requirePackageUpdate: false, tag: &quot;$version&quot;, timeout: 10
}

stage(&#x27;Twistlock: Publish&#x27;) { (4)
String version = readFile(&#x27;version.properties &#x27;).trim()
    println &quot;Publishing scan results for version: ${version}&quot;
    twistlockPublish ca: &#x27;&#x27;, cert: &#x27;&#x27;, \
        dockerAddress: &#x27;unix:///var/run/docker.sock&#x27;, key: &#x27;&#x27;, \
        logLevel: &#x27;true&#x27;, repository: &#x27;huttermann-docker-local.jfrog.io/michaelhuettermann/alpine-tomcat7&#x27;, tag: &quot;$version&quot;, \
        timeout: 10
}

1
Twistlock inspection as part of the sequence of stages in Jenkinsfile

2
Nailing down the version of the to be inspected image, dynamically

3
Configuring analysis including vulnerability severity level

4
Publishing the inspection results to Twistlock console, that is the dashboard

Now let’s start with the first phase to bring our application in shape again, that is gaining insight about the security related flaws.

Phase 1: Gain insights about security related flaws

After we’ve introduced the new quality gate, it failed, see image above. As integration with other tools, Jenkins is the automation engine and does provide helpful context information,
however, those cannot replace features and data the dedicated, triggered tool does offer. Thus, this is the moment to switch to the dedicated tool, that is Twistlock. Opening
the dashboard, we can navigate to the Jenkins build jobs, that is the specific run of the build, and the respective results of the Twistlock analysis. What we see now is a list
of vulnerabilities, and we need to fix those of severity critical in order to pass the quality gate, and get our changes again toward production. The list shows entries of
type jar, that is a finding in a binary as part of the Docker image, in our case the WAR file we’ve deployed to a web container (Tomcat), and of type OS, those are issues of the underlying image itself, the
operating system, either part of the base image, or as a package added/changed in our Dockerfile.

We can now easily zoom in and examine the vulnerabilities of the Docker layers. This really helps to structure work and identify root causes. Since, typically,
a Docker image extends a Docker base image, the findings in the base image are shown on the top, see next screenshot, grouped by severity.

Other Docker layers were added to the base image, and those can add vulnerabilities too. In our case, the packaged WAR file obviously contains a vulnerability. The next image shows how we examine that finding, while this time
expanding the Twistlock wizard (that is the plus sign) to directly see the list of found vulnerabilities.

Finding and visualizing the issues are a very good first step, and we’ve even made those findings actionable, so we now have to take action and address them.

Phase 2: Address the findings

To address the findings, we need to split our initiative into two parts:

Fixing the critical vulnerabilities related to the Docker image (in our case largely the base image)

Fixing the critical vulnerabilities related to the embedded deployment unit (in our case the WAR)

Let’s proceed bottom up, first coping with the Docker base image.

This is an easy example covering multiple scenarios particularly identifying and fixing vulnerabilities in transitive binaries, i.e. binaries contained in
other binaries, e.g. a Docker image containing a WAR file that in turn contains libraries. To expand this vertical feasibility spike, you can easily add
more units of each layer, or add more abstractions, however, the idea can always be nailed down to the primitives, covered in this blog post.

Let’s now have a look at the used Docker image by looking at the used Dockerfile.

Dockerfile: The Dockerfile based on Alpine, running OpenJDK 8

FROM openjdk:8-jre-alpine (1)
LABEL maintainer &quot;michael@huettermann.net&quot;

# Domain of your Artifactory. Any other storage and URI download link works, just change the ADD command, see below.
ARG ARTI
ARG VER

# Expose web port
EXPOSE 8080

# Tomcat Version
ENV TOMCAT_VERSION_MAJOR 9 (2)
ENV TOMCAT_VERSION_FULL  9.0.6

# Download, install, housekeeping
RUN apk add --update curl &amp;&amp;\ (3)
apk add bash &amp;&amp;\
  #apk add -u libx11 &amp;&amp;\ (4)
mkdir /opt &amp;&amp;\
  curl -LO ${ARTI}/list/generic-local/apache/org/tomcat/tomcat-${TOMCAT_VERSION_MAJOR}/v${TOMCAT_VERSION_FULL}/bin/apache-tomcat-${TOMCAT_VERSION_FULL}.tar.gz &amp;&amp;\
  gunzip -c apache-tomcat-${TOMCAT_VERSION_FULL}.tar.gz | tar -xf - -C /opt &amp;&amp;\
  rm -f apache-tomcat-${TOMCAT_VERSION_FULL}.tar.gz &amp;&amp;\
  ln -s /opt/apache-tomcat-${TOMCAT_VERSION_FULL} /opt/tomcat &amp;&amp;\
  rm -rf /opt/tomcat/webapps/examples /opt/tomcat/webapps/docs &amp;&amp;\
  apk del curl &amp;&amp;\
  rm -rf /var/cache/apk/*

# Download and deploy the Java EE WAR
ADD http://${ARTI}/list/libs-release-local/com/huettermann/web/${VER}/all-${VER}.war /opt/tomcat/webapps/all.war (5)

RUN chmod 755 /opt/tomcat/webapps/*.war

# Set environment
ENV CATALINA_HOME /opt/tomcat

# Start Tomcat on startup
CMD ${CATALINA_HOME}/bin/catalina.sh run

1
Base image ships OpenJDK 8, on Alpine

2
Defined version of web container

3
Applying some defined steps to configure Alpine, according to requirements

4
Updating package itself would address one vulnerability already

5
Deploying the application

By checking available versions of the official OpenJDK Alpine image, we see that there’s a newer version 8u181 which we could use.
We can zoom in and study release notes and contents, or we just pragmatically switch the base image to a more recent version. Often it is a good idea
to upgrade versions regularly, in defined intervals. This leads to the following change in the Dockerfile.

Dockerfile (excerpt): The Dockerfile based on Alpine, running OpenJDK 8u181

FROM openjdk:8u181-jre-alpine (1)
LABEL maintainer &quot;michael@huettermann.net&quot;

1
Base image is now OpenJDK 8u181, on Alpine

There are more options available to fix the issues, but let’s proceed to the second part, the vulnerabilities in the deployment unit.

Before we push this change to GitHub, we also address the vulnerability issue in the deployment unit, that is jetty-io. Here we are a bit unsure about
why, in this specific use case, the library is used. To retrieve more information about dependencies, we run a dependency:tree command on our Maven
based project. We now see that jetty-io is transitively referenced by org.seleniumhq.selenium:htmlunit-driver. We can surely discuss why this is a compile
dependency and the libraries are shipped as part of the WAR, but let’s consider this to be given according to requirements, thus we must take special attention now
to version 2.29.0 of the specific library.

Also here we can browse release notes and content (particularly how those libs are built themselves), and come to the conclusion to
switch from the used version, that is 2.29.0, to a newer version of htmlunit-driver, that is 2.31.1.

pom.xml (excerpt): Build file

(1)

org.seleniumhq.selenium
selenium-java
3.14.0

org.seleniumhq.selenium (2)
htmlunit-driver
2.31.1

junit
junit
4.7

1
Part of the underlying POM defining dependencies

2
Definition of the dependency, causing the vulnerability finding; we use a newer version now

OK, now we are done. We push the changes to GitHub, and our GitHub webhook directly triggers the workflow. This time the quality gate passes, so it
looks like our fixes did address the root causes and eliminated those with the configured threshold severity.

Finally, after running through our entire workflow, that is made up of different pipelines, our inspected and quality assured container does successfully
run in our production runtime environment, that is on Oracle Cloud.

Crisp, isn’t it?

Summary

This closes our quick walkthrough of how to inject security related quality gates into a Jenkins based delivery pipeline.
We’ve discussed some concepts and how this can look like with sample tools.
In the center of our efforts, we used Jenkins, the swiss army knife of automation.
We enriched our ecosystem by integrating couple of platforms and tools, above all Twistlock.
After this tasty appetizer you are ready to assess your own delivery pipelines,
concepts and tools, and to possibly invest even more attention to security.

References

&#x27;Agile ALM&#x27;, Manning, 2011

&#x27;DevOps for Developers&#x27;, Apress, 2012

Docker, the standard to develop and ship set of changes

Docker images, shipping OpenJDK

Oracle Cloud Infrastructure, for containers

Alpine Linux

SonarQube, the language/platform agnostic Continuous Inspection tool

Twistlock, the container security platform

Sources on GitHub

ASCII, commonly used standard to work on primitives, such as Docker (and their aggregations)

Common Vulnerabilities and Exposures

Holistic pipelines, Live 15-minute Jenkins Demos, Part 1, on YouTube

Holistic pipelines, Live 15-minute Jenkins Demos, Part 2, on YouTube

Delivery Pipelines, with Jenkins 2, SonarQube, and Artifactory

Delivery pipelines, with Jenkins 2: how to promote Java EE and Docker binaries toward production<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelhuettermann/">Michael Hüttermann</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devops">devops</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devsecops">devsecops</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/vulnerabilities">vulnerabilities</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/compliance">compliance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/twistlock">twistlock</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/05/security-updates/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 5</div></div><h5 class="title">Important security updates for Jenkins</h5></div><p class="teaser">We just released security updates to Jenkins, versions 2.154 and LTS 2.150.1, that fix multiple security vulnerabilities.
Since 2.150.1 is the first release in the new LTS line, we also released 2.138.4, a security update for the previous LTS line.
This allows administrators to install today’s security fixes without having to upgrade to the new LTS line immediately.

For an overview of what was fixed, see the security advisory.
For an overview on the possible impact of these changes, see our LTS 2.138.4 upgrade guide.

A note on previously released changes related to this fix

In the Jenkins core security updates released in August and October, we also included security improvements that can be disabled by setting various system properties.
Those changes are an essential part of the SECURITY-595 fix, so we strongly recommend not disabling them for any reason.
Previously published documentation has been updated.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/10/kubecon-is-here/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">10</div></div><h5 class="title">KubeCon + CloudNativeCon North America 2018 is Here!</h5></div><p class="teaser">The time has come - KubeCon + CloudNativeCon North America 2018 has arrived.
The conference has completely sold out and the schedule is jam packed with interesting talks.

If you’re among those with tickets, here are a couple Jenkins related events that might interest you:

On Wednesday at 3:40pm, Carlos Sanchez will be presenting
Jenkins X: Continuous Delivery for Kubernetes in
Tahoma 3/4 @ TCC.

On Tuesday at 2:35pm, Jonathan Hess &amp; Loren Trout from
SAP will discuss how
Migrating Jenkins to Kubernetes Broke Our Brains in Room 606-609.

I look forward to seeing you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubecon">kubecon</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/10/outreachy-audit-log-plugin/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">10</div></div><h5 class="title">Outreachy internships to add audit logging support to Jenkins</h5></div><p class="teaser">This year marks the first time the Jenkins project is participating in Outreachy.
Outreachy is a program similar to Google Summer of Code (GSoC) where interns work on open source projects for a paid stipend.
The key difference is that Outreachy reaches out to underrepresented groups and those who face systemic bias or discrimination in the technology industry in their home country.
Once I learned about this program, I immediately volunteered to mentor as the concept strongly aligns with my ideals of inclusiveness and community building.
I’m happy to report that both the Jenkins project,  and my employer [CloudBees]( https://www.cloudbees.com), have been very supportive of this program.

Expanding on our previous efforts to mentor students in GSoC, this year we’ve joined up with Outreachy to mentor two interns.
Our interns for this season of Outreachy, Latha Gunasekar and David Olorundare, will be working with me on audit logging support for Jenkins.
I am excited to welcome both David and Latha, and am looking forward to what they will learn about both professional software engineering and contributing to an open source community.
Stay tuned for blog post entries introducing both people in the near future.

The audit logging support project forms a new connection between Jenkins and Apache Log4j which offers great opportunities for our interns to learn more about open source governance and meet new people.
As a bonus, the project aims to provide the tooling necessary to support advanced observability concerns such as running anomaly detection on authentication events to detect potential intrusion attempts.
We will also be authoring a JEP to detail the audit logging API provided by the plugin and how other plugins can define and log their own audit events besides the Jenkins Core ones that come with the plugin.

I’m looking forward to the great work we’ll be doing together, and I hope that we’ll be able to welcome more Outreachy interns in the future!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jvz/">Matt Sicker</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreachy">outreachy</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreachy2018">outreachy2018</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/10/the-official-Docker-image/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">10</div></div><h5 class="title">Official Jenkins image to use from Docker Hub</h5></div><p class="teaser">There are now three different Docker Hub repositories that are or have been used as the &quot;official&quot; Jenkins image.
This article aims at providing a clarification about which one is the current official one (as of December 2018 :-)).

The official one

docker pull jenkins/jenkins

i.e. https://hub.docker.com/r/jenkins/jenkins/ is the right repository to use.

I also documented some time ago on my blog the recommended way to run Jenkins using the official Docker image.

The deprecated ones

jenkins

Deprecated since a long time already.
A short version of why we stopped using and updating this image is that we never had a way to get our images published without having each time to go through a manual process.

jenkinsci/jenkins

Deprecated since a long time too, but for easing transition, we had kept updating both jenkins/jenkins (the right one) and jenkinsci/jenkins together.
We stopped updating jenkinsci/jenkins in early December 2018 (cf. INFRA-1934 for details if you are interested)

Thanks for reading!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/14/java11-preview-availability/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">14</div></div><h5 class="title">Java 11 Support Preview is available in Jenkins 2.155+</h5></div><p class="teaser">Please refer to Running Jenkins on Java 11 documentation to have the up-to-date details on how to run Jenkins on Java 11.

This is a joint blogpost prepared by the Java 11 Support Team.
On Dec 18 (4PM UTC) we will be also presenting the Java 11 Preview Support at the Jenkins Online Meetup
( link)

Jenkins, one of the leading open-source automation servers, still supports only Java 8.
On September 25 OpenJDK 11 was released.
This is a Long-Term-Support which will stay around for years,
and in the Jenkins project we are interested to offer a full support of this version.
Over the last year many contributors have been working towards enabling support for Java 11 in the project (Jenkins JEP-211).
It was a thorny path,
but now, on behalf of the Jenkins Platform SIG,
we are happy to announce preview availability of Java 11 support in Jenkins weekly releases!

Why do we need preview availability for Java 11?
It offers Jenkins contributors and early adopters a way
to try out the changes before the general availability release happens early next year.
It should help us to get more exploratory testing and, hopefully,
resolve most of the issues before Java 11 is officially supported in Jenkins.

In this blog post we will describe how to run with Java 11,
and how to investigate compatibility issues and report them.

Background

As you probably remember,
in June 2018 we had an online hackathon targeting Java 10+ support in Jenkins.
As a part of the hackathon,
we provided the experimental support of Java 11.
This event was a big success for us,
and we were able to get Jenkins running with Java 10 and 11-ea,
including major features like Jenkins Pipeline, JobDSL, Docker/Kubernetes plugins, Configuration as Code, BlueOcean, etc.
It gave us confidence that we can provide Java 11 support in Jenkins without major breaking changes.
After the hackathon, Oleg Nenashev created
jep:211[&quot;Java 10+ support in Jenkins&quot;] (was later adjusted to target Java 11 only).
Platform Special Interest Group
has been also founded to coordinate the Java 11 support work
and other platform support efforts (packaging, operating system support, etc.).

A group of contributors continued working on Java 11 support,
mostly focusing on upstreaming functional patches,
enabling Java 11 support in development tools,
testing and addressing known compatibility issues.
See the Platform SIG meeting notes for detailed status updates.
Starting from Jenkins 2.148, Jenkins successfully runs with latest OpenJDK 11 releases on various Linux and Windows platforms.
We performed a LOT of automated and exploratory tests, Jenkins plugins appear to work well with some exceptions (see below).
There is ongoing test automation effort towards the GA releases,
but we were able to successfully run Jenkins core tests,
full Acceptance Test Harness,
and Plugin Compat Tester for recommended plugins.
We also deployed a temporary
Experimental Update Center for Java 11
which allows quickly delivering fixes for Java 11 early adopters.
Jenkins 2.155+ defaults to this update center when running with Java 11,
and that’s why we announce preview availability for this version.

On Nov 19, 2018 we presented the current Java 11 support status at the Platform SIG meeting
slides,
and we agreed that we would like to proceed with the preview availability so that
we can offer something for evaluation to Jenkins users.
By the next meeting on Dec 04, all blockers have been addressed,
and the Platform SIG meeting signed off the Java 11 preview availability.

Running Jenkins and Java 11 in Docker

Starting from Jenkins 2.155, we provide Docker images for the Jenkins controller and agent.
All these images are based on the official
openjdk:11-jdk image maintained by the Docker Community.
There were discussions about migrating to other base images,
but we decided to exclude it from the Preview Availability scope.
Similarly, we do not provide Alpine images for now.

Jenkins controller image

Java 11 support is now provided as a part of the official
jenkins/jenkins image.
You can run the Jenkins with Java 11 simply as:

docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins:jdk11

The following tags are available:

jdk11 - Latest weekly release with Java 11 support

2.155-jdk11 - Weekly releases packaged with Java 11

The image is fully compatible with
jenkins/jenkins documentation,
e.g. you can use plugins.txt to install plugins, mount volumes and pass extra options via environment variables.

Agent images

If you use containerized agents via Docker or Kubernetes plugins,
we have also released official Docker images for Jenkins agents:

jenkins/agent

jenkins/inbound-agent

jenkins/ssh-build-agent

All images use the latest-jdk11 image tag for JDK11 bundles.
And sorry for the obsolete names!

Experimental Jenkins controller images

In order to simplify testing, we also provide some experimental images on DockerHub.
We set up a continuous delivery flow for them,
so you can get patches without waiting for Jenkins weekly releases.

jenkins4eval/blueocean-platform-support -
Equivalent of jenkinsci/blueocean

Tag: latest-jdk11

The image bundles all Jenkins Pipeline and Blue Ocean patches required to run on Java 11

If you want to try Pipeline, use this image

jenkins/jenkins-experimental -
Equivalent of jenkins/jenkins

Tag: latest-jdk11

The image is released from the java11-support feature branch in the Jenkins core

The branch may be slightly ahead or behind the master branch,
we may use the branch to quickly deliver patches to Java 11 users

Eventually we will move the experimental flow to the new jenkins4eval organization
being created as a part of jep:217[].

Running jenkins.war with Java 11

Running without Docker is not that trivial,
because Jenkins depends on some modules which have been removed from Java 11.
We plan to address it in the General Availability release somehow (see jira:JENKINS-52186[]),
but for now some manual actions are required to run Jenkins WAR with Java 11.

Download Jenkins WAR for 2.155

Download the following libraries to the same directory as jenkins.war

jaxb-api-2.3.0.jar (save as jaxb-api.jar)

jaxb-core-2.3.0.1.jar (save as jaxb-core.jar)

jaxb-impl-2.3.0.1.jar (save as jaxb-impl.jar)

javax.activation v.1.2.0 (save as javax.activation.jar)

Run the following command:

Run Jenkins with ${JAVA11_HOME}/bin/java \
    -p jaxb-api.jar:javax.activation.jar --add-modules java.xml.bind,java.activation \
    -cp jaxb-core.jar:jaxb-impl.jar \
    -jar jenkins.war --enable-future-java --httpPort=8080 --prefix=/jenkins

Known compatibility issues

To help users to track down the compatibility issues,
we have created a new Known Java 11 Compatibility Issues Wiki page.

Several important issues and obstacles:

Pipeline: Support Plugin has a known issue
with context persistency when running with Java 11 (jira:JENKINS-51998[])

We have deployed a temporary fix to the
Experimental Update Center for Java 11.
 Fix version: 3.0-java11-alpha-1

If you use Jenkins Pipeline, make sure you run with this fix.
Otherwise the jobs will fail almost immediately

When updating instances to Java 11, make sure there is no running Pipelines

jira:JENKINS-54305[] -
JDK Tool Plugin does not offer installers for JDK 11

jira:JENKINS-52282[] -
Java Web Start is no longer available in Java 11, so it is no longer possible to start agents from Web UI.
We do not plan to provide a replacement.

We also know about some minor incompatibilities in other plugins,
but we do not consider them as blockers for preview availability.

Reporting compatibility issues

If you discover any Java 11 incompatibilities, please
report issues in our bugtracker.
Please set java11-compatibility labels for such issues
so that they automatically appear on the Wiki page and get triaged.

For the security issues please use the standard
vulnerability reporting process.
Although we will be fixing Java 11 specific issues in public while it is in the preview,
following the security process will help us to investigate impact on Java 8 users.

Java 11 Support Team

Once Java 11 support is released, we expect reports of regressions in plugins and Jenkins core.
One of the concerns are exotic platforms with native libraries, and of course other Java versions.
There is also a risk of 3rd-party library incompatibilities with Java 11.
To mitigate the risks, we have created a
Java 11 Support Team.
This team will be focusing on triaging the incoming issues,
helping to review pull requests and, in some cases, delivering the fixes.
The process for this team is documented in JEP-211.

We do not expect the Java 11 Support Team to be able to fix all discovered issues,
and we will be working with Jenkins core and plugin maintainers to get the fixes delivered.
If you are interested to join the team,
reach out to us in the Platform SIG Gitter Channel.

Contributing

We will appreciate any kind of contributions in the Java 11 effort,
including trying out Jenkins with Java 11, reporting and fixing compatibility issues.

If you want to do the exploratory testing,
we recommend to try out Java 11 support at one of your test instances.
Such testing will be much appreciated,
especially if you use some service integration plugins or exotic platforms.
The issue reporting guidelines are provided above

If you are a plugin developer/maintainer,
we would appreciate if you could test your plugin with Java 11.
In order to help with that, we have created a Wiki page with
Java 11 Developer guidelines.
This page explains how to build and test plugins with Java 11,
and it also lists known issues in development tools

Whatever you do, please let us know about your experience by sending a message to
the Platform SIG mailing list.
Such information will help us a lot to track changes and contributions.
Any other feedback about the migration complexity will be appreciated!

What’s next?

On Dec 18 (4PM UTC) we will be presenting the Java 11 Preview Support at the Jenkins Online Meetup
( link).
At this meetup we will summarize the current Java 11 Preview support status.
If you are a plugin developer, we will also organize separate sessions about testing plugins with Java 11 and about common best practices for fixing compatibility issues.
Please follow the Platform SIG announcements if you are interested.

In the next weeks we will focus on addressing feedback from early adopters and
fixing the discovered compatibility issues.
We will also continue working on Java 11 support patches towards the general availability next year (jira:JENKINS-51805[]).
In addition to that, we will start working on Java 11 support in subprojects,
including Jenkins X and Jenkins Evergreen.

Links

JEP-211: Java 11 support in Jenkins

Java requirements in Jenkins

Known Java 11 Compatibility Issues

Java 11 Developer guidelines

Platform Special Interest Group<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java11">java11</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/25/year-in-review/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">25</div></div><h5 class="title">2018 in Review: A year of innovation</h5></div><p class="teaser">The end of a year is a great time to step back from the daily grind to look at the big picture.

Across the industry, the relentless march toward more automation still continues on. We are writing software faster than ever, but the demand for software seems to be going up even more, and I feel more and more businesses and executives are keenly aware that software and developers are king. At the ground level, every team I meet sees the software delivery automation to be a critical part of their &quot;software factory,&quot; and it’s important for them to create and manage them with unhinged flexibility and visibility.

Jenkins continues to play a major role in making this possible, after 14+ years since its birth, and if anything the pace of growth seems to be accelerating. In this dog year industry, that’s truly remarkable. Being a part of this achievement truly makes me proud.

Building Jenkins, being a tool that everyone uses, comes with a great responsibility. So within the Jenkins community, we’ve been hard at work. In fact, 2018 has been the single most innovative year in the history of the whole project across the field, at multiple levels.

As we got bigger, we needed better ways to drive initiatives that cut across multiple people. This thinking led to JEPs and SIGs, and 2018 saw these formats getting great traction. After a year of operating them, I think we’ve learnt a lot, and I hope we will continue to improve them based on the learning.

These new formats gave rise to new collaborations. For example, Chinese Localization SIG resulted in our WeChat presence and localized website. Platform SIG was instrumental in Java 11 support.

I’m also very happy to see new batch of leaders. In fear of missing out some people, I’m not going to list them individually, but we celebrated many of them as Jenkins Ambassadors this fall (and please nominate more for the next year!) Those people who lead key efforts are often people who are new to those roles.

Some of the new leaders led other efforts that unlock new contributors. It’s about consciously thinking which segment of our potential contributors we aren’t tapping today and understanding why. Something any business does all the time. Ours resulted in Google Summer of Code and Outreachy participations.

Our security process and the pace of fixes have gone up considerably this year again, reflecting our stepping up to the trust our users gave to us. For example, this year we rolled out a telemetry system that informs us to develop better fixes more quickly.

Now, where these community improvements ultimately matter is what impact we are creating to software that you use. On that front, I think we did great in 2018, resulting in what I call&quot;5 super powers&quot; :

Jenkins X is probably the most visible innovation of this year, making it much easier to create modern cloud applications on Kubernetes. This also represents the significant expansion of the Jenkins community and its mission.

Jenkins Configuration as Code hit a major milestone &quot;1.0&quot; this year, and it’s continuing to gain more momentum and traction.

&quot;Cloud Native Jenkins&quot; is the term I gave to a new effort that I’m calling to transform Jenkins into general purpose CI/CD engine that runs at scale on Kubernetes. There’s still much to be defined here, but you can already see some great things like Serverless Jenkins.

Evergreen is another young and upcoming project that has ambitious thesis --- drastically simplifying the adoption and operation of Jenkins.

Pipeline effort formed a new SIG and I’m looking forward to the impact this will drive in 2019.

The not-so-secret sauce of the Jenkins community that threads together all these improvements from user visible changes to the community improvements is our ability to evolve. As I look forward to 2019, no doubt these things I mentioned will evolve, morph, merge, and split as we continue to learn and adopt.

So please, follow @jenkinsci and @jenkinsxio on Twitter to get updates on how we will evolve, and join our community to together build the software that rocks the world. How many open-source projects can say that?<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/new-year-blogpost">new-year-blogpost</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2018/12/26/gsoc-2019-call-for-mentors/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">26</div></div><h5 class="title">Google Summer of Code 2019. Call for Project ideas and Mentors</h5></div><p class="teaser">Google Summer of Code
is as program where students are paid a stipend by Google to work on a free open source project like Jenkins,
at full-time for four months (May to August).
Mentors get actively involved with students starting at the end of February when students start to apply
(see the timeline).

We are looking for mentors and project ideas to participate in the 15th edition of the Google Summer of Code program!
We have until February 6th, 2019 at 8pm UTC to submit the application on behalf the Jenkins Organization, but obviously,
we want to be ready before that.

The first step in the process is to have mentors and project ideas.
Then we will apply to Google.
We need Google to accept Jenkins&#x27; application to the program itself.
And for this to happen, we need project proposals and mentors.

We currently have a list of project idea proposals,
and we are looking for new project proposals, mentors, technical advisers, and subject matter experts.
GSoC projects may be about anything around code: new features, plugins, test frameworks, infrastructure, etc., etc.

Making a project idea proposal is easy, you can read the instructions here.
Quick start:

Copy the project proposal template,
add a short description of your project idea

Open the document for public view and comments, reference communication channels there (if any)

Let us know about the project idea via our gitter channel or the
mailing list.

After getting initial feedback from org admins, share your idea with other contributors who might be interested
(via the developer mailing list, chats, or special interest groups)

Potential mentors are invited to read the information for mentors for more information about the project.
Note that being a GSoC mentor does not require expert knowledge of Jenkins.
GSoC org admins will help to find technical advisors, so you can study together with your students.

Mentoring takes about 5 to 6 hours of work per week (more at the start, less at the end).
In return, a student works on your project full time for four months.
Think about the projects that you’ve always wanted to do but could not find the time…​
There are also many opportunities to engage with the Jenkins community (meetups, knowledge sharing, communications) and with other projects (e.g. going to the GSoC Mentor Summit).
GSoC is a pretty good return on the investment!

For any question, you can find the GSoC admins,
mentors and participants on the GSoC SIG Gitter chat.

The Jenkins GSoC Org Admin Team 2019<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/martinda/">Martin d&#x27;Anjou</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/01/07/webhook-firewalls/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 7</div></div><h5 class="title">Triggering builds with webhooks behind a secure firewall</h5></div><p class="teaser">In this post I wanted to show how you can run Jenkins behind a firewall (which could be a corporate firewall, a NAT’ed network like you have at home) but still receive webhooks in real time from GitHub.com. You can generalise this to other services too - such as BitBucket or DockerHub, or anything really that emits webhooks, but the instructions will be for GitHub projects hosted on github.com.

What are webhooks

Just a very quick refresher on what webhooks are: Messages (often JSON, but not always) typically posted by HTTP(S) from a server to a client that is listening for events.

The events flow left to right, Jenkins sits there happily listing on paths like /github-webhook/ or /dockerhub-webhook/ etc for some HTTP request to tell it to wake up and do some work.

GitHub/BitBucket may be reporting a new commit or PR, or DockerHub reporting an upstream image has changed. What all these things have in common is that they push to Jenkins, and expect to be able to push to it (ie that Jenkins is visible to them). This works great when the network is open - say GitHub Enterprise, or Jenkins is listening on the web.

Not on the web

The trick is when something gets in the middle, say a firewall:

( As is industry standard, all firewalls have to be a wall on fire. Please don’t somehow set bricks on fire in your organisation)

This is just the same when you fire up Jenkins on your laptop, and want to receive webhooks from github.com (a legitimate thing, perhaps to test out your setup, perhaps to run builds for iOS on a mac, or some corner of a network that is not exposed to the web). Unless your laptop is addressable to the whole web that is (not likely), or your network is configured just right, the webhooks won’t be able to flow.

This is fine - we can fall back to polling for changes. Except this is terrible. You burn through API quotas, and you don’t get changes in real time, and really no one is happy.

Some problems are opportunities

We can both solve this problem, but also, view this is an opportunity. Having things not addressable on the web, or locked down in some default way is a feature, not a bug. You massively reduce your attack surface, and can have defence in depth:

A Webhook forwarding service

Enter the memorably named Smee. This is an OSS project provided by GitHub and also helpfully hosted as a service by GitHub. This can capture and forward webhooks for you. I’ll try to explain it with a diagram:

GitHub pushes an event (via HTTPS/json in this case) to Smee.io (the funny thing with circles, which is on the public web and accessible from GitHub.com) - and Jenkins in turn subscribes to Smee with an outgoing connection from a client. Note the direction of the arrows: Jenkins only makes an outbound connection.

This is the important point: this will work as long as the firewall is one way (like a NAT typically is, and many networks). If the Jenkins side can’t connect to anything on the outside world - well, this won’t help with that of course (but that is not often the case).

Setting it up

Step 1: Firstly - go to https://smee.io/ and click “Start a new channel”:

This will give you a unique URL (which you should copy for later use):

Next you should install the smee client next to where you have the Jenkins server running:

npm install --global smee-client

(This will make the smee client/command available to receive and forward webhooks).

Now start the smee client and point it to your Jenkins server. In this case I have it running on port 8080 (the default if you fire it up on your laptop, change both the port and the smee URL as needed):

smee --url https://smee.io/GSm1B40sRfBvSjYS --path /github-webhook/ --port 8080

This says to connect to the smee service, and forward webhooks to /github-webhook/ (that trailing slash is important, don’t miss it). Once this is running, you will see it log that it is connected and forwarding webhooks. Leave this command running for as long as you want to receive webhooks.

Next, you need to configure a pipeline that makes use of github. In this case I set up one from scratch. You can skip this if you already have a pipeline setup:

I then chose “GitHub” as the where the code is:

Then choose your repository. This will set things up ready to receive webhooks from GitHub. (also if you have an existing pipeline setup, and it is using GitHub as the SCM source, that is also fine).

The final step is to tell GitHub to post webhook events for that repository (or organization, you can do that too) to Smee (which ultimately means Jenkins will receive them).

Go to the settings tab for your GitHub repository, and then click “add webhook”:

Next, configure the webhook:

Paste in the “smee” URL you copied from the step above.

Choose application/json as the content type

Tell it to send everything (you can pick and choose what events, but I just did that as simpler).

Press Add Webhook (or update)

It should look something like this:

OK - webhooks should be flowing now. You can make a change to your repository, and check that a build starts soon after:

Good luck!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/michaelneale/">Michael Neale</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/webhooks">webhooks</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/01/08/mpl-modular-pipeline-library/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 8</div></div><h5 class="title">MPL - Modular Pipeline Library</h5></div><p class="teaser">Despite speeding up development with deployment automation, one of our clients
was experiencing slow time-to-market due to a lack of collaboration in DevOps.
While they had invested in DevOps, every production pipeline was set up
individually, forcing teams to remake the wheel for each project. Making matters
worse, there was no cross-team collaboration, so any bug in the platform was
present in each new pipeline. Many of our clients have similar issues, so we
decided that we should develop a common tool which would both help current
clients, and be adaptable for use in the future. While the most obvious option
was standardizing the CI/CD platform with a common framework, this led to a
monolithic structure, which was inflexible and ultimately unworkable. Since each
team needed to work on their own pipelines, we developed a solution that would
store each reusable part of the DevOps pipeline for later use: a Jenkins-powered
modular pipeline library.

Solution: a modular pipeline library

The modular pipeline library ( MPL) we
created is a highly-flexible shared library for a Jenkins Pipeline that enables
easy sharing of best practices across the entire company. It has a clear modular
structure, an advanced testing framework, multi-level nesting, a pipeline
configuration system, improved error handling, and many other useful components.

We will take a look under the hood and explain how our solution works in several
parts:

Explore the technologies and tools we used to build the MPL

Review the MPL, and illustrate why it’s effective

Follow a step-by-step guide to operate the MPL on a sample pipeline

Dive into some of the more important components of the solution, such as the test framework and nested libraries

So now let’s jump right into an explanation of the crucial features we used to
build our solution.

Building the MPL with shared libraries and Jenkins pipelines

Jenkins, our main automation platform, recently received some updates to
Jenkins Pipeline. These updates allow us to
create one Jenkinsfile that
describes the entire pipeline, and the steps that need to be executed with a
series of self-explanatory scripts. This increases the visibility of CI/CD
automation processes for end users, and improves supportability by DevOps teams.

However, there’s a large issue with Pipeline: it’s hard to support multiple
Jenkinsfiles (and therefore multiple projects) with unique pipelines. We need to
store the common logic somewhere, which is where
Jenkins Shared Libraries
come in. They are included in the Jenkinsfile, and allow the use of prepared
interfaces to simplify automation and store common pieces.

While shared libraries allow you to store logic and manipulate Jenkins, they
don’t provide a good way to utilize all the common information. Therefore, the
MPL optimizes the pipeline and shared libraries by allowing users to create
easy-to-follow descriptions for processes, which are then stored for later use
by other teams.

The MPL works to create collaborative DevOps processes across teams

With the MPL, we are now able to collaborate and share our DevOps practices
across teams, easily adopt existing pipelines for specific projects, and debug
and test features before we actually integrate them into the library. Each team
can create a nested library, add a number of pipelines and modules inside, and
use it with pipeline automation to create great visibility of the processes for
the end user. The MPL can also work on any project to prepare a Jenkinsfile, and
manage it as flexibly as the project team wants.

At its core, the MPL provides a simple way to:

Separate pipelines and steps by introducing modules

Describe steps in the modules with an easy configuration interface

Test the described modules and share the results with other pipelines and projects

There are a lot of other features in the MPL, but it’s essentially a platform to
solve general DevOps collaboration issues. To simplify development and manual
testing, the MPL provides modules overriding and an inheritance model, allowing
users to test specific fixes in the project without affecting anything else. In
Jenkins, a module is a file with scripted steps and logic to reach a simple goal
(build an artifact, run tests, create an image, etc.). These modules are
combined in the pipeline stages, and are easily readable for anyone who knows
the Jenkins Pipeline syntax.

The MPL allows users to use the core features of the library (structure,
modules, pipelines) and create nested libraries for specific DevOps team needs.
A DevOps team can prepare complete pipelines with any custom logic and use it
for their projects. They can also override and inherit the core MPL modules in a
number of ways, or prepare custom modules which are easy to share with other
teams. Check out the infographic below to see how modules fit in:

You can also specify certain pipeline required poststeps in a module. For
example, a dynamic deployment module creates the test environment, which needs
to be destroyed when the pipeline ends. To take a closer look at the MPL calling
process, check out the infographic below:

This infographic shows how calls are executed in the MPL. First, you need a job
on your Jenkins, which will call a Jenkinsfile (for example, when the source
code is changed), after which the Jenkinsfile will call a pipeline. The pipeline
could be described on the MPL side, in the pipeline script in the job, in the
nested library, or in the project Jenkinsfile. Finally, the stages of the
pipeline will call the modules, and these modules will use features, which could
be groovy logic, pipeline steps, or steps in the shared libraries.

Now that we’ve done an overview of the solution, let’s take a look at a simple
pipeline execution to see how the MPL works in action.

An example of a pipeline execution in the MPL

For example, let’s say you have a common Java Maven project. You are creating a
Jenkinsfile in the repo, and want to use the default pipeline prepared by your
DevOps team. The MPL already has a simple pipeline: the core MPLPipeline. It’s
a really simple pipeline, but it’s a good start for anyone who wants to try the
MPL. Let’s look at a simple Jenkinsfile:

@Library(&#x27;mpl&#x27;) _
MPLPipeline {}

This Jenkinsfile contains a single line to load the MPL, and another line to run
the pipeline. Most of the shared libraries implement an interface like this,
calling one step and providing some parameters. MPLPipeline is merely a custom
Pipeline step, as it lies in the vars directory, and its structure is very
simple, following these steps:

Initialize the MPL
The MPL uses the MPLManager singleton object to control the pipeline

Merge configuration with default and store it
A default configuration needed to specify stages and predefine some useful configs

Define a declarative pipeline with 4 stages and poststeps:

Checkout - Getting the project sources

Build - Compiling, validation of static, unit tests

Deploy - Uploading artifacts to the dynamic environment and running the app

Test - Checking integration with other components

Poststeps - Cleaning dynamic environment, sending notifications, etc.

Running the defined pipeline
This is where the MPL starts to work its magic and actually runs

Stages of the main MPL usually have just one step, the MPLModule .
This step contains the core functionality of the MPL: executing the modules
which contain the pipeline logic. You can find default modules in the MPL
repository, which are placed in resources/com/griddynamics/devops/mpl/modules.
Some of the folders include: Checkout, Build, Deploy, and Test, and in each of
them we can find Groovy files with the actual logic for the stages. This
infographic is a good example of a simplified MPL repository
structure:

When the Checkout stage starts, MPLModule loads the module by name (by default
a stage name), and runs the Checkout/Checkout.groovy
logic:

if( CFG.&#x27;git.url&#x27; )
  MPLModule(&#x27;Git Checkout&#x27;, CFG)
else
  MPLModule(&#x27;Default Checkout&#x27;, CFG)

If the configuration contains the git.url option, it will load a Git Checkout
module; otherwise, it will run the Default Checkout module. All the called
modules use the same configuration as the parent module, which is why CFG was
passed to the MPLModule call. In this case, we have no specific configuration,
so it will run the
Checkout/DefaultCheckout.groovy
logic. The space in the name is a separator to place the module into a specific
folder.

In the Default Checkout module, there is just one line with checkout scm
execution, which clones the repository specified in the Jenkins job. That’s all
the Checkout stage does, as the MPL functionality is excessive for such a small
stage, and we only need to talk about it here to show how the MPL works in
modules.

The same process applies to the Build stage, as the pipeline runs the
Maven Build
module:

withEnv([&quot;PATH+MAVEN=${tool(CFG.&#x27;maven.tool_version&#x27; ?: &#x27;Maven 3&#x27;)}/bin&quot;]) {
  def settings = CFG.&#x27;maven.settings_path&#x27; ? &quot;-s &#x27;${CFG.&#x27;maven.settings_path&#x27;}&#x27;&quot; : &#x27;&#x27;
  sh &quot;&quot;&quot;mvn -B ${settings} -DargLine=&#x27;-Xmx1024m -XX:MaxPermSize=1024m&#x27; clean install&quot;&quot;&quot;
}

This stage is a little bit more complicated, but the action is simple: we take
the tool with the default name Maven 3, and use it to run mvn clean install.
The modules are scripted pipelines, so you can do the same steps usually
available in the Jenkins Pipeline. The files don’t need any specific and
complicated syntax, just a plain file with steps and CFG as a predefined
variable with a stage configuration. The MPL modules inherited the sandbox from
the parent, so your scripts will be safe and survive the Jenkins restart, just
like a plain Jenkins pipeline.

In the Deploy folder, we find the sample structure of the Openshift Deploy
module. Its main purpose here is to show how to use poststep definitions in the
modules:

MPLPostStep(&#x27;always&#x27;) {
  echo &quot;OpenShift Deploy Decommission poststep&quot;
}
echo &#x27;Executing Openshift Deploy process&#x27;

First, we define the always poststep. It is stored in the MPLManager, and is
called when poststeps are executed. We can call MPLPostStep with always as
many times as we want: all the poststeps will be stored and executed in FILO
order. Therefore, we can store poststep logic for actions that need to be done,
and then undone, in the same module, such as the decommission of the dynamic
environment. This ensures that the actions will be executed when the pipeline
is complete.

After the deploy stage, the pipeline executes the Test stage, but nothing too
interesting happens there. However, there is an aspect of testing which is very
important, and that’s the testing framework of the MPL itself.

Testing of the MPL

The testing framework of the MPL is based on the
JenkinsPipelineUnit
from LesFurets, with the one small difference being its ability to test the MPL
modules. Testing the whole pipeline doesn’t work, as pipelines can be really
complicated, and writing tests for such monsters is a Sisyphean task. It is much
easier to test a black box with a small amount of steps, ensuring that this
particular task is working correctly.

In the MPL, you can find Build module testing examples: all the tests are
stored in the
test/groovy/com/griddynamics/devops/mpl/modules
directory, and you can find the
Build/BuildTest.groovy
file with a number of test cases there. Tests are executed during the MPL build
process, allowing users to see traces like this:

Loading shared library mpl with version snapshot
  MPLModule.call(Build, {maven={tool_version=Maven 2}})
    Build.run()
      Build.MPLModule(Maven Build, {maven.tool_version=Maven 2})
        MavenBuild.run()
          MavenBuild.tool(Maven 2)
          MavenBuild.withEnv([PATH+MAVEN=Maven 2_HOME/bin], groovy.lang.Closure)
            MavenBuild.sh(mvn -B  -DargLine=&#x27;-Xmx1024m -XX:MaxPermSize=1024m&#x27; clean install)
      Build.fileExists(openshift)

The test runs the MPLModule with custom configuration and mocked steps to
check that, during execution, the tool was changed to Maven 2 according to the
provided configuration. We cover all test cases with such tests, ensuring that
the modules are working as expected, and that the pipeline will work properly.
You can test the whole pipeline if you want, but testing by modules is just an
additional way to simplify the testing process.

Now that we’ve looked at how to test the MPL modules, it’s time to look at one
of the key features of the MPL, which is nested libraries.

The benefits of nested libraries

When working with a large company, supporting one big library makes no sense.
Each department requires multiple configuration options and tuning for a
somewhat standard pipeline, which creates extra work. The MPL solves such
problems by introducing nested libraries. This infographic displays how a nested
library compares to just using the main library:

A nested library is the same as a shared library that imports the MPL and uses
its functionality, modules, and pipelines. Also, it allows the separation of
some team-related logic from the company common logic. Here is the structure of
the MPL with nested libraries:

You can import the MPL in the overridden pipeline, specify the path of some
additional modules, override module logic, and use Jenkins power moves: there
are no limitations. When another team needs your unique module, you can just
create a change request to the basic company MPL repo, and share your functional
module with the others.

With nested libraries, it’s possible to debug and modify MPL-provided steps
( MPLModule for example) and pipelines. This is because nested libraries can
override low-level functionalities of the MPL or the Jenkins Pipeline. There are
no limitations to what you can or can’t change, as these overrides only affect
your own pipeline. This enables experimentation to be done, and then discussed
with other teams to see if it will work in other nested libraries as well.

There are also no limits to the number of nesting levels created, but we
recommend using just two (MPL and nested), because additional levels make
configuration and testing of the nested libraries on lower levels very
complicated.

The power of module overriding

Further into the nested libraries or project-side modules, it’s possible to
store a module with the same name as one in the upper-level library. This is a
good way to override the logic - you can just replace Build/Build.groovy with
your own - as the functional module will be executed instead of the upper-level
module. For example, this infographic shows module overriding:

Even better, one of the strengths of the MPL is that you still can use the
upper-level module! The MPL has mechanisms to prevent loops, so the same module
can’t be executed in the same executing branch again. However, you can easily
call the original module a name from another module to use the upper-level
logic.

The Petclinic-Selenium example above uses the default MPLPipeline (you can
find it on the MPL Wiki-page), and
contains project-side modules in a.jenkins directory. These modules will be
called before the library modules. For example, the Checkout module is not
placed on the project side, so it will be called from the MPL, but the Build
module exists in a.jenkins directory on the project side, and it will be
called:

MPLPostStep(&#x27;always&#x27;) {
  junit &#x27;target/surefire-reports/*.xml&#x27;
}

MPLModule(&#x27;Build&#x27;, CFG)

if( fileExists(&#x27;Dockerfile&#x27;) ) {
  MPLModule(&#x27;Docker Build&#x27;, CFG)
}

As you can see, the Build module from the project registers the poststep,
calls the original Build module from the MPL, and then calls the additional
Docker Build module. The following stages of the pipeline are more
complicated, but all module overriding essentially works like this. Some
projects can be tricky, and need some small tunings for the existing modules.
However, you can easily implement those changes on the project level, and think
about how to move the functionality to the nested library or MPL later.

Conclusion: what the MPL brings to DevOps

Many DevOps teams and companies work with bloated, restrictive, and buggy CI/CD
automation platforms. These increase the learning curve for users, cause teams
to work slower, and raise production costs. DevOps teams frequently run into
similar issues on different projects, but a lack of collaboration means that
they have to be individually fixed each time.

However, with the MPL, DevOps teams have a shared, simple, and flexible CI/CD
platform to improve user support, collaboration, and overall project source code
to the production process. By utilizing the MPL, your company can find an
automation consensus, reach cross-company collaboration goals, and reuse the
best practices from a large community, all with open source tools. If you’re
interested in building an MPL, please contact us to learn more!

Additional resources

Jenkins Pipeline Engine

Jenkins Shared Libraries

MPL GitHub repository

Overview &amp; demo videos:

Introduction

Overview

Demo of the MPL Build

Demo of the Nested Library

Demo of the Petclinic Pipeline<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sparshev/">Sergei Parshev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsfile">jenkinsfile</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/sharedlibrary">sharedlibrary</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/01/09/jenkins-user-conference-china-shenzhen-update/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 9</div></div><h5 class="title">Jenkins User Conference China - Shenzhen Update</h5></div><p class="teaser">On November 3rd, 2018 the Jenkins User Conference China (JUCC) met Jenkins users in Shenzhen which is the most burgeoning city in China.
It was the first time to hold JUCC in Shenzhen.
We held JUCC along with DevOps International Summit, which is the biggest DevOps event in China.
More than 200 attendees gathered at JUCC Shenzhen to share and discuss Jenkins, DevOps, Continuous Delivery, Pipeline, and Agile.

Below, I am sharing pictures and some of the topics discussed at the event:

Yu Gu from Accenture presented New challenges for DevOps in Cloud Native.

Peng Wang from Meituan which is the biggest group-buying website in China much like Groupon presented
The continuous delivery toolchains based on Jenkins for ten thousand times build per day.

Guangming Zhou from Ctrip who is a Jenkins expert in China presented CD system in Ctrip.

Jiaqi Guo Jiaqi Guo from Kingston presented DevOps practices in large manufacturing industry.

Yaxing Li from Tencent presented How to support the CI CD requirements for thousands of products in Tencent based on Jenkins.

Mei Xiao from ZTE presented Fast integration practice for Android.

John Willis presented Next Generation Infrastructure which included Kubernetes and  Istio practices.

BC Shi from JD.com who is also a Jenkins Ambassador and the co-organizer of JUCC presented Pipeline 3.0  for DevOps toolchains.
He introduced the practices based on Jenkins and Jenkins X to build an end to end pipeline for DevOps from requirement to online service.

We’ve also released a DevOps tool map to recommend an excellent tool to the community.

Lastly, myself, Forest Jing co-organizer of JUCC and also am a Jenkins Ambassador interacted with the attendees.

We also organized the Jenkins workshop and Open space for the attendees.
Ruddy Li ,Yunhua Li , Yu Gu and Dingan Liang have worked together to run an open space to lead the attendees to discuss problems they met in DevOps and CD.

Huaqiang Li who is a Certified Jenkins Engineer and CCJE has led the attendees to practice Jenkins functions for a whole afternoon.

Here are more photos from our event, it was a fantastic JUCC in Shenzhen.
There were so much interest and appetite to learn about Jenkins and DevOps.
We are looking forward to doing this again next year.

Slides from the event can be downloaded at PPT Download Address, password: sepe (the website is in Chinese).

Thank you to Alyssa and Maxwell’s help to organize this event.
Jenkins User Conference China continues and we hope to see many of you next year in China for our next JUCC.
Let’s be Kung fu Jenkins!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ijyun/">Forest Jing（景韵）</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsuserconference">jenkinsuserconference</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/chinese">chinese</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/01/21/fosdem-2019/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">21</div></div><h5 class="title">FOSDEM 2019!</h5></div><p class="teaser">FOSDEM 2019 (February 2 &amp; 3) is a free event for software developers to meet, share ideas and collaborate.
It is an annual event that brings open source contributors from around the world for two days of presentations, discussions, and learning.
While the Jenkins project won’t have a table at FOSDEM 2019, we will be well represented before, during, and after the event.

Friday Day - Workshops and Jenkins Office Hours

On Friday, February 1, we’ll start off with a couple workshops:

Jenkins Pipeline Fundamentals
(9:00 AM – 5:00 PM)
Learn to create and run Declarative Pipelines!
You’ll learn the structure of Declarative Pipeline, how to control the flow of execution, how to save artifacts of the build, and get practice using some of the features that give fit and finish to your Pipeline.
Registration required - see the
event page
for details

Jenkins X, Kubernetes, and Friends
Two sessions: (9:00 AM – 12:00 PM) and (1:00pm to 4:00pm)
By combining the power of Jenkins, its community and the power of Kubernetes, the Jenkins X project provides a path to the future of continuous delivery for microservices and cloud-native applications.
Come explore some of the features of Jenkins X through this hands-on workshop.
Registration required - see the
event page
for details

Aside from the workshops, from 9am to 5pm a bunch of people will be working out of Hilton Brussels Grand Place, hanging out as travelers come in.
It’ll be a casual, unstructured day. Sign up on this meetup page to be notified what meeting room we’re in.

Friday Evening - Happy Hour

After the office hours and workshops, we’ll have a happy hour Friday evening before FOSDEM at Cafe Le Roy d’Espagne.
See the meetup page for details.

Presentations at FOSDEM

Hackers gotta eat: Building a Company Around an Open Source Project
by Kohsuke Kawaguchi

Setting up an HPC lab from scratch with Mr-Provisioner, Jenkins and Ansible
by Renato Golin

Multicloud CI/CD with OpenStack and Kubernetes by Maxime Guyot

Jenkins Hackfest after FOSDEM

Finally, a Jenkins Hackfest will be held the day after FOSDEM 2019 on Monday (February 4).
Those who would like to join us for the hackfest should register for the meetup.

Meals, snacks, and beverages will be provided for the hackfest.  Come join us, and let’s write some code!

Questions? feel free to contact
Alyssa Tong or
Baptiste Mathus or join us on the
advocacy-and-outreach gitter channel.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/01/windows-installers/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 1</div></div><h5 class="title">Windows Installer Updates</h5></div><p class="teaser">The Windows Installer for Jenkins has been around for many years as a way for users to install a Jenkins controller on Windows as a service.
Since it’s initial development, it has not received a lot of updates or features, but that is about to change.

First, let’s take a look at the current installer experience.

Step 1

This is the default look and feel for a Windows Installer using the WiX Toolset, not very pretty and doesn’t give
much branding information as to what the installer is for.

Step 2

Again, not much branding information.

Step 3

The installer in general does not give many options for installing Jenkins, other than selecting the installation location.

Issues

The current installer has a few issues that the Platform SIG wanted to fix in a new install experience for users.

The installer only supports 32-bit installations.

The user could not select ports or user accounts to run the service on.

The installer bundled a 32-bit version of the Java runtime instead of using a pre-existing JRE

The installer did not support the experimental support in Jenkins for Java 11

The JENKINS_HOME directory was not placed in a good spot for modern Windows

There is no branding in the installer.

Road Forward

With the experimental Jenkins Windows Installer, most of these issues have been resolved!

The installer will only support 64-bit systems going forward. This is the vast majority of Windows systems these days,
so this will help more users install Jenkins using the installer package.

The user is now able to enter user information for the service and select the port that Jenkins will use and verify that the port is available.

The installer no longer bundles a JRE, but will search for a compatible JRE on the system. If the user wants to use a different JRE, they can specify during install.

The installer has support for running with a Java 11 JRE, including the components listed on the Java 11 Preview Page.

the JENKINS_HOME directory is placed in the LocalAppData directory for the user that the service will run as, this aligns with modern Windows file system layouts.

The installer has been updated with branding to make it look nicer and provide a better user experience.

Screenshots

Below are screenshots of the new installer sequence:

Step 1

The Jenkins logo is now a prominent part of the UI for the installer.

Step 2

The Jenkins logo and name are now in the header during all phases of the installer.

Step 3

The installer now allows you to specify the username/password for the account to run as and checks that the account has LogonAsService rights.

Step 4

The installer also allows you to specify the port that Jenkins should run on and will not continue until a valid port is entered and tested.

Step 5

Instead of bundling a JRE, the installer now searches for a compatible JRE on the system (JRE 8 is the current search). If you want to use a different
JRE on the system than the one found by the installer, you can browse and specify it. Only JRE 8 and JRE 11 runtimes are supported. The installer will
automatically add the necessary arguments and additional jar files for running under Java 11 if the selected JRE is found to be version 11.

Step 6

All of the items that users can enter in the installer should be overridable on the command line for automated deployment as well. The full list of properties that
can be overridden will be available soon.

Next Steps

The new installer is under review by the members of the Platform SIG, but we need people to test the installer and give feedback. If you are interested in testing
the new installer, please join the Platform SIG gitter room for more information.

There are still some things that are being researched and implemented in the new installer (e.g., keeping port and other selections when doing an upgrade), but it is
getting close to release.

In addition to updates to the MSI based Windows installer, the Platform SIG is working on taking over the Chocolatey Jenkins package and
releasing a version for each update.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/slide_o_mix/">Alex Earl</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/installers">installers</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/05/jenkins-new-year-in-china/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 5</div></div><h5 class="title">Jenkins new year in China</h5></div><p class="teaser">At the time of the Spring Festival. I want to make a summary of some activities in the last year.
You might already notice that more and more Chinese contributors emerge in the Jenkins community.
We have a GSoC champion who is Shenyu Zheng.
He is a great example for other students. With the effort of three skilled engineers,
many Jenkins users could learn the edge technologies and useful use cases.
They co-organized several Jenkins Meetups in a couple of cities in China.

There are two workshops about Jenkins and Jenkins X in the DevOps International Summit. James Rawlings gave us a wonderful view of the Jenkins X. Many people start to know this project. The Chinese website of jx would be helpful to those people.

On November 3rd, 2018 the Jenkins User Conference China(JUCC) was hosted in Shenzhen. More than 200 attendees gathered at JUCC to share and discuss Jenkins, DevOps, Continuous Delivery, Pipeline, and Agile.

There was a Jenkins workshop to teach users to develop a plugin in October. It was during the Hacktoberfest 2018. So some people got a beautiful T-shirt at this meetup. We’ll keep this event in 2019. I hope more users and developers could join us.

Thank you all folks. And other friendly contributors.

Chinese is our main communication language. A large number of the Jenkins users are not a proficient English speaker.
So letting most of Chinese Jenkins users could easily use Jenkins as their CI/CD platform is the final mission of Chinese Localization SIG.
You can find three participants on the page. But that’s not the full list.
More exciting thing is that Alauda giving a big support which as a startup company.

WeChat is the greatest social media channel in China. WeChat has one billion users.
Almost everyone in China has a WeChat account. It must be a perfect place to publish articles and events.
There are over 1k people subscribed the Jenkins official WeChat Subscription Account in the last three months.

In the new year, I’m looking forward to growing up with you all!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/linuxsuren/">赵晓杰(Rick)</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/chinese">chinese</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/06/ssh-steps-for-jenkins-pipeline/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 6</div></div><h5 class="title">SSH Steps for Jenkins Pipeline</h5></div><p class="teaser">Pipeline-as-code or defining the deployment pipeline through code rather than manual job creation through UI, provides tremendous benefits for teams automating builds and deployment infrastructure across their environments.

Source of image: https://jenkins.io/doc/book/pipeline/

Jenkins Pipelines

Jenkins is a well-known open source continuous integration and continuous deployment automation tool. With the latest 2.0 release, Jenkins introduced the Pipeline plugin that implements Pipeline-as-code. This plugin lets you define delivery pipelines using concise scripts which deal elegantly with jobs involving persistence and asynchrony.

The Pipeline-as-code’s script is also known as a Jenkinsfile.

Jenkinsfiles uses a domain specific language syntax based on the Groovy programming language. They are persistent files which can be checked in and version-controlled along with the rest of their project source code. This file can contain the complete set of encoded steps (steps, nodes, and stages) necessary to define the entire application life-cycle, becoming the intersecting point between development and operations.

Missing piece of the puzzle

One of the most common steps defined in a basic pipeline job is the Deploy step. The deployment stage encompasses everything from publishing build artifacts to pushing code into pre-production and production environments. This deployment stage usually involves both development and operations teams logging onto various remote nodes to run commands and/or scripts to deploy code and configuration. While there are a couple of existing ssh plugins for Jenkins, they currently don’t support the functionality such as logging into nodes for pipelines. Thus, there was a need for a plugin that supports these steps.

Introducing SSH Steps

Recently, our team at Cerner started working on a project to automate deployments through Jenkins pipelines to help facilitate running commands on over one thousand nodes. We looked at several options including existing plugins, internal shared Jenkins libraries, and others. In the end, we felt it was best to create and open source a plugin to fill this gap so that it can be used across Cerner and beyond.

The initial version of this new plugin SSH Steps supports the following:

sshCommand : Executes the given command on a remote node.

sshScript : Executes the given shell script on a remote node.

sshGet : Gets a file/directory from the remote node to current workspace.

sshPut : Puts a file/directory from the current workspace to remote node.

sshRemove : Removes a file/directory from the remote node.

Usage

Below is a simple demonstration on how to use above steps. More documentation can be found on GitHub.

def remote = [:]
remote.name = &quot;node&quot;
remote.host = &quot;node.abc.com&quot;
remote.allowAnyHosts = true

node {
    withCredentials([usernamePassword(credentialsId: &#x27;sshUserAcct&#x27;, passwordVariable: &#x27;password&#x27;, usernameVariable: &#x27;userName&#x27;)]) {
        remote.user = userName
        remote.password = password

        stage(&quot;SSH Steps Rocks!&quot;) {
            writeFile file: &#x27;test.sh&#x27;, text: &#x27;ls&#x27;
            sshCommand remote: remote, command: &#x27;for i in {1..5}; do echo -n \&quot;Loop \$i \&quot;; date ; sleep 1; done&#x27;
            sshScript remote: remote, script: &#x27;test.sh&#x27;
            sshPut remote: remote, from: &#x27;test.sh&#x27;, into: &#x27;.&#x27;
            sshGet remote: remote, from: &#x27;test.sh&#x27;, into: &#x27;test_new.sh&#x27;, override: true
            sshRemove remote: remote, path: &#x27;test.sh&#x27;
        }
    }
}

Configuring via YAML

At Cerner, we always strive to have simple configuration files for CI/CD pipelines whenever possible. With that in mind, my team built a wrapper on top of these steps from this plugin. After some design and analysis, we came up with the following YAML structure to run commands across various remote groups:

config:
  credentials_id: sshUserAcct

remote_groups:
  r_group_1:
    - name: node01
      host: node01.abc.net
    - name: node02
      host: node02.abc.net
  r_group_2:
    - name: node03
      host: node03.abc.net

command_groups:
  c_group_1:
    - commands:
        - &#x27;ls -lrt&#x27;
        - &#x27;whoami&#x27;
    - scripts:
        - &#x27;test.sh&#x27;
  c_group_2:
    - gets:
        - from: &#x27;test.sh&#x27;
          to: &#x27;test_new.sh&#x27;
    - puts:
        - from: &#x27;test.sh&#x27;
          to: &#x27;.&#x27;
    - removes:
        - &#x27;test.sh&#x27;

steps:
  deploy:
    - remote_groups:
        - r_group_1
      command_groups:
        - c_group_1
    - remote_groups:
        - r_group_2
      command_groups:
        - c_group_2

The above example runs commands from c_group_1 on remote nodes within r_group_1 in parallel before it moves on to the next group using sshUserAcct (from the Jenkins Credentials store) to logon to nodes.

Shared Pipeline Library

We have created a shared pipeline library that contains a sshDeploy step to support the above mentioned YAML syntax. Below is the code snippet for the sshDeploy step from the library. The full version can be found here on Github.

#!/usr/bin/groovy
def call(String yamlName) {
    def yaml = readYaml file: yamlName
    withCredentials([usernamePassword(credentialsId: yaml.config.credentials_id, passwordVariable: &#x27;password&#x27;, usernameVariable: &#x27;userName&#x27;)]) {
        yaml.steps.each { stageName, step -&gt;
            step.each {
                def remoteGroups = [:]
                def allRemotes = []
                it.remote_groups.each {
                    remoteGroups[it] = yaml.remotes.&quot;$it&quot;
                }

                def commandGroups = [:]
                it.command_groups.each {
                    commandGroups[it] = yaml.commands.&quot;$it&quot;
                }
                def isSudo = false
                remoteGroups.each { remoteGroupName, remotes -&gt;
                    allRemotes += remotes.collect { remote -&gt;
                        if(!remote.name)
                            remote.name = remote.host
                        remote.user = userName
                        remote.password = password
                        remote.allowAnyHosts = true
                        remote.groupName = remoteGroupName
                        remote
                    }
                }
                if(allRemotes) {
                    if(allRemotes.size() &gt; 1) {
                        def stepsForParallel = allRemotes.collectEntries { remote -&gt;
                            [&quot;${remote.groupName}-${remote.name}&quot; : transformIntoStep(stageName, remote.groupName, remote, commandGroups)]
                        }
                        stage(stageName) {
                            parallel stepsForParallel
                        }
                    } else {
                        def remote = allRemotes.first()
                        stage(stageName + &quot;\n&quot; + remote.groupName + &quot;-&quot; + remote.name) {
                            transformIntoStep(stageName, remote.groupName, remote, commandGroups).call()
                        }
                    }
                }
            }
        }
    }
}

By using the step (as described in the snippet above) from this shared pipeline library, a Jenkinsfile can be reduced to:

@Library(&#x27;ssh_deploy&#x27;) _

node {
  checkout scm
  sshDeploy(&#x27;dev/deploy.yml&#x27;);
}

An example execution of the above pipeline code in Blue Ocean looks like this:

Wrapping up

Steps from the SSH Steps Plugin are deliberately generic enough that they can be used for various other use-cases as well, not just for deploying code. Using SSH Steps has significantly reduced the time we spend on deployments and has given us the possibility of easily scaling our deployment workflows to various environments.

Help us make this plugin better by contributing. Whether it is adding or suggesting a new feature, bug fixes, or simply improving documentation, contributions are always welcome.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/nrayapati/">Naresh Rayapati</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ssh">ssh</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/steps">steps</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/17/remoting-cli-removed/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">17</div></div><h5 class="title">Remoting-based CLI removed from Jenkins</h5></div><p class="teaser">Close to two years ago, we announced in
New, safer CLI in 2.54
that the traditional “Remoting” operation mode of the Jenkins command-line interface
was being deprecated for a variety of reasons, especially its very poor security record.
Today in Jenkins 2.165 support for this mode is finally being removed altogether,
in both the server and bundled jenkins-cli.jar client.
The projected June 5th LTS release will reflect this removal,
at which point the Jenkins project will no longer maintain this feature
nor investigate security vulnerabilities in it.

This change makes the code in Jenkins core related to the CLI considerably simpler and more maintainable.
(There are still two transports —HTTP(S) and SSH—but they have similar capabilities and behavior.)
It also reduces the “attack surface” the Jenkins security team must consider.
Among other issues, a compromised server could freely attack a developer’s laptop if -remoting were used.

The
2.46.x upgrade guide
already urged administrators to disable Remoting mode on the server.
Those Jenkins users who rely on the CLI for remote scripting (as opposed to the HTTP(S) REST APIs)
would be affected only if they were still using the -remoting CLI flag,
since the default has long been to use HTTP(S) mode.

Most CLI features have long worked fine without -remoting,
in some cases using slightly different syntax such as requiring shell redirects to access local files.
As part of this change, some CLI commands, options, and option types in Jenkins core have been removed, other than -remoting itself:

The login and logout commands, and the --username and --password options.

The -p option to select a proxy. (The CLI in default -http mode accesses Jenkins no differently than any other HTTP client.)

The install-tool, set-build-parameter, and set-build-result commands relied on a fundamentally insecure idiom that is no longer supportable.

Command options or arguments which took either a local file or = for standard input/output (e.g., install-plugin, build -p, support) now only accept the latter.

Some features of relatively little-used plugins will no longer work, such as:

DistFork

Remote Terminal Access

Build Env Propagator<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/21/credentials-masking/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">21</div></div><h5 class="title">Limitations of Credentials Masking</h5></div><p class="teaser">In the Jenkins project, we ask that people report security issues to our private issue tracker.
This allows us to review issues and prepare fixes in private, often resulting in better, safer security fixes.

As a side effect of that, we also learn about common misconceptions and usability problems related to security in Jenkins.
This post is intended to address one of those:
The goal and limitations of credentials masking.

The Problem

One very common example of that is the role of credentials masking in Jenkins, typically involving a pipeline snippet that looks like this:

// Scripted //
withCredentials([usernamePassword(credentialsId: &#x27;topSecretCredentials&#x27;, passwordVariable: &#x27;PWD&#x27;, usernameVariable: &#x27;USR&#x27;)])
  sh &#x27;./deploy.sh&#x27; // requires PWD and USR to be set
}
// Declarative //

Credentials that are in scope are made available to the pipeline without limitation.
To prevent accidental exposure in the build log, credentials are masked from regular output, so an invocation of env (Linux) or set (Windows), or programs printing their environment or parameters would not reveal them in the build log to users who would not otherwise have access to the credentials.

The misconception here is that Jenkins will prevent other, perhaps deliberate ways to reveal the password.
Some examples:

// Scripted //
withCredentials([usernamePassword(credentialsId: &#x27;topSecretCredentials&#x27;, passwordVariable: &#x27;PWD&#x27;, usernameVariable: &#x27;USR&#x27;)])
  sh &#x27;echo $PWD | base64&#x27; // will print e.g. dDBwczNjcjN0Cg= which is trivially converted back to the top secret password
}
// Declarative //

// Scripted //
withCredentials([usernamePassword(credentialsId: &#x27;topSecretCredentials&#x27;, passwordVariable: &#x27;PWD&#x27;, usernameVariable: &#x27;USR&#x27;)])
  sh &#x27;echo $PWD &gt; myfile&#x27;
  archiveArtifacts &#x27;myfile&#x27; // then browse archived artifacts from the Jenkins UI
}
// Declarative //

Both of these snippets circumvent credentials masking in the build log, and show that people with control over the build script can use credentials in ways not necessarily intended or approved by admins.

Obviously these are just the most straightforward examples illustrating the problem.
Others could involve the proc file system, sending it to an HTTP server in response to a 401 authentication challenge, embedding it in the (otherwise legitimate) build result, etc.

It would be great if Jenkins could allow the flexible use of credentials with no risk of exposing them through straightforward build script modifications, but realistically, it is impossible for Jenkins to police use of the credential by a build script without the support of a very specific environment setup (e.g. restrictive network configuration).

It should also be noted that credentials aren’t just at risk from users able to control the pipeline, typically by editing the Jenkinsfile.
Actual build scripts invoked by pipelines, either shell scripts as in the example above, or more standard build tools such as Maven (controlled by pom.xml) are just as much of a risk if they are run inside a withCredentials block, or executing on the same agent as another block that passed such credentials.

Disclosure of secrets can also happen inadvertently:
Jenkins will prevent exact matches of the password or other secret to appear in the log file.
Consider that the secret may contain shell metacharacters that bash +x would escape by adding a \ before those characters.
The sequence of characters to be printed is no longer identical to the secret, so would not be masked.

The Solution

Credentials can be defined in different scopes:
Credentials defined on the root Jenkins store (the default) will be available to all jobs on the instance.
The only exception are credentials with System scope, intended for the global configuration only, for example, to connect to agents.
Credentials defined in a folder are only available within that folder (transitively, i.e. also in folders inside this folder).

This allows defining sensitive credentials, such as deployment credentials, on specific folders whose contents only users trusted with those credentials are allowed to configure:
Directly in Jenkins using Matrix Authorization Plugin and by limiting write access to repositories defining pipelines as code.

Pipelines inside this folder can use the (e.g. deployment) credentials without limitation, while they’re inaccessible to pipelines outside the folder.
Those would need to use the build step or similar approaches to invoke the pipelines inside the folder to deploy their output.

Caveats

While the previous section outlines a solution to the problem of restricting access to credentials, care needs to be taken so that credentials are not captured anyway.
For example, a deployment pipeline that allows its users to define where to deploy to as a build parameter might still be used to send credentials to a maliciously set up host to capture them.
A blog post explaining the design of some Jenkins project infrastructure discusses some of these concerns around trust.

It should also be noted that credential domains are a UI hint only — defining a credential to only be valid for github.com does not actually prevent its use elsewhere.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/26/jenkins-alexa-voice-controlled-cicd/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">26</div></div><h5 class="title">Jenkins + Alexa: Say Hello to Voice Controlled CI/CD</h5></div><p class="teaser">Integrating Jenkins with Alexa to launch your pipelines and obtain results
about your deployments through voice is easier than you think.  Learn how Alexa
Champion, Kesha Williams&#x27;, latest side project teaches Alexa to deploy code to
the cloud.

Alexa (named after the ancient library of Alexandria) is Amazon’s Artificial
Intelligence (AI) powered intelligent voice assistant that runs in the cloud.
Software engineers make Alexa smarter by creating apps, called skills.  From
the time that I developed my first Alexa skill, I dreamed of deploying my Java
projects to the cloud via voice.  For me, telling Alexa to deploy my code is
the ultimate level of cool!  I recently made my dream a reality when I devoted
a weekend to developing my newest Alexa skill, DevOps Pal.  In this blog, I
will show you how I developed DevOps Pal and hopefully inspire you to build
your own version.

Why Choose Voice to Deploy Code

Voice-first technology is revolutionizing how we interact with technology because the interaction is simple, frictionless, and time-saving.
For me, voice is an easier way to control Jenkins and retrieve results about my deployments without having to touch a keyboard.
In this use case, voice is another access point for data and is a way to further automate the process of building, testing, and deploying a Java project to the cloud, improving efficiency.

Continuous Integration and Continuous Delivery (CI/CD)

If you’re working with DevOps, you understand the need for Continuous Integration and Continuous Delivery (CI/CD) to automate the software delivery pipeline in a reproducible way.
CI/CD is the practice of continuously building, testing, and deploying code once it’s committed to version control.
DevOps and CI/CD provides software engineering teams with confidence in the code being pushed to production and shorter development lifecycles, which in the end produces happier users, clients, and customers.

DevOps Pal Overview

DevOps Pal is a private Alexa for Business skill that is used to kick off a Jenkins pipeline job.
Alexa for Business was the perfect way for me to distribute DevOps Pal since I have the ability to enable the skill on an organization-by-organization basis, which gives me complete control over who has access.
Once DevOps Pal invokes the job, the pipeline status displays in real-time via the Blue Ocean Pipeline Run Details View Page.

DevOps Pal Architecture

I used several components and tools to create DevOps Pal. Let’s review the architecture in detail.

The flow begins by saying, &quot;Alexa, open DevOps Pal and deploy my code&quot;, to the Echo device.

The Echo device listens for the wake word (e.g. Alexa, Echo, Computer, or Amazon), which employs deep learning technology running on the device to recognize the wake word the user has chosen.
Once the wake word is detected, what I say is recorded and sent to the Alexa Voice Service (AVS), which uses speech to text and natural language understanding (NLU) to identify my intent.
My intent is sent to DevOps Pal; the skill acts accordingly by kicking off the Jenkins job and sending a response back using text-to-speech synthesis (TTS), which makes the response natural sounding.

Let’s explore each component in more detail:

Alexa Voice Service (AVS) - I often refer to the Alexa Voice Service as the &quot;Alexa brain that runs in the cloud&quot;. The AVS is a suite of services built around a voice-controlled AI assistant. The AVS is flexible enough to allow third parties to add intelligent voice control to any connected product that has a microphone and speaker, so Alexa is not limited to just Echo devices.

Alexa Skills Kit (ASK) - ASK is the &quot;SDK&quot; (Software Development Kit) that allows developers to build custom skills for Alexa.

Alexa Developer Portal - An Alexa skill includes a voice user interface, or VUI, to understand user intents, and a back-end cloud service to process intents by telling Alexa how to respond. The VUI and the integration with the back-end service is setup and configured through the Alexa Developer Portal.

AWS Lambda - A chunk of code that runs in the cloud. Developers can run their code without having to provision or manage servers. Applications created with AWS Lambda are considered to be serverless. Lambda supports several popular languages like Python, Java, Node.js, Go, C#, etc.

GitHub - A version control system for the Java project source code.

Jenkins on EC2 - I use Jenkins to build, test, and deploy my Java Application Programming Interface (API). Elastic Cloud Computer (EC2) is the virtual server where Jenkins is installed. Jenkins works alongside several other tools:

Maven - A build automation tool for Java projects.

Junit - A testing framework for Java projects.

AWS Command Line Interface (CLI) - This is a command line tool that allows developers to access their Amazon Web Services (AWS) account.

Blue Ocean - This is a plugin for Jenkins that provides an easy to use interface to create and monitor Jenkins pipelines.

AWS Elastic Beanstalk - This is an orchestration service that allows developers to deploy and manage web applications in the AWS cloud.

Postman - This is an HTTP client for testing APIs and web services.

Voice Interaction Model

The Voice User Interface (VUI) describes the overall conversational flow and is setup via the Alexa Developer Console.

A few important components of the VUI are the Invocation Name (how users launch your skill) and the Intents (phrases a user says to &quot;talk to&quot; or interact with your skill).

Specifically, the &quot;DeployCodeIntent&quot; is invoked when a user says one of several phrases (e.g. run jenkins pipeline, run jenkins job, deploy the code, deploy code, or deploy ) or a variation of the phrase like, &quot;deploy my code&quot;.

The endpoint is the destination where the skill requests are sent for fulfillment.
In this case, the backend logic is an AWS Lambda authored in Python.
The business logic in the Python Lambda uses the Jenkins remote access API to trigger the job remotely.
The format of the URL to trigger the job is jenkins_url/job/job_name/build.
The API call uses BASIC authentication and a Jenkins Crumb passed in the HTTP request header for CSRF protection.
Alternatively, since Jenkins 2.96, you can use an API token instead of a Jenkins Crumb and password to authenticate your API call.

Jenkins Job

The Jenkins job, &#x27;alexa-cicd&#x27;, is the job invoked from DevOps Pal.
Although, the Jenkins Classic User Interface (UI) is functional, I prefer the Blue Ocean interface because it rethinks the user experience of Jenkins by making it visually intuitive.
Blue Ocean is easily enabled via a plugin and leaves the option to continue using the Jenkins Classic UI should you so choose.

After Alexa kicks off the &#x27;alexa-cicd&#x27; job, I navigate to the Pipeline Run Details View Page, which allows me to watch the job status in realtime.
This job has four stages: Initialize, Build, Test, and Deploy.
The final stage, Deploy, uses the AWS Command Line Interface (CLI) on the Jenkins server to copy the artifact to Amazon Simple Storage Service (S3) and create a new Elastic Beanstalk application version based on the artifact located on S3.

Cool Features to Add

The ability to deploy code with voice is just the beginning.
There are several cool features that can easily be added:

DevOps Pal can be updated to prompt the user for the specific Jenkins pipeline job name. This adds a level of flexibility that will really empower DevOps teams.

Alexa Notifications can be integrated with DevOps Pal to send a notification to the Echo device when the Jenkins job is finished or when it fails. If the job fails, more information about where the job failed and exactly why will be provided. This will prove useful for long running jobs or for getting timely updates regarding the job status.

DevOps Pal can be updated to answer direct questions about the real-time status of a specific job.

Want to Learn More

I hope you’ve enjoyed learning more about the architecture of DevOps Pal and deploying code to the cloud using Jenkins and voice.
For more detailed steps, I’ve collaborated with Cloud Academy to author a course, AWS Alexa for CI/CD on the subject.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/keshawilliams/">Kesha Williams</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/alexa">alexa</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/02/28/serverless-jenkins/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">28</div></div><h5 class="title">Run your Jenkins pipeline without operating a Jenkins instance</h5></div><p class="teaser">My job is to work on a Jenkins pipeline specific to SAP S/4HANA extensions running on SAP Cloud Platform.
See the original blog post here.

Jenkins is a powerful tool for automation, and we heavily rely on the codified pipeline syntax introduced in Jenkins 2.

With regards to operations, we minimized the need for care with the cx-server life-cycle management greatly.
Still, you need to run that Jenkins server.
This means you’ll need to update the server and plugins (simplified by our life-cycle management), and scale as the number of builds grows.
User administration and backups are also required in a productive setup.

Is this really required, or is there an alternative approach?

In this blog post, I’ll introduce a prototype I did to get rid of that long running pet Jenkins instance.
Rather, we’ll have cattle Jenkins instances, created and destroyed on demand.
“Serverless” Jenkins in the sense that we don’t have to provision the server for Jenkins to run.

The setup described in this post is highly experimental. I encourage you to try this out in a demo project, but be very cautious until further notice to use this on productive code. In this proof of concept, I’ll use a public GitHub repository and the free open-source offering by TravisCI. This setup is not suitable for commercial software.

The pets vs cattle metaphor describes how approaches in managing servers differ.
While you care for pets and treat them when they are unwell, cattle can be easily replaced.
Your traditional Jenkins server is a pet because it is often configured manually, and replacing it is a major effort.
For more background on this metaphor, click here.

Before we’re getting into the technical details, let’s discuss why we would want to try this out in the first place.
Running Jenkins on arbitrary CI/CD services, such as TravisCI seems very odd on first sight.
On such services you’ll usually invoke your build tools like Maven or npm in a small script, and that will do your build.
But in the enterprise world, both inside SAP and in the community, Jenkins has a huge market share.
There are many shared libraries for Jenkins, providing pre-made build steps which would be expensive to re-implement for other platforms.
Additionally, SAP S/4HANA Cloud SDK Pipeline is a ready to use pipeline based on Jenkins where you as the developer of an SAP S/4HANA extension application do not need to write and maintain the pipeline yourself.
This means reduced costs and effort for you, while the quality of your application improves, for example due to the many cloud qualities which are checked out of the box.

Let me show you an experiment to see if we can get the best of both worlds.
The goal is to get all the quality checks and the continuous delivery that the SAP S/4HANA Cloud SDK Pipeline provides us, without the need for a pet Jenkins server.

How do we do that? The Jenkins project has a project called Jenkinsfile runner.
It is a command line tool that basically boots up a stripped-down Jenkins instance, creates and runs a single job, and throws away that instance once the job is done. As you might guess, there is some overhead in that process.
This will add about 20 seconds to each build, which I found to be surprisingly fast, considering the usual startup time of a Jenkins server.
For convenient consumption, we have packaged Jenkinsfile runner as a Docker image which includes the Jenkins plugins that are required for SAP S/4HANA Cloud SDK Pipeline.

We also utilize the quite new Configuration as Code plugin for Jenkins, which allows to codify the Jenkins configuration as YAML files.
As you will see in a minute, both Jenkinsfile runner and Configuration as Code are a perfect match.

If you want to follow along, feel free to use our provided Address Manager example application.
You may fork the repository, or create your own repository and activate it on TravisCI.

Based on the existing Address Manager, let’s add a small.travis.yml file to instruct the build:

language: minimal
services:
- docker
script: docker run -v /var/run/docker.sock:/var/run/docker.sock -v ${PWD}:/workspace -v /tmp -e CASC_JENKINS_CONFIG=/workspace/jenkins.yml -e CF_PW -e ERP_PW -e BRANCH_NAME=$TRAVIS_BRANCH ppiper/jenkinsfile-runner

The script line has quite a few things going on, let’s see what is there.

We run a Docker container based on the ppiper/jenkinsfile-runner image.
We need to mount the Docker socket, so that our container can spawn sibling containers for tooling such as Maven or the CloudFoundry CLI.
We also need to mount the current directory (root of our project) to /workspace, and tell the Jenkins Configuration as Code Plugin where to find the configuration file.
We’ll come to that file in a minute. Also be sure to pass your secret variables here.
Travis will mask them, so they are not in plain text in your build log.
Take note to change the names of the variables according to your requirements.
You might wonder that we need a BRANCH_NAME environment variable.
This is required for the Pipeline to check if you’re working on the “productive branch”, where a productive deployment to SAP Cloud Platform is supposed to happen.
If you omit passing this variable, the pipeline will still run but never in the productive mode, and hence not deploy to SAP Cloud Platform.

You might need some secrets in the build, for example in integration tests or for deployment to SAP Cloud Platform.
You can make use of the travis command line tool to encrypt them on your local machine as documented here.
Take care that this might add your secret in plain text to the shell history on your machine.

travis encrypt CF_PW=supersecret --add
travis encrypt ERP_PW=alsosupersecret --add

This command will add a line to your.travis.yml file with the encrypted secret value.
Be sure to commit this change.
Also take note of the name of your variable, which must match the environment parameter, and your Jenkins configuration.
You should be aware of this TravisCI document on secrets.

We’ll also need to add a jenkins.yml file to our project.
Here we need to configure two shared libraries which are required for the SAP S/4HANA Cloud SDK Pipeline, and the credentials that are required for our pipeline.
Be sure not to put your secrets in plain text in here, but use the variables you used before via the travis cli tool.
TravisCI will decrypt the password on the fly for you.

jenkins:
  numExecutors: 10
unclassified:
  globallibraries:
    libraries:
    - defaultVersion: &quot;master&quot;
      name: &quot;s4sdk-pipeline-library&quot;
      retriever:
        modernSCM:
          scm:
            git:
              remote: &quot;https://github.com/SAP/cloud-s4-sdk-pipeline-lib.git&quot;
    - defaultVersion: &quot;master&quot;
      name: &quot;piper-library-os&quot;
      retriever:
        modernSCM:
          scm:
            git:
              remote: &quot;https://github.com/SAP/jenkins-library.git&quot;
credentials:
  system:
    domainCredentials:
      - credentials:
          - usernamePassword:
              scope: GLOBAL
              id: &quot;MY-ERP&quot;
              username: MY_USER
              password: ${ERP_PW}
          - usernamePassword:
              scope: GLOBAL
              id: &quot;cf&quot;
              username: P12344223
              password: ${CF_PW}

You might add more configuration to this file as you need it.

Commit both files to your repo and push.
If the travis build works, you’ll see the build integration on GitHub.

On travis, you can follow the progress of your build live, and get the full text log of your Jenkins build.
If all went well, you will be greeted with a green build after a few minutes.

Congratulations. You’re running a serverless Jenkins build with all the qualities checked by the SAP S/4HANA Cloud SDK Pipeline, without hosting your own Jenkins instance.

Keep in mind this is a proof of concept at this point.
The serverless Jenkins ecosystem is currently evolving, and neither Jenkinsfile runner, nor Configuration as Code are in a mature state as of February 2019.
One downside of this approach is that we lose the Jenkins user interface, so we can’t see our pipeline in blue ocean, and we don’t get the nice build summary.
We can get the whole log output from TravisCI, so this can be mitigated, but this is arguable not the best user experience.

But on the contrary, we don’t have to care for our pet Jenkins, we don’t need to update plugins or backup the configuration or build logs.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/fwilhe/">Florian Wilhelm</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/serverless">serverless</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/03/01/devops-world-jenkins-world-cfp-open/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 1</div></div><h5 class="title">DevOps World - Jenkins World 2019: Call for Papers is Open</h5></div><p class="teaser">The DevOps World | Jenkins World shuttle is ready for lift off once again. As usual, the sign of festivities looming begins with the Call for Speakers.
Those who attended DevOps World | Jenkins World 2018 know that DevOps World | Jenkins World 2019 is coming back to San Francisco, and adding a stop in  Europe - Lisbon, Portugal.

Jenkins World USA | San Francisco | August 12 - 15, 2019

Jenkins World Europe | Lisbon | December 2 - 5, 2019*

To encourage open collaboration and stimulate discussions that will help advance Jenkins adoption and drive it forward, we invite Jenkins users, developers and industry experts to submit a speaking proposal to DevOps World | Jenkins World San Francisco and or Lisbon.
Submissions for both locations are being accepted now.
The submission deadline for San Francisco, CA has been extended through March 24, 2019, @ 11:59 PM Pacific and the submission deadline for Lisbon, Portugal is June 9, 2019, @ 11:59 PM Pacific.

The below Q&amp;A will help you breeze through the submission process.

Where do I go to submit my proposal?

Submissions for both DevOps World | Jenkins World USA and Europe are accepted at:

Jenkins World USA

Jenkins World Europe

Can I make proposal(s) to both conferences?

Yes, you can! Once you’ve created an account on the CFP website you will be given the option to make submission(s) to one conference or both conferences.

When is the deadline for DevOps World | Jenkins World USA?

Saturday March 24, 2019 @ 11:59PM Pacific

When is the deadline for DevOps World | Jenkins World Europe?

Tuesday, June 9, 2019, @ 11:59 PM Pacific

San Francisco Important Dates:

January 9, 2019: Call for papers opens

March 24, 2019: Call for papers closes

April 12, 2019: Submission decisions sent

May 1, 2019: Agenda published - San Francisco, CA

May 6, 2019: Speaker tasklist is sent out

August 12-15, 2019: DevOps World | Jenkins World 2019 San Francisco

*Due to the deadline extensions for DevOps World | Jenkins World 2019 San Francisco any talks submitted after March 10th will be subject to the important dates below:

January 9, 2019: Call for papers opens

March 24, 2019: Call for papers closes

Week of April 1, 2019: Submission decisions sent

Week of April 29, 2019: Agenda published - San Francisco, CA

May 6, 2019: Speaker tasklist is sent out

August 12-15, 2019: DevOps World | Jenkins World 2019 San Francisco

Lisbon Important Dates:

January 9, 2019: Call for papers opens

June 9, 2019: Call for papers closes

July 19, 2019: Submission decisions sent

August 19, 2019: Agenda published

August 23, 2019: Speaker tasklist is sent out

December 2-5, 2019: DevOps World | Jenkins World 2019 Lisbon, Portugal

*All Dates Are Subject To Change.

We look forward to receiving your inspiring stories!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/svanalstine/">Skylar VanAlstine</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/03/04/gsoc2019-announcement/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 4</div></div><h5 class="title">Jenkins is accepted to Google Summer Of Code 2019!</h5></div><p class="teaser">On behalf of the Jenkins GSoC org team,
I am happy to announce that the Jenkins project has been accepted to
Google Summer of Code 2019.
This year we invite students and mentors to join the Jenkins community and work together
on enhancing the Jenkins ecosystem.

Just to provide some numbers, this is the biggest GSoC ever, 206 organizations will participate in GSoC this year.
And it will be hopefully the biggest year for Jenkins as well.
We have 25 project ideas
and more than 30 potential mentors (and counting!).
It is already more than in 2016 and 2018 combined.
There are many plugins, SIGs and sub-projects which have already joined GSoC this year.
And we have already received messages and first contributions from dozens of students, yey!

What’s next?
GSoC is officially announced, and please expect more students to contact projects in our
Gitter channels and mailing lists.
Many communications will also happen in SIG and sub-project channels.
We will be working hard in order to help students to find interesting projects, to explore the area,
and to prepare their project proposals before the deadline on April 9th.
Then we will process the applications, select projects and assign mentor teams.

All information about the Jenkins GSoC is available on its sub-project page.

I am a student. How do I apply?

See the Information for students page for full application guidelines.

We encourage interested students to reach out to the Jenkins community early and to start exploring project ideas.
All project ideas have chats and mailing lists referenced on their pages.
We will be also organizing office hours for students,
and you can use these meetings to meet org admins and mentors and to ask questions.
Also, join our Gitter channel and the
mailing list
to receive information about such incoming events in the project.

The application period starts on March 25th, but you can prepare now!
Use the time before the application period to discuss and improve your project proposals.
We also recommend that you become familiar with Jenkins and start exploring your proposal areas.
Project ideas include quick-start guidelines and reference newbie-friendly issues
which may help with initial study.
If you do not see anything interesting,
you can propose your own project idea
or check out ideas proposed by other organizations
participating in GSoC.

I want to be a mentor. Is it too late?

It’s not!
We are looking for more project ideas and for Jenkins contributors/users
who are passionate about Jenkins and want to mentor students.
No hardcore experience required, mentors can study the project internals together with students and technical advisors.
We are especially interested in ideas beyond the Java stack, and in ideas focusing new technologies and areas
(e.g. Kubernetes, IoT, Python, Go, whatever).

You can either propose a new project idea or join an existing one.
See the Call for Mentors post
and Information for mentors for details.
If you want to propose a new project,
please do so by March 11th so that students have time to explore them and to prepare their proposals.

This year mentorship does NOT require strong expertise in Jenkins development.
The objective is to guide students and to get involved into the Jenkins community.
GSoC org admins will help to find advisers if special expertise is required.

Important dates

Mar 11 - deadline for new GSoC project idea proposals

Apr 09 - deadline for student applications

May 06 - accepted projects announced, teams start community bonding and coding

Aug 26 - coding period ends

Sep 03 - Results announced

See the GSoC Timeline for more info.
In the Jenkins project we will also organize special events during and after GSoC (e.g. at Jenkins world).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/03/11/let-s-celebrate-java-11-support/"><div class="header"><div class="date"><div class="month">March</div><div class="day">11</div></div><h5 class="title">Let&#x27;s celebrate Java 11 Support on Jenkins</h5></div><p class="teaser">This is a joint blog post prepared by the Java 11 Support Team: Adrien Lecharpentier, Ashton Treadway, Baptiste Mathus, Jenn Briden, Kevin Earls, María Isabel Vilacides, Mark Waite, Ramón León and Oleg Nenashev.

We have worked hard for this and it’s now here.
We are thrilled to announce full support for Java 11 in Jenkins starting from Jenkins 2.164 (released on Feb 10, 2019) and LTS 2.164.1 (ETA: March 14th).
This means you can now run your Jenkins controllers and agents with a Java 11 JVM.

Starting in June 2018, many events were organized to improve Jenkins code base and add Java 11 support.
Beyond these events, Core/Plugins maintainers and many other contributors have worked hard to make sure they discover and solve as many issues as possible related to Java 11 support.

The effort to support Java 11 led to the creation of the JEP-211: Java 10+ support in Jenkins.
It also spurred the creation of the Platform Special Interest Group to coordinate the Java 11 work and other platform support efforts.

Celebration

We’d like to take a moment to thank everyone involved in these tasks: code contributors, issue reporters, testers, event planners and attendees and all those in the community who have generously lent their time and support to this effort.
Thank you all!

Here are some of the contributors who helped with this task (alphabetical order):

Alex Earl,
Alyssa Tong,
Ashton Treadway,
Baptiste Mathus,
Carlos Sanchez,
Daniel Beck,
David Aldrich,
Denis Digtyar,
Devin Nusbaum,
Emeric Vernat,
Evaristo Gutierrez,
Gavin Mogan,
Gianpaolo Macario,
Isabel Vilacides,
James Howe,
Jeff Pearce,
Jeff Thompson,
Jenn Briden,
Jesse Glick,
Jonah Graham,
Kevin Earls,
Ksenia Nenasheva,
Kohsuke Kawaguchi,
Liam Newman,
Mandy Chung,
Mark Waite,
Nicolas De Loof,
Oleg Nenashev,
Oliver Gondža,
Olivier Lamy,
Olivier Vernin,
Parker Ennis,
Paul Sandoz,
Ramón León,
Sam Van Oort,
Tobias Getrost,
Tracy Miranda,
Ulli Hafner,
Vincent Latombe,
Wadeck Follonier

(We are deeply sorry if we missed anyone in this list.)

Guidelines

In order to keep it simple, here is how you can start Jenkins on Java 11 using the Docker image.
You can select a Java 11 based image by suffixing the tag of the image with -jdk11.
If you are upgrading an existing instance please read the Upgrading Jenkins Java version from 8 to 11 page before upgrading.

So you can run Jenkins on Java 11 with:

docker run -p 50000:50000 -p 8080:8080 jenkins/jenkins:2.164-jdk11

However, and as always, you can still start Jenkins with other methods.
Please see the more detailed documentation at Running Jenkins on Java 11.

Developer guidelines

For developers involved in Jenkins development, you can find details on developing and testing Jenkins to run on Java 11 on the Java 11 Developer Guidelines.

This resource regroups the modifications which might need to be done in order to validate the compatibility of plugins for Java 11.

What’s next

Even though this is a big achievement, we still have work to do.

Our first priority is adding Java 11 support to JenkinsFile Runner project.
From there, we will move on to port Java 11 support to the Jenkins X project and the Evergreen project.

So, even if this is a big deal to us, this is not the end of the story.
It is a major step that will benefit users, developers, and members of the Jenkins community.

Reference links

Running Jenkins on Java 11

https://wiki.jenkins.io/display/JENKINS/Known+Java+11+Compatibility+issues

https://wiki.jenkins.io/display/JENKINS/Java+11+Developer+Guidelines

jep:211[Java 11 support in Jenkins]<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alecharp/">Adrien Lecharpentier</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java11">java11</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/03/12/cdf-launch/"><div class="header"><div class="date"><div class="month">March</div><div class="day">12</div></div><h5 class="title">Jenkins is joining the Continuous Delivery Foundation</h5></div><p class="teaser">Today Linux Foundation, along with CloudBees, Google, and a number of other companies, launched a new open-source software foundation called Continuous Delivery Foundation (CDF.) The CDF believes in the power of Continuous Delivery, and it aims to foster and sustain the ecosystem of open-source, vendor neutral projects.

Jenkins contributors have decided that our project should join this new foundation. This discussion happened over a period of time, with a relatively succinct summary of the motivation comes from here.

Now, as a user, what does this mean?

First, there will be no big disruption/discontinuity. The same people are still here, no URL is changing, releases will come out like they’ve always been. We will make the decisions the same way as we’ve been making, and pull requests land the same way. Changes will happen continuously over the period of time.

This is yet another testament to the maturity and the importance of the Jenkins project in this space. With a quarter million Jenkins running around the globe, it’s truly rocking the world of software development from IoT to games, cloud native webapps to machine learning projects. It makes Jenkins such an obvious, safe choice for anyone seeking open heterogeneous DevOps strategy.

The CDF creates a level playing field that is well-understood to organized contributors, which further, translate into more contributors, hence resulting in a better Jenkins, faster. Over the past years, the Jenkins project has been steadily growing more structures that provide this clarity, and this is the newest step on this trajectory.

Any serious dev teams are combining multiple tools and services to cover the whole software development spectrum. A lot of work gets reinvented in those teams to integrate those tools together. Jenkins will be working more closely with other projects under the umbrella of the CDF, which would result in better aligned software with less overlap.

Our users are practitioners trying to improve the software development process in their organizations. They get that CI/CD/automation which unlocks the productivity that their organizations need, but that’s not always obvious to their organizations as a whole. So our users often struggle to get the necessary support. The CDF will advocate for the practice of Continuous Delivery, and because it’s not coming from a vendor or a project, it will reach the people who can lend that support.

So I hope you can see why we are so excited about this!

In fact, for us, this is an idea that we’ve been cooking for close to two years. I don’t think I’m exaggerating much to say the whole idea of the CDF started from the Jenkins project.

A lot of people have done so much work behind the scene to make this happen. But a few people played such instrumental roles that I have to personally thank them namely, Chris Aniszczyk for his patience and persistence, R. Tyler Croy for cooking and evolving the idea, and Tracy Miranda for bringing this idea into a reality.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cdf">cdf</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/03/28/outreachy-review/"><div class="header"><div class="date"><div class="month">March</div><div class="day">28</div></div><h5 class="title">Outreachy 2018-2019 In Review</h5></div><p class="teaser">Over the past three months, I have been mentoring two Outreachy interns, David and Latha, with my co-mentor, Jeff Thompson.
Our project was to introduce a standardized way for creating an audit log of Jenkins and plugins using Apache Log4j Audit.
While this type of feature is addressed by other existing plugins, there is no unifying way for plugins to contribute their own actions.
This project provided ample opportunities for each of our interns to experience the community processes for starting a new Jenkins plugin, contributing changes to Jenkins itself in order to support more audit event types, using CICD principles, and developing a Jenkins Enhancement Proposal to begin the standardization process of audit logging throughout the ecosystem.

During this internship, David and Latha contributed several aspects of the project, much of which lays the foundation for easily instrumenting more subsystems and plugins with audit logs.
A template log4j2.xml file is used for allowing more complex logging output configurations with a configuration UI.

New APIs have been introduced in Jenkins to allow for more authentication-related events to be audited by the plugin.
Audit events have been defined for a few authorization scenarios and some build events.
For example, here is a snippet of audit log output for a build execution in the JSON layout:

{
  &quot;thread&quot; : &quot;Executor #0 for master : executing test #1&quot;,
  &quot;level&quot; : &quot;OFF&quot;,
  &quot;loggerName&quot; : &quot;AuditLogger&quot;,
  &quot;marker&quot; : {
    &quot;name&quot; : &quot;Audit&quot;,
    &quot;parents&quot; : [ {
      &quot;name&quot; : &quot;EVENT&quot;
    } ]
  },
  &quot;message&quot; : &quot;Audit [buildStart buildNumber=\&quot;1\&quot; cause=\&quot;[Started by user anonymous]\&quot; projectName=\&quot;test\&quot; timestamp=\&quot;Mon Mar 25 13:48:09 CDT 2019\&quot; userId=\&quot;SYSTEM\&quot;]&quot;,
  &quot;endOfBatch&quot; : false,
  &quot;loggerFqcn&quot; : &quot;org.apache.logging.log4j.audit.AuditLogger&quot;,
  &quot;instant&quot; : {
    &quot;epochSecond&quot; : 1553539689,
    &quot;nanoOfSecond&quot; : 810000000
  },
  &quot;contextMap&quot; : { },
  &quot;threadId&quot; : 54,
  &quot;threadPriority&quot; : 5
}
{
  &quot;thread&quot; : &quot;Executor #0 for master : executing test #1&quot;,
  &quot;level&quot; : &quot;OFF&quot;,
  &quot;loggerName&quot; : &quot;AuditLogger&quot;,
  &quot;marker&quot; : {
    &quot;name&quot; : &quot;Audit&quot;,
    &quot;parents&quot; : [ {
      &quot;name&quot; : &quot;EVENT&quot;
    } ]
  },
  &quot;message&quot; : &quot;Audit [buildFinish buildNumber=\&quot;1\&quot; cause=\&quot;[Started by user anonymous]\&quot; projectName=\&quot;test\&quot; timestamp=\&quot;Mon Mar 25 13:48:10 CDT 2019\&quot; userId=\&quot;SYSTEM\&quot;]&quot;,
  &quot;endOfBatch&quot; : false,
  &quot;loggerFqcn&quot; : &quot;org.apache.logging.log4j.audit.AuditLogger&quot;,
  &quot;instant&quot; : {
    &quot;epochSecond&quot; : 1553539690,
    &quot;nanoOfSecond&quot; : 155000000
  },
  &quot;contextMap&quot; : { },
  &quot;threadId&quot; : 54,
  &quot;threadPriority&quot; : 5
}

Best of all, this project has helped instill important software engineering values such as automated testing and continuous delivery.

As we conclude this round, we look forward to participating in the next Outreachy internship to continue this project and grow the community.
For more information about the next round, check out the Outreachy website.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jvz/">Matt Sicker</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreachy">outreachy</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/03/29/becoming-contributor-intro/"><div class="header"><div class="date"><div class="month">March</div><div class="day">29</div></div><h5 class="title">The journey of becoming a Jenkins contributor: Introduction</h5></div><p class="teaser">As a software engineer, for many years I have used open source software (frameworks, libraries, tools…​) in the
different companies I have worked at. However, I had never been able to engage in an open-source project as a
contributor, until now.

Since I made my first—​ridiculously simple—​commit into Jenkins, six months ago (in September, 2018), I have been
attempting to contribute more to the Jenkins project. However, contributing to open-source projects is, in general,
challenging. Especially to long-lived projects, with a lot of history, legacy code and tribal knowledge. It is often
difficult to know where to start and also difficult to come up with a plan to keep moving forward and contributing
regularly, and in more meaningful ways over time.

When it comes to the Jenkins project, I have encountered challenges that others trying to get into the community are
likely to encounter. For that reason, I have decided to go ahead and share my journey of becoming a more engaged Jenkins
contributor.

I plan to publish roughly 1 post per month, describing this journey. I will attempt to start contributing to the pieces
that are easier to start with, transitioning towards more complex contributions over time.

Where to start

jenkins.io

To become a Jenkins contributor, the most obvious place to start looking at is jenkins.io. In the
top navbar there is a Community dropdown, with several links to different sections. The first entry,
Overview, takes us to the “Participate and contribute” section.

In this section we get lots of information about the many ways in which we can engage with the Jenkins project and
community. Even though the intention is to display all the possible options, allowing the reader to choose, it can feel
a bit overwhelming.

The page is divided into two columns, the column on the left shows the different options to participate, while the
column on the right shows the different options to contribute.

Suggestions to Participate

In the left column of the “Participate and contribute” page, there are several ideas on how to engage with the community,
ranging from communicating to reviewing changes or providing feedback.

One of the pieces that got me confused at first in this area were the communication channels. There are many different
channels for communication. There are several mailing lists and there are also IRC
and Gitter channels.

During my first attempts to get involved, I subscribed to many of the mailing lists and several IRC and Gitter channels,
but I quickly noticed that there is significant communication going on; and that most threads in the most active lists
and channels are specific to issues users or developers have. So, unless your goal is to support other users right away
(if you are an experienced Jenkins user already it might be the case) or you plan to ask questions that you already
have in mind, I would advise against spending too much time on this at first.

Even though it is great to see how the community members support each other, the amount of communication might be
overwhelming for a newcomer, and if you are also trying to contribute to the project (either with translations,
documentation or code), following these conversations might not be the best way to start.

Suggestions to Contribute

In the right column of the “Participate and contribute” page there are several ideas on how to contribute, mostly
grouped into: writing code, translating, documenting and testing.

In following posts, I will be going through all of these types of contributions, as well as through some of the
suggestions to participate, which include reviewing Pull Requests (PRs) or providing feedback (either reporting new
issues or replicating cases other users have already described, providing additional information to help the maintainer
reproduce and fix them).

My first contribution in this journey

When looking at the “Participate and contribute” page, I noticed a couple of things in that page that I could help
improve. And I was actually planning to pick one of those as the first example of a contribution for this post. But
when I was reading the contributing guidelines of the repository, I found an even easier contribution I could make,
which I thought would be a great example to illustrate how simple it could be to start contributing. So I decided to go
ahead with it.

The website repository

In the ”Document” section there is a link to the
contributing guidelines of the jenkins.io repository.
The CONTRIBUTING file is a common file present in the root folder of most open-source-project repositories.

Following the link to that file, I reached the jenkins.io repository, which is the one that contains the sources for
the corresponding website—​which also includes this blog. And, in fact, the contributing file was the first file I
wanted to review, in order to learn more about how to contribute to the website.

Found a broken link

When reading the contributing file, I learned about the Awestruct static site generator, which is the tool used to
transform the AsciiDoc source files in the repo into a website. However, when I clicked the link to learn more about it, I noticed it was broken. The domain had expired.

Why not fix it?

This was the opportunity I chose to show other newcomers how easy it can be to start contributing.

Forking the repository

The first step, as usual, would be to fork the repository and clone it to my machine.

Applying the change

The next step would be to apply the change to the corresponding file. To do so, I created a new branch
“alternative-awestruct-link” and applied the change there:

Making sure everything builds correctly and tests pass

Even though in this case my contribution was not to the actual website, but to the contributing guidelines (and for
that reason was unlikely to break anything), it is a best practice to get used to the regular process every
contribution should follow, making sure everything builds correctly after any change.

As stated in the contributing guidelines themselves, in order to build this repository we just have to run the default
“make” target, in the root of the repository.

Once the command execution finishes, if everything looks good, we are ready to go to the next step: creating the PR.

Creating the PR

Once my change had been committed and pushed to my repository, I just had to create the PR. We have an easy way to do so
by just clicking the link that we get in our git logs once the push is completed, although we can create the PR directly
through the GitHub UI, if we prefer so; or even use “hub”, the GitHub CLI, to do it.

In this case, I just clicked the link, which took me to the PR creation page on GitHub. Once there, I added a
description and created the PR.

When a PR to this repository is created, we notice there are some checks that start running. Jenkins repositories are
configured to notify the “Jenkins on Jenkins”, which runs the corresponding CI pipelines for
each repository, as described in the corresponding Jenkinsfile.

Once the checks are completed, we can see the result in the PR:

And if we want to see the details of the execution, we can follow the “Show all checks” link:

PR Review

Now that the PR has been created and all automated checks are passing, we only have to wait for peer code reviews.

Once someone approves the PR and it is later merged, your contribution is integrated into the master branch of the
repository, becoming part of the next release.

I have contributed!

This contribution I made is a trivial one, with very little complexity and it might not be the most interesting one if
you are trying to contribute code to the Jenkins project itself.

However, for me, as the contributor, it was a great way to get familiar with the repository, its contributing
guidelines, the technology behind the jenkins.io website; and, above anything else, to start “losing the fear” of
contributing to an open source project like Jenkins.

So, if you are in the same position I was, do not hesitate. Go ahead and find your own first contribution. Every little
counts!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/romenrg/">Romén Rodríguez-Gil</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/contributing">contributing</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/newcomer">newcomer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/04/03/security-advisory/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 3</div></div><h5 class="title">Security spring cleaning</h5></div><p class="teaser">Today we published a security advisory that mostly informs about issues in Jenkins plugins that have no fixes.
What’s going on?

The Jenkins security team triages incoming reports both to Jira and our non-public mailing list.
Once we’ve determined it is a plugin not maintained by any Jenkins security team members, we try to inform the plugin maintainer about the issue, offering our help in developing, reviewing, and publishing any fixes.
Sometimes the affected plugin is unmaintained, or maintainers don’t respond in a timely manner to the notifications or the followup emails we send.

In such cases, we publish security advisories informing users about these issues, even if there’s no new release with a fix.
Doing so allows administrators to make an informed decision about the continued use of plugins with unresolved security vulnerabilities.
Today’s advisory is overwhelmingly such an advisory.

See a plugin you love on this list and want to help out? Learn about adopting plugins.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/05/05/telemetry-success/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 5</div></div><h5 class="title">First successful use of Jenkins telemetry</h5></div><p class="teaser">Half a year ago we delivered a security fix for Jenkins that had the potential to break the entire Jenkins UI.
We needed to change how Jenkins, through the Stapler web framework, handled HTTP requests, tightening the rules around what requests would be processed by Jenkins.
In the six months since, we didn’t receive notable reports of problems resulting from this change, and it’s thanks to the telemetry we gathered beforehand.

The Problem

Jenkins uses the Stapler web framework for HTTP request handling.
Stapler’s basic premise is that it uses reflective access to code elements matching its naming conventions.
For example, any public method whose name starts with get, and that has a String, int, long, or no argument can be invoked this way on objects that are reachable through these means.
As these naming conventions closely match common code patterns in Java, accessing crafted URLs could invoke methods never intended to be invoked this way.

A simple example of that is a URL every Jenkins user would be familiar with: /job/jobname.
This ends up invoking a method called #getJob(String), with the argument being&quot;jobname&quot;, on the root application object, and having it handle the rest of the URL, if any.
Of course, this is a URL intended to be accessed this way.
How about invoking Object#getClass(), followed by Class#getClassLoader(), by accessing the URL /class/classLoader?
While this particular chain would not result in a useful response, this doesn’t change that the methods were invoked.
We identified a number of URLs that could be abused to access otherwise inaccessible jobs, or even invoke internal methods in the web application server to invalidate all sessions.
The security advisory provides an overview of the issues we’d identified by then.

The Idea

To solve this problem inherent in the Stapler framework’s design, we defined rules that restrict invocation beyond what would be allowed by Stapler.
For example, the declared return type of getters now needed to be one defined in Jenkins core or a Jenkins plugin and have either clearly Stapler-related methods (with Stapler annotations, parameter types, etc.) or Stapler-related resource files associated with it.
Otherwise, the type wouldn’t be aware of Stapler, and couldn’t produce a meaningful response anyway.

This meant that getters just declaring Object (or List, Map, etc.) would no longer be allowed by default.
It was clear to the developers working on this problem that we needed the ability to be able to override the default rules for specific getters.
But allowing plugin developers to adapt their plugins after we published the fix wasn’t going to cut it;
Jenkins needed to ship with a comprehensive default whitelist for methods known to not conform to the new rules, so that updating would not result in problems for users.

The Solution

While there is tooling like Plugin Compatibility Tester and Acceptance Test Harness, many Jenkins plugins do not have comprehensive tests of their UI — the Jenkins UI is fairly stable after all.
We did not expect to have sufficient test coverage to deliver a change like this with confidence.
The only way we would be able to build such a comprehensive whitelist would be to add telemetry to Jenkins.

While Jenkins instances periodically report usage statistics to the Jenkins project, the information included is very bare bones and mostly useful to know the number of installations, the popularity of plugins, and the general size of Jenkins instances through number and types of jobs and agents.
We also didn’t want to just collect data without a clear goal, so we set ourselves some limitations — collect as little data as possible, no personally identifiable information, have a specific purpose for each kind of information we would collect, and define an end date for the collection in advance.
We defined all of this in JEP-214, created the Uplink service that would receive submissions, and added the basic client framework to Jenkins.
The implementation is fairly basic — we just submit an arbitrary JSON object with some added metadata to a service.
This system would inform tweaks to a security fix we were anxious to get out, after all.

Starting in mid October for weekly releases, and early November for LTS, tens of thousands of Jenkins instances would submit Stapler request dispatch telemetry daily, and we would keep identifying code incompatible with the new rules and amending the fix.
Ultimately, the whitelist would include a few dozen entries, preventing serious regressions in popular plugins like Credentials Plugin, JUnit Plugin, or the Pipeline plugins suite, down to Google Health Check Plugin, a plugin with just 80 installations when we published the fix.

Learning what requests would result in problems also allowed us to write better developer documentation — we already knew what code patterns would break, and how popular each of them was in the plugin ecosystem.

The Overhaul

I wrote above:

For example, the declared return type of getters now needed to be one defined in Jenkins core or a Jenkins plugin and have either clearly Stapler-related methods (with Stapler annotations, parameter types, etc.) or Stapler-related resource files associated with it.

While this was true for the fix during most of development, it isn’t how the fix that we published actually works.
About a month before the intended release date, internal design/code review feedback criticized the complicated and time-consuming implementation that at the time required scanning the class path of Jenkins and all plugins and looking for related resources, and suggested a different approach.

So we tried to require that the declared type or any of its ancestors be annotated with the new annotation @StaplerAccessibleType, annotated a bunch of types in Jenkins itself ( ModelObject being the obvious first choice), and ran our scripts that check to see whether Stapler would be allowed to dispatch methods identified in telemetry.
We’d long since automated the daily update of dispatch telemetry processing, so it was a simple matter of changing which Jenkins build we were working with.

After a few iterations of adding the annotation to more classes, the results were very positive: Very few additional types needed whitelisting, while many more were no longer (unnecessarily) allowed to be dispatched to.
This experiment, late during development, ended up being essentially the fix we delivered.
We didn’t need to perform costly scanning of the class path on startup — we didn’t need to scan the class path at all — , and the rules governing request dispatch in Stapler, while different from before, are still pretty easy to understand and independent of how components are packaged.

The Outcome

As usual when delivering a fix we expect could result in regressions in plugins, we created a wiki page that users could report problems on.
Right now, there’s one entry on that wiki page.
It is one we were aware of well before release, decided against whitelisting it, and the affected, undocumented feature in Git Plugin ended up being removed.
The situation in our issue tracker is only slightly worse, with two apparently minor issues having been reported in Jira.

Without telemetry, delivering a fix like this one would have been difficult to begin with.
Tinkering with the implementation just a few weeks before release and having any confidence in the result?
Not causing any significant regressions?
I think this would simply be impossible.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/telemetry">telemetry</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/05/09/chinese-localization/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 9</div></div><h5 class="title">A Big Step of the Chinese Localization</h5></div><p class="teaser">Since 2017, I started to do some contributions to the Jenkins community. As a beginner, translation might be
the easiest way to help the project. You don’t need to understand the whole context, even to create a ticket in the
issue tracker system. Improvement of localization usually is minor. But some problems occurred soon,
there isn’t a native speaker of Chinese that could review my PRs. So, sometimes my PRs
are delayed from being merged into master.

Some contributors told me that I can start a thread at the mailing list. Normally, discussing at the mailing list
is the open source community way. We got a lot of ideas for the localization from there. As a result,
we achieved some goals that I’d like to share here.

JEP-216

Previously, language localization files were distributed in core and in each plugin.
For this proposal, each language has a single localization plugin, such as Chinese Localization plugin.
Finally, Localization Support Plugin and
Chinese Localization plugin are able to support
all types of localization resource files. From the plugins website,
you can see that there are already 13 000 installations.
We removed all Chinese localization files at the PR-4008.

I really appreciate Daniel Beck for helping me to add localization support,
Liam Newman helping me to review JEP-216, and many other community members.

Chinese Localization SIG

We believe that this SIG could help to improve Jenkins experience for Chinese users and gather more contributors
from China. This SIG is responsible for maintaining the Chinese Jenkins website,
promoting the Jenkins community in China in the social media with WeChat account. We publish translated blog
articles, Jenkins release notes, JAM or other events at the WeChat account. For now, there are 1800 followers that can
read our news from the last half a year.

Especially, I want to say thanks to Wang Donghui, Zhai Zhijun, and other contributors. They did a lot of contributions.
I wish I could see more and more folks join us.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/linuxsuren/">赵晓杰(Rick)</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/localization">localization</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/chinese">chinese</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/05/09/templating-engine/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 9</div></div><h5 class="title">Introducing the Jenkins Templating Engine!</h5></div><p class="teaser">Implementing DevSecOps practices at the enterprise scale is challenging. With multiple programming languages, automated testing frameworks, and security compliance tools being used by different applications within your organization, it becomes difficult to build and maintain pipelines for each team.

Most pipelines are going to follow the same generic workflow regardless of which specific tech stack is employed by an application.  The Templating Engine Plugin (abbreviated as JTE for Jenkins Templating Engine) allows you to capture this efficiency by creating tool-agnostic, templated workflows to be reused by every team.

As technology consultants with clients in both the public and private sectors, at Booz Allen we found ourselves building DevSecOps pipelines from scratch for every new project.  Through developing the Jenkins Templating Engine, we’ve seen pipeline development decrease from months to days now that we can reuse tool integrations while bringing a new level of governance to Jenkins pipelines.

Pipeline Templating

Organizations benefit from letting application developers focus on what they do best: building applications. Supporting this means building a centralized DevOps team responsible for maintaining platform infrastructure and creating CI/CD pipelines utilized by development teams.

With the rise of microservice-based architectures, a centralized DevOps teams can support many different development teams simultaneously; all of whom may be leveraging different programming languages and automated testing tools.

While the tools may differ between development teams, the workflow is often the same: unit test, static code analysis, build and publish an artifact, deploy it, and then perform different types of testing against the deployed application.

The Templating Engine Plugin allows you to remove the Jenkinsfile from each repository by defining a common workflow for teams to inherit.  Instead of an entire pipeline definition in each repository, teams supply a configuration file specifying which tools to use for the workflow.

JTE in Action

Let’s walk through a bare bones example to demonstrate the reusability of templates:

Example Pipeline Template:

unit_test()
build()
static_code_analysis()

Templates leverage Steps contributed by Libraries to outline a workflow teams must implement.  While a template does get executed just like any other Jenkinsfile (meaning that the standard scripted and declarative syntax is supported), the goal of a template should be to read like plain English and avoid any technical implementation.

Leveraging templates in this way lets you separate the business logic (what should happen when) of your pipeline from the
technical implementation (what’s actually going to happen).  The result of this is a CI/CD pipeline that’s proven to be
significantly easier to manage when supporting multiple teams simultaneously.

The steps outlined by this template ( unit_test, build, and static_code_analysis) have been named generically on purpose. This way teams can specify different libraries to use while sharing the same pipeline.

Implementing the Template

Implementing a shareable pipeline with the Templating Engine requires a few key components:

Pipeline Template : Outline the workflow to be performed

Libraries : Provide technical implementations of the steps of the workflow

Configuration Files : Specify which libraries to use and their configuration

Step 1: Create a Pipeline Configuration Repository

A Pipeline Configuration Repository is used to store common configurations and pipeline templates inherited by teams.

This example Pipeline Configuration Repository will later be configured as part of a Governance Tier : the mechanism in JTE that allows you to build hierarchical configurations representing your organization.

A Governance Tier holds three things:

Pipeline Templates

A list of Library Sources

The tier’s configuration file ( pipeline_config.groovy)

The pipeline templates and the configuration file for a Governance Tier are stored in the pipeline configuration repository.

When configuring the Governance Tier in Jenkins, you will provide a source code management location for a repository that contains the above components as well as the base directory where these artifacts can be found.

Step 2: Create the Pipeline Template

Next, we’ll create a Jenkinsfile for the Governance Tier.  In JTE, the Jenkinsfile is the default pipeline template that an execution will use.

Jenkinsfile

unit_test()
build()
static_code_analysis()

Step 3: Create the Libraries

The Templating Engine Plugin has implemented a version of Jenkins Shared Libraries to enhance the reusability of libraries.  A library is a root directory within a source code repository that has been configured as a Library Source on a Governance Tier.

In our example, the pipeline template needs to perform unit testing, package an artifact, and run static code analysis.

Let’s assume that we have some teams using gradle and some teams using maven to build and test their application but they will both use SonarQube to perform static code analysis.

In this scenario, we should create gradle, maven, and sonarqube libraries.

|- gradle/
  \-- build.groovy
  \-- unit_test.groovy
|- maven/
  \-- build.groovy
  \-- unit_test.groovy
|- sonarqube/
  \-- static_code_analysis.groovy

Step 4: Implement the Steps

Implementing a library step is exactly the same as just writing regular global variables as part of the default Jenkins Shared Libraries.

For the purposes of this demonstration, we will just have each step print out the step name and contributing library.

gradle/build.groovy

void call(){
    println &quot;gradle: build()&quot;
}

Read more about Library Development within JTE.

Step 5: Create the Configuration Files

The configuration file for JTE is named pipeline_config.groovy.

In the Governance Tier we’ll create a configuration file specifying common configurations between the applications. In this case, both applications are using the sonarqube library:

pipeline_config.groovy

libraries{
  merge = true // allow individual apps to contribute additional libraries
  sonarqube
}

Next, we’ll create two more repositories representing the maven and gradle applications. Within those repositories all we’ll need is an application-specific pipeline_config.groovy file.

These repositories both contain an application pipeline_config.groovy configuration file.

maven app: pipeline_config.groovy

libraries{
    maven
}

gradle app: pipeline_config.groovy

libraries{
    gradle
}

Step 6: Configure the Governance Tier in Jenkins

Now that we have a Pipeline Configuration Repository and a Library Source Repository, we can configure a Governance Tier in Jenkins:

This configuration shown in the image above can be found under Manage Jenkins &gt;&gt; Configure System

Through the Templating Engine, you can create a pipeline governance hierarchy matching your organization’s taxonomy by representing this structure via Folders in Jenkins.

Step 7: Create a Multibranch Pipeline for Both Applications

When creating Multibranch Pipeline Projects for each app, the Templating Engine plugin supplies a new Project Recognizer
called Jenkins Templating Engine.  This sets the project to use the Templating Engine framework for all branches within the
repository.

You can also set the Jenkins Templating Engine project recognizer for a GitHub Organization project, enabling you to easily share the same pipeline across an entire Github Organization!

Step 8: Run the Pipelines

That’s it!  Now, both applications will leverage the exact same pipeline template while having the flexibility to select which
tools should be used during each phase of the workflow.

Below is sample output from the console log from both applications pipeline runs:

Gradle:

[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-configuration
[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-app-gradle.git
[JTE] Loading Library sonarqube from git https://github.com/steven-terrana/example-jte-libraries.git
[JTE] Loading Library gradle from git https://github.com/steven-terrana/example-jte-libraries.git
...
[JTE] Obtained Template Jenkinsfile from git https://github.com/steven-terrana/example-jte-configuration
[JTE][Step - gradle/unit_test]
[Pipeline] echo
gradle: unit_test()
[JTE][Step - gradle/build]
[Pipeline] echo
gradle: build()
[JTE][Step - sonarqube/static_code_analysis]
[Pipeline] echo
sonarqube: static_code_analysis()
[Pipeline] End of Pipeline

Maven:

[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-configuration
[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-app-maven.git
[JTE] Loading Library sonarqube from git https://github.com/steven-terrana/example-jte-libraries.git
[JTE] Loading Library maven from git https://github.com/steven-terrana/example-jte-libraries.git
...
[JTE] Obtained Template Jenkinsfile from git https://github.com/steven-terrana/example-jte-configuration
[JTE][Step - maven/unit_test]
[Pipeline] echo
maven: unit_test()
[JTE][Step - maven/build]
[Pipeline] echo
maven: build()
[JTE][Step - sonarqube/static_code_analysis]
[Pipeline] echo
sonarqube: static_code_analysis()
[Pipeline] End of Pipeline

Benefits of the Templating Engine

Apply Organizational Governance

Leveraging the Templating Engine Plugin will allow you to define enterprise-scale, approved
workflows that can be used by teams regardless of what tools are being used.  This top-down
approach makes scaling and enforcing DevSecOps principles significantly easier within your organization.

Optimize Code Reuse

There’s really no need for every team in your organization to figure out how to do the same things over
and over again.  At Booz Allen, we have seen pipeline development time decrease from months to days as
we have continuously reused and expanded upon our Templating Engine library portfolio as part of our Solutions
Delivery Platform.

Simplify Pipeline Maintainability

Often DevOps engineers find themselves building and supporting pipelines for multiple development teams at
the same time.  By decoupling the workflow from the technical implementation and consolidating the pipeline
definition to a centralized location, the Templating Engine plugin allows DevOps engineers to scale much faster.

Get Involved!

The Templating Engine Plugin has been open sourced and made available in the Jenkins Update Center.

We always appreciate feedback and contributions! If you have an interesting use case or would like to ask questions, try the templating-engine-plugin on Gitter.

Advanced Features

Configuration File Conditional Inheritance

Externalize Library Configurations

Aspect Oriented LifeCycle Hooks

Multiple Pipeline Templates

Default Step Implementation

Configuration File DSL Sandboxing

More Resources

For this Demonstration

Pipeline Configuration Repository

Sample Libraries

Sample Maven Repository

Sample Gradle Repository

Additional Resources

Templating Engine Documentation

Source Code

Booz Allen’s SDP Pipeline Libraries

Booz Allen Hamilton<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/steven-terrana/">Steven Terrana</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline-authoring">pipeline-authoring</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/05/11/docs-sig-announcement/"><div class="header"><div class="date"><div class="month">May</div><div class="day">11</div></div><h5 class="title">Jenkins Documentation Special Interest Group</h5></div><p class="teaser">We’re pleased to announce the formation of the Jenkins Documentation Special Interest Group.
The Docs SIG encourages contributors and external communities to create and review Jenkins documentation.

See the Special Interest Group Overview for more details and plans.

How can I help?

The Jenkins Documentation SIG would love to have your help with:

reviewing and fixing open bug reports

reviewing Jenkins documentation pull requests

reviewing Jenkins X documentation pull requests

How can I fix a documentation bug?

Instructions for contributing to the Jenkins documentation are in the CONTRIBUTING file of the site repository.
Follow the instructions in that file and submit pull requests for review.

Instructions for contributing to the Jenkins X documentation are on the Jenkins X documentation site.
Follow the instructions in that file and submit pull requests for review.

How can I evaluate a pull request?

Pull requests for the Jenkins project are reviewed in the Jenkins documentation repository.
Log in to GitHub with your credentials and add your review comments to pull requests.

Pull requests for the Jenkins X project are reviewed in the Jenkins X documentation repository.
Login to GitHub with your credentials and add your review comments to pull requests.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docs">docs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/05/22/outreachy-audit-log-project/"><div class="header"><div class="date"><div class="month">May</div><div class="day">22</div></div><h5 class="title">Audit Logging in Jenkins: An Outreachy Project</h5></div><p class="teaser">The Audit Log Plugin for Jenkins is an in development project to integrate standardized audit logging trails to various core actions in Jenkins.
This project integrates the recently released Apache Log4j Audit library to allow for a vast array of possible audit logging destinations and configuration.
We began this plugin not long after Log4j Audit 1.0.0 was released last year by partnering with Outreachy where we mentored two interns who laid the foundations of the project.
This year, we applied to Outreachy again to continue the project, and we were able to accept two more Outreachy interns: Aarthi Rajaraman and Gayathri Rajendar.
Both have already been adding new features and improving the plugin over the past couple months, and the internship officially began on 20 May.

This round has some ambitious goals of various features and documentation we wish to create.
After having added audit log support for several built-in event listeners in Jenkins around the lifecycle of projects, builds, nodes, and authentication during both the previous internship and the applications to this one, we would like to accomplish the following:

Make a 1.0 release of the plugin for the Jenkins Update Center. #34

Add documentation on supported audit log types and configuration options. #40

Add audit logs for credential usage and lifecycle events. #35, #36

Add audit logs for user property lifecycle events. #37

Define or document an API for other plugins to use to define and log their own audit events. #30

Ensure audit log events use consistent vocabulary with the Jenkins UI. #33

Add an audit log event recorder/viewer comparable to the Jenkins logger recorder administrative UI. #32

Add support for configuring a syslog-compatible log server for writing audit logs. #29

Add support for configuring a relational database such as PostgreSQL for writing audit logs. #31

Improve unit test coverage and pay down technical debt. #38

Begin discovery on alternative ways to manage the underlying Log4j Core configuration such as via the upcoming integration with Spring Cloud Configuration. #39

In the future, we hope to participate with more projects and mentors.
Going on concurrently with Outreachy right now is Google Summer of Code 2019 where we are mentoring several more projects and students.
Please extend a warm welcome to all our new contributors and community members from Outreachy and GSoC!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jvz/">Matt Sicker</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/logging">logging</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreachy">outreachy</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/05/30/becoming-contributor-newbie-tickets/"><div class="header"><div class="date"><div class="month">May</div><div class="day">30</div></div><h5 class="title">Becoming a Jenkins contributor: Newbie-friendly tickets</h5></div><p class="teaser">Two months ago I published an introductory article on
the journey of becoming a Jenkins contributor. In that first article, the jenkins.io site was reviewed, learning about
the multiple ways in which we can participate and contribute. Then, a first—​basic—​contribution I made to the site
repository was described.

Now, in this new article we will be exploring more advanced contributions, committing code to the actual Jenkins core.

Getting started with tickets and processes

Beginners guide to contributing and Jenkins Jira

Reviewing the developer section in jenkins.io is probably the best starting point, and a
reference link to keep handy. The beginners guide to contributing to Jenkins
can also be useful, since it points to different repositories, tools (such as the issue tracker) and governance documents.
Besides, it describes best practices for commit messages, code style conventions, PR guidelines, etc.

Once we get a general understanding of the former and want to actually start coding, we may get stuck trying to come up
with something to work on.

Visiting the Jenkins issue tracker, feels like the natural next
step, since it is full of potential bugs and enhancements that have already been reported by the community. However, it
is quite easy to feel overwhelmed by the possibilities listed there. Bear in mind that in a 10+-year-old project like
this, most of the things that are reported are tricky for a newcomer to work on. For that reason, filtering by
newbie-friendly tickets is probably
the best idea.

Figure 1. Screenshot displaying the list of newbie-friendly tickets in the Jenkins Jira

Selecting a ticket

In my case, I spent some time reviewing the newbie-friendly tickets, until I found one
that seemed interesting to me and also looked like something I would be able to fix:

Figure 2. Screenshot of the ticket I decided to work on

Processes

At this stage, when we have decided to take ownership of a ticket, it’s a good practice to let the rest of the community
know that we are planning to start working on it. We can do so easily, by assigning the ticket to ourselves (see the
“ Assign ” button below the ticket summary).

Assigning the ticket to ourselves in the Jenkins Jira will allow any other contributors to know that we are planning to
take care of the ticket; and in case they are also interested in contributing to it, they will know who to reach if they
want to coordinate work or ask for status. That said, it is worth mentioning that assigning a ticket to yourself does
not mean that other contributors cannot work on it from then onwards. Jenkins is an open-source project and anyone is
welcome to create their own PRs, so anybody can propose their own solution to the ticket. But as you can guess, if the
ticket is assigned to somebody, most people will probably reach the assignee before starting to work on it.

Related to the former, it is also important to bear in mind that we should not postpone work on the ticket for too long
once we have assigned the ticket to ourselves. Other potential contributors might be ignoring the ticket because they
see yourself assigned to it.

Once we are about to actually start working on the ticket, it is also a good practice to click the “ Start Progress ”
button. This action will change the status to “ In progress ”, signaling to the community that we are currently working
on this particular ticket.

Setting up the necessary stuff on our computer

Configuring, installing and testing

As described in the first article of this journey, the
initial step to start contributing to a particular repository is to fork it to our GitHub account, and then clone it to
our local computer.

As usual, in the Jenkins core repository the CONTRIBUTING file
describes the necessary steps to get the repository working locally. This includes installing the necessary development
tools: Java Development Kit ( OpenJDK is the recommended choice), Maven and any IDE supporting
Maven projects. Note that instructions to install JDK and Maven are linked in the contributing guidelines.

Once we have all the necessary tools installed and configured, we are ready to build Jenkins locally
and also to run tests.

Getting down to business

Reviewing ticket details

Now that I was ready to start working on the ticket, I had to review it in more detail, to fully understand the problem.

The description of the ticket I was planning to work on included two links. The first one was to
a screenshot that showed the actual bug. It showed
how several non-compatible plugins were being selected when clicking “ All ”, even though the intended behavior was to
only select the compatible plugins. The second link was a reference to a code fragment
that showed other validations that had to be taken into account when checking if a plugin update was compatible or not
with the current installation.

Reproducing the issue locally

Even though I had now understood the issue in better detail, I had not seen it myself live yet, so it seemed to me that
the next logical step was to reproduce it locally.

To reproduce the issue locally in our computer, we can either use the local war file that we can generate by
building Jenkins from the source code
or we can download the latest Jenkins version available and run it locally. When I worked
on this ticket, the latest available version was 2.172 and, when I built if from the sources I saw version 2.173-SNAPSHOT,
which was the next version, in which the community was already working on.

In general it is a good idea to reproduce bugs locally, not only to get a better understanding, but also to make sure
they are actual issues. It could always be an issue happening only on the reporter’s end (e.g. some user misconfiguration).
Or it could be a ticket referencing an old issue that has been fixed already. This latest possibility didn’t sound that
strange to me, since the ticket was one month old. It could have been handled by someone else in the meantime, without
noticing the ticket existed. Or the contributor might have forgotten to update the ticket in the issue tracker after the
fix was committed.

So, for all the reasons above, I ran the latest Jenkins version locally. From a terminal, I went to the
folder in which the war file was placed, and ran java -jar jenkins.war, which starts Jenkins locally on http://localhost:8080.

From the home page I navigated to the Plugin Manager (clicking the “ Manage Jenkins ” link in the left hand side and
then selecting “ Manage Plugins ” in the list).

In the Manage Plugins page, the list of plugin updates appears. In my case, since I re-used an old JENKINS_HOME
from an older installation, several plugins showed up in the list, requiring updates. That allowed me to test the behavior
that was supposed to be failing.

When I clicked on the “Select all” option at the bottom, this is what I got:

Figure 3. Screenshot showing the error, reproduced locally, after clicking “Select All”

As it had been reported in the ticket, the behavior was inconsistent. In a previous version, the behavior of the “ All ”
selector had been changed (with the best intent), aiming to only check the compatible plugins. However, as can be seen
in the screenshot, the behavior was not the expected one. Now, neither “all” nor “only compatible” plugins were being
selected, since some plugins with compatibility issues were also being checked, unintentionally.

Figuring out a fix

When reading the conversation in the original PR in which the behavior of the “ All ” selector had been changed, I saw a
suggestion of having a separate “ Compatible ” selector, thus leaving the “ All ” selector with the traditional behavior.
I liked the idea, so I decided to include it as part of my proposed change.

At this stage, I had a clear picture of the different things I needed to change. These included: 1) The UI, to add a new
selector for “Compatible” plugins only, 2) the JS code that applied the changes to the interface when the selectors were
clicked and 3) probably the back-end method that was determining if a plugin was compatible or not.

Applying the change

As usual, and as it is also recommended in the contributing guidelines, I created a separate feature branch to work on
the ticket.

After reviewing the code, I spent some time figuring out which pieces I needed to change, both in the back-end and also
in the front-end. For more details about the changes I had to make, you can take a look at the changes in my PR.

As a basic summary, I learned that the classic Jenkins UI was built using Jelly
and, after understanding its basics, I modified the index.jelly file to include the new selector, assigning the
function that checked the compatible plugins to this new selector, and re-using the existing “toggle” function to set
all checkboxes to true in the case of “ All ”. I also had to modify the behavior of the checkPluginsWithoutWarnings
JavaScript function, to un-check the incompatible ones, since there was now an actual “ All ” selector that was not there
previously, and that un-check case was not being taken into account. Then, I created a new back-end Java method
isCompatible, inside the UpdateSite.java class, which now calls all the different methods that check different
compatibilities and returns the combined boolean result. For this change, I included an automated test to verify the
correct behavior of the method, contributing to the test coverage of the project. Finally, I modified the table.jelly
file to call the new back-end method from the UI, replacing the existing one that was not taking all cases into account.

As you can see, the change involved touching different technologies, but even if you face a similar situation in which
you are not familiar with some of them, my advice would be carry on, don’t let that stop you. As software engineers, we
should focus on our evergreen skills, rather than on knowing
specific technologies; adapting to whatever framework we have to use at a given moment, learning whatever we need about
the new technology to complete the task and applying cross-framework principles and best practices to provide a quality
solution.

Result

After the changes described above, the resulting UI includes a new option, and the corresponding behaviors of the three
selectors work as expected:

Figure 4. Screenshot of the new version, displaying the behavior achieved by clicking the new “Compatible” selector

Publishing the change

Submitting a Pull Request

In the contributing guidelines of the Jenkins core repository there is also a section about proposing changes,
which describes the necessary steps that have to be followed in order to create a Pull Request (PR) with our change.

Furthermore, there is a PR template in
the repository, which will be loaded automatically when creating a new PR and that will serve as a basis for us to provide
the necessary information for the reviewers. We are expected to: include a link to the ticket, list the proposed changelog
entries describing our changes, complete the submitter checklist and add mentions to the desired reviewers (if any).

In my case, I followed the template when creating my PR,
completing all sections. I linked the Jira ticket, provided two proposed changelog entries, completed the submitter
checklist and added three desired reviewers (explaining why I thought their reviews would be valuable). I also linked
the original PR that was referenced in the ticket, to provide further context.

Figure 5. Screenshot of the PR I submitted

The approve and merge process

As stated in the contributing guidelines, typically two approvals are needed for the PR to be merged; and it can take
from a few days to a couple of weeks to get them. Sometimes, one approval from a reviewer and a 1-week delay without
extra reviews is considered enough to set the PR as ready-for-merge. However, both the time-to-merge and the number
of approvals necessary might vary, depending on the complexity of the change or the area of Jenkins core that it affects.

After the necessary approvals have been received, a Jenkins core maintainer will set the PR as ready-for-merge, which
will lead to it being merged into the master branch when one of the following releases are being prepared.

In my case, I received a review by Daniel (the reporter of the ticket and one of my “desired reviewers”) the very day I
submitted the PR (April 14th). He made several very useful suggestions, which led to changes from my side. After those
changes, Daniel made minor remarks and my PR got another review, which was its first approval. After a week had passed
without further news, I added the remaining minor suggestions from Daniel and a few days later received another approval,
to which Daniel’s final approval was added, leading the PR to be labeled ready-for-merge, being later merged the same
day (April 26th).

Figure 6. Screenshot of the final state of the PR, after being merged

Release

For every new release, repository maintainers will select a set of PRs that have already been labeled ready-for-merge,
merge them to master, prepare changelogs (often using the suggestions included in the PRs by the authors) and proceed with
the creation of the new release. There is no additional action required from Pull Request authors at this point.

Every week a new version of Jenkins is released, so when your PR is merged, your changes will—​most likely—​become part
of the following weekly release of Jenkins.

Eventually, your changes will also reach the Long-term support (LTS) release, which is
a different release line, aimed for more conservative users. This release line gets synced with the weekly release by
picking, every 12 weeks, a relatively recent weekly release as baseline for the new LTS release. In between, intermediate
LTS releases are created only to include important bug fixes, cherry-picked from the weekly releases. New features are
typically delayed until the next baseline for the LTS release is defined.

Regarding the example described in this post, it was released in Jenkins 2.175 (weekly release), soon after being
merged. And will probably be included in the next LTS, which should be released next month (June 2019).

Done!

And that’s it! We have now covered the whole lifecycle of a new proposed change to Jenkins core. We have reviewed the
process from the very beginning, picking a ticket from the Jenkins issue tracker; all the way to the end, having our
change released in a new Jenkins version.

If you have never contributed but are willing to do so, I hope this article motivates you to go back to the list of
newbie-friendly tickets, find one that looks interesting to you, and follow the steps described above, until you see
your own change released in a new Jenkins version.

Remember, don’t try to solve a complicated issue as your first ticket, there are plenty of easier ways in which you can
contribute, and every little helps!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/romenrg/">Romén Rodríguez-Gil</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/contributing">contributing</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/newcomer">newcomer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/06/03/DevOps-World-Jenkins-World-2019-San-Francisco-Agenda-is-Live/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 3</div></div><h5 class="title">DevOps World-Jenkins World 2019 San Francisco: Agenda is Live</h5></div><p class="teaser">We are a little over two months away from the largest Jenkins gathering of the year.  From Jenkins users, to maintainers, contributors, mentors and those new to Jenkins this event will have something for everyone.

This year’s DevOps World - Jenkins World 2019 San Francisco has moved to a larger venue to facilitate the growth. From August 12 - 15, 2019 the event will take place at the Moscone West Center.  The event boasts 100+ sessions, and will offer training, hands-on workshops, onsite certification, contributor summit and much more.  Conference attendees can expect to be inspired while learning the latest innovations from industry leaders. Attendees will learn the value that digital transformation has in delivering software more efficiently, more quickly and with higher quality.

We are excited to announce most of the agenda for DevOps World Jenkins World San Francisco is now live. We will continue to fill out the agenda with more sessions, trainings/workshops, and activities. Below is a small sampling of sessions from some of our favorite Jenkins contributors:

Jenkins Configuration as Code: try it &amp; start contributing! - Ewelina Wilkosz

Jenkins Configuration as Code is an open source Jenkins plugin that allows users to keep complete Jenkins configuration in a simple configuration file (yaml format). In the talk, I’ll briefly present the history of the plugin, the vision for the future and current status. Then I’ll move to the demo section where I’ll show how easy it is to configure and run Jenkins with the help of the plugin.

Thinking about Jenkins Security - Mark Waite &amp; Wadeck Follonier

Jenkins security concepts, authorization, authentication and auditing, secure builds, agent security, configuration and administration security, auditing, and security best practices.

Docker and Jenkins [as Code] - Dr. Oleg Nenashev

The Configuration as Code plugin is a new milestone which enables managing Jenkins configurations via YAML. Together with Docker, this plugin offers many ways to produce ready-to-fly Jenkins images for any environments. In my talk, I will describe official controller and agent images offered by the Jenkins project. What’s inside them? How do you configure images with JCasC and Groovy hooks? How do you use these approaches together? And, finally, how do you simplify packaging of custom Jenkins images and define the entire system [as code]?

Can Jenkins be the Engine of Mobile DevOps? - Shashikant Jagtap

In this talk, we will explore the following topics:

How mobile DevOps is different than web DevOps

Challenges in mobile DevOps ( iOS and Android)

How Jenkins fits in mobile DevOps and CI/CD pipelines

What Jenkins misses for mobile

How we can make Jenkins better for mobile apps

Creating a CI/CD Pipeline for Your Shared Libraries - Roderick Randolph

At Capital One we run tens of thousands of CI/CD pipelines on Jenkins, leveraging the Jenkins Pipeline shared libraries extension to enable code reuse and decrease time to market for dev teams. A code change to our shared library goes live immediately and is consumed the next time a team triggers their project’s pipeline. So, why do we have such high confidence that a code change to our library won’t break a team’s pipeline? The answer: we’ve developed a fully automated CI/CD pipeline for our shared library.

During this talk, you will learn how to create a fully automated pipeline for your shared libraries including how to develop tests, create canary releases, monitor for issues and quickly rollback changes to your shared library to achieve rapid delivery while minimizing any impact on dev teams.

How Jenkins Builds and Delivers Jenkins in the Cloud - Brian Benz &amp; Tyler Croy

Want to know how Jenkins builds Jenkins? Catch this session to see the real-life implementation of Jenkins’ development (at ci.jenkins.io) and delivery infrastructure in the cloud as it evolved from a mix of platforms to multi-platform VMs, containers and Kubernetes on Microsoft Azure.  Expect a frank discussion of issues that were encountered along the way, how the architecture has evolved and what’s on the roadmap.  We’ll share important tips and tricks for implementing your own Jenkins infrastructure on any cloud, based on Jenkins’ own implementation experience.

Declarative Pipeline 2019: Tips, Tricks and What’s Next - Liam Newman

Are you using Declarative Pipeline? Are you considering using them? Are you just curious? Well, we’re going to help you get more out of Declarative Pipeline with less complexity and less effort. We’ll walk through some best practices, point out some tricks you might not have known, warn you off some common mistakes, review what’s changed in the last year and give you a preview of what we’re working on for Declarative Pipeline going forward.

Say Goodbye to Hello World, Say Hello to Real World Delivery Pipelines - Brian Benz &amp; Jessica Deen

Are you tired of &quot;Hello World&quot; and hypothetical demos? So are we! In this code-heavy, deeply technical session, you’ll learn more than just tips and tricks.  You’ll learn best practices and how to start from absolute zero. Whether you’re using Jenkins, Azure DevOps, a mixture of the two, or another CI/CD tool, you’ll learn how to create multiple build and release pipelines using real world code hosted on open source platforms such as GitHub.

For the complete agenda see DevOps World - Jenkins World 2019 San Francisco .

Feel free to use discount code JWFOSS for a 30% discount off your pass.

Hope to see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworldjenkinsworld2019">devopsworldjenkinsworld2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/06/21/performance-testing-jenkins/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">21</div></div><h5 class="title">Micro-benchmarking Framework for Jenkins Plugins</h5></div><p class="teaser">I have been working on improving the performance of the Role Strategy Plugin as a part of my Google Summer of Code project.
Since there was no existing way to measure performance and do benchmarks on Jenkins Plugins,
my work for the first phase of the project was to create a framework for running
benchmarks in Jenkins plugins with a Jenkins instance available. To make our job a bit easier,
we chose Java Microbenchmark Harness for running these benchmarks. This
allows us to reliably measure performance of our time-critical functions and will help make Jenkins perform faster
for everyone.

The micro-benchmarking framework was recently released in the Jenkins Unit Test Harness 2.50.
The blog post below shows how to run benchmarks in your plugins.

Introduction

The framework runs works by starting a temporary Jenkins instance for each fork of the JMH benchmark,
just like JenkinsRule from Jenkins Test Harness. Benchmarks are run directly from your JUnit Tests which allows
you to fail builds on the fly and easily run benchmarks from your IDE, just like unit tests. You can easily
configure your benchmarks by either using your Java methods, or by using Jenkins Configuration-as-Code plugin
and passing the path to your YAML file.

To run benchmarks from your plugins, you need to do the following:

bump up the minimum required Jenkins version to 2.60.3 or above

bump Plugin-POM to a version ≥ 3.46 or manually upgrade to Jenkins Test Harness ≥ 2.51.

Now, to run the benchmarks, you need to have a benchmark runner that contains a @Test so it can run
like a JUnit test. From inside a test method, you can use the OptionsBuilder provided by JMH to
configure your benchmarks. For example:

public class BenchmarkRunner {
    @Test
    public void runJmhBenchmarks() throws Exception {
        ChainedOptionsBuilder options = new OptionsBuilder()
                .mode(Mode.AverageTime)
                .forks(2)
                .result(&quot;jmh-report.json&quot;);

        // Automatically detect benchmark classes annotated with @JmhBenchmark
        new BenchmarkFinder(getClass()).findBenchmarks(options);
        new Runner(options.build()).run();
    }
}

Sample benchmarks

Now, you can write your first benchmark:

Without any special setup

@JmhBenchmark
public class JmhStateBenchmark {
    public static class MyState extends JmhBenchmarkState {
    }

    @Benchmark
    public void benchmark(MyState state) {
        // benchmark code goes here
        state.getJenkins().setSystemMessage(&quot;Hello world&quot;);
    }
}

Using Configuration as Code

To use configuration as code, apart from the dependencies above you also need to add the following
to your pom.xml :

io.jenkins
configuration-as-code
1.21
true

io.jenkins
configuration-as-code
1.21
tests
test

Now configuring a benchmark is as simple as providing path to your YAML file and specifying the class
containing the benchmark state.

@JmhBenchmark
public class SampleBenchmark {
    public static class MyState extends CascJmhBenchmarkState {
        @NonNull
        @Override
        protected String getResourcePath() {
            return &quot;config.yml&quot;;
        }

        @NonNull
        @Override
        protected Class getEnclosingClass() {
            return SampleBenchmark.class;
        }
    }

    @Benchmark
    public void benchmark(MyState state) {
        Jenkins jenkins = state.getJenkins(); // jenkins is configured and ready to be benchmarked.
        // your benchmark code goes here...
    }
}

More Samples

As a part of this project, a few benchmarks have been created in the Role Strategy Plugin which show
configuring the instances for various situations. You can find them
here.

Running Benchmarks

Running benchmarks from Maven

To easily run benchmarks from Maven, a Maven profile to run the benchmarks has been created
and is available starting Plugin-POM version 3.45. You can then run your benchmarks from the
command line using mvn test -Dbenchmark.

Running benchmarks on ci.jenkins.io

If you have your plugins hosted on ci.jenkins.io, you can easily run benchmarks directly from your Jenkinsfile
by using the runBenchmarks() method after the buildPlugin() step in your which is now available in
Jenkins Pipeline library.
This function also accepts the path to your generated JMH benchmark reports as an optional
parameter and archives the benchmark results. Running benchmarks in pull request builds allows you to constantly
monitor the performance implications of a given change. For example, the Jenkinsfile from Role Strategy Plugin:

buildPlugin()
runBenchmarks(&#x27;jmh-report.json&#x27;)

Visualizing benchmark results

Benchmark reports generated (in JSON) can be visualized using the either the JMH Report Plugin
or by passing the benchmark reports to the JMH visualizer web service. As an example, here is
a visualized report of some benchmarks from the Role Strategy Plugin:

These improvements seen above were obtained through a small pull request
to the plugin and shows how even seemingly small changes can bring major performance improvements. Microbenchmarks
help to find these hot-spots and estimate the impact of changes.

Some tips and tricks

Since BenchmarkRunner class name in the example above does not qualify as a test according to Maven surefire plugin’s
naming conventions, the benchmarks will not interfere with your JUnit tests.

Benchmark methods need to be annotated by @Benchmark for JMH to detect them.

Classes containing benchmarks are found automatically by the BenchmarkFinder
when annotated with @JmhBenchmark.

A reference to the Jenkins instance is available through either JmhBenchmarkState#getJenkins() or through
Jenkins.getInstance() like you would otherwise do.

JmhBenchmarkState provides setup() and tearDown() methods which can be overridden to configure the
Jenkins instance according to your benchmark’s requirements.

The benchmark builds on ci.jenkins.io are currently throttled because of the limited availability of highmem nodes.

The benchmark framework was made available in Jenkins Test Harness 2.50, it is recommended to use version 2.51 as it includes some bug fixes.

Links and Feedback

If you have any feedback, comments or questions, please feel free to reach out to me through either
the Role Strategy Plugin Gitter chat or through
the Jenkins Developer Mailing list.

Presentation slides

Demo at Platform SIG meeting

Documentation for the micro-benchmark framework:

Writing benchmarks (Jenkins Test Harness)

Preconfiguring benchmarks using JCasC

Running benchmarks using Plugin POM profile

Build Step for running benchmarks on ci.jenkins.io<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhyudayasharma/">Abhyudaya Sharma</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jmh">jmh</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/benchmark">benchmark</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/06/29/phase-1-multibranch-pipeline-support-for-gitlab/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">29</div></div><h5 class="title">Multi-branch Pipeline Jobs Support for GitLab SCM</h5></div><p class="teaser">This is one of the Jenkins project in GSoC 2019. We are working on adding support
for Multi-branch
Pipeline Jobs and Folder Organisation in GitLab. The plan is to create the following
plugins:

GitLab API Plugin - Wraps GitLab Java APIs.

GitLab Branch Source Plugin - Contains two packages:

io.jenkins.plugins.gitlabserverconfig - Manages server configuration and web hooks management.
Ideally should reside inside another plugin with name GitLab Plugin. In future, this package should
be moved into a new plugin.

io.jenkins.plugins.gitlabbranchsource - Adds GitLab Branch Source for Multi-branch Pipeline Jobs (including
Merge Requests) and Folder organisation.

Present State

FreeStyle Job and Pipeline(Single Branch) Job are fully supported.

Multi-branch Pipeline Job is partially supported (no MRs detection).

GitLab Folder Organisation is not supported.

Goals of this project

Implement a lightweight GitLab Plugin that depends on GitLab API Plugin.

Follow convention of 3 separate plugins i.e. GitLab Plugin, GitLab API Plugin, GitLab Branch Source Plugin.

Implement GitLab Branch Source Plugin with support for Multi-branch Pipeline Jobs.

Support new Jenkins features such as
Jenkins Code as Configuration (JCasC),
Incremental Tools.

Clear &amp; Efficient design.

Support new SCM Trait APIs.

Support Java 8 and above.

Building the plugin

No binaries are available for this plugin as the plugin is in the very early alpha stage, and not ready for the general
public quite yet.  If you want to jump in early, you can try building it yourself from source.

Installation:

Checkout source code to your local machine:

git clone https://github.com/baymac/gitlab-branch-source-plugin.git

cd gitlab-branch-source-plugin

Install the plugin:

mvn clean install

mvn clean install -DskipTests # to skip tests

Run the plugin:

mvn hpi:run # runs a Jenkins instance at localhost:8080

mvn hpi:run -Djetty.port= # to run on your desired port number

If you want to test it with your Jenkins server, after mvn clean install follow these steps in your Jenkins instance:

Select Manage Jenkins

Select Manage Plugins

Select Advanced tab

In Upload Plugin section, select Choose file

Select $ /target/gitlab-branch-source.hpi

Select Upload

Select Install without restart

Usage

Assuming plugin installation has done been already.

Setting up GitLab Server Configuration on Jenkins

On jenkins, select Manage Jenkins

Select Configure System

Scroll down to find the GitLab section

Select Add GitLab Server | Select GitLab Server

Now you will now see the GitLab Server Configuration options.

There are 4 fields that needs to be configured:

Name - Plugin automatically generates an unique server name for you. User may want to configure this field
to suit their needs but should make sure it is sufficiently unique. We recommend to keep it as it is.

Server URL - Contains the URL to your GitLab Server. By default it is set to &quot;https://gitlab.com&quot;. User can
modify it to enter their GitLab Server URL e.g. https://gitlab.gnome.org/, http://gitlab.example.com:7990. etc.

Credentials - Contains a list of credentials entries that are of type GitLab Personal Access Token. When
no credential has been added it shows &quot;-none-&quot;. User can add a credential by clicking &quot;Add&quot; button.

Web Hook - This field is a checkbox. If you want the plugin to setup a webhook on your GitLab project(s)
related jobs, check this box. The plugin listens to a URL for the concerned GitLab project(s) and when an event
occurs in the GitLab Server, the server sends an event trigger to the URL where the web hook is setup. If you
want continuous integration (or continuous delivery) on your GitLab project then you may want to automatically
set it up.

Adding a Personal Access Token Credentials (To automatically generate Personal Access Token see
next section):

User is required to add a GitLab Personal Access Token type credentials entry to securely persist the token
inside Jenkins.

Generate a Personal Access Token on your GitLab Server:

Select profile dropdown menu from top-right corner

Select Settings

Select Access Token from left column

Enter a name | Set Scope to api, read_user, read_repository

Select Create Personal Access Token

Copy the token generated

Return to Jenkins | Select Add in Credentials field | Select Jenkins

Set Kind to GitLab Personal Access Token

Enter Token

Enter a unique id in ID

Enter a human readable description

Select Add

Testing connection:

Select your desired token in the Credentials dropdown

Select Test Connection

It should return something like Credentials verified for user

Select Apply (at the bottom)

GitLab Server is now setup on Jenkins

Creating Personal Access Token within Jenkins

Alternatively, users can generate a GitLab Personal Access Token within Jenkins itself and automatically add the
GitLab Personal Access Token credentials to Jenkins server credentials.

Select Advanced at the bottom of GitLab Section

Select Manage Additional GitLab Actions

Select Convert login and password to token

Set the GitLab Server URL

There are 2 options to generate token;

From credentials - To select an already persisting Username Password Credentials or add an Username Password
credential to persist it.

From login and password - If this is a one time thing then you can directly enter you credentials to the text boxes
and the username/password credential is not persisted.

After setting your username/password credential, select Create token credentials.

The token creator will create a Personal Access Token in your GitLab Server for the given user with the
required scope and also create a credentials for the same inside Jenkins server. You can go back to the GitLab Server
Configuration to select the new credentials generated (select &quot;-none-&quot; first then new credentials will appear). For
security reasons this token is not revealed as plain text rather returns an id. It is a 128-bit long UUID-4 string
(36 characters).

Configuration as Code

No need for messing around in the UI. Jenkins Configuration as Code (JCasC) or simply Configuration as Code Plugin
allows you to configure Jenkins via a yaml file. If you are a first time user, you can learn more about JCasC
here.

Add configuration YAML:

There are multiple ways to load JCasC yaml file to configure Jenkins:

JCasC by default searches for a file with the name jenkins.yaml in $JENKINS_ROOT.

The JCasC looks for an environment variable CASC_JENKINS_CONFIG which contains the path
for the configuration yaml file.

A path to a folder containing a set of config files e.g. /var/jenkins_home/casc_configs.

A full path to a single file e.g. /var/jenkins_home/casc_configs/jenkins.yaml.

A URL pointing to a file served on the web e.g. /jenkins.yaml&quot; class=&quot;bare&quot;&gt;https:// /jenkins.yaml .

You can also set the configuration yaml path in the UI. Go to /configuration-as-code.
Enter path or URL to jenkins.yaml and select Apply New Configuration.

An example of configuring GitLab server via jenkins.yaml :

credentials:
  system:
    domainCredentials:
      - credentials:
          - gitlabPersonalAccessToken:
              scope: SYSTEM
              id: &quot;i&lt;3GitLab&quot;
              token: &quot;XfsqZvVtAx5YCph5bq3r&quot; # gitlab personal access token

unclassified:
  gitLabServers:
    servers:
      - credentialsId: &quot;i&lt;3GitLab&quot;
        manageHooks: true
        name: &quot;gitlab.com&quot;
        serverUrl: &quot;https://gitlab.com&quot;

For better security, see handling secrets
section in JCasC
documentation.

Future Scope of work

The second phase of GSoC will be utilized to develop GitLab Branch Source. The new feature is a work in progress, but
the codebase is unstable and requires lot of bugfixes. Some features like Multibranch Pipeline Jobs are functioning
properly. More about it at the end of second phase.

Issue Tracking

This project uses Jenkins JIRA to track issues. You can file issues under
gitlab-branch-source-plugin component.

Acknowledgements

This plugin is built and maintained by the Google Summer of Code (GSoC) Team for
Multi-branch Pipeline
Support for GitLab. A lot of inspiration was drawn from GitLab Plugin, Gitea Plugin and GitHub Plugin.

Our team consists of: baymac, LinuxSuRen,
Marky, Joseph,
Justin, Jeff.

With support from: Oleg, Greg,
Owen.

Also thanks to entire Jenkins community for contributing with technical expertise and inspiration.

Links

Phase 1 demo

Presentation slides

GitLab API Plugin

GitLab Branch Source Plugin

GitLab API Plugin Wiki

Issue Tracker for Phase 1

Blog<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/baymac/">Parichay Barpanda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gitlab">gitlab</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/credentials">credentials</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/02/plugin-management-tool-alpha-release/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 2</div></div><h5 class="title">Plugin Management Library and CLI Tool Alpha Release</h5></div><p class="teaser">&quot;Everybody is re-inventing the wheel, partially implementing the &quot;details&quot; of plugin management (signed metadata, artifacts checksums, plugins detached from core,…​).
It becomes obvious Jenkins should provide adequate tooling for plugin installation outside a live Jenkins instance.&quot; jira:JENKINS-53767[]

My Google Summer of Code project
tries to solve this problem by creating a library that will unify plugin management logic across the different implementations
of Jenkins and providing a CLI tool that will make it easy for users to download plugins and view plugin information before Jenkins even starts.
I’m excited to share that we just released an alpha version that you can check out here!

GSoC Phase 1 Update

While I looked into pulling the Plugin Manager out of Jenkins core,
this ended up being a challenging first step due to the complexity and number of dependencies.  We instead decided to start by converting the
install-plugins.sh bash script in Jenkins Docker to Java.
There are several issues with the install-plugins.sh script - namely, that it is a bash script and has limited extensibility.
Furthermore, it does not retrieve all of the most-up-to-date update center metadata.

Alpha Release Details

Mimicking what was done in the install-plugins.sh script from the official Jenkins Docker image, the new plugin management library takes in a list of plugins, their versions,
and/or urls from which to download the plugins, and downloads the requested plugins and their dependencies. The plugins are downloaded from the update center
to a specified directory, and can then be loaded into Jenkins. Currently, the plugins to be downloaded can be specified via a plugins.txt file and/or the -plugins cli option, but we plan to further expand the input formats that can be accepted.
Custom version specifiers for different update centers are also supported.

The library will first check if any of the requested plugins are currently either installed in the user-specified download location or user-specified Jenkins war file.
Already installed plugins will be ignored or upgraded if a higher version is requested or required as a dependency.  After determining the plugin download URL, the library
will download the plugins and resolve and download their dependencies.

This is just the beginning: the plugin manager library and cli tool are very much still a work in progress.
For the most up-to-date information on CLI options and how to run the tool, see the repository README.md.
More robust input parsing, support for security warnings and available updates, Docker integration, and additional features coming soon!

Links and Feedback

Feel free to reach out through
the Plugin Installation Manager CLI Tool Gitter chat or through
the Jenkins Developer Mailing list. I would love to get your questions, comments, and feedback!
We have meetings Tuesdays and Thursdays at 6PM UTC.

Phase 1 Presentation Slides

Phase 1 Recorded Demo

Jira Issue Search

Repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stopalopa/">Natasha Stopa</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pluginmanagement">pluginmanagement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cli">cli</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/05/jenkins-pipeline-stage-result-visualization-improvements/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 5</div></div><h5 class="title">Jenkins Pipeline Stage Result Visualization Improvements</h5></div><p class="teaser">Some changes have recently been released to give Pipeline authors some new tools to improve Pipeline visualizations in Blue Ocean, in particular to address the highly-voted issue JENKINS-39203, which causes all non-failing stages to be visualized as though they were unstable if the overall build result of the Pipeline was unstable. This issue made it difficult to quickly identify why a build was unstable, and forced users to read through builds logs and the Jenkinsfile to figure out what actually happened.

In order to fix this issue, we introduced a new Pipeline API that can be used to attach additional result information to individual Pipeline steps. Visualization tools like Blue Ocean use this new API when deciding how a given stage should be displayed. Steps like junit that used to set only the overall build result now additionally use the new API to set step-level result information. We created the new unstable and warnError steps so that Pipeline authors with more complicated use cases can still take advantage of this new API.

The core fixes for the issue are present in the following plugins, all of which require Jenkins 2.138.4 or newer:

Pipeline: API 2.34

Pipeline: Basic Steps 2.18 (requires a simultaneous update to Pipeline: Groovy 2.70)

Pipeline: Graph Analysis 1.10

Pipeline: Declarative 1.3.9

Blue Ocean 1.17.0

Here is a screenshot from Blue Ocean of a Pipeline using the unstable step where only the failing stage is marked as unstable:

Examples

Here are some examples of how to update your Pipelines to use the new improvements:

Use the new warnError step to catch errors and mark the build and stage as unstable. warnError requires a single String parameter, which is a message to log when an error is caught. When warnError catches an error, it logs the message  and the error and sets the build and stage result to unstable. Using it looks like this:

warnError(&#x27;Script failed!&#x27;) {
  sh(&#x27;false&#x27;)
}

Use the new unstable step to set the build and stage result to unstable. This step can be used as a direct replacement for currentBuild.result = &#x27;UNSTABLE&#x27;, and may be useful in cases where warnError is not flexible enough. unstable requires a single String parameter, which is a message to log when the step runs. Using it might look like this:

try {
  sh(&#x27;false&#x27;)
} catch (ex) {
  unstable(&#x27;Script failed!&#x27;)
}

JUnit Plugin : Update to version 1.28 or newer to pick up fixes for the junit step so that it correctly marks the stage as unstable.

Warnings Next Generation Plugin : Update to version 5.2.0 or newer to pick up fixes for the publishIssues and recordIssues steps so that they correctly mark the stage as unstable.

Other Plugins : If your Pipeline is marked as unstable by a step in another plugin, please file a new issue with the component set to that plugin (after checking for duplicates), clearly describing which step has the problem and under what circumstances it occurs, and link to the developer section of this post as a reference for how the maintainer might be able to address the problem.

Limitations

If you do not migrate to the unstable or warnError steps, or update plugins that set the build result to versions that integrate with the new API, then in cases where the build is unstable, Blue Ocean will not show any stages as unstable.

Even after these changes, currentBuild.result continues to refer only to the overall build result. Unfortunately, it was not possible to adapt the currentBuild global variable to make it track step or stage-level results, since it is implemented as a global variable, which means it does not have any step-level context through which it could use the new API.

Pipeline Stage View Plugin has not yet been updated to use the new API, so these changes do not affect the visualization it provides.

History

Jenkins Pipeline steps can complete in one of two ways: successfully, by returning a (possibly null) result, or unsuccessfully, by throwing an exception. When a step fails by throwing an exception, that exception propagates throughout the Pipeline until another step or Groovy code catches it, or it reaches the top level of the Pipeline, which causes the Pipeline itself to fail. Depending on the type of exception thrown, the final result of the Pipeline may be something other than failure (for example in some cases it will be aborted). Because of the way the exception propagates, it is easy for tools like Blue Ocean to identify steps (and therefore stages) which failed due to an exception.

In order for Pipelines to be able to interact with established Jenkins APIs, it was also necessary for Pipeline builds to have an overall build result that can be modified during the build. Among other things, this allows Pipelines to use build steps and wrappers that were originally written for use in Freestyle projects.

In some cases, it is desirable for a Pipeline step to be able to complete successfully so that the rest of the Pipeline continues normal execution, but for it to be able to note that some kind of error occurred so that visualizations are able to identify that something went wrong with the step, even though it didn’t fail completely. A good example of this is the junit step. This step looks at specified test results, and if there were any failures, marks the overall build result as unstable. This kind of behavior is problematic for visualization tools like Blue Ocean, because the step completed successfully, and there is no programmatic way to associate the overall build result with the step that ended up setting that result.

Looking at JENKINS-39203 again, we see that there were essentially two options for the visualization. If the overall build result was unstable, either all steps that completed successfully could be shown as unstable, because they may have been the step that caused the build to become unstable, or they could be shown as successful, because we have no way to relate the setting of the build result to a specific step. In the end, the first option was chosen.

To work around this issue, some users tried to do things like throw exceptions and add try/catch blocks around stages that handle exceptions so that Blue Ocean would be able to use the exceptions to mark step and stage results as desired, and then by catching the exception the Pipeline would be able to continue normal execution. These kinds of workarounds were hard to understand, fragile, and did not work well (if at all) for Declarative Pipelines.

Developers

If you are a developer of a plugin that integrates with Pipeline using a step, and want to take advantage of the new API so that your step can report an non-successful result without throwing an exception, please see this post to the Jenkins Developers mailing list, and respond there if you have any questions.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/dwnusbaum/">Devin Nusbaum</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/09/Phase1-Updates-On-Working-Hours-Plugin/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 9</div></div><h5 class="title">GSOC Phase 1 Updates On Working Hours Plugin</h5></div><p class="teaser">The Working Hour Plugin provides an interface to set up a schedule of allowable build days and times.  Jobs that run outside of configured working hours are held until the next allowable build time.

For the first code phase at Google Summer of Code, I’ve been working on Working Hours Project, which needed improvements on usability.

Rather than classical Jelly pages, React seems to be more prefered when we want to design a much customized UI with a huge amount of libraries we could use, especially the open source components such as date pickers.

But we have to face a challenge of the integration of React and Jenkins, which I’m currently working on.

Achievements For The First Code Phase

For the first code phase, we are focusing on the UI improvements, we’ve achieved following major improvements:

A standalone webapp which could be then integrated.

Slider for choosing a time range.

More fields when setting a excluded date.

Presets for choosing a excluded date.

A Jenkins styling UI.

How We Integrate React Into Jenkins

A solution doc for integration could be found at
https://drive.google.com/open?id=1JLRCDg9JNBWR0Dfq8w3pTI9mrl6i9JU29pBoH6bO0J8

At first, we found BlueOcean is a great example for using React in Jenkins, but yet it’s not a choice for common development with plugins. So we need to find out another way to integrate.

Here are the steps to do the integration:

A mount point in your jelly file, usually it’s a element with a unique id.

Write your React Application, but need to set the mount point to the id you set above.

Copy the output after you build the Project into the plugin’s webapp dir.

Add your files using a script tag in your jelly file.

Once we are using React, the traditional jelly request won’t be available anymore, another way to process requests will be using stapler. You can define a process function like below.
[source, java]

public HttpResponse doDynamic(StaplerRequest request) {
        if (config == null) {
            config = ExtensionList.lookup(WorkingHoursPlugin.class).get(0);
        }
        String restOfPath = request.getRestOfPath();
        String[] pathTokens = restOfPath.split(&quot;/&quot;);
        List params = new ArrayList&lt;&gt;();
        switch (params.get(0)) {
            case &quot;list-excluded-dates&quot;:
                return listExcludedDate(request);
            case &quot;set-excluded-dates&quot;:
                return setExcludedDates(request);
            case &quot;list-time-ranges&quot;:
                return listTimeRanges(request);
            case &quot;set-time-ranges&quot;:
                return setTimeRanges(request);
        }
    }

Run Our Application

If you would like to take a look at our plugin, you can go to the repo
working-hours-plugin

Just follow the README file, then you could run a copy of your working hours plugin.

Screenshots

The current plugin’s outlook is a bit simple and the plugin is a bit unconvinient for use.

One of the problems is that if we want to input a excluded date, it’ll be a string in a constant format like 15/9/2019, but the new UI choosed React so we could use a datepicker to improve this.

Current Plugin

New (Time Ranges)

New (Exclude Dates)

Helpful links

If you have any questions or advices, we are glad to hear from you.

Several useful links are listed below:

Develop Repo

Main Repo

Design Doc

Doc for React Integration Solution

Gitter Chat

Slides for Phase 1 Demo

Video Recording for Phase 1<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jackshen/">Jack Shen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/react">react</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/11/remoting-kafka-kubernetes-phase-1/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">11</div></div><h5 class="title">Remoting over Apache Kafka plugin with Kafka launcher in Kubernetes</h5></div><p class="teaser">I am Long Nguyen from FPT University, Vietnam. My project for Google Summer of Code 2019 is Remoting over Apache Kafka with Kubernetes features. This is the first time I have contributed for Jenkins and I am very excited to announce the features that have been done in Phase 1.

Project Introduction

Current version of Remoting over Apache Kafka plugin requires users to manually configure the entire system which includes Zookeeper, Kafka and remoting agents. It also doesn’t support dynamic agent provisioning so scalability is harder to achieve. My project aims to solve two problems:

Out-of-the-box solution to provision Apache Kafka cluster.

Dynamic agent provisioning in a Kubernetes cluster.

Current State

Kubernetes connector with credentials supported.

Apache Kafka provisioning in Kubernetes feature is fully implemented.

Helm chart is partially implemented.

Apache Kafka provisioning in Kubernetes

This feature is part of 2.0 version so it is not yet released officially. You can try out the feature by using the Experimental Update Center to update to 2.0.0-alpha version or building directly from master branch:

git clone https://github.com/jenkinsci/remoting-kafka-plugin.git
cd remoting-kafka-plugin/plugin
mvn hpi:run

On the Global Configuration page, users can input Kubernetes server information and credentials. Then they can start Apache Kafka with only one button click.

When users click Start Kafka on Kubernetes button, Jenkins will create a Kubernetes client from the information and then apply Zookeeper and Kafka YAML specification files from resources.

Helm Chart

Helm chart for Remoting over Apache Kafka plugin is based on stable/jenkins chart and incubator/kafka chart. As of now, the chart is still a Work in Progress because it is still waiting for Cloud API implementation in Phase 2. However, you can check out the demo chart with a single standalone Remoting Kafka Agent:

git clone -b demo-helm-phase-1 https://github.com/longngn/remoting-kafka-plugin.git
cd remoting-kafka-plugin
K8S_NODE=./helm/jenkins-remoting-kafka/do.sh start

The command do.sh start will do the following steps:

Install the chart (with Jenkins and Kafka).

Launch a Kafka computer on Jenkins controller by applying the following JCasC.

jenkins:
  nodes:
    - permanent:
        name: &quot;test&quot;
        remoteFS: &quot;/home/jenkins&quot;
        launcher:
          kafka: {}

Launch a single Remoting Kafka Agent pod.

You can check the chart state by running kubectl, for example:

$ kubectl get all -n demo-helm
NAME                                    READY   STATUS    RESTARTS   AGE
pod/demo-jenkins-998bcdfd4-tjmjs        2/2     Running   0          6m30s
pod/demo-jenkins-remoting-kafka-agent   1/1     Running   0          4m10s
pod/demo-kafka-0                        1/1     Running   0          6m30s
pod/demo-zookeeper-0                    1/1     Running   0          6m30s

NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/demo-0-external           NodePort    10.106.254.187 19092:31090/TCP              6m30s
service/demo-jenkins              NodePort    10.101.84.33 8080:31465/TCP               6m31s
service/demo-jenkins-agent        ClusterIP   10.97.169.65 50000/TCP                    6m31s
service/demo-kafka                ClusterIP   10.106.248.10 9092/TCP                     6m30s
service/demo-kafka-headless       ClusterIP   None 9092/TCP                     6m30s
service/demo-zookeeper            ClusterIP   10.109.222.63 2181/TCP                     6m30s
service/demo-zookeeper-headless   ClusterIP   None 2181/TCP,3888/TCP,2888/TCP   6m31s

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/demo-jenkins   1/1     1            1           6m30s

NAME                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/demo-jenkins-998bcdfd4   1         1         1       6m30s

NAME                              READY   AGE
statefulset.apps/demo-kafka       1/1     6m30s
statefulset.apps/demo-zookeeper   1/1     6m30s

Next Phase Plan

Implement Cloud API to provision Remoting Kafka Agent. ( JENKINS-57668)

Integrate Cloud API implementation with Helm chart. ( JENKINS-58288)

Unit tests and integration tests.

Release version 2.0 and address feedbacks. ( JENKINS-58289)

Links

Phase 1 Demo Video

Phase 1 Presentation Slides

Remoting over Apache Kafka plugin

Project Page

Gitter Channel<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/longnguyen/">Long Nguyen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kafka">kafka</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/helm">helm</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/15/pipeline-config-history-plugin/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">15</div></div><h5 class="title">Introducing the Pipeline Configuration History Plugin</h5></div><p class="teaser">Pipelines are the efficient and modern way how to create jobs in Jenkins.
To recognize pipeline changes quickly and easily, we developed the Pipeline Configuration History plugin.
This plugin detects changes of pipelines and provides the user an option to view changes between two builds (diffs) of pipeline configurations visibly and traceably.

How everything started

It all started 10 years ago — with classical job types (e.g. Freestyle, Maven, etc.).
Every once in a while users contacted us because their jobs failed to build overnight.
Why did the job fail?
Was the failure related to a job configuration change?
The users&#x27; typical answer was: &quot;We didn’t change anything!&quot;, but is that really true?
We thought about this and decided to develop a plugin that helped us solve this problem.
This was the idea and the beginning of Job Configuration History.

Now it was possible to view changes of job configurations (like other branches, JDK versions, etc.) and more often the reason for breaking builds were changes of job configurations.

Over the years the plugin got developed and is still under development.
New functions were added, that not only view job configurations, but also changes of global and agent configurations.
It is also possible to recover old configuration versions.
Today the plugin has more than 30,000 installations.
For many years JobConfigHistory relieves our daily work — with more than 3,000 Jenkins jobs!
Then there was a new type of job: Pipelines.

Pipelines - something new was needed

Pipeline jobs are fundamentally different than classical job types .
While classic job types are configured via the Jenkins GUI, Pipeline jobs are configured as code.
Every pipeline job indeed gets created via the Jenkins GUI, however that is not necessarily where the pipeline configuration is located.
Pipelines can be configured:

Directly in the Jenkins job as script.
The code gets inserted directly in the job configuration page.

As Jenkinsfile in the source code management system (SCM): The pipeline configuration is defined in a text file (Jenkinsfile) in the SCM.
In the job itself only the path to the repository of the Jenkinsfile is configured.
During the build the Jenkinsfile gets checked out from the SCM and processed.

As a shared library: A part of the pipeline configuration gets moved to separate files that can be used by several jobs.
These files are also saved in the SCM.
Even so a Jenkinsfile is still needed (or a pipeline script in the job).

With every save operation of the job configuration, JobConfigHistory creates a copy of the actual job configuration if something has changed.
That only works for pipeline jobs if the pipeline configuration is inserted in the job configuration page as script.
Changes in the Jenkinsfile or the shared libraries are not detected by JobConfigHistory.
You have to use the SCM system to view changes of the Jenkinsfile or the shared libraries.
It is complex and time intensive to find a correlation between the time of a build and a change to the Jenkinsfile or shared library.

This new problem is much more than JobConfigHistory.  A new solution was needed to detect pipeline changes and show these changes in Jenkins.
So we developed Pipeline Configuration History.

During every pipeline run the Jenkinsfile and related shared libraries are saved in the builds directory of the job.
Pipeline Configuration History saves changes of the pipeline files between the last run and the previous run as history events.
Therefore when a pipeline job ceases to build successfully, you can check if something has changed on any used pipeline file.
You can also see the build where changes occurred.

Because a pipeline configuration can consist of several files where changes could have occurred, only files with changes between two builds are shown in the diff.
That makes the whole thing more compact and effective:

But sometimes you may want to show more than the differences between pipeline files.  You may want to see which pipeline files are in use or the content of those files when they were used.
So it’s possible to view all files and their content.
If required you can download them as well:

Conclusion

We use Pipeline Configuration History successfully in production. It has helped us from the very first day as we solved problems that occurred due to pipeline configuration changes.
Pipeline Configuration History won’t replace Job Configuration History.
The plugins have different use cases.
Many times small changes on job or pipeline configurations also have big impacts.
Because of the correlation in time between changes of job or pipeline configurations and different build behavior, it is now possible to substantially reduce the time and effort to analyze build failures.
The Job Configuration History and Pipeline Configuration History plugins let us help our users in consulting and in solving issues.  We resolve problems much faster through easy access to the configuration history of jobs.  These plugins are essential for our daily work.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jochenafuerbacher/">Jochen A. Fürbacher</a>, <a href="/gatsby-jenkins-io/blog/authors/stefanbrausch/">Stefan Brausch</a>, <a href="/gatsby-jenkins-io/blog/authors/robinrschulz/">Robin Schulz</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/17/DevOps-World-Jenkins-World-2019-San-Francisco-Lunch-Demos/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">17</div></div><h5 class="title">DevOps World - Jenkins World 2019 San Francisco: Lunch Time Demos</h5></div><p class="teaser">If you’re looking for more opportunities to learn Jenkins and Jenkins X during the lunch hours while at DevOps World - Jenkins World 2019 San Francisco , come join us at the Jenkins and Jenkins X Community Booth!

If you don’t yet have your pass for DevOps World - Jenkins World 2019 San Francisco , and don’t want to miss out on the fun, you can get yours using JWFOSS for a 30% discount.

During lunch hours we are scheduling the following demo briefs at the Jenkins and Jenkins X Community Booth:

Wednesday  August 14, 2019

12:10 - 12:25pm 	Faster Git Mark Waite

Attendees will learn the techniques they can use with Jenkins to make their systems clone and update git repositories faster and with less disc space.

12:25 - 12:40pm	Observability in Jenkins X Oscar Medina

If you are using Jenkins X, you’re already building at rapid pace.  However, most miss the opportunity to gain real insights into their build and release pipeline.  I’ll show you how you can increase observability by activating metric capture and analysis during a containerized application deployment with Jenkins X.  This  entails modifying the declarative Tekton pipelines.

12:40 - 12:55pm	From setup to build status on the command line Martin d’Anjou

Using bash, groovy, JCasC and the jenkins-rest, we demonstrate how to setup Jenkins from scratch, upload a configuration as code yaml file, create folders and jobs, run a build, and track it to its completion, all from the command line, without ever touching the GUI.

12:55 - 1:10pm		DevOps without Quality: An IT Horror Story	Laura Keaton

DevOps, the current IT Industry sweetheart, has a dark secret that has victimized organizations on their transformational journey. Investigate two case studies that left development and delivery teams in tatters and how quality engineering solutions could have prevented their disastrous outcomes.

1:10 - 1:25pm	Securing Your Jenkins Container Pipeline with Open Source Tools Christian Wiens

Discuss the security pitfalls of containers and how embedding an open source image scanning and policy based compliance tool like Anchore into your CI/CD pipeline can mitigate this risk.

Thursday  August 15, 2019

12:25 - 12:35pm	Results from the 2019 Jenkins Google Summer of Code Martin d’Anjou

In 2019, the Jenkins project participated in the Google Summer of Code. This is an annual, international, program which encourages college-aged students to participate in open source projects during the summer break between classes. In 2019, we had dozens of applications and many student projects. In this session, we will showcase the students&#x27; projects and talk about what they bring to the Jenkins ecosystem.

12:35 - 12:45pm		Plugin installation CLI Tool Natasha Stopa

This talk will demo the new plugin installation tool done as part of a Google Summer of Code project. It will show the CLI features and how the library has been incorporated into other areas of Jenkins.

12:45 - 12:55pm		Sysdig Secure Jenkins Plugin Marky Jackson

Sysdig Secure is a container security platform that brings together docker image scanning and run-time protection to identify vulnerabilities, block threats, enforce compliance, and audit activity across your microservices. The Sysdig Secure Jenkins plugin can be used in a Pipeline job, or added as a build step to a Freestyle job, to automate the process of running an image analysis, evaluating custom policies against images, and performing security scans.

12:55 - 1:10pm		Using React for plugin UI Jeff Pearce

The working hours plugin has a date driven UI. During this summer’s Google Summer of Code, our student rewrite the UI in React, so that we could take advantage open source modules such as calendar pickers. I’ll talk about how the student approached the UI, demonstrate the UI and talk about particular challenges we faces.

1:10 - 1:25pm		Jenkins GKE Plugin Craig Barber

In this demo we will showcase the Jenkins GKE plugin, newest addition to GCP’s suite of officially supported plugins. We’ll show how to leverage this plugin to deploy applications built in Jenkins pipelines to multiple clusters running in GKE.

Grab your lunch and join us at the community theater!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworldjenkinsworld2019">devopsworldjenkinsworld2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/21/Jenkins-code-coverage-diff-for-pull-request/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">21</div></div><h5 class="title">Jenkins code coverage diff in pull requests</h5></div><p class="teaser">Hello.

As you may know, during the last year GSoC Mr. Shenyu Zheng was working on the Jenkins Code Coverage API Plugin. With Mr. Zheng we made a change so the plugin now is able to check the difference in code coverage between pull requests and target branches.

In lots of projects it is a common practice to track if unit tests code coverage doesn’t decrease. So, with this plugin, you may skip separate services that track code coverage and have this feature right in your favorite CI system.

How it works

When you build a PR in Jenkins, using plugins like Github or Bitbucket Branch Source, that use SCM API Plugin, your PR knows what target branch commit it is based on. (The commit may change because of Discover pull requests from origin strategies). To calculate the diff, when you publish your coverage from PR, it looks for the target branch build for the commit that your PR was based on. If it finds the build on the target branch, it looks for any published code coverage for this target branch build. In case the build has it, the plugin calculates the percentage diff for the line coverage and shows it on the pull request build page. Also, it gives you a link to the target branch build that was used for the comparison.

That it how it looks like:

Decreased coverage

Increased coverage

How to enable code coverage diff for pull requests

To enable this behavior you need to publish your code coverage with the calculateDiffForChangeRequests flag equals true, like this:
.Jenkinsfile

node(...) {
  ...
  // Here we are using the istanbulCoberturaAdapter
  publishCoverage adapters: [istanbulCoberturaAdapter(&#x27;cobertura-coverage.xml&#x27;)],
    sourceFileResolver: sourceFiles(&#x27;NEVER_STORE&#x27;),
    calculateDiffForChangeRequests: true

  ...
}

Links and Feedback

If you have some questions about this behavior, please ask me in email.

You are free to contribute to this plugin to make it better for everyone. There are a lot of interesting features that can be added and issues that can be solved. Also, you can write some new plugins for other code coverage formats that use the Code Coverage API plugin as a base.

Here is the repo of the plugin - Code Coverage API Plugin

Thank you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/asavanchuk/">Aliaksei Savanchuk</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/codecoverage">codecoverage</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/25/azure-artifact-manager/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">25</div></div><h5 class="title">Managing Jenkins Artifacts with the Azure Artifact Manager Plugin</h5></div><p class="teaser">Jenkins stores all generated artifacts on the controller server filesystem. This presents a couple of challenges especially when you try to run Jenkins in the cloud:

As the number of artifacts grow, your Jenkins controller will run out of disk space. Eventually, performance can be impacted.

Frequent transfer of files between agents and controller may cause load, CPU or network issues which are always hard to diagnose.

Several existing plugins allow you to manage your artifacts externally. To use these plugins, you need to know how they work and perform specific steps in your job’s configuration. And if you are new to Jenkins, you may find it hard to follow existing samples in Jenkins tutorial like Recording tests and artifacts.

So, if you are running Jenkins in Azure, you can consider automatically managing new artifacts on Azure Storage. The new Azure Artifact Management plugin allows you to store artifacts in Azure blob storage and simplify your existing Jenkins jobs that contain Jenkins general artifacts management steps. This approach will give you all the advantages of a cloud storage, with less effort on your part to maintain your Jenkins instance.

Configuration

Azure storage account

First, you need to have an Azure Storage account. You can skip this section if you already have one. Otherwise, create an Azure storage account for storing your artifacts. Follow this tutorial to quickly create one. Then navigate to Access keys in the Settings section to get the storage account name and one of its keys.

Existing Jenkins instance

For existing Jenkins instance, make sure you install the Azure Artifact Manager plugin. Then you can go to your Jenkins System Configuration page and locate the Artifact Management for Builds section. Select the Add button to configure an Azure Artifact Storage. Fill in the following parameters:

Storage Type: Azure storage supports several storage types like blob, file, queue etc. This plugin currently supports blob storage only.

Storage Credentials: Credentials used to authenticate with Azure storage. If you do not have an existing Azure storage credential in you Jenkins credential store, click the Add button and choose Microsoft Azure Storage kind to create one.

Azure Container Name: The container under which to keep your artifacts. If the container name does not exist in the blob, this plugin automatically creates one for you when artifacts are uploaded to the blob.

Base Prefix: Prefix added to your artifact paths stored in your container, a forward slash will be parsed as a folder. In the following screenshot, all your artifacts will be stored in the “staging” folder in the container “Jenkins”.

New Jenkins instance

If you need to create a new Jenkins controller, follow this tutorial to quickly create an Jenkins instance on Azure. In the Integration Settings section, you can now set up Azure Artifact Manager directly. Note that you can change any of the configuration after your Jenkins instance is created. Azure storage account and credential, in this case, are still prerequisites.

Usage

Jenkins Pipeline

Here are a few commonly used artifact related steps in pipeline jobs; all are supported to push artifacts to the Azure Storage blob specified.

You can use archiveArtifacts step to archive target artifacts into Azure storage. For more details about archiveArtifacts step, see the Jenkins archiveArtifacts setp documentation.

node {
  //...
  stage(&#x27;Archive&#x27;) {
    archiveArtifacts &quot;pattern&quot;
  }
}

You can use the unarchive step to retrieve the artifacts from Azure storage. For more details about unarchive step, please see unarchive step documentation.

node {
  //...
  stage(&#x27;Unarchive&#x27;) {
    unarchive mapping: [&quot;pattern&quot;: &#x27;.&#x27;]
  }
}

To save a set of files so that you can use them later in the same build (generally on another node or workspace), you can use stash step to store files into Azure storage for later use. Stash step documentation can be found here.

node {
  //...
  stash name: &#x27;name&#x27;, includes: &#x27;*&#x27;
}

You can use unstash step to retrieve the files saved with stash step from Azure storage to the local workspace. Unstash documentation can be found here.

node {
  //...
  unstash &#x27;name&#x27;
}

FreeStyle Job

For a FreeStyle Jenkins job, you can use Archive the artifacts step in Post-build Actions to upload the target artifacts into Azure storage.

This Azure Artifact Manager plugin is also compatible with some other popular management plugins, such as the Copy Artifact plugin. You can still use these plugins without changing anything.

Troubleshooting

If you have any problems or suggestions when using Azure Artifact Manager plugin, you can file a ticket on Jenkins JIRA for the azure-artifact-manager-plugin component.

Conclusion

The Azure Artifact Manager enables a more cloud-native Jenkins. This is the first step in the Cloud Native project. We have a long way to go to get Jenkins to run on cloud environments as a true “Cloud Native” application. We need help and welcome your participation and contributions to make Jenkins better. Please start contributing and/or give us feedback!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jshen/">Jie Shen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/07/30/plugin-management-tool-phase2-updates/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">30</div></div><h5 class="title">Plugin Management Library and CLI Tool Phase 2 GSoC Updates</h5></div><p class="teaser">At end of the first GSoC phase, I
announced
the first alpha release of the CLI tool and library that will help centralize
plugin management and make plugin tooling easier.

Phase 2 has mainly been focused on improving upon the initial CLI and library written
in Coding Phase 1. In particular, we’ve been focusing on getting the tool ready to
incorporate into the Jenkins Docker Image to replace the
install-plugins.sh bash script
to download plugins.  This work included parsing improvements so that blank lines and comments in the
plugins.txt file are filtered out, allowing update centers and the plugin download
directory to be set via environment variables or CLI Options, creating Windows
compatible defaults, and fixing a bug in which dependencies for specific
plugin versions were not always getting resolved correctly.

In parallel to getting the tool ready for Jenkins Docker integration, Phase 2 saw
the addition of several new features.

Yaml Input

In addition to specifying the plugins they want to download via the --plugins
CLI option or through a .txt file, users can now use a Jenkins yaml file with a
plugins root element.

Say goodbye to the days of specifying incremental
plugins like incrementals;org.jenkins-ci.plugins.workflow;2.20-rc530.b4f7f7869384 -
  you can enter the artifactId, groupId, and version to specify an incremental plugin.

Making the Download Process More Transparent

Previously, the plugin download process was not very transparent to users - it was
difficult to know the final set of plugins that would be downloaded after pulling in
all the dependencies.  Instead of determing the set of plugins that will be downloaded
at the time of download, users now have the option to see the full set of plugins
and their versions that will be downloaded in advance. With the --list CLI
option, users can see all currently downloaded and bundled plugins, the set of all
plugins that will be downloaded, and the effective plugin set - the set of all
plugins that are already downloaded or will be downloaded.

Viewing Information About plugins

Now that you know which plugins will be downloaded, wouldn’t it be nice to know
if these are the latest versions or if any of the versions you want to install have
security warnings?  You can do that now too.

Next Steps and Additional Information

The updates mentioned in this blog will be released soon so you can try them out.
The focus of Phase 3 will be to continue to iterate upon and improve the library
and CLI. We hope to release a first version and submit a pull request to Jenkins Docker soon.
Thanks to everyone who has already tried it out and given feedback! I will also be
presenting my work at DevOps World
in San Francisco in a few weeks.  You can use the code PREVIEW for a discounted registration
($799 instead of $1,499).

Feel free to reach out through
the Plugin Installation Manager CLI Tool Gitter chat or through
the Jenkins Developer Mailing list. I would love to get your questions, comments, and feedback!
We have meetings Tuesdays and Thursdays at 6PM UTC.

Phase 2 Presentation Slides

Phase 2 Recorded Demo

Jira Issue Search

Repository<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stopalopa/">Natasha Stopa</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pluginmanagement">pluginmanagement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cli">cli</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/16/folder-auth-plugin/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">16</div></div><h5 class="title">Introducing new Folder Authorization Plugin</h5></div><p class="teaser">During my Google Summer of Code Project,
I have created the brand new Folder Auth Plugin for easily
managing permissions to projects organized in folders from the Folders plugin.
This new plugin is designed for fast permission checks with easy-to-manage roles.
The 1.0 version of the plugin has just been released and can be downloaded
from your Jenkins&#x27; Update center.

This plugin was inspired by the Role Strategy Plugin
and brings about performance improvements and makes managing roles much easier.
The plugin was developed to overcome performance limitations of the Role Strategy
plugin on a large number of roles. At the same time, the plugin addresses one
of the most popular ways of organizing projects in Jenkins, through folders.
The plugin also has a new UI with more improvements to come in the future.

The plugin supports three types of roles which are applicable at different places
in Jenkins.

Global Roles: applicable everywhere in Jenkins

Agent Roles: restrict permissions for multiple agents connected to your instance

Folder Roles: applicable to multiple jobs organized inside folders

Performance Improvements over Role Strategy Plugin

This plugin, unlike the Role Strategy plugin, does not use regular expressions
for finding matching projects and agents giving us performance improvements
and makes administrators&#x27; lives easier. To reduce the number of roles required
to be managed, permissions given to a folder through a folder role get inherited
to all of its children. This is useful for giving access to multiple projects
through a single role. Similarly, an agent role can be applied to multiple agents
and assigned to multiple users.

This plugin is designed to outperform Role Strategy Plugin in permission
checks. The improvements were measured using the
micro-benchmark framework
I had created during the first phase of my GSoC project.
Benchmarks for identical configurations for both plugin show that the
permissions check are up to 934x faster for 500 global roles when compared to
the global roles from the Role Strategy 2.13, which in itself contains several
performance improvements. Comparing folder roles with Role Strategy’s project
roles, a permission check for access to a job almost 15x faster for 250 projects
organized in two-level deep folders on an instance with 150 users. You can see
the benchmarks and the result comparisons
here.

Jenkins Configuration as Code Support

The plugin supports Jenkins Configuration-as-Code so you can configure permissions
without going through the Web UI. A YAML configuration looks like this:

jenkins:
  authorizationStrategy:
    folderBased:
      globalRoles:
        - name: &quot;admin&quot;
          permissions:
            - id: &quot;hudson.model.Hudson.Administer&quot;
              # ...
          sids:
            - &quot;admin&quot;
        - name: &quot;read&quot;
          permissions:
            - id: &quot;hudson.model.Hudson.Read&quot;
          sids:
            - &quot;user1&quot;
      folderRoles:
        - folders:
            - &quot;root&quot;
          name: &quot;viewRoot&quot;
          permissions:
            - id: &quot;hudson.model.Item.Read&quot;
          sids:
            - &quot;user1&quot;
      agentRoles:
        - agents:
            - &quot;agent1&quot;
          name: &quot;agentRole1&quot;
          permissions:
            - id: &quot;hudson.model.Computer.Configure&quot;
            - id: &quot;hudson.model.Computer.Disconnect&quot;
          sids:
            - &quot;user1&quot;

REST APIs with Swagger support

The plugin provides REST APIs for managing roles with OpenAPI specifications
through Swagger.json. You can check out the Swagger API on
SwaggerHub.
SwaggerHub provides stubs in multiple languages which can be downloaded and
used to interact with the plugin. You can also see some sample requests from
the command line using curl.

What’s next

In the (not-too-distant) future, I would like to work on improving the UI and
make the plugin easier to work with. I would also like to work on improving the
APIs, documentation and more optimizations for improving the plugin’s performance.

Links and Feedback

I would love to hear your comments and suggestions. Please feel free to reach
out to me through either the
Role Strategy Plugin Gitter chat or through
Jenkins Developer Mailing list.

Presentation slides for second phase evaluations

Documentation for the Folder Auth Plugin

Demo of the Folder Authorization plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhyudayasharma/">Abhyudaya Sharma</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/19/remoting-kafka-kubernetes-release-2.0/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">19</div></div><h5 class="title">Remoting over Apache Kafka 2.0: Built-in Kubernetes support</h5></div><p class="teaser">I am Long Nguyen from FPT University, Vietnam. My project for Google Summer of Code 2019 is Remoting over Apache Kafka with Kubernetes features. After a successful Phase 1, finally the 2.0 version of the plugin has been released. The 2.0 version provides seamless integration with Kubernetes environment.

2.0 version features

Start a simple Apache Kafka server in Kubernetes.

Dynamically provision Remoting Kafka Agent in Kubernetes.

Helm chart to bootstrap the whole system in Kubernetes.

Start a simple Apache Kafka server in Kubernetes

Use of the plugin requires that users have a configured Apache Zookeeper and Apache Kafka server, which could be intimidating for people who just want to try out the plugin. Now, users can start a simple, single-node Apache Kafka server in Kubernetes environment with just one button click.

On the Global Configuration page, users can input Kubernetes server information and credentials. When users click Start Kafka on Kubernetes button, Jenkins will create a Kubernetes client from the information and then apply Apache Zookeeper and Apache Kafka YAML specification files from resources. After downloading images and creating containers, it will automatically update Apache Zookeeper and Apache Kafka URLs into respective fields.

Dynamically provision Remoting Kafka Agent in Kubernetes

With previous version, users have to manually add/remove nodes so it is hard to scale builds quickly. Kubernetes plugin allows us to dynamically provision agents in Kubernetes but it is designed for JNLP agent. With this new version, Remoting Kafka agent can also be provisioned automatically in Kubernetes environment.

Users can find the new feature in Cloud section in /configure. Here users could input Kubernetes connection parameters and desired Remoting Kafka agent properties including labels. When new build with matching labels gets started and there are no free nodes, Cloud will automatically provision Remoting Kafka agent pod in Kubernetes to run the build.

Helm Chart

Helm chart for Remoting over Apache Kafka plugin is based on stable/jenkins chart and incubator/kafka chart. You can follow the instruction here to install a demo ready-to-use Helm release. Your kubectl get all should look like this:

NAME                                READY   STATUS    RESTARTS   AGE
pod/demo-jenkins-64dbd87987-bmndf   1/1     Running   0          2m21s
pod/demo-kafka-0                    1/1     Running   0          2m21s
pod/demo-zookeeper-0                1/1     Running   0          2m21s

NAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
service/demo-jenkins              NodePort    10.108.238.56 8080:30386/TCP               2m21s
service/demo-jenkins-agent        ClusterIP   10.98.85.184 50000/TCP                    2m21s
service/demo-kafka                ClusterIP   10.109.231.58 9092/TCP                     2m21s
service/demo-kafka-headless       ClusterIP   None 9092/TCP                     2m21s
service/demo-zookeeper            ClusterIP   10.103.2.231 2181/TCP                     2m21s
service/demo-zookeeper-headless   ClusterIP   None 2181/TCP,3888/TCP,2888/TCP   2m21s

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/demo-jenkins   1/1     1            1           2m21s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/demo-jenkins-64dbd87987   1         1         1       2m21s

NAME                              READY   AGE
statefulset.apps/demo-kafka       1/1     2m21s
statefulset.apps/demo-zookeeper   1/1     2m21s

How to Contribute

You are welcome to try out the plugin and integrate it into your current setup. If you find out any bug or if you would like to request new feature, you can create ticket at JIRA. If you would like to contribute code directly, you can create pull requests in the GitHub page below.

Links

Phase 2 Demo Video

Phase 2 Presentation Slides

Phase 1 Blog Post

Phase 1 Demo Video

Phase 1 Presentation Slides

Remoting over Apache Kafka plugin source code

Project Page

Gitter Channel<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/longnguyen/">Long Nguyen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kafka">kafka</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/helm">helm</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/22/devops-world/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">22</div></div><h5 class="title">My DevOps World - Jenkins World 2019 Experience</h5></div><p class="teaser">Last week I had the privilege of attending DevOps World - Jenkins World in San
Francisco to present my Google Summer of Code project for plugin management. It was
an amazing experience getting to meet people from all over world who are trying
to make the development and release process easier and more efficient. I enjoyed
learning more about industry tools, processes, and standards, and meeting CI/CD
experts and contributors in the open source community.

Below is a summary of my experience. Thank you to the Jenkins project and CloudBees for making
 my trip and attendance possible!

Day 1

Monday was the Continuous Delivery Contributor Summit, which focused on projects
under the CDF umbrella.  After checking in and grabbing my badge, I was able to
meet up with some of the Google Summer of Code org admins. It was great
being able to actually meet them in person after talking to them over video
conferencing and chats all summer!

Tracy Miranda started the summit out by introducing the Continuous Delivery Foundation,
which aims to provide a vendor neutral home to help and sustain open source projects
focusing on all aspects of continuous delivery.  Currently, Jenkins, Tekton, Spinnaker,
and JenkinsX have joined the foundation.  Project updates were given for Jenkins,
Tekton, and JenkinsX.  In the afternoon, attendees split into different groups for
unconference sessions.  I presented my project to the Jenkins group.  Afterwards,
there was free time to chat with other attendees about my project and the other Jenkins
projects. Lastly, lightning talks were given before everyone headed to the contributor
appreciation event to grab some food and drinks.

Day 2

I attended the Jenkins Pipeline Fundamentals Short Course in the morning. Even
though I’m working on a project for Jenkins, there’s still a lot I don’t know so
I just wanted to try to learn more.

A lot of the afternoon sessions filled up, so I spent the afternoon trying to meet
other people at the conference, before heading to the keynote. The keynote
talked more about the CDF and some of the backstory behind its origin.  This year is also a big anniversary for Jenkins - it has now been
around for 15 years.

After the keynote, I checked out a Women in Tech mixer and
the opening of the exibition hall. Probably my favorite swag I picked up was the
&quot;Will Code for Beer&quot; stickers and a bottle of hot sauce.

Day 3

The morning began with another keynote. Shawn Ahmed of CloudBees talked about the
challenges of visibility into bottlenecks of the development process and Rajeev Mahajan
discussed how HSBC tackled DevOps.  The rest of the day I attended different sessions
on container tooling, implementing CI/CD in a cloud native environment, running
Jenkins on Jenkins, and database DevOps.

After the sessions finished, I wandered
around the expo until it closed, then joined some of the other conference attendees
to have some fun at a ping pong bar nearby.

Day 4

The final and last day of the conference was probably my favorite.  The morning
keynote revealed that Zhao Xiaojie had won an award for his work on Jenkins advocacy,
some other DevOps award panelists talked about their approaches to different challenges,
then David Stanke gave an enjoyable presentation about cloud native CI/CD. I was
able to present my summer project and attend a few more sessions, including one
about DevOps at scale, and another about use cases for machine learning in CI/CD pipelines.

The last keynote given by James Governor was a thoughtful look into the current and
future states of tech. How does tech look like it will scale in the coming years
in the U.S. and across the world? How can we make tech more inclusive and accessible?
What can we do to minimize our environmental footprint?  In particular, his points
on welcoming people from a non-traditional computer science background resonated with
me since I’m currently undergoing my own career transition to tech.

After the conference ended, I said goodbye to the remaining GSoC org admins before
meeting an old friend for dinner and bringing along some new friends I met at the
conference.  I spent the remaining part of the night singing karaoke with
them before heading out of San Francisco the next morning.

Thanks again to everyone who supported me and encouraged me leading up to and during
my presentation, patiently answered my questions as I tried to gather more context
about CI/CD tools and practices, and made my first DevOps conference so enjoyable!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stopalopa/">Natasha Stopa</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pluginmanagement">pluginmanagement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2019">devopsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/23/introduce-react-plugin-template/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">23</div></div><h5 class="title">Introduce React Plugin Template</h5></div><p class="teaser">The template’s main repo is at
React Plugin Template

This template is part of the project Working Hours UI Improvement during
Google Summer of Code 2019, which improved the UI of Working Hours Plugin using this pattern to develop Jenkins plugins with React. The Working Hours Plugin repository can be found at Working Hours Plugin.

Overview

Developing plugin for Jenkins has always been easy to do with its Jelly based UI render system, but Jelly seems to be pretty heavy when we want to use more modernized frameworks like React, or if we need to make the plugin UI more customized. This is what this template is built for.

And with React integrated, development of Jenkins plugin is more modernized, developer can now use tons of React libraries, the way to use libraries is now tinier and safer with webpack, in short, coding with Jenkins plugin can be much easier.

Features

Feature
Summary

React Integrated
React is integrated, you can take full control of the UI

Using Iframe
Using iframe can create a new javascript env, we can get rid of some side effects of some polyfills which was added globally.(such as Prototype.js)

Maven Lifecycle
npm commands are integrated into Maven lifecycle with help of Frontend Maven Plugin

Webpack
Webpack helps us reduce the size of the bundle, also avoids pollution on the global namespace.

Jenkins Crumb attached
Crumb is attached to Axios client, now you can send requests in the way you used to do in React.

Express as devserver
You can run your react app in a standalone page so you can develop in webpack hot reload mode, also with webpack proxy, the standalone app is still accessible to the jenkins dev server.

Axios as http client
Axios hugely simplify the way to make requests.

Screenshots

Example Plugin UI

Management Link

Getting Started

Clone the repo:

git clone https://github.com/jenkinsci/react-plugin-template.git
cd react-plugin-template

Install the Maven dependencies and node modules.

mvn install -DskipTests

Run standalone React app with hot reload

npm run start

Run plugin

mvn hpi:run -Dskip.npm -f pom.xml

Send HTTP requests

As Crumb Issuer is default enabled in Jenkins and each ajax request is required to contain a Jenkins Crumb in request header, so be sure to use the axiosInstance which is already set up with Jenkins Crumb and exported at src/main/react/app/api.js.

export const apiGetData = () =&gt; {
  return axiosInstance.post(&quot;/data&quot;);
};

Or if you want to use your own http client, remember to add the Jenkins Crumb to your request’s header, the Crumb’s key and content could be found at src/main/react/app/utils/urlConfig.js, then you can set the header like below.

const headers = {};
const crumbHeaderName = UrlConfig.getCrumbHeaderName();

if (crumbHeaderName) {
  headers[crumbHeaderName] = UrlConfig.getCrumbToken();
}

Write your own request handler

Now you can customize your request pattern as you want, also we need to write a handler.

Jenkins is using stapler to preprocess the requests, so if you need a request handler. For example and also in this template, you can use an Action class to create a sub-url, and then a StaplerProxy to proxy the request like a router. More info about handlers can be found in the Stapler Reference.

Example handler

ManagementLink would get the request and then hand it off to the PluginUI

@Extension
public class PluginManagementLink extends ManagementLink implements StaplerProxy {

    PluginUI webapp;

    public Object getTarget() {
        return webapp;
    }

    public String getUrlName() {
        return &quot;react-plugin-template&quot;;
    }
}

PluginUI, stapler would then find methods in the target class, in this case, it finds doDynamic, then we can choose the next handler by return the methods result, in this case, getTodos or setTodos, and PluginUI just function like a url router.

public class PluginUI{
    public HttpResponse doDynamic(StaplerRequest request) {
        ...

        List params = getRequestParams(request);

        switch (params.get(0)) {
        case &quot;get-todos&quot;:
            return getTodos();
        case &quot;set-todos&quot;:
            return setTodos(request);
        }
        ...
    }
}

Data Persistence

You can save your data with a descriptor

@Extension
public class PluginConfig extends Descriptor implements Describable

And after each time you change data, call save() to persist them.

public void setTodos(
            @CheckForNull List value) {
        this.todos = value;
        save();
    }

And in your handler, you can get the config class by calling

config = ExtensionList.lookup(PluginConfig.class).get(0);

Customize your plugin

Be sure to modify all the occurrence of react-template

At org/jenkinsci/plugins/reactplugintemplate/PluginUI/index.jelly, change the iframe’s id and its source url.

At src/main/react/app/utils/urlConfig.js change

At src/main/react/server/config.js, change the proxy route.

At src/main/react/package.json, change the start script’s BASE_URL

At pom.xml, change the artifactId

At org/jenkinsci/plugins/reactplugintemplate/PluginManagementLink.java, change names.

Also use the same value to modify the occurrence in src\main\react\app\utils\urlConfig.js.

Customize a page for your plugin

A management Link is recommended, which would get your plugin a standalone page, along with a entry button in the /manage system manage page.

How does this template work?

This template is putting a webpack project inside a Maven project, and this template is just chaining the build result by copy the webpack output to the plugin’s webapp folder to make it accessible from the iframe, then Jelly render the iframe and the client gets the Plugin UI.

Why iframe?

Over time, Jenkins has added a lot of various javascript libraries to every regular page, which now causes problems for using modern Javascript tooling and as such, we decided to inline the new react based pages in their own sandbox which prevents collisions with other libraries, and maybe the iframe is a good sandbox case.

Links

Github: React Plugin Template

Github: Working Hours Plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jackshen/">Jack Shen</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/react">react</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/template">template</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/23/introducing-gitlab-branch-source-plugin/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">23</div></div><h5 class="title">Introducing new GitLab Branch Source Plugin</h5></div><p class="teaser">The GitLab Branch Source Plugin has come out of its beta stage and has been released to the Jenkins update center. It allows you to create job based on GitLab user or group or subgroup project(s). You can either:

Import a single project’s branches as jobs from a GitLab user/group/subgroup (Multibranch Pipeline Job)

Import all or a subset of projects as jobs from a GitLab user/group/subgroup (GitLab Group Job or GitLab Folder Organization)

The GitLab Group project scans the projects, importing the pipeline jobs it identifies based on the criteria provided. After a project is imported, Jenkins immediately runs the jobs based on the Jenkinsfile pipeline script and notifies the status to GitLab Pipeline Status. This plugin unlike other Branch Source Plugins provides GitLab server configuration which can be configured in Configure System. Jenkins Configuration as Code (JCasC) can also be used to configure the server. To learn more about server configuration see my previous blog post.

Requirements

Jenkins - 2.176.2 (LTS)

GitLab - v11.0+

Creating a Job

To create a Multibranch Pipeline Job (with GitLab branch source) or GitLab Group Job, you must have GitLab Personal Access Token added to the server configuration. The credentials is used to fetch meta data of the project(s) and to set up hooks on GitLab Server. If the token has admin access you can also set up System Hooks while Web Hooks can be set up from any user token.

Create a Multibranch Pipeline Job

Go to Jenkins &gt; New Item &gt; Multibranch Pipeline &gt; Add Source &gt; GitLab Project

Server - Select your desired GitLab server from the dropdown, needs to be configured before creating this job.

Checkout Credentials - Add credentials of type SSHPrivateKey or Username/Password if there are any private projects to be built by the plugin. If all projects are public then no checkout credentials required. Checkout credential is different from the credential (of type GitLab Personal Access Token) setup in GitLab server config.

Owner - Can be a user, group or subgroup. Depending on this the Projects field is populated.

Projects - Select the project you want to build from the dropdown.

Behaviours - These traits are very powerful tool to configure the build logic and post build logic. We have defined new traits. You can see all the information in repository documentation.

Save and wait for the branches indexing. You are free to navigate from here, the job progress is displayed to the left hand side.

After the indexing, the imported project listed all the branches, merge requests and tags as jobs.

On visiting each job, you will find some action items on the left hand side:

You can trigger the job manually by selecting Build Now.

You can visiting the particular branch/merge request/tag on your GitLab Server by selecting the corresponding button.

Create a GitLab Group Job Type

Go to Jenkins &gt; New Item &gt; GitLab Group

You can notice the configuration is very similar to Multibranch Pipeline Job with only Projects field missing. You can add all the projects inside your Owner i.e. User/Group/Subgroup. The form validation will check with your GitLab server if the owner is valid. You can add Discover subgroup project trait which allows you to discover this child projects of all subgroups inside a Group or Subgroup but this trait is not applicable to User. While indexing, web hook is created in each project. GitLab Api doesn’t support creation of Group web hooks so this plugin doesn’t support that feature which is only available in GitLab EE.

You can now explore your imported projects, configuring different settings on each of those folders if needed.

GitLab Pipeline Status Notification

GitLab is notified about build status from the point of queuing of jobs.

Success - the job was successful

Failure - the job failed and the merge request is not ready to be merged

Error - something unexpected happened; example: the job was aborted in Jenkins

Pending - the job is waiting in the build queue

On GitLab Pipeline status are hyperlinks to the corresponding Jenkins job build. To see the Pipeline Stages and the console output you will be required to visit your Jenkins server. We also planned to notify the pipeline stages to GitLab but it came with some drawbacks which has been addressed so far but there is future plan to add it as trait.

You can also skip notifying GitLab about the pipeline status by selecting Skip pipeline status notifications from the traits list.

Merge Requests

Implementing support for Merge Requests for the projects was challenging. First, MRs are of 2 types i.e. Origin branches and Forked Project branches so there had to be different implementation for each head. Second, MRs from forks can be from untrusted sources, so a new strategy Trust Members was implemented which allows CI to build MRs only from trusted users who have accesslevel of Developer / Maintainer / Owner.

Third, MRs from forks do not support pipeline status notification due to GitLab issue, see this. You can add a trait Log Build Status as Comment on GitLab that allows you to add a sudo user (leave empty if you want owner user) to comment on the commit/tag/mrs the build result. To add a sudo user your token must have admin access. By default only failure/error are logged as comment but you can also enable logging of success build by ticking the checkbox.

Sometimes, Merge Requests fail due to external errors so you want to trigger rebuild of mr by commenting jenkins rebuild. To enable this trigger add the trait Trigger build on merge request comment. The comment body can be changed in the trait. For security reasons, commentor should have Developer / Maintainer / Owner accesslevel in the project.

Hooks

Web hooks are automatically created on your projects if configured to do so in server configuration. Web hooks are ensured to pass through a CSRF filter. Jenkins listens to web hooks on the path /gitlab-webhook/post. On GitLab web hooks are triggered on the following events:

Push Event - when a commit or branch is pushed

Tag Event - when a new tag is created

Merge Request Event - when a merge request is created/updated

Note Event - when a comment is made on a merge request

You can also set up System Hooks on your GitLab server if your token has admin access. System hooks are triggered when new projects are created, Jenkins triggers a rescan of the new project based on the configuration and sets up web hook on it. Jenkins listens to system hooks on the path /gitlab-systemhook/post. On GitLab system hooks are triigered on Repository Update Events.

You can also use Override Hook Management mode trait to override the default hook management and choose if you want to use a different context (say Item) or disable it altogether.

Job DSL and JCasC

You can use Job DSL to create jobs. Here’s an example of Job DSL script:

organizationFolder(&#x27;GitLab Organization Folder&#x27;) {
    description(&quot;GitLab org folder created with Job DSL&quot;)
    displayName(&#x27;My Project&#x27;)
    // &quot;Projects&quot;
    organizations {
        gitLabSCMNavigator {
            projectOwner(&quot;baymac&quot;)
            credentialsId(&quot;i&lt;3GitLab&quot;)
            serverName(&quot;gitlab-3214&quot;)
            // &quot;Traits&quot; (&quot;Behaviours&quot; in the GUI) that are &quot;declarative-compatible&quot;
            traits {
                subGroupProjectDiscoveryTrait() // discover projects inside subgroups
                gitLabBranchDiscovery {
                    strategyId(3) // discover all branches
                }
                originMergeRequestDiscoveryTrait {
                    strategyId(1) // discover MRs and merge them with target branch
                }
                gitLabTagDiscovery() // discover tags
            }
        }
    }
    // &quot;Traits&quot; (&quot;Behaviours&quot; in the GUI) that are NOT &quot;declarative-compatible&quot;
    // For some &#x27;traits, we need to configure this stuff by hand until JobDSL handles it
    // https://issues.jenkins.io/browse/JENKINS-45504
    configure {
        def traits = it / navigators / &#x27;io.jenkins.plugins.gitlabbranchsource.GitLabSCMNavigator&#x27; / traits
        traits

You can also use JCasC to directly create job from a Job DSL script. For example see the plugin repository.

How to talk to us about bugs or new features?

This project uses Jenkins JIRA to track issues. You can file issues under gitlab-branch-source-plugin component.

Send your mail in the Developer Mailing list.

Join our Gitter channel.

Future work

Actively maintain GitLab Branch Source Plugin and take feedbacks from users to improve the plugin’s user experience.

Extend support for GitLab Pipeline to Blueocean.

Resources

GitLab API Plugin

GitLab API Plugin Wiki

GitLab Branch Source Plugin

Project Summary

GitHub Branch Source Plugin Release

Thank you Jenkins and Google Summer of Code :)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/baymac/">Parichay Barpanda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gitlab">gitlab</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/multibranch">multibranch</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/25/jenkinsworld-contrib-summit-ask-the-expert-booth/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">25</div></div><h5 class="title">Jenkins World Contributor Summit and Ask the Expert booth</h5></div><p class="teaser">Jenkins turns 15 years old!
Jenkins World brings together DevOps thought leaders, IT executives, continuous delivery practitioners and the Jenkins
community and ecosystem in one global event, providing attendees with the opportunity to learn, explore, network
face-to-face and help shape the next evolution of Jenkins development and solutions for DevOps.

There is also the Jenkins Contributor Summit in San Francisco. The Jenkins Contributor Summit is the place where
current and future contributors get together to discuss, learn and collaborate on the latest and greatest efforts within
Jenkins project. The morning portion of the summit is a mix of presentations by the core contributors. The
presentations highlight what each effort is about and what community members can do to help. In the
afternoon breakout sessions with  Birds of a Feather tables for in-depth discussion, and collaboration with sub-project
contributors.

I feel very honored to have been a part of this.

Day 1

Day one started with the contributor summit. This was a chance for everyone to get together and talk about
contributions and put faces to names. Most people I had only met via video chat or on gitter so I was super excited.
We gathered to hear about the start of the Jenkins open source landscape.

Next up was the BoF/Unconference. I was leading these sessions and I felt they went really well.
We had fellow org admins Martin d’Anjou and Jeff Pearce give a talk about Google Summer of Code projects.

Google Summer of Code student Natasha Stopa presented her project, Plugin Installation Manager Library/CLI Tool. This is
a super cool project and very well received in the community.

We closed out the session with a presentation from Steven Terrana from Booz Allen Hamilton and the awesome Jenkins
Templating Engine. If you have not had a chance to try this, please make sure you do at https://github.com/boozallen/jenkins-templating-engine.

Main Expo Hall

Day two and onward saw me and other Jenkins org admins in the Ask the Expert booth for the Jenkins community.

This was a really cool experience and gave me a chance to hear about things the community is working on and help with
issues they are facing.
There were a range of questions from Jenkins X to many of the plugins I maintain such and the Jenkins Prometheus and the
Sysdig Secure Scanning plugins.
There were also a lot of Kubernetes questions. There is a lot of marketing data regarding the increased usage of
Kubernetes but I was seriously surprised by the massive interest in Jenkins on Kubernetes.
Of course there were opportunities for selfie requests.

Lunch time demos got underway and we had a busy schedule.
First up was the awesome Mark Waite to talk about the
Git plugin. A lot of people use git in
Jenkins.
Thank you so much for all that you do Mark.

Jenkins org admin Martin d’Anjou was next on deck to talk about the Google Summer of Code. So amazing to think that the
Google Summer of Code is also in its 15th year like Jenkins!

Natasha Stopa is a Google Summer of Code student and she presented her project Plugin Installation Manager Library/CLI Tool.
Natasha really put a lot of hard work in to this plugin and it was really awesome to see the turn out and support during
her presentation.

Finally there was me. I presented the Sysdig Secure Scanning Jenkins plugin which I am a maintainer of. I thank everyone who attended

Right after the lunch time demos I also oversaw the Jenkins open space. This was an opportunity for the community to talk
about items and let them flow organically. I really enjoyed this session and felt it was also well received.

We closed out the day and the event with a picture of some of the Jenkins org admins and Google Summer of Code students.
Missing from this photos are fellow org admins, Lloyd Chang and Oleg Nenashev

Closing

This was an amazing experience. Huge thanks to CloudBees, the Jenkins community, Google Summer of Code, Tracy Miranda,
Alyssa Tong and my employer Sysdig.

To think Jenkins is 15 years old is amazing! There has been so much accomplished and the future is so bright. I am so
thankful for the opportunity to serve and be a part of the open source community.
Here’s to 15 more years all!

If you are interested in joining any one of the Jenkins open source special interest groups, look here. We can use your
help: https://jenkins.io/sigs/

If you are interested in joining the Summer of Code, look here: https://jenkins.io/projects/gsoc/
If you want to chat with us, find us here: https://jenkins.io/chat/
Or if you want to email us, reach out at: https://jenkins.io/mailing-lists/

Some photos outtakes:<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markyjackson-taulia/">Marky Jackson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2019">devopsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/opensource">opensource</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/contributorsummit">contributorsummit</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/asktheexpert">asktheexpert</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/26/role-strategy-performance/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">26</div></div><h5 class="title">Performance Improvements to Role Strategy Plugin</h5></div><p class="teaser">The task for my Google Summer of Code program was to improve the performance
of the Role Strategy Plugin. The performance issues for Role Strategy Plugin
had been reported multiple times on Jenkins JIRA. With a large number of roles
and with complex regular expressions, a large slow-down was visible on the Web UI.
Even before GSoC started, there were a number of patches which tried to improve
performance of the plugin (by Deepansh Nagaria
and others).

At the time, there was no way to reliably measure improvements in performance.
Therefore, we started by creating a
framework
for running micro-benchmarks on Jenkins Plugins. Benchmarks using the framework
were added to the Role Strategy Plugin find performance
critical parts of the plugins and to measure the improvements of a change.
This blog post summarizes the changes that were made and performance improvements
measured.

Caching matching roles

A couple of major changes were made to the Role Strategy Plugin to improve its
performance. First, we started collection of roles that matched a given
project name. The Role Strategy plugin before version 2.12 used to run over
regular expressions for every role that it had for every permission checking
request it got. Storing this produced set of roles in the memory provides us
large improvements in performance and avoids repeated matching of project names
with regular expressions. For keeping the plugin working securely, we invalidate
the cache whenever any update is made to the roles.

After this change, we were able to observe performance improvements of up to
3300%. These improvements were visualized using
JMH Visualizer.

More information is available at pull request on GitHub:
https://github.com/jenkinsci/role-strategy-plugin/pull/81

Calculating Implying Permisions when plugin is loaded

Jenkins&#x27; permission model allows one permissions to imply other permissions.
When a permission check is made, we need to check if the user has any of
permissions that would imply this permisison. For every permission checking
request that that the Role Strategy, it used to calculate all the implying
permissions. To avoid this, we now calculate and store implying permissions
for every permission in the Jenkins system when the plugin gets loaded.

After both of these changes, we were able to experience improvements of up to
10000%. The benchmark results show it better:

More information about this change can be found at the GitHub pull request:
https://github.com/jenkinsci/role-strategy-plugin/pull/83

Both of these changes were integrated into the Role Strategy Plugin and the
improvements can be experienced starting with version
2.13.

Bonus: Configuration-as-Code export now works for Role Strategy

With Configuration-as-Code plugin version
1.24
and above, export of your configuration as YAML now works!

As an alternative to
Role Strategy Plugin, I also created the brand new Folder Authorization Plugin.
You can check out the blog post for
more information about the plugin.

Links and Feedback

I would love to hear your comments and suggestions. Please feel free to reach
out to me through either the
Role Strategy Plugin Gitter chat or through
Jenkins Developer Mailing list.

Presentation slides for final evaluation of GSoC

The Folder Authorization Plugin

Demo for the final evaluations<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhyudayasharma/">Abhyudaya Sharma</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/08/30/jenkins-cli/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">30</div></div><h5 class="title">Managing Jenkins with jcli</h5></div><p class="teaser">As a developer, I usually use Jenkins like this:

Find a job which is related with my current work

Trigger that job

Check the output of the build log

Sometimes, I might need to check the update center. Maybe a new plugin is needed, or I need to update an existing plugin.
Or, I want to upload a plugin from my computer. For all these cases, I just don’t need a UI or even a browser.
I like to use a CLI to complete most of my tasks. For example, I use kubectl to manage my Kubernetes cluster,
to create or modify the kubernetes resources. So, I start to think, &#x27;Why not use a CLI to manage my Jenkins?&#x27;.

Why create a new one?

First, I almost forgot about the existing Jenkins CLI, written in Java. Let me introduce how to use that one.

Visit Jenkins page from http://localhost:8080/jenkins/cli/ . You’ll see a command like java -jar jenkins-cli.jar -s http://localhost:8080/jenkins/ help. So, a jar file needs to be download.
We can use this command to complete this task wget http://localhost:8080/jenkins/jnlpJars/jenkins-cli.jar .

Now you can see that this is not a Linux-style CLI. Please consider some points below:

The users must have a JRE. This is not convenient for developers who don’t use Java.

The CLI is too wordy. We always need to type java -jar jenkins-cli.jar -s http://localhost:8080/jenkins/ as the initial command.

Cannot install it by some popular package manager, like brew or yum.

Of course, the Java CLI client is more native with Jenkins. But I’d like to use this more easily.
So I decided to create a new CLI tool which would be written in Go and which would natively run on modern platforms.

That’s the story of creating jcli.

Features

Easy to maintain config file for jcli

Multiple Jenkins support

Plugins management (list, search, install, upload)

Job management (search, build, log)

Open your Jenkins with a browser

Restart your Jenkins

Connection with proxy support

How to get it?

You can clone jcli from the jenkins-cli repo. For now, we support
these three most popular OS platforms: MacOS, Linux, and Windows.

MacOS

You can use brew to install jcli.

brew tap jenkins-zh/jcli
brew install jcli

Linux

It’s very simple to install jcli into your Linux OS. Just need to execute a command line at below:

curl -L https://github.com/jenkins-zh/jenkins-cli/releases/latest/download/jcli-linux-amd64.tar.gz|tar xzv
sudo mv jcli /usr/local/bin/

Windows

You can find the latest version by clicking here. Then download the tar file, cp the uncompressed jcli directory into your system path.

How to get started?

It’s very simple to use this. Once you get jcli on your computer, use this command to generate a sample configuration:

$ jcli config generate
current: yourServer
jenkins_servers:
- name: yourServer
  url: http://localhost:8080/jenkins
  username: admin
  token: 111e3a2f0231198855dceaff96f20540a9
  proxy: &quot;&quot;
  proxyAuth: &quot;&quot;
# Goto &#x27;http://localhost:8080/jenkins/me/configure&#x27;, then you can generate your token.

In most cases, you should modify three fields which are url, username and token. OK, I believe you’re ready. Please check whether you install the github plugin in your Jenkins:

jcli plugin list --filter name=github

That’s the end. It’s still in very early development stage. Any contribution is welcome.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/linuxsuren/">赵晓杰(Rick)</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jcli">jcli</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cli">cli</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tools">tools</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/09/10/introducing-the-jira-software-plugin-for-jenkins/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">10</div></div><h5 class="title">Introducing the Jira Software plugin for Jenkins</h5></div><p class="teaser">According to a recent survey we conducted, software &amp; IT teams on average use 4+ tools to move code from development to customer-facing production. As a result, teams struggle with keeping the status of work updated and understanding the overall health of their delivery pipeline.

To solve this problem, I am excited to announce that we built an official Jenkins plugin for Jira Software Cloud. The plugin automatically associates build and deployment information from Jenkins with relevant Jira issues and exposes key information about your pipeline across Jira issues, boards and via JQL. This means you can use Jira Software to automatically update and track issues through your complete development pipeline, from backlog to release.

I hope this plugin adds value to you and your team. If you are interested in contributing or forking this plug-in you can head over to our project on the Jenkins GitHub repo to get started.

Better collaboration between teams

This new information view is so powerful because historically it was dispersed across multiple tools only accessible to a few members of your team. Now anyone involved in the software delivery process can self-serve this information. For example, product managers, QA, and support teams can view which features have been deployed to customers and which are still waiting in staging environments.

With better information sharing between tools in your delivery stack, you can also improve cross-collaboration between teams. Teams such as QA and operations can collaborate in the software teams next sprint. For example, you can use build information in Jira Software to create a workflow between QA and developers and create a rapid feedback loop for testing at any point in your development process.

Use Jira’s Querying Language for advanced views

In addition to building better ways to collaborate, these integrations also give your team deeper insight into the development pipeline from within Jira Software. You can now create powerful views into your delivery pipeline with JQL queries across multiple connected tools. For example, you can write a custom JQL query to report all Jira issues that have been deployed to production but still have an open PR.

deploymentEnvironmentType ~ “production“ AND development[pullrequests].open

Get started

In Jira Software Cloud

Create OAuth credentials in Jira for Jenkins

Navigate to Jira home &gt; Jira settings &gt; Apps.

Select OAuth credentials.

Select Create credentials.

Enter the following details:

App name - Jenkins

App logo - A URL to the Jenkins logo, which will be used as an icon in the list of credentials. Eg: https://jenkins.yourcompany.com/logo.png

Server base URL - The URL to your Jenkins server. Eg: https://jenkins.yourcompany.com

In Jenkins

Install the Jenkins plugin

Login to your Jenkins server and navigate to the Plugin Manager.

Select the &#x27;Available&#x27; tab and search for &#x27;Atlassian Jira Software Cloud&#x27; as the plugin name then install it.

The open-source plugin is hosted in the Jenkins GitHub account. You can check it out here.

Set up Jenkins credentials

In Jenkins, go to Manage Jenkins &gt; Configure System screen and scroll to the Jira Software Cloud integration section.

Select Add Jira Cloud Site &gt; Jira Cloud Site. The Site name, ClientID, and Secret fields display.

Enter the following details:

Site name: The URL for your Jira Cloud site, for example yourcompany.atlassian.net.

Client ID: Copy from OAuth credentials screen (Client ID column).

Secret: Select Add &gt; Jenkins.

For Kind, select Secret text.

For Secret, copy from OAuth credentials screen (Secret column).

For Description, provide a helpful description

Select Test settings to make sure your credentials are valid for your Jira site.

How to use the plugin

To start using the integration:

Go into a specific pipeline in Jenkins ( Note: Your pipeline must be a &#x27;Multibranch Pipeline&#x27; ).

From the left-hand menu, select Pipeline Syntax.

In the Snippet Generator, select jiraSendDeploymentInfo or jiraSendBuildInfo from the dropdown list of Sample Steps and fill in the relevant details.

Select Generate Pipeline Script and copy/paste the output into your Jenkinsfile on the relevant Repository you are using. This will be used to notify Jira when you run that pipeline on that repo.

For sending build information

This is an example snippet of a very simple ‘build’ stage set up in a Jenkinsfile. After the pipeline is run, it will post the build information to your Jira Cloud site by looking at the branch name. If there is a Jira issue key (e.g. “TEST-123”) in the branch name, it will send the data over to Jira.

Jenkinsfile example

pipeline {
     agent any
     stages {
         stage(&#x27;Build&#x27;) {
             steps {
                 echo &#x27;Building...&#x27;
             }
             post {
                 always {
                     jiraSendBuildInfo site: &#x27;example.atlassian.net&#x27;
                 }
             }
         }
     }
 }

For sending deployment information

This is an example snippet of two stages that run on any change to the staging or master branch. Again, we use a post step to send deployment data to Jira and the relevant issues. Here, the environmentId, environmentName, and environmentType need to be set to whatever you want to appear in Jira.

Jenkinsfile example

pipeline {
     agent any
     stages {
         stage(&#x27;Deploy - Staging&#x27;) {
             when {
                 branch &#x27;master&#x27;
             }
             steps {
                 echo &#x27;Deploying to Staging from master...&#x27;
             }
             post {
                 always {
                     jiraSendDeploymentInfo site: &#x27;example.atlassian.net&#x27;, environmentId: &#x27;us-stg-1&#x27;, environmentName: &#x27;us-stg-1&#x27;, environmentType: &#x27;staging&#x27;
                 }
             }
         }
         stage(&#x27;Deploy - Production&#x27;) {
            when {
                branch &#x27;master&#x27;
            }
            steps {
                echo &#x27;Deploying to Production from master...&#x27;
            }
            post {
                always {
                    jiraSendDeploymentInfo site: &#x27;example.atlassian.net&#x27;, environmentId: &#x27;us-prod-1&#x27;, environmentName: &#x27;us-prod-1&#x27;, environmentType: &#x27;production&#x27;
                }
            }
         }
     }
 }

The entire Jenkinsfile may look something like this. This is only meant to represent an example of what the Jira snippets could look like within a stage or step.

Jenkinsfile example

pipeline {
     agent any
     stages {
         stage(&#x27;Build&#x27;) {
             steps {
                 echo &#x27;Building...&#x27;
             }
             post {
                 always {
                     jiraSendBuildInfo site: &#x27;example.atlassian.net&#x27;
                 }
             }
         }
         stage(&#x27;Deploy - Staging&#x27;) {
             when {
                 branch &#x27;master&#x27;
             }
             steps {
                 echo &#x27;Deploying to Staging from master...&#x27;
             }
             post {
                 always {
                     jiraSendDeploymentInfo site: &#x27;example.atlassian.net&#x27;, environmentId: &#x27;us-stg-1&#x27;, environmentName: &#x27;us-stg-1&#x27;, environmentType: &#x27;staging&#x27;
                 }
             }
         }
         stage(&#x27;Deploy - Production&#x27;) {
            when {
                branch &#x27;master&#x27;
            }
            steps {
                echo &#x27;Deploying to Production from master...&#x27;
            }
            post {
                always {
                    jiraSendDeploymentInfo site: &#x27;example.atlassian.net&#x27;, environmentId: &#x27;us-prod-1&#x27;, environmentName: &#x27;us-prod-1&#x27;, environmentType: &#x27;production&#x27;
                }
            }
         }
     }
 }

Questions or feedback?

If you have any questions, please contact Atlassian support and they will route it to the correct team to help you.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rafalmyslek/">Rafal Myslek</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jira">jira</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/09/23/outreachy-audit-log-release/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">23</div></div><h5 class="title">Audit Log Plugin for Jenkins Releases 1.0</h5></div><p class="teaser">Thanks to our Outreachy interns over the past year, I’m proud to announce the initial release of the Audit Log plugin for Jenkins.
This plugin is the first major project completed related to Outreachy, and I’d like to give a brief overview of the functionality that was developed for this release.
The primary goal of this plugin is to introduce an audit trail of various Jenkins events using structured logging and related audit logging standards.
Initially, this plugin covers audit events related to core Jenkins concepts like user accounts, jobs, builds, nodes, and credentials usage.
More specifically, this tracks:

User login and logout events

Credentials usage

User creation (when using the Jenkins user database as a security realm)

User password updates (ditto)

Starts and ends of builds

Creation/modification/deletion/copying of items (which correspond to projects, pipelines, folders, etc.)

Creation/modification/deletion of nodes.

This plugin defines and exports standardized log event classes and schemas corresponding to these events.
Other plugins can add audit-log as a dependency to define their own audit events using Apache Log4j Audit and its catalog editor; then they can use the Maven plugin for generating the audit event classes for use in the plugin.

The other major feature of this plugin is configuring where to output these audit logs.
By default, audit logs will be written in HTML files (rotated once per day) to $JENKINS_HOME/logs/html/audit.html which are viewable through the &quot;Audit Logs&quot; root action link.
In the system settings, a section for audit logging is added where the main audit log output can be configured.
This can initially be configured to output via either a JSON log file in $JENKINS_HOME/logs/audit.log by default or to a syslog server using RFC5424 encoding.

Overall, this experience has been rather interesting.
Besides having an opportunity to mentor new contributors, Outreachy has helped open my eyes to the struggles that developers from around the world are dealing with which can be improved upon to help expand our communities.
For example, many countries do not have reliable internet or electricity, so the use of synchronous videoconferencing and other heavyweight, synchronous processes common to more corporate-style development are inadequate in this international context.
This doesn’t even begin to account for the difference in timezones which is not always an issue, though both problems are addressable by using asynchronous communication methods like chat and email.
This notion of asynchronous communication is an important aspect of the Apache Way, for example, which emphasises processes that allow for vendor neutral communities to form and thrive around a project.

This mentoring project was valuable to myself as well.
As a software engineer myself, project management is not my specialty, so this gave me a great opportunity to develop my own PM skills and technical leadership.
My own typical discovery process for feature development involves experimenting directly with the code to see what features make sense to prioritize and which would take a vast effort to implement.
Changing my own discovery process to avoid implementing the features myself was difficult to adjust to, though I did defer any of my own feature contributions to this plugin until after the initial release.
In order to appropriately scope the project, I still had to spend a bit of time reading through the Jenkins codebase to determine which tasks could be implemented simply (e.g., good newbie-friendly issues), which tasks might require changes to Jenkins itself (previously discovered to take too long for these relatively short Outreachy rounds), and which tasks would require intimate familiarity with Jenkins and would likely be infeasible for new developers to Jenkins.
Thanks to the work done in discovery and delivery, I’ve also identified potential features for Log4j itself which could be used in future versions of this plugin.

Overall, I think we did a good job of balancing the scope of this project without spending too much time in any specific area.
The first release of this plugin is now available in the Jenkins Update Center.
In the future, I hope to learn more about developing Jenkins UI components so that we can create a more dynamic and Jenkins-like configuration page for choosing where logs are output.
While I don’t intend on using this plugin for further Outreachy rounds, I do hope to see more interest in it over time as the more security-conscious users out there discover this new plugin.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jvz/">Matt Sicker</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreachy">outreachy</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/logging">logging</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/09/25/board-elections/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">25</div></div><h5 class="title">2019 Jenkins Board and Officer elections. Nominations are open!</h5></div><p class="teaser">This is a repost of the original announcement made by Kohsuke Kawaguchi in the Jenkins Developer mailing list.
Minor changes were applied to reflect the posting date and to provide more links.

Nominations for the 2019 Jenkins Board elections open for three governing board positions and five officer positions, namely: Security, Events, Release, Infrastructure and Documentation.

The terms of office for these positions are:

Officer positions (1 year): November 4, 2019 to November 3, 2020

Governing board members (2 years): November 4, 2019 to November 3, 2021

To nominate someone, simply send an email to jenkinsci-board@googlegroups.com with their name and position you nominate them for.
Please share any information on why you are making the nomination.
Self nominations are also welcome.

The board positions and officer roles are an essential part of Jenkins&#x27; community governance and well-being.
I highly encourage everyone to consider participating.

Key dates

Oct 04, 2019: Nominations close

Oct 08, 2019: List of nominees posted to mailing list

Oct 11, 2019: Nominees’ personal statements made available

Oct 14, 2019: Voting begins

Oct 27, 2019: Voting closes at 5pm Pacific Time

Nov 04, 2019: New representatives announced

References

Jenkins Governance Board

Jenkins Board Election Process

Jenkins Officers

Announcement in the developer mailing list

2019 elections proposal in the developer mailing list<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/10/01/hacktoberfest/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 1</div></div><h5 class="title">Hacktoberfest 2019. Contribute to Jenkins!</h5></div><p class="teaser">Once again, Hacktoberfest is back!
During this October event, everyone can support open-source by contributing changes, and can earn limited edition swag.
We invite you to contribute to Jenkins, regardless of your experience and background.
You can write code, improve documentation and design, localize Jenkins or create new artwork.
Any GitHub pull request counts!

Quick start

Sign-up to Hacktoberfest on the event website.

Join our Gitter channel.

Everything is set, just start creating pull-requests!

This year Hacktoberfest does not require labeling pull requests,
but please mention Hacktoberfest in your pull requests for faster reviews
(see FAQ: Marking Pull requests)

See the details below.

How to contribute?

There are many ways to
contribute to Jenkins.
It is not just about code, any pull request in GitHub counts towards the Hacktoberfest goal.

Code - Contribute to the code or automated tests.
We have components written in Java, JavasScript, Groovy, Go, Ruby and other languages.

Write - Improve documentation, write blogposts, create tutorials or solution pages

Localize - Help us to Localize Jenkins to other languages

Design - artwork and UI improvements also count!

Organize - Organize a local meetup for Jenkins &amp; Hacktoberfest (see our event kit)

Spread the word - Share your accomplishments in social media using the #hacktoberfest and #jenkinsci hashtags
(or CC @jenkinsci in Twitter).

Where to contribute?

The Jenkins project is spread across multiple organizations on GitHub (jenkinsci, jenkins-infra, jenkins-zh).
You are welcome to contribute to any repository in any of these organizations,
or to any other Jenkins-related repository on GitHub.
If you adopt Jenkins in your own open-source projects (e.g. Jenkins Pipeline or Configuration as Code),
it counts as well! Some useful queries:

Jenkins JIRA issues suggested for Hacktoberfest

GitHub issues suggested for Hacktoberfest

Newbie-friendly issues in Jenkins JIRA

Good first issues on GitHub

Featured projects. If you are a newcomer contributor, we have prepared a list of projects/components where you will get a warm welcome.
All these projects have newbie-friendly tasks, contributing guidelines, and active maintainers
who have committed to assist contributors and to quickly review pull requests.
The list of featured projects will be updated during the event,
and we will make sure to create more newbie-friendly tasks if needed.

If you wonder about Jenkins X, it also part of Hacktoberfest this year!
They offer various topics, including hacking Jenkins X or improving its documentation.
See this blogpost for the announcement and links.

How to get help?

If you are stuck or have any question,
see our Hacktoberfest FAQ page for the common questions.
If it does not help, please reach out to us in our Gitter chat.

Any meetups this year?

There are many events being organized by open-source communities.
You can join one of these events.
We invite to join the Jenkins Online Meetups on Oct 03
 ( APAC/EMEA - 7AM UTC,
EMEA/Americas - 2PM UTC).

There will be also area meetups in Munich, Beijing, St. Petersburg and other cities.
You can find the full list here.

Useful links

Hacktoberfest website

Hacktoberfest in Jenkins

Our Gitter channel

Frequently asked questions

Contributing to Jenkins

Have a great hacking time!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hacktoberfest">hacktoberfest</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/newcomer">newcomer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/10/08/google-summer-of-code-mentor-and-org-admin-perspective/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 8</div></div><h5 class="title">Google Summer of Code Mentor and Org Admin Perspective</h5></div><p class="teaser">I was fortunate enough to participate in the Google Summer of Code 2019 as a mentor and org admin. This was great
and I wanted to share in hopes of encouraging more people to join.
You can learn more about the Google Summer of Code here: https://jenkins.io/projects/gsoc/

Community Bonding

The first phase of the project is the community bonding phase. This is where the student and other mentors come together
to lay out the plan for the project. It is important to set expectations and ensure that the student is well aware of
what will take place and also made to feel welcome.

Parichay Barpanda was the student and he was super awesome from the get go. The project he was working on was the Gitlab
Branch Source Plugin. More can be found here: jenkinsci/gitlab-branch-source-plugin

From the mentor side it was myself and Justin Harringa. Justin was just amazing throughout this project and I seriously
could not have done this without him. He was encouraging, empathetic and just all around great. I would gladly serve
with him again.

We laid out our plan and guidance and got to work.

First Evaluations

The first evaluation was quickly upon us and Parichay was ready!
The work he put in was nothing shy of amazing. We did our 1st demo and he really rocked it. A video of that demo can be
found on : Youtube

Second Evaluations

There was not much time to rest before we realized that phase II end was upon us but Parichay was ready. Again, he
nailed it.

That demo can be found here

Mentors Submit Final Evaluations

We had our final evaluation and at this point Parichay was seasoned. He was getting issues assigned to him, working on
little bug fixes and setting his roadmap for features. He absolutely blew Justin and I away.

Parichay’s final evaluation demo can be seen here

At the conclusion of the final demo’s, Justin and I met and went over Parichay’s final evaluation. At this point we had
met twice a week for several months, we have reviewed code daily, we had community involvement and most of all we had
seen Parichay grow into a seasoned software developer.

Justin and I were without a doubt passing Parichay on his entire body of work. I am actually tearing up typing this
because I am so proud of Parichay.

Org Admin

Being an org admin for the 2019 Google Summer of Code project for the Jenkins organization was truly rewarding and couldn’t
have been accomplished without the help from Oleg Nenashev, Martin d’Anjou, Jeff Pearce and Lloyd Chang.

As an org admin we handled issues with mentors, community members and disagreements involving work. These items were only
a few and as a team we handled them accordingly.

We regularly met to discuss and plan. Coordinating and dealing with a project like Google Summer of Code is no small feat
but this team made it super easy and I am so thankful for them and all that I learned.

Closing

In looking back at this experience I am so grateful for the opportunity I was given. This was such a rewarding experience
to not only be able to mentor but also be an org admin. Not only will I be back next year (we are already in the
planning stages) but I highly encourage people reading this to consider joining. You will not be disappointed.

I am so thankful for all the students, mentors and fellow org admins. Your dedication to open source is so valued. You
showed and continue to show what this project is all about, and that is being welcoming, open and transparent. Helping
people grow as individuals while learning skills is what I love about this community.

Thank you to everyone and I hope your futures are bright!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markyjackson-taulia/">Marky Jackson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mentor">mentor</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/10/08/jcasc-phase1-blog/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day"> 8</div></div><h5 class="title">JCasC Community Bridge Dev Tools - Phase 1</h5></div><p class="teaser">Community Bridge Introduction

Community Bridge is an initiative by the Linux Foundation to accelerate the adoption, innovation and sustainability of open source projects. I came across this initiative in a blog post. I had been contributing to Jenkins at the time and decided to have a chat with Oleg Nenashev and Tracy Miranda regarding the possibility of a project under the Community Bridge initiative. Fortunately for me JCasC ( Jenkins Configuration as Code) had the mentors as well as the project idea in place to start a project. After a few regular meetings we ironed out the details of the programme and on August 7th I began with my journey!

JCasC Developer Tools — JSON Schema

JSON files when submitted to a server undergo a validation to determine whether the values and the format are correct and that they conform to a well defined schema, this schema is known as a JSON Schema. A YAML file can also be validated using a JSON Schema.
The main premise of JCasC is to load YAML files written by developers into the Jenkins instance. An example of a JCasC YAML file is:

---
jenkins:
 systemMessage: “Hello World”
 numExecutors:2
 ---

The above YAML configuration will configure Jenkins to display a message Hello world with the number of executors set to two. In order to validate the YAML we have a schema. This schema is written using jelly files (Executable XML files) and currently it is not a valid schema. The first phase of the project is based around rewriting the schema generation to java and developing a better test framework for it, because currently the schema is not testable.

Phase 1 — JCasC Dev Tools

The first week I got into studying how the schema was generated.With the support of two of my awesome mentors Tim Jacomb and Joseph Peterson
I finally got an understanding of the current schema.
So JCasC has a set of configurators for describing a YAML file.
They are:
a) Base Configurators
b) Hetero Describable Configurators
c) Data Bound Configurators
These configurators together successfully describe a YAML file.
We proceeded to generate the schema with the help of individual description of each of these configurators.
The JSON Schema has a set of components, consider the above yaml file as an example:

---
{
  &quot;jenkins&quot;: {
    &quot;type&quot;: &quot;object&quot;,
    &quot;properties&quot;: {
      &quot;systemMessage&quot;: {
        &quot;type&quot;: &quot;string&quot;
      },
      &quot;numExecutors&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      }
    }
  }
}
---

So here Jenkins is the base configurator and it has a set of attributes viz systemMessage and numExecutors, so our schema needs to be able to describe a set of attributes for every field in the schema. Some of the fields that our JSON Schema uses to describe the YAML are:

1) type : String, int, Boolean etc.

2) properties : A set of fields describing the part field.

3) id: Unique Identifier for the field
Thus the above schema successfully verifies the YAML configuration.

JAVA Rewrite

We used JSON Objects to build components of the schema.The basic flow that is followed to generate the schema is as follows:

a) Iterate through the Base Configurators.

b) Iterate over the list of Base Configurator.Attributes and add each attribute to the schema.

c) Iterate over the HeteroDescribable Configurators and add each configurator to the schema along with its required properties.

The set of PR’s Resolved during Phase 1 are as follows:

a) Basic Schema

b) Schema Doc Page

c) Test Framework

d) Nested Schema

That is all from me guys, I am currently preparing for phase 2 and working towards fixing any pending issues of Phase 1. Thanks for reading.

Phase 2 Goals:

We would primarily target VSCode integration in phase 2 with the aim of:

a)Validation of JCasC YAML files with the schema

b)Autocompletion

c)Integration with a live Jenkins instance.

Contributions

We would love to get feedback from you on the stuff we are working on. Contributions to the project would be highly appreciated.

a) Gitter Chat

b) Github Repository

c) Project Introduction<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sladyn98/">Sladyn Nunes</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community-bridge">community-bridge</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/JCasC">JCasC</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/VSCode">VSCode</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/10/21/plugin-docs-on-github/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">21</div></div><h5 class="title">Plugin Documentation-as-Code: Moving docs to GitHub</h5></div><p class="teaser">In September 2019 we announced
support of GitHub as a source of documentation for the Jenkins Plugin Site.
Thanks to Zbynek Konecny and Olivier Vernin and other contributors,
now it is possible to store plugin documentation right inside plugin repositories instead of Jenkins Wiki which was historically difficult to maintain for plugin maintainers and for the Jenkins infrastructure team.

This blogpost may be interesting to plugin maintainers and to those who want to contribute to the Jenkins documentation.
I will describe how to migrate plugin documentation to GitHub and to get pages like this one:

Why?

By using plugin GitHub repositories for documentation,
plugin maintainers can follow the Documentation-as-code approach and make documentation changes a part of the pull requests so that documentation follow-ups do not get forgotten.
It also gives an opportunity to review the documentation changes and to add documentation contributor recognition, especially if the story is combined with Release Drafter.

Unfortunately, before September 2019 usage of GitHub documentation was causing some issues.
First of all, many plugin maintainers have already moved their documentation to GitHub, and it caused fragmentation of the documentation (Wiki, GitHub, jenkins.io).
To address it, plugin maintainers still had to maintain stub Wiki pages with redirects,
and users had to spend some time to find out where the real documentation is located.
By supporting GitHub as a documentation source, we allow maintainers to phase out the plugin Wiki pages while improving the user experience.

And there are even more pressing reasons to do the migration now…​
If you are subscribed to the developer mailing list,
you may have also seen an announcement by R. Tyler Croy about Jenkins Wiki stability issues
and making it read-only as a temporary measure to stabilize the instance
( mailing list thread).
Although the functionality has been partially restored afterwards,
there is a consensus in the Infrastructure team that we should gradually move to alternate solutions.

Examples

Since the announcement in September, more than 50 plugins were moved from Wiki to GitHub.
Few examples:

Configuration as Code Plugin

Mailer Plugin

Gradle Plugin

Role Strategy Plugin

How to enable GitHub documentation for your plugin?

Convert documentation from Wiki to GitHub Asciidoc or Markdown format if you have not done it yet.

It can be easily done in a semi-automatic way using Jenkins Wiki Exporter

See the guidelines
here.

Change the field in pom.xml so that it points to GitHub
( guide).
 Examples of valid links:

https://github.com/jenkinsci/mailer-plugin - plugin site will use GitHub REST API to extract README

https://github.com/jenkinsci/ssh-credentials-plugin/blob/master/doc/README.md - extraction of a plugin page from a custom location

Optional: Add badges to the page to improve look&amp;feel and to provide quick links for users.
There are standard badges for changelogs, chats, plugin site, and installation numbers.

Example for Markdown

Example for Asciidoc

Release the new plugin version

Wait a few hours till the change propagates.
After that, the Jenkins Plugin Site will show the new documentation from GitHub.

What’s next?

The story is tracked as jira:WEBSITE-406[] which is a part of the wider subproject for using GitHub as a source of data for the Jenkins plugin site and update managers (jira:WEBSITE-637[]).
Later steps include support showing changelogs from GitHub releases, pulling plugin tags from GitHub, showing plugin logos, and using Repository Permission Updater as a source of the maintainer information.

How to contribute?

October is a great time to contribute!
Plugin documentation is one of the featured projects for Hacktoberfest,
and we will welcome all contributions to the documentation and to the codebase.

Contributing to Documentation

We are looking for contributors who are interested to improve plugin documentation and to help us with migration from Wiki to GitHub.
For dozens of plugins the documentation is already in GitHub,
and you are welcome to submit pull requests against any repository.

Migrating documentation:

Migrating plugin documentation from Wiki to GitHub

Moving documentation from Jenkins Wiki to jenkins.io

jira:JENKINS-59467[Template issue for plugin docs migration]

Newbie-friendly documentation tasks

If you have any questions about contributing to the documentation,
please see this page or reach out to us in the Docs SIG Gitter chat.

Code contributions

Would you like to write some code in Java or JavaScript?
Or would you like to work on CSS styles and improve Jenkins design?
In such case you are welcome to contribute to the Jenkins Plugin Site.
It is our own plugin marketplace implementation, and we invite contributions to this area.
The plugin site is really easy to develop.

jira:WEBSITE-637[] - EPIC for Plugin site and GitHub integrations

jenkins-infra/plugin-site - Frontend (JavaScript, React, XSS, YARN)

jenkins-infra/plugin-site-api - Plugin site API and Docker packaging (Java, Maven, Docker)

Useful links

Plugin Documentation

Jenkins Plugin Site

Jenkins Wiki Exporter tool<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/hacktoberfest">hacktoberfest</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/wiki">wiki</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/contributors">contributors</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/10/21/thinking-about-jenkins-security/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">21</div></div><h5 class="title">Thinking About Jenkins Security - DevOps World | Jenkins World 2019</h5></div><p class="teaser">This is a speaker blogpost for a DevOps World | Jenkins World 2019 talk in Lisbon, Portugal

Come join us at DevOps World | Jenkins World 2019 for &quot; Thinking about Jenkins Security &quot;, a talk about securing your Jenkins server.
We’ll review the layers that secure Jenkins and describe techniques that you can use to protect your Jenkins server.

Topics will include:

The secure by default configuration that Jenkins provides

Risks associated with reducing default security settings

Authentication and authorization alternatives

Using &quot; least privilege&quot; principles

Jenkins credentials and trusted access to resources

Software updates and Jenkins project security notices

We’ll intermix descriptions of good practices with some security horror stories.
The horror stories remind us of our mistakes; we will discuss how to detect them and how to prevent them.

Come join us for the presentation in Lisbon!

Slides<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/wadeck/">Wadeck Follonier</a>, <a href="/gatsby-jenkins-io/blog/authors/stackscribe/">Meg McRoberts</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins world">jenkins world</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2019">devopsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/10/24/jenkins-performance-avoiding-pitfalls/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">24</div></div><h5 class="title">Jenkins Performance: Avoiding Pitfalls, Diagnosing Issues, and Scaling for Growth - DevOps World | Jenkins World 2019</h5></div><p class="teaser">This is a speaker blogpost for a DevOps World | Jenkins World 2019 talk in Lisbon, Portugal

With Halloween upon us, there’s no better time to discuss Jenkinstein!
Are you suffering from Jenkins performance issues?
Are users complaining about a slow UI or even scarier, is Jenkins going down frequently?

Come join me at DevOps World | Jenkins World 2019 for &quot; Jenkins Performance: Avoiding Pitfalls, Diagnosing Issues, and Scaling for Growth &quot;, a talk about JVM administration and best practices from the front lines of supporting thousands of Jenkins installations worldwide.
During this talk we’ll cover how to prevent your Jenkins instance from becoming a Jenkinstein!

Topics we will be discussing:

JVM administration best practices

Horizontal scaling

Analyzing thread dumps, GC logs, and heap dumps

Real world data showing 3500% performance increases

Garbage collection

We’ll be discussing how you can forecast for growth, and baseline using key performance indicators like application throughput and latency, by analyzing spooky data like Garbage Collection logs!

Come join me for the presentation in Lisbon! There will be candy!

Slides<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ryansmith303/">Ryan Smith</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins world">jenkins world</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2019">devopsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/01/devops-world-jenkins-world-san-francisco-in-living-colors/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 1</div></div><h5 class="title">DevOps World | Jenkins World San Francisco in Living Colors</h5></div><p class="teaser">DevOps World | Jenkins World San Francisco was August 12 - 15, 2019.
The event was delivered in vivid colors starting with flowing banners hung from street lamp posts to the big screens in breakout rooms, to the expo hall.
The energy and enthusiasm in the Moscone convention center made the colors even more vibrant, thanks to the people attending the conference.

Here’s a recap of the conference in pictures:

DevOps World | Jenkins World 2019 - San Francisco

Keynote - Evolution of the Continuous Delivery Foundation

Tracy Miranda opened the keynote explaining the evolution of the Continuous Delivery Foundation.

Keynote - Evolution of the Continuous Delivery Foundation

Influencers, Creators, and Members

The influencers, creators, and members of the CD Foundation: Tracy Miranda (far left),
Andy Glover (Netflix), Tara Hernandez (Google), Chris Aniszczyk (Linux Foundation), Dave Stanke (Google), Kohsuke Kawaguchi (Jenkins creator), Jayne Groll (DevOps Institute), James Strachan (Jenkins X creator).
“We want to help set Jenkins up for success, into the next decade”, Tyler Croy (not in picture).

Influencers, Creators, and Members of the Continuous Delivery Foundation

Contributor Summit

The inaugural Continuous Delivery Foundation Contributor Summit and it was a full house!

Continous Delivery Foudnation Contributor Summit

15 Years of Jenkins

A remarkable milestone for the Jenkins project, a celebration of Jenkins turning 15…​cake included!

Fifteen Years of Jenkins

Bee Diverse Luncheon

Interactive and engaging luncheon celebrating diversity

Bee Diverse Luncheon Entrance

Bee Diverse Luncheon Leading Voices

Bee Diverse Luncheon Group Discussions

Jenkins Contributors and Experts

Jenkins contributors and experts on hand to educate and share lightning talks and provide one on one Jenkins support.

Jenkins Lightning Talks

Jenkins Experts Answering Questions

Jenkins Experts Discussing and Helping

Jenkins Experts Gathered

DevOps Superheroes

Even though the conference offered endless learning and networking possibilities, and major milestones worth celebrating,  I felt the true highlight of the conference was the celebration of each individual, “You”.
“You” are the super hero, the driving force behind the incredible innovations to advance technology to where it is today.
Here’s celebrating the super heros in all of YOU!

DevOps Superheroes

Superheroes and the Wookie

Four Superheroes

Kohsuke Kawaguchi - Founding Superhero

A DevOps League of Superheroes

Crowd of Superheroes

This party will be coming to Lisbon, Portugal on December 3-5, 2019.
We hope to see our EU Jenkins fans at DevOps World | Jenkins World Lisbon.
Use JWFOSS for a 30% discount off your pass.

Hope to see you in Lisbon!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2019">devopsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/04/speaker-blog-how-to-build-the-top-mobile-game/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 4</div></div><h5 class="title">How to build the top mobile game for every platform imaginable</h5></div><p class="teaser">Context

You have been tasked with managing the Jenkins instance for the highest grossing mobile
game in the world. You learn that this involves helping the game studio iterate their work
against eight different target platforms, each with their SDK, on four different main pipelines,
plus a lot of extra auxiliary jobs. And, of course, the studio wants all of this to go smoothly, in
order to maintain a good pace of features and bugfixes for every release - a release happening
every two weeks. Hitting hundreds of millions of players worldwide.

How are you going to make sure that the environment stays correctly configured, with the
right versions of the required software; helping the studio maintain stability and scalability of
their pipelines; ensuring operability of the Jenkins instance; improving the speed of the builds
month after month?

It’s OK to sweat. You are going to need some help!

This is just a regular day in the office for a build engineer working at King. Facing a very
broad problem, with high quality standards and even higher stakes. Thankfully, we are not
alone. We have access to a lot of tools - either open source tools, tools developed by the
studios or tools developed by our stellar build infrastructure team in Barcelona - to help carry
us all the way to the publish line. We put all of these tools together, and by their powers
combined, we provide fast, easily operable workflows for the studios, cutting minutes here
and there, ensuring the features a smooth sail from dev, to master, to release.

I will explain all of the tricks we use at King to speed builds up, and to make Jenkins operation
easier for our studios on December 4, 2019, at DevOps World | Jenkins
World Lisbon.
Use JWFOSS for 30% discount on registration!
For now, let’s take a look at some of them.

Where do we start?

We use on-premises elastic infrastructure, spawning machines from certain templates
whenever they are needed. This means that for every build, we are getting a fresh
environment - no intermediate artifacts leftover or anything of the sort, which is good. That
also means that we need to clone our repositories and compile everything every time, which is
bad. However, we have solutions for these two problems.

We make full use of linkclones/snapshots when spawning a VM. Every night we run a
bootstrapper that will power on the base image and perform whatever operations we decide on
it, before turning it back into a template and re-creating the snapshot. In the case of Candy
Crush, we update our caches, and this helps us cut some time off of git clone and compilation.
We call this bootstrapper “cacheo”. It looks more or less like this:

Cacheo

1. Start elastic agent template image
2. Connect it to Jenkins
3. Perform cleanup
4. Trigger git reference cache jobs
5. Trigger all the builds you want cached
6. Turn off template image, delete the agent and recreate the linked clone snapshot

Every studio can specify on which templates will cacheo run, and what will it do in each of them.
Maybe you want to make sure your Android license is on point. Or download some
packages from artifactory. Perhaps pre-load your gradle dependencies. Whatever it is, cacheo
does it for you and updates your base images every night.

One of the most common uses is to pre-fill a local git cache, and when doing so, the
improvement is very visible, especially on Windows:

Linux
MacOS
Windows

NFS
2 min 11s
2min 34s
8min 32s

Local
1 min 20s
1min 35s
3min 49s

Difference
39% faster
39% faster
55% faster

This means, speeding up source code fetching by 55% on Windows, on average. That is a LOT!!

But what about actual compilation?

All of our major games use the same engine; we bring this code in by means of submodules. This means
there is a big bunch of shared code that needs to be compiled and linked whenever we build the game.
And it’s not rare that this shared code is bigger than the actual game code!
Thankfully, the engine team lent us a hand, and they developed a way to package the compiled shared code.
Normally, the game code lives alongside a specific version of the shared code, which doesn’t get updated too frequently.
Sometimes once a month, sometimes to grab a hotfix. This translates to us potentially compiling the
exact same shared code for quite some time, every time we build the game. Thanks to these
prebuilt artifacts, we are able to skip a huge part of the compilation, at the cost of a simple artifactory download.

Cacheo

if generate_prebuilt_libs:
    compile_project()

    generate_empty_cmakelists()

    for dependency in dependencies:
        merge_compiled_dependency_into_metalib(dependency)
        write_dependency_to_generated_cmakelists_as_alias_for_metalib(dependency)

elif use_prebuilt_libs:
    add_generated_cmakelists_with_metalib_as_dependency()

    compile_project()

Thanks to these prebuilt libraries, we are able to skip a big chunk of the compilation,
and it builds up really quickly! Iterative work on several branches, as long as they have
the same engine version, gets sped up in noticeable ways.
There are, however, specific cases when we do choose to build the shared code regardless, such as
when we build release candidates for instance.

Just so you get an idea, times on this table are on average:

iOS
Windows

No prebuilts
20min 17s
40min 30s

Prebuilts
10min 2s
23min 20s

Difference
51% faster
43% faster

I just don’t want to have to deal with bureaucracy

Operating Jenkins can be quite complicated. Talk about “Tell me
something I don’t know”, right? And with so many moving pieces (elastic
infrastructure, plugins, dirty workspaces), it might not be easy for
everyone to run specific maintenance tasks. We have a lot of small
pipelines, created by the build infrastructure group, that we can use to
diagnose and work around certain errors, as well as gather useful
information that might be otherwise difficult to find. These pipelines
do things like printing all the installed plugins, deleting offline
on-demand agents, cleaning disconnected VMs from vSphere, or re-run
puppet in a specific Jenkins instance. And any user can run these jobs,
there is no need to be an admin. This allows the team to unblock
themselves if they need to by using these jobs. Here’s one that I
particularly like. How many times have you modified a pipeline and, when
trying to run it, the first thing that happens is that Jenkins says that
it needs approval?

Script Approval

import org.jenkinsci.plugins.scriptsecurity.scripts.*

@NonCPS

// Disclaimer - this can have serious security consequences
// Be mindful when you run this!

def call() {
    sa = ScriptApproval.get()
    toApproveScripts = sa.getPendingScripts().collect()
    println (&quot;toApproveScripts: &quot; + toApproveScripts)
    toApproveScripts.each {pending -&gt;
        sa.get().approveScript(pending.getHash())
	println (&quot;approvedScripts: &quot; + pending.getHash())
	}
    sa.save()
}

The best part? All our Jenkins instances include these jobs, by default, so
no one misses out on the fun.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/ignacio_fernandez/">Ignacio &#x27;Nacho&#x27; Fernández</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld2019">jenkinsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mobile-game">mobile-game</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/08/board-elections/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 8</div></div><h5 class="title">2019 Jenkins Board and Officer Elections Update</h5></div><p class="teaser">The Jenkins community is conducting the 2019 elections for Board and Officer positions.
The call for nominations has concluded.
We received many nominations.
Based on the people who are willing to accept their nomination and the uncontested officer positions, we will have 3 votes:

A vote to elect 3 board members

A vote to elect the Jenkins security officer

A vote to elect the Jenkins events officer

Candidates

Each candidate has provided a statement to help guide voters on why they should vote for the candidate.
Refer to the candidate statements for more details.
The candidates running for a board position are:

Alex Earl

Oliver Gondza

Ullrich Hafner

Oleg Nenashev

Mark Waite

Zhao Xiaojie (a.k.a. Rick to many of you)

The candidates running for Security Officer are:

Daniel Beck

Wadeck Follonier

The candidates running for Events Officer are:

Alyssa Tong

Zhao Xiaojie (a.k.a. Rick to many of you)

Voter Registration

This is the first time in a while that we are running a Jenkins election; we are learning as we go.
Jenkins elections aim to be very inclusive.
We do not restrict elections to just code committers.
Anyone who has a Jenkins account registered before September 1, 2019 is eligible to vote.
Jenkins, being the successful project it is, has  approximately 100 000 accounts that meet that criteria.
As a result we are contacting eligible voters and requesting that they explicitly ‘opt-in’ to participate in the voting.

If you meet the criteria, you will receive an email at your registered jenkins.io email address.
It will be from elections@jenkins.io with the title ‘ 2019 Jenkins Election - Invitation to Participate ’.
The email will provide election details and will include an &quot; I want to participate&quot; button.

Voter Confirmation

Once you click on the link, you should see a confirmation screen as follows:

If you do not receive the email by November 14, 2019 or if you have any problems voting, please comment on the Jenkins Election 2019 Jira issue.

Voting

The voting will officially open on November 11, 2019.
Candidates will receive an email from the Condorcet internet voting sent by Kohsuke Kawaguchi.
One email will be sent for each vote (so 3 in total: 1 for board, 1 for event officer and 1 for security officer).
The vote will ask to rank the candidates using a screen like this:

Election Dates

Here is a summary of the key election dates:

Date
Event

Now
Voter registration ongoing

Nov 11, 2019
Voting begins

Nov 17, 2019
Voter registration closes

Nov 24, 2019
Voting closes a 5:00 PM Pacific Time

Dec 3, 2019
New representatives announced

Election results will be posted to the Jenkins developer mailing list, followed by an announcement blog post on jenkins.io.

If there are any delays to the proposed dates we will aim to communicate that as soon as we can.
Thank you very much for all the candidates showing the Jenkins spirit of service to their community.
We encourage everyone to register to vote and participate in the Jenkins community.

Uncontested Officer Positions

When an officer position has only one candidate that is willing to accept the nomination, there is no reason to vote on that position.
The individual becomes an officer as the sole candidate for the position.

Uncontested officers include:

Name
Role

Olivier Vernin
Infrastructure Officer

Oliver Gondza
Release Officer

Mark Waite
Documentation Officer

References

Jenkins Governance Board

Jenkins Board Election Process

Jenkins Officers

Announcement in the developer mailing list

2019 elections proposal in the developer mailing list<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/22/jenkins-health-advisor-by-cloudbees/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">22</div></div><h5 class="title">Jenkins Health Advisor by CloudBees is here!</h5></div><p class="teaser">Managing any software presents its own unique challenges. Jenkins controllers are no exception. For example,

How do you keep a finger on the pulse of everything going on in your Jenkins environment? Are you looking at every new defect opened in the issue tracker?

How do you make sure that your controllers or agents don’t silently fail? Are you monitoring its logs? All of its internal components? If something does go wrong, how do you fix it??

How do you avoid the infamous “angry Jenkins” logo?

That’s why we created Jenkins Health Advisor by CloudBees.

Here at CloudBees, we have years of experience supporting our customers who are using Jenkins, including our proprietary products build on top of Jenkins like CloudBees Core.
As a result, our support team is made up of automation experts with Jenkins knowledge you can’t get anywhere else.

Automated health checks started when our support engineers created a platform so they could write rules to detect known issues on support bundles provided by our customers, and redirect them to the required knowledge source to diagnose and resolve the issue.

After years of internal usage we decided to share this service with the community and we are pleased to introduce a new free  (as in beer) service available to every Jenkins user : Jenkins Health Advisor by CloudBees .

Jenkins Health Advisor by CloudBees automatically analyzes your Jenkins environment, proactively identifies potential issues and advises you of solutions with detailed email reports.

Jenkins Health Advisor by CloudBees can detect a large range of issues from simple configuration issues to security and best practices concerns - all critical elements of Jenkins implementations.
Getting started is done in 3 steps, and within 24 hours you will receive your first report.

We hope that you will appreciate this service and it will help you to keep your controllers healthy.

Take a few minutes to read our documentation, discover the service and don’t hesitate to contact us on the Jenkins community channels ( Gitter, jenkinsci-users@googlegroups.com, …​).

Don’t miss also the opportunity to meet our support team on the &quot;Ask the experts&quot; booth at DevOps World | Jenkins World 2019.

Useful links:

Plugin Documentation

Jenkins Plugin Site

CloudBees Jenkins Support<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/aheritier/">Arnaud Héritier</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/health">health</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/healthcheck">healthcheck</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/stability">stability</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/22/welcome-to-the-matrix/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">22</div></div><h5 class="title">Welcome to the Matrix</h5></div><p class="teaser">I often find myself needing to run the same actions on a bunch of different configurations.
Up to now, that meant I had to make multiple copies of the same stages in my pipelines.
When I needed to make changes, I had to make the same changes in multiple places throughout my pipeline.
Maintaining even a small number of configuration was difficult for larger pipelines.

Declarative Pipeline 1.5.0-beta1 (now available from the
Jenkins Experimental Update site) adds a new matrix section that lets me specify a list stages once and then run that same list in parallel on multiple configurations.
Let’s take a look!

Single configuration pipeline

I’ll start with a simple pipeline with build and test stages.
I’m using echo steps as placeholders for my build and test actions.

Jenkinsfile

pipeline {
    agent none
    stages {
        stage(&#x27;BuildAndTest&#x27;) {
            agent any
            stages {
                stage(&#x27;Build&#x27;) {
                    steps {
                        echo &#x27;Do Build&#x27;
                    }
                }
                stage(&#x27;Test&#x27;) {
                    steps {
                        echo &#x27;Do Test&#x27;
                    }
                }
            }
        }
    }
}

Pipeline for multiple platforms and browsers

I’d like to run my build and tests on a combination of platforms and browsers.
The new matrix directive lets me specify a set of axes.
Each axis has a name and a list of one or more values.
When the pipeline is run, Jenkins will take those and run my stages on all possible combinations of values from each axis.
All cells in a matrix run in parallel (limited only by the number of available agents).
Stages within each cell are run sequentially.

My matrix has two axes: PLATFORM and BROWSER.
I have three values for PLATFORM and four values for BROWSER resulting in my stages being run with twelve different combinations.
I’ve changed my echo steps to use the axis values for each cell.

Jenkinsfile

pipeline {
    agent none
    stages {
        stage(&#x27;BuildAndTest&#x27;) {
            matrix {
                agent any
                axes {
                    axis {
                        name &#x27;PLATFORM&#x27;
                        values &#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;
                    }
                    axis {
                        name &#x27;BROWSER&#x27;
                        values &#x27;firefox&#x27;, &#x27;chrome&#x27;, &#x27;safari&#x27;, &#x27;edge&#x27;
                    }
                }
                stages {
                    stage(&#x27;Build&#x27;) {
                        steps {
                            echo &quot;Do Build for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                    stage(&#x27;Test&#x27;) {
                        steps {
                            echo &quot;Do Test for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                }
            }
        }
    }
}

Log output (truncated)

...
[Pipeline] stage
[Pipeline] { (BuildAndTest)
[Pipeline] parallel
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;edge&#x27;) (hide)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;edge&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;edge&#x27;)
...
Do Build for linux - safari
Do Build for linux - firefox
Do Build for windows - firefox
Do Test for linux - firefox
Do Build for mac - firefox
Do Build for linux - chrome
Do Test for windows - firefox
...

Excluding invalid combinations

Now that I have my basic matrix created, I’ve noticed that I have some invalid combinations.
Microsoft Edge only runs on Windows and there isn’t a Linux version of Safari.

I can remove invalid cells from my matrix using exclude directives. Each exclude has one or more axis directives with name and values.
The axis directives inside an exclude generate a set of combinations (similar to generating the matrix cells).
The matrix cells that match all the values from an exclude combination are removed from the matrix.
If I have more than one exclude directive, each are evaluated separately to remove cells.

When dealing with a long lists of values to exclude, I can use notValues instead of values to specify axis values we don’t want excluded.
Yes, that’s a double negative, so it can get a little confusing.
I try to use it only when I really need it.

In my sample pipeline below, I specifically exclude the linux, safari combination and I also exclude any platform that is not windows with the edge browser.

This pipeline uses two axes but there is no limit on the number of axis directives.

Also, in this pipeline each exclude specifies values for both axes, but that is not required.
If we wanted to run only &quot;linux&quot; cells, we could use the following exclude :

exclude {
    axis {
        name &#x27;PLATFORM&#x27;
        notValues &#x27;linux&#x27;
    }
}

pipeline {
    agent none
    stages {
        stage(&#x27;BuildAndTest&#x27;) {
            matrix {
                agent any
                axes {
                    axis {
                        name &#x27;PLATFORM&#x27;
                        values &#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;
                    }
                    axis {
                        name &#x27;BROWSER&#x27;
                        values &#x27;firefox&#x27;, &#x27;chrome&#x27;, &#x27;safari&#x27;, &#x27;edge&#x27;
                    }
                }
                excludes {
                    exclude {
                        axis {
                            name &#x27;PLATFORM&#x27;
                            values &#x27;linux&#x27;
                        }
                        axis {
                            name &#x27;BROWSER&#x27;
                            values &#x27;safari&#x27;
                        }
                    }
                    exclude {
                        axis {
                            name &#x27;PLATFORM&#x27;
                            notValues &#x27;windows&#x27;
                        }
                        axis {
                            name &#x27;BROWSER&#x27;
                            values &#x27;edge&#x27;
                        }
                    }
                }
                stages {
                    stage(&#x27;Build&#x27;) {
                        steps {
                            echo &quot;Do Build for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                    stage(&#x27;Test&#x27;) {
                        steps {
                            echo &quot;Do Test for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                }
            }
        }
    }
}

Log output (truncated)

...
[Pipeline] stage
[Pipeline] { (BuildAndTest)
[Pipeline] parallel
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;edge&#x27;)
...
Do Build for linux - firefox
...

Controlling cell behavior at runtime

Inside the matrix directive I can also add &quot;per-cell&quot; directives.
These are the same directives that I would add to a stage and they let me control the behavior of each cell in the matrix.
These directives can use the axis values from their cell as part of their inputs, allowing me to customize the behavior of each cell to match its axis values.

On my Jenkins server I have configured agents with labels that match the OS for each agent (&quot;linux-agent&quot;, &quot;windows-agent&quot;, and &quot;mac-agent&quot;).
To run each cell in my matrix on the appropriate operating system, I configure the label for that cell using Groovy string templating.

matrix {
    axes { ... }
    excludes { ... }
    agent {
        label &quot;${PLATFORM}-agent&quot;
    }
    stages { ... }
    // ...
}

Occasionally I run my pipeline manually from the Jenkins Web UI.
When I do that, I’d like to be able to select just one platform to run.
The axis and exclude directives define the static set of cells that make up the matrix.
That set of combinations is generated before the start of the run, before any parameters are processed.
What this means is that I can’t add or remove cells from a matrix after the job has started.

The &quot;per-cell&quot; directives, on the other hand, are evaluated at runtime.
I can use the &quot;per-cell&quot; when directive inside matrix to control which cells in the matrix are executed.
I’ll add a choice parameter with the list of platforms, and add conditions to the when directive, which will either let all platforms execute, or only execute cells that match my selected platform.

pipeline {
    parameters {
        choice(name: &#x27;PLATFORM_FILTER&#x27;, choices: [&#x27;all&#x27;, &#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;], description: &#x27;Run on specific platform&#x27;)
    }
    agent none
    stages {
        stage(&#x27;BuildAndTest&#x27;) {
            matrix {
                agent {
                    label &quot;${PLATFORM}-agent&quot;
                }
                when { anyOf {
                    expression { params.PLATFORM_FILTER == &#x27;all&#x27; }
                    expression { params.PLATFORM_FILTER == env.PLATFORM }
                } }
                axes {
                    axis {
                        name &#x27;PLATFORM&#x27;
                        values &#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;
                    }
                    axis {
                        name &#x27;BROWSER&#x27;
                        values &#x27;firefox&#x27;, &#x27;chrome&#x27;, &#x27;safari&#x27;, &#x27;edge&#x27;
                    }
                }
                excludes {
                    exclude {
                        axis {
                            name &#x27;PLATFORM&#x27;
                            values &#x27;linux&#x27;
                        }
                        axis {
                            name &#x27;BROWSER&#x27;
                            values &#x27;safari&#x27;
                        }
                    }
                    exclude {
                        axis {
                            name &#x27;PLATFORM&#x27;
                            notValues &#x27;windows&#x27;
                        }
                        axis {
                            name &#x27;BROWSER&#x27;
                            values &#x27;edge&#x27;
                        }
                    }
                }
                stages {
                    stage(&#x27;Build&#x27;) {
                        steps {
                            echo &quot;Do Build for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                    stage(&#x27;Test&#x27;) {
                        steps {
                            echo &quot;Do Test for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                }
            }
        }
    }
}

If I run this Pipeline from the Jenkins UI and set the PLATFORM_FILTER parameter to mac, I’ll get something like the output below:

Log output (truncated - PLATFORM_FILTER = &#x27;mac&#x27; )

...
[Pipeline] stage
[Pipeline] { (BuildAndTest)
[Pipeline] parallel
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;firefox&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;chrome&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;mac&#x27;, BROWSER = &#x27;safari&#x27;)
[Pipeline] { (Branch: Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;edge&#x27;)
...
Stage &quot;Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;chrome&#x27;&quot; skipped due to when conditional
Stage &quot;Matrix - OS = &#x27;linux&#x27;, BROWSER = &#x27;firefox&#x27;&quot; skipped due to when conditional
...
Do Build for mac - firefox
Do Build for mac - chrome
Do Build for mac - safari
...
Stage &quot;Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;chrome&#x27;&quot; skipped due to when conditional
Stage &quot;Matrix - OS = &#x27;windows&#x27;, BROWSER = &#x27;edge&#x27;&quot; skipped due to when conditional
...
Do Test for mac - safari
Do Test for mac - firefox
Do Test for mac - chrome

Come join me at DevOps World | Jenkins World 2019 for &quot; Declarative Pipeline 2019: Tips, Tricks and What’s Next &quot;.
I’ll go over what’s been added to Pipeline in the last year (including matrix) and discuss ideas about where pipeline should go next.

Conclusion

In this blog post, we’ve looked at how to use the matrix directive to make concise but powerful declarative pipelines.
An equivalent pipeline created without matrix would easily be several times larger, and much harder to understand and maintain.

Matrix is now available from the experimental update center.
It will be released to the main update center as soon as we’re done putting the finishing touches on the documentation and online help.

Links

Jenkins Experimental Update Center

Using the Jenkins Experimental Update Center<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/declarative">declarative</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/matrix">matrix</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/25/macos-native-installer-deprecation/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">25</div></div><h5 class="title">Jenkins macOS native installer deprecation</h5></div><p class="teaser">In addition to WAR files and Docker images, the Jenkins project provides native installers for each weekly and LTS release.
There are installers available for Linux distributions, Windows, macOS and other operating systems.
There are also installers provided by third parties.
You can find the list of these installers on the Downloads page.

In this blog post, we announce the upcoming deprecation of the macOS native installer.
We will review the replacement options and the rollout plan.

Why?

Maintaining installers is a significant maintenance effort for the project
because installers require testing and, sometimes, specific platforms and environments for packaging.
When installers lose relevance for the majority of the Jenkins audience, we remove them or handover maintenance to third parties on other areas.
For macOS, there are currently two types of packages: native installers with GUI for desktop versions and Homebrew packages.
Since Homebrew is now a defacto standard package manager for macOS users, from the Jenkins standpoint it made sense to deprecate the native installers.

Why now?
There is ongoing work on automating Jenkins Core releases within the Jenkins infrastructure.
Long story short, we are moving Jenkins release pipelines to Kubernetes on Microsoft Azure.
This environment does not offer macOS machines that are needed to produce native installers.
If you are interested to know more, there will be a How Jenkins Builds and Delivers Jenkins in the Cloud talk presented by Olivier Vernin at DevOps World | Jenkins World 2019 Europe in Lisbon (use the JWFOSS code for a 30% discount!).

We could have used an external service for building macOS installers,
but it would have added an additional point of failure and implementation/maintenance overhead.
So we discussed it in the developer mailing list and agreed that it is better to just deprecate and then remove the packages.

Replacing native installers

In the case of macOS, there are two main alternatives available: managing the service manually or migrating to Homebrew packages.
Before doing a migration, we highly recommend backing up your instance.

Managing Jenkins with WAR file on macOS

If your Jenkins instance was previously set up with a native installer,
to update Jenkins it will be enough to replace the jenkins.war file in the installation directory and restart the instance.
The services will keep running as it was configured before the migration.
The default installation directory is /Applications/Jenkins/jenkins.war

Managing Jenkins with Homebrew

Installing Jenkins with Homebrew is a way to go for those who want to install Jenkins using a package manager.
There are two Homebrew formulas for Jenkins: jenkins for Weekly releases and jenkins-lts for LTS ones.
These packages are supported by a third party (Homebrew community),
and they may be not as frequently updated as packages supported by the Jenkins project directly.

Before doing a migration from macOS Native installers to HomeBrew, please make sure to backup your Jenkins instance.
There are no automatic migration tools available, and the installation may corrupt your JENKINS_HOME or service configuration files in edge cases.

If you switch to Homebrew, you will need to properly migrate the JENKINS_HOME data to the new location.
We do not provide an official migration guide, but it is possible to find some guidelines on the Web.

Sample commands:

Install the latest Weekly version: brew install jenkins

Install a specific Weekly version: brew install jenkins@YOUR_VERSION

Start the Jenkins service: brew services start jenkins

Restart the Jenkins service: brew services restart jenkins

Update the Jenkins version: brew upgrade jenkins

For more information see the documentation for Homebrew packages on the macOS Download pages.

Rollout plan

macOS native packaging is considered as deprecated starting from Jenkins 2.206 and Jenkins LTS 2.204.1

For Jenkins Weekly macOS native packaging will be removed with the switch to the new Jenkins release flow.
The exact date is to be determined.

After the change, there will be no macOS native installers produced for new Jenkins Weekly releases

Releases for previous versions will be available in this archive

For Jenkins LTS macOS will be removed with the switch to the new Jenkins release flow in the LTS baseline.
This change will happen only after the deployment of the new release flow in Jenkins Weekly.

After the switch, there will be no macOS native installers produced for new Jenkins LTS releases

Releases for previous versions will be available in this archive

See the discussion on the developer mailing list for more information.

Questions and feedback

If you have any questions or want to provide feedback, please use the developer mailing list thread mentioned above Platform SIG channels (chat, google group).
Any feedback will be much appreciated because we plan more installer/ and platform deprecations in the future.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/deprecation">deprecation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/macos">macos</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platforms">platforms</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/11/29/do-plugins-store-credentials-in-a-secure-way/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">29</div></div><h5 class="title">Do Plugins Store Credentials In A Secure Way? - DevOps World | Jenkins World 2019</h5></div><p class="teaser">This is a speaker blog post for a DevOps World | Jenkins World 2019 talk in Lisbon, Portugal and has been posted in line with NCC Group responsible disclosure policy.
Related Jenkins security advisories:
2017-11-08,
2017-11-16,
2018-06-25,
2018-07-30,
2018-09-25,
2019-02-19,
2019-03-06,
2019-03-25,
2019-04-03,
2019-04-17,
2019-08-07,
2019-09-12,
2019-10-01,
2019-10-16,
2019-10-23.
Some of the vulnerabilities have been announced without a fix, see Jenkins Security Spring Cleaning 2019.
The most of the announced vulnerabilities are fixed at the moment of this blogpost publishing.

Come join us at DevOps World | Jenkins World 2019 for &quot; The Story, the Findings and the Fixes Behind More than 100 Jenkins Plugins Vulnerabilities &quot;, a talk about the most common vulnerabilities found during research in more than 100 plugins.
We’ll review how to prevent these vulnerabilities during plugin development so that a more secure Jenkins CI and CD environment can be built.

When I first began familiarising myself with Jenkins, I found myself almost overwhelmed by the amount of plugins to choose from. Most of these plugins are developed by third party developers or companies and can assist the user in a range of ways. They can extend the core functions, they can offer solutions to repetitive tasks or they can help with using a service. For example, they could help with publishing to an artifact store or spinning up cloud instances. However, before a plugin can use a network based service that requires credentials to connect, those credentials have to be typed in and saved somewhere. This raises the question, are those credentials stored securely? Or not?
When I started looking at different plugins this was one of the first areas I investigated. I found a Jenkins security advisory describing this issue and came to the conclusion that this could be a problem in some plugins, albeit one that could be fixed easily. I found an example of weakly stored credentials in the Publish Over Dropbox Plugin; this plugin used a simple web form with a textbox element to display the token in the plugin’s settings page. This token was stored in plaintext:

The following Jelly code was behind the web form and shows that a password field wasn’t used:

The related plugin .xml file contained the secret key in plaintext:

GLOBAL
woodspeed

lYD2VnNz
lYD2VnNz

Jenkins offers at least two ways to store credentials in an encrypted format:

Using a Secret type offered by Jenkins

Third party plugin called Credentials Plugin

The first case is the easiest solution, because Jenkins will automatically handle the encryption and decryption.

Developers should also use the password field tag instead of the textbox field, as shown in the following Jelly control example:

If you would like to know what other vulnerabilities I discovered and how to fix them, come and join us for the presentation in Lisbon!
In case you are unable to attend the conference, you can read more at Story of a Hundred Vulnerable Jenkins Plugins.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/woodspeed/">Viktor Gazdag</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins world">jenkins world</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2019">devopsworld2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/12/02/matrix-building-with-scripted-pipeline/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 2</div></div><h5 class="title">Matrix building in scripted pipeline</h5></div><p class="teaser">Table of Contents

Matrix building with scripted pipeline
Screenshot of matrix pipeline
Adding static choices
Adding dynamic choices
Full pipeline example with dynamic choices
Background: How does it work?
Exposing a shared library pipeline step
Summary

With the recent announcement about matrix building you can perform
Matrix builds
with declarative pipeline.  However, if you must use scripted pipeline, then
I’m going to cover how to matrix build platforms and tools using scripted
pipeline.  The examples in this post are modeled after the declarative pipeline
matrix examples.

Matrix building with scripted pipeline

The following Jenkins scripted pipeline will build combinations across two
matrix axes.  However, adding more axes to the matrix is just as easy as adding
another entry to the Map matrix_axes.

Jenkinsfile

// you can add more axes and this will still work
Map matrix_axes = [
    PLATFORM: [&#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;],
    BROWSER: [&#x27;firefox&#x27;, &#x27;chrome&#x27;, &#x27;safari&#x27;, &#x27;edge&#x27;]
]

@NonCPS
List getMatrixAxes(Map matrix_axes) {
    List axes = []
    matrix_axes.each { axis, values -&gt;
        List axisList = []
        values.each { value -&gt;
            axisList &lt;&lt; [(axis): value]
        }
        axes !(axis[&#x27;BROWSER&#x27;] == &#x27;safari&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] == &#x27;linux&#x27;) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;edge&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] != &#x27;windows&#x27;)
}

// parallel task map
Map tasks = [failFast: false]

for(int i = 0; i&quot;${k}=${v}&quot;
    }
    // let&#x27;s say you have diverse agents among Windows, Mac and Linux all of
    // which have proper labels for their platform and what browsers are
    // available on those agents.
    String nodeLabel = &quot;os:${axis[&#x27;PLATFORM&#x27;]} &amp;&amp; browser:${axis[&#x27;BROWSER&#x27;]}&quot;
    tasks[axisEnv.join(&#x27;, &#x27;)] = { -&gt;
        node(nodeLabel) {
            withEnv(axisEnv) {
                stage(&quot;Build&quot;) {
                    echo nodeLabel
                    sh &#x27;echo Do Build for ${PLATFORM} - ${BROWSER}&#x27;
                }
                stage(&quot;Test&quot;) {
                    echo nodeLabel
                    sh &#x27;echo Do Build for ${PLATFORM} - ${BROWSER}&#x27;
                }
            }
        }
    }
}

stage(&quot;Matrix builds&quot;) {
    parallel(tasks)
}

Matrix axes contain the following combinations:

[PLATFORM=linux, BROWSER=firefox]
[PLATFORM=windows, BROWSER=firefox]
[PLATFORM=mac, BROWSER=firefox]
[PLATFORM=linux, BROWSER=chrome]
[PLATFORM=windows, BROWSER=chrome]
[PLATFORM=mac, BROWSER=chrome]
[PLATFORM=windows, BROWSER=safari]
[PLATFORM=mac, BROWSER=safari]
[PLATFORM=windows, BROWSER=edge]

It is worth noting that Jenkins agent labels can contain a colon ( :).  So
os:linux and browser:firefox are both valid agent labels.  The node
expression os:linux &amp;&amp; browser:firefox will search for Jenkins agents which
have both labels.

Screenshot of matrix pipeline

The following is a screenshot of the pipeline code above running in a sandbox
Jenkins environment.

Adding static choices

It is useful for users to be able to customize building matrices when a build
is triggered.  Adding static choices requires only a few changes to the above
script.  Static choices as in we hard code the question and matrix filters.

Jenkinsfile

(response[&#x27;PLATFORM&#x27;] == &#x27;all&#x27; || response[&#x27;PLATFORM&#x27;] == axis[&#x27;PLATFORM&#x27;]) &amp;&amp;
    (response[&#x27;BROWSER&#x27;] == &#x27;all&#x27; || response[&#x27;BROWSER&#x27;] == axis[&#x27;BROWSER&#x27;]) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;safari&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] == &#x27;linux&#x27;) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;edge&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] != &#x27;windows&#x27;)
}

The pipeline code then renders the following choice dialog.

When a user chooses the customized options, the pipeline reacts to the
requested options.

Adding dynamic choices

Dynamic choices means the choice dialog for users to customize the build is
generated from the Map matrix_axes rather than being something a pipeline
developer hard codes.

For user experience (UX), you’ll want your choices to automatically reflect the
matrix axis options you have available.  For example, let’s say you want to add
a new dimension for Java to the matrix.

// you can add more axes and this will still work
Map matrix_axes = [
    PLATFORM: [&#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;],
    JAVA: [&#x27;openjdk8&#x27;, &#x27;openjdk10&#x27;, &#x27;openjdk11&#x27;],
    BROWSER: [&#x27;firefox&#x27;, &#x27;chrome&#x27;, &#x27;safari&#x27;, &#x27;edge&#x27;]
]

To support dynamic choices, your choice and matrix axis filter needs to be
updated to the following.

choice(
                choices: [&#x27;all&#x27;] + options.sort(),
                description: &quot;Choose a single ${key.toLowerCase()} or all to run tests.&quot;,
                name: key)
        })
}

// filter the matrix axes since
// Safari is not available on Linux and
// Edge is only available on Windows
List axes = getMatrixAxes(matrix_axes).findAll { axis -&gt;
    response.every { key, choice -&gt;
        choice == &#x27;all&#x27; || choice == axis[key]
    } &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;safari&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] == &#x27;linux&#x27;) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;edge&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] != &#x27;windows&#x27;)
}

It will dynamically generate choices based on available matrix axes and will
automatically filter if users customize it.  Here’s an example dialog and
rendered choice when the pipeline executes.

Full pipeline example with dynamic choices

The following script is the full pipeline example which contains dynamic
choices.

// you can add more axes and this will still work
Map matrix_axes = [
    PLATFORM: [&#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;],
    JAVA: [&#x27;openjdk8&#x27;, &#x27;openjdk10&#x27;, &#x27;openjdk11&#x27;],
    BROWSER: [&#x27;firefox&#x27;, &#x27;chrome&#x27;, &#x27;safari&#x27;, &#x27;edge&#x27;]
]

@NonCPS
List getMatrixAxes(Map matrix_axes) {
    List axes = []
    matrix_axes.each { axis, values -&gt;
        List axisList = []
        values.each { value -&gt;
            axisList &lt;&lt; [(axis): value]
        }
        axes 
choice(
                choices: [&#x27;all&#x27;] + options.sort(),
                description: &quot;Choose a single ${key.toLowerCase()} or all to run tests.&quot;,
                name: key)
        })
}

// filter the matrix axes since
// Safari is not available on Linux and
// Edge is only available on Windows
List axes = getMatrixAxes(matrix_axes).findAll { axis -&gt;
    response.every { key, choice -&gt;
        choice == &#x27;all&#x27; || choice == axis[key]
    } &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;safari&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] == &#x27;linux&#x27;) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;edge&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] != &#x27;windows&#x27;)
}

// parallel task map
Map tasks = [failFast: false]

for(int i = 0; i&quot;${k}=${v}&quot;
    }
    // let&#x27;s say you have diverse agents among Windows, Mac and Linux all of
    // which have proper labels for their platform and what browsers are
    // available on those agents.
    String nodeLabel = &quot;os:${axis[&#x27;PLATFORM&#x27;]} &amp;&amp; browser:${axis[&#x27;BROWSER&#x27;]}&quot;
    tasks[axisEnv.join(&#x27;, &#x27;)] = { -&gt;
        node(nodeLabel) {
            withEnv(axisEnv) {
                stage(&quot;Build&quot;) {
                    echo nodeLabel
                    sh &#x27;echo Do Build for ${PLATFORM} - ${BROWSER}&#x27;
                }
                stage(&quot;Test&quot;) {
                    echo nodeLabel
                    sh &#x27;echo Do Build for ${PLATFORM} - ${BROWSER}&#x27;
                }
            }
        }
    }
}

stage(&quot;Matrix builds&quot;) {
    parallel(tasks)
}

Background: How does it work?

The trick is in axes.combinations()*.sum().  Groovy combinations are a quick
and easy way to perform a
cartesian product.

Here’s a simpler example of how cartesian product works.  Take two simple lists
and create combinations.

List a = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]
List b = [1, 2, 3]

[a, b].combinations()

The result of [a, b].combinations() is the following.

[
    [&#x27;a&#x27;, 1],
    [&#x27;b&#x27;, 1],
    [&#x27;c&#x27;, 1],
    [&#x27;a&#x27;, 2],
    [&#x27;b&#x27;, 2],
    [&#x27;c&#x27;, 2],
    [&#x27;a&#x27;, 3],
    [&#x27;b&#x27;, 3],
    [&#x27;c&#x27;, 3]
]

Instead of a, b, c and 1, 2, 3 let’s do the same example again but instead using matrix maps.

List java = [[java: 8], [java: 10]]
List os = [[os: &#x27;linux&#x27;], [os: &#x27;freebsd&#x27;]]

[java, os].combinations()

The result of [java, os].combinations() is the following.

[
    [ [java:8],  [os:linux]   ],
    [ [java:10], [os:linux]   ],
    [ [java:8],  [os:freebsd] ],
    [ [java:10], [os:freebsd] ]
]

In order for us to easily use this as a single map we must add the maps
together to create a single map.  For example, adding
[java: 8] + [os: &#x27;linux&#x27;] will render a single hashmap
[java: 8, os: &#x27;linux&#x27;].  This means we need our list of lists of maps to
become a simple list of maps so that we can use them effectively in pipelines.

To accomplish this we make use of the
Groovy spread
operator ( *. in axes.combinations()*.sum()).

Let’s see the same java / os example again but with the spread operator being
used.

List java = [[java: 8], [java: 10]]
List os = [[os: &#x27;linux&#x27;], [os: &#x27;freebsd&#x27;]]

[java, os].combinations()*.sum()

The result is the following.

[
    [ java: 8,  os: &#x27;linux&#x27;],
    [ java: 10, os: &#x27;linux&#x27;],
    [ java: 8,  os: &#x27;freebsd&#x27;],
    [ java: 10, os: &#x27;freebsd&#x27;]
]

With the spread operator the end result of a list of maps which we can
effectively use as matrix axes.  It also allows us to do neat matrix filtering
with the findAll {} Groovy List method.

Exposing a shared library pipeline step

The best user experience is to expose the above code as a shared library
pipeline step.  As an example, I have added
vars/getMatrixAxes.groovy
to Jervis.  This provides a flexible shared library step which you can copy
into your own shared pipeline libraries.

The step becomes easy to use in the following way with a simple one dimension matrix.

Jenkinsfile

Map matrix_axes = [
    PLATFORM: [&#x27;linux&#x27;, &#x27;windows&#x27;, &#x27;mac&#x27;],
]

List axes = getMatrixAxes(matrix_axes)

// alternately with a user prompt
//List axes = getMatrixAxes(matrix_axes, user_prompt: true)

Here’s a more complex example using a two dimensional matrix with filtering.

Jenkinsfile

!(axis[&#x27;BROWSER&#x27;] == &#x27;safari&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] == &#x27;linux&#x27;) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;edge&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] != &#x27;windows&#x27;)
}

And again with a three dimensional matrix with filtering and prompting for user
input.

Jenkinsfile

!(axis[&#x27;BROWSER&#x27;] == &#x27;safari&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] == &#x27;linux&#x27;) &amp;&amp;
    !(axis[&#x27;BROWSER&#x27;] == &#x27;edge&#x27; &amp;&amp; axis[&#x27;PLATFORM&#x27;] != &#x27;windows&#x27;)
}

The script approval is not necessary for
Shared Libraries.

If you don’t want to provide a shared step.  In order to expose matrix building
to end-users, you must allow the following method approval in the script
approval configuration.

Script approval

staticMethod org.codehaus.groovy.runtime.DefaultGroovyMethods combinations java.util.Collection

Summary

We covered how to perform matrix builds using scripted pipeline as well as how
to prompt users for customizing the matrix build.  Additionally, an example was
provided where we exposed getting buildable matrix axes to users as an easy to
use Shared Library
step via vars/getMatrixAxes.groovy.  Using a shared library step is
definitely the recommended way for admins to support users rather than trying
to whitelist groovy methods.

Jervis shared pipeline library has supported matrix building since 2017 in Jenkins scripted pipelines.
( see here and
here
for an example).<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sgleske/">Sam Gleske</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/matrix">matrix</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scripted">scripted</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/12/10/introducing-aws-secrets-manager-credentials-provider-plugin/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">10</div></div><h5 class="title">Introducing the AWS Secrets Manager Credentials Provider for Jenkins</h5></div><p class="teaser">API keys and secrets are difficult to handle safely, and probably something you avoid thinking about. In this post I’ll show how the new AWS Secrets Manager Credentials Provider plugin allows you to marshal your secrets into one place, and use them securely from Jenkins.

When CI/CD pipelines moved to the public cloud, credential management did not evolve with them. If you’re in this situation, you may have seen a number of tactical workarounds to keep Jenkins builds talking to the services they depend on. The workarounds range from bad (hardcoding plaintext secrets into Git) to merely painful (wrangling Hiera EYAML), but their common feature is that they tend to make copies of secrets beyond the reach of automation. This increases their attack surface, makes routine key rotation impractical, and makes remediation difficult after a breach.

The good news is that there is a better way!

AWS Secrets Manager is a comprehensive solution for secure secret storage. You define a secret just once for your whole AWS account, then you give your consumers permission to use the secrets. Secrets Manager lets you manage a secret entry (name and metadata) separately from its value, and it integrates with other AWS services that you already use:

Secret entry management: Manual (Web console, AWS CLI) or with an infrastructure management tool ( Terraform, CloudFormation etc.)

Secret value management: Manual (Web console, AWS CLI) or automatic (secret rotation Lambda function).

Access control: AWS IAM policies (for both applications and human operators).

Secret encryption: Amazon KMS automatically encrypts the secret value. Use either the account’s default KMS key, or a customer-managed KMS key.

Auditing: AWS CloudTrail and CloudWatch Events.

A couple of teams in my company started to use Secrets Manager from Jenkins jobs by calling the AWS CLI, but this remained a niche approach as it was quite unwieldy. There was clearly an appetite to integrate key developer apps with a centralised secrets store, but production-ready integrations were needed for wider adoption. So this year I created the AWS Secrets Manager Credentials Provider plugin for Jenkins, with help from friends in the Jenkins community, to do exactly that.

This is how you set it up…​

Install the plugin from the Jenkins update center.

Give Jenkins read-only access to Secrets Manager with an IAM policy.

(Optional) Configure the plugin, either through the Global Configuration screen or Jenkins Configuration As Code.

This is how you use it…​

Create your build secrets in AWS Secrets Manager. (You can start by uploading secrets via the AWS CLI. More sophisticated methods of secret creation are also available.)

View the credentials in the Jenkins UI, to check that Jenkins can see them.

Bind the credentials by ID in your Jenkins job.

The provider supports the following standard Jenkins credential types:

Secret Text

Username With Password

SSH User Private Key

PKCS#12 Certificate

And it has powerful advantages over quick-fix tactical solutions:

Your Jenkins jobs consume the credentials with no knowledge of Secrets Manager, so they stay vendor-independent.

The provider caches relevant Secrets Manager API calls, for a quicker and more reliable experience.

The provider integrates with the ecosystem of existing Jenkins credential consumers, such as the Git and SSH Agent plugins.

The provider records credential usage in the central Jenkins credentials tracking log.

Jenkins can use multiple credentials providers concurrently, so you can incrementally migrate credentials to Secrets Manager while consuming other credentials from your existing providers.

After the plugin’s first public release, developers at other companies adopted it too. It has had contributions so far from people at Elsevier, GoDaddy, and Northeastern University, as well as the fantastic Jenkins core team. We even got fan mail for our work!

In enterprise security, &quot;The important things are always simple. The simple things are always hard. The easy way is always mined.&quot; ( @thegrugq) It’s easy to buy a shiny ‘next generation&#x27; security appliance and drop it into your network. But it’s hard to embed the security fundamentals (like secrets management, OS patching, secure development) across your organisation. This Jenkins plugin is part of the effort [ 1 ] to take one of the persistent hard problems in security, and make it easier for everyone.

1. If you’re on Azure or you run most of your workload on Kubernetes, check out the Azure Credentials Plugin and the Kubernetes Credentials Provider Plugin.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/chriskilding/">Chris Kilding</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/aws">aws</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/credentials">credentials</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/12/14/generic-webhook-trigger-plugin/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">14</div></div><h5 class="title">Generic Webhook Trigger Plugin</h5></div><p class="teaser">Table of Contents

The Problem

Code Duplication And Security
A Branch Is Not A Feature
Documentation

The Solution

Code Duplication And Security
A Branch Is Not A Feature
Documentation

This post will describe some common problems I’ve had with Jenkins and how I solved them by developing Generic Webhook Trigger Plugin.

The Problem

I was often struggling with the same issues when working with Jenkins:

Code duplication and security - Jenkinsfiles in every repository.

A branch is not a feature - Parameterized jobs on master branch often mix parameters relevant for different features.

Poorly documented trigger plugins - Proper documented services but poorly documented consuming plugins.

Code Duplication And Security

Having Jenkinsfiles in every Git repository allows developers to let those files diverge. Developers pushes forward with their projects and it is hard to maintain patterns to share code.

I have, almost, solved code duplication with shared libraries but it does not allow me to setup a strict pattern that must be followed. Any developer can still decide to not invoke the features provided by the shared library.

There is also the security aspect of letting developers run any code from the Jenkinsfiles. Developers might, for example, print passwords gathered from credentials. Letting developers execute any code on the Jenkins nodes just does not seem right to me.

A Branch Is Not A Feature

In Bitbucket there are projects and each project has a collection of git repositories. Something like this:

PROJ_1

REPO_1

REPO_2

PROJ_2

REPO_3

Lets think about some features we want to provide for these repositories:

Pull request verification

Building snapshot (or pre release if you will)

Building releases

If the developers are use to the repositories being organized like this in Bitbucket, should we not organize them the same way in Jenkins? And if they browse Jenkins should they not find one job per feature, like pull-request, snapshot and release? Each job with parameters only relevant for that feature. I think so! Like this:

/ - Jenkins root

/PROJ_1 - A folder, lists git repositories

/PROJ_1/REPO_1 - A folder, lists jobs relevant for that repo.

/PROJ_1/REPO_1/release - A job, performs releases.

/PROJ_1/REPO_1/snapshot - A job, performs snapshot releases.

/PROJ_1/REPO_1/pull-request - A job, verifies pull requests.

…​

In this example, both snapshot and release jobs might work with the same git branch. The difference is the feature they provide. Their parameters can be well documented as you don’t have to mix parameters relevant for releases and those relevant for snapshots. This cannot be done with Multibranch Pipeline Plugin where you specify parameters as properties per branch.

Documentation

Webhooks are often well documented in the services providing them. See:

Bitbucket Cloud

Bitbucket Server

GitHub

GitLab

Gogs and Gitea

Assembla

Jira

It bothered me that, even if I understood these webhooks, I was unable to use them. Because I needed to perform development in the plugin I was using in order to provide whatever value from the webhook to the build. That process could take months from PR to actual release. Such a simple thing should really not be an issue.

The Solution

My solution is pretty much back to basics : We have an automation server (Jenkins) and we want to trigger it on external webhooks. We want to gather information from that webhook and provide it to our build. In order to support it I have created the Generic Webhook Trigger Plugin.

The latest docs are available in the repo and I also have a fully working example with GitLab implemented using configuration-as-code. See the repository here.

Code Duplication And Security

I establish a convention that all developers must follow. Instead of letting the developers explicitly invoke the infrastructure from Jenkinsfiles. There are rules to follow, like:

All git repositories should be built from the root of the repo.

If it contains a gradlew

Build is done with./gradlew build

Release is done with./gradlew release

…​ and so on

If it contains a package.json

Build is done with npm run build

Release is done with npm run release

…​ and so on

With these rules, pipelines can be totally generic and no Jenkinsfiles are needed in the repositories. Some git repositories may, for some reason, need to disable test cases. That can be solved by allowing repositories to add a special file, perhaps jenkins-settings.json, let the infrastructure discover and act on its content.

This also helps the developers even when not doing CI. When they clone a new, to them unknown, repository they will know what commands can be issued and their semantics.

A Branch Is Not A Feature

I implement:

Jenkins job configurations - With Job DSL.

Jenkins build process - With Pipelines and Shared Library.

By integrating with the git service from Job DSL I can automatically find the git repositories. I create jobs dynamically organized in folders. Also invoking the git service to setup webhooks triggering those jobs. The jobs are ordinary pipelines, not multibranch, and they don’t use Jenkinsfile from Git but instead Jenksinfile configured in the job using Job DSL. So that all job configurations and pipelines are under version control. This is all happening here.

Documentation

The plugin uses JSONPath, and also XPath, to extract values from JSON and provide them to the build. Letting the user pick whatever is needed from the webhook. It also has a regular expression filter to allow not triggering for some conditions.

The plugin is not very big, just being the glue between the webhook, JSONPath / XPath and regular expression. All these parts are very well documented already and I do my best supporting the plugin. That way this is a very well documented solution to use!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tomasbjerre/">Tomas Bjerre</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/webhooks">webhooks</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/trigger">trigger</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/12/16/board-election-results/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">16</div></div><h5 class="title">2019 Jenkins Board and Officer Elections Results</h5></div><p class="teaser">The Jenkins community has recently completed the 2019 elections for Board and Officer positions.
The call for nominations concluded on Nov 25 and the election results were announced in the developer mailing list on Nov 28.

On behalf of the Jenkins community, we congratulate all elected board members and officers!
We also thank all contributors who participated this year: all nominees and hundreds of voters.
These are the first elections ever conducted by the Jenkins project, and it is a big milestone for the community.

Election results:

Ullrich Hafner, Alex Earl and Oleg Nenashev will join Kohsuke Kawaguchi and R. Tyler Croy on the Jenkins Governance Board

Daniel Beck was elected as Security Officer

Alyssa Tong was elected as Events Officer

Nominations for Infrastructure, Release and Documentation officer positions were uncontested.

Olivier Vernin was elected as Infrastructure Officer (uncontested)

Oliver Gondža was elected as Release Officer (uncontested)

Mark Waite was elected as Documentation Officer (uncontested)

If you are interested to learn more, please see the blog post below.

Board election details

The voting results are:

Oleg Nenashev (Condorcet winner: wins contests with all other choices)

Mark Waite loses to Oleg Nenashev by 181–127

Ullrich Hafner loses to Oleg Nenashev by 198–115, loses to Mark Waite by 171–133

Alex Earl loses to Oleg Nenashev by 225–82, loses to Ullrich Hafner by 168–128

Oliver Gondža loses to Oleg Nenashev by 227–76, loses to Alex Earl by 151–136

Zhao Xiaojie (aka Rick) loses to Oleg Nenashev by 233–82, loses to Oliver Gondža by 160–131

Although Mark Waite came second in the voting results, being on the board would violate the Corporate Involvement clause which states that &quot;the number of board members affiliated with one company must be less than 50%&quot;.
Based on that rule, the third seat Alex Earl will join the Jenkins board.
At the same time, Mark Waite will take the newly introduced role of Documentation officer.

All new board members are elected for a 2-year term, unless they step down earlier.
The estimated end of term for them is December 02, 2021.
The actual date will depend on the election schedule in 2021.

Officer election details

We have reelected all 5 officers for the new 1-year term, with the estimated end of term on Dec 02, 2020.

Alyssa Tong won the biggest support as an Events officer ( voting results)

Daniel Beck won the biggest support as a Security officer ( voting results)

When an officer position has only one candidate that is willing to accept the nomination, there is no reason to vote on that position.
This year some nominees declined the nominations before the election happened, and 3 officer nominations were finally uncontested:
Olivier Vernin - infrastructure officer,
Oliver Gondža - release officer,
Mark Waite - documentation officer.

Statistics

Here are some voting stats from these elections:

Total number of eligible accounts: 91,015

Total number of registered voters: 831

Total number of votes: 343

This election was hosted on the Condorcet Internet Voting Service (CIVS).
While preparing for the elections, we discovered that CIVS is unable to support our large number of eligible voters.
We created a voter registration system to identify voters and then registered those voters with CIVS.
The workaround required a slight voting delay.
Special thanks to Olivier Vernin and Tracy Miranda who made it possible!

What’s next for the board?

In short term, the renewed board will focus on running the Jenkins governance processes (meetings, budget approvals, funding, etc.) and defining next steps towards improving the project.
One of the priorities will be to organize knowledge and permission transfers to new board members so that they can be effective in their new roles.
There are also pending activities like Jenkins&#x27; transition to Continuous Delivery Foundation which require attention from board members.

For longer term, there are some ideas floating around:
  roadmap for key components,
  long-anticipated architecture changes (UX revamp, pluggable storage, cloud native Jenkins),
  adopting Linux Foundation best practices like Core Infrastructure Initiative,
  contributor onboarding,
  etc.
Such initiatives are instrumental for further evolvement of the Jenkins project,
and the board could help to facilitate them in the community.
The ideas will be discussed in mailing lists and during governance meetings.
If you would like to share your vision and ideas about what’s needed in the project,
it is definitely a great time to do so!

Feedback

We will also also plan to conduct a public retrospective at one of the next Advocacy and Outreach SIG meetings.

Jenkins project plans to conduct elections every year.
We appreciate and welcome any feedback regarding the election process.
Please use the following channels for feedback and suggestions:

There is a Retrospective document in Google Docs.
Everyone can suggest changes in this document, and we will integrate them.

For ideas about the project improvements and next steps for the board,
please use the Jenkins Developers mailing list.

For private feedback, please send an email to the Jenkins Board or to Tracy Miranda.

References

Jenkins Governance Board

Jenkins Board Election Process

Jenkins Officers

2019 election announcement

2019 election updates on Nov 08

Retrospective document<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2019/12/20/call-for-mentors/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">20</div></div><h5 class="title">Google Summer of Code 2020 call for Project ideas and Mentors</h5></div><p class="teaser">Google Summer of Code (GSoC)
is as program where students are paid a stipend by Google to work on a free open source project.
Students work on the project full-time for four months (May to August).
Mentors are actively involved with students starting at the end of February when students start to work on and submit their applications.
(see the timeline)

We are looking for project ideas and mentors to participate in GSoC 2020.
GSoC project ideas are coding projects that university or college students can accomplish in about four months.
The coding projects can be new features, plugins, test frameworks, infrastructure, etc.
Anyone can submit a project idea, but of course we like it even better if you offer to mentor your project idea.

We accept new project ideas at any time,
BUT we need a series of ideas READY before February 5th, 2020 at 7pm UTC,
which is the deadline for the Jenkins organization to apply to the GSoC program.
So send us your project ideas before the beginning of February so they can get a proper review by the GSoC committee and by the community.

How to submit a project idea

For 2020, we have simplified the process.
Simply create a pull-request with your idea in a.adoc file
in the idea folder.
It is no longer necessary to submit a Google Doc, but it will still work if you want to do that.
See the instructions on submitting ideas which include an.adoc template and some examples.

Current list of ideas

We currently have a list of project ideas for students to browse,
copied from last year. Note that this list is subject to change.

What does mentoring involve?

Potential mentors are invited to read the information for mentors.
Note that being a GSoC mentor does not require expert knowledge of Jenkins.
Mentors do not work alone. We make sure that every project has at least two mentors.
GSoC org admins will help to find technical advisers, so you can study together with your students.

Mentoring takes about 5 to 8 hours of work per week (more at the start, less at the end).
Mentors provide guidance, coaching, and sometimes a bit of cheerleading.
They review student proposals, pull-requests and the students presentations
at the evaluation phase.
They fill in the Google provided evaluation report form at the end of coding periods.

What do you get in exchange?

In return of mentoring, a student works on your project full time for four months.
Think about the projects that you’ve always wanted to do but never had the time…​

Having a mentoring opportunity also means that you get to improve your management and people skills.

As well, up to two mentors per organization are eligible to participate in the Google Mentor Summit taking place each year.
The Jenkins Org Admins try to send different mentors each year.
It is also possible to win an additional seat at the summit in the &quot;last minute draw&quot;
(Google draws mentors at random to fill the cancellations and empty seats).

See this post from one of the 2019 mentors
on the kind of experience this was.

GSoC is a pretty good return on the investment!

For any question, you can find the GSoC Org Admins,
mentors and participants on the GSoC SIG Gitter chat.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/martinda/">Martin d&#x27;Anjou</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/01/07/happy-new-year/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 7</div></div><h5 class="title">Happy New Year! 2019/2020 edition</h5></div><p class="teaser">Jenkins project congratulates all users and contributors with the New Year!
Let’s take a look at some changes this year.

Highlights

We celebrated 15 years of Jenkins

We had first ever Governance Board and Officer elections

Jenkins project joined the Continuous Delivery Foundation (CDF)

We released Java 11 support in Jenkins

Jenkins X has graduated as a Jenkins sub-project and became a new project under umbrella of CDF

In October 2019 we reached the record high number of contributions: 915 unique contributors, 124 of them were first-timers

We started new special interest groups for Documentation and User Experience.

A new position of the Documentation officer was introduced to highlight an important role of documentation in the project

We ran multiple mentorship programs with 12 mentees in total: Google Summer of Code, Hacktoberfest and Outreachy

If you are interested to know more about Jenkins features introduced in 2019,
stay tuned for a separate blog post about it (coming soon!).

Project updates

Highlights above do not cover all advancements we had in the project.
Below you can find slides from the Jenkins contributor summit in Lisbon.
There we had project updates by officers, SIG and sub-project leaders.
See the slide deck to know about: Jenkins Core, Pipeline, Configuration-as-Code, Security, UX Overhaul, Jenkins Infrastructure, platform support and documentation.

Some stats and numbers

If this section seems to be too long for you, here is some infographic prepared by Tracy Miranda.
As you may see, Jenkins is pretty big :)

Community.
Over the past year we had 5433 contributors in GitHub repositories (committers, reviewers, issue submitters, etc.).
We had 1892 unique committers who created 7122 pull requests and 45484 commits, bots excluded.
Contributors represent 273 companies and 111 countries, 8% of contributors are recognized as independent.
The most active repositories were Jenkins Core and jenkins.io.
The most active month was October 2019 when we reached the record high number of contributions: 915 unique contributors, 124 of them were first-timers, thanks to Hacktoberfest!.

Jenkins core.
In 2019 Jenkins core had 54 weekly and 13 LTS releases with several hundreds of notable fixes/enhancements.
There was a login screen extensibility rework, many update manager and administrative monitors improvements.
We also introduced support for user timezones, not speaking of emojis support 🥳.
There was also a lot of housekeeping work: better APIs, codebase refresh, cleaning up static analysis warnings and removing deprecated features like Remoting CLI.
The core’s components also got major updates.
Only Jenkins Remoting got 11 releases with stability improvements and new features like support of inbound connections to headless Jenkins controllers.
There are also major incoming features like jep:222[WebSocket Services support], UI look&amp;feel updates, jira:JENKINS-12548[Readonly system configuration support], Docker images for new platforms like Arm.
To facilitate further changes we created a new Core pull request reviewers team and added 9 contributors there.

Plugins.
There were 2654 plugin releases, and 157 NEW plugins have been hosted in the Update Center.
Jenkins ecosystem got a lot of new integrations with Development and DevOps tools.
Also, warm welcome back to the Scriptler Plugin which was depublished in 2017 due to security issues.
If you are afraid about such plugin numbers and dependency management, there is a new Plugin Installation Manager CLI Tool which should help Jenkins users to manage plugins more efficiently.

Security.
It was a hot year for the Jenkins Security Team.
There were 5 security advisories for the core and 20 - for plugins.
In total we disclosed 288 vulnerabilities across the project, including some backlog cleaning for unmaintained plugins.
Script Security Plugin was the hottest plugin with 10 critical fixes addressing various sandbox bypass vulnerabilities.
Plain text storage and unprotected credentials were the most popular vulnerability type 120 disclosures in 2019.
It was made possible by hundreds of reports submitted by contributors after code surveys,
special thanks to Viktor Gazdag who reported the most of the issues and became the Jenkins 2019 Security MVP (check out his story here).

Infrastructure.
Got Jenkins? If so, you rely on Jenkins update centers, website and issue tracker.
All these and many other services are maintained by the Jenkins Infrastructure Team.
This year the team handled more than 400 requests in the bugtracker, and many other informal requests.
In total, more than 30 people contributed to Jenkins infrastructure this year (website content is excluded).
We also deployed 4 new services, migrated 7 services from Azure Container Service to Azure Kubernetes Service and updated many other services.
More changes will happen in the next months, and we are looking for new INFRA team members!

Documentation.
Only last quarter we had 178 contributors to Jenkins documentation. It includes jenkins.io and other documentation hosted on GitHub, Wiki is not included.
There is also ongoing migration plugin documentation from Jenkins Wiki to GitHub ( announcement).
Since the beginning of the project in Sep 2019, more than 150 plugin were migrated, and they got significant documentation revamp during the migration.
You can see the current status here.
We also work on introducing changelog automation in the project.
123 plugins have already adopted the new changelog tools, powered by Release Drafter.
Also, we had more than 60 technical blog posts published on jenkins.io.

Configuration as Code was one of the most popular areas this year.
Jenkins Configuration as Code Plugin had more than 30 releases with new features and bug fixes.
More than 50 plugins have been also updated in order to offer better configuration-as-code support.
As a result, the JCasC Plugin got massive adoption this year (from 2000 to almost 8000 installations),
and now it becomes a de-facto standard for managing Jenkins as code.
This year we also ran our very first CommunityBridge project devoted to JCasC Schema validation and developer tools.

Events and outreach programs.
In 2019 we participated in multiple conferences, including FOSDEM, DevOps World | Jenkins World, SCALE.
More than 40 Jenkins Area Meetups were organized across the world, and there were many other meetups devoted to Jenkins.
We also kept expanding our outreach programs.
In total we had 12 students who participated in Google Summer of Code, Outreachy and newly introduced Community Bridge.
We also had the biggest ever Hacktoberfest with 664 pull requests and 102 participants.
These outreach programs help us to deliver new features in Jenkins.
For example, this year we added Multi-branch Pipeline support for Gitlab and a new Plugin Installation Manager Tool during GSoC,
and Outreachy resulted in a new Audit Log Plugin.

Where did we get those stats?
GitHub stats came from the CDF DevStats service.
These stats include all repositories in the jenkinsci organization and most popular repositories in jenkins-infra, Jenkins X and other organizations/repositories within the project are not included.
Other stats came from project reports, component changelogs, Jenkins usage statistics service, plugin releases history.

What’s next?

Year 2020 will be pretty busy for the Jenkins project.
There are many long-overdue changes in the project, which need to happen if we want the project to succeed.
As it was written Board elections blogpost,
there are many areas to consider: UX revamp, cloud native Jenkins, pluggable storage, etc.
In the coming months there will be a lot of discussions in mailing lists and special interest groups,
and we invite all teams to work on their roadmaps and to communicate them in the community.

Next month we will participate in FOSDEM, and there will be a Jenkins stand there.
On January 31st we will also host a traditional contributor summit in Brussels,
where we will talk about next steps for the project, in terms of technical roadmaps and the project governance.
If you are interested in Jenkins, stop by at our community booths and join us at the summit!
See this thread for more information.

We also plan to continue all outreach programs.
At the moment we are looking for Google Summer of Code 2020 mentors and project ideas ( announcement),
and we will be also interested to consider non-coding projects as a part of other programs like CommunityBridge.
We also work on improving contribution guidelines for newcomers and expert contributors.
If you are interested, please contact the Advocacy and Outreach SIG.

And even more

This blog post does not provide a full overview of what changed in the project.
The Jenkins project consists of more than 2000 plugins and components which are developed by thousands of contributors.
Thanks to them, a lot of changes happen in the project every day.
We are cordially grateful to everybody who participates in the project, regardless of contribution size.
Everything matters: new features, bug fixes, documentation, blog posts, well reported issues, Stackoverflow responses, etc.
THANKS A LOT FOR ALL YOUR CONTRIBUTIONS!

So, keep updating Jenkins and exploring new features.
And stay tuned, there is much more to come next year!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/new-year-blogpost">new-year-blogpost</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/01/08/atlassians-new-bitbucket-server-integration-for-jenkins/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day"> 8</div></div><h5 class="title">Atlassian&#x27;s new Bitbucket Server integration for Jenkins</h5></div><p class="teaser">We know that for many of our customers Jenkins is incredibly important and its integration with Bitbucket Server is a key part of their development workflow.
Unfortunately, we also know that integrating Bitbucket Server with Jenkins wasn’t always easy – it may have required multiple plugins and considerable time.
That’s why earlier this year we set out to change this.
We began building our own integration, and we’re proud to announce that v1.0 is out.

The new Bitbucket Server integration for Jenkins plugin, which is built and supported by Atlassian, is the easiest way to link Jenkins with Bitbucket Server.
It streamlines the entire set-up process, from creating a webhook to trigger builds in Jenkins, to posting build statuses back to Bitbucket Server.
It also supports smart mirroring and lets Jenkins clone from mirrors to free up valuable resources on your primary server.

Our plugin is available to install through Jenkins now.
Watch this video to find out how, or read the BitBucket Server solution page to learn more about it.

Once you’ve tried it out we’d love to hear any feedback you have.
To share it with us, visit https://issues.jenkins.io and create an issue using the component atlassian-bitbucket-server-integration-plugin.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/dkjellin/">Daniel Kjellin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/bitbucket">bitbucket</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/01/10/fosdem-is-coming/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">10</div></div><h5 class="title">FOSDEM 2020 is coming</h5></div><p class="teaser">FOSDEM 2020 is coming and with it, a lot of great folks come in town.
It’s always a great moment to meet Jenkins community members, share stories and get inspired.
I hope that this year will be as great as it always been and for that, we organize a few things

Things we’ll do

During the whole event, we’ll be virtually on the Gitter

On the Thursday 30 of January, there will be two workshops one about Jenkins Pipelines lead by Mark Waite, and a second one about JenkinsX by Viktor Farcic.

On the Friday 31 of January, the Jenkins project will hold a Contributor Summit where we invite active contributors and those who are interested in working on foundation projects, e.g. key architecture changes and projects (UX, JCasC, Cloud native Jenkins, etc.), governance, infrastructure. There will be no user-focused topics (no presentations, no trainings, etc.) but we will focus on defining key priorities for the project, building a roadmap and resolving issues we have in the project at the moment.
We’ll end up the day with our now traditional Orval and flemish beef stew at Le Roy d’Espagne

Finally the FOSDEM, the 01 and 02 of February, we’ll all be at FOSDEM. So come and say &quot;hi&quot; at the Jenkins/JenkinsX stand, inside the CICD Devroom.

Or just come and share beers

Cheers<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/fosdem">fosdem</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/01/23/a-new-chapter-for-kohsuke/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">23</div></div><h5 class="title">A new chapter for Kohsuke</h5></div><p class="teaser">2020 is going to be a year of change for me.
By the end of January, I’ll be officially stepping back from Jenkins,
switching my role at CloudBees to an advisor,
and turning attention to my new startup.
The rest of this post is to contextualize this transition, because if you haven’t been working closely with me, this might come across as a surprise.

Jenkins has been an amazing journey that never stopped giving.
I have loved it all - especially meeting the users around the world who made Jenkins what it is today.
As the creator of the project, at some point I started wondering how to pass the torch to the next leaders, how to get people to step up and drive it forward.
Today, thanks to CloudBees and the community, there is a new generation of talented and capable leaders who are passionately driving things forward - and it’s been great to see.
Newly elected board members, Jenkins X folks, just to name a few.
These new people bring new culture and new code, and altogether it has created a positive jolt that pushed Jenkins out of a local optimum I talked about.
They have all my support and respect.
In reality, my involvement with Jenkins lately has already been largely symbolic, a little bit like an emperor of Japan or a queen of the UK.
That’s why this announcement has little practical impact on the forward motion of Jenkins.

Several years ago, I used to feel like the sky would fall down if I stepped aside.
Somewhere in 2019, I suddenly noticed that I wasn’t feeling like that at all anymore.
The shift was gradual and steady, so I’m not sure exactly when I crossed the threshold, but in 2019 it was clear I was on the other side.
That’s how I knew I could finally end this chapter of my life.
15 years with Jenkins and 9 years with CloudBees.
That is a long time.

I hope you will be wondering what is my new chapter.
I’m launching a new startup, Launchable, with my old time buddy Harpreet Singh.
I have known him since my days at Sun Microsystems and JavaEE, and he was my partner in crime at CloudBees to build the Jenkins business from scratch.
He went to Atlassian running its BitBucket business for a while, but now he and I are back sitting side by side again.
A number of CloudBees people invested, including Sacha Labourey,
Bob Bickel,
and John Vrionis.

Through Jenkins and CloudBees, I was able to push the state of automation forward in software development.
Such automation is producing a lot of data, but we are not using that data to improve our lives.
It truly is a wasted gold mine.
Launchable is working on harnessing that information to improve developer productivity.
I wrote a separate blog post to discuss more about my thinking.

Lastly, even though I’m moving on from CloudBees as a full-time employee, I’m not completely going away.
I’ll be still in the CloudBees orbit, as an advisor.
I’m still very much invested both emotionally and financially in CloudBees.
I’m still a big fan, and I’ll continue to cheer for them, but from the sideline.
The same with Jenkins.
I’m still on the governance board, ensuring the continuity.
I’m also still on the Technical Oversight Committee of the Continuous Delivery Foundation,
though my chairperson term will expire in March.

I’m incredibly grateful for the undeserved opportunity and the privilege given to me during this chapter.
I was surrounded by wonderful, inspiring, and talented people, from whom I learned a lot.
I can only hope that I was able to make a positive impact, and give something back in return to them.
I won’t name names, but you know who you are, and we’ll stay in touch.

This year is going to be truly exciting for me. To infinity and beyond!!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/kohsuke/">Kohsuke Kawaguchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/01/29/gsoc-report/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">29</div></div><h5 class="title">Google Summer of Code 2019 Report</h5></div><p class="teaser">Google Summer of Code is much more than a summer internship program, it is a year-round effort for the organization and some community members.
Now, after the DevOps World | Jenkins World conference in Lisbon and final retrospective meetings, we can say that GSoC 2019 is officially over.
We would like to start by thanking all participants: students, mentors, subject matter experts and all other contributors who proposed project ideas, participated in student selection, in community bonding and in further discussions and reviews.
Google Summer of Code is a major effort which would not be possible without the active participation of the Jenkins community.

In this blogpost we would like to share the results and our experience from the previous year.

Results

Five GSoC projects were successfully completed this year:
Role Strategy Plugin Performance Improvements,
Plugins Installation Manager CLI Tool/Library,
Working Hours Plugin - UI Improvements,
Remoting over Apache Kafka with Kubernetes features,
Multi-branch Pipeline support for Gitlab SCM.
We will talk about the projects a little later in the document.

Project details

We held the final presentations as Jenkins Online Meetups in late August and Google published the results on Sept 3rd.
The final presentations can be found here:
Part 1,
Part 2,
Part 3.
We also presented the
2019 Jenkins GSoC report
at the DevOps World | Jenkins World San Francisco
and at the
DevOps World | Jenkins World 2019 Lisbon conferences.

In the following sections, we present a brief summary of each project, links to the coding phase 3 presentations, and to the final products.

Role Strategy Plugin Performance Improvements

Role Strategy Plugin is one of the most widely used authorization plugins for Jenkins,
but it has never been famous for performance due to architecture issues and regular expression checks for project roles.
Abhyudaya Sharma was working on this project together with hist mentors:
Oleg Nenashev, Runze Xia and Supun Wanniarachchi.
He started the project from creating a new Micro-benchmarking Framework for Jenkins Plugins based on JMH,
created benchmarks and achieved a 3501% improvement on some real-world scenarios.
Then he went further and created a new Folder-based Authorization Strategy Plugin which offers even better performance for Jenkins instances where permissions are scoped to folders.
During his project Abhyudaya also fixed the Jenkins Configuration-as-Code support in Role Strategy and contributed several improvements and fixes to the JCasC Plugin itself.

Project page

Blog posts: Micro-benchmarking Framework for Jenkins Plugins,
Introducing new Folder Authorization Plugin, Performance Improvements to Role Strategy Plugin

Final evaluation: slides, video

Source code: Role Strategy Plugin, Folder Authorization Plugin

Plugins Installation Manager CLI Tool/Library

Natasha Stopa was working on a new CLI tool for plugin management,
which should unify features available in other tools like install-plugins.sh in Docker images.
It also introduced many new features like YAML configuration format support, listing of available updates and security fixes.
The newly created tool should eventually replace the previous ones.
Natasha’s mentors: Kristin Whetstone, Jon Brohauge and Arnab Banerjee.
Also, many contributors from Platform SIG and JCasC plugin team joined the project as a key stakeholders and subject-matter experts.

Project page

Blog posts: alpha release announcement,
coding phase 2 updates

Final evaluation: slides,
video

Source code: Plugin installation manager tool

Working Hours Plugin - UI Improvements

Jenkins UI and frontend framework are a common topic in the Jenkins project,
especially in recent months after the new UX SIG was established.
Jack Shen was working on exploring new ways to build Jenkins Web UI together with his mentor Jeff Pearce.
Jack updated the Working Hours Plugin to use UI controls provided by standard React libraries.
Then he documented his experienced and created template for plugins with React-based UI.

Project page

Blog posts: Updates on Working Hours Plugin UI,
React Plugin Template

Final evaluation: slides, video

Source code: Working Hours Plugin, Template for Jenkins plugins with React-based UI

Remoting over Apache Kafka with Kubernetes features

Long Le Vu Nguyen was working on extended Kubernetes support in the Remoting over Apache Kafka Plugin.
His mentors were Andrey Falco and Pham vu Tuan who was our GSoC 2018 student and the plugin creator.
During this project Long has added a new agent launcher which provisions Jenkins agents in Kubernetes and connects them to the controller.
He also created a Cloud API implementation for it and a new Helm chart which can provision Jenkins as entire system in Kubernetes,
with Apache Kafka enabled by default.
All these features were released in Remoting over Apache Kafka Plugin 2.0.

Project page

Blog post for [Remoting over Apache Kafka Plugin 2.0

Final evaluation: slides, video

Plugin source code

Multi-branch Pipeline support for Gitlab SCM

Parichay Barpanda was working on the new GitLab Branch Source Plugin with Multi-branch Pipeline Jobs and Folder Organisation support.
His mentors were
Marky Jackson-Taulia,
Justin Harringa,
Zhao Xiaojie and
Joseph Petersen.
The plugin scans the projects, importing the pipeline jobs it identifies based on the criteria provided.
After a project is imported, Jenkins immediately runs the jobs based on the Jenkinsfile pipeline script and notifies the status to GitLab Pipeline Status.
This plugin also provides GitLab server configuration which can be configured in Configure System or via Jenkins Configuration as Code (JCasC).
read more about this project in the GitLab Branch Source 1.0 announcement.

Project page

Coding phase 3 presentation

Gitlab Branch Source Plugin, Gitlab API plugin

Projects which were not completed

Not all projects have been completed this year.
We were also working on Artifact Promotion plugin for Jenkins Pipeline
and on Cloud Features for External Workspace Manager Plugin,
but unfortunately both projects were stopped after coding phase 1.
Anyway, we got a lot of experience and takeaways in these areas (see linked Jira tickets!.
We hope that these stories will be implemented by Jenkins contributors at some point.
Google Summer of Code 2020 maybe?

Running the GSoC program at our organization level

Here are some of the things our organization did before and during GSoC behind the scenes.
To prepare for the influx of students, we updated all our GSoC pages and wrote down all the knowledge we accumulated over the years of running the program.
We started preparing in October 2018, long before the official start of the program.
The main objective was to address the feedback we got during GSoC 2018 retrospectives.

Project ideas.
We started gathering project ideas in the last months of 2018.
We prepared a list of project ideas in a Google doc, and we tracked ownership of each project in a table of that document.
Each project idea was further elaborated in its own Google doc.
We find that when projects get complicated during the definition phase, perhaps they are really too complicated and should not be done.

Since we wanted all the project ideas to be documented the same way, we created a template to guide the contributors.
Most of the project idea documents were written by org admins or mentors, but occasionally a student proposed a genuine idea.
We also captured contact information in that document such as GitHub and Gitter handles, and a preliminary list of potential mentors for the project.
We embedded all the project documents on our website.

Mentor and student guidelines.
We updated the mentor information page with details on what we expect mentors to do during the program,
including the number of hours that are expected from mentors,
and we even have a section on preventing conflict of interest.
When we recruit mentors, we point them to the mentor information page.

We also updated the student information page.
We find this is a huge time saver as every student contacting us has the same questions about joining and participating in the program.
Instead of re-explaining the program each time, we send them a link to those pages.

Application phase.
Students started to reach out very early on as well, many weeks before GSoC officially started.
This was very motivating.
Some students even started to work on project ideas before the official start of the program.

Project selection. This year the org admin team had some very difficult decisions to make.
With lots of students, lots of projects and lots of mentors, we had to request the right number of slots and try to match the projects with the most chances of success.
We were trying to form mentor teams at the same time as we were requesting the number of slots, and it was hard to get responses from all mentors in time for the deadline.
Finally we requested fewer slots than we could have filled.
When we request slots, we submit two numbers: a minimum and a maximum. The GSoC guide states that:

The minimum is based on the projects that are so amazing they really want to see these projects occur over the summer,

and the maximum number should be the number of solid and amazing projects they wish to mentor over the summer.

We were awarded minimum. So we had to make very hard decisions: we had to decide between &quot;amazing&quot; and &quot;solid&quot; proposals.
For some proposals, the very outstanding ones, it’s easy.
But for the others, it’s hard.
We know we cannot make the perfect decision, and by experience, we know that some students or some mentors will not be able to complete the program due to uncontrollable life events, even for the outstanding proposals.
So we have to make the best decision knowing that some of our choices won’t complete the program.

Community Bonding.
We have found that the community bonding phase was crucial to the success of each project.
Usually projects that don’t do well during community bonding have difficulties later on.
In order to get students involved in the community better, almost all projects were handled under the umbrella of Special Interest Groups so that there were more stakeholders and communications.

Communications.
Every year we have students who contact mentors via personal messages.
Students, if you are reading this, please do NOT send us personal messages about the projects, you will not receive any preferential treatment.
Obviously, in open source we want all discussions to be public, so students have to be reminded of that regularly.
In 2019 we are using Gitter chat for most communications, but from an admin point of view this is more fragmented than mailing lists.
It is also harder to search.
Chat rooms are very convenient because they are focused, but from an admin point of view, the lack of threads in Gitter makes it hard to get an overview.
Gitter threads were added recently (Nov 2019) but do not yet work well on Android and iOS.
We adopted Zoom Meetings towards the end of the program and we are finding it easier to work with than Google Hangouts.

Status tracking.
Another thing that was hard was to get an overview of how all the projects were doing once they were running.
We made extensive use of Google sheets to track lists of projects and participants during the program
to rank projects and to track statuses of project phases (community bonding, coding, etc.).
It is a challenge to keep these sheets up to date, as each project involves several people and several links.
We have found it time consuming and a bit hard to keep these sheets up to date, accurate and complete, especially up until the start of the coding phase.

Perhaps some kind of objective tracking tool would help.
We used Jenkins Jira for tracking projects, with each phase representing a separate sprint.
It helped a lot for successful projects.
In our organization, we try to get everyone to beat the deadlines by a couple of days, because we know that there might be events such as power outages,
bad weather (happens even in Seattle!), or other uncontrolled interruptions, that might interfere with submitting project data.
We also know that when deadlines coincide with weekends, there is a risk that people may forget.

Retrospective.
At the end of our project, we also held a retrospective and captured some ideas for the future.
You can find the notes here.
We already addressed the most important comments in our documentation and project ideas for the next year.

Recognition

Last year, we wanted to thank everyone who participated in the program by sending swag.
This year, we collected all the mailing addresses we could and sent to everyone we could the 15-year Jenkins special edition T-shirt, and some stickers.
This was a great feel good moment.
I want to personally thank Alyssa Tong her help on setting aside the t-shirt and stickers.

Mentor summit

Each year Google invites two or more mentors from each organization to the Google Summer of Code Mentor Summit.
At this event, hundreds of open-source project maintainers and mentors meet together and have unconference sessions targeting GSoC, community management and various tools.
This year the summit was held in Munich,
and we sent Marky Jackson and Oleg Nenashev as representatives there.

Apart from discussing projects and sharing chocolate, we also presented Jenkins there, conducted a lightning talk and hosted the unconference session about automation bots for GitHub.
We did not make a team photo there, so try to find Oleg and Marky on this photo:

GSoC Team at DevOps World | Jenkins World

We traditionally use GSoC organization payments and travel grants to sponsor student trips to major Jenkins-related events.
This year four students traveled to the DevOps World | Jenkins World conferences in San-Francisco and Lisbon.
Students presented their projects at the community booth and at the contributor summits,
and their presentations got a lot of traction in the community!

Thanks a lot to Google and CloudBees who made these trips possible.
You can find a travel report from Natasha Stopa here,
more travel reports are coming soon.

Conclusion

This year, five projects were successfully completed.
We find this to be normal and in line with what we hear from other participating organizations.

Taking the time early to update our GSoC pages saved us a lot of time later because we did not have to repeat all the information every time someone contacted us.
We find that keeping track of all the mentors, the students, the projects, and the meta information is a necessary but time consuming task.
We wish we had a tool to help us do that.
Coordinating meetings and reminding participants of what needs to be accomplished for deadlines is part of the cheerleading aspect of GSoC, we need to keep doing this.

Lastly, I want to thank again all participants, we could not do this without you.
Each year we are impressed by the students who do great work and bring great contributions to the Jenkins community.

GSoC 2020?

Yes, there will be Google Summer of Code 2020!
We plan to participate, and we are looking for project ideas, mentors and students.
Jenkins GSoC pages have been already updated towards the next year, and we invite everybody interested to join us next year!

Main page with all contacts

GSoC 2020 Project Ideas

GSoC 2020 Call for Mentors and Project Ideas

Information for students and mentors<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/martinda/">Martin d&#x27;Anjou</a>, <a href="/gatsby-jenkins-io/blog/authors/jeffpearce/">Jeff Pearce</a>, <a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a>, <a href="/gatsby-jenkins-io/blog/authors/markyjackson-taulia/">Marky Jackson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/02/02/web-socket/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 2</div></div><h5 class="title">WebSocket</h5></div><p class="teaser">I am happy to report that jep:222[] has landed in Jenkins weeklies,
starting in 2.217.
This improvement brings experimental WebSocket support to Jenkins,
available when connecting inbound agents or when running the CLI.
The WebSocket protocol allows bidirectional, streaming communication over an HTTP(S) port.

While many users of Jenkins could benefit,
implementing this system was particularly important for CloudBees
because of how CloudBees Core on modern cloud platforms
(i.e., running on Kubernetes) configures networking.
When an administrator wishes to connect an inbound (formerly known as “JNLP”) external agent to a Jenkins controller,
such as a Windows virtual machine running outside the cluster and using the agent service wrapper,
until now the only option was to use a special TCP port.
This port needed to be opened to external traffic using low-level network configuration.
For example, users of the nginx ingress controller
would need to proxy a separate external port for each Jenkins service in the cluster.
The instructions to do this are complex and hard to troubleshoot.

Using WebSocket, inbound agents can now be connected much more simply when a reverse proxy is present:
if the HTTP(S) port is already serving traffic,
most proxies will allow WebSocket connections with no additional configuration.
The WebSocket mode can be enabled in agent configuration,
and support for pod-based agents in the Kubernetes plugin is coming soon.
You will need an agent version 4.0 or later,
which is bundled with Jenkins in the usual way (Docker images with this version are coming soon).

Another part of Jenkins that was troublesome for reverse proxy users was the CLI.
Besides the SSH protocol on port 22, which again was a hassle to open from the outside,
the CLI already had the ability to use HTTP(S) transport.
Unfortunately the trick used to implement that confused some proxies and was not very portable.
Jenkins 2.217 offers a new -webSocket CLI mode which should avoid these issues;
again you will need to download a new version of jenkins-cli.jar to use this mode.

The WebSocket code has been tested against a sample of Kubernetes implementations (including OpenShift),
but it is likely that some bugs and limitations remain,
and scalability of agents under heavy build loads has not yet been tested.
Treat this feature as beta quality for now and let us know how it works!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/agents">agents</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cli">cli</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/02/07/trip-to-dwjw/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 7</div></div><h5 class="title">Trip to DevOps World | Jenkins World</h5></div><p class="teaser">I had the privilege of being invited to DevOps World | Jenkins World
2019 for presenting the work I did during Google Summer of Code 2019.
What follows is a day-by-day summary of an amazing trip to the
conference.

Day 0: December 1, 2019

I am an undergraduate student from New Delhi, India and had traveled to
Lisbon to attend the conference. I had an early morning flight to Lisbon
from Delhi via Istanbul. At the Airport, I met Parichay who had been
waiting there from his connecting flight. After flying 8000 km, we
reached Lisbon. We took a taxi to the hotel and were greeted there by
one of my Google Summer of Code mentors, Oleg. After four months of
working with him on my GSoC project, meeting him was an amazing
experience. Later that day, after stretching our legs in the hotel, we
met Long for an early dinner, who came to the hotel after exploring much
of Lisbon.

Day 1: Hackfest, December 2

Next morning, we all met for breakfast where we all got to taste some
Pastel de Nata. We then took a cab to the Congress Centre for attending
the Jenkins and Jenkins X hackfest. At the Hackfest, I met Mark, Joseph,
Kasper, Andrey and other Jenkins contributors. I also met Oleg, this
time together with his son and his wife. After our introductions, and a
short presentation by Oleg, I started hacking on the Folder Auth plugin
and made it possible to delete user sids from roles. The best part of
hacking there was to get instant feedback on what I was working on. More
and more people kept coming throughout the day. It was great to see so
many people working hard to improve Jenkins. At the end, everyone
presented what they had achieved that day. Having skipped lunch for some
snacks, Oleg and others tried hard to get some pizza delivered without
much success. After the Hackfest, everyone was hungry and most attendees
including me went looking for nearby restaurants. Since it was early and
most restaurants were not open yet, we all decided to have burgers. It
was a great learning experience listening to and talking about Jenkins,
Elasticsearch, Jira, GitHub and a lot of other things. After that, we
took a taxi back to the hotel and I went to bed.

Day 2: Contributor Summit, December 3

We had the Jenkins and Jenkins X contributor summit the next day. Me and
Parichay took the bus to the Congress Centre in the morning. After
registration, I got my ‘Speaker’ badge and the conference T-shirt. The
contributor summit took place in the same hall as the Hackfest, but the
seating arrangement was completely different and there were a lot more
people. The summit started with everyone introducing themselves. It
turned out that there were a lot of people from Munich. There were
presentations and talks about all things Jenkins, Jenkins X and the
Continuous Delivery Foundation by Kohsuke, Oleg, Joseph, Liam, Olivier,
Wadek and others. I had no experience with Jenkins X which made the
summit very interesting. After lunch, the talks were over, and everyone
was free to join any session discussing various things about Jenkins. I
attended the Cloud Native Jenkins and the Configuration-as-Code
sessions.

While some of the conference attendees were in the Contributor summit,
the others were going through certifications and trainings. At around 5
o’clock in the evening, the summit and the trainings all got over and
the expo hall was thrown open. On the entrance, there was a large stack
of big DWJW bags. I did not realize why those bags were kept there.
Since everyone was taking one, I took one as well. As soon as I went
into the hall, I realized that those bags were for collecting swag. I
had never seen anything like this where sponsors were just giving away
T-shirts, stickers and other stuff. There were snacks and Kohsuke was
cutting the extremely tasty 15 years of Jenkins cake. After having the
cake, I went on a swag-collecting spree going from one sponsor booth to
the other. This was an amazing experience, not only was I able to get
cool stuff, I was also able to learn a lot about the software these
companies made and how it fits into the DevOps pipeline.

After the conference got over, me, Long and Parichay went to the Lisbon
Mariott Hotel for the Eurodog party. After collecting another T-shirt, I
went to the nearest restaurant (McDonald’s) with Andrey who I had
earlier met at the Hackfest.

Day 3: December 4

This was the first official day of the conference and it began with the
keynote. There were over 900 people in the keynote hall. It was amazing
to see so many people attending the conference. After the keynote got
over, I went to several sessions throughout the day learning about how
companies are using Jenkins and implementing DevOps tools.

In the evening, we had the Sonatype Superparty which was a lot of fun.
There were neon lights, arcade machines, VR experiences, superheroes and
more swag. There was a lot of good food including pizzas and burgers and
hot dogs. Superhero inspired desserts were very interesting. I was able
to talk to Oleg and Wadek about the security challenges in Jenkins.
During the party, I also got a chance to meet the CEO of CloudBees,
Sacha Labourey.

Day 4, December 5

This was the last day of the conference and it began with another
keynote. After the keynote, I attended a very interesting talk on how
the European Observatory built software for large telescopes using
Jenkins. After that, I prepared for my talk on the work I did during
Google Summer of Code 2019. I had my presentation in the community booth
during the lunch time. Presenting in front of real people was an amazing
experience and very different from the ones we had on Zoom chats for our
GSoC evaluations. In the evening, I got another chance to present my
project at the Jenkins Community Lightning Talks.

After that, the conference came to an end and I went back to the hotel.
After relaxing for some time, me, Parichay and Long were invited by Oleg
to a dinner at Corinthia Hotel with Kohsuke, Mark and his wife, Tracy,
Alyssa, and Liam. Unfortunately, Long couldn’t attend the dinner because
he had the flight back earlier that evening. After the amazing dinner, I
thanked everyone for such an amazing trip and said goodbye.

DWJW was the best experience I’ve ever had. I was able to learn about a
lot of new things and talk to some amazing people. In the end, I would
like to especially thank Oleg for helping me throughout and making it
possible for me to attend such a wonderful conference. I would like to
thank my other mentors Runze Xia and Supun for their support in my
Google Summer of Code project. I would like to thank Google for
organizing Google Summer of Code, everyone at Jenkins project for
sponsoring my travel, and CloudBees for inviting me to the conference.

Looking forward to seeing you all again soon!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/abhyudayasharma/">Abhyudaya Sharma</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld">devopsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/02/19/jenkins-world-lisbon-with-love-from-india/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">19</div></div><h5 class="title">My DevOps World | Jenkins World Lisbon Experience</h5></div><p class="teaser">After an amazing three months of development period in the summer of 2019 with Jenkins Project, I was a better developer, loved open source, met
passionate people and had fun at work. Jenkins is not just a community, it is a family. When GSoC period was over, we received swags from Jenkins.
Natasha Stopa (one of the students in GSoC 2019) was invited to attend DevOps World | Jenkins World San Francisco.
It was nice to see her enjoy there. But guess what? Jenkins also invited three other students (Abhyudaya, Long and me) to DevOps World | Jenkins World Lisbon.
I was super psyched when Marky Jackson (one of my project mentors) broke the news to me.

The trip to Lisbon required to sort a few things like flight tickets, hotel booking, passport, visa etc. Oleg Nenashev had scheduled meetings to discuss
and help us with arranging everything for our travel. Thanks to him. :)

From India to Lisbon (Dec 1)

Abhyudaya and I boarded our flight from Indira Gandhi Airport (New Delhi) to Lisbon on December 1, 2019 morning at 0500 hours (local time). It was a fine
trip with an hour layover in Istanbul Ataturk Airport. We arrived in Lisbon at 1500 hours (local time). The weather in Lisbon was terrific. A mild cold
but strong sea breeze was the starting point of me falling in love with the place. We arrived at our hotel (Novotel Lisboa) in an Uber. Oleg met us at
the lobby to help us with check-in. It was great to finally meet him in person after months of knowing and working together. We had a good chat about the
event, what to expect and other sightseeing areas. After a short time of refresh, Long who traveled from Berlin a day before met us at the restaurant. We
had a brief chat knowing each other, had our food and went to bed. The next day was Hackfest. We hit the bed after that as we had to reach Centro de
Congressos de Lisboa (CCL) where the event was organised by 0900 hours.

Day 0 (Dec 2)

I woke up early for a short jog in the streets. Lisbon is a city made on hills. The streets have beautiful mosaic styled pavements. It was
nice to see around the city. Then Abhyudaya and me went for breakfast and reached CCL in an Uber at 0815 hours.

There was a round table sitting arrangement in an auditorium. It was like a meet-and-greet event to interact with other developers (some known and some new).
Everybody had to figure out their problem statements and work on it. There was milk, juice, sandwiches which gave us energy throughout the day. I took a
small break to come out of the building to go to the other side of the road which was on the banks of Tagus River. From there you could have very close
view underneath the Ponte 25 de Abril (looks strikingly similar to Golden Gate Bridge). You can also see The Sanctuary of Christ the King on the other side
of the river (again looks similar to Christ the Redeemer in Rio, Brazil). It was great to kick off the event with Hackfest. At the end of Hackfest some of
us presented our work. Later, we went to a nearby restaurant to have burgers which apparently was the best burger I ever had (could be because I hadn’t
tried too many burgers before :P). We talked and interacted with people from other parts of the world for about an hour and a half then went back to our hotel
rooms.

Day 1 (Dec 3)

The conference officially began on this day. Abyudaya and me had breakfast and took the shuttle to CCL. We collected our t-shirts and IDs. The event managing team
made an app for DevOps World | Jenkins World (DWJW) Lisbon with all schedules and other informations which was incredibly convenient for all attendees.
There were multiple sessions/events on different topics related to Jenkins or DevOps in general. I attended the Jenkins and Jenkins X contributor summit.
Had a nice lunch and went around to explore Lisbon. I went to Padrao dos Descobrimentos and the beautiful Belem Palace. Had some Pasteis de Belem
(a popular Portuguese desert). Took a tram to Praça do Comércio. It is Lisbon’s most important square. You will find lots of tourists, street bands,
sea food restaurants, shops for every budget, the famous pink street and so much more. Later that evening we had a party hosted by EURODOG (European
DevOps Group) at Lisboa Marriott. It was a nice party to network with developers over casual wine and beer. We later head out to a nearby Indian restaurant
for Kebab and rice.

Day 2 (Dec 4)

The second day began with the opening keynote. Later went to the Jenkins X Introduction, Deploying K8s with Jenkins on GCP, Build top mobile games
by King in that order. Also occasionally hitting the sponsors booth to have a chat and collect some swags. In the evening there was the superhero
themed party, sponsored by Sonatype. It was probably the most fun event in the entire conference. The expo hall had an entirely different look with the party lights on,
people wearing capes, fun events going around. There were artists dressed in a Bumblebee, a Batman, a Superman, a Supergirl, a Thor and more superhero
costumes! I was previously made aware of the interesting parties at Jenkins World but the experience was very different. People from all over the world had
come together to celebrate the 15 years of success of an open source software. After partying from 5 to 7 we went back to the hotel. I spent some time
to prepare the slides for the next day’s presentation and went to bed.

Day 3 (Dec 5)

The third and final day of conference began with Jenkins World Fun Run. I missed the keynote for being late and other setup required for the
presentation. My laptop was broken so had to do all the setup for demo on a friend’s laptop. The situation felt like a Jenkins admin under fire
for a production bug. After being under pressure for a while, took a break to admire the developer comics and had a chat with the graffiti painter.
During lunch it was time for the GSoC presentation at the Jenkins community booth. All our presentation went well and we also interacted with real users.
Then we had the GSoC Team pic at the Jenkins community booth. Later Abhyudaya and me gave our presentation at the lightning talks as well upon Mark Waite’s
request. The event concluded with emotional goodbyes.

All GSoC Students were invited for dinner at Corinthia Lisboa’s Soul Garden restaurant. The party comprised of Oleg, Mark and his lovely wife, Liam, Tracy,
Alyssa and Olivier. We had a very nice conversation and I had a very delicious Bacalhau (cod fish) dish. Then bid final goodbye to everybody.

It was a wonderful experience in a wonderful country among wonderful people. Hats off to the management team lead by Alyssa Tong and co. An event this big was
carried out without any hiccups! Everybody contributed their part to the event which made it very interactive and fun. Checkout some of my swags:

A big shout out to the Jenkins project and CloudBees for sponsoring this trip. Also thank you Jenkins and Google Summer of Code for support. :)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/baymac/">Parichay Barpanda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gitlab">gitlab</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld">devopsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsworld">jenkinsworld</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2019">gsoc2019</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/02/25/vscode-caseStudy/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">25</div></div><h5 class="title">Validating JCasC configuration files using Visual Studio Code</h5></div><p class="teaser">Configuration-as-code plugin

Problem Statement: Convert the existing schema validation workflow from the current scripting language in the Jenkins Configuration as Code Plugin to a Java based rewrite thereby enhancing its readablity and testability supported by a testing framework for the same. Enhance developer experience by developing a VSCode Plugin to facilitate autocompletion and validation which would help the developer write correct yaml files before application to a Jenkins Instance.

The Configuration as Code plugin has been designed as an opinionated way to configure Jenkins based on human-readable declarative configuration files. Writing such a file should be feasible without being a Jenkins expert, just translating into code a configuration process one is used to executing in the web UI. The plugin uses a schema to verify the files being applied to the Jenkins instance.

With the new JSON Schema being enabled developers can now test their yaml file against it. The schema checks the descriptors i.e. configuration that can be applied to a plugin or Jenkins core, the correct type is used and help text is provided in some cases. VSCode allows us to test out the schema right out of the box with some modifications. This project was built as part of the Community Bridge initiative which is a platform created by the Linux Foundation to empower developers — and the individuals and companies who support them — to advance sustainability, security, and diversity in open source technology. You can take a look at the Jenkins Community Bridge Project Page

Steps to Enable the Schema Validation

a) The first step includes installing the JCasC Plugin for Visual Studio Code and opening up the extension via the extension list. Shortcut for opening the extension list in VSCode editor using Ctrl + Shift + X.

b) In order to enable validation we need to include it in the workspace settings.
Navigate to File and then Preference and then Settings. Inside settings search for json and inside settings.json include the following configuration.

{
&quot;yaml.schemas&quot;: {
        &quot;schema.json&quot;: &quot;y[a]?ml&quot;
    }
}

You can specify a glob pattern as the value for schema.json which is the file name for the schema. This would apply the schema to all yaml files. eg:.[y[a]?ml]

c) The following tasks can be done using VSCode:

a) Auto completion (Ctrl + Space):
  Auto completes on all commands.

b) Document Outlining (Ctrl + Shift + O):
Provides the document outlining of all completed nodes in the file.

d) Create a new file under the work directory called jenkins.yml. For example consider the following contents for the file:

jenkins:
  systemMessage: “Hello World”
  numExecutors: 2

The above yaml file is valid according to the schema and vscode should provide you with validation and autocompletion for the same.

Screenshots

We are holding an online meetup on the 26th February regarding this plugin and how you could use it to validate your YAML configuration files.
For any suggestions or dicussions regarding the schema feel free to join our gitter channel.
Issues can be created on Github.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sladyn98/">Sladyn Nunes</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community-bridge">community-bridge</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/JCasC">JCasC</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/VSCode">VSCode</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/03/02/findsecbugs/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 2</div></div><h5 class="title">Findsecbugs for Developers</h5></div><p class="teaser">Spotbugs is a utility used in Jenkins and many other Java projects to detect common Java coding mistakes and bugs. It is integrated into the build process to improve the code before it gets merged and released. Findsecbugs is a plugin for Spotbugs that adds 135 vulnerability types focused on the OWASP TOP 10 and the Common Weakness Enumeration (CWE). I’m working on integrating findsecbugs into our Jenkins ecosystem.

Background

Spotbugs traces its history through Findbugs, which started in 2006. As Findbugs it was widely adopted by many projects. About 2016, the Findbugs project ground to a halt. Like the mythical phoenix, the Spotbugs project rose from the ashes to keep the capabilities alive. Most things are completely compatible between the two systems.

Jenkins has used Findbugs and now Spotbugs for years. This is integrated as a build step into parent Maven poms, including the plugin parent pom and the parent pom for libraries and core components. There are various properties that can be set to control the detection threshold, the effort, and findings or categories to exclude. Take a look at the effective pom for a project to see the settings.

Conundrums

There is a fundamental conundrum with introducing an analysis tool into a project. The best time to have done it is always in the past, particularly when the project first started. There are always difficulties in introducing it into an existing project. Putting it off for later just delays the useful results and makes later implementation more difficult. The best time to do it is now, as early as possible.

All analysis tools are imperfect. They report some issues that don’t actually exist. They miss some important issues. This is worse in legacy code, making the adoption more difficult. Findings have to be examined and evaluated. Some are code weaknesses but don’t indicate necessary fixes. For example, MD5 has been known for years as a weak algorithm, unsuitable for security uses. It can be used for non-security purposes, such as fingerprinting, but even there other algorithms (SHA-2) are preferred. We should replace all usages of MD5, but in some cases that’s difficult and it’s not exactly a problem.

Ultimately, the gain from these analysis tools isn’t so much from finding issues in existing code. The value comes more from catching new regressions that might be introduced or improving new code. This is one reason why it is valuable to add useful new analysis such as findsecbugs now, so that we can begin reaping the benefits.

With a security tool like findsecbugs, there is another paradox. Adding the tool makes it easier to find potential security issues. Attackers could take advantage of this information. However, security by obscurity is not a good design. Anyone can run findsecbugs now without the project integrating it. Integrating it makes it easier for legitimate developers to resolve issues and prevent future ones.

Implementation

I’ve been working on integrating findsecbugs into the Jenkins project for several months. It is working in several repos. There are several others where I have presented draft PRs to demonstrate what it will look like once it is enabled. As soon as we can disseminate the information enough, I propose to enable it in the parent poms for widespread use.

Existing

I started by enabling findsecbugs in two major components where I have a high degree of familiarity, Remoting, and Jenkins. Most of the work here involves examining each finding and figuring out what to do with it. In most cases this results in using one of the suppression mechanisms to ignore the finding. In some cases, the code can be removed or improved.

Findsecbugs reported a significant number of false positives in Remoting for a couple of notable reasons. (See the PR.) Remoting uses Spotbugs aggressively with a Low threshold setting. This produces more results. Findsecbugs targets Java web applications. As the communication layer between agents and controller, Remoting uses some mechanisms that would be a problem on the server side but are acceptable on the agent.

Even without all its plugins, Jenkins is a considerable collection of code. Findsecbugs reported a smaller number of false positives for Jenkins (See the PR.) It runs Spotbugs at a High threshold, so it only reports issues it deems more concerning. A number of these indicate code debt, deprecated code to remove, or areas that could be improved. I created Jira tickets for many of these.

Demonstrated

I have created draft PRs to demonstrate how findsecbugs will look in several plugins. The goal is not to use these PRs directly but instead integrate findsecbugs at the parent pom level. These PRs serve as reference documentation.

Credentials

This one is particularly interesting because here findsecbugs correctly detects the remains of a valid security vulnerability ( CVE-2019-10320). Currently, this code is safely used only for migration of old data. If we had run findsecbugs on this plugin a year ago, it would have detected this valid vulnerability.

SSH Build Agents

This one is interesting because it flags MD5 as a concern. Since it is used for fingerprinting, it isn’t a valid vulnerability, but since the hash isn’t stored it is easy to improve the code here.

EC2

In this case, findsecbugs found some valid concerns, but the code isn’t used so it can be removed. Also, MD5 is harder to remove here but should be considered technical debt and removed when possible.

Platform Labeler

Findsecbugs didn’t find any concerns here. This means adapting to it requires no work. In this demonstration, I added a fake finding to prove that it was working.

File Leak Detector

There is one simple finding noted here. Because it is part of the configuration performed by an administrator we can ignore it.

Credentials Binding

Nothing was found here so integration requires no effort.

Proposed

My proposal is to integrate findsecbugs configuration into the parent poms as soon as we can. The delay is currently mostly around sharing the information to prepare developers by blog post, email list discussion, and presentation.

Even before I started working on this, StefanSpieker proposed a PR to integrate into the parent Jenkins pom. This will apply to Jenkins libraries and core components. Once this is integrated, I will pull out the changes I made to the Jenkins and Remoting project poms.

I also plan on integrating findsecbugs into the plugin and Stapler parent poms. Once it is added to the plugin parent pom all plugins will automatically perform these checks when they upgrade their parent pom version. If there are any findings, developers will need to take care of them as described in the next section.

What do you need to do?

Once developers upgrade to a parent pom version that integrates findsecbugs, they may have to deal with evaluating, fixing, or suppressing findings. The parent pom versions do not yet exist but are in process or proposed.

Extraneous build message

In some cases, an extraneous message may show up in the build logs. It starts with a line like this The following classes needed for analysis were missing: followed by lines listing some methods by name. Ignore this message. It results from SpotBugs printing some internal, debug information that isn’t helpful here.

Examine findings

If findsecbugs reports any findings, then a developer needs to examine and determine what to do about each one.

Excluding issues

You can exclude an issue, so that it is never reported in a project. This is done by configuring an exclusion file. If you encounter the findings CRLF_INJECTION_LOGS or INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE feel free to add these to an exclusion file. These are not considered a concern in Jenkins. See the Jenkins project exclusion file for an example. You should be cautious about including other issue types here.

Temporarily disable findsecbugs

You may disable findsecbugs by adding to the exclusion file. I strongly encourage you to only disable findsecbugs temporarily when genuinely needed.

Suppress a finding

After determining that a finding is not important, you can suppress it by annotating a method or a class with @SuppressFBWarnings(value = “…​”, justification=”…​”). I encourage you to suppress narrowly. Never suppress at the class level when you can add it to a method. For a long method, extract the problematic part into a small method and add the suppression there. I also encourage you to always add a meaningful justification.

Improve code

Whenever possible improve the code such that the problematic code no longer exists. This can include removing deprecated or unused code, using improved algorithms, or improving structure or implementation. This is where the significant gains come from with SpotBugs and findsecbugs. Also, as you make changes or add new features make sure to implement them so as not to introduce new issues.

Report security vulnerabilities

If you encounter a finding related to a valid security vulnerability, please report it via the Jenkins security reporting process. This is the responsible behavior that benefits the community. Try not to discuss or call attention to the issue before it can be disclosed in a Jenkins security advisory.

Create tasks

If you discover an improvement area that is too large to fit into your current work or release plan, I encourage you to record a task to get it done. You can do this in Jira, like I did for several issues in Jenkins core, or in whatever task management system you use.

Conclusion

SpotBugs has long been used in Jenkins to catch bugs and improve code quality. Findsecbugs adds valuable security-related bug definitions. As we integrate it into the existing Jenkins code base it will require analysis and suppression for legacy code. This identifies areas we can improve and enhances quality as we move forward. Please responsibly report any security vulnerabilites you discover.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jeffret-b/">Jeff Thompson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/03/02/pipeline-authoring-sig-update/"><div class="header"><div class="date"><div class="month">March</div><div class="day"> 2</div></div><h5 class="title">Pipeline-Authoring SIG Update</h5></div><p class="teaser">What is the Pipeline-Authoring Special Interest Group

This special interest group aims to improve and curate the experience of authoring Jenkins Pipelines. This includes the
syntax of `Jenkinsfile`s and shared libraries, code sharing and reuse, testing of Pipelines and shared libraries, IDE
integration and other development tools, documentation, best practices, and examples.

What Are The Focus Areas of the Pipeline-Authoring Special Interest Group

Syntax - How `Jenkinsfile`s and shared libraries are written.

Code sharing and reuse - Shared libraries and future improvements.

Testing - Unit and functional testing of `Jenkinsfile`s and shared libraries.

IDE integration, editors, and other development tools - IDE plugins, visual editors, etc.

Documentation - Reference documentation, tutorials, and more.

Best practices - Defining, maintaining, and evangelizing best practices in Jenkins Pipeline.

Examples - Real-world `Jenkinsfile`s and shared libraries demonstrating how to utilize various features of Pipeline,
as well as basic or starter `Jenkinsfile`s for common patterns that can be used as jumping-off points by new users.

What Have We Been Up To

With the start of a new year, members got together to discuss the roadmap for 2020. During the initial discussions we
determined that it would be good to examine the goals of previous meetings and determine the best path forward.

A mutual decision was made that to better create a roadmap; we needed to understand better who we were aiming to help.
We decided that creating personas was very beneficial. Personas are fictional characters, which we are creating based
upon our research to represent the different user types that might use Jenkins pipelines.
Creating personas can help us step out of ourselves. It can help us to recognize that different people have different
needs and expectations, and it can also help us to identify with the user we are building the roadmap for. Personas make
the task at hand less complicated, they guide our ideation processes, and they can help us to achieve the goal of
creating a good user experience for our target user group.
A lot of that work can be found here:
https://docs.google.com/document/d/1CdyzJwt50Wk3uUNsLMl2d4w2MGYss-phqet0s-KjbEs/edit
The idea is to map the personas to a maturity model and then map the maturity model to the actual documentation. That
maturity model can be found here: https://drive.google.com/file/d/1ByzWlPU0j1qM_gqspJppkNKkR5ZVLWlB/view

How Can I Get Involved

We have been meeting regularly to define personas to help us better create the SIG roadmap. We meet twice a week,
once on Thursday for the EMEA timezone and once on Friday for the US timezone. Meeting notes can be found here:
https://docs.google.com/document/d/1EhWoBplGl4M8bHz0uuP-iOynPGuONjcz4enQm8sDyUE/edit# and the calendar, if you would
like to attend, is here: https://jenkins.io/event-calendar/. The previous recording of the meetings are
located here: https://www.youtube.com/watch?v=pz_kPpb9C1w&amp;list=PLN7ajX_VdyaOKKLBXek6iG8wTS24Ac7Y3

Next Steps

We have a lot of work to do and could use your help. If you would love to join us, check out the meeting link. If you
would like to check out the personas and give feedback, also check out the link.
Once we have wrapped up the personas work, we will start to identify the available documentation and ensure we have
adequate documentation with the help of the Doc SIG.
We will finally then start working to build out tools to help the community with pipelines in Jenkins better.

Contact Us

If you would like to get in touch with the Pipeline-Authoring SIG, you can by joining the
Pipeline-Authoring SIG gitter channel or via the
Pipeline-Authoring SIG mailing list<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markyjackson-taulia/">Marky Jackson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/Pipeline-Authoring">Pipeline-Authoring</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/SIG">SIG</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/opensource">opensource</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/03/17/ui-plugins/"><div class="header"><div class="date"><div class="month">March</div><div class="day">17</div></div><h5 class="title">Hands On: Beautify the user interface of Jenkins reporter plugins</h5></div><p class="teaser">This article has been presented in an recorded online session
during the Jenkins 2020 UI/UX Hackfest.

For Jenkins a large number of plugins are available that visualize the results of a wide variety of build steps. There
are plugins available to render the test results, the code coverage, the static analysis and so on. All of these plugins
typically pick up the build results of a given build step and show them in the user interface. In order to render these
details most of the plugins use static HTML pages, since this type of user interface is the standard visualization in
Jenkins since its inception in 2007.

In order to improve the look and feel and the user experience of these plugins it makes sense to move forward and
incorporate some modern Java Script libraries and components. Since development of Blue Ocean has been stopped (see
Jenkins mailing list post)
plugin authors need to decide on their own, which UI technologies are helpful for that task. However, the universe of
modern UI components is so overwhelming that it makes sense to pick up only a small set of components that are proven
to be useful and compatible with Jenkins underlying web technologies. Moreover, the initial setup of
incorporating such a new component is quite large so it would be helpful if that work needs to be done only once.

This guide introduces a few UI components
that make sense to be used by all plugin authors in the future to provide a rich user interface for reports in Jenkins.
In order to simplify the usage of these libraries in the context of Jenkins as a Java based web application, these
Java Script libraries and components have been packaged as ordinary Jenkins plugins.

In the following sections, these new components will be introduced step by step. In order to see how these components
can be used a plugin, I demonstrate the new features while enhancing the existing
Forensics Plugin with a new user
interface. Since the Warnings Next Generation Plugin also uses these new components, you can see additional examples
in the documentation of the warnings plugin
or in our public ci.jenkins.io instance, that
already is using these components in the detail views of the warnings plugin.

1. New user interface plugins

The following UI components are provided as new Jenkins plugins:

jquery3-api-plugin :
Provides jQuery 3 for Jenkins Plugins.
jQuery is — as described on their home page — a fast, small, and feature-rich JavaScript library. It makes things
like HTML document traversal and manipulation, event handling, animation, and Ajax much simpler with an easy-to-use API
that works across a multitude of browsers. With a combination of versatility and extensibility, jQuery has changed the
way that millions of people write JavaScript.

bootstrap4-api-plugin :
Provides Bootstrap 4 for Jenkins Plugins. Bootstrap is — according to their self-perception — the world’s most popular front-end component library to build responsive, mobile-first projects on the web. It is
an open source toolkit for developing with HTML, CSS, and JS. Developers can quickly prototype their ideas or
build entire apps with their Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful plugins
built on jQuery.

data-tables-api-plugin :
Provides DataTables for Jenkins Plugins.
DataTables is a plug-in for the jQuery Javascript library. It is a highly flexible tool, built upon the foundations
of progressive enhancement, that adds all of these advanced features to any HTML table:

Previous, next and page navigation

Filter results by text search

Sort data by multiple columns at once

DOM, Javascript, Ajax and server-side processing

Easily theme-able

Mobile friendly

echarts-api-plugin :
Provides ECharts for Jenkins Plugins. ECharts is an open-sourced
JavaScript visualization tool to create intuitive, interactive, and highly-customizable charts. It
can run fluently on PC and mobile devices and it is compatible with most modern
Web Browsers.

font-awesome-api-plugin :
Provides Font Awesome for Jenkins Plugins. Font Awesome has vector icons and social logos,
according to their self-perception it is the web’s most popular icon set and toolkit. Currently, it contains more than
1,500 free icons.

popper-api-plugin
Provides Popper.js for Jenkins Plugins. Popper can
easily position tooltips, popovers or anything else with just a line of code.

plugin-util-api-plugin : This small plugin provides
some helper and base classes to simplify the creation of reporters in Jenkins. This plugin also
provides a set of architecture rules that can be included in an architecture test suite of your plugin.

2. Required changes for a plugin POM

In order to use these plugins you need to add them as dependencies in your plugin pom. You can use the following snippet
to add them all:

pom.xml

[...]

1.0.2
5.12.0-7
4.4.1-10
4.6.0-8
1.10.20-13
[...]

io.jenkins.plugins
plugin-util-api
${plugin-util-api.version}

io.jenkins.plugins
font-awesome-api
${font-awesome-api.version}

io.jenkins.plugins
bootstrap4-api
${bootstrap4-api.version}

io.jenkins.plugins
echarts-api
${echarts-api.version}

io.jenkins.plugins
data-tables-api
${data-tables-api.version}

[...]

[...]

Alternatively, you have a look at the POM files of the
Warnings Next Generation Plugin or the
Forensics API Plugin which already use these
plugins.

3. General structure of a reporter

In this section I will explain some fundamentals of the design of Jenkins, i.e. the Java model and the associated
user interface elements. If you are already familiar on how to implement the corresponding extension points of a
reporter plugin (see section Extensibility in Jenkins&#x27;
developer guide), then you can skip this section and head directly to Section 3.1.

Jenkins organizes projects using the static object model structure shown in Figure 1.

Figure 1. Jenkins design - high level view of the Java model

The top level items in Jenkins user interface are jobs (at least the top level items
we are interested in). Jenkins contains several jobs of different types (Freestyle jobs, Maven Jobs, Pipelines, etc.).

Each of these jobs contains an arbitrary number of builds (or more technically, runs). Each build is identified by its
unique build number. Jenkins plugins can attach results to these builds, e.g. build artifacts, test results,
analysis reports, etc. In order to attach such a result, a plugin technically needs to implement and create an action
that stores these results.

These Java objects are visualized in several different views, which are described in more detail in the following
sections. The top-level view that shows all available Jobs is shown in Figure 2.

Figure 2. Jenkins view showing all available jobs

Plugins can also contribute UI elements in these views, but this is out of scope of this guide.

Each job has a detail view, where plugins can extend corresponding extension points and provide summary boxes and
trend charts. Typically, summary boxes for reporters are not required on the job level, so I describe only trend charts
in more detail, see section Section 5.5.2.

Figure 3. Jenkins view showing details about a job

Each build has a detail view as well. Here plugins can provide summary boxes similar to the boxes for the job details
view. Typically, plugins show here only a short summary and provide a link to detailed results, see Figure 4 for
an example.

Figure 4. Jenkins view showing details about a build

The last element in the view hierarchy actually is a dedicated view that shows the results of a specific plugin. E.g.,
there are views to show the test results, the analysis results, and so on. It is totally up to a given plugin what
elements should be shown there. In the next few sections I will introduce some new UI components that can be used
to show the corresponding results in a pleasant way.

3.1. Extending Jenkins object model

Since reporters typically are composed in a similar way, I extended Jenkins&#x27; original object model
(see Figure 1) with some additional elements, so it will be much simpler to create or implement
a new reporter plugin. This new model is shown in Figure 5. The central element is a build action that
will store the results of a plugin reporter. This action will be attached to each build and will hold (and persist) the
results for a reporter. The detail data of each action will be automatically stored in an additional file, so the
memory footprint of Jenkins can be kept small if the details are never requested by users. Additionally, this
action is also used to simplify the creation of project actions and trend charts, see Section 5.5.2.

Figure 5. Jenkins reporter design - high level view of the model for reporter plugins

4. Git Forensics plugin

The elements in this tutorial will be all used in the new
Forensics API Plugin (actually the plugin is not new, it is a dependency of the
Warnings Next Generation Plugin). You can download the plugin content
and see in more detail how these new components can be used in practice. Or you can change this plugin just to see
how these new components can be parametrized.

If you are using Git as source code management system then this plugin will mine
the repository in the style of
Code as a Crime Scene
(Adam Tornhill, November 2013) to determine statistics of the contained source code files:

total number of commits

total number of different authors

creation time

last modification time

The plugin provides a new step (or post build publisher) that starts the repository mining and stores
the collected information in a Jenkins action (see Figure 5). Afterwards you get a new
build summary that shows the total number of scanned files (as trend and as build result). From
here you can navigate to the details view that shows the scanned files in a table that can be
simply sorted and filtered. You also will get some pie charts that show important aspects of the
commit history.

Please note that this functionality of the plugin still is a proof of concept: the performance of this step heavily
depends on the size and the number of commits of your Git repository. Currently it scans the whole repository in each
build. In the near future I hope to find a volunteer who is interested in replacing this dumb algorithm with an incremental scanner.

5. Introducing the new  UI components

As already mentioned in Section 3, a details view is plugin specific. What is shown and how these
elements are presented is up to the individual plugin author. So in the next sections I provide some examples
and new concepts that plugins can use as building blocks for their own content.

5.1. Modern icons

Jenkins plugins typically do not use icons very frequently. Most plugins provide an icon for the actions and that’s it.
If you intend to use icons in other places, plugin authors are left on their own: the recommended Tango icon set is more
than 10 years old and too limited nowadays. There are several options available, but the most popular is the
Font Awesome Icon Set. It provides more than 1500 free icons that follow the same
design guidelines:

Figure 6. Font Awesome icons in Jenkins plugins

In order to use Font Awesome icons in a plugin you simply need a dependency to the corresponding
font-awesome-api-plugin. Then you can use any of the solid icons
by using the new tag svg-icon in your jelly view:

index.jelly

[...]

[...]

If you are generating views using Java code, then you also can use the class SvgTag to generate the
HTML markup for such an icon.

5.2. Grid layout

Jenkins currently includes in all views an old and patched version of Boostrap’s grid system (with 24 columns). This version
is not compatible with Boostrap 4 or any of the JS libraries that depend on Bootstrap4. In order to use Bootstrap 4
features we need to replace the Jenkins provided layout.jelly file with a patched version, that does not load
the broken grid system. I’m planning to create a PR that fixes the grid in Jenkins core, but that will take some time.
Until then you will need to use the provided layout.jelly of the Boostrap4 plugin, see below.

The first thing to decide is, which elements should be shown on a plugin page and how much space each element
should occupy. Typically, all visible components are mapped on the available space using a simple grid.
In a Jenkins view we have a fixed header and footer and a navigation bar on the left
(20 percent of the horizontal space). The rest of a screen can be used by
a details view. In order to simplify the distribution of elements in that remaining space we use
Bootstrap’s grid system.

Figure 7. Jenkins layout with a details view that contains a grid system

That means, a view is split into 12 columns and and arbitrary number of rows. This grid system is simple to use
(but complex enough to also support fancy screen layouts) - I won’t go into
details here, please refer to the Bootstrap documentation
for details.

For the forensics detail view we use a simple grid of two rows and two columns. Since the number of columns always is 12
we need to create two &quot;fat&quot; columns that fill 6 of the standard columns.
In order to create such a view in our
plugin we need to create a view given as a jelly file and a corresponding Java view model object. A view with this layout
is shown in the following snippet:

index.jelly

(1)

(2)
(3)

(4)
(5)
Content of column 1 in row 1

(6)
Content of column 2 in row 1

(7)
(8)
Content of row 2

1
Use a custom layout based on Bootstrap: since Jenkins core contains an old version of Bootstrap,
we need to replace the standard layout.jelly file.

2
Import Bootstrap 4: Importing of JS and CSS components is done using the adjunct concept,
which is the preferred way of referencing static resources within Jenkins&#x27; Stapler Web framework.

3
The whole view will be placed into a fluid container that fills up the whole screen (100% width).

4
A new row of the view is specified with class row. The additional class py-3 defines the padding to use for
this row, see Bootstrap Spacing for more details.

5
Since Bootstrap automatically splits up a row into 12 equal sized columns we define here
that the first column should occupy 6 of these 12 columns. You can also leave off the detailed numbers, then Bootstrap will
automatically distribute the content in the available space. Just be aware that this not what you want in most of the times.

6
The second column uses the remaining space, i.e. 6 of the 12 columns.

7
The second row uses the same layout as row 1.

8
There is only one column for row 1, it will fill the whole available space.

You can also specify different column layouts for one row, based on the actual visible size of the screen.
This helps to improve the layout for larger screens. In the warnings plugin you will find
an example: on small devices, there is one card visible that shows one pie chart in a carousel. If you are
opening the same page on a larger device, then two of the pie charts are shown side by side and the carousel is hidden.

5.3. Cards

When presenting information of a plugin as a block, typically plain text elements are shown. This will normally result
in some kind of boring web pages. In order to create a more appealing interface, it makes sense to present such information
in a card, that has a border, a header, an icon, and so on. In order to create such a
Bootstrap card a small jelly tag has been provided by the new
Bootstrap plugin that simplifies this task for a plugin.
Such a card can be easily created in a jelly view in the following way:

Content of the card

In Figure 8 examples of such cards are shown. The cards in the upper row contain pie charts that show the
distribution of the number of authors and commits in the whole repository. The card at the bottom shows the detail
information in a DataTable. The visualization is not limited to charts or tables, you can
show any kind of HTML content in there. You can show any icon of your
plugin in these cards, but it is recommended to use one of the existing Font Awesome icons
to get a consistent look and feel in Jenkins&#x27; plugin ecosystem.

Figure 8. Bootstraps cards in Jenkins plugins

Note that the size of the cards is determined by the grid configuration, see Section 5.2.

5.4. Tables

A common UI element to show plugin details is a table control. Most plugins (and Jenkins core) typically use
plain HTML tables. However, if the table should show a large number of rows then using a more sophisticated control
like DataTables makes more sense. Using this JS based table control provides additional
features at no cost:

filter results by text search

provide pagination of the result set

sort data by multiple columns at once

obtain table rows using Ajax calls

show and hide columns based on the screen resolution

In order to use DataTables in a view there are two options, you can either decorate existing
static HTML tables (see Section 5.4.1) or populate the table content using Ajax (see Section 5.4.2).

5.4.1. Tables with static HTML content

The easiest way of using DataTables is by creating a static HTML table that will be decorated by simply calling the
constructor of the datatable. This approach involves no special handling on the Java and Jelly side, so I think it is
sufficient to follow the example in the DataTables
documentation. Just make sure that after building the table in your Jelly file you need to decorate the table
with the following piece of code:

[...]

[...]

[...]

1
replace id with the ID of your HTML table element

In the Forensics plugin no such static table is used so far, but you can have a look at the
table that shows fixed warnings
in the warnings plugin to see how such a table can be decorated.

5.4.2. Tables with dynamic model based content

While static HTML tables are easy to implement, they have several limitations. So it makes sense to follow a more
sophisticated approach. Typically, tables in user interfaces are defined by using a corresponding table (and row) model.
Java Swing successfully provides such a
table model concept since the early days of Java.
I adapted these concepts for Jenkins and DataTables as well. In order to create a table in a Jenkins view a plugin
needs to provide a table model class, that provides the following information:

the ID of the table (since there might be several tables in the view)

the model of the columns (i.e., the number, type, and header labels of the columns)

the content of the table (i.e. the individual row objects)

You will find an example of such a table in the Forensics plugin: here a table lists
the files in your Git repository combined with the corresponding commit statistics (number of authors,
number of commits, last modification, first commit). A screenshot of that table is shown in Figure 9.

Figure 9. Dynamic Table in the Forensics plugin

In order to create such a table in Jenkins, you need to create a table model class that derives from TableModel.
In Figure 10 a diagram of the corresponding classes in the Forensics plugin is shown.

Figure 10. Table model of the Forensics plugin

Table column model

This first thing a table model class defines is a model of the available columns by creating corresponding
TableColumn instances. For each column you need to specify a header label and the name of the bean property that
should be shown in the corresponding column (the row elements are actually Java beans: each column will
show one distinct property of such a bean, see next section). You can
use any of the supported column types by simply providing a
String or Integer based column.

Table rows content

Additionally, a table model class provides the content of the rows. This getRows() method
will be invoked asynchronously using an Ajax call. Typically, this method simply returns a list of Java Bean instances,
that provide the properties of each column (see previous section). These objects will be converted automatically
to an array of JSON objects, the basic data structure required for the DataTables API.
You will find a fully working example table model
implementation in the Git repository of the forensics plugin in the class
ForensicsTableModel.

In order to use such a table in your plugin view you need to create the table in the associated
Jelly file using the new table tag:

index.jelly

[...]

(1)
[...]

1
replace id with the id of your table

The only parameter you need to provide for the table is the model — it is typically part of the corresponding
Jenkins view model class (this object is referenced with ${it} in the view).
In order to connect the corresponding Jenkins view model class with the table, the view model class needs to
implement the AsyncTableContentProvider interface. Or even simpler, let your view model class derive from
DefaultAsyncTableContentProvider. This relationship is required, so that Jenkins can automatically create
and bind a proxy for the Ajax calls that will automatically fill the table content after the HTML page has been created.

If we put all those pieces together, we are required to define a model similar to the model of the Forensics plugin,
that is shown in Figure 11.

Figure 11. Jenkins reporter design - high level view of the model for reporter plugins

As already described in Figure 5 the plugin needs to attach a BuildAction to each build. The
Forensics plugin attaches a ForensicBuildAction to the build. This action stores a RepositoryStatistics instance,
that contains the repository results for a given build. This action delegates all Stapler requests to a new
staplerdoc:org.kohsuke.stapler.StaplerProxy[Stapler proxy instance] so we can keep the
action clean of user interface code. This ForensicsViewModel class then acts as view model that provides the server
side model for the corresponding Jelly view given by the file index.jelly.

While this approach looks quite complex at a first view, you will see that the actual implementation part
is quite small. Most of the boilerplate code is already provided by the base classes and you need to implement
only a few methods. Using this concept also provides some additional features, that are part of the DataTables plugin:

Ordering of columns is persisted automatically in the browser local storage.

Paging size is persisted automatically in the browser local storage.

The Ajax calls are actually invoked only if a table will become visible. So if you have
several tables hidden in tabs then the content will be loaded on demand only, reducing the amount of data
to be transferred.

There is an option available to provide an additional details row that can be expanded with a + symbol,
see warnings plugin table for details.

5.5. Charts

A plugin reporter typically also reports some kind of trend from build to build. Up to now Jenkins core provides only a
quite limited concept of rendering such trends as trend charts. The
JFreeChart framework offered by Jenkins core is a server
side rendering engine that creates charts as static PNG images that will be included on the job and details pages.
Nowadays, several powerful JS based charting libraries are available, that do the same job
(well actually an even better job) on the client side. That has the advantage that these charts can be customized
on each client without affecting the server performance. Moreover, you get a lot of additional
features (like zooming, animation, etc.) for free. Additionally, these charting libraries not only support the typical
build trend charts but also a lot of additional charts types that can be used to improve the user experience of
a plugin.
One of those charting libraries is ECharts : this library has a powerful API
and supports literally every chart type one can image of. You can get some impressions of the features on the
examples page of the library.

In order to use these charts one can embed charts that use this library by importing the corresponding JS files and by
defining the chart in the corresponding Jelly file. While that already works quite well it
will be still somewhat cumbersome to provide the corresponding model for these charts from Jenkins build results. So
I added a powerful Java API that helps to create the model for these charts on the Java side. This API provides the
following features:

Create trend charts based on a collection of build results.

Separate the chart type from the aggregation in order to simplify unit testing of the chart model.

Toggle the type of the X-Axis between build number or build date (with automatic aggregation of results that
have been recorded at the same day).

Automatic conversion of the Java model to the required JSON model for the JS side.

Support for pie and line charts (more to come soon).

Those charts can be used as trend chart in the project page (see Figure 3) or as information chart in the details
view of a plugin (see Section 5).

5.5.1. Pie charts

A simple but still informative chart is a pie chart that illustrates numerical proportions of plugin data. In the Forensics
plugin I am using this chart to show the numerical proportions of the number of authors or commits for the
source code files in the Git repository (see Figure 8). In the warnings plugin I use this chart to show the
numerical proportions of the new, outstanding, or fixed warnings, see Figure 12.

Figure 12. Pie chart in the Warnings plugin

In order to include such a chart in your details view, you can use the provided pie-chart tag.
In the following snippet you see this tag in action (embedded in a Bootstrap card, see Section 5.3):

index.jelly

[...]
&lt;c:pie-chart id=&quot;authors&quot; model=&quot;${it.authorsModel}&quot; height=&quot;256&quot; /&gt;

[...]

You need to provide a unique ID for this chart and the corresponding model value. The model must be the JSON
representation of a corresponding PieChartModel instance. Such a model can be created with a couple of lines:

ViewModel.java

[...]
    PieChartModel model = new PieChartModel(&quot;Title&quot;);

    model.add(new PieData(&quot;Segment 1 name&quot;, 10), Palette.RED);
    model.add(new PieData(&quot;Segment 2 name&quot;, 15), Palette.GREEN);
    model.add(new PieData(&quot;Segment 3 name&quot;, 20), Palette.YELLOW);

    String json = new JacksonFacade().toJson(model);
    [...]

5.5.2. Trend charts on the job level view

In order to show a trend that renders a line chart on the job page (see Figure 3) you need to provide a so called
floating box (stored in the file floatingBox.jelly of your job action (see Section 3)).
The content of this file is quite simple and contains just a trend-chart tag:

floatingBox.jelly

&lt;c:trend-chart it=&quot;${from}&quot; title=&quot;${%SCM Files Count Trend}&quot; enableLinks=&quot;true&quot;/&gt;

On the Java side the model for the chart needs to be provided in the corresponding sub class of JobAction (which is
the owner of the floating box). Since the computation of trend charts is quite expensive on the server side as well
(several builds need to be read from disk and the interesting data points need to be computed) this process has been
put into a separate background job. Once the computation is done the result is shown via an Ajax call. In order to
hide these details for plugin authors you should simply derive your JobAction class from the corresponding
AsyncTrendJobAction class, that already contains the boilerplate code. So your static plugin object model will actually
become a little bit more complex:

Figure 13. Jenkins chart model design

Basically, you need to implement the method LinesChartModel createChartModel() to create the line
chart. This method is quite simple to implement, since most of the hard work is provided by the library: you will
invoke with an iterator of your build actions, starting with the latest build. The iterator advances from build to build
until no more results are available (or the maximum number of builds to consider has been reached). The most important
thing to implement in your plugin is the way how data points are computed for a given BuildAction. Here is an example of
such a SeriesBuilder implementation in the Forensics Plugin:

FilesCountSeriesBuilder.java

package io.jenkins.plugins.forensics.miner;

import java.util.HashMap;
import java.util.Map;

import edu.hm.hafner.echarts.SeriesBuilder;

/**
 * Builds one x-axis point for the series of a line chart showing the number of files in the repository.
 *
 * @author Ullrich Hafner
 */
public class FilesCountSeriesBuilder extends SeriesBuilder {
    static final String TOTALS_KEY = &quot;total&quot;;

    @Override
    protected Map computeSeries(final ForensicsBuildAction current) {
        Map series = new HashMap&lt;&gt;();
        series.put(TOTALS_KEY, current.getNumberOfFiles());
        return series;
    }
}

You are not limited to a single line chart. You can show several lines in a single chart, you can show stacked values,
or even the delta between some values. You can also have a look at the
charts of the warnings plugin
to see some of these features in detail.

Figure 14. Trend chart with several lines in the Warnings plugin

Figure 15. Trend chart with stacked lines in the Warnings plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/uhafner/">Ullrich Hafner</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ui">ui</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/03/30/azure-key-vault-cred-provider/"><div class="header"><div class="date"><div class="month">March</div><div class="day">30</div></div><h5 class="title">Introducing the Azure Key Vault Credentials Provider for Jenkins</h5></div><p class="teaser">Azure Key Vault is a product for securely managing keys, secrets and certificates.

I’m happy to announce two new features in the Azure Key Vault plugin:

a credential provider to tightly link Jenkins and Azure Key Vault.

huge thanks to Jie Shen for contributing this

integration with the configuration-as-code plugin.

These changes were released in v1.8 but make sure to run the latest version of the plugin, there has been some fixes since then.

Some advantages of using the credential provider rather than your own scripts:

your Jenkins jobs consume the credentials with no knowledge of Azure Key Vault, so they stay vendor-independent.

the provider integrates with the ecosystem of existing Jenkins credential consumers, such as the Slack Notifications plugin.

credential usage is recorded in the central Jenkins credentials tracking log.

Jenkins can use multiple credentials providers concurrently, so you can incrementally migrate credentials to Azure Key Vault while consuming other credentials from your existing providers.

Note: Currently only secret text credentials are supported via the credential provider, you can use the configuration-as-code integration to load the secret from Azure Key Vault into the System Credential Provider to work around this limitation.

Getting started

Install the Azure Key Vault plugin

Then you will need to configure the plugin.

Azure authentication

There’s two types of authentication you can use &#x27;Microsoft Azure Service Principal&#x27; or &#x27;Managed Identities for Azure Resources&#x27;

The easiest one to set this up quickly with is the &#x27;Microsoft Azure Service Principal&#x27;,

$ az ad sp create-for-rbac --name http://service-principal-name
Creating a role assignment under the scope of &quot;/subscriptions/ff251390-d7c3-4d2f-8352-f9c6f0cc8f3b&quot;
  Retrying role assignment creation: 1/36
  Retrying role assignment creation: 2/36
{
  &quot;appId&quot;: &quot;021b5050-9177-4268-a300-7880f2beede3&quot;,
  &quot;displayName&quot;: &quot;service-principal-name&quot;,
  &quot;name&quot;: &quot;http://service-principal-name&quot;,
  &quot;password&quot;: &quot;d9d0d1ba-d16f-4e85-9b48-81ea45a46448&quot;,
  &quot;tenant&quot;: &quot;7e593e3e-9a1e-4c3d-a26a-b5f71de28463&quot;
}

If this doesn’t work then take a look at the Microsoft documentation for creating a service principal.

Note: for production &#x27;Managed Identities for Azure Resources&#x27; is more secure as there’s no password involved and you don’t need to worry about the service principal’s password or certificate expiring.

Vault setup

You need to create a vault and give your service principal access to it:

RESOURCE_GROUP_NAME=my-resource-group
az group create --location uksouth --name $RESOURCE_GROUP_NAME

VAULT=my-vault # you will need a unique name for the vault
az keyvault create --resource-group $RESOURCE_GROUP_NAME --name $VAULT
az keyvault set-policy --resource-group $RESOURCE_GROUP_NAME --name $VAULT \
  --secret-permissions get list --spn http://service-principal-name

Jenkins credential

The next step is to configure the credential in Jenkins:

click &#x27;Credentials&#x27;

click &#x27;System&#x27; (it’ll appear below the Credentials link in the side bar)

click &#x27;Global credentials (unrestricted)&#x27;

click &#x27;Add Credentials&#x27;

select &#x27;Microsoft Azure Service Principal&#x27;

fill out the form from the credential created above, appId is &#x27;Client ID&#x27;, password is &#x27;Client Secret&#x27;

click &#x27;Verify Service Principal&#x27;, you should see &#x27;Successfully verified the Microsoft Azure Service Principal&#x27;.

click &#x27;Save&#x27;

Jenkins Azure Key Vault plugin configuration

You now have a credential you can use to interact with Azure resources from Jenkins, now you need to configure the plugin:

go back to the Jenkins home page

click &#x27;Manage Jenkins&#x27;

click &#x27;Configure System&#x27;

search for &#x27;Azure Key Vault Plugin&#x27;

enter your vault url and select your credential

click &#x27;Save&#x27;

Store a secret in Azure Key Vault

For the step after this you will need a secret, so let’s create one now:

$ az keyvault secret set --vault-name $YOUR_VAULT --name secret-key --value my-super-secret

Create a pipeline

Install the Pipeline plugin if you don’t already have it.

From the Jenkins home page, click &#x27;New item&#x27;, and then:

enter a name, i.e. &#x27;key-vault-test&#x27;

click on &#x27;Pipeline&#x27;

add the following to the pipeline definition:

// Declarative //
pipeline {
  agent any
  environment {
    SECRET_KEY = credentials(&#x27;secret-key&#x27;)
  }
  stages {
    stage(&#x27;Foo&#x27;) {
      steps {
        echo SECRET_KEY
        echo SECRET_KEY.substring(0, SECRET_KEY.size() - 1) // shows the right secret was loaded, don&#x27;t do this for real secrets unless you&#x27;re debugging
      }
    }
  }
}

// Scripted //
withCredentials([string(credentialsId: &#x27;secret-key&#x27;, variable: &#x27;SECRET_KEY&#x27;)]) {
    echo SECRET_KEY
    echo SECRET_KEY.substring(0, SECRET_KEY.size() - 1) // shows the right secret was loaded, don&#x27;t do this for real secrets unless you&#x27;re debugging
}

You have now successfully retrieved a credential from Azure Key Vault using native Jenkins credentials integration.

configuration-as-code integration

The Configuration as Code plugin has been designed as an opinionated way to configure Jenkins based on human-readable declarative configuration files. Writing such a file should be easy without being a Jenkins expert.

For many secrets the credential provider is enough,
but when integrating with other plugins you will likely need more than string credentials.

You can use the configuration-as-code plugin (aka JCasC) to allow integrating with other credential types.

configure authentication

As the JCasC plugin runs during initial startup the Azure Key Vault credential provider needs to be configured before JCasC runs during startup.

The easiest way to do that is via environment variables set before Jenkins starts up:

export AZURE_KEYVAULT_URL=https://my.vault.azure.net
export AZURE_KEYVAULT_SP_CLIENT_ID=...
export AZURE_KEYVAULT_SP_CLIENT_SECRET=...
export AZURE_KEYVAULT_SP_SUBSCRIPTION_ID=...
export AZURE_KEYVAULT_SP_SUBSCRIPTION_ID=...

See the azure-keyvault documentation for other authentication options.

You will now be able to refer to Azure Key Vault secret IDs in your jenkins.yaml file:

credentials:
  system:
    domainCredentials:
      - credentials:
        - usernamePassword:
            description: &quot;GitHub&quot;
            id: &quot;jenkins-github&quot;
            password: &quot;${jenkins-github-apikey}&quot;
            scope: GLOBAL
            username: &quot;jenkinsadmin&quot;

Thanks for reading, send feedback on twitter using the tweet button in the top right, any issues or feature requests use GitHub issues.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/timja/">Tim Jacomb</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/azure">azure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/credentials">credentials</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/credential-provider">credential-provider</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/configuration-as-code">configuration-as-code</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/04/16/github-app-authentication/"><div class="header"><div class="date"><div class="month">April</div><div class="day">16</div></div><h5 class="title">GitHub App authentication support released</h5></div><p class="teaser">This blogpost was updated to reflect the general availability of the feature after the release of GitHub Branch Source 2.7.1 on April 26th, 2020.

I’m excited to announce support for authenticating as a GitHub app in Jenkins.
This has been a long awaited feature by many users.
It has been released in GitHub Branch Source 2.7.1 which is now available in the Jenkins update centers.

Authenticating as a GitHub app brings many benefits:

Larger rate limits - The rate limit for a GitHub app scales with your organization size,
whereas a user based token has a limit of 5000 regardless of how many repositories you have.

User-independent authentication - Each GitHub app has its own user-independent authentication. No more need for &#x27;bot&#x27; users or figuring out who should be the owner of 2FA or OAuth tokens.

Improved security and tighter permissions - GitHub Apps offer much finer-grained permissions compared to a service user and its personal access tokens. This lets the Jenkins GitHub app require a much smaller set of privileges to run properly.

Access to GitHub Checks API - GitHub Apps can access the the GitHub Checks API to create check runs and check suites from Jenkins jobs and provide detailed feedback on commits as well as code annotation

Getting started

Install the GitHub Branch Source plugin,
make sure the version is 2.7.1 or above.

Configuring the GitHub Organization Folder

Follow the GitHub App Authentication setup guide.  These instructions are also linked from the plugin’s README on GitHub.

Once you’ve finished setting it up, Jenkins will validate your credential and you should see your new rate limit.
Here’s an example on a large org:

How do I get an API token in my pipeline?

In addition to usage of GitHub App authentication for Multi-Branch Pipeline, you can also use app authentication directly in your Pipelines.
You can access the Bearer token for the GitHub API by just loading a &#x27;Username/Password&#x27; credential as usual,
the plugin will handle authenticating with GitHub in the background.

This could be used to call additional GitHub API endpoints from your pipeline, possibly the
deployments api or you may wish to implement your own
checks api integration until Jenkins supports this out of the box.

Note: the API token you get will only be valid for one hour, don’t get it at the start of the pipeline and assume it will be valid all the way through

Example: Let’s submit a check run to Jenkins from our Pipeline:

pipeline {
  agent any

  stages{
    stage(&#x27;Check run&#x27;) {
      steps {
        withCredentials([usernamePassword(credentialsId: &#x27;githubapp-jenkins&#x27;,
                                          usernameVariable: &#x27;GITHUB_APP&#x27;,
                                          passwordVariable: &#x27;GITHUB_ACCESS_TOKEN&#x27;)]) {
            sh &#x27;&#x27;&#x27;
            curl -H &quot;Content-Type: application/json&quot; \
                 -H &quot;Accept: application/vnd.github.antiope-preview+json&quot; \
                 -H &quot;authorization: Bearer ${GITHUB_ACCESS_TOKEN}&quot; \
                 -d &#x27;{ &quot;name&quot;: &quot;check_run&quot;, \
                       &quot;head_sha&quot;: &quot;&#x27;${GIT_COMMIT}&#x27;&quot;, \
                       &quot;status&quot;: &quot;in_progress&quot;, \
                       &quot;external_id&quot;: &quot;42&quot;, \
                       &quot;started_at&quot;: &quot;2020-03-05T11:14:52Z&quot;, \
                       &quot;output&quot;: { &quot;title&quot;: &quot;Check run from Jenkins!&quot;, \
                                   &quot;summary&quot;: &quot;This is a check run which has been generated from Jenkins as GitHub App&quot;, \
                                   &quot;text&quot;: &quot;...and that is awesome&quot;}}&#x27; https://api.github.com/repos/ / /check-runs
            &#x27;&#x27;&#x27;
        }
      }
    }
  }
}

What’s next

GitHub Apps authentication in Jenkins is a huge improvement.  Many teams have already started using it and have helped improve it by giving pre-release feedback. There are more improvements on the way.

There’s a proposed Google Summer of Code project: GitHub Checks API for Jenkins Plugins.
It will look at integrating with the Checks API,
with a focus on reporting issues found using the warnings-ng plugin
directly onto the GitHub pull requests, along with test results summary on GitHub.
Hopefully it will make the Pipeline example below much simpler for Jenkins users :)
If you want to get involved with this, join the GSoC Gitter channel
and ask how you can help.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/timja/">Tim Jacomb</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/github">github</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/github-branch-source">github-branch-source</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/04/30/jenkins-is-the-way/"><div class="header"><div class="date"><div class="month">April</div><div class="day">30</div></div><h5 class="title">Call for User Stories - Jenkins is the Way</h5></div><p class="teaser">One of the things we loved about going to developer conferences was meeting Jenkins users — newbies and old-timers alike — who are excited to talk about their projects and share tips on how to move forward using Jenkins.
Since the coronavirus pandemic, we’re learning to rely more on new ways to gather, and it’s happening via Jenkins online meetups, GitHub collaborations, and Twitter threads, to name a few.

It’s a significant change.
But what hasn’t changed is the need to share stories about the things users have built, the solutions they’ve developed, and the excellent results they’re getting from some really innovative Jenkins implementations.
Then we wondered, why isn’t anyone collecting these user stories and sharing them with the Jenkins community.

Introducing Jenkins is the Way

So we took the first step to record and archive all the great stuff everyone in our community is building with Jenkins.
This way, Jenkins users old and new can come to an archive and search for Jenkins solutions for inspiration.
We foresee a vast library of solutions from all around the world, solving a wide array of challenges in every industry imaginable.
We decided to call this archive &quot; Jenkins Is The Way&quot; and host it at https://JenkinsIsTheWay.io.

To aggregate all these stories, we built a simple online questionnaire so that Jenkins users can submit their own experience using this leading open source automation server.
With so many plugins to support building, deploying, and automating your projects, we expect to see a vast collection of stories.

We’ve already received a handful, including stories that illustrate how Jenkins Is The Way :

to code your own release pipelines

to cast magic of continuous delivery

to understand and simplify your software lifecycle

to accelerate automation in the cloud

to facilitate day-to-day work

Add your story. Show your Jenkins pride. Get our T-shirt

Be an inspiration to the Jenkins community by sharing your Jenkins story.
Just go to this link and fill out the form.
We’ll ask you about your project’s goals, the technical challenges you overcame with Jenkins, and the solutions you created.
It should take no more than 20-30 minutes to complete.

We’ll clean it up for clarity and publish it on https://JenkinsIsTheWay.io.

Once it’s part of our archive, we’ll send you our new 2020 Jenkins Is the Way t-shirt.

And since the more, the merrier, please share this blog post with peers and colleagues.
We want to hear everyone’s stories about the clever ways Jenkins is used to automate all that we need to do.

Thanks and Acknowledgement

Special thanks to abConsulting for creating and managing the https://JenkinsIsTheWay.io site and for reviewing, editing, and publishing the submitted stories.

Thanks to the Jenkins Advocacy and Outreach SIG for their reviews and feedback.

Thanks also to CloudBees for sponsoring the &quot; Jenkins is the Way&quot; program.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a>, <a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/advocacy-and-outreach">advocacy-and-outreach</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-is-the-way">jenkins-is-the-way</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/05/06/docker-agent-image-renaming/"><div class="header"><div class="date"><div class="month">May</div><div class="day"> 6</div></div><h5 class="title">Docker images for agents: New names and What&#x27;s next</h5></div><p class="teaser">We would like to announce the renaming of the official Docker images for Jenkins agents.
It does not have any immediate impact on Jenkins users, but they are expected to gradually upgrade their instances.
This article provides information about the new official names, upgrade procedure, and the support policy for the old images.
We will also talk about what’s next for the Docker packaging in Jenkins.

New image names

jenkins/agent is the new name of the old jenkins/slave image,
starting from 4.3-2

jenkins/inbound-agent is the new name of the jenkins/jnlp-slave image,
starting from 4.3-2

jenkins/ssh-agent is the new name of the old jenkins/ssh-slave image,
starting from 2.0.0

See the upgrade guidelines below.

Why?

The &quot;slave&quot; term is widely considered inappropriate in open source communities.
It has been officially deprecated in Jenkins 2.0 in 2016, but there are remaining usages in some Jenkins components.
The jira:JENKINS-42816[Slave to Agent renaming leftovers] EPIC tracks cleanup of such usages.
Official Docker agent images were a glaring case, it was not easy to fix that with the previous versions of the image release Pipelines on DockerHub.
It is great to have the image naming issue finally fixed by this update.

Another notable change is replacing the JNLP agent term with inbound agent.
Historically &quot;JNLP&quot; has been used as a name of Remoting protocols.
JNLP stands for Java Network Launch Protocol which is a part of the Java Web Start.
Jenkins supports Java Web Start mode for agents when running agents on Java 1.8,
but our networking protocols are based on TCP and have nothing to do with Java Network Launch Protocol.
This name has been very confusing since the beginning
and became worse with the introduction of WebSocket support in Jenkins 2.217 (jep:222[]).
Docker agent images support WebSockets, so we decided to change the image name to jenkins/inbound-agent so that it prevents further confusion.
Inbound agent term refers to agent protocols in which the agent initiates the connection to the Jenkins controller through different protocols.

Thanks a lot to Alex Earl and krufab for the repository restructuring groundwork which made the renaming possible!
Also thanks to Tim Jacomb, Marky Jackson, Mark Waite, Ivan Fernandez Calvo and other contributors for their reviews and testing.

Upgrading and Compatibility Notes

Good news, there are no breaking changes caused by this renaming.
All images have been already modified to use the new terminology internally.
If you use the recent versions of the previous images,
you can just replace the old names with the new ones.
These names may be referenced in your Dockerfiles, scripts, and Jenkins configurations.

We will keep updating the old images on DockerHub for at least 3 months (until August 05, 2020).
There will be no new configurations and platforms added to the old images,
but all existing ones will remain available (Debian for Java 1.8 and 11, Alpine for Java 1.8, etc.).
After August 05, 2020, the old images will no longer receive updates, but previous versions will remain available to users on DockerHub.

What’s next?

We will continue renaming of the Docker images in Jenkins components which reference old image names.
There is also a set of convenience Docker images which include build tools like Maven or Gradle which will be renamed later.
The jenkins/ssh-agent image might be renamed again in the future as well;
see the ongoing discussion in this developer mailing list thread.

If you are rather interested in new features in Jenkins Docker packaging,
stay tuned for future announcements!
There are multiple ongoing initiatives which you can find on the public Jenkins roadmap
(in the draft stage, see jep:14[]).
Some stories:

General availability of Windows images.

Support for more platforms (AArch64, IBM s390x, PowerPC).

Switching to AdoptOpenJDK.

Introducing multi-platform Docker images.

If you are interested in any of these projects and would like to contribute,
please reach out to the Platform Special Interest Group which coordinates initiatives related to Jenkins in Docker.

Regarding the agent terminology cleanup outside Docker images,
we will keep working on this project in the Advocacy &amp; Outreach SIG.
If you see the usage of the obsolete &quot;slave&quot; term anywhere in the Jenkins organization (Web UI, documentation, etc.),
please feel free to submit a pull request or to report an issue in the jira:JENKINS-42816[Slave to Agent renaming leftovers] EPIC.
There are &quot;just&quot; 3000 occurences left in the jenkinsci GitHub organization, but we will get there.
Any contributions will be appreciated!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/05/11/docker-windows-agents/"><div class="header"><div class="date"><div class="month">May</div><div class="day">11</div></div><h5 class="title">Windows Docker Agent Images: General Availability</h5></div><p class="teaser">We would like to announce the availability of official Windows agent images for Docker.
These images allow provisioning Jenkins agents with Windows OS on Docker and Kubernetes.

New images

All official Docker images for agents now provide nanoserver-1809 and windowsservercore-1809 tags which include Windows images and, at the moment, Java 8 (these are like the latest tag).
We also provide tags with explicit Java selection, e.g. jdk8-windowsservercore-1809 or jdk11-nanoserver-1809.
Version tags are also available, e.g. jenkins/agent:4.3-4-jdk8-nanoserver-1809.

jenkins/agent is a basic agent which bundles the agent.jar for agent ⇐ ⇒ controller communication. This is most useful as a base image for other images.
Windows images are available starting from version 4.3-4

jenkins/inbound-agent is an agent that is based on the jenkins/agent image above. It provides a wrapper script written in PowerShell to help specify the parameters to agent.jar.
Windows images are available starting from version 4.3-4

jenkins/ssh-agent is an image which has OpenSSH installed and should be used with the SSH Build Agents Plugin.
Windows images are available starting from version 2.1.0

Using Windows Docker images

To use the new images, you will need a proper Docker or Kubernetes environment which supports running Windows containers.
For Windows desktop users, the easiest way is to use Docker for Windows.
Windows support in Kubernetes is documented here.

jenkins/agent

The jenkins/agent image is a simple agent with the JDK and the agent.jar (Jenkins Remoting library).

There are two main use cases for this image:

As a base image for other Docker images (e.g., FROM jenkins/agent:jdk8-nanoserver-1809 in your Dockerfile). The jenkins/inbound-agent is based on this image.

This image may also be used to launch an agent using the Launch method of Launch agent via execution of command on the master.  This allows the controller to launch the agent inside the docker container automatically.

To run the agent for the second use case, you would specify the following command on the Jenkins controller after setting Remote root directory to C:\Users\jenkins\agent :

docker run -i --rm --name agent --init jenkins/agent:jdk8-windowsservercore-1809 java -jar C:/ProgramData/Jenkins/agent.jar

jenkins/inbound-agent

The inbound-agent Docker image tries to provide a higher level interaction with the agent.jar executable. It provides a PowerShell wrapper script around agent.jar and it is specified as the entrypoint so that you just need to pass in some command line arguments to run the agent. A pull request has been opened which documents these command line parameters and environment variables.

Example:

docker run jenkins/inbound-agent:windowsservercore-1809 `
   -Url http://jenkins-server:port `
   -WorkDir=C:/Users/jenkins/Agent `
   -Secret `
   -Name

Example using environment variables:

docker run -e &quot;JENKINS_URL=http://jenkins-server:port&quot; -e &quot;JENKINS_AGENT_NAME=AGENTNAME&quot; `
   jenkins/inbound-agent:windowsservercore-1809 `
   -WorkDir=C:/Users/jenkins/Agent `
   -Secret `
   -Name

The -Url, -Name and -Secret parameters are required, but can be specified as either command line parameters or environment variables.

jenkins/ssh-agent

As mentioned above the jenkins/ssh-agent docker image is based on SSH communication with the controller, rather than the remoting TCP or WebSocket protocols. The image sets up a jenkins user and the OpenSSH server so that the controller can connect to the agent via SSH. The image expects an SSH public key as a parameter and puts that key into the authorized_keys file for the jenkins user. The private key should be specified in the agent configuration on the controller to allow the controller to connect.

Example:

docker run jenkins/ssh-agent:jdk8-windowsservercore-1809 &quot;&quot;

You can also pass the public key as an environment variable when using docker run.

Example:

docker run -e &quot;JENKINS_AGENT_SSH_PUBKEY=&quot; jenkins/ssh-agent:jdk8-windowsservercore-1809

You will then be able to connect this agent using the SSH Build Agents Plugin as &quot;jenkins&quot; with the matching private key.

What’s next?

We are considering providing versions based on Windows Server 2019 build 1909 so that Jenkins users can run these images on GKE clusters (see this issue).

We are also looking into providing multiarch manifests which would allow Windows images to be part of the latest tag.

There is also an open pull-request to create a Windows based Docker image for a Jenkins controller. There hasn’t been a lot of requests for this, but to make the offerings complete for Windows users, the pull request was created.

For plans unrelated to Windows, please see the Docker images for agents: New names and What’s next blogpost.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/slide_o_mix/">Alex Earl</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/05/12/uiux-hackfest-announcement/"><div class="header"><div class="date"><div class="month">May</div><div class="day">12</div></div><h5 class="title">Join us for online UI/UX hackfest on May 25-29!</h5></div><p class="teaser">This event is over, thanks a lot to all contributors!
Please the event page for results.

On behalf of the Jenkins User Experience, Documentation and Advocacy and Outreach special interest groups,
we are happy to announce the online UI/UX hackfest on May 25-29!
Everyone is welcome to participate, regardless of their Jenkins development experience.

The goal is to get together and work on improving Jenkins user experience,
including but not limited to user interface and user documentation.
We also invite you to share experiences about Jenkins and to participate in UX testing.
The event follows the Jenkins is the Way theme and the
most active contributors will get special edition swag and prizes!

Event plan

This hackfest is NOT a hackathon.
We do not expect participants to dedicate all their time during the event timeframe, but hop-in/hop-out as their time allows.
Everybody can spend as much time as they are willing to dedicate.
Spending a few days or just a few hours is fine, any contributions matter regardless of their size.
Jenkins development experience is not required,
we have newcomer-friendly stories for those who want to start contributing to the project.
We will also have a 24/7 jenkinsci/hackfest Gitter chat for Q&amp;A and coordination between contributors.

There will be 3 main tracks :

User Interface -
Improve look&amp;feel and accessibility for Jenkins users,
work on new read-only interface for instances managed with configuration as code,
create and update Jenkins themes,
and many other topics.
This track is coordinated by the UX SIG.

User Documentation -
Improve and create new user documentation, tutorials and solution pages.
Also, there is ongoing documentation migration from Wiki to jenkins.io and plugin repositories.
This track is coordinated by the Documentation SIG.

Spread the word -
Write user stories for Jenkins Is The Way site and the Jenkins blog,
post about your Jenkins user experience and new features,
record overview and HOWTO videos, etc.
This track is coordinated by the Advocacy and Outreach SIG.

We are working on publishing project ideas and issues for the listed tracks.
The current list can be found on the UI / UX hackfest event page,
this list will be finalized by the beginning of the hackfest.
You are welcome to propose your own projects within the User Experience theme.

During the event, we will organize online meetups and ad-hoc training sessions in different timezones.
All these sessions will be recorded and shared on our YouTube channel.
There are no mandatory sessions you must attend, you are welcome to join ones remotely or watch the recordings.
After the event we will invite participants to demo their projects at online meetings or recorded sessions.

Registration

This event is over, thanks a lot to all contributors!

P.S: Note that the registration form has a question top 3 things we could change in Jenkins to improve your user experience.
We would appreciate your response there!

Contacts

Please use the following contacts to contact organizers:

Gitter chat

Mailing list

Resources

Event Page

Registration form.

Project ideas (work-in-progress).
The full list will be published by the beginning of the event.

Frequently Asked Questions

Contributing to Jenkins

Code of Conduct

Swag and Prizes

Thanks to our sponsors ( CloudBees, Inc. and Continuous Delivery Foundation),
we are happy to offer swag to active contributors!

50 most-active contributors will get an exclusive &quot;Jenkins Is The Way&quot; T-shirt and stickers

Active contributors will get Jenkins stickers and socks

We are working on special prizes for top contributors, to be announced later

Acknowledgements

We thank all contributors who participate in this event as committers!
We especially thank all reviewers, organizers and those who participated in the initial program reviews and provided invaluable feedback.
In particular, we thank User Experience, Documentation and Advocacy and Outreach SIG members who heavily contributed to this event.

We also thank sponsors of the event who make the swag and prizes possible:
CloudBees, Inc. and
Continuous Delivery Foundation (CDF).
In addition to swag, CloudBees donates working time for event hosts and reviewers.
CDF also sponsors our online meetup platform which we will be using for the event.

.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ui">ui</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/advocacy-and-outreach">advocacy-and-outreach</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-is-the-way">jenkins-is-the-way</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/05/25/read-only-jenkins-announcement/"><div class="header"><div class="date"><div class="month">May</div><div class="day">25</div></div><h5 class="title">Read-only Jenkins Configuration</h5></div><p class="teaser">I’m excited to announce that the &#x27;read-only&#x27; Jenkins feature is now available for preview.
This feature allows restricting configuration UIs and APIs while providing access to essential Jenkins system configuration, diagnostics, and self-monitoring tools through Web UI.
Such mode is critical for instances managed as code, e.g. with Jenkins Configuration-as-Code plugin.
It is delivered as a part of the jep:224[Readonly system configuration] effort.

You will want to use at least Jenkins 2.238 to have all the features mentioned in this post.

Read-only Jenkins currently allows users to have access to:

job configuration

system configuration

plugin manager

system logs

cloud configuration

agent configuration

agent logs

For more planned integrations see the jira:JENKINS-12548[] epic.

Read-only Jenkins is split into three permissions:

Job/ExtendedRead - Read-only access to job configurations

existed since 2009 but the UI didn’t do anything to indicate to the users
that they couldn’t edit the job configuration page.
This has now been adapted to the new read-only engine.

Agent/ExtendedRead - Read-only access to agent configurations

existed since 2013 but it was undocumented and only allowed access to API and no UI

UI support added in Jenkins 2.238

Overall/SystemRead - Read-only access to Jenkins system configuration.
It is very useful for Jenkins instances managed as code, e.g. with help of the Jenkins Configuration as Code Plugin.

Introduced in Jenkins 2.222 as a part of jep:224[Readonly system configuration]

You can selectively grant the permission(s) as you wish.

Why do I want this?

Given the rise of the configuration-as-code plugin a lot of Jenkins instances are fully managed as code,
which means that no changes are allowed through the UI.

The problem with this is you don’t know when new plugin versions are available and in order to see what other configuration options are available to a plugin you currently need the &#x27;Administer&#x27; permission.

Read-only access to system administration information allows users who are not administrators to more easily debug build issues.
For example, given a &#x27;Jenkins&#x27; error message in a build the user can check:

which plugins are installed

the version of the plugin

This can allow the user to solve their issue themselves and makes it easier for the user to report an issue with a plugin directly to the maintainers.

What can I expect

All built in UI controls have been adapted to clearly distinguish between
an editable control and a control you don’t have permission to edit:

Editable:

Non editable:

Note: there are other controls such as in the credentials and pipeline plugins that have
not been updated yet.

Action buttons, (Such as &#x27;Save&#x27; and &#x27;Apply&#x27;) have been hidden in most cases.

Work will continue on read-only configuration.  Some plugins need support added and certain controls
could have some improvements done to render better.

How can I use it?

These permissions are currently available in beta and for now disabled by default.
You can enable them by installing the Extended read permission plugin v3.2 or above.

Then you will need to add the following permissions to a user / group depending on your use case:

Overall/SystemRead

Job/ExtendedRead

Agent/ExtendedRead

Note: You will need to set the Overall/Read and Job/Read permissions as well.  You might
want to consider creating a role containing the required permissions.

Here is an example using the Configuration as Code plugin and the Folder-based Authorization Strategy plugin :

jenkins:
  authorizationStrategy:
    folderBased:
      globalRoles:
        - name: &quot;admin&quot;
          permissions:
            - id: &quot;Overall/Administer&quot;
          sids:
            - &quot;admin&quot;
        - name: &quot;global read&quot;
          permissions:
            - id: &quot;Agent/ExtendedRead&quot;
            - id: &quot;Overall/SystemRead&quot;
            - id: &quot;Overall/Read&quot;
            - id: &quot;Job/Read&quot;
            - id: &quot;Job/ExtendedRead&quot;
          sids:
            - &quot;reader&quot;

I can’t see a configuration that I think should be allowed

Most of Jenkins itself has been updated to support read-only Jenkins, but not very many plugins.
Please create an enhancement issue on the plugins issue tracker.
If the plugin uses Jira to track issues, then you can add it to the jira:JENKINS-12548[] epic.

How do I update my plugin to support it

See the Read only view section of the developer documentation.

What’s next

In this release we introduce a foundation feature which is already supported in all key Jenkins core controls and in some plugins.
There are many plugins which contribute to global configurations and diagnostics which still need to be adapted to support the new mode.
We will keep working on this feature and its adoption so that the next LTS baseline in September provides a full-fledged user experience for Jenkins admins.

System read permission is a featured project in the UI/UX Hackfest
happening May 25-29 2020. If you want to get involved please check it out!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/timja/">Tim Jacomb</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/system-read">system-read</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/extended-read">extended-read</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/configuration-as-code">configuration-as-code</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/03/machine-learning-plugin-community-bonding/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 3</div></div><h5 class="title">Machine Learning Plugin project - community bonding blog post</h5></div><p class="teaser">Hello everyone !

This is one of the Jenkins project in GSoC 2020. We are working this new Machine Learning Plugin for this GSoC 2020.
This is my story about the community bonding of GSoC 2020. I am happy to share my journey with you.

Introducing Myself and my Fantastic 4 Mentors

I am Loghi Perinpanayagam from University of Moratuwa. I was selected for GSoC 2020 for Machine Learning Plugin in Jenkins. I am glad to introduce my mentors to this project. I was assigned with four mentors who are really enthusiastic to help me on kicking off this summer of code.

Student

Loghi Perinpanayagam

Mentors

Bruno P. Kinoshita

Ioannis Moutsatsos

Marky Jackson

Shivay Lamba

How was my preparation last year ?

I learned about this open source program in my second year. But atleast I tried last year on a different organization’s project that was related to Data Visualization Recommendation for Data Science. But the problem was I did not contribute as much as this year and was too late in the application process. As usual Machine learning related projects have a lot of competition compared to other projects. I prepared on learning Data visualization in Machine Learning and existing Models for the recommendation system. Finally I wrote a proposal with the SeqToSeq model without much knowledge on neural networks at that time. And I did not communicate much through the dedicated slack channel.  That may be one of the reasons for the failure. But the main reason was my latency for GSoC 2019.

How did I hurdle GSoC 2020 ?

Since the time I realized how open source is needed and helpful for the community, I have been passionate about contributing to open source projects. At the instance, I finished my internship in Bangalore, India in 2019, I immediately focused on participating in GSoC. This is my last year (2020) as a student of my BSc Computer Science life, I wanted to get selected this year as a student.

There was a guidance seminar organized by our department, I got to know that Jenkins had opened their project ideas. That was an extremely impressive beginning of my GSoC 2020 journey. I walked through all the draft and accepted projects in the Jenkins.io page. As I am already interested in Machine Learning and I am familiar with Java, I picked the most impressive idea for me that does not have an initial repo. That means I wanted to use my knowledge to think and research a lot with this project. But I had to contribute and want to know about the infrastructure of Jenkins codebase. Because that makes the selection panel easy to pick up the student for the project.  Then I repeatedly searched to contribute to Jenkins. I found issues that were easy for me to work from the git plugin and git client plugin. I started to contribute some test issues on git plugin and git client plugin. After I got a clear knowledge on how a plugin works in Jenkins, I started working on the POC with the hint provided in the project idea page. Actually, that was fun to code.

Mentors have helped many students during the application process. I was able to do a working POC that had a minimum capability to do the task of the project. Finally mentors opened for proposal submission. I hurried to prepare a draft proposal. After I got reviews from mentors, I started to improve the proposal. At the end of the proposal submission, I was able to deliver a good proposal for this project. As I was curious about this plugin, I dug into more on how to integrate Jupyter notebook with this plugin. I published an medium article as a result of my research during the acceptance waiting period.

Results released

The result was going to be announced on 4th May, I believed in my project proposal and POC and I got selected for this GSoC 2020. Whoa ! That was a goosebumping moment in my entire life. The feeling was like Something I achieved. As a result of my hard work, I deserved that.
For example, I spent 7 days continuously making the POC work without any collision between maven artifacts.

Community Bonding

After the release of results, I was preparing myself for the community bonding. There are lots of interactions happening between me and mentors than before.I had to update my project page and my profile in Jenkins.io. We had our first meeting with lots of excitement and love on 10th of May. Mentors and I introduced ourselves even though we know each other. We discussed the high level view of GSoC and I asked some questions that I had in my mind. As my plugin was a new repository, most of the discussion was related to the repository and its name. I had  to find a name for the new plugin. We had regular conversations about the blogpost and presentations at the end.

In the second meeting, We discussed the process for hosting a new plugin in Jenkins, tracking issues with JIRA, blog posts and high level road map for the project. And I suggested some interesting plugin names but they were not matching to the goal of the project, mentors told me to try other names which perfectly describe the project. I was advised to read all the research guidelines and plugin naming conventions. We discussed how code reviews will be done and source code management through the git. After this meeting, our meeting has shifted to the official Jenkins Zoom account.

Our third meeting was quite serious about our project planning. I had been preparing my design document for the project with the help of mentors before the meeting day. Hence I got lots of reviews and useful examples for my future work on phase 1. At this point, we decided with the plugin name Machine Learning Plugin which was accepted by all mentors and I created the repo and requested a Jira ticket for the plugin hosting request. We were planning to remind the Jira ticket within the next 3 days. Mentors want me to make sure I updated the Jenkins GSoC page before the community period ends. Lots of discussion carried about the design document that I had been preparing last week before the meeting. Some important points from the meeting notes follows :

Define features in the design document

Diagrams for the operations

How plugin works in distributed environment

Code editor library

Requirements for the first Plugin release

Blog post draft document

ToDo works for me for next week

Therefore, I had to work hard after this meeting, this made me involved in the project more. I have to put my huge effort to make this opportunity golden. Our team has the willingness to complete this project and will definitely help the Data Science community with this plugin.
Kudos to my team for the amazing work so far!!!

This was my entire journey until now. Hope you enjoyed it and hope you learned the mistakes I made last year and corrected in this summer.
Thanks for reading, and Stay tuned I will be uploading blog posts for those of you interested.

Resources and Links

Project page

Design document<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/loghijiaha/">Loghi Perinpanayagam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/machinelearning">machinelearning</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/datascience">datascience</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/communitybonding">communitybonding</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/08/hackfest-docs-results/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 8</div></div><h5 class="title">Jenkins User Experience Hackfest Documentation Results</h5></div><p class="teaser">Documentation is not glamorous, but it is goodness.

— Thomas Otter

Jenkins technical documentation is an important part of our project as it is key to using Jenkins well.
Good documentation guides users and encourages good implementation choices.
It is a crucial part of the user experience.

In the recent Jenkins UI/UX hackfest, documentation was a specific track to improve the Jenkins user experience.
We received many improvements from experienced Jenkins contributors and newcomers alike.
Contributors from all around the world submitted pull requests for documentation on installing, managing, administering, and operating Jenkins.

Documentation migration from Wiki

The Jenkins Wiki pages have collected 15 years of experience and wisdom for Jenkins users.
However, that experience and wisdom is intermixed with inaccurate, incomplete, and outdated information.

The Jenkins Wiki migration project identified the 50 most accessed pages on the Jenkins wiki and created GitHub issues to track the migration of those pages to www.jenkins.io.
This was our first large scale experiment using GitHub issues for documentation.
The results have been overwhelmingly positive.
Hackfest contributors added new sections to many documentation chapters, including:

Using Jenkins

Pipeline

Managing Jenkins

System Administration

The Hackfest closed 19 of the wiki migration issues.
Work is in progress on an additional 25 wiki migration issues.
We’ve made great progress and look forward to even better results in the future.
New contributors used the &quot;good first issue&quot; label very effectively.
We started the Hackfest with most of the 25 &quot;good first issues&quot; unassigned and completed the Hackfest with 14 closed and 10 others in progress.
We’ll provide more &quot;good first issues&quot; as we use the Jenkins Wiki migration to welcome new documentation contributors.

Migrating plugin documentation

Plugin documentation is also in transition.
Since November 2019, plugins have been moving their documentation into the GitHub repository that hosts the plugin source code.
This&quot;documentation as code&quot; approach allows plugin maintainers to include documentation improvements in the same pull requests that implement new capabilities.
It assures that documentation changes are reviewed by the same maintainers who review and approve new capabilities.

Hackfest participants submitted pull requests to migrate plugin documentation to GitHub.
10 plugin pull requests are in progress from the Hackfest.
5 plugin pull requests from the Hackfest have been already merged and are awaiting the release of the plugin.

Chuck Norris uses documentation as code

In the spirit of fun and adventure, Oleg Nenashev migrated the &quot;Chuck Norris plugin&quot; to GitHub documentation as code in a live Hackfest presentation May 26, 2020.
Links to the recording, the plugin migration guide, and the export tool are available from&quot;Migrating plugins to documentation-as-code&quot;.

Documentation updates

Jenkins works with other technologies to solve automation challenges in many different environments.
We describe those environments in our&quot;Solution Pages&quot;.
As part of the Hackfest, we’ve started a series of improvements to the solution pages.

The Docker solutions page now includes updated videos and a better page layout for easier reading and better navigation.
Other solution pages will receive similar improvements in the future.

System properties

The global configuration of Jenkins can be modified at startup by defining Java properties.
System properties can change system defaults and can provide compatibility &quot;escape hatches&quot; when a new default configuration might be incompatible with existing installations.

Daniel Beck has improved the navigation and user experience of the system properties page as part of the Hackfest.
It is now much easier to read and to reference, with embeddable links available with a mouse-over to the right of every property and labels that categorize and classify each property.

Plugin site improvements

During the Hackfest, Gavin Mogan has continued his efforts to improve the Jenkins Plugins Site so that users can easily access plugin changelogs and reported issues.
Once this pull request is merged, it will greatly improve the experience of those Jenkins users who want to update plugins and look for documentation about what has changed in them and what are the possible issues they might experience.

Example of the incoming UI for the Jira plugin:

What’s next?

There is still much to do in Jenkins documentation and we need your help to do it.
There are many ways to participate in the Jenkins project, including documentation.
See the contributing guidelines for detailed instructions.
Join the documentation chat for personalized help and encouragement.

The Jenkins project has been also accepted to Google Season of Docs this year.
This open-source mentorship program brings together open source and technical writers communities for the benefit of both.
We are looking for technical writers who are interested to contribute to the project in September-December 2020.
It is a great opportunity to study Documentation-as-code tools and to learn more about contributing to open-source projects.
You can find Jenkins project ideas and more information here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/tracymiranda/">Tracy Miranda</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-is-the-way">jenkins-is-the-way</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/17/infra-and-aws-donation/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">17</div></div><h5 class="title">Jenkins Infrastructure: Stats, Updates, and AWS sponsorship</h5></div><p class="teaser">The Jenkins project relies heavily on its infrastructure.
We use websites like www.jenkins.io and plugins.jenkins.io, ticketing systems like issues.jenkins.io, CI/CD infrastructure like ci.jenkins.io, and many other services.
Just to provide some context about the Jenkins infrastructure scale, here are some stats from April 2020:

Over 600 000 people visited www.jenkins.io

Over 250 000 Jenkins servers regularly checked the
Jenkins package server and the
Jenkins update server

Over 43 000 continuous integration jobs ran on ci.jenkins.io

Over 950 plugins ran their continuous integration pipelines on ci.jenkins.io

Country by country visitors to jenkins.io

The Jenkins project, as an open source project, is built and maintained by its awesome community.
Like in any organization, there are specific people who make sure that those services are always up and running.
Everyone is welcome to participate.
Infrastructure is no exception, we are always looking for new contributors to the infrastructure!

While we can’t share publicly everything like secrets and certificates,
we still try to be as transparent as possible so that everybody can understand and improve our infrastructure without having privileged access.
What better way than using Git to manage infrastructure work?

Who said GitOps?

Since the creation of the Jenkins-infra organization on GitHub in March 2008, more than 650 people have contributed to over 80 git repositories.
Those contributions make the Jenkins community what it is today.
If you can’t find something there, it probably means that some help is welcomed.

More recently, with help from Gavin Mogan, Tim Jacomb, and Alex Earl, big achievements have been possible on many fronts like automating Jenkins releases, refreshing plugins.jenkins.io, adding new agents to ci.jenkins.io, and maintaining our Kubernetes cluster.
We thank them for their help and for the infrastructure progress they have enabled.

Infrastructure at Scale

Running infrastructure at the scale the Jenkins project does is expensive and sometimes quite challenging.
We are fortunate enough to be supported by many leading companies that provide us their expertise, their products, and their support.

Recently, Amazon Web Services donated $60 000 to run Jenkins infrastructure on the AWS cloud.
We’re so grateful for their donation and for the flexibility it provides.
We’re running Linux agents with AMD64 and ARM64 architectures on AWS.
We’re using AWS cloud for our Windows agents.
The generous infrastructure donation from Amazon Web Services has increased our continuous integration capacity and broadened our platform coverage.

Our Sponsors

Major sponsors of the Jenkins infrastructure include
CloudBees,
Oregon State University Open Source Lab,
Continuous Delivery Foundation,
Red Hat,
Amazon Web Services, and
GitHub.

Additional sponsors of Jenkins infrastructure services and software include
Atlassian,
Datadog,
Fastly,
IBM.
JFrog,
Pagerduty,
Rackspace,
Sentry,
Serverion,
SpinUp,
Tsinghua University, and
XMission.

Each of these organizations support the Jenkins project in their own way.
We thank them for their contributions, their support and for their willingness to help the Jenkins community.

https://www.jenkins.io/projects/infrastructure/<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/aws">aws</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/18/terminology-update/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">18</div></div><h5 class="title">On Jenkins Terminology Updates</h5></div><p class="teaser">In 2016, the Jenkins community decided to start removing offensive terminology within the project.
The &quot;slave&quot; term was deprecated in Jenkins 2.0 and replaced by the &quot;agent&quot; term.
Other terminology was slated for review after the cleanup of the &quot;slave&quot; term which was considered as most problematic one.
In 2017, the project began tracking areas for correction.
Work has been done on renaming the SSH build agent plugin as well as gradual removal of offensive naming in services and repositories.
This year, a group of core contributors continued addressing this critical work.

The Advocacy &amp; Outreach SIG met to discuss and prioritize the continued work. The governance board has also met and there will be more information coming regarding removal of offensive terminology.
Last week we took another step towards removing offensive terminology within the project by updating previous blog posts and removing offensive terminology in old blogs, cleaning up some references in Jenkins built-in documetation and localization, etc.
The meeting minutes are available here and a recording of the meeting here
There is more work to do. The core team is working to address terms such as &quot;Master&quot;, &quot;whitelist&quot; and &quot;blacklist&quot; as well addressing git branching terminology.

We could use your help
We continue to do this much needed work and would like to remind everyone that the Jenkins project is governed by the Code of Conduct.

Sincerely,
Marky Jackson<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markyjackson-taulia/">Marky Jackson</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/opensource">opensource</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/26/ui-ux-hackfest-ui-track/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">26</div></div><h5 class="title">UI/UX Hackfest: Jenkins User Interface track highlights</h5></div><p class="teaser">In this article, I would like to share some highlights from the User Interface track of the
Jenkins UI/UX Hackfest we held on May 25..29.
This blog post has been slightly delayed by the infrastructure issues we had in the project,
but, as for improving the Jenkins UI, it is better late than never.
Key highlights from the event:

We delivered a preview of Jenkins read-only configuration.
During the hackfest we discovered and fixed many compatibility issues.

We created a new Dark Theme for Jenkins.
We also improved theming support in the core, and fixed compatibility in many plugins.

We contributed to the Jenkins UI accessibility, including UX testing and fixing the reported issues.
jira:JENKINS-62437[Configuration UI: Tables to divs migration] testing was the dominant story there.

We worked on a New Script Security approvals management UI

We had 54 contributors at the hackfest.
22 of them have contributed to the user interface track as committers, testers and reviewers:
Tim Jacomb,
Ullrich Hafner,
Raihaan Shouhell,
Sumit Sarin,
Daniel Beck,
Romén Rodríguez-Gil,
wadeck Follonier,
Runxia Ye,
Félix Queiruga,
Aytunc Beken,
Peter Jonsson,
Antonio Muniz,
Kseniia Nenasheva,
Sladyn Nuner,
Abhyudaya Sharma,
Oleg Nenashev,
Nimish Bongale,
Esther Álvarez Feijoo,
Denys Digtiar,
Slavo,
Liam Newman, and
Gavin Mogan.
Thanks to all contributors!

See the blog post below to know more about these and other user interface improvements.

Read-only Jenkins Configuration

Quick access:
demo,
feature preview announcement,
presentation materials

A read-only view of Jenkins configurations, jobs and agents is important to Jenkins Configuration-as-Code users.
It would allow them to access configuration and diagnostics information about their Jenkins instances while having no opportunity to occasionally change it.
This story is a part of the Jenkins roadmap,
and it was featured as an area for contribution during the UI/UX hackfest.

On May 25th we have released a preview for Read-only Jenkins Configuration.
Read the announcement by Tim Jacomb in this blogpost.
During the hackfest we kept testing the change and fixing compatibility in the Jenkins plugins,
including the Cloud Stats Plugin, Role Strategy Plugin, Simple Disk Usage Plugin and others.

We would appreciate feedback and testing from the Jenkins users!
See the blogpost for the guidelines.

Dark Theme

Quick access:
demo,
project repository

Dark user interface themes are very popular among developers: in IDE, communication tools, etc.
And there is an interest to have one for Jenkins.
There were a few of implementations before the hackfest, most notably camalot/jenkins-dark-stylish and a dark version of the Neo2 Theme.
These themes were difficult to maintain, and finally they were either removed or abandoned.
What if Jenkins had an official theme?

During the event a group of contributors focused on creating a new Dark Theme for Jenkins.
This effort included:

Patches to the Jenkins core which simplified development and maintenance of UI themes.
Support for CSS variables was added, as well as PostCSS processing which helps to simplify browser compatibility.

Dark Theme itself.

UI Testing and compatibility fixes in the core and multiple Jenkins plugins.

Dark theme demo with support for the development mode.

You can try out this theme starting from Jenkins 2.239.
It is available as a plugin from the Jenkins Update Center.
An example screenshot of the main page:

If you discover any Dark theme compatibility issues,
please report them here.

Jenkins Configuration UI Accessibility

Quick access:
demo,
project page

Jenkins Web UI accessibility was one of the suggested topics at the event.
We would like to make Jenkins usable by as many people as possible.
It includes multiple groups of users: people with disabilities, ones using mobile devices, or those with slow network connections.
In general, all Jenkins users would benefit from better navigation and layouts.
Some of the accessibility improvements we implemented during the event:

Added aria-labels to username &amp; password input fields

Indicate the language of the page in the footer (not merged yet)

Remove page generation timestamp from the footer

At the UI/UX hackfest the major focus was on migrating configuration pages from tables to divs
(jira:JENKINS-62437[]).
It will make them more user-friendly on narrow and especially mobile screens.
The change will also help users to navigate complex forms with multiple levels of nesting.
Our progress:

User Experience testing.
Thanks to the contributors, we discovered several compatibility issues in plugins.

Bug fixes in several plugins

A new Dockerized demo which allows to evaluate the change with a set of pre-configured plugins.

Here is an example of a job configuration page using the new layout:

We will keep working on this change in the coming weeks,
and we invite Jenkins users and Contributors to help us with testing the change!
Testing guidelines are available in the jira:JENKINS-62437[] ticket.

New Script Security approvals management UI

Quick access:
demo,
pull request

During the hackfest Wadeck Follonier redesigned the script approval interface in the Script Security Plugin.
The new UI allows viewing the list of approved scripts, shows the last access timestamp, and allows managing the approvals individually.
Before, it was not possible to do it from the Web interface.
Once the pull request is released,
the feature will become available to Jenkins users.

Other UI improvements

In addition to the major improvements listed above,
there were also many smaller patches in the Jenkins core and various plugins.
You can find a full list of contributions to the user interface here,
some important improvements:

Improved navigation in the Credentials plugin.

Support for wide screens in the Autograding plugin.

UI Improvements in the Folder-based Authorization Strategy plugin.

Improved Fingerprint listing in the Jenkins core

Contributing

We invite Jenkins users and contributors to join the effort and to improve the user interface together.
The Jenkins project gradually adopts modern frontend stacks (JavaScript, React, Gatsby, Vue.js, etc.) and design methodologies.
For example, see the presentation about beautifying the UI of Jenkins reporter plugins by Ullrich Hafner.
It is a great opportunity for frontend developers to join the project, share their experiences, experiment with new technologies, and improve the Jenkins user interface and user experience.
Join us!

See this page for more information about contributing to the Jenkins codebase.
If you want to know more, join us in the Jenkins User Experience SIG channels.

References

You can find more information about the Hackfest here:

Jenkins UI/UX Hackfest Page

UI/UX Hackfest Closing Demos

All presentations and demos

Full list of contributions to the user interface<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ui">ui</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-is-the-way">jenkins-is-the-way</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/27/external-fingerprint-storage/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">27</div></div><h5 class="title">External Fingerprint Storage Phase-1 Updates</h5></div><p class="teaser">Externalizing fingerprint storage for Jenkins is a  Google Summer of Code 2020 project.
We are working on building a pluggable storage engine for fingerprints (see jep:226[]).

File fingerprinting is a way to track which version of a file is being used by a job/build, making dependency tracking easy. The fingerprint engine of Jenkins can track usages of artifacts, credentials, files, etc. within the system. Currently, it does this by maintaining a local XML-based database which leads to dependence on the physical disk of the Jenkins controller.

Allowing fingerprint storage to be moved to external storages decreases the dependence of Jenkins instances on the physical disk space and also allows for tracking the flow of fingerprints across instances of Jenkins connected to the same external storage.

Advantages of using external storage drivers:

Remove dependence on Jenkins controller disk storage

Can configure pay-as-you-use cloud storages

Easy Backup Management

Better Reliability and Availability

Fingerprints can be tracked across Jenkins instances

Along with this API, we are also working on a reference implementation in the form of a plugin, powered by Redis.

As phase 1 of this project comes to an end, this blog post serves as a summary of the progress we made to the entire Jenkins community.

Current State

The new API introduced in Jenkins core is under review. Once merged, it will offer developers to extend it to build external fingerprint storage plugins.

The Redis Fingerprint Storage Plugin is alpha release ready. We would immensely appreciate any feedback.

External Fingerprint Storage Demo

Introducing the new API for plugin developers

With PR-4731, we introduce a new fingerprint storage API, allowing configuring custom storage engines.
We exposed the following methods in the new FingerprintStorage class:

void save()

Saves the given Fingerprint in the storage.

Fingerprint load(String id)

Returns the Fingerprint with the given unique ID. The unique ID for a fingerprint is defined by Fingerprint#getHashString().

void delete(String id)

Deletes the Fingerprint with the given unique ID.

boolean isReady()

Returns true if there is some data in the fingerprint database corresponding to the particular Jenkins instance.

Introducing Redis Fingerprint Storage Plugin

Redis Fingerprint Storage Plugin uses the new External Fingerprint Storage API to store the fingerprints in a Redis instance.

Installation:

The alpha release (version 0.1-alpha-1) for the plugin was drafted, and can be installed using the experimental update center.

Follow along the following steps after running Jenkins to download and install the plugin:

Select Manage Jenkins

Select Manage Plugins

Go to Advanced tab

Configure the Update Site URL as: https://updates.jenkins.io/experimental/update-center.json

Click on Submit, and then press the Check Now button.

Go to Available tab.

Search for Redis Fingerprint Storage Plugin and check the box along it.

Click on Install without restart

The plugin should now be installed on your system.

Usage

Once the plugin has been installed, you can configure the Redis server details by following the steps below:

Select Manage Jenkins

Select Configure System

Scroll to the section Redis Fingerprint Storage Configuration and fill in the required details:

Host - Enter hostname where Redis is running

Port - Specify the port on which Redis is running

SSL - Click if SSL is enabled

Database - Redis supports integer indexed databases, which can be specified here.

Connection Timeout - Set the connection timeout duration in milliseconds.

Socked Timeout - Set the socket timeout duration in milliseconds.

Credentials - Configure authentication using username and password to the Redis instance.

Enabled - Check this to enable the plugin (Note: This is likely to be removed very soon, and will be enabled by default.)

Use the Test Redis Connection to verify that the details are correct and Jenkins is able to connect to the Redis instance.

Press the Save button.

Now, all the fingerprints produced by this Jenkins instance should be saved in the configured Redis server!

Future Work

Some of the topics we aim to tackle in the next phases include extending the API, fingerprint cleanup, migrations (internal→external, external→internal, external→external), tracing, ORM, implementing the saveable listener, etc.

Acknowledgements

The Redis Fingerprint Storage plugin is built and maintained by the Google Summer of Code (GSoC) Team for
External Fingerprint Storage for Jenkins.

Special thanks to Oleg Nenashev, Andrey Falko, Mike Cirioli, Jesse Glick, and the entire Jenkins community for all the contribution to this project.

Reaching Out

Feel free to reach out to us for any questions, feedback, etc. on the project’s Gitter Channel or the Jenkins Developer Mailing list

We use Jenkins Jira to track issues.
Feel free to file issues under redis-fingerprint-storage-plugin component.

Other Links

Phase 1 demo

Presentation slides

Redis Fingerprint Storage Plugin

Issue Tracker for Phase 1

jep:226[]

Gitter Channel

Project Page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stellargo/">Sumit Sarin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/fingerprint">fingerprint</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/external-storage">external-storage</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/redis">redis</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/06/30/machine-learning-plugin-coding-phase1/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">30</div></div><h5 class="title">Machine Learning Plugin project - coding phase 1 blog post</h5></div><p class="teaser">Welcome back !

This blog post is briefing my coding phase 1 in Jenkins Machine Learning Plugin for this GSoC 2020.

After a fresh introduction of community bonding, On June 1st, coding of GSoC had started officially with phase 1. At this point, every GSoC student should be expected to have a rigid plan with their entire project. With the guidance of mentors I was able to complete a design document and timeline which can be slightly adjustable during the coding. The coding phase was more about coding and discussion.

Quick review

Pull Requests
21

Jira Issues
11

Major Tasks
3

Completed
3

In progress
0

Week 1

I have to ensure that I have a solid architecture for implementing the core of this plugin such that perhaps I or future community will be able to develop R and Julia kernels for this plugin. Factory method design patterns are suitable when users need different types of products ( Python, R and Julia) without knowing much about the internal infrastructure ( Manager of these interpreters ).

All the base classes were implemented this week.

Design the Kernel connectors

Initiate the interpreter

Close the connection

Add simple tests

Update pom.xml

More than these changes, repo was updated with pull request template and licence header. Readme was extended a little at the end of the week.

Issues and Challenges

Git rebase and squash

Tests invokes ipython client in the server failed during the CI build

Week 2

With the help of a design document, I had a plan to do the configurations globally and using the Abstract Folder property I could save the configuration and retrieve for the job configuartion. I used to reference some other well developed plugin for the structure of code. That helped me a lot while I was coding. Our first official contributor has popped out his pull request.

Form validations and helper html will be a great help in the user point of view as well as developers. A minor bug was fixed with the guidance of mentors by writing tests with ‘Jenkins WebClient`. Until the end of the week, builder class of the plugin has been implemented with lots of research and discussion. Finally,  Test connection was added to the global configuration page to start the connection and test it. A single issue that blocked me using py4j authentication about zeppelin-python was reported in Jira.

Server Configuration

Issues and challenges

Backend depends on Apache zeppelin-python API to connect IPython

Find relevant extension points to extend the plugin

Week 3

Earlier in this week, we were trying to merge our IPython builder PR without any memory leaks or bugs that will cause the system to be devastating while running this plugin. Later, this whole week I was implementing a file parser that could copy the necessary files and had the ability to accomplish the file conversion.

Supported file types

Python (.py)

JSON (Zeppelin notebooks format)

IPython builder was able to run Jupyter Notebooks and Zeppelin formatted JSON files at the end of the 3rd week. Minor issues were fixed in the code. We used ANSI color plugin to fix the abnormal view of error messages produced by the ipython kernel.

Copying and converting Jupyter Notebook

Issues and Challenges

Python error messages could not be displayed in rich format
If a job is running at user level, but if the python code access file/file path which is not authorized to the user, it returns a permission denied message.
While running on agent, notebook has to be written/copied to agent workspace
Artifacts should be maintained/reachable from controller after build.

Week 4

As all the major tasks has done, the demo preparation and plan for a experimental release was carried during the last week. There were lots of research on how to connect to a existing kernel in remote. Demo and presentation were prepared along the week.

Issues and Challenges

Releasing the first version was bit late

Knowledge transfer

How to debug the code through IntelliJ

Edit configuration → Add new Configuration → Maven

Command line → type hpi:run

Click the debug icon on the toolbar or go to Run menu then Debug

How to setup to test the plugin

Setup JDK 8 and Maven 3.5.*

Create a directory $ mkdir machine-learning-plugin

Create a virtual environment $ virtualenv venv

Activate your virtual environment $ source venv/bin/activate

Run $ which python to ensure your python path

$ git clone https://github.com/jenkinsci/machine-learning-plugin.git

Run $ mvn clean install from the machine-learning-plugin directory

Run $ mvn hpi:run to start Jenkins with the plugin

Set up the builder with localhost and other parameters

Create a job

Write python code like print(“plugin works”)

Build the job

Issues and bugs

JENKINS-62528 Issues on Jenkins build in the plugin repository

JENKINS-62621 Global configuration for IPython servers

JENKINS-62649 Implementation of IPython Builder

JENKINS-62711 File parser to copy source files to workspace

JENKINS-62733 Python errors are not displayed properly in console log

JENKINS-62735 Send/Receive necessary files from controller/agent to agent/controller

JENKINS-62593 Improve the documentation

JENKINS-62742 Increase Test coverage

Resources and Links

Github

Project page

Design document<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/loghijiaha/">Loghi Perinpanayagam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/machinelearning">machinelearning</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/datascience">datascience</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/communitybonding">communitybonding</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/27/custom-distribution-service/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">27</div></div><h5 class="title">Custom Distribution Service : Midterm Summary</h5></div><p class="teaser">Hello,
After an eventful community bonding period we finally entered into the coding phase. This blog post will summarize the work done till the midterm of the coding phases i.e. week 6. If some of the topics here require a more detailed explanation, I will write a separate blog post. These blogs posts will not have a very defined format but would cover all of the user stories or features implemented.

Project Summary

The main idea behind the project is to build a customizable jenkins distribution service that could be used to build tailor-made jenkins distributions. The service would provide users with a simple interface to select the configurations they want to build the instance with eg: plugins, authorization matrices etc. Furthermore it would include a section for sharing community created distros so that users can find and download already built jenkins war/configuration files to use out of the box.

Quick review

Pull Requests Opened
38

Github Issues completed
36

Details

I have written separate blog posts for every week in GSoC and the intricate details for each of them can be found at their respective blog pages. I am including a summary for every phase supported with the respective links.

Community Bonding

This year GSoC had a longer community bonding than any of the previous editions due to the Coronavirus pandemic and therefore this gave me a lot of time to explore, so I spent it by building a prototype for my project. I realised some of the blockages I might face early on, and therefore it gave me more clarity in terms of how I can proceed. I also spent this time preparing a design document which you can find here.

Community Bonding Blog

Week 1

In week one, I spent time getting used to the tech stack I would be using, I was pretty familiar with Spring Boot but React was something I was going to be using for the first time, so I spent time studying more about it. I also got the project page ready, the issues I was going to tackle and the milestones that I had to achieve before the evaluation. I also spent a bit of time setting up the home page and a bit of front-end components.

Week 1 Blog

Week 2

Once we were done with the initial setup, it was time to work on the core of the project.
In the second week, I worked on generating the package configuration and the plugin list dummy display page setup.
I also ran into issues with the Jenkinsfile so the majority of time was spent fixing it.
Finally I managed to get around those problems.
You can read more about it in the Week 2 Blog post.

Week 2 Blog

Week 3

The last week was spent cleaning up most of the code and getting the remaining milestones in. This was probably the hardest part of phase 1 because it involved connecting the front and back end of the project.You can read more about it here.

Week 3

Midterm Update

The second phase has been going on for the past 3 weeks and we have already accomplished a majority of the deliverables including community configurations, war downloading and filtering of plugins. More details about the mid term report can be found here.

Midterm Update

Getting the Code

The Custom Distribution Service was created from scratch during GSoC and can be found here on Github.

Other links

GSoC Proposal
Design Document
Daily Notes
Demo

Feedback channel

Gitter Channel Link.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sladyn98/">Sladyn Nunes</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/service">service</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/distribution">distribution</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/packaging">packaging</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/05/say-hello-blueocean-1-0/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 5</div></div><h5 class="title">Say hello to Blue Ocean 1.0</h5></div><p class="teaser">Back in May 2016 we announced our intent
to rethink the Jenkins User experience with the Blue Ocean project and today
the Jenkins project are pleased to announce the general
availability of Blue Ocean 1.0.

Blue Ocean is an entirely new, modern and fun way for developers to use Jenkins
that has been built from the ground up to help teams of any size approach
Continuous Delivery. Easily installed as a plugin for Jenkins and integrated
with Jenkins Pipeline, it is available from today for production use.

Since the start of the beta at Jenkins World 2016 in September there are now
over 7400+ installations making use of Blue Ocean. This wouldn’t be possible
without the support of the entire Jenkins developer and
user community - so thank you for your support!

Blue Ocean is available today from the update center and also as a
Docker image - why not give it a try?

Visual Pipeline Editing - Team members of any skill level can create continuous
delivery pipelines from start to finish, with just several clicks, using the
intuitive, visual pipeline editor. Any pipeline created with the visual editor
can also be edited in your favorite text editor
bringing all the benefits of Pipeline as Code.

Pipeline Visualization - Developers can visually represent pipelines in a way
that anyone on the team can understand - even your boss’s boss - improving
clarity into the continuous delivery process for the whole organization.
The visualization helps you focus on what the pipeline does, not how it does it.

Pinpoint Troubleshooting - Blue Ocean enables developers to locate automation
problems instantly, without endlessly scanning through logs or navigating
through many screens, so you can get back to building the next big thing.

GitHub and Git Integration - Pipelines are created for all feature branches
and pull requests, with their status reported back to GitHub.
The whole team has visibility into whether changes need work or are good to go.

Personalization – Every team member can make Jenkins their own by customizing
the dashboard so that they only see those pipelines that matter to them.
Favoriting any pipeline or branch in Blue Ocean will show a favourite card on
the dashboard so you can see its status at a glance.

Just one more thing – I’d like to pay special thanks to:

The Core team – to Keith Zantow, Thorsten Scherler, Tom Fennelly,
Ivan Meredith, Josh McDonald, Vivek Pandey, Brody Maclean and Cliff Meyers.
Each of and everyone of you have brought your own passion, expertise and flair
to the project – and it shows. It’s been crazy fun and I hope working on
Blue Ocean is something you look back on fondly.

Jenkins Developers past and present – we recognise that we are standing on
the shoulders of giants and none of this wouldn’t be possible without your
hard work and dedication to free &amp; open source software and Jenkins.
Here’s to the next 10 years 🍻 !

CloudBees – in particular, Sacha Labourey (CEO), Harpreet Singh
(VP of Product) and Spike Washburn (VP of Engineering) whose dedication to
Jenkins, Open Source and continued faith in the vision and team made all of
this possible, and of course Bob Bickel (Advisor) who dared us to dream big.

Michael Neale – who drank all the kool-aide and is just as obsessed with
and dedicated to Blue Ocean as I am. This project would never have shipped
without his hand steady at the tiller. I couldn’t ask for a better friend
and partner-in-crime.

Tyler Croy – for guiding the project and myself on how to do open source
The Right Way™. Tyler works tirelessly behind the scenes to to make Jenkins
awesome and it wouldn’t be possible to keep this show running without
his help and sage-like advice.

Kohsuke Kawaguchi – For creating Jenkins, getting Blue Ocean off of
the ground, his tour of Tokyo and above all, his trust.

Jenkins Users – your enthusiasm for better development tools which
kept our spirits and momentum up when the days grew long and things
looked tough. We couldn’t ask for a better, more appreciative or
passionate group of people. Hopefully we’ve done our job and you can get
back to building your next big thing!

Next stop, some well needed rest &amp; recovery then back to to making
Jenkins one of the experiences for software developers worldwide!

If you’re interested in joining us to make Blue Ocean a great user experience
for Jenkins, please join the Blue Ocean development
team on Gitter!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/i386/">James Dumay</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/03/24/jenkins-community-survey/"><div class="header"><div class="date"><div class="month">March</div><div class="day">24</div></div><h5 class="title">The State of Jenkins - 2016 Community Survey</h5></div><p class="teaser">This is a guest post by Bhavani Rao, Marketing Manager at CloudBees

Last fall, prior to Jenkins World, CloudBees conducted a
Community Survey.
We received over 1200 responses, and thanks to this input, we have some
interesting insights into how Jenkins users and their use of Jenkins are
evolving.

Based on the survey’s results, Jenkins is increasingly being used to support
continuous delivery (CD). Adoption of Jenkins 2, which featured &quot;Pipeline as code&quot; and
encouraged users to adopt Jenkins Pipeline, has
skyrocketed to more than half of all Jenkins installations.  Other data
remained consistent with findings year-to-year, for example, the number of
Jenkins users continues to increase and 90% of survey respondents still
consider Jenkins mission-critical.

Get the survey infographic PDF

Get the complete survey results in PDF

Here are some of the key findings:

85% of respondants indicated that Jenkins usage had increased

30% of organizations with more than 50 software projects used Jenkins in 2016 as compared to 16% in 2015

An impressive 46% of respondents were running Jenkins 2.x, eight months after
its release.

Adoption of Jenkins Pipeline for continuous delivery
(CD) is accelerating, 54% of respondents who have adopted CD are using Pipeline.

61% of respondents are deploying changes to production at least once per week

Linux is the platform of choice for builds, favored by 85% of respondents

85% of respondants use Git as the source code repository

Half of respondents are deploying applications directly to the cloud, with Amazon Web Services as the favored platform

We want to thank everyone for completing the survey, and congratulations to
Iker Garcia for winning a free pass to
Jenkins World 2017 and to
Dave Leifer for winning the Amazon gift card.

We’re looking forward to creating a 2017 Community Survey later this year and
hearing more from users at Jenkins World 2017 in San Francisco, we hope to
see you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/brao/">Bhavani Rao</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/survey">survey</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/continuous delivery">continuous delivery</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2017/04/05/welcome-to-blue-ocean/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 5</div></div><h5 class="title">Getting Started with Blue Ocean</h5></div><p class="teaser">This is a guest post by Liam Newman,
Technical Evangelist at CloudBees.

Welcome to Blue Ocean 1.0!

In case you’ve been heads down on other projects
for the past 10 months,
Blue Ocean is a new user experience for Jenkins,
and version 1.0 was released today!
Blue Ocean makes Jenkins, and continuous delivery, approachable to all team members.
I’ve been working with it for the past several months, and I can tell you it is amazing.
I wish all the interactions with Jenkins were as easy as this:

10 minutes to Blue Ocean

Blue Ocean is simple to install and will work on basically any Jenkins 2 instance (version 2.7 or later).
Even better, it runs side-by-side with the existing Jenkins web UI -
you can switch back and forth between them whenever you like.
There’s really no risk.
If you have a Jenkins instance and a good network connection,
in 10 minutes you could be using Blue Ocean.

Login to your Jenkins server

Click Manage Jenkins in the sidebar then Manage Plugins

Choose the Available tab and use the search bar to find Blue Ocean

Click the checkbox in the Install column

Click either Install without restart or Download now and install after
restart

After you install Blue Ocean, you can start using it
by clicking on Open Blue Ocean in the navigation bar of the
Jenkins web UI, or you can navigate directly to Blue Ocean by adding
/blue to your Jenkins URL, for example https://ci.jenkins.io/blue .

If you have to go back to the &quot;classic&quot; Jenkins UI,
there’s an &quot;exit&quot; icon located at the top of every page in Blue Ocean.

Dive in!

That’s it! You now have a working Blue Ocean installation.
Take a look around at your Pipelines and activity, or try creating a new Pipeline.
I think you’ll be pleasantly surprised at how intuitive and helpful Blue Ocean can be.
Blue Ocean is so cool, I never want to leave it.
Over the next few days, I’ll be publishing a series of videos,
showing some common Jenkins use cases and how Blue Ocean makes them clearer and easier than ever before.

Stay Tuned!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/lnewman/">Liam Newman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/blueocean">blueocean</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ux">ux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/08/winsw-yaml-support/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 8</div></div><h5 class="title">Windows Service Wrapper : YAML Configuration Support - GSoC Phase - 01 Updates</h5></div><p class="teaser">Hello all, I am Buddhika Chathuranga from Sri Lanka and I am a final year undergraduate at the Faculty of IT, University of Moratuwa. I am participating in GSoC 2020 with Jenkins.
I am working on the Windows Service Wrapper Project.
So the Coding Phase 01 of GSoC 2020 is now over and this blog post describes what I have done so far.

Windows Service Wrapper is an executable, which we can use to run applications as Windows Services on Windows machines, which has almost one million downloads.
In Jenkins, we use Windows service wrapper to run Jenkins server and agents as Windows services to gain more robustness.
This feature is bundled into Jenkins’s core. Currently, the Windows Service wrapper is configured by an XML file.
However, there is a limited number of configuration checks and there is no XML schema.

XML is not such a human-friendly way to do that. It is quite verbose and not easy to identify the schema without some effort.
Usually, users misconfigure the service wrapper. This is a sample XML configuration file that we can use to provide configurations to Windows Service Wrapper.

Sample XML Configuration File

jenkins
Jenkins
This service runs Jenkins automation server.

C:\Program Files\Java\jdk1.8.0_201\bin\java.exe
-Xrs -Xmx256m -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle
    -jar &quot;C:\Program Files\Jenkins\jenkins.war&quot; --httpPort=8081 --webroot=&quot;%LocalAppData%\Jenkinswar&quot;
rotate

%LocalAppData%\Jenkinsjenkins.pid
10000
false

The usage of YAML could simplify configuration management in Jenkins, especially when automated and configuration management tools are used.
So what we are doing under GSoC - 2020 is to update the Windows Service Wrapper to support YAML configurations.
After finishing this project, users will be able to provide configurations to the Windows Service Wrapper as a YAML file.

This is a sample YAML configuration file for Windows Service Wrapper and you can see it is less verbose than XML or JSON and much more human friendly.
Users can read and edit this without a big effort.

Sample YAML Configuration File

id: jenkins
name: Jenkins
description: This service runs Jenkins automation server.
env:
    _name: JENKINS_HOME
    _value: &#x27;%LocalAppData%\Jenkins.jenkins&#x27;
executable: &#x27;C:\Program Files\Java\jdk1.8.0_201\bin\java.exe&#x27;
arguments: &gt;-
    -Xrs -Xmx256m -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle
    -jar &quot;C:\Program Files\Jenkins\jenkins.war&quot; --httpPort=8081 --webroot=&quot;%LocalAppData%\Jenkinswar&quot;
logmode: rotate
onfailure:
    _action: restart
extensions:
    -
        pidfile: &#x27;%LocalAppData%\Jenkinsjenkins.pid&#x27;
        stopTimeout: &#x27;10000&#x27;
        stopParentFirst: &#x27;false&#x27;
        _enabled: &#x27;true&#x27;
        _className: winsw.Plugins.RunawayProcessKiller.RunawayProcessKillerExtension
        _id: killOnStartup

Advantages of YAML as a configuration file

It is less verbose and much more human friendly than XML.

Since YAML is not using extra delimiters, it is lightweight.

Nowadays YAML has become more popular among configuration management tools.

Project Scope

During this project, I will add the following features to Windows Service Wrapper.

YAML Configuration support

YAML Schema validation

New CLI for the Windows Service Wrapper

Support for XML Schema validation via XML Schema Definition (XSD)

Phase 01 Updates

In GSoC - 2020 phase 01, I have done the following updates to the Windows Service Wrapper.

Project Structure overview document. (Published)

YAML configurations support (Not released yet) - Pull Request

New CLI (Not released yet) - Pull Request

XML Schema validation (Not released yet) - Pull Request

You can find Phase 01 Demo slides in this link.

Below you can find more details about the deliverables listed above.

Project Structure overview

The project structure overview document describes how files and directories are organized in the Windows Service Wrapper project.
It will help contributors as well as users, to understand the codebase easily.
Also, it helps me a lot to understand the codebase. You can find the document from the given link.

YAML configurations support

As I explained before, in this project, configurations will be provided as a YAML file.
I used YamlDotNet library which has more than 2.2k stars on GitHub, to deserialize the YAML file into an Object graph.
In this YAML file, users can specify configurations in a more structured way than in XML configuration files.
As an example, now users can specify all the log related configurations under the log config.
Users can specify all service account related configurations under serviceaccount config etc.

At the moment, I am working on a design document for YAML configuration support. I will add it to the GitHub Issue once ready

New CLI

Before moving into Phase 01 updates, it’s better to explain why we needed a new CLI for Windows Service Wrapper.
In the early phases of Windows Service Wrapper, we will keep the XML configuration support as well.
So we should allow users to specify the configurations file separately.
The current approach is, configurations file should be in the same directory, where Windows Service Wrapper executable exists and the file name of the XML file should be the same as the Windows Service Wrapper executable file name.
Also, users should be able to redirect logs if they need to and they should be allowed to elevate command prompt using Windows Service Wrapper.
Also, we thought that it’s better to allow users to skip schema validation if they needed. So we decided to move into a new CLI.

As I explained, after releasing this, users will have options in addition to commands.
It will make the WinSW CLI more flexible so that we can easily extend it later. These are the options users are allowed to use.
These options are available with all the commands except help and version

--redirect / -r [string]

Users can specify the redirect path for the logs if needed

Not required | Default value is null

--elevated / -e [boolean]

Elevate the command prompt before executing the command

Not required | Default value is false

--configFile / -c [string]

Users can specify the configurations file as a path

Not Required | Default value is null

--skipConfigValidation / -s [boolean]

Users can skip schema validation for configurations file if needed

Not required | Default value is true

--help / -h

User can find what options are available with a particular command with this option

This option is available with the install command

--profile / -f [boolean]

If this option is true, then users can provide a service account for installation explicitly.

Not required | Default value is false

We used commandlineparser/commandline library to parse the command line argument which has more than 2k stars in GitHub. At a glance, the library is compatible with .NET Framework 4.0+, Mono 2.1+ Profile, .NET Standard, and .NET Core.

XML Schema validation

As I mentioned before, there was no schema validation for XML in Windows Service Wrapper.
Hence, I was working on schema validation for XML. I use XSD to validate XML files. The XSD file will be shipped as an embedded resource with the executable.
You can find the XSD file in my pull request.

Future updates

In the next phase, for GSoC 2020 the listed deliverables features will be released and the YAML schema validation feature will be added.
Also, we hope to publish a design document for the new features, which will help contributors.

How to contribute

You can find the GitHub repository in this link. Issues and Pull requests are always welcome.
Also, you can communicate with us in the WinSW Gitter channel, which is a great way to get in touch and there are project sync up meetings every Tuesday at 13:30 UTC on the Gitter channel.

Some useful links

Project Page

Project Repository

Gitter Channel

YamlDotNet library

Command Line Parser library<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/buddhikac96/">Buddhika Chathuranga</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/winsw">winsw</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/09/git-performance-improvement-phase1/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 9</div></div><h5 class="title">Git Plugin Performance Improvement: Phase-1</h5></div><p class="teaser">Git Plugin Performance Improvement is a Google Summer of Code 2020 project.
It aims to improve the performance of the git plugin, which provides fundamental git functionalities.

Internally, the plugin provides these functionalities using two implementations: command line git and JGit (pure java implementation).

CLI git is the default implementation for the plugin, a user can switch to JGit if needed

The project is divided into two parallel stages:

Stage 1 : Create benchmarks which evaluate the execution time of a git operation provided by CLI git and JGit using JMH, a micro benchmarking test harness.

Stage 2 : Implement the insights gained from the analysis into the plugin to improve the overall performance of the plugin.

The project also aims to fix any existing performance bottlenecks within the plugin as well.

Benchmarks

The benchmarks are written using JMH. It was introduced in a GSoC 2019 project to Jenkins.

JMH is provided within the plugin through the Jenkins Unit Test Harness POM dependency.

The JMH benchmarks are created and run within the git client plugin

During phase-1, we have created benchmarks for two operations: &quot;git fetch&quot; and &quot;git ls-remote&quot;

Results and Analysis

The benchmark analysis for git fetch:

Git fetch results

The performance of git fetch (average execution time/op) is strongly correlated to the size of a repository

There exists an inflection point on the scale of repository size after which the nature of JGit performance changes (it starts to degrade)

After running multiple benchmarks, it is safe to say that for a large sized repository CLI-git would be a better choice of implementation.

We can use this insight to implement a feature which avoids JGit when it comes to large repositories.

Please refer to PR-521 for an elaborate explanation on these results

Note: Repository size means du -h .git

Fixing redundant fetch issue

The git plugin performs two fetch operations instead of one while performing a fresh checkout of a remote git repository.

To fix this issue, we had to safely remove the second fetch keeping multiple use-cases in mind. The fix itself was not difficult to code, but to do that safely without breaking any existing use-case was a challenging task.

Further Plan

After consolidating a benchmarking strategy during Phase 1, the next steps will be:

Provide functionality to the git plugin, which enables it to estimate the size of the repository without cloning it.

Broaden the scope of benchmarking strategy

Consider parameters like number of branches, references and commit history to find a relation with the performance of a git operation

The git plugin depends on other plugins like Credentials which might require benchmarking the plugin itself and the effects of these external dependencies on the plugin’s performance

Focus on other use-cases of the plugin

For phase-1, I focused on the checkout step and the operations involved with it

For the next phase, the focus will shift to other areas like Multibranch pipelines or Organisation Folders

How can you help?

If you have reached this far of the blog, you might be interested in the project.

To help, you can

Review the benchmarks in the benchmarks module

Analyse the benchmarks results available on ci.jenkins.io [soon]

Come visit our Gitter channel: https://gitter.im/jenkinsci/git-plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rishabhbudhouliya/">Rishabh Budhouliya</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/git">git</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/09/github-checks-api-plugin-coding-phase-1/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day"> 9</div></div><h5 class="title">GitHub Checks API Plugin Project - Coding Phase 1</h5></div><p class="teaser">This blog post is about our coding phase 1 progress on GSoC project: GitHub Checks API Plugin.

The GitHub Checks API is a highly customized way to integrate CI tools to make reports for pull-requests (PRs).
It allows users to see CI reports on GitHub pages directly.

Figure 1. GitHub Check Run Screenshot from GitHub Docs

What’s more exciting is that it can leave annotations on specific lines of code, just as the comments people left while reviewing.

Figure 2. Check Run Annotation Screenshot from GitHub Docs

While on Jenkins&#x27; side, the source code view provided by Warnings Next Generation Plugin does pretty much the same thing.

Figure 3. Source Code View from Warnings Next Generation Plugin

Utilizing such features through GitHub Checks API, it would make Jenkins more convenient to GitHub users.

Features from Coding Phase 1

In the past month, our team was mostly working on the general checks API and an implementation for GitHub checks API.

GitHub Checks API Plugin Demo [starts from 50:15]

General Checks API

Although the general checks API is developed based on the semantic meaning of GitHub Checks API, we still want to prepare it for similar concepts on other platforms like Commit Status API from GitLab.
Contributions for implementations on these platforms will be welcomed in the future.

GitHub Checks API Implementation

Our work on supporting GitHub Checks API is mostly done by now.
Besides, we implemented a consumer to automatically create a check run that simply indicates the current stage of a Jenkins build.
After the release, Jenkins developers (especially publisher plugin ones) can create their own GitHub checks for a GitHub branch source project by consuming our API.

Example: To create a check run like:

Consumers need to use our API in this way:

ChecksDetails details = new ChecksDetailsBuilder()
        .withName(&quot;Jenkins&quot;)
        .withStatus(ChecksStatus.COMPLETED)
        .withDetailsURL(&quot;https://ci.jenkins.io&quot;)
        .withStartedAt(LocalDateTime.now(ZoneOffset.UTC))
        .withCompletedAt(LocalDateTime.now(ZoneOffset.UTC))
        .withConclusion(ChecksConclusion.SUCCESS)
        .withOutput(new ChecksOutputBuilder()
                .withTitle(&quot;Jenkins Check&quot;)
                .withSummary(&quot;# A Successful Build&quot;)
                .withText(&quot;## 0 Failures&quot;)
                .withAnnotations(Arrays.asList(
                        new ChecksAnnotationBuilder()
                                .withPath(&quot;Jenkinsfile&quot;)
                                .withLine(1)
                                .withAnnotationLevel(ChecksAnnotationLevel.NOTICE)
                                .withMessage(&quot;say hello to Jenkins&quot;)
                                .withStartColumn(0)
                                .withEndColumn(20)
                                .withTitle(&quot;Hello Jenkins&quot;)
                                .withRawDetails(&quot;a simple echo command&quot;)
                                .build(),
                        new ChecksAnnotationBuilder()
                                .withPath(&quot;Jenkinsfile&quot;)
                                .withLine(2)
                                .withAnnotationLevel(ChecksAnnotationLevel.WARNING)
                                .withMessage(&quot;say hello to GitHub Checks API&quot;)
                                .withStartColumn(0)
                                .withEndColumn(30)
                                .withTitle(&quot;Hello GitHub Checks API&quot;)
                                .withRawDetails(&quot;a simple echo command&quot;)
                                .build()))
                .build())
        .withActions(Collections.singletonList(
                new ChecksAction(&quot;formatting&quot;, &quot;format code&quot;, &quot;#0&quot;)))
        .build();

ChecksPublisher publisher = ChecksPublisherFactory.fromRun(run);
publisher.publish(details);

Future Works

The next step is integrating our API into Warnings Next Generation Plugin and Code Coverage API Plugin consume our API.
After that, pipeline support will be added: users can publish checks directly in a pipeline script without requiring a consumer plugin that support the checks.

Resources

GitHub Repository

Project Page

Gitter Channel

References

GitHub Doc: Creating CI tests with the Checks API

Warnings Next Generation Plugin: Source Code View<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/xiongkezhi/">Kezhi Xiong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/github">github</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/api">api</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/15/xss-severity/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">15</div></div><h5 class="title">Severity of cross-site scripting vulnerabilities</h5></div><p class="teaser">Eagle-eyed readers of today’s security advisory may already have noticed that we consider the cross-site scripting (XSS) vulnerabilities to be &#x27;High&#x27; severity.
This is a change from previous security advisories, in which similar vulnerabilities got a &#x27;Medium&#x27; score.

We follow the guidelines of CVSS version 3.0 for the severity we assign to these issues.
Their examples for XSS vulnerabilities, as well as XSS vulnerabilities in other software, consider the most severe, immediate impact to be a modification of the HTML output, possibly also the extraction of the session cookie (something Jenkins prevents by declaring it to be HttpOnly).

Unfortunately, this does not adequately model the impact that a successful XSS exploitation in Jenkins can have:
Jenkins administrators can perform far more sensitive actions than e.g. the admins of most content management systems could, as it is designed to allow users to execute code to build, test, and deploy their software.
So this kind of vulnerability, that allows attackers to do anything their victims have permission to do, in Jenkins can mean execution of arbitrary code, perhaps via the script console, if the victim has the Overall/Administer permission.
None of this requires chaining different actions in an attack, a well-chosen XSS payload will accomplish this.

Therefore, starting today, we score XSS vulnerabilities by the highest immediate impact a successful attack can have, which is a complete system compromise if admins can be attacked.
For stored XSS requiring some permissions, like the ability to configure jobs, a typical score would be 8.0.
Reflected XSS, which don’t require any permissions to exploit, will usually score 8.8.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/23/windows-support-updates/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">23</div></div><h5 class="title">Jenkins 2.248: Windows Support Updates</h5></div><p class="teaser">In this article, I would like to announce the new Windows support policy
which was introduced in the Jenkins project in June 2020.
This policy sets an expectation about how we handle issues and patches related to Windows support for the Jenkins server and agents, and how we organize testing of Windows support in the project.
We will also talk about .NET Framework 2.0 support removal in Jenkins 2.248,
and about new Windows service management features and fixes Jenkins users get with this release.

Figure 1. Jenkins on Windows

Why?

In theory, Jenkins can run everywhere where you can run Java 8 or Java 11, but, in practice, there are some limitations.
The Jenkins core and some plugins contain native code, and hence they rely on operating systems and platforms.
We use Java Native Access and Java Native Runtime libraries which provide wide platform support for low-level operations,
but there are platform-specific cases not covered by such generic libraries.
In the case of Windows platforms we use Windows Service Wrapper (WinSW) and
Windows Process Management Library (WinP).
These libraries depend on particular Windows API versions and, in the case of Windows services, on .NET Framework.

Historically Jenkins had no documented support policy for Windows,
and we were accepting patches for all versions which existed since the Hudson inception in 2004.
It became a serious obstacle for Windows component maintainers who had to be very conservative about incoming patches so that we could avoid breaking instances running on old platforms.
Lack of testing for older platforms did not help either.
And it is not just about maintenance overhead.
Users were impacted as well, because it blocked us from adopting some new Windows features and making Jenkins more stable/maintainable on modern platforms.

New policy

To set proper expectations about Windows support,
in the new policy we defined four support levels.
See the Windows support policy page for the actual information about the support levels and the supported platforms.
This blogpost captures the support state as of Jul 23, 2020:

Level 1 - Full Support

We run automated testing for these platforms, and we intend to timely fix the reported issues.
This support level includes 64-bit (amd-64) Windows Server versions with the latest GA update pack,
and versions used in the official Jenkins server and agent Docker images.

Level 2 - Supported

We do not actively test these platforms, but we intend to keep compatibility.
We are happy to accept patches.
This support level includes 64-bit (amd64) Windows Server and Windows 10 versions generally supported by Microsoft.

Level 3 - Patches considered

The platforms are generally expected to work, but they may have limitations and extra requirements.
We do not test compatibility, and we may drop support if needed.
We will consider patches if they do not put Level 1/2 platforms at risk and if they do not create maintenance overhead.
This support level includes non-amd64 platforms like x86 (32-bit) and AArch64 (Arm).
It also applies to non-mainstream release lines like Windows Embedded, preview releases, and versions no longer supported by Microsoft.

Level 4 - Unsupported

These versions are known to be incompatible or to have severe limitations.
We do not support the listed platforms, and we will not accept patches.
At the moment this level applies to platforms released before 2008.

When the policy was introduced, there were questions raised about platforms listed in the Level 3 support category.
First of all, these platforms are still supported.
Users are welcome to run Jenkins on these platforms.
We recognize the importance of the platforms listed there, and we intend to keep compatibility with them.
At the same time, particular functionality may break there due to the lack of testing when we update Jenkins or upstream dependencies.
It may take a while until a fix is submitted by a user or contributor,
because we do not maintain development environments for these platforms.
By setting a Level 3 support level, we want to set an explicit expectation about those limitations.

If you are interested in expanding the official Windows support policy and adding more platforms there,
we invite you to participate in quality assurance of Jenkins.
You may contribute by expanding test automation for Jenkins,
contributing test environments for your platforms,
or participating in the LTS release candidate testing and reporting results.
Please contact us via Platform SIG channels if you are interested.

Windows Service Management changes in Jenkins 2.248

Figure 2. WinSW Logo

Although the policy was introduced more than 1 month ago,
Jenkins 2.248 is the first release where the new policy is applied.
Starting from this release, we won’t support .NET Framework 2.0 for launching the Jenkins server or agents as Windows services.
 .NET Framework 4.0 or above is now required for using the default service management features.

This release also upgrades Windows Service Wrapper (WinSW) from 2.3.0 to 2.9.0 and replaces the bundled binary from .NET Framework 2.0 to 4.0.
There are many improvements and fixes in these versions,
big thanks to NextTurn and all other contributors.
You can find the full WinSW changelog here,
just a few highlights important to Jenkins users:

Prompt for permission elevation when administrative access is required.
Now Jenkins users do not need to run the agent process as Administrator to install the agent as a service from GUI.

Enable TLS 1.1/1.2 in .NET Framework 4.0 packages on Windows 7 and Windows Server 2008 R2.

Enable strong cryptography when running .NET Framework 4.0 binaries on .NET 4.6.

Support security descriptor string in the Windows service definition.

Support &#x27;If-Modified-Since&#x27; and proxy settings for automatic downloads.

Fix Runaway Process Killer extension so that it does not kill wrong processes with the same PID on startup.

Fix the default domain name in the serviceaccount parameter (jira:JENKINS-12660[])

Fix archiving of old logs in the roll-by-size-time mode.

As you may see, there are many improvements available with this version,
and we hope that it will make Windows service installation even more reliable.
Some of the changes in WinSW also replaced old workarounds in the Jenkins core,
making the code more maintainable.

Use-cases affected by .NET Framework 2.0 support removal

If you use .NET Framework 2.0 to run the Jenkins Windows services,
the following use-cases are likely to be affected:

Installing the Jenkins server as a Windows service from Web UI.
The official MSI Installer supports .NET Framework 2.0 for the moment, but it will be changed in future versions.

Installing agents as Windows services from GUI.
This feature is provided by in Windows Agent Installer Module from the Jenkins core.

Installing agents over Windows Management Instrumentation (WMI) via the WMI Windows Agents plugin

Auto-updating of Windows service wrappers on agents installed from GUI.

Upgrade guidelines

If all of your Jenkins server and agent instances already use .NET Framework 4.0 or above,
there are no special upgrade steps required.
Please enjoy the new features!

If you run the Jenkins server as a Windows Service with .NET Framework 2.0,
this instance will require an upgrade of .NET Framework to version 4.0 or above.
We recommend running with .NET Framework 4.6.1 or above,
because this .NET version provides many platform features by default
(e.g. TLS 1.2 encryption and strong cryptography),
and Windows Service Wrapper does not have to apply custom workarounds.

If you want to continue running some of your agents with .NET Framework 2.0,
the following extra upgrade steps are required:

Disable auto-upgrade of Windows Service Wrapper on agents by setting the
-Dorg.jenkinsci.modules.windows_slave_installer.disableAutoUpdate=true flag on the Jenkins server side.

Upgrade agents with .NET Framework 4.0+ by downloading the recent Windows Service Wrapper 2.x
version from WinSW GitHub Releases
and manually replacing the wrapper &quot;.exe&quot; files in the agent workspaces.

What’s next?

We plan to continue expanding the Windows support in Jenkins,
including providing official Docker images for newer Windows versions.
For example, there is already a pull request which will introduce official agent images for Windows Server Core LTSC 2019 and
for Windows Server Core and Nano Server 1909.
We are also interested to keep expanding test coverage for Windows platforms.
Any contributions and feedback will be appreciated!

We also keep working on improving Windows Services.
Buddhika Chathuranga, a Google Summer of Code 2020 student, is working on support for YAML Configurations in Windows Service Wrapper,
and on better verification of XML and YAML Configurations.
See the details on the project page and in the
Coding Phase 1 Report.
In addition to that, there is ongoing work on a new Windows Service Wrapper 3.0 release which will redesign CLI and introduce a lot more improvements.
If you are interested in contributing to Windows Service Wrapper,
see the guidelines here.
We will also appreciate your feedback on the WinSW Gitter channel.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform">platform</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/winsw">winsw</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/24/external-fingerprint-storage-phase-2/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">24</div></div><h5 class="title">External Fingerprint Storage Phase-2 Updates</h5></div><p class="teaser">As another great phase for the
External Fingerprint Storage Project
comes to an end, we summarise the work done during this phase in this blog post.
It was an exciting and fruitful journey, just like the previous phase, and offered some great learning experience.

To understand what the project is about and the past progress, please refer to the
phase 1 blog post.

New Stories Completed

We targeted four stories in this phase, namely fingerprint cleanup, fingerprint migration, refactoring the current
implementation to use descriptors, and improved testing of the Redis Fingerprint Storage Plugin.
We explain these stories in detail below.

Fingerprint Cleanup

https://github.com/jenkinsci/jenkins/pull/4817

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/23

This story involved extending the FingerprintStorage API to allow external storage plugins to perform and configure
their own fingerprint cleanup strategies.
We added the following functionalities to Jenkins core API:

FingerprintStorage#iterateAndCleanupFingerprints(TaskListener taskListener)

This allows external fingerprint storage implementations to implement their own custom fingerprint cleanup.
The method is called periodically by Jenkins core.

FingerprintStorage#cleanFingerprint(Fingerprint fingerprint, TaskListener taskListener)

This is a reference implementation which can be called by external storage plugins to clean up a fingerprint.
It is upto the plugin implementation to decide whether to use this method.
They may choose to write a custom implementation.

We consume these new API functionalities in the
Redis Fingerprint Storage plugin.
The plugin uses cursors to traverse the fingerprints, updating the build information, and deleting the build-less
fingerprints.

Earlier, fingerprint cleanup was always run periodically and there was no way to turn it off.
We also added an option to allow the user to turn off fingerprint cleanup.

This was done because it may be the case that keeping redundant fingerprints in memory might be cheaper than the
cleanup operation (especially in the case of external storages, which are cheaper these days).

Fingerprint Migration

https://github.com/jenkinsci/jenkins/pull/4825

Earlier, there was no support for fingerprints stored in the local storage.
In this phase, we introduce migration support for users.
The old fingerprints are now migrated to the new configured external storage whenever they are used (lazy migration).
This allows gradual migration of old fingerprints from local disk storage to the new external storage.

Refactor FingerprintStorage to use descriptors

https://github.com/jenkinsci/jenkins/pull/4834

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/36

Earlier, whenever an external fingerprint storage plugin was installed, it was enabled by default.
We refactored the implementation to make use of Descriptor pattern so the fingerprint engine can now be selected
as a dropdown from the Jenkins configuration page.
The dropdown is shown only when multiple fingerprint storage engines are configured on the system.
Redis Fingerprint Storage Plugin was refactored
to use this new implementation.

Strengthened testing for the Redis Fingerprint Storage Plugin

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/33

We introduced new connection tests in the
Redis Fingerprint Storage Plugin.
These tests allow testing of cases like slow connection, breakage of connection to Redis, etc.
These were implemented using the Toxiproxy module inside Testcontainers.

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/31

We introduced test for Configuration-as-code (JCasC) compatibility with the plugin.
The documentation for configuring the plugin using JCasC was also added.

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/39

We introduced a suite of authentication tests, to verify the proper working of the Redis authentication system.
Authentication uses the credentials plugin.

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/32

https://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/36

We strengthened our web UI testing to ensure that the configuration page for the plugin works properly as planned.

Other miscellaneous tasks

Please refer to the Jira Epic for this phase.

Releases 🚀

Changes in the Jenkins core (except migration) were released in Jenkins 2.248.

We drafted 1.0-rc-1
release for the Redis Fingerprint Storage Plugin
to deliver the changes.
This was an increment from the alpha release
we had drafted at the end of the previous phase.
The plugin is now available at https://plugins.jenkins.io/redis-fingerprint-storage/!

Trying out the new features!

The latest release for the plugin can be downloaded from the update center, instructions for which can be
found in the README
of the plugin.
We appreciate you trying out the plugin, and welcome any suggestions, feature requests, bug reports, etc.

Acknowledgements

The Redis Fingerprint Storage plugin is built and maintained by the Google Summer of Code (GSoC) Team for
External Fingerprint Storage for
Jenkins. Special thanks to Oleg Nenashev,
Andrey Falko, Mike Cirioli,
Tim Jacomb, and the entire Jenkins community for all the contribution to this project.

Future Work

Some of the topics we aim to tackle in the next phase include a new reference implementation (possibly backed
by PostgreSQL), tracing, etc.

Reaching Out

Feel free to reach out to us for any questions, feedback, etc. on the project’s Gitter Channel or the Jenkins
Developer Mailing list.
We use Jenkins Jira to track issues.
Feel free to file issues under redis-fingerprint-storage-plugin component.

Other Links

Redis Fingerprint Storage Plugin

Issue Tracker for Phase 2

jep:226[]

Gitter Channel

Project Page

Phase 1 Blog Post<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stellargo/">Sumit Sarin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/fingerprint">fingerprint</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/external-storage">external-storage</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/redis">redis</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/27/machine-learning-plugin-coding-phase2/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">27</div></div><h5 class="title">Machine Learning Plugin project - Coding Phase 2 blog post</h5></div><p class="teaser">Welcome back folks!

This blog post is about my coding phase 2 in Jenkins Machine Learning Plugin for this GSoC 2020.
After successfully passing the evaluation and demo in the phase 1, our team went ahead for facing the challenges in phase 2.

Summary

This phase of coding was well spent by documentation and by fixing many bugs.
As the main feature of connecting to an IPython Kernel is done in phase 1, we were able to focus on fixing minor/major bugs and documenting for the users.
According to the JENKINS-62927 issue, a Docker agent was built to facilitate users without concerning plugin dependencies in python.
In the act of deprecation of Python 2, we ported our plugin to support Python 3.
We have tested our plugin in Conda, venv and Windows environments.
Machine learning plugin has successfully passed the end to end test. A feature for a code editor is needed for further discussion/analysis as we have done a simple editor that may be useful in other ways in the future. PR#35

Main features of Machine Learning plugin

Run Jupyter notebook, (Zeppelin) JSON and Python files

Run Python code directly

Convert Jupyter Notebooks to Python and JSON

Configure IPython kernel properties

Support to execute Notebooks/Python on Agent

Support for Windows and Linux

Upcoming features

Extract graph/map/images from the code

Save artifacts according to the step name

Generate reports for corresponding build

Future improvements

Usage of JupyterRestClient

Support for multiple language kernels

Note : There is no commitment on future improvements during GSoC period

Docker agent

The following Dockerfile can be used to build the Docker container as an agent for the Machine Learning plugin. This docker agent can be used to run  notebooks or python scripts.

Dockerfile

FROM jenkins/agent:latest

MAINTAINER Loghi

USER root

RUN apt update &amp;&amp; apt install --no-install-recommends python3 -y \
    python3-pip \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

COPY requirements.txt /requirements.txt

RUN pip3 install --upgrade pip setuptools &amp;&amp; \
    pip3 install --no-cache-dir -r /requirements.txt &amp;&amp; \
    ln -sf /usr/bin/python3 /usr/bin/python &amp;&amp; \
    ln -sf /usr/bin/pip3 /usr/bin/pip

USER jenkins

Ported to Python 3

As discussed in the previous meeting, we concluded that the plugin should support Python 3 as Python 2.7+ has been deprecated since the beginning of 2020. Pull request for docker agent should be also ported to Python 3 support.

Jupyter Rest Client API

The Jupyter Notebook server API seemed to be promising that it can be also used to run notebooks and codes. There were 3 api implementations that were merged in the master. But we had to focus on what was proposed in the design document and had to finish all must-have issues/works. Jupyter REST client was left for future implementation. It is also a good start to contribute to the plugin from the community.

Fixed bugs for running in agent

There were a few bugs related to the file path of notebooks while building a job. The major problem was caused by the python dependencies needed to connect to a IPython kernel. All issues/bugs were fixed before the timeline given.

R support as a future improvement

This is what we tried to give a glimpse of knowledge that this plugin can be extended for multi language support in the future. There was a conclusion that the kernel should be selected dynamically using extension of the script file(like eval_model.rb or train_model.r), instead of scripting the same code for each kernel.

Documentation and End to End testing

A well explained documentation was published in the repository. A guided tutorial to run a notebook checked out from a git repo in an agent was included in the docs page. Mentors helped to test our plugin in both Linux and Windows.

Code editor with rebuild feature

Code editor was filtered as a nice to have feature in the design document. After grabbing the idea of Jenkinsfile replay editor, I could do the same for the code. At the same time, when we are getting the source code from git, it is not an elegant way of editing code in the original code. After the discussion, we had to leave the PR open that may have use cases in the future if needed.

Jenkins LTS update

The plugin has been updated to support Jenkins LTS 2.204.1 as 2.164.3 had some problems with installing pipeline supported API/plugin

Installation for experimental version

Enable the experimental update center

Search for Machine Learning Plugin and check the box along it.

Click on Install without restart

The plugin should now be installed on your system.

Resources

Community Bonding blog post

Phase 1 blog post

Github

Project page

Design document<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/loghijiaha/">Loghi Perinpanayagam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/machinelearning">machinelearning</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/datascience">datascience</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/communitybonding">communitybonding</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/27/repository-signing-keys-changing/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">27</div></div><h5 class="title">Jenkins 2.235.3: New Linux Repository Signing Keys</h5></div><p class="teaser">The Jenkins core release automation project has been delivering Jenkins weekly releases since Jenkins 2.232, April 16, 2020.
The Linux repositories that deliver the weekly release were updated with new GPG keys with the release of Jenkins 2.232.

Beginning with Jenkins LTS release 2.235.3, stable repositories will be signed with the same GPG keys that sign the weekly repositories.
Administrators of Linux systems must install the new signing keys on their Linux servers before installing Jenkins 2.235.3.

Debian/Ubuntu

Update Debian compatible operating systems (Debian, Ubuntu, Linux Mint Debian Edition, etc.) with the command:

Debian/Ubuntu

# wget -qO - https://pkg.jenkins.io/debian-stable/jenkins.io.key | apt-key add -

Red Hat/CentOS

Update Red Hat compatible operating systems (Red Hat Enterprise Linux, CentOS, Fedora, Oracle Linux, Scientific Linux, etc.) with the command:

Red Hat/CentOS

# rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key

Frequently Asked Questions

What if I don’t update the repository signing key?

Updates will be blocked by the operating system package manager (apt, yum, dnf) on operating systems that have not installed the new repository signing key.
Sample messages from the operating system may look like:

Debian/Ubuntu

Reading package lists... Done
W: GPG error: https://pkg.jenkins.io/debian-stable binary/ Release:
    The following signatures couldn&#x27;t be verified because the public key is not available:
        NO_PUBKEY FCEF32E745F2C3D5
E: The repository &#x27;https://pkg.jenkins.io/debian-stable binary/ Release&#x27; is not signed.
N: Updating from such a repository can&#x27;t be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.

Red Hat/CentOS

Downloading packages:
warning: /var/cache/yum/x86_64/7/jenkins/packages/jenkins-2.235.3-1.1.noarch.rpm:
    Header V4 RSA/SHA512 Signature, key ID 45f2c3d5: NOKEY
Public key for jenkins-2.235.3-1.1.noarch.rpm is not installed

Why is the repository signing key being updated?

The original repository GPG signing key is owned by Kohsuke Kawaguchi.
Rather than require that Kohsuke disclose his personal GPG signing key, the core release automation project has used a new repository signing key.
The updated GPG repository signing key is used in the weekly repositories and the stable repositories.

Which operating systems are affected?

Operating systems that use Debian package management (apt) and operating systems that use Red Hat package management (yum and dnf) need the new repository signing key.

Other operating systems like Windows, macOS, FreeBSD, OpenBSD, Solaris, and OpenIndiana are not affected.

Are there other signing changes?

Yes, there are other signing changes, though they do not need specific action from users.

The jenkins.war file is signed with a new code signing certificate.
The new code signing certificate has been used on weekly releases since April 2020.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/linux">linux</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform">platform</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/07/29/git-performance-improvement-phase2/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">29</div></div><h5 class="title">Git Plugin Performance Improvement Phase-2 Progress</h5></div><p class="teaser">The second phase of the Git Plugin Performance Improvement project has been great in terms of the progress we have achieved in implementing performance improvement insights
derived from the phase one JMH micro-benchmark experiments.

What we’ve learned so far in this project is that a git fetch is highly correlated to the size of the remote repository. In order to make fetch improvements in this plugin, our task was to find the difference in performance for the two available git implementations in the Git Plugin, git and JGit.

Our major finding was that git performs much better than JGit when it comes to a large sized repository (&gt;100 MiB). Interestingly, JGit performs better than git when size of the repository is less than 100 MiB.

In this phase, we were successful in coding this derived knowledge from the benchmarks into a new functionality called the
GitToolChooser.

GitToolChooser

This class aims to add the functionality of recommending a git implementation on the basis of the size of a repository which has a strong correlation to the performance of git fetch (from performance Benchmarks).

It utilizes two heuristics to calculate the size:

Using cached .git dir from multibranch projects to estimate the size of a repository

Providing an extension point which, upon implementation, can use REST APIs exposed by git service providers like Github, GitLab, etc to fetch the size of the remote repository.

Will it optimize your Jenkins instance?
That requires one of the following:

you have a multibranch project in your Jenkins instance, the plugin can use that to recommend the optimal git implementation

you have a branch Source Plugin installed in the Jenkins instance, the particular branch source plugin will recommend a git implementation using REST APIs provided by GitHub or GitLab respectively.

The architecture and code for this class is at: PR-931

Note : This functionality is an upcoming feature in the subsequent Git Plugin release.

JMH benchmarks in multiple environments

The benchmarks were being executed on Linux and macOS machines frequently but there was a need to check if the results gained from those benchmarks would hold true across more platforms to ensure that the solution (GitToolChooser) is generally platform-agnostic.

To test this hypothesis, we performed an experiment:

Running git fetch operation for a 400 MiB sized repository on:

Windows

FreeBSD 12

ppc64le

s390x

The result of running this experiment is given below:

Observations:

ppc64le and s390x are able to run the operation in almost half the time it takes for the Windows or FreeBSD 12 machine. This behavior may be attributed to the increased computational power of those machines.

The difference in performance between git and JGit remains constant across all platforms which is a positive sign for the GitToolChooser as its recommendation would be consistent across multiple devices and operating systems.

Release Plan 🚀

JENKINS-49757 - Avoid double fetch from Git checkout step
This issue was fixed in phase one, avoids the second fetch in redundant cases.
It will be shipped with some benchmarks on the change in performance due to the removal of the second fetch.

PR-574

PR-904

GitToolChooser

PR-931
This pull request is under review, will be shipped in one of the subsequent Git Plugin releases.

Current Challenges with GitToolChooser

Implement the extension point to support GitHub Branch Source Plugin, Gitlab Branch Source Plugin and Gitea Plugin.

The current version of JGit doesn’t support LFS checkout and sparse checkout, need to make sure that the recommendation doesn’t break existing use cases.

Future Work

In phase three, we wish to:

Release a new version of the Git and Git Client Plugin with the features developed during the project

Continue to explore more areas for performance improvement

Add a new git operation: git clone (Stretch Goal)

Reaching Out

Feel free to reach out to us for any questions or feedback on the project’s Gitter Channel or the Jenkins
Developer Mailing list.

Project Page

Phase 1 Blog Post<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rishabhbudhouliya/">Rishabh Budhouliya</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/git">git</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/03/github-checks-api-plugin-coding-phase-2/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 3</div></div><h5 class="title">GitHub Checks API Plugin Project - Coding Phase 2</h5></div><p class="teaser">Another great coding phase for GitHub Checks API Project ends!
In this phase, we focused on consuming the checks API in two widely used plugins:

Warnings NG Plugin

Code Coverage API Plugin

Besides the external usage, we have also split the general checks API from its GitHub implementation and released both of the plugins:

Checks API Plugin

GitHub Checks Plugin

Coding Phase 2 Demo [starts from 25:20]

Warning Checks

The newly released Warnings NG plugin 8.4.0 will use checks API to publish different check runs for different static analysis tools.
Without leaving GitHub, users are now able to see the analysis report they interested in.

On GitHub’s conversation tab for each PR, users will see summaries for those checks like the screenshot above. The summaries will include:

The status that indicates the quality gate

The name of the analysis tool used

A short message that indicates statistics of new and total issues

More fine-grained statistics can be found in the Details page.

Another practical feature is the annotation for specific lines of code. Users can now review the code alone with the annotations.

Try It

In Wanings NG plugin 8.4.0, the warning checks is set as a default feature only for GitHub.
For other SCM platforms, a NullPublisher will be used which does nothing.
Therefore, you can get those checks for your own GitHub project just in a few steps:

Update Warnings NG plugin to 8.4.0

Install GitHub Checks plugin on your Jenkins instance

Follow the GitHub app authentication guide to configure the credentials for the multi-branch project or GitHub organization project you are going to use

Use warnings-ng plugin in your Jenkinsfile for the project you configured in the last step, e.g.

node {
    stage (&#x27;Checkout&#x27;) {
        checkout scm
    }

    stage (&#x27;Build and Static Analysis&#x27;) {
        sh &#x27;mvn -V -e clean verify -Dmaven.test.failure.ignore&#x27;

        recordIssues tools: [java(), javaDoc()], aggregatingResults: &#x27;true&#x27;, id: &#x27;java&#x27;, name: &#x27;Java&#x27;
        recordIssues tool: errorProne(), healthy: 1, unhealthy: 20
        recordIssues tools: [checkStyle(pattern: &#x27;target/checkstyle-result.xml&#x27;),
            spotBugs(pattern: &#x27;target/spotbugsXml.xml&#x27;),
            pmdParser(pattern: &#x27;target/pmd.xml&#x27;),
            cpd(pattern: &#x27;target/cpd.xml&#x27;)],
            qualityGates: [[threshold: 1, type: &#x27;TOTAL&#x27;, unstable: true]]
    }
}

For more about the pipeline usage of warnings-ng plugin, please see the official documentation.

However, if you don’t want to publish the warnings to GitHub, you can either uninstall the GitHub Checks plugin or disable it by adding skipPublishingChecks: true.

recordIssues enabledForFailure: true, tools: [java(), javaDoc()], skipPublishingChecks: true

Coverage Checks

The coverage checks are achieved by consuming the API in Code Coverage API plugin.
First, in the conversation tab of a PR, users will be able to see the summary about the coverage difference compared to previous builds.

The Details page will contain some other things:

Links to the reference build, including the target branch build from the master branch and the last successful build from this branch

Coverage healthy score (the default value is 100% if the threshold is not configured)

Coverages and trends of different types in table format

The pull request for this feature will soon be merged and will be included in the next release of Coverage Checks API plugin. After that, you can use it by adding the below section to your pipeline script:

node {
    stage (&#x27;Checkout&#x27;) {
        checkout scm
    }

    stage (&#x27;Line and Branch Coverage&#x27;) {
        publishCoverage adapters: [jacoco(&#x27;**/*/jacoco.xml&#x27;)], sourceFileResolver: sourceFiles(&#x27;STORE_ALL_BUILD&#x27;)
    }
}

Like the warning checks, you can also disable the coverage checks by setting the field skipPublishingChecks, e.g.

publishCoverage adapters: [jacoco(&#x27;**/*/jacoco.xml&#x27;)], sourceFileResolver: sourceFiles(&#x27;STORE_ALL_BUILD&#x27;), skipPublishingChecks: true

Next Phase

In the next phase, we will turn our attention back to Checks API Plugin and GitHub Checks Plugin and add the following features in future versions:

Pipeline Support

Users can publish checks directly in a pipeline script without requiring a consumer plugin that supports the checks.

Re-run Request

Users can re-run Jenkins build through Checks API.

Lastly, it is exciting to inform that we are currently making the checks feature available on ci.jenkins.io for all plugins hosted in the jenkinsci GitHub organization, please see INFRA-2694 for more details.

Resources

Checks API Plugin

GitHub Checks Plugin

Project Page

Gitter Channel<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/xiongkezhi/">Kezhi Xiong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/github">github</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/api">api</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/04/cdf-graduation/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 4</div></div><h5 class="title">Jenkins graduates in the Continuous Delivery Foundation</h5></div><p class="teaser">We are happy to announce that the Jenkins project has achieved the graduated status in
the Continuous Delivery Foundation (CDF).
This status is officially effective Aug 03, 2020.
Jenkins is the first project to graduate in the CD Foundation.
Thanks to all contributors who made our graduation possible!

In this article, we will discuss what the CD Foundation membership and graduation mean to the Jenkins community.
We will also talk about what changed in Jenkins as a part of the graduation,
and what are the future steps for the project.

To know more about the Jenkins graduation,
see also the announcement on the CD Foundation website.
Also see the special edition of the CD Foundation Newsletter for Jenkins user success stories and some surprise content.
The press release is available here.

How does CDF membership help us?

About 18 months ago, Jenkins became one of the CDF founding projects, along with Jenkins X, Spinnaker and Tekton.
A new foundation was formed to provide a vendor-neutral home for open source projects used for Continuous Delivery and Continuous Integration.
Special interest groups were started to foster collaboration between projects and end user companies,
most notably:
Interoperability,
MLOps and
Security SIGs.
Also, a Community Ambassador role was created to organize local meetups and to provide public-facing community representatives.
Many former Jenkins Ambassadors and other contributors are now CDF Ambassadors, and they promote Jenkins and other projects there.

Thanks to this membership we addressed key project infrastructure needs.
Starting from Jan 2020, CDF covers a significant part of the infrastructure costs
including our services and CI/CD instances running on Microsoft Azure.
The CD Foundation provided us with legal assistance required to get code signing keys for the Jenkins project.
Thanks to that, we were able to switch to a new Jenkins Release Infrastructure.
The foundation sponsors the Zoom account we use for Jenkins Online Meetups and community meetings.
In the future we will continue to review ways of reducing maintenance overhead by switching some of our self-hosted services to equivalents provided by the Linux Foundation to CDF members.

Another important CDF membership benefit is community outreach and marketing.
It helped us to establish connections with other CI/CD projects and end user companies.
Through the foundation we have access to the DevStats service
that provides community contribution statistics and helps us track trends and discover areas for improvement.
On the marketing side, the foundation organizes webinars, podcasts and newsletters.
Jenkins is regularly represented there.
The CD Foundation also runs the meetup.com professional account which is used by local Jenkins communities for
CI/CD and Jenkins Area Meetups.
Last but not least, the Jenkins community is also represented at virtual conferences where CDF has a booth.
All of that helps to grow Jenkins visibility and to highlight new features and initiatives in the project.

Why did we graduate?

The Jenkins project has a long history of open governance which is a key part of today’s project success.
Starting from 2011, the project has introduced the governance meeting which are open to anyone.
Most of the discussions and decision making happen publicly in the mailing lists.
In 2015 we introduced teams, sub-projects and officer roles.
In 2017 we introduced the Jenkins Enhancement Proposal process which helped us to make the key architecture and governance decisions more open and transparent to the community and the Jenkins users.
In 2018 we introduced special interest groups that focus on community needs.
In 2019 we have expanded the Jenkins governance board
so that it got more bandwidth to facilitate initiatives in the project.

Since the Jenkins project inception 15 years ago, it has been steadily growing.
Now it has millions of users and thousands of contributors.
In 2019 it has seen 5,433 contributors from 111 countries and 272 companies,
67 core and 2,654 plugin releases,
45,484 commits, 7,000+ pull requests.
In 2020 Q2 the project has seen 21% growth in pull requests numbers compared to 2019 Q2, bots excluded.

One may say that the Jenkins project already has everything needed to succeed.
It is a result of continuous work by many community members,
and this work will never end as long as the project remains active.
Like in any other industry, the CI/CD ecosystem changes every day and sets new expectations from the automation tools in this domain.
Just as the tools evolve, open source communities need to evolve so that they can address expectations, and onboard more users and contributors.
The CDF graduation process helped us to discover opportunities for improvement,
and address them.
We reviewed the project processes and compared them with the Graduated Project criteria defined in the CDF project lifecycle.
Based on this review, we made changes in our processes and documentation.
It should improve the experience of Jenkins users,
and help to make the Jenkins community more welcoming to existing and newcomer contributors.

What changed for the project?

Below you can find a few key changes we have applied during the graduation process:

Public roadmap

We introduced a new public roadmap for the Jenkins project.
This roadmap aggregates key initiatives in all community areas: features, infrastructure, documentation, community, etc.
It makes the project more transparent to all Jenkins users and adopters,
and at the same time helps potential contributors find the hot areas and opportunities for contribution.
The roadmap is driven by the Jenkins community and it has a fully public process documented in jep:14[].

More details about the public roadmap are coming next week, stay tuned for a separate blogpost.
On July 10th we had an online contributor meetup about the roadmap
and you can find more information in its materials
( slides, video recording).

User Documentation

Jenkins Weekly Release line is now documented on our website ( here).
We have also reworked the downloads page and added guidelines explaining how to verify downloads.

A new list of Jenkins adopters was introduced on jenkins.io.
This list highlights Jenkins users and references their case studies and success stories,
including ones submitted through the Jenkins Is The Way portal.
Please do not hesitate to add your company there!

Community

We passed the Core Infrastructure Initiative (CII) certification.
This certification helps us to verify compliance with open source best practices
and to make adjustments in the project (see the bullets below).
It also provides Jenkins users and adopters with a public summary about compliance with each best practice.
Details are on the Jenkins core page.

Jenkins Code of Conduct was updated
to the new version of Contributor Covenant.
In particular, it sets best practices of behavior in the community, and expands definitions of unacceptable behavior.

The default Jenkins contributing template was updated to cover more common cases for plugin contributors.
This page provides links to the Participate and Contribute guidelines hosted on our website,
and helps potential contributors to easily access the documentation.

The Jenkins Core maintainer guide was updated to include maintenance and issues triage guidelines.
It should help us to deliver quality releases and to timely triage and address issues reported by Jenkins users.

What’s next?

It an honor to be the first project to reach the graduated stage in the Continuous Delivery Foundation,
but it is also a great responsibility for the project.
As a project, we plan to continue participating in the CDF activities and to work with other projects and end users to maintain the Jenkins&#x27; leader role in the CI/CD space.

We encourage everyone to join the project and participate in evolving the Jenkins project and driving its roadmap.
It does not necessarily mean committing code or documentation patches;
user feedback is also very important to the project.
If you are interested to contribute or to share your feedback,
please contact us in the Jenkins community channels ( mailing lists, chats)!

Acknowledgements

CDF graduation work was a major effort in the Jenkins community.
Congratulations and thanks to the dozens of contributors who made our graduation possible.
I would like to thank
Alex Earl,
Alyssa Tong,
Dan Lorenc,
Daniel Beck,
Jeff Thompson,
Marky Jackson,
Mark Waite,
Olivier Vernin,
Tim Jacomb,
Tracy Miranda,
Ullrich Hafner,
Wadeck Follonier,
and all other contributors who helped with reviews and provided their feedback!

Also thanks to the Continuous Delivery Foundation marketing team (Jacqueline Salinas, Jesse Casman and Roxanne Joncas) for their work on promoting the Jenkins project and, specifically, its graduation.

About the Continuous Delivery Foundation

The Continuous Delivery Foundation (CDF) serves as the vendor-neutral home of many of the fastest-growing projects for continuous delivery, including Jenkins, Jenkins X, Tekton, and Spinnaker,
as well as fosters collaboration between the industry’s top developers, end users and vendors to further continuous delivery best practices.
The CDF is part of the Linux Foundation, a nonprofit organization.
For more information about the foundation, please visit its website.

More information

To know more about the Jenkins graduation in the Continuous Delivery Foundation,
see the announcement on the CD Foundation website.
Also see the special edition of the CD Foundation Newsletter for Jenkins user success stories and some surprise content.
The press release is available here.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cdf">cdf</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/general">general</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/09/custom-distribution-service-phase-2/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 9</div></div><h5 class="title">Custom Distribution Service : Phase 2 Blogpost</h5></div><p class="teaser">Hello everyone,
It is time to wrap up another successfull phase for the custom distribution service project,
and we have incorporated most of the features that we had planned at the start of the phase.
It has been an immense learning curve for me and the entire team.

To understand what the project is about and the past progress, please refer to the phase one blogpost
here.

Front-End

Filters for Plugins

In the previous phase we implemented the ability to add plugins to the configuration,
and the ability to search these plugins via a search bar.
Sometimes though we would like to filter these plugins based on their usage,
popularity, stars etc. Hence we have added a certain set of filters to these plugins.
We support only four major filters for now. They are:

Title

Most installed

Relevance

Trending

Filter implementation

The major heavy lifting is done by the plugin api which takes in the necessary parameters
and returns the relevant plugins in the form of a json object,
here is an example of the api call url: const url = https://plugins.jenkins.io/api/plugins?$params .

For details, see:

Feature request #9

Pull Request #76

Community Configurations

One major deliverable for the project was the ability for users to share the configurations developed by them, so that they can be used widely within the community.
For example we see quite a lot of jenkins configurations involve being run on AWS and kubernetes and so on. Therefore it would be really good for the community to have a place to find and run
these configurations right out of the box.

Design Decision

The major design decision taken here was whether to include the configurations inside
the repository or to have them in a completely new repository.
Let us talk about both these approaches.

Having the configurations in the current repository:

This allows us to have all of the relevant configurations inside the repository itself,
and so users would not have to go fetch this in different repositories.
We could have issues with the release cycle and dependencies since,
it would have to happen along with the custom distribution service project releases.

Having the configurations in a different repository:

This allows us to manage all of the configurations and the relevant dependencies separately and easily,
thus avoiding any release conflict with the current repository.
However it would be a bit difficult if users were to not find this repository.

Decision : We still cannot quite agree on what is the best method so for now,
I have included the url from which the community configurations are picked up as a
configuration variable in the.env file which can be configured later and
therefore it can be up to the user to configure. Another advantage of having it configurable,
is that the user can decide to load configurations which are private to his organization as well.

For details, see:

Issue #6161

Pull Request #73

Back-End

War Generation

The ability to generate and download war files has finally been achieved,
the reason this feature took so long to complete is because we had some difficulty
in implementing the war generation and its tests. However this has been completed
and can now be tested successfully.

Things to take care while generating war files

In its current state the war generation cannot include casc.yml or groovy files
if they are included in the configuration they would have to be added externally.
There is an issue opened here.
The war file generation would yell at you if you tried to build a war file with a jcasc file configuration.

For details, see:

Issue #60

Pull Request #68

Pull Request Creation

This feature was included in the design document that I created after my GSoC selection.
It involves the ability to create pull requests via the front-end of the service.
The User Story behind this feature was that If I want to share a configuration with the community and I do not quite know how to use github or I do not want to do it via the terminal.
This feature includes creation of a bot that handles the creation of pull requests in the repository.
This bot would have to be installed by the jenkins organization in this repository and the bot would handle the rest.

For details, see:

Issue #59

Pull Request #72

Disclaimer:

This feature has however been put on the back-burner for now because
we are focusing on getting the project to be self hosted and therefore
would like to implement this once we have a clear path for the project to be hosted by the jenkins-infra team.If you would like to participate in the discussion here are the links for the pull requests,
PR 1 and link: PR 2, or you can even jump in our gitter channel.

If you have been following my posts,
I mentioned in my second week blog post that pulling in the json file consisting of more than
1600 plugins took a bit more time that my liking.
We managed to solve that issue using a caching mechanism,
so now the files are pulled in the first time you start the service and downloaded in a temporary folder. The next time you want to view the plugin cards they are pulled in directly from the temp directory bam ! thereby reducing time.

For details see Pull Request #90

Fixes and improvements

Port 8080

Port 8080 now does have a message instead of a whitelabel error message which is present
by default in the spring-boot tomcat server setup.
Turns out it requires overriding a particular class, and inserting a custom message

For details, see:

Pull Request #92

War Generation

Till now while you were generating the war file,
if something went wrong during genration the service would not complain it would just swallow the error and throw back a corrupted war file,
however now we have added an error support feature
that will alert you when something goes wrong, the error is not very informative as of now,
but we are working on making it more informative in the future.

For details, see:

War generation error handling #91

Add Github controller and jwt helper #66

Dockerfile

One of the major milestones of this phase was to have a project that can be self hosted,
needless to say we needed the dockerfile i.e docker-compose.yml to spin the project with a few commands.
The major issue we faced here was that there was a bit of a problem making the two containers talk to each other. Let me give you a little bit of context here.
Our docker-compose is constructed using two separate dockerfiles one for the backend of the service and the other for the front-end.
The backend makes api calls to the front-end via the proxy url i.e localhost:8080.
We now had to change this since the network bridge between the two containers spoke to each other via the backend-server name i.e app-server.
To brige that gap we have this PR that ensured that the docker compose works flawlessly.

For details, see:

Pull Request #82

However there is a minor draw-back of the above approach was now the entire
project just relied on the docker compose and could not run using the simple
combination of npm and maven since the proxy was different.
In order to fix this I decided to follow a multiple environment approach,
where we have multiple environment files that pick up the correct proxy and insert it at build time,
to elaborate further we have two environment files,
(using the env-cmd library ).env and the docker.env and we insert,
the correct file depending on how you want to build the project.
For instance if you want to run it using the dockerfile the command that is run under the hood is something along these lines — npm --env-cmd -f docker.env start scripts.

For details, see:

Pull Request #88

Other links

Gitter Channel Link
GSoC Proposal
Design Document
Daily Notes
Demo<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sladyn98/">Sladyn Nunes</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/service">service</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/distribution">distribution</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/packaging">packaging</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/12/windows-installers-upgrade/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">12</div></div><h5 class="title">Windows Installer Upgrades</h5></div><p class="teaser">This article describes the transition from the old Jenkins Windows installer 2.235.2 (32 bit) to the new Jenkins Windows installer 2.235.3 (64 bit)

Let’s take a look how Jenkins installation on Windows happened before release of this upgrade.

Step 1

It’s evident that branding information is not present here.

Step 2

Jenkins would be installed into the 32 bit programs directory along with a 32 bit Java 8 runtime environment.

Step 3

There was no option to select the user that would run the Jenkins service or the network port that would be used.

Issues

The previous installer had issues that needed to be resolved:

Only supported 32-bit installations

Bundled an outdated Java 8 runtime environment

No support for Java 11

No port selection during installation

No choice of account for the Jenkins service

The Program Files (x86) directory was used for the Jenkins home directory

Road Forward

The new Jenkins Windows Installer resolves those issues

Supports 64 bit installations and drops 32 bit support

Supports 64 bit Java 8 and 64 bit Java 11

Port selection and validation from the installer

Service account selection and validation from the installer

Program is installed in Program Files with Jenkins home directory in %AppData% of the selected service account

The JENKINS_HOME directory is placed in the LocalAppData directory for the user that the service will run as, this aligns with modern Windows file system layouts

The installer has been updated with branding to make it look nicer and provide a better user experience

Screenshots

You may see below the sequence of screenshots for the new installer:

Step 1

We can see now the Jenkins logo as a prominent part of the installer UI.

Step 2

Jenkins installs by default in the 64 bit programs folder rather than in the 32 bit folder.
Now the Jenkins logo and name are in the header during entire process of installation.

Step 3

Now the installer allows both specifying and testing the credentials by validating that the account has LogonAsService rights.

Step 4

Now the installer also allows specifying the port that Jenkins should run on and will not continue until a valid port is entered and tested.

Step 5

Now instead of bundling a JRE, the installer searches for a compatible JRE on the system (in the current search no JRE was installed).
In case you would like to use a different JRE from the one found by the installer, you can browse and specify it.
Only Java 8 and Java 11 runtimes are supported.
In case the selected JRE is found to be version 11 the installer will automatically add the necessary arguments and additional jar files for running under Java 11.

Step 6

All of the items that users can enter in the installer should be overridable on the command line for automated deployment as well. The full list of properties that can be overridden will be available soon.

Next Steps

Windows users have alternatives for their existing Jenkins installations:

Upgrade from inside Jenkins

The &quot;Manage Jenkins&quot; section of the running Jenkins will continue to include an &quot;Upgrade&quot; button for Windows users.
You may continue to use that &quot;Upgrade&quot; button to update the Jenkins installation on your Windows computer.
Upgrade from inside Jenkins will continue to use the current Java version.
Upgrade from inside Jenkins will continue to use the current installation location.

Upgrade with the new Jenkins MSI installer

If you run the new Jenkins MSI installer on your Jenkins that was installed with the old Jenkins MSI installer, it will prompt for a new port and a service account.

Stop and disable the existing Jenkins service from the Windows Service Manager

Run the new installer to create the new installation with desired settings

Stop the newly installed Jenkins service

Copy existing Jenkins configuration files to the new Jenkins home directory

Start the newly installed Jenkins service

After the new Jenkins MSI installer has run, the &quot;Manage Jenkins&quot; section of the running Jenkins will continue to include an &quot;Upgrade&quot; button for Windows users.
You may continue to use that &quot;Upgrade&quot; button to update the Jenkins installation on your Windows computer.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/vsilverman/">Vlad Silverman</a>, <a href="/gatsby-jenkins-io/blog/authors/slide_o_mix/">Alex Earl</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/installers">installers</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/25/external-fingerprint-storage-phase-3/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">25</div></div><h5 class="title">External Fingerprint Storage Phase-3 Update: Introducing the PostgreSQL Fingerprint Storage Plugin</h5></div><p class="teaser">The final phase for the External Fingerprint Storage
Project has come to an end and to finish off, we release one more fingerprint storage plugin:
the PostgreSQL Fingerprint Storage Plugin!

This post highlights the progress made during phase-3.
To understand what the project is about and the past progress, please refer to the
phase-1 post and the
phase-2 post.

Introducing the PostgreSQL Fingerprint Storage Plugin

Why PostgreSQL?

There were several reasons why it made sense to build another reference implementation, especially backed by PostgreSQL.

Redis is a key-value storage, and hence stores the fingerprints as blobs.
The PostgreSQL plugin defines a relational structure for fingerprints.
This offers a more powerful way to query the database for fingerprint information.
Fingerprint facets can store extra information inside the fingerprints, which cannot be queried in Redis directly.
PostgreSQL plugin allows powerful (indexing) and efficient querying strategies which can even query the facet metadata.

Another reason for building this plugin was to provide a basis for other relational database plugins to be built.
It also validates the flexibility and design of our external fingerprint storage API.

Since PostgreSQL is a traditional disk storage database, it is more suitable for systems storing a massive number of
fingerprints.

Among relational databases, PostgreSQL is quite popular, has extensive support, and is open-source.
We expect the new implementation to drive more adoption, and prove to be beneficial to the community.

Installation:

The plugin can be installed using the
experimental update center.
Follow along the following steps after running Jenkins to download and install the plugin:

Select Manage Jenkins

Select Manage Plugins

Go to Advanced tab

Configure the Update Site URL as: https://updates.jenkins.io/experimental/update-center.json

Click on Submit, and then press the Check Now button.

Go to Available tab.

Search for PostgreSQL Fingerprint Storage Plugin and check the box along it.

Click on Install without restart

The plugin should now be installed on the system.

Usage

Once the plugin has been installed, you can configure the PostgreSQL server details by following the steps below:

Select Manage Jenkins

Select Configure System

Scroll to the section Fingerprints and choose PostgreSQL Fingerprint Storage in the dropdown for
Fingerprint Storage Engine.

Configure the following parameters to connect to your PostgreSQL instance:

Host - Enter hostname where PostgreSQL is running

Port - Specify the port on which PostgreSQL is running

SSL - Click if SSL is enabled

Database Name - Specify the database name inside the PostgreSQL instance to be used. Please note that the database
will not be created by the plugin, the user has to create the database.

Connection Timeout - Set the connection timeout duration in seconds.

Socket Timeout - Set the socket timeout duration in seconds.

Credentials - Configure authentication using username and password to the PostgreSQL instance.

Use the Test PostgreSQL Connection button to verify that the details are correct and Jenkins is able to connect to
the PostgreSQL instance.

[IMPORTANT] When configuring the plugin for the first time, it is highly important to press the Perform PostgreSQL
Schema Initialization button. It will automatically perform schema initialization and create the necessary indexes.
The button can also be used in the case the database is wiped out and schema needs to be recreated.

Press the Save button.

Now, all the fingerprints produced by this Jenkins instance should be saved in the configured PostgreSQL instance!

Querying the Fingerprint Database

Due to the relational structure defined by PostgreSQL, it allows users/developers to query the fingerprint data which
was not possible using the Redis fingerprint storage plugin.

The fingerprint storage can act as a consolidated storage for multiple Jenkins instances.
For example, to search for a fingerprint id across Jenkins instances using the file name, the following query could be
used:

SELECT fingerprint_id FROM fingerprint.fingerprint
WHERE filename = &#x27;random_file&#x27;;

A sample query is provided which can be tweaked depending on the parameters to be searched:

SELECT * FROM fingerprint.fingerprint
WHERE fingerprint_id = &#x27;random_id&#x27;
        AND instance_id = &#x27;random_jenkins_instance_id&#x27;
        AND filename = &#x27;random_file&#x27;
        AND original_job_name = &#x27;random_job&#x27;
        AND original_job_build_number = &#x27;random_build_number&#x27;
        AND timestamp BETWEEN &#x27;2019-12-01 23:59:59&#x27;::timestamp AND now()::timestamp

The facets are stored in the database as jsonb.
PostgreSQL offers support to query jsonb.
This is especially useful for querying the information stored inside fingerprint facets.
As an example, the Docker Traceability Plugin stores information like the name of Docker images inside these
facets.
These can be queried across Jenkins instances like so:

&gt;&#x27;imageName&#x27; = &#x27;random_container&#x27;;

At the moment these queries require working knowledge of the database.
In future, these queries can be abstracted away by plugins and the features made available to users directly inside
Jenkins.

Demo

External Fingerprint Storage Demo

Slide deck

Releases 🚀

We released the 0.1-alpha-1 version for the
PostgreSQL Fingerprint Storage Plugin.
Please refer to the

changelog for more information.

Redis Fingerprint Storage Plugin 1.0-rc-3 was also
released.
The

changelog provides more details.

A few API changes made in the Jenkins core were released in Jenkins-2.253.
It mainly includes exposing fingerprint range set serialization methods for plugins.

Future Directions

The relational structure of the plugin allows some performance improvements that can be made when implementing
cleanup, as well as improving the performance of Fingerprint#add(String job, int buildNumber).
These designs were discussed and are a scope of future improvement.

The current external fingerprint storage API supports configuring multiple Jenkins instances to a single storage.
This opens up the possibility of developing traceability plugins which can track fingerprints across Jenkins instances.

Please consider reaching out to us if you feel any of the use cases would benefit you, or if you would like to share
some new use cases.

Acknowledgements

The PostgreSQL Fingerprint Storage Plugin and the Redis Fingerprint Storage plugin are maintained by the
Google Summer of Code (GSoC) Team for External
Fingerprint Storage for Jenkins.
Special thanks to Oleg Nenashev,
Andrey Falko, Mike Cirioli,
Tim Jacomb, and the entire Jenkins community for all the contribution to this project.

As we wrap up, we would like to point out that there are plenty of future directions and use cases for the externalized
fingerprint storage, as mentioned in the previous section, and we welcome everybody to contribute.

Reaching Out

Feel free to reach out to us for any questions, feedback, etc. on the project’s
Gitter Channel or the
Jenkins Developer Mailing list.
We use Jenkins Jira to track issues.
Feel free to file issues under either the postgresql-fingerprint-storage-plugin or the
redis-fingerprint-storage-plugin component depending on the plugin.

Other Links

Phase 1 Post

Phase 2 Post

PostgreSQL Fingerprint Storage Plugin

Redis Fingerprint Storage Plugin

jep:226[]

Gitter Channel

Project Page<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/stellargo/">Sumit Sarin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/fingerprint">fingerprint</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/external-storage">external-storage</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/PostgreSQL">PostgreSQL</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/27/machine-learning-plugin-coding-phase3/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">27</div></div><h5 class="title">Machine Learning Plugin project - Coding Phase 3 blog post</h5></div><p class="teaser">Good to see you all again !

This is my final blog post about coding phase 3 in Jenkins Machine Learning Plugin for GSoC 2020.
Being at the end of GSoC 2020, we had to finish all the pending issues and testing before a stable release in the main repository. Throughout this program, there were lots of learning and hard work will make this plugin valuable to the Data Science and Jenkins community.

Summary

With combining all of the work in phase 1, 2 and 3, initial version of Machine learning plugin( 1.0 ) was successfully released in Jenkins plugin repository.
An interesting feature which allows users to connect to their existing programming language kernels more than connecting to only IPython kernel was introduced in this phase. It can be selected in multiple steps with different kernel.
Images and graphs produced by Jupyter notebooks will be saved in user preferred folder in the workspace that can be used for reporting/analytic purposes later. Hoping this blog summarizes the Machine Learning’s features and future contributions. Thank you for your interest and support !!!

Main features of Machine Learning plugin

Execute Jupyter notebooks directly

Run different language scripts using multiple build steps

Convert Jupyter Notebooks to Python

Configure Jupyter kernels( IPython, IRKernel, IJulia etc) properties

Support to execute Notebooks/scripts on Agent

Extract graph/map/images from the code

Each build step can be associated with a machine learning task

Support for Windows and Linux

Future improvements

Improving performance of the plugin

Try to implement jira:JENKINS-63377[]

Support parameterized definitions in Notebooks jira:JENKINS-63478[]

Increasing testing code coverage

Multiple language kernel support

If there are existing kernels in the system, user will be able to configure in the global configurations in order to apply in the builder/step configuration.

Some popular interactive kernels

IPython for python

IRKernel for R

IJulia for Julia

IJavascript for javascript

More kernels and installation guides are found here. https://github.com/jupyter/jupyter/wiki/Jupyter-kernels

Dump images and graphs

Text output will be displayed in the console log. At the same time images/graphs/heat maps and HTMLs will be saved in the workspace. An action is shown in the left panel to display images in realtime. Due to the Content Security Policy of jenkins, some HTMLs which contain harmful javascript may not render in jenkins UI.

Fixed bugs

There were more bugs identified and fixed with many interactive testings. Setting the working directory of kernels was a big issue while getting datasets/files by script. Zeppelin process launcher was bypassed to fix this issue.

Patch version released

A major bug which was created while setting the process working directory had patched in the v1.0.1. The latest release is more stable now.

Acknowledgement

Machine Learning plugin had been developed under GSoC 2020 program. A huge thanks to Bruno P. Kinoshita, Marky Jackson, Shivay Lamba, Ioannis Moutsatsos and Org admins for this wonderful experience.
I would be grateful for contributing this plugin continuously and more in Jenkins.

Resources

Community Bonding blog post

Phase 1 blog post

Phase 2 blog post

Github

Project page

Plugin page

Design document<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/loghijiaha/">Loghi Perinpanayagam</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/machinelearning">machinelearning</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/datascience">datascience</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jupyter">jupyter</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/27/winsw-yaml-support/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">27</div></div><h5 class="title">Jenkins Windows Services: YAML Configuration Support - GSoC Project Results</h5></div><p class="teaser">Hello, world! GSoC 2020 Phase 3 has ended now and it was a great period for thw Jenkins Windows Services - YAML Configuration Support project.
In this blog post, I will announce the updates during the GSoC 2020 - Phase 2 and Phase 3. If you are not already aware of this project,
I would recommend reading this blog post which was published after GSoC 2020 - Phase 1.

Project Scope

Windows Service Wrapper - YAML configuration support

YAML schema validation

New CLI

XML Schema validation

YAML Configuration Support

Under WinSW - YAML configurations support, these tasks will be done.

YAML to Object mapping

At the moment YAML object mapping is finished and merged.
You can find all the implementations in this Pull Request.

Extend WinSW to support both XML and YAML

This task is already done and merged. Find the implementation in this Pull Request.

YAML Configuration support for Extensions

At the moment there are 2 internal plugins in WinSW. RunAwayProcessKiller and SharedDirectoryMapper.
We allow users to provide configurations for those plugins in the same XML and YAML configuration file which is used to configure WinSW. This task is merged as well.
Pull Request

YAML schema validation

Users can validate YAML configuration file against JSON schema file.
Users can use YAML utility tool from Visual Studio market place to validate YAML config file against JSON schema.

Key updates in Phase 2 and Phase 3

YAML Configuration structure

Environment variables

Now users can provide environment variables as a sequence of dictionaries that contains name and value for environment variables.

TimeStamp values

Users can specify timestamp values in the same manner used in XML (e.g. 10 ms, 5 sec, 3 min)

YAML configuration document was published. YAML Configuration Specification

Extend the WinSW to support both XML and YAML

YAML support for extensions

YAML schema validation against JSON schema

Sample YAML Configuration File

id: jenkins
name: Jenkins
description: This service runs Jenkins automation server.
env:
    - name: JENKINS_HOME
      value: &#x27;%LocalAppData%\Jenkins.jenkins&#x27;
    - name: LM_LICENSE_FILE
      value: host1;host2
executable: java
arguments: &gt;-
    -Xrs -Xmx256m -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle
    -jar &quot;E:\Winsw Test\yml6\jenkins.war&quot; --httpPort=8081
log:
    mode: rotate
onFailure:
    - action: restart
      delay: 10 sec
    - action: reboot
      delay: 1 hour
extensions:
    - id: killOnStartup
      enabled: yes
      classname: WinSW.Plugins.RunawayProcessKiller.RunawayProcessKillerExtension
      settings:
            pidfile: &#x27;%BASE%\pid.txt&#x27;
            stopTimeOut: 5000
            StoprootFirst: false
    - id: mapNetworDirs
      enabled: yes
      classname: WinSW.Plugins.SharedDirectoryMapper.SharedDirectoryMapper
      settings:
            mapping:
                - enabled: false
                  label: N
                  uncpath: \\UNC
                - enabled: false
                  label: M
                  uncpath: \\UNC2

New CLI

Let me explain in brief, why we need a new CLI.
In WinSW, we will keep both XML and YAML configuration support.
But according to the current implementation, the user can’t specify the configurations file explicitly.
Also, we want to let the user skip the schema validation as well.
So We decided to move into new CLI which is more structured with commands and options.
Please read my previous blog post to learn more about commands and options in the new CLI.

Key updates in Phase 2 and Phase 3

Remove the /redirect command

testwait command was removed and add the wait option to the test command.

stopwait command was removed and add the wait option to the stop command.

How to try

User can configure the Windows Service Wrapper by both XML and YAML configuration files using the following steps.

Create the configuration file (XML or YAML).

Save it with the same name as the Windows Service Wrapper executable name.

Place the configuration file inside the directory(or in a parent directory), where the Windows Service Wrapper executable is located.

If there are both XML and YAML configuraiton files, Windows Service Wrapper will be configured by the XML configuration file.

GSoC 2020 Phase 2 Demo

GSoC 2020 Phase 3 Demo

Future Works

XML Schema validation

XML configuration file will be validated with the XSD file.
I have started working on this feature and you can find the implementation in this Pull Request.

YAML Configuration validate on startup

How to contribute

You can find the GitHub repository in this link.
Issues and Pull requests are always welcome. Also, you can communicate with us in the WinSW Gitter channel,
which is a great way to get in touch and there are project sync up meetings every Tuesday at 13:30 UTC on the Gitter channel.

Some useful links

Presentation Slides

Project Page

Project Repository

Feature preview

Gitter Channel

YamlDotNet library

Command Line Parser library<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/buddhikac96/">Buddhika Chathuranga</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/winsw">winsw</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/29/git-performance-improvement-phase3/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">29</div></div><h5 class="title">Git Plugin Performance Improvement: Final Phase and Release</h5></div><p class="teaser">Since the beginning of the project, the core value which drove its progress was &quot;To enhance the user experience for running Jenkins jobs by reducing the overall execution time&quot;.

To achieve this goal, we laid out a path:

Compare the two existing git implementations i.e CliGitAPIImpl and JGitAPIImpl using performance benchmarking

Use the results to create a feature which would improve the overall performance of git plugin

Also, fix existing user reported performance issues

Let’s take a journey to understand how we’ve built the new features. If you’d like to skip the journey part, you can directly go to the [major performance improvements] section and the [minor performance section] to see what we’ve done!

Journey to release

The project started with deciding to choose a git operation and then trying to compare the performance of that operation by using command line git and then with JGit.

Stage 1: Benchmark results with git fetch

The performance of git fetch (average execution time/op) is strongly correlated to the size of a repository

There exists an inflection point on the scale of repository size after which the nature of JGit performance changes (it starts to degrade)

After running multiple benchmarks, it is safe to say that for a large sized repository command line git would be a better choice of implementation.

We can use this insight to implement a feature which avoids JGit with large repositories.

Stage 2: Comparing platforms

The project was also concerned that there might be important differences between operating systems.
For example, what if command line Git for Windows performed very differently than command line Git on Linux or FreeBSD?
Benchmarks were run to compare fetch performance on several platforms.

Running git fetch operation for a 400 MiB sized repository on:

AMD64 Microsoft Winders

AMD64 FreeBSD

IBM PowerPC 64 LE Ubuntu 18

IBM System 390 Ubuntu 18

The result of running this experiment is given below:

The difference in performance between git and JGit remains constant across all platforms.

Benchmark results on one platform are applicable to all platforms.

Stage 3: Performance of git fetch and repository structure

The area of the circle enclosing each parameter signifies the strength of the positive correlation between the performance of a git fetch operation and that parameter. From the diagram:

Size of the aggregated objects is the dominant player in determining the execution time for a git fetch

Number of branches and Number of tags play a similar role but are strongly overshadowed by size of repository

Number of commits has a negligible effect on the performance of running git fetch

After running these experiments from Stage-1 to Stage-3, we developed a solution called the GitToolChooser which is explained in the next stage

Stage 4: Faster checkout with Git tool chooser

This feature takes the responsibility of choosing the optimal implementation from the user and hands it to the plugin. It takes the decision of recommending an implementation on the basis of the size of the repository. Here is how it works.

The image above depicts the performance enhancements we have performed over the course of the GSoC project. These improvements have enabled the checkout step to be finished within half of what it used to take earlier in some cases.

Let’s talk about performance improvements in two parts.

Major performance improvements

Building Tensorflow (~800 MiB) using a Jenkins pipeline, there is over 50% reduction in overall time spent in completing a job!
The result is consistent multiple platforms.

The reason for such a decrease is the fact that JGit degrades in performance when we are talking about large sized repositories. Since the GitToolChooser is aware of this fact, it chooses to recommend command line git instead which saves the user some time.

Minor performance improvements

Note: Enable JGit before using the new performance features to let GitToolChooser work with more options → Here’s how

Building the git plugin (~ 20 MiB) using a Jenkins pipeline, there is a drop of a second across all platforms when performance enhancement is enabled. Also, eliminating a redundant fetch reduces unnecessary load on git servers.

The reason for this change is the fact that JGit performs better than command line git for small sized repositories (&lt;50MiB) as an already warmed up JVM favors the native Java implementation.

Releases

Git Plugin 4.4.0

Add GitToolChooser

Remove redundant fetch

Git Client Plugin 3.4.0

Add support to communicate compatibility of JGit with certain additional SCM behaviors

The road ahead

Support from other branch source plugins

Plugins like the GitHub Branch Source Plugin or GitLab Branch Source Plugin need to extend an extension point provided by the git plugin to facilitate the exchange of information related to size of a remote repository hosted by the particular git provider

JENKINS-63519 : GitToolChooser predicts the wrong implementation

Addition of this feature to GitSCMSource

Detection of lock related delays accessing the cache directories present on the controller

This issue was reported by the plugin maintainer Mark Waite, there is a need to reproduce the issue first and then find a possible solution.

Reaching out

Feel free to reach out to us for any questions or feedback on the project’s
Gitter Channel or the
Jenkins Developer Mailing list.
Report an issue at Jenkins Jira.

Useful Links

Phase 1 Blog: https://www.jenkins.io/blog/2020/07/09/git-performance-improvement-phase1/

Phase 2 Blog: https://www.jenkins.io/blog/2020/07/29/git-performance-improvement-phase2/

Project Page: https://www.jenkins.io/projects/gsoc/2020/projects/git-plugin-performance/

Demonstration<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/rishabhbudhouliya/">Rishabh Budhouliya</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/git">git</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/performance">performance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/31/custom-distribution-service/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">Custom Distribution Service : Phase 3 Blogpost</h5></div><p class="teaser">Hello everyone,

This is the final blog post for the Custom Distribution Service project during the Google Summer of Code timeline.
I have mixed feelings since we are almost near the finish line for one of the most amazing open source programs out there.
However, it is time to wrap things up for this project and achieve a state where the project can be built upon and extended further.
This phase has been super busy with respect to the bug fixes, testing and getting the project hosted, so let us get straight into the phase 3 updates.

Fixes and Code quality assurance

Set Jenkinsfile agent to linux

We realised that the build was failing on windows and that there was not really a use-case
for running it on windows for right now. Maybe it could be on a future roadmap. Therefore, we
decided to shift the testing to only linux agents with respect to running the tests on the jenkins
server.

Pull Request #116

Backend port error message

Spring boot has a default message on the port:8080 and therefore we wanted to change
it to a custom message on the backend. So the major takeaway here is that we needed to
implement the Error Controller interface and include a custom message in it.
This was technical debt from the last phase and was completed and merged during this phase.

Pull Request #92

PMD Analysis

In order to enhance the quality of the code, the PMD source code analyser was applied to the project.
It helped me catch tons of errors. When the initial PMD check was run and we found approximately 162 PMD errors. We realised some of them were not relevant and some of them could be fixed later.

Pull Request #102

Findbugs Analysis

Another tool to improve code quality that we included in this phase was findbugs.
It did catch around 5-10 bugs in my code which I immediately resolved. Most of them were
around the Closeable HTTP Request and an easy fix was the try with resources.

Pull Request #118

Jacoco Code Coverage

We needed to make sure most of the code we write had proper coverage for all branches and
lines. Therefore we decided to include a JaCoco Code Coverage reporter that helped us find the
uncovered lines and areas we need to improve coverage on.

Pull Request #103

Remove JCasC generation

While developing the service we quickly realised that the generation of the war package broke if we
included a configuration as code section but did not provide a path to the corresponding required yml
file. Therefore we took a decision to remove the casc section all together. Maybe it will comeback in
a future patch

Pull Request link: #127

Issue link: #65

Minor Fixes

Logging Fix: #99

Docs Fix : link: #120

Update Center Dump Fix : link: #125

Class Path Fix: link: #126

Release Drafter Addition: link: #136

Front end

Community Config Navigation link

There was no community configuration link present for navigation which was added here.
 Now it is easier to navigate to the community page from the home page itself.

Pull Request #100

Docker updates

Build everything with Docker

This was one of the major changes this phase with respect to making the service very easy to spin up locally, this change will greatly help community adoption since it eliminates the tools one needs to install locally. Initially the process was to run maven locally, generate all of the files and then copy all of its contents into the container. However, with this change we are going to generate all of the files inside the docker container itself. Allowing the user to just run a couple of commands to get the service up and running.

So some of the major changes we did with respect to the dockerfile was:

a) Copy all of the configuration files and pom.xml into the container.

b) Run the command mvn clean package inside the container which generates the jar.

c) Run the jar inside the container.

Pull Request #104

Hosting updates

This process was supposed to be a future roadmap, however the infra team approved and was super helpful
in making this process as smooth as possible. Thanks to Gavin, Tim and Oblak for making this possible.
Here is the google group dicussion

The project has now been hosted here as a preview. It still needs
some fixes to be fully functional.

Infra Docker PR #131

Infra Project Addition PR link: #393

Testing Updates

Unit test the services

With respect to community hosting and adoption, testing of the service one of the most important and major milestones for this phase was to test the majority of the code and we have completed the testing with flying colors. All of the services have been completely unit tested, which is a major accomplishment.
For the testing of the service we decided to go with wiremock which can be used to mock external services. Kezhi’s comment helped us to understand what we needed to do since he had done something quite similar in his Github Checks API project.

So we basically wiremocked the update-center url and made sure we were getting
the accurate response with appropriate control flow logic tested.

wireMockRule.stubFor(get(urlPathMatching(&quot;/getUpdateCenter&quot;))
                .willReturn(aResponse()
                        .withStatus(200)
                        .withHeader(&quot;Content-Type&quot;, &quot;application/json&quot;)
                        .withBody(updateCenterBody)));

Pull Request #105

Add Update Center controller tests

Another major testing change involved testing the controllers. For this we decided to use the wiremock library in java to mock the server response when the controllers were invoked.

For example: If I have a controller that serves in an api called /api/plugin/getPluginList
wiremock can be used to stub out its response when the system is under test. So we use something like this to test it out.

when(updateService.downloadUpdateCenterJSON()).thenReturn(util.convertPayloadToJSON(dummyUpdateBody))

When the particular controller is called the underlying service is mocked and it returns a response according to the one provided by us. To find more details the PR is here.

Pull Request #106

Add Packager Controller Tests

Along with the update center controller tests another controller that needed to be tested was the
packager controller. Also we needed to make sure that all the branches for the controllers were properly tested. Additional details can be found in the PR below.

Pull Request #133

Docker Compose Tests

One problem that we faced the entire phase was the docker containers. We regularly found out that due to
some changes in the codebase the docker container build sometimes broke, or even sometimes the inner api’s seemed to malfunction. In order to counteract that we decided to come up with some tests locally.
So what I did was basically introduce a set of bash scripts that would do the following:

a) Build the container using the docker-compose command.

b) Run the container.

c) Test the api’s using the exposed port.

d) Teardown the running containers.

Pull Request #131

User Documentation

We also included a user docs guide so that it makes it super easy to get started with the service.

Pull Request #145

Future Roadmap

This has been a super exciting project to work on and I can definitely see this project being built
upon and extended in the future.

I would like to talk about some of the features that are left to come in and can be taken up in
a future roadmap discussion

a) JCasC Support :

Description: Support the generation of a Jenkins Configuration as Code file asking the user interactively for the plugins they select what would be the configuration they would want eg: If the user selects the slack plugin we need to ask him questions like what is the slack channel? what is the token? etc, and on the basis of this generate a casc file. This feature was initially planned to go into the service but we realised this is a project in its own capacity.

b) Auto Pull Request Creation :

Description: Allow users to create a configuration file and immediately open a pull request on github
without leaving the user interface. This was originally planned using a github bot and we started the work on it. But we were in doubt if the service would be hosted or not and therefore put the development on hold.
You can find the pull requests here:

Github Controller #72

Pull Request Creation Functions #66

c) Synergy with Image Controller

Description: This feature requires some planning, some of the questions we can ask are:

a) Can we generate the images (i.e Image Controller).
b) Can we have the service as a multipurpose generator ?

Statistics

This phase has been the busiest of all phases and it has involved a lot of work, more than I had
initially expected in the phase. Although lines
of code added is not an indication of work done, however 800 lines of Code added is a real personal milestone for me.

Pull Requests Opened
26

Lines of Code Added
1096

Lines of Docs Added
200

Other links

Gitter Channel Link
GSoC Proposal
Design Document
Daily Notes<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sladyn98/">Sladyn Nunes</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/service">service</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/distribution">distribution</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/packaging">packaging</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/08/31/github-checks-api-plugin-coding-phase-3/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">31</div></div><h5 class="title">GitHub Checks API Plugin Project - Coding Phase 3</h5></div><p class="teaser">This blog post is about our phase 3 progress on GitHub Checks API Project, you can find our previous blog posts for phase 1 and phase 2.

At the end of this summer, the GSoC journey for GitHub Checks API Project comes to an end as well.
In this blog post, I’ll show you our works during the last month:

Pipeline Support

Rerun Request Support

Git SCM Support

Documentation

All the above features will be available in our planned 1.0.0 version of Checks API Plugin and GitHub Checks Plugin.

Coding Phase 3 Demo

Pipeline Support

The pipeline support allows users to directly publish checks in their pipeline script without depending on any other consumers.

The check in the above screenshot is published by script:

publishChecks name: &#x27;pipeline check&#x27;, title: &#x27;pipeline &#x27;, summary: &#x27;# A pipeline check example&#x27;,
        text: &quot;## This check is published through the pipeline script&quot;,
        detailsURL: &#x27;https://ci.jenkins.io&#x27;

If you want to publish checks to GitHub, please install the GitHub implementation and refer to the GitHub API documentation for the requirements for each field. A default value (build link) for detailsURL will be provided automatically.

This feature can be useful when many stages exist in your pipeline script and each takes a long time: you can publish a check for each stage to keep track of the build.

Rerun Request Support

The rerun request allows GitHub users to rerun the failed builds. When a build failed (which leads to a failed check), a Re-run button will be added automatically by GitHub.

By clicking the Re-run button, Jenkins will reschedule a build for the last commit of this branch.

Since all checks of a commit are produced by a single build, you don’t have to rerun all failed checks, just rerun any one of the failed check will refresh all checks.

Git SCM Support

Thanks to Ullrich &#x27;s great help, the GitHub Checks Plugin now supports Git SCM.
This means now you can publish checks for your freestyle project or any other projects that use Git SCM.

Document

Consumers Guide and Implementation Guide are now available.
As a Jenkins developer, you can now start consuming our API or even providing an implementation for other SCM platforms beside GitHub.

Acknowledgment

The whole GitHub Checks API project is started as a Google Summer of Code project. Much appreciate my mentors ( Tim and Ullrich) for their great help during the whole summer. Also huge thanks to the Jenkins GSoC SIG and the whole community for the technique support and resources.

Resources

Checks API Plugin

GitHub Checks Plugin

Project Page

Gitter Channel<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/xiongkezhi/">Kezhi Xiong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/github">github</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/api">api</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/09/10/jenkins-continuous-evolution-cdcon/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">10</div></div><h5 class="title">Learn more about Jenkins&#x27; continuous evolution at CDCon</h5></div><p class="teaser">The Jenkins project has been around for over fifteen years and is the defacto platform for CI/CD. One of the reasons it continues to be so ubiquitous is that Jenkins constantly evolves and offers flexibility to integrate other tools that work well for your solution.

At CDCon, on October 7-8, there are two particular Jenkins talks that will focus on new directions that the Jenkins platform is evolving too and getting better and better for users.

Heard of JCasC and Not Sure Where to Start? Let me Help You!

Configuration as code is a best practice for your CI/CD setup as it makes the complex process of setting up Jenkins simpler and more reproducible. Jenkins Configuration as Code (JCasc) enables Jenkins users to define the whole configuration as a simple, plain text YAML syntax. With JCasc, setting up a new Jenkins controller is easier than ever before. To get started with JCasC some initial effort is required. This talk walks you through a basic setup for easily spinning up new Jenkins instances.

October 7 at 2:20 PM PST
Speaker: Ewelina Wilkosz, Eficode

Ewelina W is passionate about making sure that her customers&#x27; software is being built, tested and released in the best possible way. And, most importantly, that software developers don’t hate the process. Ewelina has been involved in Jenkins Configuration as Code plugin development from the very beginning. This is a must-see talk where Ewelina will also share some tips and tricks. The talk will feature using Docker, Jenkins and GitHub Actions as a quick way to build… Jenkins!

Bridging the Gap with Tekton-client-plugin for Jenkins

Tekton provides Kubernetes-native CI/CD building blocks. It enables users to take full advantage of cloud-native features around scalability and high availability. Jenkins flexibility enables integration with Tekton. This talk showcases the new tekton-client-plugin for Jenkins that enables Jenkins to interact with Tekton pipelines on a Kubernetes cluster. Tekton and Jenkins are both CDF projects and this talk highlights the first steps towards better Tekton and Jenkins interoperability, a key goal of the CD Foundation.

October 7 at 11:40 AM PST
Speaker: Vibhav Bobade, Red Hat

Register for CDCon

Both these talks showcase the ultimate flexibility and power of the Jenkins platform and how it continues to evolve to meet the challenges of modern-day CI/CD. Don’t miss out; register for CDCon to attend.

CDCon has pledged to donate 100% of the proceeds received from CDCon 2020 registration to charitable causes: Black Girls Code, Women Who Code and the CDF Diversity Fund. Registrants indicate which charitable fund they want their 25 USD registration fees to go to during registration. If you can’t afford the registration cost, please apply for the diversity scholarship.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cdfoundation/">Continuous Delivery Foundation</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cdcon">cdcon</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/talks">talks</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jcasc">jcasc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cicd">cicd</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tekton">tekton</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/09/12/new-jenkins-release-observations/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">12</div></div><h5 class="title">Testing Jenkins 2.249.1 on Windows</h5></div><p class="teaser">This article describes our observations during Windows testing of the Jenkins 2.249.1 release candidate.

Upgrade testing

Jenkins 2.249.1 is a new long term support release with user interface improvements and changes in Windows support.
It is the first long term support release to drop support for Microsoft.NET framework 2.0.
The end of support for Microsoft.NET framework 2.0 was announced in the Windows Support Updates blog post.
The Windows support upgrade guidelines describe major things to consider when upgrading Jenkins controllers and agents on Windows.

As part of our preparation for the release, we tested several configurations.
This article describes our experiences with those configurations.

Upgrade approaches

We tested controller and agent upgrades from Jenkins 2.235.x to 2.249.1-rc on Windows.
The tests included:

32 bit Windows MSI

64 bit Windows MSI

WAR (file) on Windows

Upgrade process

Our upgrade process included:

Install a previous version of Jenkins controller on Windows

Install a previous version of Jenkins agent on Windows and configure it as a service

Upgrade Jenkins controller from &quot;Manage Jenkins&quot;

Restart the Jenkins Windows service for the controller

Upgrade the Jenkins agent on Windows with the latest agent.jar

Restart the Jenkins Windows service for the agent

Testing results

We successfully tested

Restarting Windows service for controller ( JENKINS-63198)

Restarting Windows service for agents ( JENKINS-63223)

We confirmed that we can continue our Level 1 support policy for Jenkins 2.249.1.

32 bit Windows MSI

Prior to Jenkins 2.235.3, the Jenkins LTS Windows installer was provided as a 32 bit MSI and included a bundled Java 8 runtime environment.
The Jenkins agent can be downloaded and run through Java web start using the bundled Java 8 runtime environment.
The agent can also be configured to run as a service using the bundled Java 8 runtime environment.

Jenkins controller

Jenkins 2.235.1 installs JRE 8u144 for 32 bit Windows.
The installer configures the Jenkins controller to run as the SYSTEM user.

Refer to the Windows Installer Updates blog post for details of the controller installation process with the 32 bit MSI.

Jenkins agent

Jenkins agents on Windows are often configured to &quot;Launch agent by connecting it to the master&quot;.
The Jenkins agent configuration correctly warns that the controller must open the TCP port for inbound agents in the &quot;Configure Global Security&quot; page.
It is easiest to allow Jenkins to choose the port (a &quot;Random&quot; port).
Jenkins selects a random available port number and shares that port number with agents during their initial connection to the Jenkins http port.

Configure the agent

Once the Jenkins TCP port is open for inbound agents, a new agent is configured from the Jenkins &quot;Nodes&quot; menu
This creates an &quot;inbound Jenkins agent&quot; that uses the Jenkins agent.jar to initiate the connection to the Jenkins controller.

Download the agent

The agent starts the first time by clicking the &quot;Launch&quot; button on the agent configuration page (only available with Java 8).
That downloads the &quot;slave-agent.jnlp&quot; file from the web browser.

Start the agent

The downloaded file needs to be opened from a command prompt using the javaws command that is included with the bundled JRE:

C:\&gt; &quot;C:\Program Files (x86)\Jenkins\jre\bin\javaws.exe&quot; -wait slave-agent.jnlp

The javaws program has been removed from  the most recent releases of Java 8 and from Java 11.
Refer to [Jenkins agent and icedtea] for a technique that can help users of the most recent releases of Java 8.

Java web start (javaws.exe) prompts for permission to run the program with this dialog:

Install the agent as a service

The agent runs and displays a window on the desktop with a single menu entry, &quot;Install as a service&quot;.

When the &quot;Install as a service&quot; menu item is clicked, the agent is adjusted to run as a Windows service using the SYSTEM account.

Upgrade the controller

The Jenkins controller on Windows can be upgraded to Jenkins 2.249.1 from the &quot;Manage Jenkins&quot; page.
The upgrade process downloads the new jenkins.war file, saves the current version in case of later downgrade, and offers to restart.

Upgrade the agent

The Jenkins inbound agent is not upgraded automatically.
The agent administrator downloads the most recent agent.jar from their Jenkins controller, stops the running agent, and replaces the installed agent.jar with the downloaded version.
The agent service will reconnect to the Jenkins controller after the administrator restarts it.

64 bit Windows MSI

Beginning with Jenkins 2.235.3, the Jenkins LTS Windows installer is a 64 bit MSI.
It runs Jenkins with the 64 bit JDK (Java 8 or Java 11) selected by the user.

Jenkins controller

Jenkins 2.235.3 was installed using AdoptOpenJDK Java 8u262 in one test.
It was installed using AdoptOpenJDK Java 11.0.8 in another test.
In both cases, the installer configured the Jenkins controller to run with the Windows service account we had previously configured.

Refer to the Windows Installer Updates blog post for details of the controller installation process with the 64 bit MSI.

Jenkins agent

Jenkins agents on Windows are often configured to &quot;Launch agent by connecting it to the master&quot;.
The Jenkins agent configuration correctly warns that the controller must open the TCP port for inbound agents in the &quot;Configure Global Security&quot; page.
It is easiest to allow Jenkins to choose the port (a &quot;Random&quot; port).
Jenkins selects a random available port number and shares that port number with agents during their initial connection to the Jenkins http port.

Configure the agent

Once the Jenkins TCP port is open for inbound agents, a new agent is configured from the Jenkins &quot;Nodes&quot; menu
This creates an &quot;inbound Jenkins agent&quot; that uses the Jenkins agent.jar to initiate the connection to the Jenkins controller.
Once the Jenkins TCP port is open for inbound agents, a new agent is configured from the Jenkins &quot;Nodes&quot; menu
This creates an &quot;inbound Jenkins agent&quot; that uses the Jenkins agent.jar to initiate the connection to the Jenkins controller.
Once the Jenkins TCP port is open for inbound agents, a new agent is configured from the Jenkins &quot;Nodes&quot; menu
This creates an &quot;inbound Jenkins agent&quot; that uses the Jenkins agent.jar to initiate the connection to the Jenkins controller.

Download the agent

The agent was started the first time by clicking the &quot;Launch&quot; button on the agent configuration page (only available with Java 8).
That downloads the &quot;slave-agent.jnlp&quot; file from the web browser.

Start the agent with IcedTea-Web

Recent versions of Java 8 and all versions of Java 11 have removed the javaws command.
Jenkins agents for Java 8 can still be started with the javaws command, but it needs to be downloaded separately from the JVM.
We open &quot;slave-agent.jnlp&quot; from a command prompt using the javaws command that is available from AdoptOpenJDK IcedTea :

C:\&gt; C:\icedtea-web-1.8.3.win.bin\icedtea-web-image\bin\javaws.exe -wait slave-agent.jnlp

Java web start (javaws.exe) prompts for permission to run the program with this dialog:

Install the agent as a service

The agent runs and displays a window on the desktop with a single menu entry, &quot;Install as a service&quot;.

When the &quot;Install as a service&quot; menu item is clicked, the agent is installed and configured to run as a Windows service using the SYSTEM account.

Upgrading the controller

The Jenkins controller on Windows was upgraded to Jenkins 2.249.1 from the &quot;Manage Jenkins&quot; page.
The upgrade process downloads the new jenkins.war file, saves the current version in case of later downgrade, and offers to restart.

Upgrading the agent

The Jenkins inbound agent is not upgraded automatically or from a Jenkins user interface.
The agent administrator downloads the most recent agent.jar from their Jenkins controller and replaces the installed agent.jar with the downloaded version.

WAR (file) on Windows

Jenkins allows users to run the Jenkins web archive (WAR) file from a command line and then install it as a service from within Jenkins.
This installation technique uses the Jenkins WAR file but does not use a Windows MSI package.
The Jenkins WAR file includes the necessary components to install and configure Jenkins as a service.

Install controller as a service

When the Jenkins war file is started from a Windows command prompt, &quot;Manage Jenkins&quot; includes &quot;Install as a service&quot;.
An administrator selects that entry and Jenkins will configure itself to run as a service/
The installer configures the Jenkins controller to run as the SYSTEM user.

Jenkins agent

Jenkins agents on Windows are often configured to &quot;Launch agent by connecting it to the master&quot;.
The Jenkins agent configuration correctly warns that the controller must open the TCP port for inbound agents in the &quot;Configure Global Security&quot; page.
It is easiest to allow Jenkins to choose the port (a &quot;Random&quot; port).
Jenkins selects a random available port number and shares that port number with agents during their initial connection to the Jenkins http port.

Configure the agent

After opening the Jenkins TCP port for inbound agents, we configured a new agent from the &quot;Nodes&quot; menu
This created an &quot;inbound Jenkins agent&quot; that uses the Jenkins agent.jar to initiate the connection to the Jenkins controller.

Download the agent

The agent was started the first time by clicking the &quot;Launch&quot; button on the agent configuration page (only available with Java 8).
That downloads the &quot;slave-agent.jnlp&quot; file from the web browser.

Start the agent with IcedTea-Web

Recent versions of Java 8 and all versions of Java 11 have removed the javaws command.
Jenkins agents for Java 8 can still be started with the javaws command, but it needs to be downloaded separately from the JVM.
Open &quot;slave-agent.jnlp&quot; from a command prompt using the javaws command that is available from AdoptOpenJDK IcedTea-Web :

C:\&gt; C:\icedtea-web-1.8.3.win.bin\icedtea-web-image\bin\javaws.exe -wait slave-agent.jnlp

Java web start (javaws.exe) prompts for permission to run the program with this dialog:

Install the agent as a service

The agent runs and displays a window on the desktop with a single menu entry, &quot;Install as a service&quot;.

When the &quot;Install as a service&quot; menu item is clicked, the agent is installed and configured to run as a Windows service using the SYSTEM account.

Conclusion

Jenkins controller installation is best done with the new 64 bit MSI package.
Previous controller installations can be upgraded to the most recent Jenkins release from within Jenkins.

Jenkins inbound agent installation is more complicated now that the javaws.exe program is not included in the JDK.
The AdoptOpenJDK IcedTea-Web project allows administrators to install and configure Jenkins inbound agents with most of the ease that was available in prior Java releases.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/vsilverman/">Vlad Silverman</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/windows">windows</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/installers">installers</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/09/19/jenkins-at-devops-world-2020/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">19</div></div><h5 class="title">Jenkins at DevOps World 2020</h5></div><p class="teaser">The annual DevOps World, formerly known as DevOps World | Jenkins World is next week - Sept 22-24, with workshops on Sept 25. Just like other events this year, DevOps World pivoted to a virtual event but that doesn’t mean there is a shortage of sessions or networking opportunities. There will be over 50 Jenkins/open source sessions and opportunities to virtually connect with over 20,000+ attendees on the event platform. Below are just a few sessions, the full agenda can be found HERE :

Jenkins: Where It Is and Where It is Going

Date: Tuesday, September 22, 7:00 a.m.-7:30 a.m (PDT)

Speaker: Oleg Nenashev

Jenkins keeps evolving to address demands from its users and contributors: configuration as code, better support of cloud-native technologies, etc. Recently, we have introduced a public roadmap for the project, and there are many key initiatives in development and preview phases. This session will cover the current state of Jenkins and what’s next for the project.

Managing DevSecOps Pipelines at Scale with Jenkins Templating Engine

Date: Tuesday, September 22, 11:30 a.m.-12:00 p.m. (PDT)

Speaker: Steven Terrana

Are you currently helping build or maintain a Jenkins pipeline for more than one application or team? Are you tired of copying and pasting Jenkinsfiles and tweaking them to fit each team’s specific needs? This session will feature a live demonstration of getting up and running with the Jenkins Templating Engine (JTE). Attendees will learn how to stop creating bespoke pipelines on a per-application basis and, instead, create tool-agnostic pipeline templates that multiple teams can inherit - regardless of tech stack.

eBay’s Journey Building CI at Scale

Date: Tuesday, September 22, 12:30 p.m.-1:00 p.m.(PDT)

Speakers: Ravi Kiran Rao Bukka &amp; Vasumathy Seenuvasan

A scalable CI platform with 6,000+ Jenkins instances serving around 43,000 builds per day on multi-cluster Kubernetes. A system built with metrics, key resource tuning, remediation’s and security in place. Join this session to hear from eBay on their journey of best practices and learnings about open source.

Machine Learning Plugins for Data Science in Jenkins

Date: Wednesday, September 23, 11:00 a.m.-11:15 a.m.(PDT)

Speaker: Loghi Perinpanayagam

Machine Learning has evolved rapidly in the software industry for recent years. Jenkins CI/CD can be a good practice to deliver a high reliable product in the end. We have done an initial startup on this plugin that can be used to build Jupyter Notebooks, Python files and JSON files in Zeppelin format. In addition, the build wrappers could be used to convert Jupyter Notebooks to Python/JSON and/or copy the files to the workspace for more actions.  This Machine Learning plugin will endeavor to satisfy the data science community together with the help of other plugins. Success of this plugin will definitely serve much benefits to the community and Jenkins.

Jenkins UI Gets a Makeover

Date: Thursday, September 24, 7:30 a.m.-8:00 a.m.(PDT)

Speakers: Felix Queiruga &amp; Jeremy Hartley

An overview of the Jenkins UI overhaul. We are taking an iterative approach to gradually refresh the Jenkins UI. This approach will make Jenkins look fresh and modern, without changing the way users are accustomed to working with Jenkins or require plugins to be rewritten to render properly in the new Jenkins UI. Join this session to learn the changes we’ve made and how you can help to improve the Jenkins UI.

The event is free to everyone and recordings will be available on-demand. Registration is required to access the on-demand recordings. And don’t forget to visit the CDF booth in the expo hall for one on one Q&amp;A’s with Jenkins experts.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/conference">conference</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cicd">cicd</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/talks">talks</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workshops">workshops</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/09/24/board-elections/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">24</div></div><h5 class="title">2020 Jenkins Board and Officer elections. Nominations and voter registration are open!</h5></div><p class="teaser">Jenkins 2020 Elections are over, thanks to all participants!
Please see the results announcement.

We are happy to announce the 2020 elections in the Jenkins project!
Nominations are open for two governance board and for all five officer positions,
namely: Security, Events, Release, Infrastructure, and Documentation.
The board positions and officer roles are an essential part of Jenkins&#x27; community governance and well-being.
We invite Jenkins contributors and community members to sign-up for elections and to nominate contributors for the elected roles.
Deadline for nominations is Oct 15, voter registration ends on Nov 02.

These are the second elections held by the Jenkins project.
During the 2019 elections, we elected 3 board members and 5 officers.
You can find the voting results here.
This year, we decided to make a few changes in the election process based on the 2019 elections feedback.

Key dates

Sep 24 - Nominations open, voting sign-up begins.

Oct 15 - Board and officer nominations deadline.

Oct 26 (or later) - List of candidates is published, including personal statements.

Nov 10 - Voting begins. Condorcet Internet Voting Service will be used for voting.

Nov 24 - Voting sign-up is over.

Nov 27 - Voting ends, 11PM UTC.

Dec 03 - Election results are announced and take effect.

Signing up for voting

Any Jenkins individual contributor is eligible to vote in the election
if there was a contribution made before September 01, 2020.
Contribution does not mean a code contribution,
all contributions count:
documentation patches,
code reviews,
substantial issue reports,
issues and mailing list responses,
social media posts,
testing,
etc.
Such a contribution should be public.

You can register to vote in one of two ways:

Fill out this Google Form.
This way requires logging into your Google Account to verify authenticity.

Send an email to jenkins-2020-elections@googlegroups.com.
You will need to provide the information specified here.

During the registration period, the election committee will process the form submissions and prepare a list of the registered voters.
In the case of rejection, one of the election committee members will send a rejection email.
Every individual contributor is expected to vote only once.

Deadline for the voter registration is November 24.

Nominating contributors

Suggestions from the community members are highly valued,
and the board welcomes additional nominations.
If you feel that a particular person is well suited to help guide Jenkins, please submit a name and the reason for your nomination to jenkinsci-board@googlegroups.com.
Self nominations are also welcome.

Deadline for nominations is October 15.

Terms

The terms of office for these elected positions are:

Officer positions (1 year): December 03, 2020 to December 2, 2021

Governing board member (2 years): December 03, 2020 to December 2, 2022

Elections committee

The 2020 elections are coordinated by the Jenkins Governance Board members who are not up for re-election this year:
Alex Earl,
Ullrich Hafner, and
Oleg Nenashev.
These contributors are responsible for managing the process,
preparing the nominee list for elections,
forming and verifying the voter list,
processing the votes,
and announcing the results.

You can contact the election committee via jenkins-2020-elections@googlegroups.com.
Please use this email for any queries and feedback regarding the elections.

References

Jenkins Governance Board and Jenkins Officers

Jenkins Board and Officer Election Process

2019 election results

Elections coordination in the mailing list<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/09/25/document-jenkins-on-kubernetes-introduction/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">25</div></div><h5 class="title">Documenting Jenkins on Kubernetes Introduction</h5></div><p class="teaser">I’m thrilled to announce that I will be participating in Google Season of Docs (GSoD)
2020 with the Jenkins project. I started contributing to Jenkins documentation during the technical writer
exploration phase for Google Season of Docs 2020 and I must say, my journey so far
has been nothing short of amazing majorly because of the supportive community behind this project.
I chose the Jenkins project because I understood this project from a user point of view as I had been exposed to setting up, configuring,
and using Jenkins to automate CI/CD processes. I piqued interest in two of Jenkins project ideas,
Plugin documentation migration and update and Document Jenkins on Kubernetes, submitted proposals for these two projects and to my utmost joy, the latter was selected.

In this article, I’m going to be explaining what my selected project is about and why this project is important to the Jenkins community and its users.

Introduction

Kubernetes is a platform-agnostic container orchestration tool created by Google and heavily supported
by the open-source community as a project of the Cloud Native Computing Foundation.
It allows you to use container instances and manage them for scaling and fault tolerance.
It also handles a wide range of management activities that would otherwise require separate solutions or custom code,
including request routing, container discovery, health checks, and rolling updates.

Kubernetes is compatible with the majority of CI/CD tools which allow developers to run tests,
deploy builds in Kubernetes and update applications with no downtime.
One of the most popular CI/CD tools now is Jenkins for the following reasons:

It is open-source and free.

it is user-friendly, easy to install and does not require additional installations or components.

Jenkins is also quite easy to configure, modify and extend.

It deploys code and generates test reports.

It also boasts a rich plugin ecosystem. The extensive pool of plugins makes Jenkins flexible and allows building, deploying and automating across various platforms.

Jenkins can be configured according to the requirements for continuous integrations and continuous delivery.

Jenkins is available for all platforms and different operating systems, whether it is OS X, Windows or Linux.

Most of the integration work is automated. Hence fewer integration issues. This saves both time and money over the lifespan of a project.

The following reasons have made Jenkins on Kubernetes a popular theme for Jenkins users, however,
there’s currently no central location for documentation describing Jenkins on Kubernetes,
thereby making it difficult for Jenkins on Kubernetes users to navigate and find information.
This project would create a new Kubernetes Volume on Jenkins.io which would describe the concepts,
techniques, and choices for Kubernetes users running Jenkins.

Current State

There are a lot of presentations and articles about running Jenkins on Kubernetes, however,
there’s no central location for describing Jenkins on Kubernetes. This makes it difficult for:

Jenkins on Kubernetes users to navigate and find information

Track, update and maintain information on Jenkins on Kubernetes

Project Improvements

To solve the existing issue with Jenkins on Kubernetes documentation,
a new Kubernetes volume will be created on Jenkins.io.
This Volume is going to aggregate user guides, information on cloud providers and demos on Jenkins on Kubernetes.
You can find the proposed contents for the new volume here.
Feel free to comment on any suggestions you might have in the proposed content doc.

This project will also provide the following advantages:

Improve the user experience of Jenkins on Kubernetes users by giving them a one-stop-shop for information on Jenkins on Kubernetes.

Make it easy to track, update and maintain information on Jenkins on Kubernetes using the Solutions page

Reference the existing community documentation for Jenkins on K8s (plugins and tools/integrations).

How to guides, tutorials and explanations of concepts and techniques in Jenkins on Kubernetes.

Just-In-Time documentation which means that rather than documenting every feature comprehensively,
we will produce and release documentation in bits but continuously based on popular questions,
feedback and area of interests gathered from the community and users.

Project Timeline

Find below a summary of the project timeline.

Community bonding ( August 17 - September 13 )

Set up a communication channel and time (due to time difference).

Refine my goals and set expectations on both sides.

Learn more about the community and Jenkins.

Gather and thoroughly study existing resources that will be useful and helpful to the project.

Pre-planning of the project

Contacting Stakeholders and onboarding contributors

Documentation Period

This period is going to be focused on creating contents which include user guides,
tutorials, demos, etc. for Jenkins on Kubernetes.
Some of the topics to be covered include Installing Jenkins on Kubernetes,
Administering Jenkins on Kubernetes, Cloud providers and much more.

Documentation Timeline

1st Month (September - October)

Some basic prerequisites for installing jenkins on kubernetes include docker, a kubernetes cluster, and optionally Helm or the Jenkins Operator for Kubernetes.

Helm is a package manager which automates the process of installing, configuring, upgrading, and removing complex Kubernetes application. A Helm chart defines several Kubernetes resources as a set. Helm can make deployments easier and repeatable because all resources for an application are deployed by running one command.

Helm has two elements, a client (helm) and a server (Tiller). The server element runs inside a Kubernetes cluster and manages the installation of charts. With Helm, configuration settings are kept in values.yaml file separate from the manifest formats. The configuration values can be changed according to application need without touching the rest of the manifest.

On the other hand, the Jenkins operator is a Kubernetes native operator which fully manages Jenkins on Kubernetes. It is easy to install with just a few manifests and allows users to configure and manage Jenkins on Kubernetes. To run jenkins-operator, you need to have a running Kubernetes cluster and kubectl installed.

The Jenkins Operator provides out of the box:

Integration with Kubernetes — preconfigured kubernetes-plugin for provisioning dynamic Jenkins Slaves as Pods

Pipelines as Code — declarative way to version your pipelines in VCS

Extensibility via Groovy scripts or Configuration as Code plugin-customize your Jenkins, configure OAuth authorization and more

Security and Hardening — an initial security hardening of Jenkins instance via Groovy scripts to prevent security vulnerabilities

In the first month, the focus will be on documenting an introductory section.
This section will include but is not limited to Setting up Kubernetes cluster, Installing Jenkins on Kubernetes, exploring the various approaches by which this can be achieved such as using helm package manager or the Jenkins Operator as explained above and Administering Jenkins on Kubernetes.

2nd Month (October - November)

In the second month, the focus will be on documenting how to setup up CI/CD pipelines using Jenkins and Kubernetes on different cloud providers.
Some of the cloud providers we will be looking at include but are not limited to:

Amazon Web Service (AWS)

Azure Kubernetes Service

Google Cloud

3rd Month (November - December)

In the final month, the focus will be on creating demos and tutorials,
submitting project report, evaluation of mentors and finally,
publishing a report of my experience as a participant in Season of Docs.

Conclusion

Jenkins community is actively working towards improving its documentation to create a better
experience for Jenkins users and invites technical writers to join the community and contribute to the Jenkins on Kubernetes project.

To contribute to the Jenkins on Kubernetes project, simply join the Jenkins documentation Gitter channel and drop a message,
you can also find the Google season of docs office hour notes and recordings for Jenkins on Kubernetes here.
GSOD office hours take place twice a week on Mondays and Thursdays between 6pm GMT+1 and 7pm GMT+1,
if you would like to be part of these meetings, you can indicate interest in the Jenkins Documentation
Gitter channel and we would be happy to have you.

If you are also a newcomer and would like to contribute to Jenkins, documentation is a great place to contribute.
A lot of small patches can be done from the GitHub web interface even without cloning repositories locally.
You can find some good first issues to get started with here.

Find more information on contributing to Jenkins documentation here.
If you have further questions about the Jenkins on Kubernetes project or contributing to Jenkins,
you can reach out on the Jenkins documentation Gitter channel.

Additional Resources

GSoD Proposal

GSoD Office Hours Notes

Google Season of Docs - Startup

Google Season of Docs on jenkins.io

Docs SIG for Google Season of Docs startup ( video)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/zaycodes/">Zainab Abubakar</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsod">gsod</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsod2020">gsod2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/10/20/Cross-Industry-DevOps-3-Firms-Get-It-Right-with-Jenkins/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">20</div></div><h5 class="title">Cross-Industry DevOps: 3 Firms Get It Right with Jenkins</h5></div><p class="teaser">Some months ago, we took a significant step in helping the Jenkins community share their stories of how they improved workflows, sped up testing, and saw better quality results after implementing Jenkins into their software development processes.

By the end of the year, we’ll have over 50 Jenkins user stories published with many more in the pipeline. We invite you to explore them all but wanted to share three inspiring examples highlighting how various organizations approach — and implement — Jenkins in the workplace. Enjoy!

Story 1: Jenkins is the way to tackle any challenge

Enterprise-wide CI/CD solution caters to the complex problems that project teams face each day, as told by Jenkins user Mark Baumann:

“Our development teams work in a wide range of projects and domains. We have a very diverse tooling landscape since the projects work with all kinds of different software tools. Of course, projects in the embedded domain will have different toolsets than those working in the automotive domain.

Each project team created its own CI Toolchain, which caused a lot of work for the developers and the IT department. Each project needed to set up their own virtual machine, install and manage their own CI Server, Version Management, and whatever they needed. Creating such a toolchain could easily take up weeks until it was running because there was no standard solution and each team had to start from scratch.”

Discover how ITK-Engineering GmbH developed a company-wide, common, internal CI/CD toolchain and increased the number of builds for each project and how nearly all departments are now practicing CI/CD. The full Jenkins / ITK Engineering story is here!

Story 2: Jenkins is the way to add spicy flavors to agency processes

A creative agency start-up simplifies the build, test, and deploy steps, allowing the small team to focus more on the deliverables and less on the process. As told by Jenkins user Erik Woitschig:

“It was quite a challenge to streamline and combine all the services to build an artifact to deploy. Because of our micro service-oriented and distributed architecture, the most challenging part of rethinking our build, test, and deploy process was to figure out how best to sync the deployment of all services. We also had to retest builds properly to go live or initiate a rollback.

With Jenkins and some pipelines, it was relatively simple to create a local and distributed artifact of our application to quickly share and deploy across the team, locally and globally.”

Because Jenkins is simple to install and easy to maintain, Muzkat has increased productivity far beyond that of a 3-person team. Read on to learn how this bootstrapped Berlin-based agency is making a go of it with Jenkins. The full Jenkins / Muzkat story is here!

Story 3: Jenkins is the way to focus on your code

As demands for the Wright Medical’s services grew, they required an agile DevOps environment that would grow and scale along with the tech team, as told by Jenkins user Christophe Carpentier:

“What was critical to our success was the stability of Jenkins and a significant number of reliable plugins! We could take a few plugins, set up our workflow, and add GitLab and SonarQube integration without ever stopping or losing data in over a year. We found that all of the problems we encountered were our own, and that is why it was critical to make Jenkins an essential part of our workflow.

With this implementation, Jenkins allows more than would be manually possible. It flawlessly updates our staging environments, blocks commits based on the SonarQube analysis, and provides us with near-instant feedback on merge requests.”

Learn how Wright Medical supports a growing dev team by switching to an agile DevOps process that allows for automatic daily releases — versus weekly manual builds. Best of all, it’s letting the developers focus on building great code rather than infrastructure. The full Jenkins / Wright Medical story is here!

What are you building?

Hope you enjoy these Jenkins user stories. You’ll find that “Jenkins Is The Way” website is a global showcase of how developers and engineers build, deploy, and automate great stuff with Jenkins. If you want to share your story, we’ll send you a free Jenkins Is The Way T-Shirt in return. Hope to hear from you soon!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsistheway">jenkinsistheway</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/Jenkinsuserstories">Jenkinsuserstories</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/10/21/a-sustainable-pattern-with-shared-library/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">21</div></div><h5 class="title">A sustainable pattern with shared library</h5></div><p class="teaser">Table of Contents

Context
The Problems
The Solution

Shared Library
Duplication
Documentation
Scalability
Installation Agnostic
Feature Toggling

This post will describe how I use a shared library in Jenkins. Typically when using multibranch pipeline.

If possible (if not forced to) I implement the pipelines without multibranch. I previously wrote about how I do that with my Generic Webhook Trigger Plugin in a previous post. But this will be my second choice, If I am not allowed to remove the Jenkinsfile :s from the repositories entirely.

Context

Within an organization, you typically have a few different kinds of repositories. Each repository versioning one application. You may use different techniques for different kinds of applications. The Jenkins organization on GitHub is an example with 2300 repositories.

The Problems

Large Jenkinsfiles in every repository containing duplicated code. It seems common that the Jenkinsfile :s in every repository contains much more than just the things that are unique for that repository. The shared libraries feature may not be used, or it is used but not with an optimal pattern.

Installation specific Jenkinsfile:s that only work with one specific Jenkins installation. Sometimes I see multiple Jenkinsfile :s, one for each purpose or Jenkins installation.

No documentation and/or no natural place to write documentation.

Development is slow. Adding new features to repositories is a time consuming task. I want to be able to push features to 1000+ repositories without having to update their Jenkinsfile :s.

No flexible way of doing feature toggling. When maintaining a large number of repositories it is sometimes nice to introduce a feature to a subset of those repositories. If that works well, the feature is introduced to all repositories.

The Solution

My solution is a pattern that is inspired by how the Jenkins organization on GitHub does it with its buildPlugin(). But it is not exactly the same.

Shared Library

Here is how I organize my shared libraries.

Jenkinsfile

I put this in the Jenkinsfile :s:

buildRepo()

Default Configuration

I provide a default configuration that any repository will get, if no other configuration is given in buildRepo().

I create a vars/getConfig.groovy with:

def call(givenConfig = [:]) {
  def defaultConfig = [
    /**
      * The Jenkins node, or label, that will be allocated for this build.
      */
    &quot;jenkinsNode&quot;: &quot;BUILD&quot;,
    /**
      * All config specific to NPM repo type.
      */
    &quot;npm&quot;: [
      /**
        * Whether or not to run Cypress tests, if there are any.
        */
      &quot;cypress&quot;: true
    ],
    &quot;maven&quot;: [
      /**
        * Whether or not to run integration tests, if there are any.
        */
      &quot;integTest&quot;: true
    ]
  ]
  // https://e.printstacktrace.blog/how-to-merge-two-maps-in-groovy/
  def effectiveConfig merge(defaultConfig, givenConfig)
  println &quot;Configuration is documented here: https://whereverYouHos/getConfig.groovy&quot;
  println &quot;Default config: &quot; + defaultConfig
  println &quot;Given config: &quot; + givenConfig
  println &quot;Effective config: &quot; + effectiveConfig
  return effectiveConfig
}

Build Plan

I construct a build plan as early as possible. Taking decisions on what will be done in this build. So that the rest of the code becomes more streamlined.

I try to rely as much as possible on conventions. I may provide configuration that lets users turn off features, but they are otherwise turned on if they are detected.

I create a vars/getBuildPlan.groovy with:

def call(effectiveConfig = [:]) {
  def derivedBuildPlan = [
    &quot;repoType&quot;: &quot;NOT DETECTED&quot;
    &quot;npm&quot;: [],
    &quot;maven&quot;: []
  ]

  node {
    deleteDir()
    checkout([$class: &#x27;GitSCM&#x27;,
      branches: [[name: &#x27;*/branchName&#x27;]],
      extensions: [
          [$class: &#x27;SparseCheckoutPaths&#x27;,
            sparseCheckoutPaths:
            [[$class:&#x27;SparseCheckoutPath&#x27;, path:&#x27;package.json,pom.xml&#x27;]]
          ]
      ],
      userRemoteConfigs: [[credentialsId: &#x27;someID&#x27;,
      url: &#x27;git@link.git&#x27;]]
    ])

    if (fileExists(&#x27;package.json&#x27;)) {
      def packageJSON = readJSON file: &#x27;package.json&#x27;
      derivedBuildPlan.repoType = &quot;NPM&quot;
      derivedBuildPlan.npm.cypress = effectiveConfig.npm.cypress &amp;&amp; packageJSON.devDependencies.cypress
      derivedBuildPlan.npm.eslint = packageJSON.devDependencies.eslint
      derivedBuildPlan.npm.tslint = packageJSON.devDependencies.tslint
    } else if (fileExists(&#x27;pom.xml&#x27;)) {
      derivedBuildPlan.repoType = &quot;MAVEN&quot;
      derivedBuildPlan.maven.integTest = effectiveConfig.maven.integTest &amp;&amp; fileExists(&#x27;src/integtest&#x27;)
    } else {
      throw RuntimeException(&#x27;Unable to detect repoType&#x27;)
    }

    println &quot;Build plan: &quot; + derivedBuildPlan
    deleteDir()
  }
  return derivedBuildPlan
}

Public API

This is the public API, this is what I want the users of this library to actually invoke.

I implement a buildRepo() method that will use that default configuration. It can also be called with a subset of the default configuration to tweak it.

I create a vars/buildRepo.groovy with:

def call(givenConfig = [:]) {
  def effectiveConfig = getConfig(givenConfig)
  def buildPlan = getBuildPlan(effectiveConfig)

  if (effectiveConfig.repoType == &#x27;MAVEN&#x27;)
    buildRepoMaven(buildPlan);
  } else if (effectiveConfig.repoType == &#x27;NPM&#x27;)
    buildRepoNpm(buildPlan);
  }
}

A user can get all the default behavior with:

buildRepo()

A user can also choose not to run Cypress, even if it exists in the repository:

buildRepo([
  &quot;npm&quot;: [
    &quot;cypress&quot;: false
  ]
])

Supporting Methods

This is usually much more complex, but I put some code here just to have a complete implementation.

I create a vars/buildRepoNpm.groovy with:

def call(buildPlan = [:]) {
  node(buildPlan.jenkinsNode) {
    stage(&quot;Install&quot;) {
      sh &quot;npm install&quot;
    }
    stage(&quot;Build&quot;) {
      sh &quot;npm run build&quot;
    }
    if (buildPlan.npm.tslint) {
      stage(&quot;TSlint&quot;) {
        sh &quot;npm run tslint&quot;
      }
    }
    if (buildPlan.npm.eslint) {
      stage(&quot;ESlint&quot;) {
        sh &quot;npm run eslint&quot;
      }
    }
    if (buildPlan.npm.cypress) {
      stage(&quot;Cypress&quot;) {
        sh &quot;npm run e2e:cypress&quot;
      }
    }
  }
}

I create a vars/buildRepoMaven.groovy with:

def call(buildPlan = [:]) {
  node(buildPlan.jenkinsNode) {
    if (buildPlan.maven.integTest) {
      stage(&quot;Verify&quot;) {
        sh &quot;mvn verify&quot;
      }
    } else {
      stage(&quot;Package&quot;) {
        sh &quot;mvn package&quot;
      }
    }
  }
}

Duplication

The Jenkinsfile :s are kept extremely small. It is only when they, for some reason, diverge from the default config that they need to be changed.

Documentation

There is one single point where documentation is written, the getConfig.groovy -file. It can be referred to whenever someone asks for documentation.

Scalability

This is a highly scalable pattern. Both with regards to performance and maintainability in code.

It scales in performance because the Jenkinsfile :s can be used by any Jenkins installation. So that you can scale by adding several completely separate Jenkins installations, not only nodes.

It scales in code because it adds just a tiny Jenkinsfile to repositories. It relies on conventions instead, like the existence of attributes in package.json and location of integration tests in src/integtest.

Installation Agnostic

The Jenkinsfile :s does not point at any implementation of this API. It just invokes it and it is up to the Jenkins installation to implement it, with a shared libraries.

It can even be used by something that is not Jenkins. Perhaps you decide to do something in a Docker container, you can still parse the Jenkinsfile with Groovy or (with some magic) with any language.

Feature Toggling

The shared library can do feature toggling by:

Letting some feature be enabled by default for every repository with name starting with x.

Or, adding some default config saying&quot;feature-x-enabled&quot;: false, while some repos change their Jenkinsfile :s to buildRepo([&quot;feature-x-enabled&quot;: true]).

Whenever the feature feels stable, it can be enabled for everyone by changing only the shared library.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/tomasbjerre/">Tomas Bjerre</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/scalability">scalability</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/sharedlibrary">sharedlibrary</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/10/28/election-candidates/"><div class="header"><div class="date"><div class="month">Oct</div><div class="day">28</div></div><h5 class="title">2020 Elections: Governance Board and Officer candidates</h5></div><p class="teaser">Jenkins 2020 Elections are over, thanks to all participants!
Please see the results announcement.

As you probably know, in a few weeks we will have the Jenkins 2020 elections.
We will be electing two governance board members and five officers,
namely: Security, Events, Release, Infrastructure, and Documentation.
After the announcement on Sep 24,
we have been accepting nominations from community members.

After the processing and confirmations with potential candidates,
the Jenkins 2020 Elections committee is happy to announce the candidates for the Jenkins Governance Board and Officer roles:

Governance Board candidates: Andrey Falko, Ewelina Wilkosz, Frederic Gurr, Gavin Mogan, Justin Harringa, Mark Waite, Marky Jackson, Steven Terrana, Zhao Xiaojie (Rick)

Release officer: Baptiste Mathus, Tim Jacomb, Victor Martinez

Security officer: Daniel Beck (uncontested)

Events officer: Marky Jackson (uncontested)

Infrastructure Officer: Olivier Vernin (uncontested)

Documentation officer: Mark Waite (uncontested)

We encourage all community members to support the candidates and to participate in the elections!

Key dates

Nov 10 - Voting begins. Condorcet Internet Voting Service will be used for voting.

Nov 24 - Voting sign-up is over.

Nov 27 - Voting ends, 11PM UTC.

Dec 03 - Election results are announced and take effect.

Signing up for voting

Any Jenkins individual contributor is eligible to vote in the election
if there was a contribution made before September 01, 2020.
Contribution does not mean a code contribution,
all contributions count:
documentation patches,
code reviews,
substantial issue reports,
issues and mailing list responses,
social media posts,
testing,
etc.
Such a contribution should be public.

You can register to vote in one of two ways:

Fill out this Google Form.
This way requires logging into your Google Account to verify authenticity.

Send an email to jenkins-2020-elections@googlegroups.com.
You will need to provide the information specified here.

Once sign-up is over, the election committee will process the form submissions and prepare a list of the registered voters.
In the case of rejection, one of the election committee members will send a rejection email.
Every individual contributor is expected to vote only once.

Candidates

Below you can find statements, affiliations and profile links provided by the candidates.

Minimum copy-editing was applied to the content by the Jenkins 2020 Elections Committee.
Candidates are sorted by the first name.

Governance Board

Andrey Falko

I have been a Jenkins user and administrator on and off since around 2010.
In 2016, I got into evangelism by organizing a
Jenkins Area Meetup in San Francisco.
I spoke at Jenkins World 2017
and again at
Jenkins World 2018.
Justin Harringa and I wrote and open sourced the Config Driven Pipeline Plugin.
For two years running, I’ve been a mentor for two Google Summer of Code projects:
External Fingerprint Storage Project and
Remoting over Apache Kafka with Kubernetes features.

With this nomination, I hope to continue helping strengthen and
progress the community further. As a member of the governance board,
I’ll bring a fresh perspective by asking questions, providing feedback,
and finding opportunities for others to contribute.

Profile links:
GitHub,
LinkedIn

Affiliations: Stripe

Ewelina Wilkosz

As a consultant I support my customers with their Jenkins issues since the beginning of 2017.
And almost from the start it was some kind of &quot;as code&quot; approach.
The experience I gained during that time resulted in getting myself involved in the development of Configuration as Code Plugin for Jenkins.
I consider becoming a part of Jenkins Community one of the most valuable experiences in my career so far.
I appreciate how much I have learned and how welcoming the community is.

I am not a very active contributor these days, at least when it comes to code, but what I have to offer is rather extensive experience
with Jenkins end users - from small, single instance setups to environments with hundreds of controllers run in a different way on different operating systems.
Every day I see challenges those users go through, I know what issues they are facing and which features they consider valuable or missing.
As a Jenkins Governance Board Member I can represent those users.

Thanks to my involvement in Configuration as Code Plugin development
I had a chance to deliver a number of public presentations
where I focused on the benefits of the solution and tried to make it easier for newcomers to try it.
Here are a few examples of my activities related to Jenkins Configuration as Code:
blogpost,
cdCON presentation,
podcast recording.
So my focus is not only on representing users but also on educating them, and educating myself,
so I actually know what they need and why.

Profile links:
GitHub,
LinkedIn,
Twitter

Affiliations: Eficode (former Praqma)

Frederic Gurr

I started to use Jenkins back in 2008, when it still had a different name.
In 2011 I started to contribute and created my first little plugin called
extra-columns.
Since then, using and administering Jenkins servers has become a major part of my work life,
while getting involved with the Jenkins community
kickstarted my interest and involvement with open source software and communities.

I’ve been working as a release engineer at the Eclipse Foundation since 2016,
supporting 250+ Jenkins instances for various open source projects.
I’d be honored to bring a user and admin oriented perspective to the Governance Board and help
shape the future of Jenkins.

Profile links:
GitHub,
Twitter

Affiliations: Eclipse Foundation

Gavin Mogan

I got started with Jenkins early on when I was just getting started with testing.
I knew there had to be a way to run the tests automatically and report on them back to people.
I started hacking my own tools before I came across Jenkins (then Hudson) and was hooked ever since.
Over the years I’ve managed to install and configure Jenkins at various jobs,
and even was employed making internal and external plugins and integrations.
You’ll often find me on the Jenkins IRC and Gitter channels as well as the subreddit giving a hand to people who are stuck.
I also try to get involved with Jenkins Infrastructure projects as much as I can.
I currently maintain the plugin site, plugin site API, Jenkins Wiki exporter, and a bunch of other minor projects.
I also help run Vancouver’s chapter of Nodeschool.

If elected, I would like to address improving commercial support avenues.
Right now it’s a lot of people flailing in isolation.
I would like to not only improve things so people can find easier ways to get help,
but also encourage more users to help others, and push for a
centralized source of companies providing commercial support.

Profile links:
GitHub,
Twitter

Affiliations: Digital Ocean, Nodeschool Vancouver

Justin Harringa

The nomination is quite an honor for me.
I have been a Hudson/Jenkins user since around 2009/2010 when
I started working through driving continuous integration in a corporate environment at John Deere.
As time went on, I began contributing some small fixes to plugins such as the Job DSL Plugin, OpenID Plugin, and the Workflow Job Plugin.
Eventually, I ended up helping maintain Salesforce’s Chatter plugin and then open sourcing plugins such as the Config-Driven Pipeline Plugin with Andrey Falko.
More recently, I have also had the extreme pleasure of mentoring in 2 Jenkins projects for Google Summer of Code
(Multi-branch Pipeline support for Gitlab in 2019 and Git Plugin Performance Improvements in 2020).

I have learned so much from working with Jenkins and I would love to give back to the project further.
Having introduced Jenkins at both small and large companies,
I would love to help contribute to the direction of the project through the Roadmap/SIGs/JEPs and encourage others to also contribute / improve Jenkins.

Profile links:
GitHub,
Twitter,
LinkedIn

Affiliations: Salesforce, Spinnaker SIG for Azure

Mark Waite

I’m a Jenkins contributor, a member of the Jenkins core team,
one of the leaders of the Platform Special Interest Group,
and leader of the Documentation Special Interest Group.
I’ve served as the Jenkins Documentation Officer since 2019.
I was a mentor for Google Season of Code 2020 and am one of the maintainers of the Git plugin for Jenkins.

If elected and allowed to serve on the Jenkins Board, I’ll work to increase community involvement and community development.
I’m deeply interested in tooling and environments that support the Jenkins project,
including the Jenkins CI environments, issue tracker, artifact repository, and source code repositories.

Profile links:
GitHub,
Twitter,
LinkedIn,
Jenkins Blog

Affiliations: CloudBees

Marky Jackson

I have been involved in the Jenkins project for many years.
I started out as a plugin maintainer, SIG member and general helper.
I moved to a SIG lead, speakers and Google Summer of Code and Docs org admin and mentor.
My current goals are to help continue the work of the public roadmap as well and gain most community members by continuing to be a champion of the community.

For me, being on the Jenkins Board is another opportunity to improve upon the great work
we have all done as well as work toward branching out our efforts to have more women, people of color and LGBTQIA members.
I would be honored to have this opportunity.

Profile links:
GitHub,
Twitter,
LinkedIn,
Jenkins Blog

Affiliations: Equinix Metal, Continuous Delivery Foundation, Kubernetes, Ortelius

Steven Terrana

I have been a Jenkins user since 2017 and contributor since 2018.
I am the primary maintainer of the Jenkins Templating Engine,
a plugin that allows users to create truly templated Jenkins pipelines that can be shared across teams.
Through that work, I’ve had the great pleasure of helping to organize the Pipeline Authoring Special Interest Group,
contributing to the Jenkins Pipeline documentation, and contributing bug fixes to various plugins
(including the pipeline plugin and workflow-cps library).

As a Continuous Delivery Foundation Ambassador,
I’ve enjoyed doing what I can to advance the community’s approach to CI/CD and simplifying DevSecOps adoption within large organizations.
It would be a privilege to serve on the Jenkins Governance Board and offer my support wherever I can.

Profile links:
GitHub,
LinkedIn

Affiliations: Booz Allen Hamilton, Continuous Delivery Foundation

Zhao Xiaojie (Rick)

Three years ago I joined the Jenkins community.
I learned a lot during the process of contributing.
I even became a Jenkins hero in my city.
The most exciting thing I want to do is help more new users of Jenkins get started, and let more contributors feel comfortable.
I always love to host a JAM no matter if it’s online or offline.

Plans: improve the experience of using Jenkins in different
countries; reorganize the knowledge of Jenkins, for example the tutorial
by text or video format; help other SIG leaders to organize meetings.

Profile links:
GitHub,
Twitter

Affiliations: N/A

Release Officer

Baptiste Mathus

I have been using and contributing to Jenkins for so long that it is difficult for me to check when it started exactly.
My first pull-request to Jenkins was in 2011 and I had started to use it long before it.
Throughout the years, I have contributed to various areas:
created our local Jenkins Area Meetup with Michaël Pailloncy,
helped users and developers on our mailing lists and IRC channels,
contributed to the Jenkins infrastructure, the website,
processing plugins hosting requests, worked full time on Jenkins Evergreen,
and I am still present today.

For all these reasons, it would be an honor to serve as the Release Officer for the Jenkins Project.

Profile links:
GitHub,
Twitter,
Jenkins Blog

Affiliations: CloudBees

Tim Jacomb

I have been a user of Jenkins for the last 8 years and a regular contributor since 2018.
I began with maintaining the Slack plugin and over the last couple of years I have since expanded that to many more plugins and the Jenkins core.
These are some of the components I maintain when I have time: Slack, Azure Key Vault, Junit,
most of the Database plugins, Dark theme, Plugin installation manager, Jenkins Helm chart, Configuration as code plugin.
I am also a member of the Jenkins infrastructure team,
and I was involved in the release automation project and the mirrors modernisation effort,
along with the day to day support helping people regain access to accounts etc.

As a Release Officer I would like to increase automation,
ease onboarding of new contributors to the release team, and ensure that
responsibilities rotate among people so that I wouldn’t be a bottleneck for any task.

Profile links:
GitHub,
Jenkins Blog

Affiliations: Kainos

Victor Martinez

I have been involved in the Jenkins project since 2011 by different means, as a user, as an administrator, as a contributor
(bug reporting, plugin development, documentation, hackfest),
being active in the different Jenkins forums such as the Jenkins-dev and Jenkins-user mailing lists,
working with the jenkins-infra shared library and so on.
I’m also an advocate for the Jenkins project through some presentations anytime that I had the opportunity such as
DevOps World 2020 and
Jenkins World 2017.

I’ve been happily nominated for the Release officer role which matches not just my area of professional expertise that
I’ve been doing for the last 14 years in different roles for different companies but also that’s an area of personal interest
where I’d like to spend time with the Jenkins community to understand, document and automate the process
in a way we can keep the project sustainable for a long term as it’s today,
it’s not just about what I can bring for the community but also about growing together.

If elected as a Release officer I would aim to focus on the following areas:
proceed with the existing responsibilities for this role;
document and automate the release process;
being an enabler for the Continuous Delivery not just for the plugins but also for the core.

Profile links:
GitHub,
LinkedIn

Affiliations: Elastic

Security Officer - uncontested

Daniel Beck

I’ve been a Jenkins user since 2011, contributor since 2013, and core maintainer since 2014.
In 2015, I took on the scheduling and authoring of security advisories and have been doing that ever since,
working with reporters, maintainers, and the Jenkins security team to deliver security fixes.
Beyond that, I regularly contribute to Jenkins and project infrastructure.

Since I’ve started in the Security Officer role, we’ve made significant
improvements:
Plugins no longer allow ordinary users to run arbitrary scripts (no sandbox!) as a regular feature. I introduced fine-grained permission management
for our GitHub repositories and
the Maven repository hosting our releases.
Warnings directly in Jenkins inform admins when an installed component has known security issues (and their UX was improved earlier this year).
The Jenkins project is now a CVE Numbers Authority,
to ensure timely and high-quality information in the CVE vulnerability database.
Working with Tyler, I added telemetry to Jenkins,
which allowed us to deliver multiple large-scale security fixes with
minimal impact.
More recently, I’ve started writing code scanning rules for common problems in Jenkins and
invited maintainers to sign their plugins up,
which is something I hope to properly publish and roll out more widely soon.

Profile links:
GitHub
Jenkins Blog

Affiliations: CloudBees

Events Officer - uncontested

Marky Jackson

I have been a part of the Jenkins community for some time, and I have received the utmost joy in volunteering.
I have been extremely fortunate to have played a lead role in the Outreach &amp; Advocacy SIG, the pipeline-Authoring SIG,
and, most recently, the Cloud-Native SIG.
I have taken part in many meetups, org admin, and mentor in the GSoC &amp; GSoD.
Finally, At DevOps World 2020, I received Jenkins most valuable advocate at DevOps World.
I have experience advocating in other communities as well:
Kubernetes Release Manager Associate, Kubernetes Mentoring Lead, Ortelius Community Manager.

Jenkins is the most widely used Continuous Integration tool around,
and I want to continue to promote that by focusing on the following areas: meetups; conference presentation from the Jenkins community;
new user outreach and onboarding; cross-community collaboration (e.g., Kubernetes community);
working with the Continuous Delivery Foundation on interoperability; focusing on SIG events.

My roots are open-source, and I am so proud to be a part of the Jenkins community.
You can read more about my journey in open-source here.
You can also see some of my presentations here and
here.

Profile links:
GitHub,
Twitter,
LinkedIn,
Jenkins Blog

Affiliations: OpsMx, Continuous Delivery Foundation, Kubernetes, Ortelius, Spinnaker

Infrastructure Officer - uncontested

Olivier Vernin

I have been actively contributing to the Jenkins project for the past four years with contributions across many areas,
and infrastructure is one of my favorite topics.
Over my previous mandate as a Jenkins infrastructure officer, I focused on improving contribution experience,
and let community members opportunities to take ownership of the different services.
I worked on various sponsoring initiatives to make the Jenkins infrastructure more sustainable.
We provided a new environment for releasing Jenkins core (and one plugin!), and also many more things.

For the coming year, It is hard to make commitments on what it will look like as we have things we know,
like services that need some attention (“ci.jenkins.io/) and the things we don’t know yet.
Anyway, It’s important to me to have a transparent project where everybody could read, learn, participate,
and understand how the Jenkins project manages infrastructure and I want to continue down that path.

Profile links:
GitHub,
Twitter,
Jenkins Blog

Affiliations: CloudBees

Documentation Officer - uncontested

Mark Waite

I’m a Jenkins contributor, a member of the Jenkins core team, one of the leaders of the Platform Special Interest Group,
and leader of the Documentation Special Interest Group.
I’ve served as the Jenkins Documentation Officer since 2019.
I was a mentor for Google Season of Code 2020 and am one of the maintainers of the Git plugin for Jenkins.

If elected and allowed to serve as Documentation Officer,
I’ll continue efforts to invite more contributors through regular Documentation Office Hours and outreach programs like Google Season of Docs, CommunityBridge, Outreachy, and Jenkins Hackfests.
I’ll work to assure an inviting and welcoming environment for contributors.

Profile links:
GitHub,
Twitter,
LinkedIn,
Jenkins Blog

Affiliations: CloudBees

More information

Jenkins 2020 elections announcement

Jenkins Governance Board and Jenkins Officers

Jenkins Board and Officer Election Process

2019 election results

Elections coordination in the mailing list<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/11/04/codeql/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 4</div></div><h5 class="title">First results from using GitHub CodeQL to discover security vulnerabilities in Jenkins plugins</h5></div><p class="teaser">A little over a month ago, GitHub announced the general availability of its code scanning solution.
It’s based on CodeQL, which makes it pretty easy to write queries for it and run them using the CodeQL GitHub action, CodeQL command line tools, or on lgtm.com.

Many of the security vulnerabilities discovered in Jenkins plugins are fairly similar to each other, and unfortunately they’re usually specific to Jenkins, which means existing generic tools would not be able to discover them.
So I decided to write CodeQL queries for Jenkins-specific issues and invited maintainers to sign their plugins up for a &quot;private beta&quot; of code scanning for these issues.

Today’s security advisory is the first one that includes findings discovered through that initiative.
All these issues were discovered with assistance by this tooling:

SECURITY-2101 in AWS Global Configuration Plugin,

SECURITY-2102 and SECURITY-2103 in Kubernetes Plugin,

SECURITY-2104 and SECURITY-2115 in Mercurial Plugin,

SECURITY-2110 in Azure Key Vault Plugin, and

SECURITY-2126 in Active Directory Plugin

While there were of course also false positives we had to review and mark as ignored, the integration with the GitHub UI made this pretty straightforward.
Overall I’m very happy with the results so far, especially considering how new this initiative is.

Interested in making the plugin you are maintaining more secure?
Sign up now by filing an INFRA issue in the github component and list the plugin repositories you’d like to have scanned.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/daniel-beck/">Daniel Beck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/11/05/installing-jenkins-on-kubernetes/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day"> 5</div></div><h5 class="title">Document Jenkins on Kubernetes: Installing Jenkins on Kubernetes Documentation Release</h5></div><p class="teaser">We are super excited to announce that the Document Jenkins on Kubernetes Project recently merged its first PR into Jenkins.io.
This PR adds a new Kubernetes section to the existing Installing Jenkins chapter of Jenkins.io.

This new section describes two options to install/run Jenkins on Kubernetes, how to setup a minikube cluster on which to run your Jenkins deployment and finally a bonus segment that explains some Post-installation setups such as unlocking Jenkins, customizing Jenkins with plugins and creating your first administrator user.

The first installation option covered in this section is helm a package manager for Kubernetes whose package format is called a chart. The helm section covers the prerequisites for installing Jenkins on Kubernetes using Helm, installing and configuring helm, creating a persistent volume and service account, and finally, Installing Jenkins.

The second option describes how to install Jenkins using a set of yaml files.
This section explains how to create a Jenkins deployment file, Deploy Jenkins, grant access to jenkins service, and finally access your Jenkins dashboard after installation.

Splitting the Installing Jenkins Chapter

The addition of the Kubernetes section highlighted a long-standing challenge with the Installing Jenkins chapter.
It was too long and contained too many topics, making it difficult and unpleasant for
most users to navigate.
To top the icing on the cake and further improve the experience on Jenkins documentation users, another PR was merged into Jenkins.io to split the Installing Jenkins chapter into smaller chapters for better separation of concerns and easy navigation. This PR also redirects bookmarks that linked to the previous locations like https://www.jenkins.io/doc/book/installing/#debianubuntu using Javascript.

The image above is a snapshot of what the Installing Jenkins chapter looked like before the PR.
All sections of this chapter such as docker, Kubernetes and others were lumped up on the same page making it too long with so much information thereby making it difficult to navigate or even find information on this page.

This snapshot shows what the Installing Jenkins chapter looks like after the PR.
With this chapter split into smaller sections, it’s neater, clearer and most importantly easier to navigate to the section of interest without having to scroll through so much information that’s not necessarily needed.

Testing, Participating and Contributing

The Jenkins Community invites the general public to try out these documentation updates and give feedback to help us further improve the documentation.
If you have any feedback, suggestions, or would like to contribute to the Jenkins on Kubernetes project,  drop a message indicating your interest in the Jenkins documentation Gitter channel.
You can also find the Google season of docs office hour notes and recordings for Jenkins on Kubernetes here.
GSOD office hours take place twice a week on Mondays and Thursdays between 6 pm GMT+1 and 7 pm GMT+1, if you would like to be part of these meetings, you can indicate interest in the Jenkins Documentation Gitter channel and we would be happy to have you.

Additional Resources

Installing Jenkins on Kubernetes PR

Splitting Installing Jenkins Chapter PR

Document Jenkins on Kubernetes Project

GSoD Proposal

GSoD Office Hours Notes

Google Season of Docs - Startup

Google Season of Docs on jenkins.io

Docs SIG for Google Season of Docs startup ( video)<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/zaycodes/">Zainab Abubakar</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/helm">helm</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsod">gsod</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsod2020">gsod2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/11/10/major-changes-in-weekly-releases/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">10</div></div><h5 class="title">Jenkins 2.264+: Major changes in the weekly release line</h5></div><p class="teaser">Recently we have selected Jenkins 2.263 as a new baseline for the LTS release line, with ETA in December 2020.
It allows delivering significant and in some cases breaking changes which have been previously on hold.
Beginning with the Jenkins 2.264 release on October 27, 2020, we’ve entered a period where the Jenkins weekly releases will include more significant changes than usual.
That period of more significant changes is expected to continue for a month or more.
As you may have seen from the release community ratings, there might be regressions and instabilities during this period.

We’re excited for the changes.
They help to improve user experience and to address the technical debt accumulated in the Jenkins core.
We invite Jenkins users to evaluate those changes and provide feedback.
This is an especially valuable time for users and administrators to test the weekly releases and report issues with them,
especially on Jenkins test environments.
In the Jenkins project we have invested a lot in test coverage for the main functionality,
but in many cases we rely on user feedback for exotic plugins and environments not yet covered by our test automation.

The most notable changes include:

Configuration UI - Tables to Divs

Core - Spring Security replaces Acegi Security

Core - XStream unfork

UI - JQuery upgrade

Configuration UI - Tables to Divs

Jenkins 2.264 is the first weekly release to include the &quot;Tables to Divs migration&quot; user interface work of Josh Soref, Tim Jacomb, and Felix Queiruga.
It is a significant step to improve forms in the Jenkins user interface (configuration pages, build parameters, etc.), especially for users on narrow devices like tablets and phones.

A better user interface

The transition from using HTML table tags to using HTML div tags provides a more attractive user interface for all users and a much better experience for users on narrower devices.
Before the conversion from table tags to div tags, the&quot;Manage Jenkins&quot; page looked like this in a 1024x768 window:

After the conversion, the&quot;Manage Jenkins&quot; page now looks like this:

The user interface improvements from the transition are a nice step forward for Jenkins.
However, because the user interface improvements require changes in plugins, we need your help.

We need users to test the latest weekly Jenkins releases with the plugins and configurations that are most important to them.
When users detect an issue, we need them to report the issue with enough detail that a plugin maintainer can fix the issue.
Please add the tables-to-divs-regression label to the issues.
The tables-to-divs-regression label makes it easier to find issues related to the tables to divs transition.

Plugin developers

Several plugins have already been identified that may need changes.
See the Jira epic for plugins that are likely to need changes for the new user interface layout.
The list of open tables-to-divs-regression issues can also be used to see plugins that need changes.

If you can assist with plugin testing and code changes, select one of the plugins from that epic, test it, and propose a pull request to help with this user interface transition.
If you’re not comfortable proposing a pull request, describe the problems you see in a bug report.

A tables to divs migration guide is available.
It describes areas that typically need to be changed as part of the migration from tables to divs.
It also includes detailed examples that allow the plugin to continue supporting older Jenkins versions with table layouts and use div layouts for newer Jenkins versions.

Core - Spring Security replaces Acegi Security

The Jenkins 2.266 release on November 10, 2020 will include the migration to the Spring Security libraries from the Acegi security libraries that Jesse Glick has proposed and developed through jep:227[Jenkins Enhancement Proposal 227].

This upgrade replaces the Acegi Security library with the current release of the Spring Security library.
Details of the change are described in jep:227[] and in the pull request.

We need users to test the latest Jenkins weekly releases with their plugins and watch for issues related to authentication.

Refer to Jesse Glick’s blog post that introduces the details of the change and provides links to the Spring Security compatibility table.
Jesse’s blog post provides specific instructions for those who report bugs related to this change.
Please use those instructions as you submit bug reports related to the Spring Security upgrade.

Core - XStream unfork

Jenkins has been using a fork of the XStream serialization library to read and write XML files.
The XStream library was forked over 10 years ago and had a few fixes applied to it.
Unfortunately, at that time the fixes were rejected by the upstream maintainers of XStream (unsupported patterns of API use) and the fork fell behind the upstream version.

The Jenkins 2.266 release on November 10, 2020 will include the migration to the upstream version of the XStream library that Jesse Glick has proposed and developed through jep:228[Jenkins Enhancement Proposal 228].

Refer to Jesse Glick’s blog post that introduces the details of the change and provides links to the XStream compatibility table.
Jesse’s blog post provides specific instructions for those who report bugs related to this change.
Please use those instructions as you submit bug reports related to the XStream upgrade.

UI - JQuery upgrade

Jenkins uses a 1.x version of the jQuery user interface library for some of its components.
Felix Queiruga has started the work to update that library to a current jQuery version.

It will arrive in a future Jenkins weekly release.
When it arrives, it will be noted in the Jenkins weekly changelog.

When the jQuery update arrives, We will need users to test the Jenkins weekly release with the plugins and configurations that are most important to them.
When users detect an issue, we need them to report the issue with enough detail that a plugin maintainer can fix the issue.

Call to test

This is a great time to help the Jenkins project by testing the weekly releases.
We encourage you to test the user interface and the interactions that are most important to you.
If you find an issue, please report the issue so that others can benefit from your discovery.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/testing">testing</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ui">ui</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/11/10/spring-xstream/"><div class="header"><div class="date"><div class="month">Nov</div><div class="day">10</div></div><h5 class="title">Spring and XStream updates (breaking changes!)</h5></div><p class="teaser">Cleaning up technical debt is a perennial topic among Jenkins core developers,
and one of the most visible issues is the use of obsolete and/or forked third-party libraries.
In a world where Dependabot is offering updates to libraries released just hours before,
it is unpleasant to be working with dependencies that are many years old.
Since large organizations in particular are unhappy to install software using obsolete or nonstandard versions,
my employer (CloudBees) gave its blessing for me to spend some time cleaning up some of the worst offenders.

The toughest nut to crack was the Acegi Security library used for authentication,
which has long since been replaced by Spring Security
(and Jenkins was also bundling a long-outdated version of some Spring Framework dependencies).
jep:227[] tracks the complicated task of updating to Spring Security
without breaking the numerous plugins that interact with authentication,
especially those offering a Security Realm.

Another longstanding problem was the XStream library which Jenkins uses to read and write XML configuration files.
This had been forked long ago by what was then the Hudson project and a few fixes applied.
Unfortunately, some of those fixes were rejected upstream as invalid (representing unsupported usage patterns),
and the fork fell behind the upstream version.
jep:228[] describes the impact of switching to the upstream library in a more standard usage mode,
including fixes to a smaller number of plugins which would otherwise be incompatible.

Now that the Jenkins 2.266 weekly release includes both updates,
it is important for both Jenkins administrators and plugin maintainers to check for actual or potential incompatibilities.
There are two tables listing the impact of these changes on plugins:

Spring Security compatibility

XStream compatibility

If you use Jenkins then it is a good idea before upgrading to take a look at these tables
to see if you are running any plugins considered incompatible.
If so, try not to rely on that plugin, or find out if there is an active maintainer who could help.
For entries marked unknown, it would be appreciated if you could do a sanity check after upgrading
and offer a pull request to the table page (click Edit this file) with a more informative status.

If you find a regression in a plugin, please file a bug report in Jira and link to it from the table.
Also please add a JEP-227 or JEP-228 label as appropriate, for ease of tracking:

Open JEP-227 issues

Open JEP-228 issues

It is a good idea to update all your plugins before upgrading Jenkins core.
In the case of the Spring Security update, some security realm plugins including LDAP and Active Directory must be updated in advance.
(You can safely run the new plugin versions on Jenkins releases prior to this change.)
Otherwise, you risk being unable to log in to Jenkins—and thus unable to update those plugins from the GUI!
The LDAP plugin additionally has a new version available only after the core upgrade, but there is no rush in switching to that.

If you maintain a Jenkins plugin then please check whether it is marked anything less than compatible.
In some cases, there are already pull requests awaiting merge.
In other cases, some minor aspects of the source code have been identified that could be edited to improve compatibility.

We expect to see a bit of disruption from these changes
but hope that in the long run they will save time for core and plugin developers
and lead to a more secure and stable tool.
Please reach out on the developers’ list with any questions or suggestions.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jglick/">Jesse Glick</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/03/election-results/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 3</div></div><h5 class="title">2020 Jenkins Board and Officer Elections Results</h5></div><p class="teaser">The Jenkins community has recently completed the 2020 elections.
On behalf of the Jenkins community and the elections committee,
we congratulate all newly elected board members and officers!
We also thank all candidates and voters who participated this year.

Election results:

Gavin Mogan and Marky Jackson will join
Kohsuke Kawaguchi, Ullrich Hafner and Oleg Nenashev
on the Jenkins Governance Board

Tim Jacomb was elected as Release Officer

Marky Jackson will become the new Events Officer (uncontested)

Olivier Vernin will continue in the role of Infrastructure Officer for another term (uncontested)

Daniel Beck will continue in the role of Security Officer for another term (uncontested)

Mark Waite will continue in the role of Documentation Officer for another term (uncontested)

The board positions and officer roles are an essential part of Jenkins&#x27; community governance and well-being,
and we are excited to see contributors taking these roles.
If you are interested to learn more, please see the blog post below.

Governance Board election details

This year we had nine candidates participating in Jenkins Governance Board elections:
Andrey Falko, Ewelina Wilkosz, Frederic Gurr, Gavin Mogan, Justin Harringa,
Mark Waite, Marky Jackson, Steven Terrana, and Zhao Xiaojie (Rick).
All of them are awesome community leaders who actively contribute to the Jenkins project and
represent its users.
It would be an honor to have them on the Jenkins board.
Regardless of the election results, we appreciate their participation and the time they invested in these elections.

This year we were electing 2 governance board members.
We were using the Condorcet Internet Voting Service that allows voters to rank their choices rather than just picking their one favorite choice.
You can find full voting results here :

Mark Waite  (Condorcet winner: wins contests with all other choices)

Marky Jackson loses to Mark Waite by 48–12

Gavin Mogan loses to Mark Waite by 51–10, loses to Marky Jackson by 31–20

Ewelina Wilkosz  loses to Mark Waite by 48–14, loses to Gavin Mogan by 29–28

Justin Harringa  loses to Mark Waite by 51–11, loses to Ewelina Wilkosz by 35–16

Steven Terrana  loses to Mark Waite by 47–16, loses to Justin Harringa by 20–19

Zhao Xiaojie (Rick)  loses to Mark Waite by 57–5, loses to Steven Terrana by 25–24

Frederic Gurr  loses to Mark Waite by 52–10, loses to Zhao Xiaojie (Rick) by 25–24

Andrey Falko  loses to Mark Waite by 56–6, loses to Frederic Gurr by 26–13

Although Mark Waite came first in the voting results,
being on the board would violate the Corporate Involvement clause which states that
&quot;the number of board members affiliated with one company must be less than 50%&quot;.
Mark will continue to be Documentation officer.
Regardless of his official role, Mark has been leading many initiatives and helping a lot with various aspects of the community governance.

Congratulations to Marky and Gavin, and thanks to all candidates!
All new board members are elected for a 2-year term unless they decide to step down earlier.
The estimated end of the term for them is December 02, 2022.
We would also like to thank Alex Earl and R. Tyler Croy who step down from the Jenkins Governance Board this year.
Thanks to them for all contributions and for continued community leadership.

Statement from Marky Jackson:

It is a tremendous honor to be elected to this roles. I am so humbled.
Being part of this community is a fantastic opportunity that I have had. It has given me so many joys. Whether helping to foster community collaboration, working on the roadmap, leading various SIG’s or helping meetups or conferences, this community has given me so much.
My goals are bridging the Jenkins project with other interoperability projects, defining the roadmap, achieving roadmap goals, continuing to help meetups thrive, and our conferences focus on the community. I want to ensure we are transparent in our goals and how we achieved them. I want to continue to build up a welcoming community that holds diversity and inclusion at the forefront.
I look forward to working with the other members of the Governance Board to continue to deliver on the incredible things this project is known for.

— Marky Jackson, Jenkins Governance Board Member and Events Officer

Statement from Gavin Mogan:

Gavin here. I’m still in shock that I got voted in for the Jenkins board.
It felt like yesterday I just got started helping people randomly on IRC. This is truly exciting.
I plan to continue to help out as much as I can wherever I can, just in a bit more official capacity.
This is truly exciting. I have no firm plans or agenda, just keep pushing advocacy and getting people to help each other in a positive and safe way.
My specialities lie in outside of Jenkins core, whether it be working on the plugin site, or hanging out on IRC, Gitter and Reddit helping out where I can.

— Gavin Mogan, Jenkins Governance Board Member

Officer election details

All 5 officer positions were up for election this year.
These roles have a 1-year term, with the estimated end of term on Dec 02, 2021.
After the initial review of nominations and confirmations with potential candidates,
4 officer positions were uncontested:

Olivier Vernin - Infrastructure officer.

Marky Jackson - Events officer.
Marky inherits this role from Alyssa Tong
who decided to step down from the officer role and to focus on the Jenkins community marketing,
including Jenkins Is The Way and many other initiatives started by Alyssa.

Mark Waite - Documentation officer.

Daniel Beck - Security officer.

Thanks to all Jenkins officers for their continued leadership!
Officers take responsibility for many day-to-day processes in the Jenkins community and lead the contributor teams working on them.
It requires significant time commitment, and it is not taken for granted.

Release Officer election results

Tim Jacomb won the biggest support as a Release officer ( voting results).
Tim will replace in this role Oliver Gondža
who has been leading the Release Team and the release processes since 2016 when the role was officially introduced.

Tim Jacomb (Condorcet winner: wins contests with all other choices)

Baptiste Mathus  loses to Tim Jacomb by 40–23

Victor Martinez  loses to Tim Jacomb by 38–25, loses to Baptiste Mathus by 32–31

Here is a statement from Tim Jacomb:

I’m excited for the year ahead, let’s see where we can take the Jenkins release area in the future.
As a Release Officer I would like to increase automation, ease onboarding of new contributors to the release team,
and ensure that responsibilities rotate among people so that I wouldn’t be a bottleneck for any task.

— Tim Jacomb, Jenkins Release Officer

Thanks to Alyssa Tong and Oliver Gondža for their long-time service as Jenkins officers!
We are looking to continue working with them in the Jenkins community.
And congratulations to Tim Jacomb and Marky Jackson for joining the team!

Statistics

This year we had 92 registered voters and around 65 actual votes.
It is significantly lower than in the 2019 elections when we had almost 350 voters.
It can be partially explained by the change of the communication process.
This year we decided to not use the previous voter registration system,
and we relied on the user and developer mailing lists instead of sending messages to the entire LDAP user database.
This is definitely something we need to review at the retrospective.

What’s next for the board?

The last year was awesome for the Jenkins project governance.
With help of many contributors and with the renewed board,
we have been able to facilitate many initiatives in the Jenkins project,
for example hosting contributor summits,
publishing the public roadmap,
Code of Conduct update,
terminology changes,
and graduation in the Continuous Delivery Foundation.
There is a lot more work to do to grow the community and to ensure the long term sustainability of the project.

In short term, our key priority is to organize knowledge and permission transfers to the new board members and officers so that they can be effective in their new roles.
The board will also focus on maintaining the Jenkins governance processes
(meetings, budget approvals, funding, etc.) and defining the next steps and priorities.

There are many longer-term initiatives the board could facilitate:
long-anticipated features and architecture changes,
changing the Jenkins Enhancement Proposal process,
creating better communication channels with Jenkins users,
and onboarding of new contributors and maintainers.
Such initiatives are instrumental for the evolution of the Jenkins project.
The ideas will be discussed in mailing lists and during governance meetings.
If you would like to share your vision and ideas about what’s needed in the project,
it is definitely a great time to contribute!

Feedback

Jenkins project plans to conduct elections every year.
We will appreciate and welcome any feedback regarding the election process so that we can improve the process.
We have started a Retrospective document for these elections.
Everyone can suggest changes in this document, and we will integrate them.
There will be also a public retrospective review at the next Advocacy and Outreach SIG meeting on Dec 17.

If you have any private feedback you would like to share,
please send an email to the Jenkins Board.
If you would like to raise any issues about the election process,
please contact one of the elected Governance Board members.

References

Jenkins Governance Board

Jenkins Board Election Process

Jenkins Officers

2020 election announcement

2020 election candidates

Retrospective document<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a>, <a href="/gatsby-jenkins-io/blog/authors/slide_o_mix/">Alex Earl</a>, <a href="/gatsby-jenkins-io/blog/authors/uhafner/">Ullrich Hafner</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/04/gsod-project-report/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 4</div></div><h5 class="title">GSOD Project Report: Document Jenkins on Kubernetes</h5></div><p class="teaser">Jenkins is the world’s leading open-source automation server used by companies large and small around the globe to implement continuous integration and continuous delivery.
Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation.
Kubernetes is compatible with the majority of CI/CD tools which allow developers to run tests, deploy builds in Kubernetes and update applications with no downtime.
One of the most popular CI/CD tools now is Jenkins thereby making Jenkins on Kubernetes a popular theme for Jenkins users.

During the Google Season Of Docs program, I worked with the Jenkins organization on the project - Document Jenkins on Kubernetes.
The original proposal for this project can be found here.

Project Goals

After my proposal was accepted by the Jenkins organization, my mentors and I agreed on the expectations for the Google Season of Docs project.
The goal of this project was to create a new Kubernetes Volume which would describe the concepts, techniques, and choices for Kubernetes users running Jenkins thereby providing the following advantages:

Improve the user experience of Jenkins on Kubernetes users by giving them a one-stop-shop for information on Jenkins on Kubernetes.

Make it easy to track, update and maintain information on Jenkins on Kubernetes

Reference the existing community documentation for Jenkins on K8s (plugins and tools/integrations).

How to guides, tutorials and explanations of concepts and techniques in Jenkins on Kubernetes.

Just-In-Time documentation which means that rather than documenting every feature comprehensively, we produce and release documentation in bits but continuously based on popular questions, feedback and area of interests gathered from the community and users.

Community Bonding: Planning the solution

Find below an outline of my activities during the community bonding phase:

Setting up communication channels: meetings, mailings, chats: My mentors and I agreed on the right time and channel for communication due to time difference.
We agreed to meet twice weekly, on Mondays and Thursdays at 7:00 PM GMT +1 and use Jenkins documentation gitter channel for other communications.

Contacting Stakeholders and onboarding contributors: The project was  announced on social media and different Jenkins channels.
I wrote a blog post to announce the project and created a project page on Jenkins.io.

Knowledge transfer: I and my mentors planned knowledge sharing sessions and fixed tentative dates based on the availability of the trainers.
My mentors also shared useful resources to help me prepare for the project.

Getting permissions: I and my mentors agreed I didn’t need any special permissions from the beginning, however, this topic was left open for discussion if the need arose later on in the project.

Pre-planning of the project: I refined my goals and set expectations with my mentor and also learned more about the community(Jenkins).
I also had to ensure that the proposed documentation structure I drafted was in line with the goals of the organization so my mentors vetted it and we finalized on the proposed sections that I was supposed to work on.

Documentation Development Phase

Knowledge Sharing Sessions

During the development phase, my mentors hosted two knowledge sharing sessions:

Katacoda and Helm by Marky Jackson

See the slides

Helm by Torsten Walter

See the slides

These sessions gave me an in-depth understanding of concepts and tools needed for the project.

Jenkins on Kubernetes Documentation Skeleton

At the application phase, I drafted a structure describing the proposed Jenkins on Kubernetes section.
My intention was to use it as a guide during the implementation phase of the project, but when the development phase kicked off, my mentors and I thought of a better approach to creating a new Jenkins on Kubernetes section which was to add the Jenkins on Kubernetes contents to existing related sections for easier navigation and better user experience.
An example of this approach would be creating the Installing Jenkins on Kubernetes section under the Installing Jenkins section rather than putting it under an entirely new section.
With this new approach, I was assigned a task to create a skeleton with all the proposed Jenkins on Kubernetes sections on Jenkins.io and mark these sections as
Work In Progress (WIP).
The Plan was to use this skeleton as a guide throughout the GSOD Project.
The Jenkins on Kubernetes skeleton PR can be found here.

Documenting Jenkins on Kubernetes

While working on this project, I had to do a lot of research and test all the documented steps locally before pushing the documentation out for review.
I also made sure to use updated terms and terminologies where necessary like Controller instead of Master and Agents instead of Slave.

During the documentation phase, I was able to work on documenting Installing Jenkins on Kubernetes with three sections Helm, Set of Yaml files and Jenkins Operator.
I also worked on creating a directory for Jenkins on kubernetes sample files in Jenkins.io repository, documenting Scaling Jenkins on Kubernetes and Jenkins on AWS which is still in progress.

Work Done

Pull Requests : All the pull requests I submitted to Jenkins.io documentation can be found here.
This spreadsheet contains links to the published documentation on Jenkins.io.
The spreadsheet also highlights the initial proposed tasks and the status of each of them.

If you would like to contribute to the Jenkins on Kubernetes documentation, you can check out pending tasks here and reach out in the Jenkins documentation gitter channel.

Challenges

Using a Windows computer was a bit of a challenge for me.
To run Jenkins.io locally, the project uses GNU/Make and Docker in order to generate the fully statically generated jenkins.io web site.
The key tool for converting source code into the site is the Awestruct static site generator, which is downloaded automatically as part of the build process.
To achieve this, I needed to have GNU/Make and Docker available on my machine.
Docker was not a problem, but to achieve the latter, I needed to use Windows Subsystem for Linux (WSL).
WSL had two versions WSL1 and WSL2. Using WSL2 would have been much more convenient, but my version of windows wasn’t compatible with WSL2 as it required Version 1903 or higher, with Build 18362 or higher for x64 systems.
With this obstacle, I had to stick to making WSL1 work but I still couldn’t get this to work, a series of issues came up which I was able to pass through with the help of my mentors until I got stuck at permission issues.
I raised the issue with my mentor and after looking through the issue with me and trying to solve it to no avail, he suggested setting up an Ubuntu VM in Hyper-V.
This article helped me achieve this and that solved my problem.

What did I learn?

I learned a lot more about the Jenkins project, Kubernetes, helm package manager, Jenkins Operator and much more.
This project also gave me the opportunity to work with cloud providers like AWS which was totally new to me and also learn from field experts through knowledge sharing sessions and weekly meetings with my mentors and org admin.
My technical writing skill and communication skill have definitely become better and I owe it to this project.

Overall, contributing to the Jenkins.io project is an amazing experience for me.
I have been using Jenkins, and the fact that I was able to contribute to the organization and collaborate with the community is an honor.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/zaycodes/">Zainab Abubakar</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/helm">helm</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsod">gsod</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsod2020">gsod2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/05/3-Cases-Jenkins-Success-stories-from-the-community/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day"> 5</div></div><h5 class="title">3 Cases: Jenkins success stories from the community</h5></div><p class="teaser">Back in April, when we started canvassing the Jenkins community for user stories concerning how Jenkins helped enterprise companies, startups, and students, we thought we’d see some exciting tales of DevOps inspiration and CI/CD integration. We found that some submitted stories were far too big to be constrained by our format of &#x27;background/goal/solution/results.&#x27;

Some Jenkins users had a much more complex story to tell, whether it was about getting upper management to buy-in, keeping developers happy, or simply making sure pipelines weren’t just bottlenecks in disguise.

Here are a handful of Jenkins Case Studies we’ve published in the past few months, with many more on the way!

Case Study #1: D4Science

Amping up scientific research with CI/CD powered by Jenkins

To promote open science practices and support scientific communities while serving 11k registered users in 45 countries, D4Science introduced a new delivery pipeline that replaced their pre-existing build platform.

Of course, they had to build and release their software framework (gCube) in a way that would support multi-project releases at scale — from 200+ Git repositories within the same day! It had to be fast, automate all release activities, and it had to deliver incremental releases to address user requirements quickly. Most of all, the solution had to be cost-effective.

Using Jenkins, they created an innovative approach to software delivery: a continuous integration/continuous delivery (CI/CD) pipeline, scalable, easy to maintain, and upgradable at a minimal cost.

Discover how D4Science empowers e-Science and virtual research communities with software released via Jenkins. Read the Jenkins case study featuring D4Science here!

Case Study #2: Gainsight

Humanizing CSX with tech innovation and a robust DevSecOps platform

Gainsight’s customer service experience platform helps customer success teams at more than 100 leading IT and healthcare clients. How? By driving engagement for tens of thousands of their customers.

That’s why the engineering team at Gainsight approached the customer experience by building a smarter, faster DevSecOps platform using Jenkins. They stuck to an infrastructure-as-code approach while integrating various tools and programming languages all within the platform. And they secured processes with better visibility and air-tight quality control.

The result was a flexible DevSecOps infrastructure, 95% of which is scalable with code. And the cost of infrastructure costs was 40% less. That provides Gainsight with ease of collaboration, keener operational insight, and — because builds are 30% faster — the ability to stay a step ahead of the competition.

Read why Gainsight’s lead DevOps engineer, Prudviraj Pentakota, says &quot;Jenkins is the epicenter of DevSecOps in our organization.&quot; Get the full story here.

Case Study #3: Avoris Travel

Reinventing travel with an inventive technology platform

Part of Barceló Group, Ávoris Travel is behind prominent destination travel brands like LeSki, Le Musik, and a selection of author travels under its &quot;Viagens Com Assinatura&quot; signature travel concept. A proprietary database and a smart, dynamic booking engine are the tickets to offering differentiating and inventive travel opportunities.

Also unique to Avoris is a discreet machining technology that enables agents to enter specific criteria to search and find all types of trips and travel opportunities across the entire network.

&quot;Our infrastructure is very important because we have to be online to meet customer demand anywhere in the world,&quot; said Alejandro Alvarez Vazquez, Sysadmin, Avoris Travel. &quot;Our CI/CD platform is used by 200 people. The services that we build and deploy are used by thousands of potential clients and by our network of 675 own agencies located in Spain and Portugal.&quot;

Read the case study to learn how the flexibility of Jenkins plugins helped Avoris reduce build times by over 50% and became a go-to, scalable infrastructure supporting 675 agencies and over 2.8 million international consumers.

What’s your story?

We want to know what you’re building with Jenkins and would love to post your case study on our&quot;Jenkins Is The Way&quot; website, a global showcase of how developers and engineers build, deploy, and automate great stuff with Jenkins.

The best way to get started is to share your Jenkins User story with us. We’ll send you a free Jenkins Is The Way T-Shirt in return and publish your account for the entire Jenkins community to see. And if it’s selected for a Case Study, we’ll be in touch for a one-on-one interview! Hope to hear from you soon!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/Jenkinsistheway">Jenkinsistheway</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/Jenkinsuserstories">Jenkinsuserstories</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/11/devops-world-2020-jenkins-contributors-awarded-top-honors-at-devops-worlds-2020/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">11</div></div><h5 class="title">“Jenkins Contributors Awarded Top Honors at DevOps World 2020”</h5></div><p class="teaser">At DevOps World on September 24, 2020, through the sponsorship of CloudBees, three Jenkins contributors were recognized for their contributions to the Jenkins project.  The Jenkins Contributor Awards honor those who have made significant contributions to the Jenkins project.  The 2020 Jenkins Contributor Award winners are:

Most Valuable Jenkins Contributor

This award is presented to an individual who has contributed to the Jenkins project the most through new features, bug fixes or plugin development efforts.

Tim Jacomb - Tim is everywhere in the Jenkins community: plugins, Jenkins core maintenance, Google Summer of Code, infrastructure, and new initiatives like GitHub App authentication and Dark Theme. His software, frontend and infrastructure skills help to push the Jenkins project forward. Several examples of features shipped by Tim in 2020: Read-only Jenkins configuration, GitHub App Authentication support, Jenkins Dark Theme and many other smaller features here and there. Tim is also the second most active code reviewer in the Jenkins core.

Jenkins Security MVP

This award is presented to the individual who most consistently provides excellent Jenkins security reports or resolves Jenkins security issues.

James Holderness - Security issues reported by James have been included in nine of the nineteen security advisories published by the Jenkins project in the last 12 months. His issue reports have detected many cases where sensitive information was being stored insecurely by plugin maintainers. Jenkins users and the Jenkins security team are sincerely grateful for the issue reports that James has provided.

Most Valuable Jenkins Advocate

This award is presented to an individual who has helped advocate for Jenkins through organization of a local Jenkins Area Meetup(s), or virtual equivalent.

Marky Jackson -  Marky has been very active in many Jenkins advocacy &amp; Outreach initiatives. He was a leader of the Advocacy &amp; Outreach SIG, and he participated in many promotional initiatives organized by the SIG. Marky was also a copy-editor of the Jenkins Twitter account where he contributed a lot to it. In addition to that, Marky has presented talks as well as provided technical support on Jenkins at multiple events including Jenkins Online Meetups, in person as well as virtual conferences.

Congratulations to James, Marky and Tim! We are grateful for their contributions to the betterment of the Jenkins project.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/event">event</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/devopsworld2020">devopsworld2020</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/16/call-for-mentors/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">16</div></div><h5 class="title">Google Summer of Code 2021 call for Project Ideas and Mentors</h5></div><p class="teaser">Google Summer of Code (GSoC)
is a program where students are paid a stipend by Google to work on a free open source project.
Students work on the project for three months (June to August).
Prior to the coding phase, there is a month of community bonding, to welcome students to the Jenkins community and acquaint them with the projects processes for communication and collaboration.
Mentors are actively involved with students from March when students start to work on and submit their applications.
(see the timeline)

We are looking for project ideas and mentors to participate in GSoC 2021.
GSoC project ideas are coding projects that university or college students can accomplish in about three months.
The coding projects can be new features, plugins, test frameworks, infrastructure, etc.
Anyone can submit a project idea, but of course we like it even better if you offer to mentor your project idea.

We accept new project ideas at any time,
However, project ideas need to be finalised before February 19th, 2021 at 7pm UTC,
which is the deadline for the Jenkins organization to apply to the GSoC program.
Please send us your project ideas before the beginning of February so they can get a proper review by the GSoC committee and by the community.

How to submit a project idea

Create a pull-request with your idea in a.adoc file
in the project ideas.
It is not necessary to submit a Google Doc, but it will still work if you want to do that.
See the instructions on submitting ideas which include an.adoc template and some examples.

Current list of ideas

We currently have a list of project ideas for students to browse.
Note that this list is subject to change.

What does mentoring involve?

Potential mentors are invited to read the information for mentors.
Note that being a GSoC mentor does not require expert knowledge of Jenkins.
Mentors do not work alone. We make sure that every project has at least two mentors.
GSoC org admins will help to find technical advisers, so you can study together with your students.

Mentoring takes about 5 to 8 hours of work per week (more at the start, less at the end).
Mentors provide guidance, coaching, and sometimes a bit of cheerleading.
They review student proposals, pull-requests and the students presentations
at the evaluation phase.
They fill in the Google provided evaluation report form at the end of coding periods.

What do you get in exchange?

In return of mentoring, a student works on your project full time for three months.
Think about the projects that you’ve always wanted to do but never had the time…​

Mentoring is also an opportunity to improve your management and people skills, while giving back to the community.

There will be a Google Mentor Summit which takes place every year.
In 2020, the Mentor Summit was virtual, but in previous years the summit has taken place in person.

See this post
about the 2019 in person Mentor Summit.

GSoC is a fantastic program and the Jenkins project is happy to participate in GSoC again in 2021!

For any question, you can find the GSoC Org Admins,
mentors and participants on the GSoC SIG Gitter chat.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/marckk/">Kara de la Marck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/17/jira-upgrade-for-the-jenkins-project/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">17</div></div><h5 class="title">Jira upgrade for the Jenkins project</h5></div><p class="teaser">The Jenkins project has used Jira to track issues for many years.
Jenkins core, Jenkins modules, Jenkins infrastructure, and many Jenkins plugins manage their issue reports with our Jira server.

Jira helps the Jenkins project manage issues and tasks related to over 250 000 Jenkins installations.
It tracks bugs, enhancement requests, tasks, and security issues.
It is used regularly by users around the world.

We’re grateful for the long-standing contribution that Atlassian provides by donating the Jira license to the Jenkins project.
We’re grateful to the Oregon State University Open Source Lab for their donation of equipment and bandwidth to host the server.

Upgrade Timeline

We were running Jira 7.13 and had been managing that installation for a few years.
Atlassian announced that Jira 7.13 would end its support life on November 28, 2020.
We needed to upgrade from Jira 7.13 to a more recent version of Jira.
As part of our membership in the Continuous Delivery Foundation, a Linux Foundation initiative, we could use their project services team to manage our Jira server.
We decided to move from hosting our own Jira server to having the Jira experts at the Linux Foundation host it.

The upgrade timeline looked like this:

November 2019 - Infrastructure team begins discussions about the November 2020 end of support for Jira 7.13

August 2020 - First conversations with Linux Foundation to host Jira for the Jenkins project.  Draft of the upgrade plan assembled and shared with the community

September 2020 - Schedule for testing week and final transition week proposed.  Authentication options evaluated and selected

October 2020 - Test upgrade performed and tested

November 2020 - Final upgrade completed and verified

Confronting the Complications

Initial discussions between the Jenkins infrastructure team and the Linux Foundation identified complications related to authentication and SSL certificates.
We planned, negotiated, and tested our assumptions throughout the project.

Authentication

Jira servers at the Linux Foundation typically use Linux Foundation accounts for user access.
Unfortunately, the Jenkins LDAP database includes over 100,000 users and for many of them, Linux Foundation username doesn’t correspond to Jenkins account username.
It was not feasible to transition 100,000 user accounts from the Jenkins LDAP database to the Linux Foundation accounts system and still complete the Jira upgrade before the November 28, 2020 deadline.

The Linux Foundation Project Services team evaluated authentication alternatives and confirmed that they could use the Jenkins LDAP server.
Using the Jenkins LDAP server spared us from two transitions, LDAP and Jira, and kept the project timeline feasible.

SSL Certificates

Jira servers at the Linux Foundation use Let’s Encrypt to generate SSL certificates for HTTPS.
The Linux Foundation uses the DNS method to obtain SSL certificates.
Unfortunately, the Jenkins project uses the HTTP method to obtain SSL certificates.

Thankfully, Olivier Vernin of the Jenkins project and Anton Baranov of the Linux Foundation found a solution.
They created an ACME record in the Jenkins DNS server and pointed the issues.jenkins.io DNS record at the new Linux Foundation Jira server.

Building the Prototype

Anton Baranov created a prototype Jira server, restored an older Jenkins Jira backup, and upgraded it to Jira 8.13.
That first restore detected that we had not provided the Jira attachments or the Jira avatars.
That attachments and avatars added multiple gigabytes to the initial backup data and were vital to complete the update.

Testing the Upgrade

A group of volunteers including Jenkins users, security team members, and infrastructure team members tested the upgrade during the week of October 26, 2020.
The tests confirmed that authentication worked as expected and that the Jira prototype was functioning as expected.

We thank the test team, including:

Daniel Beck

Tim Jacomb

Olivier Vernin

Mark Waite

The tests included:

Creating and routing issues

Commenting on issues

Viewing dashboards with the expected content

LDAP settings

Email notification

The tests detected minor issues that Anton was able to correct in preparation for the final upgrade.
The testing team agreed that the tests were successful.

Deploying the Upgrade

Olivier Vernin announced the final upgrade by email to the Jenkins infra list with details of the changes happening during the upgrade.
Monday, November 9, 2020, the final backup of the existing Jira server was copied into the new Linux Foundation server.

The final upgrade encountered issues that we had not seen during the initial tests.
The &quot;bumps and bruises&quot; from the unexpected issues were resolved by Anton Baranov as he used a multi-step upgrade process.
The steps included:

Restore the earlier backup to Jira 7.13

Restore the most recent backup

Upgrade to Jira 8.13

Install avatars, attachments, and other images

Update DNS entries to point to the new Jenkins Jira server

Lessons from the Upgrade

Lessons were related to timing, estimation, and communication.

Scheduling the Upgrade

The test upgrade started the week of October 19, 2020.
It took several days longer than originally expected.
Thankfully, we had allowed an extra week between the test upgrade and the production upgrade.

The originally announced schedule for the final upgrade was intentionally placed in a week that would not include a long term support release.
That reduced the risk of disruption if the upgrade took longer than required or failed and we had to roll back.

Estimating the Work

Discussions with the Jenkins project Jira administrators and the Linux Foundation Jira experts provided very reasonable estimates of time to complete the work.
We intentionally allowed additional time between first test and final upgrade.
We needed that additional time and used it well as the testing week.

Communicating the Plan

The distributed nature of the Jenkins project makes communication challenging for major changes.
We communicated plans at various stages but still found occasions where the communication was insufficient.
In this case, the adage held true that it is, &quot;impossible to communicate too much&quot;.

Thanks for your patience during the upgrade and thanks to the Linux Foundation for administering the Jenkins Jira server.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jira">jira</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2020/12/22/gsoc-report/"><div class="header"><div class="date"><div class="month">Dec</div><div class="day">22</div></div><h5 class="title">Google Summer of Code 2020 summary</h5></div><p class="teaser">With the mentor summit and the project retrospectives finished in October,
now we can call Google Summer of Code 2020 officially over in the Jenkins community.
On behalf of the Jenkins org team, we would like to thank all participants: students, mentors, applicants, and dozens of other contributors who participated in the project this year.
Google Summer of Code would not be successful without the active participation of the Jenkins community.

If you follow the Jenkins blog, you may have already seen many GSoC 2020 articles created by the project teams.
Here I would like to focus on the key highlights from the project.

Projects

In 2020 we had seven students working in the Jenkins mentoring organization.
We had 6 projects focused on Jenkins and one project focused on Jenkins X.
As usual, in GSoC we focused on problems important to the Jenkins users and community members.
The projects delivered highly anticipated new features and key architecture changes
needed for long-term evolution of Jenkins.

Here are the projects we had this year:

Custom Jenkins distribution build service by Sladyn Nunes

External Fingerprint Storage by Sumit Sarin

Git Plugin Performance Improvements by Rishabh Budhouliya

GitHub Checks API for Jenkins Plugins by Kezhi Xiong

Jenkins X: Apps/Addons consolidation by Zixuan Liu

Machine Learning Plugins for Data Science by Loghi Perinpanayagam

Jenkins Windows Services: YAML Configuration Support by Buddhika Chathuranga

Please refer to the project pages for more information, links to the blog posts, and project demos.
Let’s focus on the results instead.
This is the first ever time in Jenkins when all GSoC students have reached the final evaluation and successfully passed it.
It was an incredible effort by all the project members and, most importantly, by the students. Thanks a lot to them!

.

Thanks a lot to all mentors who were guiding students during their projects:
Zhao Xiaojie,
Kristin Whetstone,
Parichay Barpanda,
Martin d’Anjou,
Oleg Nenashev,
Andrey Falko,
Mike Cirioli,
Mark Waite,
Francisco Fernandez,
Justin Harringa,
Omkar Deshpande,
Ulli Hafner,
Tim Jacomb,
Kara de la Marck,
James Strachan,
Neha Gupta,
Oscar Medina,
Nikhil Da Rocha,
Sahil Kalra,
Bruno P. Kinoshita,
Ioannis Moutsatsos,
Marky Jackson,
Shivay Lamba, and
Next Turn.

GSoC 2020 Org admin team:
Kara de la Marck,
Martin d’Anjou,
Marky Jackson,
Oleg Nenashev.

Events

Thanks to the GSoC organization stipend from Google and other donations,
the Jenkins project usually provides travel grants to successful students so that they can visit a major community event, meet their mentors and community members in person, and present their work there.
Here are some notes about the GSoC 2019 travel.
Unfortunately this year it was not possible, and GSoC went completely virtual this year.

Online meetups

In August we organized Jenkins Online Meetups where students have presented their projects
( part 1, part 2).
You can find recordings of these presentations in this playlist on the Jenkins YouTube channel.

DevOps World

This year CloudBees, one of the Jenkins corporate sponsors, invited all students to participate in the DevOps World virtual conference on September 23-25.
GSoC students did lighting talks about their projects, attended other conference talks, and joined the Continuous Delivery Foundation booth which represented the project at the conference.
You can find recordings of the talks and all materials here.
Although the conference was in September, the talks were pre-recorded in early August.
Please refer to the Jenkins online meetup recordings for the recent versions.

GSoC Mentor summit

This is a regular gathering for Google Summer of Code mentors and org admins where they share their experiences about GSoC, outreach programs, community management, and tools.
Usually it is organized as a multi-day unconference after the end of GSoC, with 2-3 representatives from each project.
It has been a great learning experience to participate in it.
This year it was a single-day virtual event, and all mentors were able to attend.
Shivay Lamba, one of the GSoC 2020 mentors, also did a lightning talk about the GSoC projects he was working on in Jenkins and CNCF ( slides).

Swag

All Google Summer of Code students and mentors get swag from Google.
This year, Contrinuos Delivery Foundation (CDF) has sponsored swag for 50 most active GSoC participants:
all students, mentors, and many other contributors who participated and helped the projects to succeed.
This is the third year when the Jenkins organization sends extra GSoC swag,
In the previous years the swag logistics was one of the most challenging tasks for org admins during the entire project.
and we highly appreciate help from CDF with this part.
As DevOps World presenters, the students have also received special edition speaker swag from CloudBees.

Thanks a lot to Google, Contrinuos Delivery Foundation (CDF) and CloudBees!

Retrospective

After completion of the coding phases,
org admins have reached out to all GSoC 2020 participants to gather their feedback and suggestions.
We also recommended that project teams hold their own retrospective meetings.
Such information is instrumental to continuously improving GSoC in the Jenkins community.
We thank all contributors who shared their feedback!

The organization-wide retrospective was organized as a survey and a series of retrospective meetings.
You can find aggregated results in this Google Doc.
Overall, we received very positive feedback from students and mentors.
The GSoC framework in Jenkins has matured significantly during the previous years.
The effort we invested to create guidelines and recommendations for all parties helped a lot because all the expectations were known in advance.
As usual, there is much to improve, especially with regards to the community bonding phases and cross-project communications.
We are processing the feedback, and we will expand our documentation and the contributor onboarding plans next year.

Some personal notes

I have been involved in leading and coordinating Google Summer of Code in open source projects since 2016.
This year I visited the GSoC stand at FOSDEM and met a few organizers and former students.
A few days after, I proposed participating in GSoC at the Jenkins contributor summit in Brussels,
and several contributors supported this idea.
We spent several hours to create the first Jenkins GSoC page and brainstorm on project ideas.
We submitted our application and were accepted.
Thanks a lot to the Google team that gave us a chance!

It is great to work with the students and see how they explore the open source community and grow professionally as engineers.
It is also awesome to see how some of them stay in the project and keep contributing,
including becoming plugin maintainers and GSoC mentors.
But, for me, Google Summer of Code is not just about mentoring.
It also helps a lot with the community bonding…​ for the existing community like Jenkins which has a lot of isolated sub-communities in plugins.
Many maintainers work alone, and it can be quite lonely working to maintain a plugin without feedback, developer ideas, and user interactions.
When plugin contributors become project mentors, they join the wider community effort and work in teams.
In many cases they start contributing to the organization-wide activities and goals,
and it grows the &quot;backbone&quot; of the Jenkins community.
Like other community-driven projects, we need such backbone to scale the community and onboard more contributors to the countless Jenkins components.
So far it works really well and GSoC excels among outreach programs in this regard.

I would like to thank the Google Open Source team, students and all Jenkins community members for the great Google Summer of Code this year.
We also thank the Continuous Delivery Foundation for their help to recognize contributors and allow organization administrators to focus on projects.
Last but not least, I would like to thank the Jenkins org admin team:
Martin d’Anjou,
Marky Jackson, and
Kara de la Marck.
This was a crazy year for everyone. Regardless of that, the org admins stepped up and took responsibility for students and mentors involved in the project, with a serious time commitment.
Not all work by the organizers is publicly visible (applications, project selection, resolving conflicts),
but this work is essential to the project’s success.
Thanks a lot to org admins and mentors who helped with the administrative tasks this year!

What’s about GSoC 2021?

Yes, we plan to participate in Google Summer of Code 2021.
The application period for organizations will start in a few months,
but we have already started preparing for the next GSoC session.
We are looking for mentors, org admins and project ideas.
Please contact us if you are interested!

Call for Mentors and Project Ideas

GSoC 2021 project ideas

HOWTO: Propose a project idea

Information for mentors : guidelines and expectations

We invite potential students to start exploring the project and the available project ideas.
Original ideas are always welcome in the project, and starting early is a great opportunity to
get introduced to the Jenkins community, collect more information about the problem areas,
and to create a good proposal.
&quot;Start early&quot; is the most popular recommendation from GSoC 2020 participants to future GSoC students,
and we encourage you to follow this advice!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2020">gsoc2020</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mentor">mentor</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/01/12/new-year-report/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">12</div></div><h5 class="title">2020 A Year Like No Other</h5></div><p class="teaser">The Jenkins community congratulates all users and contributors with the New Year!
Let’s take a look at some changes this year.
We would like to thank all awesome Jenkins users and contributors who have been with us during this year.

Highlights

Some of the key highlights:

Hundreds of first-timer contributors joined the community

Major UI/UX improvements in the Jenkins core, including the landing page, plugin manager, dark theme, and read-only configurations support

Outreach programs like Google Summer of Code (7 projects), Google Season of Docs, UI/UX hackfest, etc.

Public roadmap for the project

Terminology changes in the project, new Code of Conduct

Technical debt cleanup: XStream unforking, Acegi Security replacement, etc.

Continued evolution of the plugin ecosystem, especially in the area of Cloud Native solutions and tool integrations

Continued documentation cleanup, great progress with plugin documentation migration

Graduation in the Continuous Delivery Foundation

Jenkins User Interface and User Experience

This year there were many activities around Jenkins user experience and long-anticipated user interface changes.
This is a coordinated effort being led by the User Experience SIG, and by many contributors to the project.
Key project highlights:

Look &amp; Feel updates of the Jenkins Web UI, including styling rework, new typography and layouts

Major rework of plugin management UI/UX

Dark theme for Jenkins

Accessibility improvements

Support for read-only configuration pages

In May we also organized a Jenkins UI/UX hackfest where we worked on some key stories improving user experience.

Jenkins security

In 2020 the Jenkins security team has released 19 advisories for the Jenkins core, plugins and other components.
In total 198 vulnerabilities were fixed, and 72 plugin vulnerabilities were announced without a fix at the time of advisory publishing.
As a project, we are receiving a continuous flow of new reports and continue to provide corrections.
Cross-site scripting (XSS) vulnerabilities were the most popular type this year, followed by unprotected credentials.

There have also been developer tooling improvements,
including GitHub CodeQL evaluation for targeted security issues search
and Find-Sec-Bugs adoption for static analysis of the plugin and Jenkins core code.
Along with wider adoption of Dependabot and automated dependency scanning on GitHub.

Documentation

Jenkins Documentation SIG is working on creating more documentation for Jenkins on different platforms,
including cloud platforms.
Jenkins on Kubernetes was one of the key stories this year for the SIG,
along with documentation migration to jenkins.io and wider adoption of Documentation-as-code in plugins.
95% of the 200 most installed Jenkins plugins have moved to &quot;documentation as code&quot; or have a pending pull request with updates.
In total, almost 600 plugins have already been migrated.
There were major updates in Jenkins documentation on jenkins.io, with a lot of content being moved from the old Jenkins Wiki.

2020 was the first year when Jenkins participated in Google Season of Docs (GSoD).
This program brings together open-source and technical writers communities for the benefit of both.
This year’s student, Zainab Abubakar,
did an amazing job documenting Jenkins on Kubernetes.
Now Jenkins users can find official documentation about deploying and scaling Jenkins in Kubernetes.
See the project report by Zainab here.

Jenkins Release Automation

The Jenkins project has delivered weekly and long term support releases since it was formed in 2011.
Those releases were delivered by Kohsuke Kawaguchi from his release infrastructure.

Beginning in April 2020, those releases are delivered by the new release automation setup.
It is hosted within the Jenkins’ Kubernetes cluster, with fully automated management and continuous delivery of services within the setup.
We transitioned to new build processes, new code signing certificates, and new release automation jobs.
Thanks to Olivier Vernin and all Infrastructure sub-project contributors for the successful completion of the release automation project!

Moreover, there is ongoing work on continuous delivery of Jenkins plugins ( JEP-229) and on re-designing other Jenkins instances within the project (infra-ci, trusted-ci, and ci.jenkins.io for plugins).
In the next few months these stories should provide Jenkins contributors with a modern environment for CI and CD of all Jenkins components.

Terminology updates

Since July, we have officially replaced the old &quot;master&quot; terminology with the &quot;controller&quot; term.
It is a follow-up to the &quot;agent&quot; terminology introduced in 2016.
We have also deprecated usages of the “blacklist/whitelist” terminology in all components.
Currently the community is working on the cleanup of the remaining occurrences in the codebase and documentation, and we invite everyone to contribute.

As a part of the terminology cleanup, last spring we announced the renaming of the official Docker images for Jenkins agents.
As a reminder, it does not have any immediate impact on Jenkins users, but they are expected to gradually upgrade their instances.

See more information about terminology updates here and here.

“Jenkins is the Way” program

This year the Advocacy and Outreach SIG started the “Jenkins is the Way” initiative which focuses on promoting user success stories.
Over the year, the team published 54 user stories and six case studies on https://jenkinsistheway.io/ as well as a significant amount of community marketing.
We also published a number of testimonial videos advertising user stories,
including this Introduction to &quot;Jenkins is the Way&quot; video.

See all the stories HERE

Events

Google Summer of Code

In 2020 we had seven students working in the Jenkins mentoring organization.
We had 6 projects focused on Jenkins and one project focused on Jenkins X.
As usual, in GSoC we focused on problems important to the Jenkins users and community members.
The projects delivered highly anticipated new features and key architecture changes needed for the long-term evolution of Jenkins.

This is the first-ever time in Jenkins when all GSoC students have reached the final evaluation and successfully passed it.
It was an incredible effort by all the project members and, most importantly, by the students. Thanks a lot to them!

Read more: https://www.jenkins.io/blog/2020/12/22/gsoc-report/

Jenkins in Hacktoberfest 2020

In October we participated in Hacktoberfest.
Our featured projects included the Jenkins core, jenkins.io website and plugins.jenkins.io, Helm charts, and multiple plugins.
We also encouraged contributors to participate in the Documentation as Code and terminology cleanup across the entire Jenkins ecosystem.

See the details in the Hacktoberfest page.

In total we received 226 pull requests from Hacktoberfest participants.
Some stats per Jenkins GitHub organization:

&#x27;jenkinsci&#x27;, PRs: 189, Hacktoberfest contributors: 61

&#x27;jenkins-infra&#x27;, PRs: 100, Hacktoberfest contributors: 40

&#x27;jenkins-zh&#x27;, PRs: 37, Hacktoberfest contributors: 2

Jenkins at DevOps World

The annual DevOps World,
formerly known as DevOps World | Jenkins World held on Sept 22-24, with workshops on Sept 25.
Just like other events in 2020, DevOps World pivoted to a virtual event but that didn’t mean there was a shortage of sessions or networking opportunities. There were over 50 Jenkins/open-source.
And a special congratulations is in order to this year’s Jenkins Contributor Award winners:

James Holderness - Jenkins security MVP

Marky Jackson - Most valuable Jenkins advocate

Tim Jacomb - Most valuable Jenkins contributor

Below are just a few sessions, the full agenda can be found HERE :

Jenkins Where It Is and Where It Is Going

One Jenkins to Rule them All

Jenkins UI Gets a Makeover

Jenkins Pipeline and DevSecOps for API Security

Graduation at Continuous Delivery Foundation

Jenkins is the first project to graduate in the CD Foundation.
In August the project announced that the Jenkins project has achieved the graduated status in the Continuous Delivery Foundation (CDF).
Thanks to all contributors who made our graduation possible!
Below you can find a few key changes we have applied during the graduation process:

We introduced a new public roadmap for the Jenkins project.
This roadmap aggregates key initiatives in all community areas: features, infrastructure, documentation, community, etc.
It makes the project more transparent to all Jenkins users and adopters, and at the same time helps potential contributors find the hot areas and opportunities for contribution.
The roadmap is driven by the Jenkins community and it has a fully public process documented in JEP-14.

A new list of Jenkins adopters was introduced on jenkins.io.
This list highlights Jenkins users and references their case studies and success stories,
including ones submitted through the Jenkins Is The Way portal.
Please do not hesitate to add your company there!

We passed the Core Infrastructure Initiative (CII) certification.
This certification helps us to verify compliance with open source best practices and to make adjustments in the project (see the bullets below).
It also provides Jenkins users and adopters with a public summary about compliance with each best practice.
Details are on the Jenkins core page.

Jenkins Code of Conduct was updated to the new version of Contributor Covenant.
In particular, it sets best practices of behavior in the community, and expands definitions of unacceptable behavior.

More information can be found HERE, and HERE.

Public Roadmap

The Jenkins project now has a public, community-driven project roadmap.  Roadmap items are major initiatives and are considered as official plans.
The roadmap aggregates key initiatives in all areas of the project.

Many of the 2020 released roadmap items are mentioned elsewhere in this document, including release automation, Core Infrastructure Initiative (CII) certification,
user interface improvements, read-only configuration pages,
and Google Summer of Code projects like the GitHub Checks API or External Fingerprint Storage.

Other roadmap items include mirror infrastructure improvements, a new Windows installer,
and preview releases of pluggable storage for external fingerprints, build logs, and unit test results.

Jenkins 2020 Elections

In October-December the Jenkins community held the regular elections.
This year we were  electing for 2 governance board members and for all five officer positions, namely: Security, Events, Release, Infrastructure, and Documentation. These roles are an essential part of Jenkins&#x27; community governance and well-being. We thank all candidates and voters who participated this year.

Key results:

Gavin Mogan and Marky Jackson joined the Jenkins Governance Board

Tim Jacomb was elected as Release Officer

Marky Jackson became the new Events Officer

Olivier Vernin, Daniel Beck, and Mark Waite will continue as Infrastructure, Security and Documentation officers

Full election results: https://www.jenkins.io/blog/2020/12/03/election-results/

And even more

This blog post does not provide a full overview of what changed in the project,
it is just a slice of the key highlights mentioned by the contributors.
The Jenkins project consists of more than 2000 plugins and components which are developed by thousands of contributors.
Thanks to them, a lot of changes happen in the project every day. We are cordially grateful to everybody who participates in the project, regardless of contribution size. Everything matters: new features, bug fixes, documentation, blog posts, well reported issues, Stackoverflow responses, etc. THANKS A LOT TO ALL CONTRIBUTORS!

So, keep updating Jenkins and exploring new features.
And stay tuned, there is much more to come next year!

What’s next?

Technical changes. 2021 will be another busy year for the Jenkins community.
There are many long-overdue changes in the project, which need to happen if we want Jenkins to succeed.
There are many areas on the roadmap : UX revamp, cloud native Jenkins, pluggable storage, etc.
There will also be a continued cleanup of old dependencies and technical debt.
Several key changes are expected to land in the March LTS baseline: update to Spring Security, XStream unforking, JQuery update, etc.( announcement).
In addition to that, we will keep working on expanding platform support in Jenkins, including provisioning support for new Java versions and official images for more architectures like Arm.

Documentation. Documentation efforts will continue in the next year,
with a focus on documenting Jenkins usage on modern platforms and and automation use-cases.
Wide adoption of documentation-as-code will also continue for plugins By this time almost 600 plugins have been migrated, but there are hundreds more plugins to go.

Security. Another important area is Jenkins security. Automation tools like Jenkins are a key part of the software delivery process in organizations, and their security is essential for the security of products.
Misconfigured or outdated systems are a common attack vector, but there are also areas for improvement on the project’s side.
Be sure there will be security advisories and vulnerability fixes in 2021.
We plan to keep adopting best security development and software delivery practices, and to improve dependency management and developer tools in the project. These areas will be in the spotlight for the project next year.

Events. Next month we will participate in FOSDEM, and there will be a virtual Jenkins stand there.
There will also be a CI/CD devroom.
If you are interested to meet Jenkins contributors, it is a great opportunity. We also plan to continue all outreach programs and on onboarding more contributors.
At the moment we are looking for Google Summer of Code 2020 mentors and project ideas ( announcement).
We are also ready to consider other non-coding project ideas as a part of CommunityBridge.
If you are interested, please contact the Advocacy and Outreach SIG.

Join us in 2021!

We are always looking for more contributors, regardless of the profile and experience.
Jenkins is a vast ecosystem which includes many modern technologies.

We invite Jenkins users and contributors to participate in the community and to move these initiatives forward!
Join us in the mailing lists and special interest groups,<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markyjackson-taulia/">Marky Jackson</a>, <a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/new-year-blogpost">new-year-blogpost</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/01/26/new-ebook-build-deploy-and-automate-great-stuff-with-jenkins/"><div class="header"><div class="date"><div class="month">Jan</div><div class="day">26</div></div><h5 class="title">New eBook: Build, deploy, and automate great stuff with Jenkins</h5></div><p class="teaser">In April of last year, we launched a new Jenkins community website called JenkinsIsTheWay.
The Jenkins Is The Way site has collected the experiences of Jenkins users around the world as they develop software and create solutions.
They are charting new paths, discovering new opportunities, and overcoming challenges.

That’s what makes Jenkins Is The Way tick.
Engineers in the Netherlands might have already met challenges faced by developers in India.
Solutions uncovered by DevOps teams in Spain may benefit those just starting in the USA.
Interns in Bogota may develop pipeline solutions that can be integrated into workflows used across the globe in Tokyo.
Or vice versa!

No matter where you are, regardless of whether your solution is regional or global in nature, Jenkins Is The Way.

Telling your stories in a new eBook

To date, we have nearly 60 user stories, a handful of case studies, and some new user testimonial videos from the Jenkins community.
You shared how using Jenkins has helped make your builds faster, your pipelines more secure, and your developers and software engineers happier.
In essence, Jenkins Is The Way showcases how Jenkins has made it a whole lot easier to do the work you do every day.

We’ve now gathered some of those stories in our first Jenkins Is The Way ebook, covering various challenges and solutions from six different industries: Aerospace, Education, Finance, Insurance, Retail, and Travel.

You’ll read about innovations from KP Labs in Poland and Preply in Ukraine.
You’ll discover how automation helped Avoris out of Spain &amp; Portugal and Tymit in the United Kingdom.
And you’ll be inspired by what China’s JD.com and Topdanmark in Denmark were able to achieve after tapping into the Jenkins community.

This curated collection of stories illustrates how Jenkins community members build next-generation DevOps and CI/CD platforms as the backbone for software innovation across companies of all sizes.
They highlight the innovation, ingenuity, and keen ability to adapt Jenkins plugins to handle everyday business issues, everywhere.

The technology landscape is full of solutions perfected to tackle all aspects of software development.
But time and time again, developers keep coming back to Jenkins.
Your engineering time and resources are too valuable to be spent re-inventing the wheel or handling manual testing and deployment cycles.

Jenkins&#x27; vast array of plugins and pre-built solutions will have you automating more than you ever imagined.
So, get inspired to build great stuff with Jenkins.
And, please share this ebook with your network.

Share your story!

And when you’re ready to tell your story, we’re prepared to help you share it.
Fill out the short questionnaire, and we’ll send you our Jenkins Is The Way T-shirt as a thank you!

Special thanks to CloudBees, Inc. for sponsoring this program.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkinsistheway">jenkinsistheway</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/casestudies">casestudies</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/Jenkinsuserstories">Jenkinsuserstories</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/02/08/docker-base-os-upgrade/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day"> 8</div></div><h5 class="title">Docker image updates</h5></div><p class="teaser">Beginning with Jenkins 2.279 and Jenkins 2.263.4, the Jenkins project is upgrading the base operating system and Java version used in the jenkins/jenkins:latest and jenkins/jenkins:lts images.
The update replaces OpenJDK 8u242 with AdoptOpenJDK 8u282 and replaces Debian 9 (&quot;Stretch&quot;) with Debian 10 (&quot;Buster&quot;).

Why?

We’re changing the base image so that we have a better supported operating system and a more current Java release for Jenkins controllers.

Better supported operating system

The Docker images provided by the Jenkins project rely on the operating system security processes of the operating system provider.

Our Docker images have used Debian 9 (&quot;Stretch&quot;) for multiple years.
Debian 9 security updates have been discontinued as of July 6, 2020.
Debian 9 Long Term Support security updates will be discontinued at the end of June 2022.
The upgrade to Debian 10 keeps us on an operating system maintained by the operating system security team.

More current Java release

The Debian 9 Docker images were based on the openjdk:8-jdk-stretch Docker image.
The last update to that image was one year ago with the release of JDK 8u242.
We need a maintained Docker base image that keeps pace with JDK releases and operating system updates so that the controller is running the most recent Java updates and most recent operating system updates.

Other Jenkins controller images have already switched from using openjdk base images to instead use base images provided by Eclipse Adoptium.
Eclipse Adoptium is the Eclipse project formed when AdoptOpenJDK joined the Eclipse Foundation.
This change adapts the jenkins/jenkins:latest and jenkins/jenkins:lts images to use the Adoptium JDK images in the same pattern as is already used for the Jenkins JDK 11 Docker images like jenkins/jenkins:lts-jdk11.
The Jenkins Platform SIG has enjoyed very good results in our interactions with the Eclipse Adoptium project.
We look forward to continuing our collaboration with them.

Thanks a lot to Alex Earl and Jim Crowley for the image build restructuring groundwork that made the image upgrade possible!
Also thanks to Oleg Nenashev and other contributors for their reviews and testing.

Packaging changes

The Jenkins Docker image based on Debian 10 (&quot;Buster&quot;) includes some different packages than Debian 9 (&quot;Stretch&quot;).
Some packages have been removed because they are no longer supported by their communities.
Some packages have been removed due to infrequent and decreasing use.
Users of the Jenkins Docker images may need to extend their definition of their Docker image to include packages that are no longer included in the base image.

SCM packages removed

The following source control management packages are no longer included in the Jenkins controller images for jenkins/jenkins:latest or for jenkins/jenkins:lts :

bzr

mercurial

subversion

Other packages removed

Additional packages that are no longer included in the Jenkins controller images include:

bzip2

mime-support

python (the Python project stopped supporting Python 2 January 1, 2020)

xz-utils

A detailed list of the exact package changes is available in the pull request.

Upgrade and compatibility notes

The Jenkins controller images are designed to be extended to meet user needs.
Custom Jenkins controller images can be created from the base images and are designed to allow additional Jenkins plugins and additional operating system packages.

For example, the Installing Docker instructions illustrate a technique to install the Blue Ocean plugins and some operating system packages in a custom Docker image.

Docker image with Subversion

The following Docker image definition installs the most recent Jenkins Long Term Support release with the subversion plugin and the operating system subversion command:

FROM jenkins/jenkins:lts
USER root
RUN apt-get update &amp;&amp; \
    apt-get install -y --no-install-recommends subversion
USER jenkins
RUN jenkins-plugin-cli --plugins subversion:2.14.0

Build a new docker image from this Dockerfile and assign the image a meaningful name, e.g. &quot;myjenkins-subversion:1.1&quot;:

docker build -t myjenkins-subversion:1.1 .

Docker image with Mercurial

The following Docker image definition installs the most recent Jenkins Weekly release with the mercurial plugin and the operating system hg command:

FROM jenkins/jenkins:latest
USER root
RUN apt-get update &amp;&amp; \
    apt-get install -y --no-install-recommends mercurial
USER jenkins
RUN jenkins-plugin-cli --plugins mercurial:2.12

Build a new docker image from this Dockerfile and assign the image a meaningful name, e.g. &quot;myjenkins-mercurial:1.1&quot;:

docker build -t myjenkins-mercurial:1.1 .

What’s next?

We will continue Docker image updates as new Java versions are released.

If you are interested in new features in Jenkins Docker packaging,
stay tuned for future announcements!
There are multiple ongoing initiatives which you can find on the public Jenkins roadmap.
Some stories:

Switching to AdoptOpenJDK.

General availability of Windows images.

Support for more platforms (AArch64, IBM s390x, PowerPC).

Introducing multi-platform Docker images.

If you are interested in any of these projects and would like to contribute,
please reach out to the Platform Special Interest Group which coordinates initiatives related to Jenkins in Docker.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform-sig">platform-sig</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/02/16/contributor-summit-online/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">16</div></div><h5 class="title">Jenkins Contributor Summit Online Feb 23-25</h5></div><p class="teaser">The Jenkins Contributor Summit brings together current and future contributors to the Jenkins project.
We’re hosting an online summit this year to encourage contributors from around the world to meet, discuss, and plan for the future.

The Contributor Summit will be Tuesday, February 23rd 2021 through Thursday, February 25, 2021.
The summit brings together community members to learn, meet, and help shape the future of Jenkins.
In the Jenkins community we value all types and sizes of contributions and love to welcome new participants.

Format

The online format allows greater flexibility for meeting times and topics.
Contributors will meet to discuss specific topics in smaller groups at times that are convenient for those in the meeting.

Opening session

The opening session will start Tuesday, February 23, 2021 at 15:00 UTC.
After an initial welcome and overview, we’ll hear from leaders in the Jenkins project as they share the results from the previous 12 months and outline ideas for the next 12 months.

Security - Daniel Beck

Infrastructure - Olivier Vernin

Release - Tim Jacomb

User experience - Félix Queiruga

Chinese localization - 赵晓杰(Rick)

Configuration as code - Tim Jacomb

Google Summer of Code - Kara de la Marck

Documentation - Mark Waite

Events and Advocacy - Alyssa Tong

Cloud Native - Kara de la Marck

Platforms - Mark Waite

After those presentations, we’ll create &quot;breakout rooms&quot; in the online meeting that will allow those interested in specific tracks to meet, identify preferred times for their tracks, and prepare draft agendas for their tracks.

Tracks

Smaller sessions (&quot;tracks&quot;) will be run in the 48 hour period between the opening session and the closing session.
These smaller sessions will be focused on specific topics.
A track leader will organize the track meeting, facilitate discussions in the track meeting, and present a summary of the track results in the closing session.

Closing session

The opening session will start Thursday, February 25, 2021 at 15:00 UTC.
After an initial welcome and overview, we’ll hear from track leaders as they share the results from their track meetings.

We’ll identify items that should be added to the Jenkins roadmap, items that should be further investigated by special interest groups, and items that need further discussion elsewhere.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/02/17/cfp-cdcon/"><div class="header"><div class="date"><div class="month">Feb</div><div class="day">17</div></div><h5 class="title">cdCon 2021 - Call for Jenkins Proposals</h5></div><p class="teaser">Hear ye! Hear ye! Jenkins Community,

cdCon 2021 (the Continuous Delivery Foundation’s annual flagship event) is happening June 23-24 and its call for papers is open!

This is your chance to share what you’ve been doing with Jenkins.
Are you building something cool?
Using it to solve real-world problems?
Are you making things fast?
Secure?
Or maybe you’re a contributor and want to share what’s new.
In all cases, we want to hear from you!

Submit your talk for cdCon 2021 to be part of the conversation driving the future of software delivery for technology teams, enterprise leadership, and open-source communities.

Submission Deadlines

Early-Bird Deadline

Friday, February 19 by 11:59 PM PST

Final Deadline

Friday, March 5 at 11:59 PM PST

Topics

Here are the suggested tracks:

Continuous Delivery Ecosystem

This track spans the entire Continuous Delivery ecosystem, from workflow orchestration, configuration management, testing, security, release automation, deployment strategies, developer experience, and more.

Advanced Delivery Techniques

For talks on the very cutting edge of continuous delivery and emerging technology, for example, progressive delivery, observability, and MLOps.

GitOps &amp; Cloud-Native CD

Submit to this track for talks related to continuous delivery involving containers, Kubernetes, and cloud*native technologies. This includes GitOps, cloud-native CD pipelines, chatops, best practices, etc.

Continuous Delivery in Action

This track is for showcasing real-world continuous delivery addressing challenges in specific domains e.g. fintech, embedded, healthcare, retail, etc. Talks may cover topics such as governance, compliance, security, etc.

Leadership Track

Talks for leaders and decision-makers on topics such as measuring DevOps, build vs buy, scaling, culture, security, FinOps, and developer productivity.

Community Track

There is more to open source than code contributions. This track covers topics such as growing open source project communities, diversity &amp; inclusion, measuring community health, project roadmaps, and any other topic around sustaining open source and open source communities.

Singular project focus and/or interoperability between:

Jenkins

Jenkins X

Ortelius

Spinnaker

Screwdriver

Tekton

Other – e.g. Keptn, Flagger, Argo, Flux

View all tracks and read CFP details.

We look forward to reading your proposal!

Submit it here<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cdfoundation/">Continuous Delivery Foundation</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cdcon">cdcon</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cfp">cfp</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cicd">cicd</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/continuous delivery">continuous delivery</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/03/15/update-center-certificate-rotation/"><div class="header"><div class="date"><div class="month">March</div><div class="day">15</div></div><h5 class="title">Update-Center certificate rotation</h5></div><p class="teaser">On the 29th of March 2021, we’ll rotate the Jenkins update center certificate.
The existing certificate expires in April 2021.
When the new certificate is installed on March 29, 2021, Jenkins versions older than 2.178 (April 2018), won’t be able to communicate with the default and experimental update centers.
Instances using alternative update centers (self-hosted or vendor-provided) will not be affected by this change.
Regarding plugins update, the update-center usually supports up to one-year-old Jenkins core versions with 2.204 being the oldest version supported.

If you don’t update regularly, please review the Jenkins security advisories and use this change as your motivation to update to a more recent Jenkins version.

Who

Jenkins users running Jenkins versions older than 2.178 will not see any further updates after the update center certificate change March 29, 2021.

Jenkins developers will not see plugin updates when they use mvn hpi:run to test their plugin if the Jenkins version is older than 2.178.
Plugin developers can update their minimum Jenkins version to a newer Jenkins version.
Refer to the guidelines in&quot;Choosing a Jenkins version&quot; when selecting the new minimum Jenkins version.
Plugin developers may also be able to test with a newer Jenkins version using arguments like mvn -Djenkins.version=2.249.1 hpi:run.

Jenkins users running versions 2.178 or newer are not affected by this change.

What

Jenkins uses the update center to identify updates to core and to plugins.
The service signs its metadata with a certificate that is cross-signed by a root certificate.
Jenkins is bundled with the root certificate so it can confirm the authenticity of update center data.
When updates are available, an alert is shown to Jenkins users that reminds them to update.

Why

The root certificate bundled in Jenkins was created in April 2011 and will expire in April 2021.
We prepared for this rotation in April 2018 when we bundled the new root certificate with Jenkins core releases.
It’s now time to use the new root certificate with a new update center certificate.
The new root certificate will expire in April 2028.

You can follow the work for this certificate rotation in this ticket INFRA-2902

So again, keep your instance updated and everything should be fine.

See you in 2028,

Various Links:

INFRA-2902 - Rotate the update center certificate

INFRA-2732 - Annual certificate update

INFRA-1502 - Add new root certificate (2018)

jenkins-infra/update-center2 - Jenkins update center certificates

updates.jenkins.io - Jenkins update center

advisories - Jenkins security advisories<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/update-center">update-center</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/03/17/gsoc2021-announcement/"><div class="header"><div class="date"><div class="month">March</div><div class="day">17</div></div><h5 class="title">Jenkins accepted in Google Summer Of Code 2021!</h5></div><p class="teaser">On behalf of the Jenkins GSoC org team,
I am happy to announce that this year, for the first time, the Jenkins projects will be participating in
Google Summer of Code 2021
as part of the
Continuous Delivery Foundation (CDF) GSoC organization.

We’re very excited to have the Jenkins project participate in GSoC as part the CDF mentoring organisation along with
fellow CDF projects such as Ortelius, Screwdriver, Spinnaker, and Tekton. We believe that being part of the CDF
GSoC org will create an environment for students with even more mentoring channels, potential cross-fertilization of ideas,
and an even greater community of DevOps practitioners to join!

What’s next?
GSoC is officially announced, and please expect more students to contact projects in our
Gitter channels and mailing lists.
Many communications will also happen in SIG and sub-project channels.
Also, please join the gsoc channel on the /&quot;&gt;CDF Slack.
We will be working hard in order to help students to find interesting projects, to explore the area,
and to prepare their project proposals before the deadline on April 13th.
Then we will process the applications, select projects and assign mentor teams.

All information about the Jenkins GSoC is available on its sub-project page.

I am a student. How do I apply?

See the Information for students page for full application guidelines.

We encourage interested students to reach out to the Jenkins community early and to start exploring project ideas.
All project ideas have chats and mailing lists referenced on their pages.
We will be also organizing office hours for students,
and you can use these meetings to meet org admins and mentors and to ask questions.
Also, join our Gitter channel and the
mailing list
to receive information about such incoming events in the project.

The application period starts on March 29th, but you can prepare now!
Use the time before the application period to discuss and improve your project proposals.
We also recommend that you become familiar with Jenkins and start exploring your proposal areas.
Project ideas include quick-start guidelines and reference newbie-friendly issues
which may help with initial study.
If you do not see anything interesting,
you can propose your own project idea
or check out ideas proposed by other CDF organizations
participating in GSoC.

I want to be a mentor. Is it too late?

It’s not!
We are looking for more project ideas and for Jenkins contributors/users
who are passionate about Jenkins and want to mentor students.
No hardcore experience required, mentors can study the project internals together with students and technical advisors.
We are especially interested in ideas beyond the Java stack, and in ideas focusing new technologies and areas
(e.g. Kubernetes, IoT, Python, Go, whatever).

You can either propose a new project idea or join an existing one.
See the Call for Mentors post
and Information for mentors for details.
If you want to propose a new project,
please do so as soon as possible so that students have time to explore them and to prepare their proposals.

This year mentorship does NOT require strong expertise in Jenkins development.
The objective is to guide students and to get involved into the Jenkins community.
GSoC org admins will help to find advisers if special expertise is required.

Testimonials from former Jenkins GSoC participants ❤️

&quot;I participated in Google Summer of Code 2020 in cooperation with the Jenkins organization
and I work on a project called Windows Service Wrapper, which allows running Jenkins as a service on a Windows machine.
GSoC was the most wonderful and the most valuable experience I gained during my student life.
The whole journey was full of experiences and Jenkins mentors always were there for us.
I experienced a huge development of my skills while I was working on the project.
I had many meetings, knowledge sharing sessions, and one pair-coding session with my mentors.
One of the best things that I learned is the open-source community and open source mentality.
It is not only about taking, but also about giving.
Today I am maintaining an open-source project which is a simple programming language for kids
which allows them to code in their native language, which will help to learn coding to students in rural areas of my country.
Finally, Jenkins is a wonderful family and they always were there for us in all the ups and downs.
I am proud to be a part of the Jenkins community.&quot;

Buddhika Chathuranga, GSoC 2020 student, Support for YAML Configuration in Windows Service Wrapper

&quot;My GSoC journey in the Jenkins community starts by a draft proposal full of comments from mentors and ends by two plugins with hundreds of installations.
Along with the daily coding review, the weekly meeting and the growth of the project,
I increased my skills on programming and became a much more eligible engineer.
What is more, the support from the whole Jenkins community leads me to a broader career path.
I learned how to maintain a project, how to communicate with users and other developers on GitHub.
Most importantly, the Jenkins community teaches me the principles of the open source world
and welcomes me to the open source world with all their kind help.&quot;

Kezhi Xiong, GSoC 2020 students, GitHub Checks API project

&quot;I worked as a Google Summer of Code student with the Jenkins project during the summer of 2019.
The project provided me with an excellent opportunity to contribute to the world’s most popular automation server,
learn about building performant and reliable applications, and interact with awesome people around the globe.
Jenkins&#x27; ever helpful and extremely knowledgeable community made working on my project a real treat.
I even got a chance to present my project at DevOps World in Lisbon!
If you’re deciding which organization to work for this year, choose the Jenkins project — you can’t have a better GSoC experience than this!&quot;

Abhyudaya Sharma, GSoC 2019 student, Role Strategy Performance Improvements

&quot;I participated in Google Summer of Code 2018 with Jenkins as a student developer.
Working for Jenkins in GSoC 2018 was one of the best experiences I have ever had.
During 3 months of summer, I learned a lot of new things when working on the open-source project with Jenkins.
Another best thing about Jenkins is the people, I received a lot of support from my mentors
and other developers from the Jenkins community when working on my project.
After GSoC, I also had a chance to go to the Jenkins World Conference in San Francisco
to meet and connect with my mentors and other people in the Jenkins community.
Overall, GSoC with Jenkins was a great experience and
I highly recommend Jenkins as a great community to kickstart your open source journey.&quot;

Pham Vu Tuan, GSoC 2018 student, Remoting over Apache Kafka project

Important dates for GSoC 2021

Apr 13 - deadline for student applications

May 17 - accepted projects announced, teams start community bonding and coding

Aug 16 - coding period ends

Aug 31 - Results announced

See the GSoC Timeline for more info.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/marckk/">Kara de la Marck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/03/19/SheCodeAfrica-announcement/"><div class="header"><div class="date"><div class="month">March</div><div class="day">19</div></div><h5 class="title">Jenkins accepted in She Code Africa Contributhon</h5></div><p class="teaser">She Code Africa is a non-profit organization focused on celebrating and empowering young girls and women in technology across Africa.
They provide resources and events that help women grow and achieve their personal and career goals.
Their mentoring programs provide help and guidance as participants learn and grow in their careers.

This year, She Code Africa is organizing the She Code Africa Contributhon.
Contributhon is a boot camp where African women are paid to work with open source organizations on selected projects with dedicated mentors.
This program aims to create a more diverse, inclusive, and innovative culture within the African open source ecosystem by matching African women in technology with sponsor and mentor open source organizations.

Jenkins in She Code Africa Contributhon

The Jenkins project has been accepted as a Contributhon mentoring organization.
Our project idea will introduce participants to Jenkins and plugin development as they create Pipeline examples and create Pipeline help for Jenkins Pipeline plugins.
Participants will learn more about Jenkins Pipeline and will submit plugin pull requests with examples and online help.

The Jenkins Pipeline Steps Reference and Pipeline online help often receive feedback that more examples are needed, that step return values need to be described, and that arguments need more description of their purpose, allowed values, and expected results.
Most plugin maintainers do not provide detailed documentation of the pipeline steps, or the arguments to those pipeline steps.
This project will improve the documentation of pipeline steps and their arguments while introducing Jenkins Pipeline, Jenkins plugin development, Jenkins documentation as code, and the concepts of GitHub forks and pull requests.

We’ve identified development tasks that up to three Contributhon participants will complete during April.
The tasks will introduce the participants to Jenkins plugin development.
They will experiment with plugin changes in Jenkins and submit pull requests to provide Pipeline examples and help.
They will meet twice a week with Jenkins mentors, Kristin Whetstone, Mark Waite, and Meg McRoberts to review their progress, provide coaching, and help with issues.

Data driven choices

We’ve been collecting Jenkins documentation feedback since 2017.
Now we’re using that feedback to prioritize the plugins to improve as part of this project.
The top 10 Pipeline plugins that have received the most feedback are:

Build step

SCM step

Git step

Input step

Nodes and processes steps

Workspace cleanup step

Basic Pipeline steps

Slack notification steps

HTTP request step

Email extension steps

What about my plugin?

If you are a plugin maintainer and would like help to add examples and online help for the Pipeline steps in your plugin, send email to the Jenkins Documentation mailing list.
We’ll consider including additional plugins as we better understand the development pace for She Code Africa participants.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/03/22/governance-updates/"><div class="header"><div class="date"><div class="month">March</div><div class="day">22</div></div><h5 class="title">Welcome Ewelina Wilkosz - new Jenkins Governance Board member</h5></div><p class="teaser">We would like to announce changes in the Jenkins Governance Board.
As it was announced earlier this month, Marky Jackson has decided to step down from his elected roles.
On behalf of the Jenkins community, we would like to thank Marky for all contributions and for the continued participation in the Jenkins community.
As an active Jenkins contributor and community leader, Marky helped a lot of initiatives to happen:
 Jenkins and Kubernetes ecosystem, terminology changes, GSoC and GSoD, pipeline authoring SIG and many more activities.
Thank you Marky!

The governance board has followed the interim procedure
to nominate the new governance board member until the end of the term.
The board decided to respect the results of the 2020 elections and
to nominate Ewelina Wilkosz who received the most of the votes after the elected candidates.
She has accepted the nomination, and on March 10th the Governance Meeting has confirmed it.
We are happy to welcome Ewelina Wilkosz as a new Governance Board Member!

Ewelina will join other governance Board Members:
Kohsuke Kawaguchi,
Ullrich Hafner,
Oleg Nenashev, and
Gavin Mogan.
The term will last until December 2022.

About Ewelina Wilkosz

Ewelina has been a Jenkins Contributor since 2017, when she got involved in Jenkins Configuration as Code Plugin development.
Voted Most Valuable Jenkins Contributor in 2018.
She has 14 years of experience in IT, working as a CI/CD consultant since the beginning of 2017.
In that role she’s trying to solve numerous issues Jenkins users are facing daily - as developers, administrators, maintainers.

Here is Ewelina’s statement from the elections:

As a consultant I support my customers with their Jenkins issues since the beginning of 2017.
And almost from the start it was some kind of &quot;as code&quot; approach.
The experience I gained during that time resulted in getting myself involved in the development of Configuration as Code Plugin for Jenkins.
I consider becoming a part of Jenkins Community one of the most valuable experiences in my career so far.
I appreciate how much I have learned and how welcoming the community is.

I am not a very active contributor these days, at least when it comes to code, but what I have to offer is rather extensive experience
with Jenkins end users - from small, single instance setups to environments with hundreds of controllers run in a different way on different operating systems.
Every day I see challenges those users go through, I know what issues they are facing and which features they consider valuable or missing.
As a Jenkins Governance Board Member I can represent those users.

Thanks to my involvement in Configuration as Code Plugin development
I had a chance to deliver a number of public presentations
where I focused on the benefits of the solution and tried to make it easier for newcomers to try it.
Here are a few examples of my activities related to Jenkins Configuration as Code:
blogpost,
cdCON presentation,
podcast recording.
So my focus is not only on representing users but also on educating them, and educating myself,
so I actually know what they need and why.

What’s next for the Jenkins Governance Board?

In February we had the Jenkins Contributor Summit.
There we discussed many topics related to the Jenkins evolution and its roadmap.
We identified several initiatives we would like to focus on,
including but not limited to improving user experience, contributor onboarding, and securing Jenkins delivery pipelines.
These initiatives will be a key focus until the next contributor summit we plan to organize in June.
The board will also focus on maintaining the Jenkins governance processes
(meetings, budget approvals, funding, etc.) and facilitating contributions to the project.

Participating in Jenkins Governance

Jenkins Governance Board has just a representative function in the community.
The project and the community have a long history of open and inclusive governance driven by many contributors.
We invite all community members to participate in the project by joining the
governance meeting,
participating in the mailing list conversations,
and joining special interest groups driving particular topics.

See this page to know more about contributing to Jenkins in general.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/04/07/contributhon-participants/"><div class="header"><div class="date"><div class="month">April</div><div class="day"> 7</div></div><h5 class="title">Welcome the She Code Africa Contributhon participants!</h5></div><p class="teaser">The She Code Africa Contributhon started April 1, 2021.
The She Code Africa Contributhon is a boot camp where African women are paid to work with open source organizations on selected projects with dedicated mentors.
This program aims to create a more diverse, inclusive, and innovative culture within the African open source ecosystem by matching African women in technology with sponsor and mentor open source organizations.
The 5 mentees joining the Jenkins project come from Nigeria, Kenya, and Rwanda.

The Jenkins project has been accepted as a Contributhon mentoring organization.
Our project idea will introduce mentees to Jenkins and plugin development as they create Pipeline examples and create Pipeline help for Jenkins Pipeline plugins.

Twice weekly mentoring sessions are scheduled with the mentees and are listed in the events calendar.
We’ve already received the first pull request to improve the embedded documentation that generates the Steps Reference and provides contextual help in the Snippet Generator.
We’re looking forward to more pull requests and more improvements throughout April, 2021.

We’d like to introduce our mentees so that you recognize them and can welcome them during code review and online chat.

Onyinye Ezike

Onyinye is based in Lagos, Nigeria.
She’s a junior fullstack software developer who is very passionate about learning.
She uses Angular, React, Nodejs, and Spring Boot.
She has spent the last two years building up herself in software development and she’s hoping to become a world-class software developer.

You’ll recognize her contributions as Onyimatics on GitHub and on the Jenkins issue tracker.

Sharon Jebitok

Sharon is based in Kenya.
She’s a software development student at Microverse, a remote school for software developers.
She has been an active member of She Code Africa and she’s presently a mentee on She Code Africa’s Contributhon Program with the Jenkins project.
She has spent one year in the software industry since she switched her career into tech, learning to write meaningful code and collaborate with other developers/designers and the tech community.

You’ll recognize her contributions as jebitok-dev on GitHub and as jebitok16_ on the Jenkins issue tracker.

Esther Ejidike

Esther is a frontend developer based in Lagos, Nigeria.
She is one of the participants in the She Code Africa Contributhon Open Source Program working with Jenkins and will be contributing to the nodes and processes plugin.
She loves to convert designs to exact replicas in the form of webpages and she likes to learn new things in her free time.

You’ll recognize her contributions as Queen-esther01 on GitHub and as esther101 on the Jenkins issue tracker.

Cynthia Iradukunda

Cynthia Iradukunda is based in Kigali, Rwanda.
She is currently a junior Computing student at the African Leadership University (ALU) in Mauritius.
She wants to be a software engineer because it will help her solve real-world problems while also allowing her to use her coding skills.
Her coding skills include but not limited to Java, JavaScript, and attention to detail.
By contributing to the Git plugin, she hopes to help users have a smooth process using its documentation, get involved with the project, and connect with other community members.

You’ll recognize her contributions as ciradu2204 on GitHub and as ciradu2204 on the Jenkins issue tracker.

Lucy Karimi

Lucy is based in Nairobi, Kenya.
She is a software developer with experience in mobile app development.
She is very passionate about tech and is currently involved in the SheCodeAfrica Contributhon.

You’ll recognize her contributions as luciahroyalty101 on GitHub and as luciahroyalty101 on the Jenkins issue tracker.

About the Contributhon projects

See the previous blog post for more information about She Code Africa, the Contributhon, and the plans for Jenkins.

Jenkins development tasks

She Code Africa Contributhon mentoring organizations

She Code Africa Contributhon

She Code Africa

Conversations related to the Contributhon are happening in a Continuous Delivery Foundation slack channel.

Mentors

We’re very grateful to the mentors from the Jenkins project that are hosting mentoring sessions, reviewing pull requests, and encouraging the mentees.
Thanks to:

Meg McRoberts

Mark Waite

Kristin Whetstone

Oleg Nenashev

Angélique Jard

We also thank Zainab Abubakar of She Code Africa for her efforts to facilitate the Contributhon and encourage participation.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/documentation">documentation</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/outreach-programs">outreach-programs</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/contributing">contributing</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/04/15/jenkins-operator-sub-project/"><div class="header"><div class="date"><div class="month">April</div><div class="day">15</div></div><h5 class="title">Jenkins Operator becomes an official sub-project!</h5></div><p class="teaser">We are happy to announce that Jenkins Operator officially became an official Jenkins sub-project.

What does it mean for the project?

Becoming an official part of the Jenkins project was a major step towards better alignment with the overall Jenkins’ roadmap and more opportunities to increase adoption of the Jenkins Operator project.

Finally, with a dedicated team at VirtusLab actively maintaining the project we can engage with the wider community and participate in some of the Cloud-Native SIG meetings.
This opens a room for everyone to voice their opinions or start supporting the project.

We truly believe that this community engagement will result in significant improvements to Jenkins Operator, as well as the Jenkins ecosystem itself.

Bridging the gap between Jenkins and Kubernetes

Running Jenkins in a cloud-native environment like Kubernetes is not a trivial task.
With Jenkins Operator project we want to enable the community to take full advantage of Kubernetes and public cloud capabilities by:

native integration with public cloud services in areas of observability, storage and cloud security

Kubernetes autoscaling and self-healing mechanism

secure access to Jenkins instance

declarative configuration using Kubernetes Custom Resources

full lifecycle management, eventually transforming it to autopilot

Take part in the journey toward global trends

Start contributing and play an important role in creating the automated Jenkins experience! Don’t hesitate - engage in the community.
Join us in our work of creating the functionalities you see beneficial.
You are welcome to create issues and pull requests. We are actively resolving community issues and providing answers on a dedicated Slack channel.

As the project has been initially developed and still actively maintained by VirtusLab, we started discussion towards an open governance model to facilitate communication and collaboration.

Lead the way we are heading by providing us feedback

To celebrate the new possibilities that are being opened for our project, we would like to invite you to take part in a short survey that will help put us on the right track.
If you have been using Jenkins Operator or running Jenkins in any other environment, please take a moment to fill out our quick survey.
We will choose at least three of the most informative answers and send you an awesome Jenkins Operator T-shirt with our cute Gopher butler.
The survey can be found here. Remember, the most sincere answers are the best.

And if you still haven’t used Jenkins Kubernetes Operator, you’re more than welcome to do so.
Give it a shot and discover a new kind of simplicity of running Jenkins.

How to get started.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/antoniaklja/">Bartek Antoniak</a>, <a href="/gatsby-jenkins-io/blog/authors/sylwiabrant/">Sylwia Brant</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/operator">operator</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/contributing">contributing</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/04/21/tekton-plugin/"><div class="header"><div class="date"><div class="month">April</div><div class="day">21</div></div><h5 class="title">Easily reuse Tekton and Jenkins X from Jenkins</h5></div><p class="teaser">What is Tekton?

Tekton is a powerful and flexible open-source framework for creating CI/CD systems, allowing developers to build, test, and deploy across cloud providers and on-premises systems.

Why use Tekton?

Tekton pipelines have a number of benefits:

they are cloud native and designed from the ground up for kubernetes

each Tekton Pipeline is fully declarative and completely self described; it does not depend on any separate out of band Jenkins controllers, plugins or plugin/controller configurations

each Pipeline Task runs as a stand alone kubernetes Pod which is completely independent of any other pods and pipelines and are fully scheduled by Kubernetes to maximise resilience and optimize resource usage. A bad pipeline cannot take down another one &amp; the kubernetes scheduler manages them all

each step can be any command in any container image with whatever secrets, volume mounts, environment variables and resource limits you need

there is no need to bundle a JVM or Jenkins Remoting container into the pod so you can keep resources and cost down

Why use Jenkins and Tekton together?

Jenkins is the most popular open source automation server around. Lots of developers use it every day to get things done.
Jenkins can now be used to automate Tekton pipelines too which helps teams digitally transform to more cloud native solutions for their CI and CD.
In such a case, you can use Tekton pipeline engine while getting all benefits from Jenkins as an orchestrator, user interface and the reporting engine.

Introducing the Tekton Plugin for Jenkins

The Tekton Client plugin for Jenkins lets you easily use Jenkins to automate creating and running Tekton pipelines.
It bridges the Kubernetes learning gap and allows invoking Tekton Pipelines and resources through Jenkins.
This allows users to not have much of the Kubernetes specific knowledge beforehand and work.

Its a single Jenkins plugin to install - so it’s easy to use.

For background check out the  blog post Bridging the Gap with Tekton-client-plugin for Jenkins by the founder of the plugin Vibhav Bobade.

Requirements

The Tekton Client plugin for jenkins assumes you have access to a kubernetes cluster.

The kubernetes cluster should have Tekton pipelines installed.

If you have not yet installed Tekton you could use this tekton helm chart

The Jenkins controller should also have kubernetes RBAC access to be able to create Tekton resources and watch them and their associated pods and pod logs.

If you are running your Jenkins controller inside Kubernetes then an easy way to setup the RBAC is to install the Jenkins Resource Helm Chart in the same namespace as your Jenkins controller.

Another option is to use an installation of Jenkins X and let it setup a Jenkins controller via GitOps

Specifying the Tekton pipelines

You can configure the Tekton pipeline via:

a file path in a git clone block

a URL to a tekton YAML file

a block of YAML

We recommend defining Tekton pipelines as YAML files and checking them into a git repository so that you can use GitOps and follow the Pipeline As Code pattern.

This means that you can version your pipelines in git. It also means you can benefit from the various IDE plugins available for Tekton such as VS Code and IDEA so that you get auto completion, formatting and validation while editing the YAML.

So you can use the usual Git provider support in Jenkins to clone the git repository that contains then Tekton YAML file then reference the file by name.

Reusing Pipelines from the Tekton Catalog

The Tekton Catalog defines a ton of Tekton Tasks you can reuse in your pipelines

We have found when it comes to a microsevices style architecture you end up with lots of repositories and pipelines. Then using a Pipeline As Code pattern with GitOps we want to Version Everything but also make it easy for any repository to use any version of any task or pipeline.

e.g. you may have many repositories using the current version of a pipeline but want to try out a new change to the pipeline in just 1 repository to verify it works well; then if it does, incrementally roll that change out to more repositories.

This can make it hard trying to reuse as much as you can across the different git repositories while also minimising the number of versions and forks of git repositories you have and simplifying the maintenance of all of the pipelines.

We have found on the Jenkins X project that a nice way to do this via GitOps such that we reference versioned Tekton Tasks and Pipelines in git so that they are easy to reuse or override.

So we reuse Tasks and Pipelines via the uses: image notation which lets us keep all of our Tekton Tasks and Pipelines in vanilla Tekton YAML; so that the IDE completion and validation works - but we can easily reuse Tasks or steps from libraries while also Versioning Everything

Note that if wish to reuse steps/tasks via the uses: image notation then you must click the Tekton Catalog flag in your Job definition which will then resolve the uses: clause with the actual step/task.

What is Jenkins X?

The Jenkins X project automates your CI/CD on kubernetes to help you accelerate :

Automated CI/CD pipelines lets you focus on your actually application code while Jenkins X automatically creates battle tested Tekton CI/CD pipelines for your project which are managed via GitOps so that its super easy to keep your pipelines up to date across your repositories or to upgrade or override pipelines or steps for specific repositories.

Automatic promotion of versioned artifacts via GitOps through your Environments such as Staging, Pre-production and Production whether they are running in the same kubernetes cluster or you are using multiple clusters for your environments

Preview Environments lets you propose code changes via Pull Requests and have a Preview Environment automatically created, running your code in kubernetes to get fast feedback from your team before agreeing to merge changes to the main branch

ChatOps comment on Pull Requests to give feedback, approve/hold changes, trigger optional pipelines for additional testing and other ChatOps commands

All of the above is implemented in reusable Tekton pipelines.

Reusing Jenkins X Pipelines

So how can we reuse automated CI/CD pipelines from Jenkins X project from Jenkins?

Make sure you have the Tekton Client plugin for Jenkins installed in your Jenkins server.

Using a working template

If you want to start with a working example then

Create A Git Repository From This Template

add a new Frestyle project to your Jenkins server

enable the Git source code management for your new github.com repository

click Add build Step (near the bottom of the page) and then select Tekton : Create Resource (Raw)

make sure that FILE is selected for the input and enter the name.lighthouse/jenkins-x/release.yaml for the file name

if you are using a Jenkins X cluster enter jx for the namespace

ensure that Enable Tekton Catalog is checked

now save the pipeline - it should look something like this:

Now if you trigger the pipeline you should see it create a Tekton Pipeline and you should see the output of the tekton pipeline in the Jenkins console. The pipeline is actually running as a completely separate Pod in kubernetes; the Jenkins controller just tails the log into the console.

In a Jenkins X cluster this pipeline should just work (reusing all the cloud resources and IAM roles setup by the Terraform) but in an arbitrary kubernetes cluster you may get issues around not being able to push images or promote due to lack of GitOps environments being defined which we can help you work through via the Jenkins X slack room

Using an existing repository

You can configure a Pull Request or Release pipeline in your project by copying the YAML file for the language pack you wish to use.

e.g. if you are using maven then copy pullrequest.yaml or release.yaml into your projects source code then reference it from your Jenkins Job:

Then follow the above instructions for setting up a Freestyle project for your git repository and referencing the file name for your pipeline.

Overriding steps

Being able to reuse steps from libraries of pipelines is awesome; but sometimes you need to change things. The assumptions, commands, arguments, environment variables or approaches used for every step in a library may not quite match what you need on a specific application. You may need to run steps before/after steps in the library or you may need to override a specific step to do something different.

You can easily customize any inherited step in any shared pipeline or add custom steps before/after any step.

The fact that all the Tekton YAML is fully declarative makes it super easy to modify things via your IDE with validation and smart completion and not have to use a scripting language and understand complex shared pipeline libraries.

The easiest way to try overriding a step is to install the jx binary to your $PATH then use the jx pipeline override command which will create a new locally overridden step you can then just edit in your IDE.

Then at any time you can view the effective pipeline when you make local changes

Comparing the Kubernetes and Tekton plugins

Those of you using Jenkins on a Kubernetes cluster are probably using the kubernetes plugin right now.

Here is an example of how to use a Jenkinsfile with a pod YAML file so that you can run commands in different containers in the pod.

What this means is that:

a kubernetes pod is created based on the pod YAML file which is scheduled by kubernetes

the Jenkinsfile runs on the Jenkins controller talking over Jenkins remoting to the pod to tell it to run commands in different containers. The pod includes the jnlp container which does the remoting between the Jenkins controller and the pod

This has a few issues:

each container in the pod must have a shell so that jnlp can invoke commands. This may mean you have to create your own images

it can be a little slow to start since there is chattiness with the Jenkins controller and the pod - whereas with Tekton pods just start and run locally without any coodination with the Jenkins controller

you have to maintain 2 files: the Jenkinsfile and the pod.yaml and it’s hard to share/override both of those files across multiple repositories as you need to make changes (e.g. overriding environment variables/images/commands/resource limits on demand on steps).

Though one downside of the tekton approach is that by default there is no automatic synchronisation of state; after a Task in tekton completes there’s no automatic upload of state to the Jenkins controllers disk. You can always add a step in your Task to upload workspace state to the Jenkins controller if that’s what you want.

Though remember that tekton plugin doesn’t take anything away; so you can mix and match the kubernetes and tekton plugins to suit your needs.

Conclusion

We are really excited about the combination of Jenkins, Tekton and Jenkins X letting developers pick the best tool for the job while becoming more cloud native and increasing the automation help reduce the amount of manual work creating and maintaining pipelines while also helping to improve the quality and practices of our CI/CD.

Please try it out and let us know how you get on!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jstrachan/">James Strachan</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-x">jenkins-x</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/pipeline">pipeline</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tekton">tekton</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gitops">gitops</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interoperability">interoperability</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/04/23/jenkins-contributor-awards/"><div class="header"><div class="date"><div class="month">April</div><div class="day">23</div></div><h5 class="title">Jenkins Contributor Awards - Nominations Open</h5></div><p class="teaser">This year, the Jenkins Contributor Awards will be run by the Continuous Delivery Foundation (CDF) along with many other CDF Community Awards.

The nominations are currently open and are being accepted using GitHub issues to make the process more transparent. Any contributor is eligible this time around! The deadline to nominate someone is May 14, 2021, and voting will open in May.

Nominate contributors or vote with reactions/comments for all three Jenkins awards:

Most Valuable Jenkins Contributor

Most Valuable Jenkins Advocate

Jenkins Security MVP

The winners will be announced at cdCon 2021, where we’re also co-locating the Jenkins Contributor Summit on June 25, 2021!

You can also nominate Jenkins community members for global awards like &quot;Top CDF Ambassador&quot; or &quot;Top GitOps Evangelist&quot;!
For all CDF Community Awards and more details, visit the CDF Award Page.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/cdfoundation/">Continuous Delivery Foundation</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/awards">awards</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cdcon">cdcon</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/05/20/configure-plugins-with-jcasc/"><div class="header"><div class="date"><div class="month">May</div><div class="day">20</div></div><h5 class="title">Configure Plugins with JCasC</h5></div><p class="teaser">This blog post is for anyone interested to know how to configure a plugin using the Jenkins Configuration as a Code (JCasC) plugin, more specifically, this blog will guide you to get the YAML equivalent of a plugin’s configuration and use it to do some changes to the plugin without using the Jenkins UI.

If you’re a beginner at JCasC and want to learn more about it, you can head over to the following resources to understand JCasC better:

JCasC Documentation

Overview of JCasC (Video Presentation)

Manage JCasC (DevOps World 2018)

Configuring your first plugin using JCasC (Video Demo)

Overview

So, these are the steps we will be following to achieve our aim:

Brief Introduction to jenkins.yaml file

Configure the plugin on the UI

Download the Configuration

Update JCasC file locally

Load the jenkins.yaml file on the Jenkins server

Verify the changes on the UI

Brief Introduction to jenkins.yaml file

The jenkins.yaml file contains the configuration of the Jenkins instance in YAML format.
The JCasC plugin refers to this file to configure the Jenkins instance.

The default location of jenkins.yaml is $JENKINS_HOME/jenkins.yaml, from where it can be fetched into the Jenkins server whenever you apply a new configuration.

Download your jenkins.yaml file by going to Manage Jenkins Configuration as Code Download Configuration.

Make sure this file is saved at location $JENKINS_HOME/jenkins.yaml.

Let’s change the systemMessage field to:

Figure 1. Updating the jenkins.yaml file

Reload the existing configuration to apply the system message change

Now, go back to the Dashboard and you can see the updated System Message on top:

Figure 2. Viewing the changes on Dashboard

This file will be used later to configure the plugin using JCasC.

Configure the plugin on the UI

For this demo, install the View Job Filters plugin.

Let’s create a view by clicking on the New View option on the left side of the Dashboard.

Give it a name (say, “testView”) and set its type to List View, and click on the OK button.

Figure 3. Creating the View

Now click on Add Job Filter to add any kind of filter, so let’s select Build Duration Filter and fill the field with any value (say, &quot;60&quot; minutes),

Figure 4. Adding filter to the view

Click on Apply Save.

To view the full configuration, check out your main jenkins.yaml configuration file, by clicking on Manage Jenkins Configuration as Code View Configuration

Go to the views section in this YAML file to see details related to the view,

Figure 5. Here, details regarding the view (which we just created) is visible

Download the Configuration

Now that you have successfully configured your plugin by UI, let’s download the configuration by going to Manage Jenkins on the Dashboard, then click on Configuration as Code under &quot;System Configuration&quot;.

Now click on the Download Configuration button to save the configuration file locally.

Figure 6. Downloading the Configuration

Update JCasC file locally

Add some changes in your downloaded copy of the jenkins.yaml file, to see those changes being automatically reflected on the UI.

For demo purposes, let’s change the name to “YoutubeDemoView” and set the buildDurationMinutes as &quot;55&quot;.

Figure 7. Changing the View details locally

Save the file.

Load the jenkins.yaml file on the Jenkins server

Now to reflect the local changes done in the jenkins.yaml file onto the Jenkins server, click on the Reload existing configuration button.

Figure 8. Applying the New Configuration to the Jenkins instance

Verify the changes on the UI

Go back to the main page by clicking on the Jenkins logo on the top-left side.

And you will notice that the name of your view has been changed from &quot;testView&quot; to “YoutubeDemoView”,

And the field value of Build Duration Filter has been changed from &quot;60&quot; to “55”.

These two are the exact changes that we did locally in our jenkins.yaml file.

Figure 9. Verifying the changes

Congratulations! You’ve successfully configured a plugin (“View Job Filter”) automatically with the help of the “Jenkins Configuration as Code” plugin! You can repeat the same process for other plugins as well.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/dheerajodha/">Dheeraj Singh Jodha</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jcasc">jcasc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/tutorial">tutorial</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/yaml">yaml</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/06/04/digester-removal/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day"> 4</div></div><h5 class="title">Apache Commons Digester library removal (breaking changes!)</h5></div><p class="teaser">Keeping up with our goal to clean up some of the technical debt inside Jenkins Core and reduce the maintenance overheads, we are happy to report we were able to remove a long-deprecated Apache Commons Digester library.

Jenkins Core does not depend anymore on Apache Commons Digester v.2.1, a version that has been released in 2010.

Some plugins will require update to operate properly after the Jenkins core upgrade.
See JEP-231 for the full list of the affected plugins.
Below there is the list of plugins that did not have their fix released at the time of writing.
They will start to break with the weekly on the 7th of June, expected to be the 2.297.

teamconcert

vs-code-metrics

BlameSubversion

javatest-report

vss

synergy

config-rotator

harvest

cmvc

In addition to these still-served plugins, a few others will break.
Note however that these were already suspended [ 1 ] for various reasons, so we do recommend to move away from using them or step up as maintainers.
The IDs for these plugins are: tfs, svn-release-mgr, cpptest, cflint, script-scm, rtc.

It is always a good idea to update all your plugins before upgrading Jenkins core.

Please reach out on the developers’ list with any questions or suggestions.

Getting fixes in the affected plugins

For all affected plugins we have submitted pull requests with compatibility patches.
These plugins seem to have no active maintainer, and hence we cannot commit on delivering those fixes.
In mean time you can build a custom patch locally to resolve the issue on your instances.
If you use any of those plugins, consider stepping up and adopting them so that the fixes could be released.
We will appreciate any contributions!

Resources

PR-5320

removing commons-digester:2.1.
This also contains a complete list of impacted plugins and their PRs and statuses.

JEP-231

describing this change.

1. this means these plugins are not served anymore by the Jenkins Project’s hosting service. Even if they were released, the releases would not show up until additional issues are fixed.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/batmat/">Baptiste Mathus</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/core">core</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/developer">developer</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/06/10/jenkins-is-the-way-ebook-2/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">10</div></div><h5 class="title">New eBook: Jenkins is the Way for IT and software developers</h5></div><p class="teaser">A little over a year ago, we launched JenkinsIsTheWay.io, a website whose sole purpose is to share Jenkins user stories with the developers and engineers in our community.  Over a hundred of you have already shared your innovations, and they just keep coming.  It comes as no surprise that many of the submitted stories are from IT consultants and software developers around the world building next-generation DevOps and CI/CD platforms to fuel the modernization of enterprise companies far and wide.

That’s why we’ve dedicated our latest eBook to focus on Jenkins users in the global Information Technology sector.  We shine the spotlight on these developers and engineers who have solved unique software development and DevOps challenges by turning to the leading open source automation server.  From powering large enterprises needing a better way to manage their inventory to innovative tech firms looking to advance technologies and healthcare initiatives during a pandemic, you’ll read about how teams everywhere solved their unique challenges — with the help of Jenkins.

Jenkins is the Way to…

In our short User Story Survey, we ask Jenkins users to fill in the blank: Jenkins is the way to …​…​

We’ve seen results-oriented submissions like &quot;Jenkins is the way to deliver our new releases on time!&quot; and &quot;Jenkins is the way to understand and simplify your software workflows.&quot;  Several submissions riffed off of something like &quot;Jenkins is the way to completely automate your CI/CD workflow.&quot;  Meanwhile, others have had a bit more fun and languished praise on Jenkins, stating, &quot;Jenkins is the way to help teams focus on what is really important, make our life easier&quot; and, even, &quot;Jenkins is the way to save the day.&quot;

In this new eBook, we focus on the challenges users in the community face, and what they’ve built using Jenkins to achieve their unique goals. For example, Build &amp; Release Manager, Donald Morton, turned to Jenkins to establish a flexible, modern, and more efficient DevOps platform for Graylog, a leading log management platform serving the enterprise.

With a Jenkins assist, Mark Baumann, DevOps Engineer with ITK Engineering, created “ one CI to rule them all.” He told us that “Jenkins provides a common CI/CD platform for all different kinds of projects and technology domains.”

When IBM Lead Software Engineer Alec Rieger sought to simplify the build and testing pipeline for the company’s software engineers and developers, he also turned to Jenkins.  For a company the size of IBM, which services enterprise clients worldwide, Rieger wanted to help his colleagues manage many nodes on a large scale. Now, according to his Jenkins Is The Way user story, IBM uses Jenkins pipelines for each of their builds and relies on the flexibility and countless plugin features to continually improve their processes.

Stronger, Smarter, Faster Software Innovation

While we all fondly think of Jenkins as a modest butler who has empowered developers with the open-source tools they need to succeed — on JenkinsIsTheWay.io, we liken him to an unpretentious, yet powerful superhero.  And like any great superhero, he (or she!) is sure to save the day.

For our Jenkins users, that means results — significant, measurable results with a common theme.  Using Jenkins has enabled you — the user — to help the businesses you serve save money, spin up software faster, and automate processes.  In doing so, you’ve freed up developers and engineers from countless hours of mundane tasks.  Thanks to Jenkins, you’re empowering entire IT teams to innovate, focus on what they love to do and, ultimately, build great stuff.

Of course, we devote much of our latest eBook to those victories.  Results like how RedHat’s releases are 5x faster thanks to Jenkins.  The fact that DevOps problem tickets were reduced by over 90% for Electronic Health Solutions.  And why the CTO at Cloudologia was psyched to share that — with a Jenkins at the helm — they were able to shorten onboarding for deployment &amp; build release cycles from one week to a single day.

Share Your User Story, Too!

I am proud to share another common theme from the users who have submitted their story:  you turn to our community for collaboration, guidance, and advice.  A community of a million strong and growing, this eBook and JenkinsIsTheWay.io are other ways to provide you with the insight and lessons learned by developers and engineers, like you, to innovate and build next-generation technologies for companies of all sizes.

When you’re ready to tell your story, we’re prepared to help you share it. Fill out our short questionnaire, and we’ll send you our Jenkins Is The Way T-shirt as a thank you once it’s published!

Links

Jenkins IsThe Way. IT User Story eBook, chapter 2

Jenkins IsThe Way. IT User Story eBook, chapter 1

Visit Jenkins Is The Way

Share Your User Story

Special thanks to CloudBees, Inc. for sponsoring this program.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-is-the-way">jenkins-is-the-way</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/case-study">case-study</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ebook">ebook</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/06/17/libera-chat/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">17</div></div><h5 class="title">Jenkins IRC moves to Libera Chat</h5></div><p class="teaser">We are happy to announce that
the Jenkins community has moved all its official IRC channels to Libera chat.
We have started our migration on May 26 as a response to the
hostile takeover
of hundreds of open source community channel by the new Freenode management.
As decided  by the Jenkins governance meeting on June 16th,
Libera Chat IRC channels are the only official channels going forward.

A more detailed history of the transition is available on the Jenkins developers mailing list.

What did we move?

We have created the following IRC chats:

that currently live on freenode to libera.chat:

#jenkins - general discussion channel for Jenkins users and developers.
We no longer consider it a central chat for all things Jenkins, but we intend to keep it available to users
who want to keep using IRC.

#jenkins-hosting - Chat used by the Hosting Team to manage hosting automation

#jenkins-infra - Chat used by the Infrastructure Team to coordinate efforts related to Jenkins project infrastructure and the incident response

#jenkins-release - Chat used for Jenkins core release coordination by the Release Team

All other channels have NOT been moved to Libera Chat IRC and were replaced by other channels.
Most notable channels:

#jenkins-meeting - the Jenkins Governance Meeting uses combination of Zoom and Google Docs at the moment. We do not longer use the IRC chat for that purpose.

#jenkins-cert - no private chat going forward. The Security Team will use mailing lists only going forward

#jenkins-community - Replaced by the Advocacy&amp;Outreach Gitter channel.

Freenode concerns and disclaimers

Going forward, the Jenkins community does not have ANY official channels on Freenode.
All channels are either removed or left abandoned.
We no longer manage or control our channels.
Most of the Jenkins IRC channel operators use IRCCloud,
and hence they were banned by the Freenode team on June 11th.
Only a few operators have reconnected since this event.

Taking the takeover of Freenode and hostile actions taken by the new management,
we can no longer guarantee any of the following:

Authenticity of registered users on Freenode.
All IRC accounts, cloaked or not, might have been taken over by the new Freenode management.
 Do not trust messages from the Jenkins contributor account IDs there.

Confidentiality of private channels like #jenkins-cert.
We performed audit of the conversations there, and we believe there are no undisclosed security vulnerabilities referenced in the channel.
 After all, this IRC has been rather dormant for the last 18 months.

IRC User Passwords.
All passwords on Freenode IRC may be compromised in the future.
We strongly advise all users to rotate their passwords if they were used on Freenode IRC.

We have made backups of IRC channel conversations in the abandoned channels.
If you need to access the conversation history, please reach out to the Jenkins Infrastructure team.

Acknowledgements

We thank the entire Libera Chat team and all contributors who have worked on creating
a Freenode replacement for hundreds of open source communities using IRC.
Within just a month, a new platform has been created and adopted by almost all active projects.
We remember the Hudson to Jenkins renaming days when a similar mobilization happened in the Jenkins community,
and we appreciate all the effort put by contributors.

Special thanks to Tim Jacomb, Gavin Mogan, Alex Earl, and Olivier Vernin for their work on the migration of IRC channels
and our automation like the IRC Bot used by the Jenkins hosting team.

What’s next?

In the Jenkins community we will keep using Libera Chat IRC and maintaining user and contributor channels there.
Other Jenkins chat channels like Gitter and Slack are unchanged.
We intend to gradually replace many of those channels with community.jenkins.io.
This is a new portal powered by Discourse.
The service is sponsored by Civilized Discourse Construction Kit, Inc..
It is currently in preview, stay tuned for announcements.
As always, we will appreciate any suggestions and [feedback]( https://community.jenkins.io/c/site-feedback/2)!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/oleg_nenashev/">Oleg Nenashev</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/chat">chat</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/06/21/student-luminy-project-security/"><div class="header"><div class="date"><div class="month">Jun</div><div class="day">21</div></div><h5 class="title">Four students and their master project in Jenkins security</h5></div><p class="teaser">Context

Jenkins is a CI/CD solution and as such, it is critical that the open source plugins that constitute an integral part of it don’t expose the systems they are used on to any security risks and vulnerabilities.
It is in that context that we worked as an audit/code review team to track and report such flaws and problematic practices.

We worked in collaboration with Jenkins Security team member Wadeck Follonier, as part of an end-of-study project during our last year of the Master’s Degree - Reliability and IT Security in the university of Aix-Marseille.

Project Goals

The main goal of this project was to allow us to discover and work on diverse security vulnerabilities in the context of a widely-used software solution, and in order to achieve that we had to separate the project in multiple other goals:

Learning about some of the most common vulnerabilities and the form in which they can be found on a Jenkins Instance and its plugins.

Performing code review and technical audit on the application, and compiling our results as part of a security team.

Reporting our findings to the Jenkins team and the plugin maintainers, while sometimes helping the latter to correct these vulnerabilities.

Knowledge Sharing

At the beginning of the project, we set up communication channels with our mentor through Slack and Google Meets, and agreed to schedule weekly sessions with him.
The goal of these sessions was both to teach us more about the functionalities of Jenkins and the types of vulnerabilities we would encounter, and to allow us to ask more specific questions regarding our findings.

Thanks to our mentor developing a mock plugin compiling a variety of classic vulnerabilities and several of their implementations, including server side request forgery ( SSRF), cross site scripting ( XSS), and XML external entity ( XXE) attacks, we have been able to learn through practice.
It allowed us to analyze the context of the code and the different ways the Jelly framework can be used to display information, expanding our payload options and giving us a clearer view of the patterns to look for during our code reviews.

We have also had the opportunity to learn about the process used to report the vulnerabilities to the maintainers through Jira issues, and some ways we could correct them or provide steps to do so.

Searching and compiling

At first, we decided to work as a pretty loose team, with each member working on a different plugin and regrouping our findings to confirm or reject them, while staying in constant contact to ask each other questions.
This allowed us to broaden the scope of our searches, and is the reason why we have been able to find a larger number of vulnerabilities, in plugins that differed widely in popularity, than we would have working together from the start.

We used a single file to compile the plugins we audited and our findings, making it easier for our mentor to review them and give us feedback.
Pinpointing the specific portion of code causing the issue and providing reproduction steps as clear as we could proved useful for the reporting process, thus making the approval and correction faster.

During the last third of this project, we began to work together on bigger plugins, in order to have more points of view reflecting on the same problem.
With different analyses, we were able to come up with new payloads, and sometimes with new vulnerabilities where we only found one separately.

Reporting and correcting the vulnerabilities

All of the reporting was done through Jira issues, which allows the Jenkins team to centralize and triage the vulnerabilities.
Once we provided the necessary information, along with the reproduction steps we had, a member of the Jenkins security team contacted the plugin maintainer and guided them through the next steps of the process, with hope that they would answer.

We have also tried to make the maintainers&#x27; job easier, working on some fixes.
To achieve this, we delved not only into the functionalities of the vulnerable plugins, but also into some mitigation processes that we found either in the Jenkins documentation,  or with the help of our mentor.

Each one of our modifications has been tested locally, in order to assess whether the vulnerability was still present, and whether no function had been altered.
However, some of the plugins we audited demanded more complex fixes, due to their intrinsic logic, or the thought process of their developer, which led to us being unable to provide a clear fix.

Considering this, the fixes we have been able to bring into light were only suggestions to the maintainers, for them to use as inspiration or template, in order not to interfere with the plugin logic.

Conclusion

Through this project, we have been able to work as a team, delving into some of the different issues that security engineers are bound to face, and the ways they have at their disposal to mitigate them.
This has allowed us to complement our studies with a more practical aspect, that we couldn’t have had otherwise, and to transition into the companies we are now interns in.
This experience has strongly encouraged us to improve in and document ourselves on this branch of cybersecurity, which will have a significant impact on our professional future.

Useful links

Jenkins - 2021/03/30 Security Advisory - 5 from us

Jenkins - 2021/05/11 Security Advisory - 4 from us

Jenkins - 2021/05/25 Security Advisory - 3 from us

Jenkins - 2021/06/16 Security Advisory - 1 from us

Jenkins - 2021/06/18 Security Advisory - 1 from us

Message from the mentor

I didn’t expect to have four students with a so deep desire to learn new things, new tricks.
Their curiosity helped them to find numerous vulnerabilities that already led to 14 published CVEs.
The experience was great and I wish them all the best for their professional career and their never ending quest for knowledge.

If you are student, intern, or just someone really interested in security and Jenkins in particularly, please reach out to us to see if there is a possibility to organize something together.
Mailing list: jenkinsci-cert@googlegroups.com<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/jphilip/">Justin Philip</a>, <a href="/gatsby-jenkins-io/blog/authors/kguerroudj/">Kevin Guerroudj</a>, <a href="/gatsby-jenkins-io/blog/authors/qparra/">Quentin Parra</a>, <a href="/gatsby-jenkins-io/blog/authors/mheyries/">Marc Heyries</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/07/16/gsoc-midterm-presentation/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">16</div></div><h5 class="title">GSoC CDF Meetup: Google Summer of Code Midterm Demos</h5></div><p class="teaser">Congratulations to all GSoC students who have made it through the first half of the GSoC 2021 coding phase!

This year, the Jenkins project has been participating in GSoC as part of the Continuous Delivery Foundation’s GSoC org.
To celebrate our GSoC students and the fantastic work they have been doing, the CDF is hosting an online meetup where students will present their work.
Students will be showcasing what they have learned and accomplished thus far in GSoC, demoing their work, and discussing their goals and plans for the second coding phase.

The CDF Google Summer of Code Midterm Demos will be held online on July 20th, 13:00 UTC - 15:00 UTC.

Sign up here: Meetup Event

Speakers

Akihiro Kiuchi - Jenkins Remoting Monitoring

Akihiro is a student in the Department of information and communication engineering at the University of Tokyo.
He is improving the monitoring experience of Jenkins Remoting during Google Summer of Code 2021.

Affiliation: The University of Tokyo and Jenkins project

GitHub: Aki-7

Title: Jenkins Remoting Monitoring with OpenTelemetry

In this talk, he will discuss the problems in maintaining Jenkins agents and how to support Jenkins admins in troubleshooting them.
As one of the solutions, he will introduce the new Remoting monitoring with OpenTelemetry plugin that collects Jenkins Remoting monitoring data and troubleshooting data using OpenTelemetry.
What kind of data the plugin will collect and how we will be able to visualize them using available open-source monitoring tools will be demonstrated.

Shruti Chaturvedi - CloudEvents Plugin for Jenkins

Shruti is an undergrad student of Computer Science at Kalamazoo College.
She is developing a CloudEvents integration for Jenkins, allowing other CloudEvents-compliant CI/CD tools to communicate easily.
Shruti is also the Founding Engineer of a California-based startup, MeetKlara, where she is building serverless solutions and advocating for developing CI/CD pipelines using open-source tools.

Affiliation: Kalamazoo College and Jenkins project

GitHub: ShrutiC-git

LinkedIn: Shruti Chaturvedi

Title: CloudEvents Plugin for Jenkins: Moving Towards Interoperability

In this talk, we will look at interoperability as an essential element in building workloads across several services.
We will also talk about how CloudEvents solves one of the biggest challenges in achieving interoperability between systems: lack of normalization/standardization.
Without any standard definition, in order to achieve interoperability, services have to develop adapters specific to a particular system.
That, however, is complex because services are always changing the way data/events are emitted.
CloudEvents solves this problem by defining a standard format for events, which can be emitted/consumed agnostically, thereby achieving indirect interoperability.
Shruti will demonstrate the workings of CloudEvents Plugin for Jenkins; she will walk us through how Jenkins can be configured as a source and a sink, emitting and consuming CloudEvents-compliant events in a platform-independent manner.

Daniel Ko - try.spinnaker.io

Daniel is studying computer science at the University of Wisconsin - Madison.
He is developing a public Spinnaker sandbox environment for Google Summer of Code 2021.

Affiliation: University of Wisconsin - Madison and Spinnaker project

GitHub: ko28

Title: try.spinnaker.io:  Explore Spinnaker in a Sandbox Environment!

The talk will go through a brief explanation of Spinnaker and the challenges that users face during the installation process.
He will discuss the infrastructure of this project and how a public multi tenant spinnaker instance will be managed and installed.
We will end with a demo of the site so far and the various features implemented, including Github authentication, K8s manifest deployment, AWS Load Balancer Controller to expose deployments, private ECR registry and the blocking of all public images, and auto resource cleanup.

Aditya Srivastava - Conventional Commits Plugin for Jenkins

Aditya is a curiosity driven individual striving to find ingenious solutions to real-world problems.
He is an open-source enthusiast and a lifelong learner.
Aditya is also the Co-Founder and Maintainer of an Open Source Organization - Auto-DL, where he’s leading the development of a Deep Learning Platform as a Service application.

Affiliation: V.E.S.I.T &amp; Jenkins project

GitHub: ADI10HERO

LinkedIn: Aditya S.

Title: Conventional Commits Plugin for Jenkins

In this talk, we’ll start with what are conventional commits and why they are needed.
Then we’ll see what the jenkins plugin, &quot;Conventional Commits&quot; is and what goal it is trying to achieve.
A demo of how the plugin can be used/integrated in the current workflow will be shown.
Finally, we’ll talk about the next steps in plugin development followed by the QnA.

Harshit Chopra - Git credentials binding for sh, bat, and powershell

Harshit Chopra is a recent graduate and is currently working on a Jenkins project which brings the authentication support for cli git commands in a pipeline job and freestyle project.

Affiliation: Punjab University &amp; Jenkins Project

GitHub: link: arpoch

LinkedIn: Harshit Chopra

Website

Title: Git credentials binding for sh, bat, and powershell

In this talk, he will give an overview of the project and will move on further explaining what problems are being faced, a bit about the workaround that are being used to tackle the problems,
what makes the authentication support so important, why a feature and not a plugin in itself, accomplishments achieved and work done during the coding phase 1, will talk about the implementation of the feature, demonstration of git authentication support over HTTP protocol.

Pulkit Sharma - Security Validator for Jenkins Kubernetes Operator

Pulkit is a student at Indian Institute of Technology,BHU,Varanasi.
He is working on a GSoC Project under Jenkins where he aims to add a security validator to the Jenkins Kubernetes Operator.

Affiliation: Indian Institute of Technology, BHU and Jenkins Project.

GitHub: sharmapulkit04

Title: Security Validator for Jenkins Kubernetes Operator

In this talk, we will discuss why we need a security validator for the Jenkins Kubernetes Operator and how we are going to implement it via admission webhooks.
We will have a look at how we are going to implement the validation webhook, the validation logic being used and what tools we are using to achieve it.
Pulkit will showcase his progress and will discuss his future plans for phase 2 and beyond as well.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/marckk/">Kara de la Marck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/07/27/git-credentials-binding-phase-1/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">27</div></div><h5 class="title">Git username / password credentials binding</h5></div><p class="teaser">Google Summer of Code 2021 is implementing git credentials binding for sh, bat, and powershell .
Git credentials binding is one of the most requested features for Jenkins Pipeline (see jira:JENKINS-28335[]).

The project involves extending the Credentials Binding Plugin to create custom bindings for two types of credentials essential to establish a remote connection with a git repository

Username/Password

SSH Private Key

Why use git credentials binding?

Many operations in a Jenkins Pipeline or Freestyle job can benefit from authenticated access to git repositories.
Authenticated access to a git repository allows a Jenkins job to

apply a tag and push the tag

merge a commit and push the merge

update submodules from private repositories

retrieve large files with git LFS

The git credentials username / password binding included in git plugin 4.8.0 allows Pipeline and Freestyle jobs to use command line git from sh, bat, and powershell for authenticated access to git repositories.

How to use git credentials binding?

The binding is accessible using the withCredentials Pipeline step.
It requires two parameters:

credentialsId

Reference id provided by creating a Username/Password type credential in the Jenkins configuration. To understand how to configure credentials in a Jenkins environment: Using Credentials

gitToolName

Name of the git installation in the machine running the Jenkins instance
(Check Global Tool Configuration section in Jenkins UI)

Note: In case a user is not aware of the git tool installation of the particular machine, the default git installation will be chosen.

Examples

The withCredentials wrapper allows declarative and scripted Pipeline jobs to perform authenticated command line git operations with sh , bat , and powershell tasks.

Shell example

withCredentials([gitUsernamePassword(credentialsId: &#x27;my-credentials-id&#x27;, gitToolName: &#x27;git-tool&#x27;)]) {
  sh &#x27;git fetch --all&#x27;
}

Batch example

withCredentials([gitUsernamePassword(credentialsId: &#x27;my-credentials-id&#x27;, gitToolName: &#x27;git-tool&#x27;)]) {
  bat &#x27;git submodule update --init --recursive&#x27;
}

Powershell example

withCredentials([gitUsernamePassword(credentialsId: &#x27;my-credentials-id&#x27;, gitToolName: &#x27;git-tool&#x27;)]) {
  powershell &#x27;git push&#x27;
}

The Pipeline Syntax Snippet Generator is a good way to explore the syntax of the withCredentials step and the git username / password credentials binding.

Limitations

The git credentials username / password binding has been tested on command line git versions 1.8.3 through 2.32.0.
It has been tested on CentOS 7, CentOS 8, Debian 9, Debian 10, FreeBSD 12, OpenBSD 6.9, openSUSE 15.2, Ubuntu 18.04, Ubuntu 20.04, Ubuntu 21.04, and Windows 10.
Processor testing has included amd64, arm32, arm64, and s390x.

The binding does not support private key credentials.
The binding is not supported on command line git versions prior to 1.8.3.

What’s next?

Private key credentials support is coming soon.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/rishabhbudhouliya/">Rishabh Budhouliya</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/git">git</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/07/30/introducing-conventional-commits-plugin-for-jenkins/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">30</div></div><h5 class="title">Introducing the Conventional Commits Plugin for Jenkins</h5></div><p class="teaser">The conventional commits plugin is a Google Summer of Code project.
Special thanks to the mentors Gareth Evans, Kristin Whetstone, Olivier Vernin and Allan Burdajewicz.

What are Conventional Commits

According to the official website, conventonal commits are, &quot;A specification for adding human and machine readable meaning to commit messages.&quot;

Conventional commits are a lightweight convention on top of commit messages.

The following table shows major structural elements offered by the conventional commits convention.

Structural Element
Example

Chore
chore: improve logging

Fix
fix: minor bug fix

Feat
feat: add a new feature

Breaking Change
BREAKING CHANGE: reimplement

Why Conventional Commits

As the CI/CD world is moving more towards complete automation and minimal human interaction, the ability to fully automate a release is desired.
Conventional Commits enable the use of automated systems on top of commit messages.
These systems can &quot;truly&quot; automate a release with almost no human interaction.

The convention dovetails with semantic versioning.
Let’s take an example, a maven project is currently versioned at 1.2.0.
The following table shows how conventional commits would bump the version depending on the type of the commit.

Commit Message
Version Bump
SemVer Equivalent

chore: improve logging
1.2.0 → 1.2.0
No version bump

fix: minor bug fix
1.2.0 → 1.2.1
Increment in the patch version

feat: add a new feature
1.2.0 → 1.3.0
Increment in the minor version

BREAKING CHANGE: reimplement
1.2.0 → 2.0.0
Increment in the major version

The Conventional Commits Plugin

The conventional commits plugin is a Jenkins plugin to programatically determine the next semantic version of a git repository using:

Last tagged version

Commit message log

Current version of the project

How it works?

The plugin will read the commit messages from the latest tag or the current version of the project till the latest commit.
Using this information it will determine what would be the next semantic Version for that particular project.

Supported Project Types?

Currently the plugin can read the current version from various configuration files of the following project types:

Project Type
Configuration File(s) Read

Maven
pom.xml

Gradle
build.gradle

Make
Makefile

Python
setup.py
setup.cfg
pyproject.toml

Helm
Charts.yml

Node (NPM)
package.json

How to request a project type support?

Please feel free to open an issue on the GitHub repository of the plugin.

How to use the plugin

Recommended way of using the plugin is to add a step in a Jenkins Pipeline Project.

nextVersion() is the pipeline step to be used.

For example:

pipeline {
    agent any

    environment {
        NEXT_VERSION = nextVersion()
    }

    stages {
        stage(&#x27;Hello&#x27;) {
            steps {
                echo &quot;next version = ${NEXT_VERSION}&quot;
            }
        }
    }
}

Tip: The pipeline step can also be generated with the help of the Snippet Generator.
Please select &quot;nextVersion&quot; in the Sample Step drop down and then click on &quot;Generate Pipeline Snippet&quot;

The plugin is released on every feature using JEP-229.

The plugin is available to download from the plugins site.

Demo

You can watch the plugin in action in a demo presented at the GSoC Midterm Presentations

Next Steps

Support for pre-release information. Example: 1.0.0-alpha, 1.0.0-beta, etc

Support for build metadata. Example: 1.0.0-beta+exp.sha.5114f85

Optionally writing the calcuated &quot;Next Version&quot; into the project’s configuration file. Example: pom.xml for a maven project, setup.py for python.

Feedback

We would love to hear your feedback &amp; suggestions for the plugin.

Please reach out on the plugin’s GitHub repository, the Gitter channel or start a discussion on community.jenkins.io.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/adi10hero/">Aditya Srivastava</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/conventionalcommits">conventionalcommits</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/07/31/remoting-monitoring-phase-1/"><div class="header"><div class="date"><div class="month">Jul</div><div class="day">31</div></div><h5 class="title">Remoting Monitoring with OpenTelemetry - Coding Phase 1</h5></div><p class="teaser">Goal

The goal of this project:

collect telemetry data(metrics, traces, logs) of remoting module with
OpenTelemetry.

send the telemetry data to OpenTelemetry Protocol endpoint

Which OpenTelemetry endpoint to use and how to visualize the data are up to
users.

OpenTelemetry

An observability framework for cloud-native software

OpenTelemetry is a collection of tools, APIs, and SDKs.
You can use it to instrument, generate, collect, and export telemetry
data(metrics, logs, and traces) for analysis in order to understand your
software’s performance and behavior.

Phase 1 summary

User survey

Our team conducted a user survey to understand the pain point regarding Jenkins
remoting.

Fig 1. What agent type/plugins do you use?

Fig 1 shows what types of agent users use, and 17 unique respondents out of
28 use docker for agent. So I’m planning to publish a docker image to
demonstrate how we can build Docker image with our monitoring feature.

This survey and investigation of JIRA tickets of past two years also tell me five
common causes of agent unavailability.

Configuration mistakes

Jenkins agent settings, e.g. misuse of &quot;tunnel connection through&quot; option.

Platform settings, e.g. invalid port setting of Kubernetes&#x27; helm template.

Network settings, e.g. Load balancer misconfiguration.

Uncontrolled shutdown of nodes for downscaling.

Timeout during provisioning a new node.

Firewall, antivirus software or other network component kill the connection

Lack of hardware resources, e.g. memory, temp space, etc…​

We also heard valuable user voice in the survey.

What areas would you like to see better in Jenkins monitoring?

I have created a bunch of adhoc monitoring jobs to check on the agent’s health
and send e-mail. Would be nice to have this consolidated.

Having archive of nodes with the access to their logs/events would have been
nice.

I hope that implementing these feature with OpenTelemetry, which is expected to
become the industry standard for observability, will bring great monitoring
experience to Jenkins community.

Proof of Concept

How to deliver the monitoring program to agents

1. Sending monitoring program to the agent over remoting

In my first implementation, I prepared a Jenkins plugin and send the
monitoring program from Jenkins controller. However, this approach have
following disadvantages.

We cannot collect telemetry data before the initial connection.
We are likely to encounter a problem while provisioning a new node,
so it’s important to observe agents&#x27; telemetry data from the beginning.

Some agent restarters (e.g. UnixSlaveRestarter)
restart agent completely when reconnecting. It means that the agent lost
monitoring program every time the connection closed, and we cannot collect
telemetry data after the connection is lost before a new connection is
established.

So we decided to take the next approach.

2. Install monitoring engine when provisioning a new agent

In this approach, user will download the monitoring program called monitoring
engine, which is a JAR file, and place it in the agent node when provisioning.

How to instrument remoting to produce remoting trace

Add instrumentation extension point to remoting

Pull Request: https://github.com/jenkinsci/remoting/pull/471

This approach makes the agent launch command more complicated,
and we have to overcome this problem.

Current State

Metrics

We currently support the following metrics and planning to support more.

metrics
unit
label
key
description

system.cpu.load
1

System CPU load. See com.sun.management.OperatingSystemMXBean.getSystemCpuLoad

system.cpu.load.average.1m

System CPU load average 1 minute See java.lang.management.OperatingSystemMXBean.getSystemLoadAverage

system.memory.usage
bytes
state
used, free
see com.sun.management.OperatingSystemMXBean.getTotalPhysicalMemorySize
and com.sun.management.OperatingSystemMXBean.getFreePhysicalMemorySize

system.memory.utilization
1

System memory utilization,
see com.sun.management.OperatingSystemMXBean.getTotalPhysicalMemorySize
and com.sun.management.OperatingSystemMXBean.getFreePhysicalMemorySize.
Report 0% if no physical memory is discovered by the JVM.

system.paging.usage
bytes
state
used, free
see com.sun.management.OperatingSystemMXBean.getFreeSwapSpaceSize
and com.sun.management.OperatingSystemMXBean.getTotalSwapSpaceSize.

system.paging.utilization
1

see com.sun.management.OperatingSystemMXBean.getFreeSwapSpaceSize
and com.sun.management.OperatingSystemMXBean.getTotalSwapSpaceSize.
Report 0% if no swap memory is discovered by the JVM.

process.cpu.load
%

Process CPU load. See com.sun.management.OperatingSystemMXBean.getProcessCpuLoad.

process.cpu.time
ns

Process CPU time. See com.sun.management.OperatingSystemMXBean.getProcessCpuTime.

runtime.jvm.memory.area
bytes
type
used, committed, max
see MemoryUsage

area
heap, non_heap

runtime.jvm.memory.pool
bytes
type
used, committed, max
see MemoryUsage

pool
PS Eden Space, G1 Old Gen…​

runtime.jvm.gc.time
ms
gc
G1 Young Generation, G1 Old Generation, …​
see GarbageCollectorMXBean

runtime.jvm.gc.count
1
gc
G1 Young Generation, G1 Old Generation, …​
see GarbageCollectorMXBean

Traces

We tried several approaches to instrument remoting module, but good approach is not established yet.

Here is a draft documentation of the spans to collect. Google Doc

Logs

Coming soon!

Metric and span demo visualization

Our team created a demo example with Docker compose and visualized the metrics and spans.

Click to open in new tab

Google Summer of Code Midterm Demo

Our project demo starts with 8:20

Next Step

Log support

Alpha release!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/aki-7/">Akihiro Kiuchi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/remoting">remoting</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/open-telemetry">open-telemetry</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/08/02/cloudevents-plugin-phase-I/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day"> 2</div></div><h5 class="title">CloudEvents Plugin for Jenkins: Interoperability between Jenkins and other CI/CD Tools</h5></div><p class="teaser">The What, Why and How of Interoperability

With workloads and teams becoming more diverse and complex, there is an increasing need to automate various tasks in the CI/CD ecosystem of an application as a way to decrease complexity that can come with CI/CD.

A more diverse team working across different aspects of the application requires a diverse suite of CI/CD tools too, to test and deliver to a wide range of users. More often than not, we need these tools to work together and exchange data to form an effective CI/CD pipeline. However, chaining multiple services together can very easily increase complexity.

How? Each of these services use a different &quot;language&quot; to communicate and represent the entity(an event) which occured inside that service. In order for another service to understand this &quot;language&quot;, the service might need to develop customized clients and agents which specialize in understanding, traversing and taking-actions based on what was transmitted to it by the first service.

One can think of it as a translator who specializes in a language called ABC, and each service who wants to communicate with the service who uses ABC will have to employ this translator, or perhaps get another trained translator. And there is no guarantee that this translator will also help communicate with other services speaking a completely different language.

We can see how easily that can grow in cost and maintenance. A preferred way is to have a common language each of these services use and understand as a way to communicate amongst each other. This way, an event which is emitted using this common language will be available to any of the interested receiver without that receiver needing a special agent. This way of communication which uses a common/standard language also creates a way for agnostic communication where the sender or the receiver are sending and receiving data without creating a tight coupling between the two.

CloudEvents specification is enabling that loosely-coupled, event-driven communication between services by enforcing a common language which defines how an event should be emitted and transferred between systems.

CloudEvents and Jenkins

A specification for describing event data in a common way

Consistency

Consistent across tools and services.

Accessibility

Common event format means common libraries, tooling, and infrastructure for delivering event data across environments can be used to develop with CloudEvents.

Portability

Easily port event-data across tools, truly leveraging event-driven architecture.

The CloudEvents plugin for Jenkins is developed as an effort to make interoperability between Jenkins and CI/CD tools much easier. The CloudEvents plugin for Jenkins is a GSoC project, and with the help from an amazing team of mentors, this project is aimed at enhancing event-driven interoperability between cloud-native CI/CD tools, making it easier for developers to include Jenkins in their CI/CD pipelines.

With this plugin, Jenkins can send and receive CloudEvents-compliant events to and from a wide variety of CI/CD tools using CloudEvents as their event format. This plugin makes chaining Jenkins with multiple tools like Tekton, Keptn, Knative and more, very easy.

GSoC Phase 1 - CloudEvents Plugin

Using CloudEvents plugin for Jenkins

This plugin allows Jenkins to be configured as a source and sink, which can emit and consume CloudEvents from a range of tools simultaneously.

Jenkins as a Source

Configuring Jenkins as a Source enables Jenkins to send CloudEvents to a CloudEvents sink. For Phase-I of this project, there is support for HTTP Sinks, however CloudEvents supports various protocol bindings. Moving forward, there will also be support for other protocol bindings supported by CloudEvents.

To use Jenkins as a Source, the following configuration is needed:

Click on Manage Jenkins in the Root-Actions menu on the left.

Inside the Manage Jenkins UI, search for Configure System under System Configuration.

In the Configure System UI, scroll down to the CloudEvents plugin section, and this is where all the plugin configuration will be present. Here, you will have to enter the following information:

Sink Type (For now, HTTP Protocol Binding for CloudEvent and HTTP Sink is supported.)

Sink URL (URL of the Sink where you want the cloudevents sent.)

Events you want sent to the CloudEvents sink URL.

Step 1: Manage Jenkins

Step 2: Configure System

Step 3: Configure CloudEvents Sink

With Jenkins as a Source configured, Jenkins will send a POST request to the configured sink right as the selected event occurs inside Jenkins. Each event has a different payload specific to the type of the event emitted.

Event Types, Payload and Metadata

CloudEvents emitted by Jenkins follow the Binary-structure supported by CloudEvents, where the CloudEvents metadata is present inside the header, and the event-data is serialized as JSON, and present under request-body. This is the HTTP Protocol Binding for CloudEvents. Each protocol binding for CloudEvents follows a definition specific to the binding protocol.

For now, the following Jenkins events are supported in the CloudEvents Plugin-Jenkins as a Source:

Queue Events

Queue Entered Waiting

Queue Left

Build Events

Job Started

Job Completed

Job Finalized

Job Failed

Job Events

Job Created

Job Updated

Node Events

Node Online

Node Offline

Following is a table of the queue-entered waiting cloudevents metadata:

Event Metadata Headers Key
Event Metadata Headers Value

ce-specversion
1.0

ce-type
org.jenkinsci.queue.entered_waiting

ce-source
job/test

ce-id
123-456-789

All of these fields will be present inside the HTTP-request headers since the CloudEvents format used here is the Binary structure.

Here’s also an example of event payload for the queue-entered event:

{
  &quot;ciUrl&quot;: &quot;http://3.101.116.80/&quot;,
  &quot;displayName&quot;: &quot;test2&quot;,
  &quot;entryTime&quot;: 1626611053609,
  &quot;exitTime&quot;: null,
  &quot;startedBy&quot;: &quot;shruti chaturvedi&quot;,
  &quot;jenkinsQueueId&quot;: 25,
  &quot;status&quot;: &quot;ENTERED_WAITING&quot;,
  &quot;duration&quot;: 0,
  &quot;queueCauses&quot;: [
    {
    &quot;reasonForWaiting&quot;: &quot;In the quiet period. Expires in 0 ms&quot;,
    &quot;type&quot;: &quot;entered_waiting&quot;
    }
  ]
}

Try the Plugin

The plugin will soon be releasing as the CloudEvents Plugin under https://plugins.jenkins.io/!!

Here’s the GitHub Repo of the Plugin: CloudEvents Plugin GitHub Repo

Demo

Here is a video of the CloudEvents plugin with SockEye demoed at CDF GSoC Midterm Demos. SockEye is an open-source tool which is designed as a way to visulaize cloudevents which are sent from a sink. In this demo, we will take a look at how Jenkins installed in a multi-node K8s environment work with the CloudEvents plugin as a Source, sending events over HTTP to the SockEye sink.

Next Steps

Jenkins as a Sink to allow Jenkins to trigger various actions as cloudevents are received from other tools.

Enabling filtering on CloudEvents metadata to only act upon a certain kind of events recieved.

Support for other protocol bindings in CloudEvents.

Feedback

We would absolutely love to hear your suggestions and feedback. This will help us understand the various use-cases for the plugin, and iterate to support a variety of bindings and formats.

Feel free to log an issue at the CloudEvents Plugin GitHub repository. We are on CDF slack under gsoc-2021-jenkins-cloudevents-plugin. You can also start a discussion on community.jenkins.io. I also love emails! Drop me one on: shrutichaturvedi16.sc@gmail.com<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/shrutic-git/">Shruti Chaturvedi</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloudevents">cloudevents</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/interoperability">interoperability</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cloud-native">cloud-native</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/08/17/docker-images-use-jdk-11-by-default/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">17</div></div><h5 class="title">Docker images use Java 11 by default</h5></div><p class="teaser">The Jenkins project provides Docker images for controllers, inbound agents, outbound agents, and more.
Beginning with Jenkins 2.307 released August 17, 2021 and Jenkins 2.303.1 released August 25, 2021, the Docker images provided by the Jenkins project will use Java 11 instead of Java 8.

Controllers use Java 11 by default

If you are running one of the Jenkins Docker controller images that does not include a JDK version in its label, the Java runtime will switch from Java 8 to Java 11 with the upgrade.

For example:

Jenkins 2.306 running as jenkins/jenkins:latest uses Java 8.
When Jenkins 2.307 or later is run with jenkins/jenkins:latest, it will use Java 11

Jenkins 2.289.3 running as jenkins/jenkins:lts uses Java 8.
When Jenkins 2.303.1 or later is run with jenkins/jenkins:lts, it will use Java 11

The Docker image tags affected by this upgrade include:

alpine

centos7

latest

lts

slim

Users that need to remain with Java 8 may use a different Docker image tag to run with Java 8.

Jenkins 2.306 running as jenkins/jenkins:latest uses Java 8.
When Jenkins 2.307 or later is run with jenkins/jenkins:latest-jdk8, it will use Java 8

Jenkins 2.289.3 running as jenkins/jenkins:lts uses Java 8.
When Jenkins 2.303.1 or later is run with jenkins/jenkins:lts-jdk8, it will use Java 8

Agents use Java 11 by default

During the next 1-2 weeks (Aug 17, 2021 - Aug 31, 2021), the Jenkins agent images will be updated to use Java 11 instead of Java 8.

For example:

Running a Jenkins agent from Docker image jenkins/jenkins-inbound-agents:4.9-1 uses Java 8.
When running a Jenkins agent from Docker image jenkins/jenkins-inbound-agents:4.10-1 it will use Java 11.

Running a Jenkins agent from Docker image jenkins/jenkins-inbound-agents:latest uses Java 8.
When running a Jenkins agent from Docker image jenkins/jenkins-inbound-agents:latest after the agent change, it will use Java 11.

Users that need to remain with Java 8 may use a different Docker image tag to run with Java 8.

Running a Jenkins agent from Docker image jenkins/jenkins-inbound-agents:4.9-1 uses Java 8.
When running a Jenkins agent from Docker image jenkins/jenkins-inbound-agents:4.10-1-jdk8 it will also use Java 8.

Docker tag updates stopped

The Jenkins project will no longer update the Docker images that are based on CentOS 8.
The CentOS project has changed direction to track just ahead of a Red Hat Enterprise Linux release rather than tracking after a release.
They are no longer publishing updates for CentOS 8 Docker images.

Users running Jenkins 2.306 or earlier with the jenkins/jenkins:centos tag will need to switch to use a different tag.
They may consider using:

jenkins/jenkins:almalinux

jenkins/jenkins:rhel-ubi8-jdk11

Users running Jenkins 2.289.3 or earlier with the jenkins/jenkins:centos tag will need to switch to use a different tag

They may consider using:

jenkins/jenkins:lts-almalinux

jenkins/jenkins:lts-rhel-ubi8-jdk11

Window 1809 Docker images stopped

The Windows Docker images have published versions based on both the 1809 feature release and the Windows Server long term support channel (&quot;LTSC&quot;).
Windows support for the 1809 images will no longer be published because Microsoft has ended mainstream support for the 1809 images.
Users should switch to use the Jenkins images based on the &quot;LTSC&quot; channel.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/dheerajodha/">Dheeraj Singh Jodha</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/java">java</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/platform">platform</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/docker">docker</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/08/19/git-credentials-binding-work-report/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">19</div></div><h5 class="title">Git Credentials Binding for sh, bat, powershell</h5></div><p class="teaser">Abstract

This project implemented two new credential bindings to perform authenticated operations using command line git in Jenkins pipeline and freestyle jobs.

The two credential bindings are gitSshPrivateKey and gitUsernamePassword.

Implementation

Type

Feature

Location

The gitUsernamePassword binding is implemented in Jenkins git plugin v4.8.0.
The gitSshPrivateKey binding is implemented in a pull request to the Jenkins git plugin

Dependencies

Credentials Binding Plugin -
It is used to bind Git specific environment variables with shell scripts/commands which perform git authentication on behalf of the user, without their interaction with the command-line.

Bouncy Castle API Plugin -
Provides an API to do common tasks like PEM/PKCS#8 Encoding/Decoding and ensuring its stability among Bouncy Castle API versions.

SSH Server Plugin -
Provides an API to perform tasks like OpenSSH private key encoding and decoding.

Phase 1: Git Username Password Binding (gitUsernamePassword)

Deliverables

Support git authentication over the HTTP protocol

Use the GIT_ASKPASS environment variable to provide user credentials to command line git

Support different

OS environments : CentOS 7, CentOS 8, Debian 9, Debian 10, FreeBSD 12, OpenBSD 6.9, openSUSE 15.2, Ubuntu 18.04, Ubuntu 20.04, Ubuntu 21.04, and Windows 10.

Processors : amd64, arm32, arm64, and s390x.

Authentication support for command line git only, not JGit or JGit Apache.

Check for specific git versions

Setting git specific environment variables based on OS type

Automated test coverage more than 90%

Resources

Pull Requests

Add Git Credentials binding for Username and Password

Check the least command line git version required

Git username password binding doc update in git-plugin

gitUsernamePassword binding explanation

Webinar slides

Git username password binding released blog post

Phase 1 demo and presentation:

Phase 2: Git SSH Private Key Binding (gitSshPrivateKey)

Deliverables

To support git authentication over the SSH protocol

Supports:

Private Key Formats

OpenSSH

PEM

PKCS#8

Encryption algorithms

RSA

DSA

ECDSA

ED25519

OS environments : CentOS 7, CentOS 8, Debian 9, Debian 10, FreeBSD 12, OpenBSD 6.9, openSUSE 15.3, Ubuntu 18.04, Ubuntu 20.04, Ubuntu 21.04, and Windows 10.

Processors : amd64, arm32, arm64, and s390x.

Authentication support for command line git only, not JGit or JGit Apache.

Use git specific environment variables depending upon the minimum git version

GIT_SSH_COMMAND - If the version is greater than 2.3, provides ssh command including the necessary options.

SSH_ASKPASS - If the version is less than 2.3, an executable script is attached to the variable.

Setting variables based on the OS type

Resources

Pull Requests

Add Git Credentials binding for SSH Private Key

Last GSOC-2021 noted commit

Scope change of getSSHExecutable method

gitSshPrivateKey binding explanation

Webinar Slides

Final phase demo and presentation

Achievements

The git credential bindings which are available through the git plugin automate the git authentication process for a user effortlessly

The gitUsernamePassword and gitSshPrivateKey binding provides git authentication support for Pipeline and Freestyle Project users in various OS environments on different processors

The gitUsernamePassword binding has been released and is readily available from git plugin v4.8.0 and above

The gitSshPrivateKey binding provides support for OpenSSH format which is default for OpenSSH v7.8 and above

Future Work

SSH private key binding pull request merge and release

Unexpected complications from Jenkins class loader required extra effort and investigation, including an experiment shading a dependency into the git plugin
We intentionally chose to avoid the complication and risk of shading the dependency
If the SSH library use requires shading, then we may need to use maven modules in the git plugin<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/arpoch/">Harshit Chopra</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/git">git</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/08/23/jenkins-operator-security-work-report/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">23</div></div><h5 class="title">Security Validator for Jenkins Operator for Kubernetes</h5></div><p class="teaser">Background

Jenkins custom resources on a Kubernetes cluster are deployed using declarative YAML configuration files; hence some of the plugins declared in these files may contain security warnings.
So there is no way for the user to know other than manually checking for each on the site.
This project aims to add an extra step of validation before creating/updating a new Jenkins Custom Resource.

Deliverables

This project aims to add a validating admission webhook to the Jenkins Operator for Kubernetes to detect potential security vulnerabilities in the plugins before the object is created.

Dependencies

Webhooks communicate to the API server over HTTPS and use TLS. Thus, Jetstack/cert-manager is used to provision TLS certificates and establish connection between Kubernetes API and webhook.

Implementaion

Operator-SDK takes care of creating a new webhook and appending it to the manager and creating handlers.
Tls certificates are managed using cert-manager.

Validation Logic:

Proposed Implementations: Iterate through the list of plugins to be installed and fetch warnings for each plugin from the plugin center API and check if the version of that plugin has any of those warnings.

Caveats: Webhooks add latency to an API request, hence they should evaluate as quickly as possible thus having max allowed timeout of 30s. In the earlier approach I was fetching the security warnings from the plugin site API in the validator interface itself, and since network operations are slow, it was causing a timeout in the case of validating a larger number of plugins or when the Internet connection was not good.

Updated Implementaion: Instead of fetching information for each plugin, the information about all the plugins is downloaded and cached at the start of the operator and updated periodically, thus eliminating network calls and finishing validation in less than a second.

Evaluation Phase 1:

Scaffoled a new validation webhook

Added manifests for ValidatingWebhookConfiguration, certificates and volumes, and updated Makefile

Implemented the validator interface

Updated helm charts

Evaluation Phase 2:

Reimplemented the validator interface.

Added unit tests for internal functions

Added e2e tests along with helm tests

Updated helm charts

Resources

Pull Requests

Added validation webhook,manifests,and updated Makefile

Implemented validation logic,added tests and updated helm charts

Phase 1 demo

User Guide

The webhook feature is completely optional for the user. It can be easily deployed using Helm Chart by setting webhook.enabled in values.yaml and in the Operator command line flag.

webhook.enabled=true

To enable security validation in the jenkins custom resource set

jenkins.ValidateSecurityWarnings=true

Note: The webhook takes some time to get up and running, also when helm renders the template, the validating webhook configuration is applied last, hence if the user wants to deploy the Jenkins Custom Resource with validation turned on, he needs to wait for some time. After the webhook is up and running the user can deploy the Jenkins Custom Resource using helm or kubectl

Future work

Implementing a post-install hook in the helm charts that checks whether the webhook is up and running.

Adding validation for required core version of plugin and core version of Jenkins.

Migrating other validation logic from controller to the webhook.

Adding validation for the dependencies of the plugins.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/sharmapulkit04/">Pulkit Sharma</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc21">gsoc21</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/kubernetes">kubernetes</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugins">plugins</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/08/28/conventional-commits-plugin-project-report/"><div class="header"><div class="date"><div class="month">Aug</div><div class="day">28</div></div><h5 class="title">Work report for the Conventional Commits Plugin for Jenkins</h5></div><p class="teaser">This blog post is part 2 of the Introducing the Conventional Commits Plugin blog.

The goal of this blog is to showcase the work done during the Google Summer of Code 2021 coding phases.

Please refer the part 1 of the blog for a detailed description of the plugin.

Abstract

The project/plugin aims to fully automate a release process.

The plugin tries to achieve this goal by automatically determining the next semantic version based on commit messages.

There were 2 coding phases in the GSoC 2021.
I call the first phase - &quot;Read&quot; and the 2nd phase - &quot;Write&quot;, let’s see why.

Phase 1: Read

In this phase, the &quot;read&quot; aspect of the plugin was enhanced.
The plugin supported multiple project types (Maven, Gradle, NPM, Helm, Python, Make) and was able to read current version information from the configuration files of the supported project types.

Deliverables

Support multiline comments

Support reading the current version from a maven pom.xml

Support reading the current version from a build.gradle

Support reading the current version from a Makefile

Support reading the current version from a package.json

Support reading the current version from a helm Chart.yaml

Resources

List of related issues

Phase 1 Demo and Presentation:

Phase 2: Write

In this phase, some work was done in extending the &quot;write&quot; aspect of the plugin.
A provision (optional parameter) to write back the calculated next semantic version to the configuration files of projects was added to the plugin.
Along with that, the plugin now can append &quot;Pre-Release&quot; and &quot;Build Metadata&quot; information to the calculated semantic version.

Deliverables

Add prerelease information to the calculated/new version

Add build metadata to the calculated/new version

Write next version in pom.xml

Write next version in package.json

Handle version mismatch between config file and latest tag

Resources

Link to related Issues

Using optional parameters in the Conventional Commits Plugin

Phase 2 Presentation

Next Steps

Write back version for Python project.

Write back version for Gradle project.

Handle remote workspaces

Feedback

We would love to hear your feedback &amp; suggestions for the plugin.

Please reach out on the plugin’s GitHub repository, the Gitter channel or start a discussion on community.jenkins.io.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/adi10hero/">Aditya Srivastava</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/conventionalcommits">conventionalcommits</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/plugin">plugin</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/09/04/wiki-attacked/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day"> 4</div></div><h5 class="title">Jenkins project Confluence instance attacked</h5></div><p class="teaser">Earlier this week the Jenkins infrastructure team identified a successful attack against our deprecated Confluence service.
We responded immediately by taking the affected server offline while we investigated the potential impact.
At this time we have no reason to believe that any Jenkins releases, plugins, or source code have been affected.

Thus far in our investigation, we have learned that the Confluence CVE-2021-26084 exploit was used to install what we believe was a Monero miner in the container running the service.
From there an attacker would not be able to access much of our other infrastructure.
Confluence did integrate with our integrated identity system which also powers Jira, Artifactory, and numerous other services.

The trust and security in Jenkins core and plugin releases is our highest priority.
We do not have any indication that developer credentials were exfiltrated during the attack.
At the moment we cannot assert otherwise and are therefore assuming the worst.
We are taking actions to prevent releases at this time until we re-establish a chain of trust with our developer community.
We have reset passwords for all accounts in our integrated identity system.
We are improving the password reset system as part of this effort.

At this time, the Jenkins infrastructure team has permanently disabled the Confluence service, rotated privileged credentials, and taken proactive measures to further reduce the scope of access across our infrastructure.
We are working closely with our colleagues at the Linux Foundation and the Continuous Delivery Foundation to ensure that infrastructure which is not directly managed by the Jenkins project is also scrutinized.

In October 2019 we made the Confluence server read-only effectively deprecating it for day-to-day use within the project.
At that time, we began migrating documentation and changelogs from the wiki to GitHub repositories.
That migration has been ongoing, with hundreds of plugins and many other documentation pages moved from the wiki to GitHub repositories.

We are grateful for those of you who followed our responsible disclosure procedure and reached out to us about this vulnerability affecting the Jenkins project.

We will continue to take proactive measures to improve the security of our infrastructure and encourage you to follow us on Twitter for further updates.<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/markewaite/">Mark Waite</a>, <a href="/gatsby-jenkins-io/blog/authors/rtyler/">R. Tyler Croy</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/infrastructure">infrastructure</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/security">security</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/09/20/election-period-opened/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">20</div></div><h5 class="title">Jenkins Election 2021</h5></div><p class="teaser">Dear all,

Time flies and the Jenkins elections period is here.

This year, two board seats and all officer positions are up for election.
Thanks, Oleg Nenashev and Ullrich Hafner who led the Jenkins project as board members for the last two years.
Thanks, Tim Jacomb, Daniel Beck, Mark Waite for your dedication as officers over the past year.

We already had two successful editions in a row. I want us to continue on that path.
This is a tremendous opportunity for community members to influence the direction of the project for the next two years.
To make this year’s election even better, we slightly modified the process by leveraging our new community platform aka community.jenkins.io.

To participate in the election, we ask every Jenkins community member to have an account on community.jenkins.io.
You can either reuse your Github account or create a new discourse account specific to community.jenkins.io.
The second requirement is to be able to showcase at least one contribution done before the first of September 2021.
As mentioned on jenkins.io.io/participate, they are many different ways to contribute to Jenkins and for many of them, it’s very difficult to measure.
Therefore we’ll trust participants and will not require that they provide evidence of contribution as part of their voter registration. We reserve the right to ban the specific account from the election process if we identify abuse.
The election works in three stages:

Identify voters and nominees

Voting period

Announce results

Voters

To invite participants to vote, we need a list of email’s addresses that we would share with the Condorcet Internet Voting Service.
Therefore we ask every community member who matches the requirements to join the group election-voter on community.jenkins.io.
The group will be open for joining during the registration period after we’ll close registration during the voting period.
We’ll use emails from the “election-voter” group members.

Nominees

During the same period, we invite every community member to nominate candidates by sending a message to the group election-committee mentioning the position and the motivation.
On the 31 of October, the nomination period will end. We’ll notify all the nominees and get confirmation that they are interested in running as a candidate.
The list of candidates will be announced on the 7th of November.

Everybody can nominate candidates.

This year we are looking for nominees for the following positions:

Board members

Documentation Officer

Events Officer

Infrastructure Officer

Release Officer

Security Officer

More information about the different roles can be found on jenkins.io/project/team-leads.

Election

On the 7th of November, once voters and candidates are identified, we’ll invite everybody by email to vote using civs.cs.cornell.edu.
At this stage of the election, nobody will be allowed to register.
Voting deadline is the 30th of November.

Result

As soon as we have the election results, we’ll publish them.
Elected members will begin their official roles on the 3rd of December 2021.

Key Dates

Sep 20: Nomination and voter registration begin

Oct 31: Nomination deadline

Nov 07: Candidates announced, Registration deadline, voting start

Nov 30: Voting deadline

Dec 03: Results announced

Key Information:

Everybody can suggest candidates by sending a private message to the group election-committee.

Voters register for the election by joining the public group election-voter.

Email participants will be shared with Condorcet Voting System to send voting invitations.

Nobody can register for the election once we send invitations to Condorcet Voting System.

Once the election is over, every member of the group&quot;election-voter&quot; will get a badge on https://community.jenkins.io as a “2021 Election Participant”.

Once the election is over, every nominee will get the badge “2021 Election Nominee”.

Cheers,<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/olblak/">Olivier Vernin</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance">governance</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/governance-board">governance-board</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/elections">elections</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/09/21/jenkins-at-devops-world/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">21</div></div><h5 class="title">Join Jenkins at DevOps World 2021</h5></div><p class="teaser">DevOps World has been the largest gathering for Jenkins for many years.
In keeping with tradition, many Jenkins presentations and sessions are planned for this year’s event.

Join us for DevOps World on September 28 - 30, 2021.
The event is virtual, free to attend and will include the following Jenkins activities:

Jenkins workshops

Contributing to Open Source

Securing Jenkins Pipeline with CyberArk Conjur Secrets Manager

See the conference workshop list for more information about workshops.

Breakout sessions

Embracing Observability in Jenkins with OpenTelemetry - Cyrille Le Clerc

Expanding Open Source in Africa with Jenkins - Experience Report - Mark Waite and Zainab Abubakar

Visualizing Git Forensics Data in a Jenkins Plugin - Ullrich Hafner

Speeding up Jenkins and Maven with a Build Cache - Justin Reock

Auto Versioning at Scale with Jenkins and Ontrack - Taming the Hydra - Damien Coraboeuf

Build up a Reliable Jenkins on KubeSphere - Rick Zhao

Automate Jenkins operations on Kubernetes : Jenkins Automation Operator - Vibhav Bobade and Jawed Khelil

Running JenkinsFileRunner as a Service - Jose Taboada

From Big and Slow to Small and Agile: Splitting Monolithic Jenkins Controllers for Increased Performance - Dylan Dewhurst

See the full agenda for more Jenkins sessions.

Birds of a feather

These are 30 minute networking sessions.
Topics will be on security and pipeline.
Discussions are led by Wadeck Follonier, Daniel Beck, Joost van der Griendt, and Mark Waite.

Jenkins contributor summit

A Jenkins Contributor Summit will be held October 2, 2021 at 7:00 AM UTC.

The planning discussion is taking place at community.jenkins.io.
We welcome topic suggestions or you can volunteer to present a topic about which you are passionate.
Join in on the discussion.
New and veteran contributors are welcome!

Virtual expo hall

Be sure to stop by the Jenkins booth for project update content or to chat with one of the Jenkins maintainers.

Special thanks to review committee

Lastly, special THANKS to the DevOps World review committee.
We are grateful for their contributions to review, score and provide feedback for paper submissions.

Alex Earl

Viktor Farcic

Victor Martinez

Carlos Sanchez

Looking forward to seeing you there!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/conference">conference</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/cicd">cicd</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/talks">talks</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/workshops">workshops</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/09/22/fortune-500-real-world-results/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">22</div></div><h5 class="title">New eBook: Fortune 500 Developers and Engineers Turn to Jenkins for Real-World Results</h5></div><p class="teaser">If you’ve been following JenkinsIsTheWay.io, you’ve read some fantastic stories from the Jenkins user community about the great stuff they are building with Jenkins.
With over 200,000 installations to date, Jenkins remains the most widely used open-source automation server.
And story after story, we hear what a critical role Jenkins plays in building robust, secure CI/CD pipelines.

So it comes as no surprise that in many of the back (and remote) offices of Fortune 500 companies, developers are turning to Jenkins to help make their lives easier with automation while also giving their engineers more time to innovate.
With this in mind, I invite you to read the latest ebook focused on the behind-the-scenes development activities underway in large-scale enterprises.

Jenkins led

Learn how companies like IBM continue to innovate their software prowess while confidently relying on their custom-built CI/CD pipelines.
You’ll also read how Jenkins became the ultimate collaboration tool for thousands of Apple developers.
And we don’t just shine the spotlight on tech companies.
In this ebook, Jenkins users span multiple industries across the enterprise.

You’ll read how Jenkins made it possible to standardize multidisciplinary team procedures so Roche engineers can create innovative healthcare applications with confidence.
We also dive into how Telstra’s software team was able to automate the build cycle - across 100,000 microservices - to accelerate the creation of world-class communication tools.
And how Sainsbury’s development team used Jenkins as the way to &quot;bring a retail giant into the 21st century&quot;.

Results inspired

No time to dive into this Fortune 500 ebook?
I thought it’s worth highlighting the real-world results experienced by enterprise developers and engineers who have turned to awesome plugins to help build, deploy and automate their software solutions.
Here’s what they had to say in their own words!

Software acceleration

Build times are much faster with the new node mechanism

Shared build pipelines are consistent and evolve faster

Faster deployment times - from 5 days to several minutes

Deploy multiple server patches 30x faster than normal processes

Reduce release time from 7 to 4 days

Simpler, smarter processes

One-stop-shop for building, deploying, monitoring, testing and even self-managing

Easy onboarding for new applications

Credential management has gotten much simpler and stricter

Made setting up CI/CD really easy

Provides the visibility needed to track the deployment process

Loved and relied on by developers

Ultimate collaboration tool for thousands of developers

100% confidence in a consistent and repeatable pipeline

Keeps the DevOps team in the loop

Jenkins-as-code has freed teams up to experiment more

Teams are more self-empowered to provision and support their own builds

One thing to remember is that since Jenkins is a free open source solution, it also means savings across the enterprise.
This is highlighted in several of our user stories in this ebook.
You’ll discover how peers have &quot;decreased build server costs&quot; and have mentioned &quot;cost-cutting&quot; as a top Jenkins benefit.

Share your story

Whether working for a large corporation or an emerging tech startup, we relish hearing your experiences and the results you get with a Jenkins assist.
When you’re ready to tell your story, we’re prepared to help you share it.
Fill out our short questionnaire, and we’ll send you our Jenkins Is The Way T-shirt as a thank you once it’s published!

Links

Download Fortune 500 User Story eBook

Visit JenkinsIsTheWay

Share your story<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/alyssat/">Alyssa Tong</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins-is-the-way">jenkins-is-the-way</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/case-study">case-study</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/ebook">ebook</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/announcement">announcement</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/09/23/jenkins-health-advisor-by-cloudbees/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">23</div></div><h5 class="title">Jenkins Health Advisor by CloudBees Tool Makes Life Easier for Jenkins Administrators</h5></div><p class="teaser">There are many ways to set up your Jenkins environment, and depending on the configuration you choose, there are different best practices and options to optimize your environment.
In this blog, I’m going to focus on Jenkins Health Advisor by CloudBees as a way to fine-tune your environment.
It’s a free tool that can help administrators understand and manage their Jenkins controller.
If you’re a CloudBees customer, the tool automatically comes with CloudBees CI.
However, it’s also available as a free open source tool to anyone who uses Jenkins.
The Jenkins Health Advisor tool can make your life easier, because it can arm you with the information you need to keep your Jenkins environment running smoothly.

A Bit of Background

The CloudBees support team originally created the tool as a way to help customers troubleshoot Jenkins issues.
With the tool, our support engineers could gather information from a customer’s Jenkins controller about the configuration of the controller and agents, the operating system, stats from web requests, and the like.
Our tech support teams used this data to help customers pinpoint problems, such as security vulnerabilities, performance problems, and plugin version issues.
Very quickly, our support tooling team saw the bigger-picture benefits of the diagnostic tool as an opportunity for people to proactively manage their controller.
With that bit of background, let’s dive into the Jenkins Health Advisor tool so you understand how it can help you.

The Problem — Lack of Visibility into Controller Environment

Because of the open-source nature of Jenkins and the vast array of plugins that you can deploy in your Jenkins installation, downstream code changes to plugins and corresponding dependencies can inadvertently impact your environment, which slows productivity, causes confusion, and impacts the quality of your software delivery.
When problems arise, Jenkins administrators need to quickly pinpoint the root cause of an issue, and that can be quite a challenge.

The Solution — Jenkins Health Advisor by CloudBees

When an issue arises, you need razor sharp insight to help you quickly sift through lines upon lines of data about your Jenkins controller and your plugins to identify the problem.
And, that’s exactly what Jenkins Health Advisor does.
It gives you specific information about potential problems in your environment so you can resolve issues as quickly as possible.

When you first install the Jenkins Health Advisor tool in your environment, you’ll receive a report that lists everything it detects in your system.
You’ll then receive report emails only when something changes that could impact your environment or when the tool identifies an issue that could be problematic.
If there are no issues in your environment, you don’t receive an email.
It’s really that simple.

The Power is in the Insight … and the CloudBees Support

Ok, so let’s explain how Jenkins Health Advisor uses data to help you optimize your environment.
The tool actually generates a support bundle every 24 hours.
We don’t want to bog down your email inbox with redundant reports emails, so we don’t send every report to you—only the reports that indicate an issue with your environment.
However, CloudBees receives every support bundle from every user.
We are constantly monitoring all of this active Jenkins controller data with external Jenkins and open source data about known issues, plugin updates, security vulnerabilities, etc.
If the Jenkins Health Advisor tool identifies an issue that could impact your system, you’ll receive an email so you can proactively address the problem.
At the same time, CloudBees engineering teams are continually working to enhance the detection capabilities of the Jenkins Health Advisor tool, so you can work as proactively as possible to manage your environment.

The emails you receive identify potential problems, and they also include supporting information to help you resolve issues, with links to solutions and recommended resolutions as well as articles to understand the problem.

Helpful Tips to Gain Value from Jenkins Health Advisor

Improve Troubleshooting

If you need to troubleshoot a particular issue, you can manually generate a support bundle to give you point-in-time information on your environment.
You can filter the support bundle data on different system parameters, like the build queue, dump agent export tables, and garbage collection logs, so you get the specific information you need.

Generate Anonymized System Data

At any time, you can change the settings on your tool to anonymize the data in your support bundles.
You may want to do this if you don’t want to share sensitive project data with CloudBees.
Our support and engineering teams can still gain valuable insight from your generic system data.
This is also a helpful feature if you need to share system data with a partner or vendor, and you don’t want to share project or personnel data.

Jenkins Health Advisor Tool Updates and Support

As we mentioned above, the CloudBees support tooling team is constantly working to enhance the tool.
To ensure it’s always as current as possible, we release updates to the tool every two weeks.
Usually these updates won’t impact your Jenkins environment.
However, if there are changes to the tool that might affect your system, you’ll receive a notification email so there are no surprises.
And, if you need help with the Jenkins Health Advisor tool, our support engineers are available to answer your questions.

Start Using Jenkins Health Advisor Today

Given the vast Jenkins community, it’s impossible to know everything that may impact your environment, even if you look at your control panel every day and scour open source forums on a regular basis to stay on top of new issues and vulnerabilities.
The Jenkins Health Advisor tool is designed to streamline the work effort of your daily routine by automatically telling you when there’s an issue that may impact your Jenkins environment.
With the proactive Jenkins Health Advisor notifications, you can spend your time on more strategic tasks.

Install the plugin and enroll your controller with Jenkins Health Advisor today!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/aheritier/">Arnaud Héritier</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/health">health</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/healthcheck">healthcheck</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/stability">stability</a></li></ul></div></li><li class="post"><a class="body" href="/gatsby-jenkins-io/blog/2021/09/24/gsoc-report/"><div class="header"><div class="date"><div class="month">Sept</div><div class="day">24</div></div><h5 class="title">Congratulations to all Jenkins and CDF Google Summer of Code 2021 participants!</h5></div><p class="teaser">Congratulations to all Google Summer of Code (GSoC) 2021 students!
On behalf of the Jenkins org team, we would like to thank all participants: students, mentors, applicants, and dozens of other contributors who participated in GSoC this year.

In 2021, the Jenkins project participated in GSoC as part of the Continuous Delivery Foundation’s GSoC mentor organisation.
Within the CDF GSoC mentor organisation, we had six students working on projects: five projects focused on Jenkins
and one project focused on Spinnaker.
In GSoC, we focus on projects that solve problems important to end users and community members.
This year’s GSoC projects delivered highly anticipated new features for Jenkins and Spinnaker.

Google Summer of Code has been a successful and positive experience for students due to the active participation of the Jenkins community and the wider Continuous Delivery Foundation community.

🎉 All of the CDF GSoC students have successfully completed their projects! 🎉

This is the second year in a row that all Jenkins GSoC students have reached the final evaluation and successfully passed!
This has been an extremely challenging year, and the amount of work and dedication that the students and their mentoring teams
have put into GSoC has been phenomenal.
Jenkins, Spinnaker, and the CDF are incredibly grateful to everyone who has contributed to GSoC 2021!

☀️ GSoC Students and their Projects

Please see the individual project pages for more details on the projects and work undertaken.
You can view student presentations during mid-term demos and final demos
and students have written numerous blog posts about their work.

Shruti Chaturvedi - CloudEvents Plugin for Jenkins

Shruti is an undergrad student of Computer Science at Kalamazoo College.
She is developing a CloudEvents integration for Jenkins, allowing other CloudEvents-compliant CI/CD tools to communicate easily.
Shruti is also the Founding Engineer of a California-based startup, MeetKlara, where she is building serverless solutions and advocating for developing CI/CD pipelines using open-source tools.

Affiliation: Kalamazoo College and Jenkins project

GitHub: ShrutiC-git

LinkedIn: Shruti Chaturvedi

CloudEvents Plugin for Jenkins

Project page

Completed project blog post: Jenkins Interoperability with CloudEvents

Mid-term blog: CloudEvents Plugin for Jenkins: Interoperability between Jenkins and other CI/CD Tools

Final demo

Mid-term demo

Harshit Chopra - Git credentials binding for sh, bat, and powershell

Harshit Chopra is a recent graduate and is currently working on a Jenkins project which brings the authentication support for cli git commands in a pipeline job and freestyle project.

Affiliation: Punjab University &amp; Jenkins Project

GitHub: link: arpoch

LinkedIn: Harshit Chopra

Website

Git credentials binding for sh, bat, and powershell

Project page

Mid-term blog: Git Credentials Binding for sh, bat, powershell

Final demo

Mid-term demo

Akihiro Kiuchi - Jenkins Remoting Monitoring

Akihiro is a student in the Department of information and communication engineering at the University of Tokyo.
He is improving the monitoring experience of Jenkins Remoting during Google Summer of Code 2021.

Affiliation: The University of Tokyo and Jenkins project

GitHub: Aki-7

Jenkins Remoting Monitoring with OpenTelemetry

Project page

Mid-term blog: Remoting Monitoring with OpenTelemetry

Final demo

Mid-term demo

Daniel Ko - try.spinnaker.io

Daniel is studying computer science at the University of Wisconsin - Madison.
He is developing a public Spinnaker sandbox environment for Google Summer of Code 2021.

Affiliation: University of Wisconsin - Madison and Spinnaker project

GitHub: ko28

LinkedIn: Daniel Ko

try.spinnaker.io:  Explore Spinnaker in a Sandbox Environment!

Project page

Completed project blog post: Interview with Daniel Ko — Google Summer of Code 2021

Final demo

Mid-term demo

Pulkit Sharma - Security Validator for Jenkins Kubernetes Operator

Pulkit is a student at Indian Institute of Technology,BHU,Varanasi.
He is working on a GSoC Project under Jenkins where he aims to add a security validator to the Jenkins Kubernetes Operator.

Affiliation: Indian Institute of Technology, BHU and Jenkins Project.

GitHub: sharmapulkit04

Security Validator for Jenkins Kubernetes Operator

Project page

Completed project blog post: Security Validator for Jenkins Operator for Kubernetes

Final demo

Mid-term demo

Aditya Srivastava - Conventional Commits Plugin for Jenkins

Aditya is a curiosity driven individual striving to find ingenious solutions to real-world problems.
He is an open-source enthusiast and a lifelong learner.
Aditya is also the Co-Founder and Maintainer of an Open Source Organization - Auto-DL, where he’s leading the development of a Deep Learning Platform as a Service application.

Affiliation: V.E.S.I.T &amp; Jenkins project

GitHub: ADI10HERO

LinkedIn: Aditya S.

Conventional Commits Plugin for Jenkins

Project page

Completed project blog post: Work report for the Conventional Commits Plugin for Jenkins

Mid-term blog: Introducing the Conventional Commits Plugin for Jenkins

Final demo

Mid-term demo

Upcoming Events, September 28-30: DevOps World!

This year CloudBees, one of the Jenkins corporate sponsors, has invited all students to participate in the DevOps World virtual conference on September 28-30.
GSoC students will present lighting talks about their projects, attended other conference talks, and join the Continuous Delivery Foundation booth which represents CDF projects at the conference.
We look forward to GSoC students&#x27; lightning talks during DevOps World!

Swag

All Google Summer of Code students and mentors receive swag from Google.
In addition, this year, CloudBees has sponsored swag for the most active GSoC participants:
all students, mentors, and many other contributors who participated and helped the projects to succeed.
This is the forth year when the Jenkins organization sends extra GSoC swag.
In the previous years swag logistics was one of the more challenging tasks for org admins during GSoC,
and we highly appreciate that the Continuous Delivery Foundation will handle sending out the additional swag.

Thanks you Google Open Source, Continuous Delivery Foundation (CDF) and CloudBees!<span class="more"></span></p></a><div class="attrs"><a href="/gatsby-jenkins-io/blog/authors/marckk/">Kara de la Marck</a><ul class="list-inline tags"><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc">gsoc</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/gsoc2021">gsoc2021</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/jenkins">jenkins</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/community">community</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/events">events</a></li><li><a class="tag-link" href="/gatsby-jenkins-io/node/tags/jenkins/mentor">mentor</a></li></ul></div></li></ul></div></div></div></div><script src="https://www.jenkins.io/assets/bower/anchor-js/anchor.min.js"></script><script src="https://www.jenkins.io/assets/bower/tether/js/tether.min.js"></script><script src="https://www.jenkins.io/assets/bower/bootstrap/js/bootstrap.min.js"></script><footer id="footer"><div class="container"><div class="row"><div class="col-md-4"><div class="license-box"><div id="creativecommons"><a href="https://creativecommons.org/licenses/by-sa/4.0/"><p><img alt="Creative Commons Attribution-ShareAlike license" src="https://licensebuttons.net/l/by-sa/4.0/88x31.png"/></p></a><p>The content driving this site is licensed under the Creative Commons Attribution-ShareAlike 4.0 license.</p></div></div></div><div class="links col-md-8"><div class="container"><div class="row"><div class="area col-md-3"><div class="div-mar"><h5>Resources</h5><ul class="resources"><li><a href="https://www.jenkins.io/download/">Downloads</a></li><li><a href="https://www.jenkins.io/node/">Blog</a></li><li><a href="https://www.jenkins.io/doc/">Documentation</a></li><li><a href="https://plugins.jenkins.io/">Plugins</a></li><li><a href="https://www.jenkins.io/security/">Security</a></li><li><a href="https://www.jenkins.io/participate/">Contributing</a></li></ul></div></div><div class="area col-md-3"><div class="div-mar"><h5>Project</h5><ul class="project"><li><a href="https://www.jenkins.io/project/">Structure and governance</a></li><li><a href="https://issues.jenkins.io">Issue tracker</a></li><li><a href="https://www.jenkins.io/project/roadmap/">Roadmap</a></li><li><a href="https://github.com/jenkinsci">GitHub</a></li><li><a href="https://ci.jenkins.io">Jenkins on Jenkins</a></li></ul></div></div><div class="area col-md-3"><div class="div-mar"><h5>Community</h5><ul class="community"><li><a href="https://www.jenkins.io/events/">Events</a></li><li><a href="https://www.jenkins.io/mailing-lists/">Mailing lists</a></li><li><a href="https://www.jenkins.io/chat/">Chats</a></li><li><a href="https://www.jenkins.io/sigs/">Special Interest Groups</a></li><li><a href="https://twitter.com/jenkinsci">Twitter</a></li><li><a href="https://reddit.com/r/jenkinsci">Reddit</a></li></ul></div></div><div class="area col-md-3"><div class="div-mar"><h5>Other</h5><ul class="other"><li><a href="https://www.jenkins.io/conduct/">Code of Conduct</a></li><li><a href="https://www.jenkins.io/press/">Press information</a></li><li><a href="https://www.jenkins.io/merchandise/">Merchandise</a></li><li><a href="https://www.jenkins.io/artwork/">Artwork</a></li><li><a href="https://www.jenkins.io/awards/">Awards</a></li></ul></div></div></div></div></div></div></div></footer><script>
  $(function(){
    var $body = $(document.body);
    $(".nav-link.dropdown-toggle").on("mousedown", function(){
      $body.addClass("no-outline");
    })
    $body.on("keydown", function(){
      $body.removeClass("no-outline");
    })
  })
</script></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-ea100fe6f02bbc648246.js"],"app":["/app-78a498257c1e7f31ccf8.js"],"component---src-pages-404-js":["/component---src-pages-404-js-47ac51e928948b38608d.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-31fe540eab0531bb5744.js"],"component---src-pages-index-js":["/component---src-pages-index-js-1a97f429813fea6561af.js"],"component---src-pages-page-2-js":["/component---src-pages-page-2-js-74b0880e66be9d8858e3.js"],"component---src-pages-using-typescript-tsx":["/component---src-pages-using-typescript-tsx-c165de62207de7fb5221.js"],"component---src-templates-post-js":["/component---src-templates-post-js-0c119c5f31bd1397e53d.js"]};/*]]>*/</script><script src="/gatsby-jenkins-io/polyfill-ea100fe6f02bbc648246.js" nomodule=""></script><script src="/gatsby-jenkins-io/component---src-pages-blog-js-31fe540eab0531bb5744.js" async=""></script><script src="/gatsby-jenkins-io/commons-e65a75583f121ad6113a.js" async=""></script><script src="/gatsby-jenkins-io/app-78a498257c1e7f31ccf8.js" async=""></script><script src="/gatsby-jenkins-io/framework-094b0089736b8f621f0d.js" async=""></script><script src="/gatsby-jenkins-io/webpack-runtime-b42e528980e987374b2f.js" async=""></script></body></html>