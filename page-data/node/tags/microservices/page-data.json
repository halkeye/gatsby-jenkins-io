{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/microservices",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-10-02T00:00:00.000Z","id":"3c59e404-8125-5869-a3c8-98dd83976f14","slug":"/blog/2017/10/02/pipeline-templates-with-shared-libraries/","strippedHtml":"This is a guest post by Philip Stroh, Software Architect at\nTimoCom.\n\nWhen building multiple microservices - e.g. with Spring Boot - the integration\nand delivery pipelines of your services will most likely be very similar.\nSurely, you don’t want to copy-and-paste Pipeline code from one Jenkinsfile\nto another if you develop a new service or if there are adaptions in your\ndelivery process. Instead you would like to define something like a pipeline\n\"template\" that can be applied easily to all of your services.\n\nThe requirement for a common pipeline that can be used in multiple projects does not only emerge in microservice architectures. It’s valid for all areas where applications are\nbuilt on a similar technology stack or deployed in a standardized way (e.g. pre-packages as containers).\n\nIn this blog post I’d like to outline the possibility to create such a pipeline \"template\" using Jenkins Shared Libraries. If\nyou’re not yet familiar with Shared Libraries I’d recommend having a look at\nthe documentation.\n\nThe following code shows a (simplified) integration and delivery Pipeline for a\nSpring Boot application in declarative syntax.\n\nJenkinsFile\n\npipeline {\n    agent any\n    environment {\n        branch = 'master'\n        scmUrl = 'ssh://git@myScmServer.com/repos/myRepo.git'\n        serverPort = '8080'\n        developmentServer = 'dev-myproject.mycompany.com'\n        stagingServer = 'staging-myproject.mycompany.com'\n        productionServer = 'production-myproject.mycompany.com'\n    }\n    stages {\n        stage('checkout git') {\n            steps {\n                git branch: branch, credentialsId: 'GitCredentials', url: scmUrl\n            }\n        }\n\n        stage('build') {\n            steps {\n                sh 'mvn clean package -DskipTests=true'\n            }\n        }\n\n        stage ('test') {\n            steps {\n                parallel (\n                    \"unit tests\": { sh 'mvn test' },\n                    \"integration tests\": { sh 'mvn integration-test' }\n                )\n            }\n        }\n\n        stage('deploy development'){\n            steps {\n                deploy(developmentServer, serverPort)\n            }\n        }\n\n        stage('deploy staging'){\n            steps {\n                deploy(stagingServer, serverPort)\n            }\n        }\n\n        stage('deploy production'){\n            steps {\n                deploy(productionServer, serverPort)\n            }\n        }\n    }\n    post {\n        failure {\n            mail to: 'team@example.com', subject: 'Pipeline failed', body: \"${env.BUILD_URL}\"\n        }\n    }\n}\n\nThis Pipeline builds the application, runs unit as well as integration tests and deploys the application to\nseveral environments. It uses a global variable \"deploy\" that is provided within a Shared Library. The deploy method\ncopies the JAR-File to a remote server and starts the application. Through the handy REST endpoints of Spring Boot\nActuator a previous version of the application is stopped beforehand. Afterwards the deployment is verified via the\nhealth status monitor of the application.\n\nvars/deploy.groovy\n\ndef call(def server, def port) {\n    httpRequest httpMode: 'POST', url: \"http://${server}:${port}/shutdown\", validResponseCodes: '200,408'\n    sshagent(['RemoteCredentials']) {\n        sh \"scp target/*.jar root@${server}:/opt/jenkins-demo.jar\"\n        sh \"ssh root@${server} nohup java -Dserver.port=${port} -jar /opt/jenkins-demo.jar &\"\n    }\n    retry (3) {\n        sleep 5\n        httpRequest url:\"http://${server}:${port}/health\", validResponseCodes: '200', validResponseContent: '\"status\":\"UP\"'\n    }\n}\n\nThe common approach to reuse pipeline code is to put methods like \"deploy\" into\na Shared Library. If we now start developing the next application of the same\nfashion we can use this method for deployments as well. But often there are\neven more similarities within projects of one company. E.g. applications are\nbuilt, tested and deployed in the same way into the same environments\n(development, staging and production). In this case it is possible to define\nthe whole Pipeline as a global variable within a Shared Library. The next code\nsnippet defines a Pipeline \"template\" for all of our Spring Boot applications.\n\nvars/myDeliveryPipeline.groovy\n\ndef call(Map pipelineParams) {\n\n    pipeline {\n        agent any\n        stages {\n            stage('checkout git') {\n                steps {\n                    git branch: pipelineParams.branch, credentialsId: 'GitCredentials', url: pipelineParams.scmUrl\n                }\n            }\n\n            stage('build') {\n                steps {\n                    sh 'mvn clean package -DskipTests=true'\n                }\n            }\n\n            stage ('test') {\n                steps {\n                    parallel (\n                        \"unit tests\": { sh 'mvn test' },\n                        \"integration tests\": { sh 'mvn integration-test' }\n                    )\n                }\n            }\n\n            stage('deploy developmentServer'){\n                steps {\n                    deploy(pipelineParams.developmentServer, pipelineParams.serverPort)\n                }\n            }\n\n            stage('deploy staging'){\n                steps {\n                    deploy(pipelineParams.stagingServer, pipelineParams.serverPort)\n                }\n            }\n\n            stage('deploy production'){\n                steps {\n                    deploy(pipelineParams.productionServer, pipelineParams.serverPort)\n                }\n            }\n        }\n        post {\n            failure {\n                mail to: pipelineParams.email, subject: 'Pipeline failed', body: \"${env.BUILD_URL}\"\n            }\n        }\n    }\n}\n\nNow we can setup the Pipeline of one of our applications with the following method call:\n\nJenkinsfile\n\nmyDeliveryPipeline(branch: 'master', scmUrl: 'ssh://git@myScmServer.com/repos/myRepo.git',\n                   email: 'team@example.com', serverPort: '8080',\n                   developmentServer: 'dev-myproject.mycompany.com',\n                   stagingServer: 'staging-myproject.mycompany.com',\n                   productionServer: 'production-myproject.mycompany.com')\n\nThe Shared library documentation mentions the ability to encapsulate\nsimilarities between several Pipelines with a global variable. It shows how we\ncan enhance our template approach and build a higher-level DSL step:\n\nvars/myDeliveryPipeline.groovy\n\ndef call(body) {\n    // evaluate the body block, and collect configuration into the object\n    def pipelineParams= [:]\n    body.resolveStrategy = Closure.DELEGATE_FIRST\n    body.delegate = pipelineParams\n    body()\n\n    pipeline {\n        // our complete declarative pipeline can go in here\n        ...\n    }\n}\n\nNow we can even use our own DSL-step to set up the integration and deployment Pipeline of our project:\n\nJenkinsfile\n\nmyDeliveryPipeline {\n    branch = 'master'\n    scmUrl = 'ssh://git@myScmServer.com/repos/myRepo.git'\n    email = 'team@example.com'\n    serverPort = '8080'\n    developmentServer = 'dev-myproject.mycompany.com'\n    stagingServer = 'staging-myproject.mycompany.com'\n    productionServer = 'production-myproject.mycompany.com'\n}\n\nThe blog post showed how a common Pipeline template can be developed using the\nShared Library functionality in Jenkins. The approach allows to create a\nstandard Pipeline that can be reused by applications that are built in a\nsimilar way.\n\nIt works for Declarative and Scripted Pipelines as well. For declarative\npipelines the ability to define a Pipeline block in a Shared Library is\nofficial supported since version 1.2 (see the recent blog post on\nDeclarative Pipeline 1.2).","title":"Share a standard Pipeline across multiple projects with Shared Libraries","tags":["pipeline","declarative","microservices"],"authors":[{"avatar":null,"blog":null,"github":"pstrh","html":"","id":"pstrh","irc":null,"linkedin":null,"name":"Philip Stroh","slug":"blog/author/pstrh","twitter":null}]}}]}},"pageContext":{"tag":"microservices","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}