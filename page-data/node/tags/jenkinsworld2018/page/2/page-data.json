{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/jenkinsworld2018/page/2",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-09-10T00:00:00.000Z","id":"3cfe2a34-ab7c-5a8e-baa2-c46178e12dd1","slug":"/blog/2018/09/10/scaling-network-connections/","strippedHtml":"Oleg Nenashev and I will be speaking at DevOps World | Jenkins World in San Francisco this year about\nScaling Network Connections from the Jenkins Controller.\nOver the years there have been many efforts to analyze, optimize, and fortify the “Remoting channel”\nthat allows a controller to orchestrate agent activity and receive build results.\nTechniques such as tuning the agent launcher can improve service,\nbut qualitative change can only come from fundamentally reworking what gets transmitted and how.\n\nIn March, jira:27035[] introduced a framework for inspecting the traffic on a Remoting channel at a high level.\nPreviously, developers could only use generic low-level tools such as Wireshark,\nwhich cannot identify the precise piece of Jenkins code responsible for traffic.\n\nOver the past few months, the\nCloud Native SIG\nhas been making progress in addressing root causes.\nThe\nArtifact Manager on S3 plugin\nhas been released and integrated with Jenkins Evergreen,\nallowing upload and download of large artifacts to happen entirely between the agent and Amazon servers.\nPrototype plugins allow all build log content generated by an agent (such as in sh steps)\nto be streamed directly to external storage services such as AWS CloudWatch Logs.\nWork has also begun on uploading JUnit-format test results, which can sometimes get big,\ndirectly from an agent to database storage.\nAll these efforts can reduce the load on the Jenkins controller and local network\nwithout requiring developers to touch their Pipeline scripts.\n\nOther approaches are on the horizon.\nWhile “one-shot” agents run in fresh VMs or containers greatly improve reproducibility,\nthey suffer from the need to transmit megabytes of Java code for every build,\nso Jenkins features will need to be built to precache most or all of it.\nWork is underway to use Apache Kafka to make channels more robust against network failures.\nMost dramatically, the proposed\nCloud Native Jenkins MVP\nwould eliminate the bottleneck of a single Jenkins controller service handling hundreds of builds.\n\nCome meet Jesse, Oleg, and other Cloud Native SIG members at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Scaling Network Connections from the Jenkins Controller","tags":["jenkinsworld","jenkinsworld2018","cloud-native","performance","scalability","remoting"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-08-30T00:00:00.000Z","id":"76fe30c4-d5ca-529d-af0c-044c46a5a864","slug":"/blog/2018/08/30/speaker-blog-kubernetes-plugin/","strippedHtml":"This is a guest blog by Niklas Tanskanen, consultant at\nEficode.\n\nKubernetes, the container orchestration platform is rapidly becoming popular. There are more and more workloads that you can run on top of Kubernetes. It’s becoming an enabling layer of your Hyper-convergenced infrastructure.\n\nIf you set up Kubernetes as a Cloud provider in Jenkins, you’ll get a very powerful couple for running your workloads.\nTo do that, you can simply install\nKubernetes plugin.\nKubernetes is able to run your Jenkins workloads as long as they are run in container.\nAnd containers are an awesome way if your workload is a build, because you can pack all your application and OS dependencies in a container and then run it anywhere!\n\nLet’s imagine that you have been running a Kubernetes cluster setup in your organisation for a while now.\nFirst it was all about proof of concept but now its becoming more popular within your developers and you have to think about scaling and orchestration.\nResource quotas are a part of that and every responsible operator should set those up both in both development and production clusters.\nOtherwise people will be lazy and just reserve all the resources of your cluster without actually using those resources for anything.\nBy introducing quotas into your cluster, you can control how many resources should each namespace have.\n\nQuotas are a mature feature of Kubernetes already.\nYou have the possibility to create very fine grained quotas for different hardware resources, whenever it’s fast disk, GPUs or CPU time.\nYou can also specify multiple scopes of quota per one namespace.\nFor example, you can have a quota for workloads that are to be run to the infinity like web servers or databases.\nOr have quota for workloads that are short lived like builds or test automation runs.\n\nTable 1. Scopes\n\nScope\nDescription\n\nTerminating\nMatch pods where.spec.activeDeadlineSeconds >= 0\n\nNotTerminating\nMatch pods where.spec.activeDeadlineSeconds is nil\n\nBestEffort\nMatch pods that have best effort quality of service.\n\nNotBestEffort\nMatch pods that do not have best effort quality of service.\n\nDifferent scopes of Kubernetes quota\n\nSince Jenkins is all about running short workloads, you should aim for the Terminating scope of quota.\nBut how do you specify workloads in Jenkins so that correct scope is used?\n\nIf you were to do this in Kubernetes, you have to specify.spec.activeDeadlineSeconds.\nThe same field can also be specified by the Kubernetes plugin when you are specifying a Pod Template.\n\nFigure 1. Specifying.spec.activeDeadlineSeconds in the Kubernetes plugin\n\nSame configuration is available in the Jenkinsfile as well if you don’t like static configurations.\n\npodTemplate(label: 'maven', activeDeadlineSeconds: 180, containers: [\n    containerTemplate(name: 'maven', image: 'maven:3.5.4-jdk-10-slim')\n  ]) {\n  // maven magic\n}\n\nThis was just a small sample of features of the Kubernetes plugin in Jenkins. For more, be sure to check out our\ntalk where we share more of how you can utilise Kubernetes with Jenkins!\n\nCome see Niklas Tanskanen and many other Jenkins experts and contributors at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Effectively using Kubernetes plugin with Jenkins","tags":["kubernetes","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":null,"blog":null,"github":"tanskann","html":"","id":"tanskann","irc":null,"linkedin":null,"name":"Niklas Tanskanen","slug":"/blog/authors/tanskann","twitter":null}]}},{"node":{"date":"2018-08-23T00:00:00.000Z","id":"409d4d90-3aa4-5eba-ac07-97d9486bc294","slug":"/blog/2018/08/23/speaker-blog-casc-part-1/","strippedHtml":"This blog post is part 1 of a Configuration-as-Code series\n\nJenkins is highly flexible and is today the de facto standard for implementing CI/CD, with an active community to maintain plugins for almost any combination of tools and use-cases.\nBut flexibility has a cost: in addition to Jenkins core, many plugins require some system-level configuration to be set so they can do their job.\n\nIn some circumstances, \"Jenkins Administrator\" is a full time position.\nOne person is responsible for both maintaining the infrastructure, and also pampering a huge Jenkins controller with hundred installed plugins and thousands hosted jobs.\nMaintaining up-to-date plugin versions is a challenge and failover is a nightmare.\n\nThis is like years ago when system administrators had to manage dedicated machines per service.\nIn 2018, everything is managed as code using infrastructure automation tools and virtualization.\nNeed a fresh new application server as staging environment for your application? Just deploy a Docker container.\nInfrastructure is missing resources? Apply a Terraform recipe to allocate more on your favourite Cloud.\n\nWhat about the Jenkins administrator role in this context? Should they still spend hours in the web UI, clicking checkboxes on web forms? Maybe they already adopted some automation, relying on Groovy script voodoo, or some home-made XML templating?\n\nEarly this year we announced the first alpha release of “Jenkins Configuration-as-Code” (JCasC), a fresh new approach to Jenkins configuration management, based on YAML configuration files and automatic model discovery.\n“JCasC” has been promoted as a\ntop-level Jenkins project, and the corresponding\nJenkins Enhancement Proposal has been accepted.\n\nWhat can JCasC do for our Jenkins Administrator?\n\nJCasC allows us to apply a set of YAML files on our Jenkins controller at startup or on-demand via the web UI.\nThose configuration files are very concise and human readable compared to verbose XML files the Jenkins uses to actually store configuration.\nThe files also have user-friendly naming conventions making it easy for administrators to configure all Jenkins components.\n\nHere’s an example:\n\njenkins:\n systemMessage: \"Jenkins managed by Configuration as Code\"\n\n securityRealm:\n   ldap:\n     configurations:\n       - server: ldap.acme.com\n         rootDN: dc=acme,dc=fr\n         managerPasswordSecret: ${LDAP_PASSWORD}\n     cache:\n       size: 100\n       ttl: 10\n     userIdStrategy: CaseInsensitive\n     groupIdStrategy: CaseSensitive\n\nAs you can see, you don’t need long explanation to understand how this YAML file will setup your Jenkins controller.\n\nBenefits\n\nThe most immediate benefit of JCasC is reproducibility.\nAn administrator can now bootstrap a new Jenkins controller with the exact same configuration with a trivial setup.\nThis allows them to create a test instance and check the impact of plugin upgrades in a sandboxed environment.\nThis also lets them be more confident with failover and disaster recovery scenarios.\n\nFurther benefits come when administrators start managing their Jenkins’ YAML configuration files in source control, like they do with Terraform configuration.\nDoing so gives them auditing and reversibility of their Jenkins controller configuration.\nTheycan establish a sane configuration change workflow that runs a test Jenkins instance and ensures configuration is healthy before actually applying any change to their production Jenkins controller.\n\nLast but not least, with ability to quickly setup Jenkins controllers and control them from a set of shared YAML configuration files, administrators can now offer per-team Jenkins instances, with more flexibility on installed plugins.\nA controller becomes more or less a transient piece of infrastructure for your team, as long as they also manage build definition with Jenkinsfiles.\n\nWith Configuration-as-Code we can stop having to treat our Jenkins controller like a pet we need to pamper, and start managing Jenkins controllers as cattle you can replace without effort nor impacts.\nWelcome in the “as-code” world.\n\nFigure 1. They are still cute though, right?\n\nOk, so what’s next?\n\nYou can read more about the Jenkins Configuration-as-Code plugin on the project’s\ngithub repository.\nTo chat with the community and contributors join our\ngitter channel,\nor come see us in person at\nlink: Jenkins World to discuss the JCasC project and its future!\n\nAlso don’t miss next post from the Configuration-as-Code series, where we’ll look at how JCasC works with sensitive data like passwords and other credentials.\n\nCome meet the Configuration as Code contributors, Nicolas de Loof and Ewelina Wilkosz at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins Configuration-as-Code: Look ma, no hands","tags":["configuration-as-code","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":null,"blog":null,"github":"ndeloof","html":"","id":"ndeloof","irc":null,"linkedin":null,"name":"Nicolas De Loof","slug":"/blog/authors/ndeloof","twitter":null}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"003e40e9-a1b3-5859-a18a-60017d86c651","slug":"/blog/2018/08/17/speaker-blog-brent-laster/","strippedHtml":"More and more today, continuous delivery (CD) pipelines are making use of containers.\nIn many implementations, the primary workflow/orchestration tool for CD pipelines is Jenkins.\nAnd the primary container orchestration tool is Docker.\nTogether these two applications provide a powerful, yet simple to understand and use, model for leveraging containers in your CD pipeline.\n\nWhen creating a pipeline script in Jenkins, there are multiple ways to incorporate Docker into your CD pipeline.\nThey include:\n\nManually running a predefined Docker image as a separate Jenkins agent\n\nAutomatically provisioning a Docker image, when needed, as a part of a “cloud” configuration\n\nReferencing a “docker” global variable that can be invoked via the Jenkins DSL\n\nCalling the Docker executable directly via a shell call in the Jenkins DSL\n\nFor this article, we’ll focus on the third item in this list given that it provides the most flexibility and convenience for Docker use in the pipeline.\nMore details on the other three can be found in the upcoming “Continuous Delivery and Containerization” workshop at Jenkins World/DevOps World 2018.\n\nFirst, we’ll provide some background on a couple of terms for those who may not be familiar with Jenkins 2.\nIf you already are familiar with it, feel free to skip ahead to the Global Variables section.\n\nBackground\n\nWhen we talk about Jenkins here, we’re referring to “Jenkins 2” - a name we use to generally refer to the 2.0 and beyond versions of Jenkins.\nJenkins 2 offers a powerful evolution of Jenkins over prior versions.\nIn particular, it provides full integration for “pipeline-as-code” (PAC).\nPAC refers to being able to write your pipeline in a scripting language, much like source code for any program.\nThe code you write becomes the program that defines your pipeline.\nIt is also the code that gets executed when your pipeline is initiated.\nListing 1 shows a simple example pipeline.\nNotice that this is very different from the classic way of creating pipelines in Jenkins.\nHere you are writing code - rather than the more traditional approaches, such as filling in web forms to configure a Freestyle job.\n\n// Scripted Pipeline //\nnode('worker') {\n    stage('Source') { // Get code\n        // Get code from our git repository\n        git 'git@diyvb2:/home/git/repositories/workshop.git'\n    }\n    stage('Compile') { // Compile and do unit testing\n        // Run gradle to execute compile and unit testing\n        sh \"gradle clean compileJava test\"\n    }\n}\n// Declarative //\n\nListing 1: Example Jenkins 2 pipeline\n\nThe language that we write the Jenkins pipeline code in is a Domain-Specific Language (DSL).\nYou can think of it as the “programming language” for Jenkins pipelines.\nThere are two variants of it.\nThe style we saw in figure 1 is called “scripted syntax”.\nIt is a mixture of elements from the Groovy programming language and special Jenkins “steps”.\nThe Jenkins steps are provided by the plugins that are installed in the current system.\nA built-in tool called the Snippet Generator provides a wizard interface to allow users to pick the step and options they want.\nThen, the user can click on a button to have Jenkins automatically generate the correct DSL code in the large text box (figure 1).\nThe DSL code can be copied from there and pasted into the pipeline script.\n\nFigure 1. The Snippet Generator\n\nA second type of syntax is called “declarative syntax.”  We won’t go into detail on it here.\nBut it is a much more structured syntax that focuses on having users declare what they want in a pipeline, rather than writing the logic to make it happen.\n\nGlobal Variables\n\nIn addition to the steps that are provided by plugins, additional functionality for pipelines can be provided by global variables.\nThe simplest way to think of a global variable is as an object with methods that can be invoked on it.\nSeveral of these are built in to Jenkins, such as the Docker global variable.\nOthers can be created by users as part of the structure of a shared source code repository called a “shared pipeline library.”\n\nTo get a list of the global variables that are currently available to your Jenkins instance, you can go to the Snippet Generator screen.\nImmediately below the box for the generated pipeline script is a section titled Global Variables.\nThere, within the small print, is a link to get to the actual section (figure 2).\n\nFigure 2. Link to Global Variables Reference section.\n\nClicking on that link takes us to a list of currently available Global Variables.\nIf you have the Docker Pipeline Plugin installed, you will see one at the top for Docker. (Figure 3).\n\nFigure 3. Docker global variable specifics.\n\nBroadly, the docker global variable includes methods that can be applied to the Docker application, Docker images, and Docker containers.\n\nWe’ll focus first on a couple of the Docker image methods as shown in figure 4.\n\nFigure 4. Key methods for getting a Docker image.\n\nThere are multiple ways you can use these methods to create a new image.\nListing 2 shows a basic example of assigning and pulling an image using the image method.\n\nmyImage = docker.image(\"bclaster/jenkins-node:1.0\")\nmyImage.pull()\n\nListing 2: Assigning a image to a variable and pulling it down.\n\nThis can also be done in a single statement as shown in listing 3.\n\ndocker.image(\"bclaster/jenkins-node:1.0\").pull()\n\nListing 3: Shorthand version of previous call.\n\nYou can also download a Dockerfile and build an image based on it.(See listing 4.)\n\nnode() {\n    def myImg\n    stage (\"Build image\") {\n        // download the dockerfile to build from\n        git 'git@diyvb:repos/dockerResources.git'\n\n        // build our docker image\n        myImg = docker.build 'my-image:snapshot'\n    }\n}\n\nListing 4: Pipeline code to download a Dockerfile and build an image from it.\n\nFigure 5 shows the actual output from running that “Build image” stage.\nNote that the docker.build step was translated into an actual Docker build command.\n\nFigure 5. Actual Docker output from running the download and build\n\nThe Inside Command\n\nAnother powerful method available for the Docker global variable is the inside method.\nWhen executed, this method will do the following:\n\nGet an agent and a workspace to execute on\n\nIf the Docker image is not already present, pull it down\n\nStart the container with that image\n\nMount the workspace from Jenkins\n\nExecute the build steps\n\nMounting the workspace means that the Jenkins workspace will appear as a volume inside the container.\nAnd it will have the same file path.\nSo, things running in the container will have direct access to the same location.\nHowever, this can only be done if the container is running on the same underlying system - such that it can directly access the path.\n\nIn terms of executing the build steps, the inside method acts as a scoping method.\nThis means that the environment it sets up is in effect for any statement that happens within its scope (within the block under it bounded by {}).\nThe practical application here is that any pipeline “sh” steps (a call to the shell to execute something) are automatically run in the container.\nBehind the scenes, this is done by wrapping the calls with “docker exec”.\n\nWhen executed, the calls with the global variable are translated (by Jenkins) into actual Docker call invocations.\nListing 5 shows an example of using this in a script, along with the output from the first invocation of the “inside” method.\nYou can see in the output the docker commands that are generated from the inside method call.\n\nstage (\"Get Source\") {\n        // run a command to get the source code download\n        myImg.inside('-v /home/git/repos:/home/git/repos') {\n            sh \"rm -rf gradle-greetings\"\n            sh \"git clone --branch test /home/git/repos/gradle-greetings.git\"\n        }\n    }\n    stage (\"Run Build\") {\n        myImg.inside() {\n            sh \"cd gradle-greetings && gradle -g /tmp clean build -x test\"\n        }\n    }\n\nListing 5: Example inside method usage.\n\nFigure 6. Example inside method Docker command output.\n\nOnce completed, the inside step will stop the container,\nget rid of the storage, and create a record that this image was used for the build.\nThat record facilitates image traceability, updates, etc.\n\nAs you can see, the combination of using the Docker “global variable” and its “inside” method provide a simple and powerful way to spin up and work with containers in your pipeline.\nIn addition, since you are not having to make the direct Docker calls, you can invoke steps like sh within the scope of the inside method, and have them executed by Docker transparently.\n\nAs we mentioned, this is only one of several ways you can interact with Docker in your pipeline code.\nTo learn about the other methods and get hands-on practice, join me at DevOps World/Jenkins World in San Francisco or Nice for the workshop\n\" Creating a Deployment Pipeline with Jenkins 2\".\nHope to see you there!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Using the Docker Global Variable in Your Jenkins Pipeline","tags":["event","jenkinsworld","jenkinsworld2018","pipeline","docker"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg","srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/77b35/brentlaster.jpg 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/d4a57/brentlaster.jpg 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/68974/brentlaster.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/ef6ff/brentlaster.webp 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/8257c/brentlaster.webp 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/6766a/brentlaster.webp 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/22bfc/brentlaster.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"brentlaster","html":"<div class=\"paragraph\">\n<p>Brent Laster is a Senior Manager in the Research and Development division at SAS in Cary, North Carolina. He manages several groups involved with release engineering processes, best practices, and tooling. He also serves as a resource for the use of open-source technologies and conducts internal training classes in technologies such as Git, Gerrit, Gradle, and Jenkins, both in the U.S. and abroad.</p>\n</div>\n<div class=\"paragraph\">\n<p>Brent Laster is the author of \"Professional Git\"\n(a comprehensive guide to Git for users ranging from beginners to advanced)\nand \"Jenkins 2 – Up and Running:  Evolve Your Pipeline for Next-Generation Automation\".</p>\n</div>","id":"brentlaster","irc":null,"linkedin":null,"name":"Brent Laster","slug":"/blog/authors/brentlaster","twitter":"brentclaster"}]}},{"node":{"date":"2018-08-16T00:00:00.000Z","id":"8a951bf4-62b1-5a68-b1e8-22376e509229","slug":"/blog/2018/08/16/dwjw-2018-is-almost-here/","strippedHtml":"DevOps World | Jenkins World 2018 in San Francisco is only a month away.\nIt is shaping up to be a great event including the Contributor Summit,\nthe \"Ask the Experts\" desk at the Jenkin booth, several days of training and certifications,\nand tons of informative presentation and demos.\n\nTo give you a taste of what you’ll see this year at DevOps World | Jenkins World 2018,\nwe’ve lined up a series of guest blog posts by a number of this years speakers,\nstarting in the next week with posts from Tracy Miranda, Brent Laster, and Nicholas De Loof.\nFor now, let’s take a look at last year’s keynote from Kohsuke Kawaguchi.\n\nStay tuned!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"DevOps World | Jenkins World 2018 is Almost Here","tags":["event","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"tag":"jenkinsworld2018","limit":8,"skip":8,"numPages":2,"currentPage":2}},
    "staticQueryHashes": ["3649515864"]}