{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/cloud-native",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2021-10-28T00:00:00.000Z","id":"bb5b6b61-0b2c-523e-9fa6-6f2912642e51","slug":"/blog/2021/10/28/introducing-junit-external-storage/","strippedHtml":"In common CI/CD use-cases a lot of the space is consumed by test reports.\nThis data is stored within JENKINS_HOME,\nand the current storage format requires huge overheads when retrieving statistics and, especially, trends.\nIn order to display trends, each report has to be loaded and then processed in-memory.\n\nThe main purpose of externalising Test Results is to optimize Jenkins performance and storage\nby querying the desired data from external storages.\n\nI‚Äôm please to announce that the JUnit Plugin external storage is now available for use.\n\nGetting started\n\nInstall your database vendor specific plugin, you can use the Jenkins plugin site to search for it:\n\nhttps://plugins.jenkins.io/ui/search/?labels=database\n\ne.g. you could install the PostgreSQL Database plugin.\n\nWe currently support PostgreSQL or MySQL, but can support others, just create an issue or send a pull request.\n\nFrom Jenkins UI\n\nNavigate to: Manage Jenkins ‚Üí Configure System ‚Üí Junit\n\nIn the dropdown select 'SQL Database'\n\nNow configure your Database connection details.\n\nSearch for 'Global Database' on the same 'Configure System' page.\n\nSelect the database implementation you want to use and click 'Test Connection' to verify Jenkins can connect\n\nClick 'Save'\n\nConfiguration as code\n\nIf you want to configure the plugin via Configuration as Code then see the below sample:\n\nunclassified:\n  globalDatabaseConfiguration:\n    database:\n      postgreSQL:\n        database: \"jenkins\"\n        hostname: \"${DB_HOST_NAME}\"\n        password: \"${DB_PASSWORD}\"\n        username: \"${DB_USERNAME}\"\n        validationQuery: \"SELECT 1\"\n  junitTestResultStorage:\n    storage: \"database\"\n\nUsing the plugin\n\nNow run some builds, here‚Äôs an example pipeline configuration to get you started if you‚Äôre just trying out the plugin:\n\nnode {\n  writeFile file: 'x.xml', text: '''\n\n'''\n  junit 'x.xml'\n}\n\nYou will see a test result trend appear like below on the builds project page:\n\nIf you check on the controller‚Äôs file system you will see no junitResult.xml for new builds.\n\nIf you connect to your database and run:\n\nSELECT * FROM caseresults;\n\nYou will see a number of test results in the database.\n\nWhat happens to existing test results?\n\nExisting test results will stay on disk but will not be loaded.\n\nCurrently there is no migration scripts or plugin functionality to do this, if you need it then please raise an issue.\n\nHow are test results cleaned up\n\nWhen a job or build is deleted the related test results are removed.\n\nThis is expected to be done as part of a 'Build Discarder'.\n\nIf you wish to keep your results longer than this you can disable this feature by enabling:\n\nSkip cleanup of test result on build deletion on the system configuration page.\n\nIf you need more complex cleanup strategies built into the plugin then please raise an issue.\n\nAPI\n\nThe API is defined at:\n\njenkinsdoc:junit:io.jenkins.plugins.junit.storage.JunitTestResultStorage[]\n\njenkinsdoc:junit:io.jenkins.plugins.junit.storage.JunitTestResultStorageDescriptor[]\n\njenkinsdoc:junit:io.jenkins.plugins.junit.storage.TestResultImpl[]\n\nJunitTestResultStorage#load is passed a job name and build which can be used to construct an instance of the external storage implementation.\n\nThis implementation will then act on that job and build except for the optimised calls that act across all builds.\n\nThe API contains the basic methods like getFailCount, getSkipCount, but also APIs that are optimised for retrieving data for the trend graphs on the job page and the test result history page.\n\nThese allow single API calls to be made for what used to be a lot of work for Jenkins to look up before.\n\nFeedback\n\nI would love to hear your feedback & suggestions for this feature.\n\nPlease create an issue at https://github.com/jenkinsci/junit-plugin or provide feedback on https://community.jenkins.io","title":"Introducing external storage for JUnit test results","tags":["cloud-native","pluggable-storage","junit"],"authors":[{"avatar":null,"blog":null,"github":"timja","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer, along with slack, azure-keyvault and configuration-as-code plugins.\nTim started using Jenkins in 2013 and became an active contributor in 2018.\nTim enjoys working on open source software in his ‚Äúfree‚Äù time.</p>\n</div>","id":"timja","irc":null,"linkedin":"tim-jacomb-98043174","name":"Tim Jacomb","slug":"/blog/authors/timja","twitter":"Tjaynz"}]}},{"node":{"date":"2021-08-02T00:00:00.000Z","id":"4b818957-350e-52f3-a687-d86ebc43405d","slug":"/blog/2021/08/02/cloudevents-plugin-phase-I/","strippedHtml":"The What, Why and How of Interoperability\n\nWith workloads and teams becoming more diverse and complex, there is an increasing need to automate various tasks in the CI/CD ecosystem of an application as a way to decrease complexity that can come with CI/CD.\n\nA more diverse team working across different aspects of the application requires a diverse suite of CI/CD tools too, to test and deliver to a wide range of users. More often than not, we need these tools to work together and exchange data to form an effective CI/CD pipeline. However, chaining multiple services together can very easily increase complexity.\n\nHow? Each of these services use a different \"language\" to communicate and represent the entity(an event) which occured inside that service. In order for another service to understand this \"language\", the service might need to develop customized clients and agents which specialize in understanding, traversing and taking-actions based on what was transmitted to it by the first service.\n\nOne can think of it as a translator who specializes in a language called ABC, and each service who wants to communicate with the service who uses ABC will have to employ this translator, or perhaps get another trained translator. And there is no guarantee that this translator will also help communicate with other services speaking a completely different language.\n\nWe can see how easily that can grow in cost and maintenance. A preferred way is to have a common language each of these services use and understand as a way to communicate amongst each other. This way, an event which is emitted using this common language will be available to any of the interested receiver without that receiver needing a special agent. This way of communication which uses a common/standard language also creates a way for agnostic communication where the sender or the receiver are sending and receiving data without creating a tight coupling between the two.\n\nCloudEvents specification is enabling that loosely-coupled, event-driven communication between services by enforcing a common language which defines how an event should be emitted and transferred between systems.\n\nCloudEvents and Jenkins\n\nA specification for describing event data in a common way\n\nConsistency\n\nConsistent across tools and services.\n\nAccessibility\n\nCommon event format means common libraries, tooling, and infrastructure for delivering event data across environments can be used to develop with CloudEvents.\n\nPortability\n\nEasily port event-data across tools, truly leveraging event-driven architecture.\n\nThe CloudEvents plugin for Jenkins is developed as an effort to make interoperability between Jenkins and CI/CD tools much easier. The CloudEvents plugin for Jenkins is a GSoC project, and with the help from an amazing team of mentors, this project is aimed at enhancing event-driven interoperability between cloud-native CI/CD tools, making it easier for developers to include Jenkins in their CI/CD pipelines.\n\nWith this plugin, Jenkins can send and receive CloudEvents-compliant events to and from a wide variety of CI/CD tools using CloudEvents as their event format. This plugin makes chaining Jenkins with multiple tools like Tekton, Keptn, Knative and more, very easy.\n\nGSoC Phase 1 - CloudEvents Plugin\n\nUsing CloudEvents plugin for Jenkins\n\nThis plugin allows Jenkins to be configured as a source and sink, which can emit and consume CloudEvents from a range of tools simultaneously.\n\nJenkins as a Source\n\nConfiguring Jenkins as a Source enables Jenkins to send CloudEvents to a CloudEvents sink. For Phase-I of this project, there is support for HTTP Sinks, however CloudEvents supports various protocol bindings. Moving forward, there will also be support for other protocol bindings supported by CloudEvents.\n\nTo use Jenkins as a Source, the following configuration is needed:\n\nClick on Manage Jenkins in the Root-Actions menu on the left.\n\nInside the Manage Jenkins UI, search for Configure System under System Configuration.\n\nIn the Configure System UI, scroll down to the CloudEvents plugin section, and this is where all the plugin configuration will be present. Here, you will have to enter the following information:\n\nSink Type (For now, HTTP Protocol Binding for CloudEvent and HTTP Sink is supported.)\n\nSink URL (URL of the Sink where you want the cloudevents sent.)\n\nEvents you want sent to the CloudEvents sink URL.\n\nStep 1: Manage Jenkins\n\nStep 2: Configure System\n\nStep 3: Configure CloudEvents Sink\n\nWith Jenkins as a Source configured, Jenkins will send a POST request to the configured sink right as the selected event occurs inside Jenkins. Each event has a different payload specific to the type of the event emitted.\n\nEvent Types, Payload and Metadata\n\nCloudEvents emitted by Jenkins follow the Binary-structure supported by CloudEvents, where the CloudEvents metadata is present inside the header, and the event-data is serialized as JSON, and present under request-body. This is the HTTP Protocol Binding for CloudEvents. Each protocol binding for CloudEvents follows a definition specific to the binding protocol.\n\nFor now, the following Jenkins events are supported in the CloudEvents Plugin-Jenkins as a Source:\n\nQueue Events\n\nQueue Entered Waiting\n\nQueue Left\n\nBuild Events\n\nJob Started\n\nJob Completed\n\nJob Finalized\n\nJob Failed\n\nJob Events\n\nJob Created\n\nJob Updated\n\nNode Events\n\nNode Online\n\nNode Offline\n\nFollowing is a table of the queue-entered waiting cloudevents metadata:\n\nEvent Metadata Headers Key\nEvent Metadata Headers Value\n\nce-specversion\n1.0\n\nce-type\norg.jenkinsci.queue.entered_waiting\n\nce-source\njob/test\n\nce-id\n123-456-789\n\nAll of these fields will be present inside the HTTP-request headers since the CloudEvents format used here is the Binary structure.\n\nHere‚Äôs also an example of event payload for the queue-entered event:\n\n{\n  \"ciUrl\": \"http://3.101.116.80/\",\n  \"displayName\": \"test2\",\n  \"entryTime\": 1626611053609,\n  \"exitTime\": null,\n  \"startedBy\": \"shruti chaturvedi\",\n  \"jenkinsQueueId\": 25,\n  \"status\": \"ENTERED_WAITING\",\n  \"duration\": 0,\n  \"queueCauses\": [\n    {\n    \"reasonForWaiting\": \"In the quiet period. Expires in 0 ms\",\n    \"type\": \"entered_waiting\"\n    }\n  ]\n}\n\nTry the Plugin\n\nThe plugin will soon be releasing as the CloudEvents Plugin under https://plugins.jenkins.io/!!\n\nHere‚Äôs the GitHub Repo of the Plugin: CloudEvents Plugin GitHub Repo\n\nDemo\n\nHere is a video of the CloudEvents plugin with SockEye demoed at CDF GSoC Midterm Demos. SockEye is an open-source tool which is designed as a way to visulaize cloudevents which are sent from a sink. In this demo, we will take a look at how Jenkins installed in a multi-node K8s environment work with the CloudEvents plugin as a Source, sending events over HTTP to the SockEye sink.\n\nNext Steps\n\nJenkins as a Sink to allow Jenkins to trigger various actions as cloudevents are received from other tools.\n\nEnabling filtering on CloudEvents metadata to only act upon a certain kind of events recieved.\n\nSupport for other protocol bindings in CloudEvents.\n\nFeedback\n\nWe would absolutely love to hear your suggestions and feedback. This will help us understand the various use-cases for the plugin, and iterate to support a variety of bindings and formats.\n\nFeel free to log an issue at the CloudEvents Plugin GitHub repository. We are on CDF slack under gsoc-2021-jenkins-cloudevents-plugin. You can also start a discussion on community.jenkins.io. I also love emails! Drop me one on: shrutichaturvedi16.sc@gmail.com","title":"CloudEvents Plugin for Jenkins: Interoperability between Jenkins and other CI/CD Tools","tags":["gsoc","gsoc2021","cloudevents","interoperability","cloud-native"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/bf8e1/ShrutiC-git.png","srcSet":"/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/914ee/ShrutiC-git.png 32w,\n/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/1c9ce/ShrutiC-git.png 64w,\n/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/bf8e1/ShrutiC-git.png 128w,\n/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/acb7c/ShrutiC-git.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/ef6ff/ShrutiC-git.webp 32w,\n/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/8257c/ShrutiC-git.webp 64w,\n/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/6766a/ShrutiC-git.webp 128w,\n/gatsby-jenkins-io/static/02bce5237e5a6152567788b0da82ce8e/22bfc/ShrutiC-git.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"ShrutiC-git","html":"<div class=\"paragraph\">\n<p>Shruti Chaturvedi is the <strong>Founding Engineer</strong> for Klara, a startup to revolutionalize the shopping experience for beauty products.\nShe is an <strong>Oracle Certified Cloud Practitioner</strong>, and is developing solutions on Cloud where CI/CD is her primary focus. She has worked with Jenkins as a User, and is very excited to contribute to Jenkins and be a part of the community.</p>\n</div>","id":"ShrutiC-git","irc":null,"linkedin":null,"name":"Shruti Chaturvedi","slug":"/blog/authors/shrutic-git","twitter":"shruti_tech"}]}},{"node":{"date":"2020-08-31T00:00:00.000Z","id":"43eb825a-3d18-5e4f-a85a-0f03ad89902f","slug":"/blog/2020/08/31/custom-distribution-service/","strippedHtml":"Hello everyone,\n\nThis is the final blog post for the Custom Distribution Service project during the Google Summer of Code timeline.\nI have mixed feelings since we are almost near the finish line for one of the most amazing open source programs out there.\nHowever, it is time to wrap things up for this project and achieve a state where the project can be built upon and extended further.\nThis phase has been super busy with respect to the bug fixes, testing and getting the project hosted, so let us get straight into the phase 3 updates.\n\nFixes and Code quality assurance\n\nSet Jenkinsfile agent to linux\n\nWe realised that the build was failing on windows and that there was not really a use-case\nfor running it on windows for right now. Maybe it could be on a future roadmap. Therefore, we\ndecided to shift the testing to only linux agents with respect to running the tests on the jenkins\nserver.\n\nPull Request #116\n\nBackend port error message\n\nSpring boot has a default message on the port:8080 and therefore we wanted to change\nit to a custom message on the backend. So the major takeaway here is that we needed to\nimplement the Error Controller interface and include a custom message in it.\nThis was technical debt from the last phase and was completed and merged during this phase.\n\nPull Request #92\n\nPMD Analysis\n\nIn order to enhance the quality of the code, the PMD source code analyser was applied to the project.\nIt helped me catch tons of errors. When the initial PMD check was run and we found approximately 162 PMD errors. We realised some of them were not relevant and some of them could be fixed later.\n\nPull Request #102\n\nFindbugs Analysis\n\nAnother tool to improve code quality that we included in this phase was findbugs.\nIt did catch around 5-10 bugs in my code which I immediately resolved. Most of them were\naround the Closeable HTTP Request and an easy fix was the try with resources.\n\nPull Request #118\n\nJacoco Code Coverage\n\nWe needed to make sure most of the code we write had proper coverage for all branches and\nlines. Therefore we decided to include a JaCoco Code Coverage reporter that helped us find the\nuncovered lines and areas we need to improve coverage on.\n\nPull Request #103\n\nRemove JCasC generation\n\nWhile developing the service we quickly realised that the generation of the war package broke if we\nincluded a configuration as code section but did not provide a path to the corresponding required yml\nfile. Therefore we took a decision to remove the casc section all together. Maybe it will comeback in\na future patch\n\nPull Request link: #127\n\nIssue link: #65\n\nMinor Fixes\n\nLogging Fix: #99\n\nDocs Fix : link: #120\n\nUpdate Center Dump Fix : link: #125\n\nClass Path Fix: link: #126\n\nRelease Drafter Addition: link: #136\n\nFront end\n\nCommunity Config Navigation link\n\nThere was no community configuration link present for navigation which was added here.\n Now it is easier to navigate to the community page from the home page itself.\n\nPull Request #100\n\nDocker updates\n\nBuild everything with Docker\n\nThis was one of the major changes this phase with respect to making the service very easy to spin up locally, this change will greatly help community adoption since it eliminates the tools one needs to install locally. Initially the process was to run maven locally, generate all of the files and then copy all of its contents into the container. However, with this change we are going to generate all of the files inside the docker container itself. Allowing the user to just run a couple of commands to get the service up and running.\n\nSo some of the major changes we did with respect to the dockerfile was:\n\na) Copy all of the configuration files and pom.xml into the container.\n\nb) Run the command mvn clean package inside the container which generates the jar.\n\nc) Run the jar inside the container.\n\nPull Request #104\n\nHosting updates\n\nThis process was supposed to be a future roadmap, however the infra team approved and was super helpful\nin making this process as smooth as possible. Thanks to Gavin, Tim and Oblak for making this possible.\nHere is the google group dicussion\n\nThe project has now been hosted here as a preview. It still needs\nsome fixes to be fully functional.\n\nInfra Docker PR #131\n\nInfra Project Addition PR link: #393\n\nTesting Updates\n\nUnit test the services\n\nWith respect to community hosting and adoption, testing of the service one of the most important and major milestones for this phase was to test the majority of the code and we have completed the testing with flying colors. All of the services have been completely unit tested, which is a major accomplishment.\nFor the testing of the service we decided to go with wiremock which can be used to mock external services. Kezhi‚Äôs comment helped us to understand what we needed to do since he had done something quite similar in his Github Checks API project.\n\nSo we basically wiremocked the update-center url and made sure we were getting\nthe accurate response with appropriate control flow logic tested.\n\nwireMockRule.stubFor(get(urlPathMatching(\"/getUpdateCenter\"))\n                .willReturn(aResponse()\n                        .withStatus(200)\n                        .withHeader(\"Content-Type\", \"application/json\")\n                        .withBody(updateCenterBody)));\n\nPull Request #105\n\nAdd Update Center controller tests\n\nAnother major testing change involved testing the controllers. For this we decided to use the wiremock library in java to mock the server response when the controllers were invoked.\n\nFor example: If I have a controller that serves in an api called /api/plugin/getPluginList\nwiremock can be used to stub out its response when the system is under test. So we use something like this to test it out.\n\nwhen(updateService.downloadUpdateCenterJSON()).thenReturn(util.convertPayloadToJSON(dummyUpdateBody))\n\nWhen the particular controller is called the underlying service is mocked and it returns a response according to the one provided by us. To find more details the PR is here.\n\nPull Request #106\n\nAdd Packager Controller Tests\n\nAlong with the update center controller tests another controller that needed to be tested was the\npackager controller. Also we needed to make sure that all the branches for the controllers were properly tested. Additional details can be found in the PR below.\n\nPull Request #133\n\nDocker Compose Tests\n\nOne problem that we faced the entire phase was the docker containers. We regularly found out that due to\nsome changes in the codebase the docker container build sometimes broke, or even sometimes the inner api‚Äôs seemed to malfunction. In order to counteract that we decided to come up with some tests locally.\nSo what I did was basically introduce a set of bash scripts that would do the following:\n\na) Build the container using the docker-compose command.\n\nb) Run the container.\n\nc) Test the api‚Äôs using the exposed port.\n\nd) Teardown the running containers.\n\nPull Request #131\n\nUser Documentation\n\nWe also included a user docs guide so that it makes it super easy to get started with the service.\n\nPull Request #145\n\nFuture Roadmap\n\nThis has been a super exciting project to work on and I can definitely see this project being built\nupon and extended in the future.\n\nI would like to talk about some of the features that are left to come in and can be taken up in\na future roadmap discussion\n\na) JCasC Support :\n\nDescription: Support the generation of a Jenkins Configuration as Code file asking the user interactively for the plugins they select what would be the configuration they would want eg: If the user selects the slack plugin we need to ask him questions like what is the slack channel? what is the token? etc, and on the basis of this generate a casc file. This feature was initially planned to go into the service but we realised this is a project in its own capacity.\n\nb) Auto Pull Request Creation :\n\nDescription: Allow users to create a configuration file and immediately open a pull request on github\nwithout leaving the user interface. This was originally planned using a github bot and we started the work on it. But we were in doubt if the service would be hosted or not and therefore put the development on hold.\nYou can find the pull requests here:\n\nGithub Controller #72\n\nPull Request Creation Functions #66\n\nc) Synergy with Image Controller\n\nDescription: This feature requires some planning, some of the questions we can ask are:\n\na) Can we generate the images (i.e Image Controller).\nb) Can we have the service as a multipurpose generator ?\n\nStatistics\n\nThis phase has been the busiest of all phases and it has involved a lot of work, more than I had\ninitially expected in the phase. Although lines\nof code added is not an indication of work done, however 800 lines of Code added is a real personal milestone for me.\n\nPull Requests Opened\n26\n\nLines of Code Added\n1096\n\nLines of Docs Added\n200\n\nOther links\n\nGitter Channel Link\nGSoC Proposal\nDesign Document\nDaily Notes","title":"Custom Distribution Service : Phase 3 Blogpost","tags":["service","distribution","cloud-native","gsoc","gsoc2020","packaging","platform-sig"],"authors":[{"avatar":null,"blog":null,"github":"sladyn98","html":"<div class=\"paragraph\">\n<p>Sladyn is a Computer Science student at Mumbai University, India.\nHe is participating in Community Bridge 2019 to provide development tools to JCasC plugin in the form of IDE integrations, schema architecture improvements and configuration extension points <a href=\"https://github.com/jenkinsci/configuration-as-code-plugin\">Configuration as Code Plugin</a>.</p>\n</div>","id":"sladyn98","irc":null,"linkedin":null,"name":"Sladyn Nunes","slug":"/blog/authors/sladyn98","twitter":"SladynN"}]}},{"node":{"date":"2020-08-25T00:00:00.000Z","id":"7a744457-8457-529e-9c68-1e00d5e790df","slug":"/blog/2020/08/25/external-fingerprint-storage-phase-3/","strippedHtml":"The final phase for the External Fingerprint Storage\nProject has come to an end and to finish off, we release one more fingerprint storage plugin:\nthe PostgreSQL Fingerprint Storage Plugin!\n\nThis post highlights the progress made during phase-3.\nTo understand what the project is about and the past progress, please refer to the\nphase-1 post and the\nphase-2 post.\n\nIntroducing the PostgreSQL Fingerprint Storage Plugin\n\nWhy PostgreSQL?\n\nThere were several reasons why it made sense to build another reference implementation, especially backed by PostgreSQL.\n\nRedis is a key-value storage, and hence stores the fingerprints as blobs.\nThe PostgreSQL plugin defines a relational structure for fingerprints.\nThis offers a more powerful way to query the database for fingerprint information.\nFingerprint facets can store extra information inside the fingerprints, which cannot be queried in Redis directly.\nPostgreSQL plugin allows powerful (indexing) and efficient querying strategies which can even query the facet metadata.\n\nAnother reason for building this plugin was to provide a basis for other relational database plugins to be built.\nIt also validates the flexibility and design of our external fingerprint storage API.\n\nSince PostgreSQL is a traditional disk storage database, it is more suitable for systems storing a massive number of\nfingerprints.\n\nAmong relational databases, PostgreSQL is quite popular, has extensive support, and is open-source.\nWe expect the new implementation to drive more adoption, and prove to be beneficial to the community.\n\nInstallation:\n\nThe plugin can be installed using the\nexperimental update center.\nFollow along the following steps after running Jenkins to download and install the plugin:\n\nSelect Manage Jenkins\n\nSelect Manage Plugins\n\nGo to Advanced tab\n\nConfigure the Update Site URL as: https://updates.jenkins.io/experimental/update-center.json\n\nClick on Submit, and then press the Check Now button.\n\nGo to Available tab.\n\nSearch for PostgreSQL Fingerprint Storage Plugin and check the box along it.\n\nClick on Install without restart\n\nThe plugin should now be installed on the system.\n\nUsage\n\nOnce the plugin has been installed, you can configure the PostgreSQL server details by following the steps below:\n\nSelect Manage Jenkins\n\nSelect Configure System\n\nScroll to the section Fingerprints and choose PostgreSQL Fingerprint Storage in the dropdown for\nFingerprint Storage Engine.\n\nConfigure the following parameters to connect to your PostgreSQL instance:\n\nHost - Enter hostname where PostgreSQL is running\n\nPort - Specify the port on which PostgreSQL is running\n\nSSL - Click if SSL is enabled\n\nDatabase Name - Specify the database name inside the PostgreSQL instance to be used. Please note that the database\nwill not be created by the plugin, the user has to create the database.\n\nConnection Timeout - Set the connection timeout duration in seconds.\n\nSocket Timeout - Set the socket timeout duration in seconds.\n\nCredentials - Configure authentication using username and password to the PostgreSQL instance.\n\nUse the Test PostgreSQL Connection button to verify that the details are correct and Jenkins is able to connect to\nthe PostgreSQL instance.\n\n[IMPORTANT] When configuring the plugin for the first time, it is highly important to press the Perform PostgreSQL\nSchema Initialization button. It will automatically perform schema initialization and create the necessary indexes.\nThe button can also be used in the case the database is wiped out and schema needs to be recreated.\n\nPress the Save button.\n\nNow, all the fingerprints produced by this Jenkins instance should be saved in the configured PostgreSQL instance!\n\nQuerying the Fingerprint Database\n\nDue to the relational structure defined by PostgreSQL, it allows users/developers to query the fingerprint data which\nwas not possible using the Redis fingerprint storage plugin.\n\nThe fingerprint storage can act as a consolidated storage for multiple Jenkins instances.\nFor example, to search for a fingerprint id across Jenkins instances using the file name, the following query could be\nused:\n\nSELECT fingerprint_id FROM fingerprint.fingerprint\nWHERE filename = 'random_file';\n\nA sample query is provided which can be tweaked depending on the parameters to be searched:\n\nSELECT * FROM fingerprint.fingerprint\nWHERE fingerprint_id = 'random_id'\n        AND instance_id = 'random_jenkins_instance_id'\n        AND filename = 'random_file'\n        AND original_job_name = 'random_job'\n        AND original_job_build_number = 'random_build_number'\n        AND timestamp BETWEEN '2019-12-01 23:59:59'::timestamp AND now()::timestamp\n\nThe facets are stored in the database as jsonb.\nPostgreSQL offers support to query jsonb.\nThis is especially useful for querying the information stored inside fingerprint facets.\nAs an example, the Docker Traceability Plugin stores information like the name of Docker images inside these\nfacets.\nThese can be queried across Jenkins instances like so:\n\n>'imageName' = 'random_container';\n\nAt the moment these queries require working knowledge of the database.\nIn future, these queries can be abstracted away by plugins and the features made available to users directly inside\nJenkins.\n\nDemo\n\nExternal Fingerprint Storage Demo\n\nSlide deck\n\nReleases üöÄ\n\nWe released the 0.1-alpha-1 version for the\nPostgreSQL Fingerprint Storage Plugin.\nPlease refer to the\n\nchangelog for more information.\n\nRedis Fingerprint Storage Plugin 1.0-rc-3 was also\nreleased.\nThe\n\nchangelog provides more details.\n\nA few API changes made in the Jenkins core were released in Jenkins-2.253.\nIt mainly includes exposing fingerprint range set serialization methods for plugins.\n\nFuture Directions\n\nThe relational structure of the plugin allows some performance improvements that can be made when implementing\ncleanup, as well as improving the performance of Fingerprint#add(String job, int buildNumber).\nThese designs were discussed and are a scope of future improvement.\n\nThe current external fingerprint storage API supports configuring multiple Jenkins instances to a single storage.\nThis opens up the possibility of developing traceability plugins which can track fingerprints across Jenkins instances.\n\nPlease consider reaching out to us if you feel any of the use cases would benefit you, or if you would like to share\nsome new use cases.\n\nAcknowledgements\n\nThe PostgreSQL Fingerprint Storage Plugin and the Redis Fingerprint Storage plugin are maintained by the\nGoogle Summer of Code (GSoC) Team for External\nFingerprint Storage for Jenkins.\nSpecial thanks to Oleg Nenashev,\nAndrey Falko, Mike Cirioli,\nTim Jacomb, and the entire Jenkins community for all the contribution to this project.\n\nAs we wrap up, we would like to point out that there are plenty of future directions and use cases for the externalized\nfingerprint storage, as mentioned in the previous section, and we welcome everybody to contribute.\n\nReaching Out\n\nFeel free to reach out to us for any questions, feedback, etc. on the project‚Äôs\nGitter Channel or the\nJenkins Developer Mailing list.\nWe use Jenkins Jira to track issues.\nFeel free to file issues under either the postgresql-fingerprint-storage-plugin or the\nredis-fingerprint-storage-plugin component depending on the plugin.\n\nOther Links\n\nPhase 1 Post\n\nPhase 2 Post\n\nPostgreSQL Fingerprint Storage Plugin\n\nRedis Fingerprint Storage Plugin\n\njep:226[]\n\nGitter Channel\n\nProject Page","title":"External Fingerprint Storage Phase-3 Update: Introducing the PostgreSQL Fingerprint Storage Plugin","tags":["plugins","fingerprint","cloud-native","external-storage","developer","PostgreSQL","gsoc","gsoc2020"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/19e71/stellargo.jpg","srcSet":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/77b35/stellargo.jpg 32w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/d4a57/stellargo.jpg 64w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/19e71/stellargo.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/ef6ff/stellargo.webp 32w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/8257c/stellargo.webp 64w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/6766a/stellargo.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://medium.com/@sumitsarinofficial","github":"stellargo","html":"<div class=\"paragraph\">\n<p>Jenkins Google Summer of Code 2020 student. Sumit is an engineering student (senior) at Netaji Subhas Institute of Technology, University of Delhi. He started his journey of contributing to Jenkins in December 2019. His tiny contribution revolved around the Jenkins Fingerprint engine. He is currently working on building <a href=\"https://www.jenkins.io/projects/gsoc/2020/projects/external-fingerprint-storage\">External Fingerprint Storage for Jenkins</a>.</p>\n</div>","id":"stellargo","irc":null,"linkedin":"sumit-sarin","name":"Sumit Sarin","slug":"/blog/authors/stellargo","twitter":null}]}},{"node":{"date":"2020-08-09T00:00:00.000Z","id":"babe2cb7-b1f3-538d-a0da-40bd4f32b839","slug":"/blog/2020/08/09/custom-distribution-service-phase-2/","strippedHtml":"Hello everyone,\nIt is time to wrap up another successfull phase for the custom distribution service project,\nand we have incorporated most of the features that we had planned at the start of the phase.\nIt has been an immense learning curve for me and the entire team.\n\nTo understand what the project is about and the past progress, please refer to the phase one blogpost\nhere.\n\nFront-End\n\nFilters for Plugins\n\nIn the previous phase we implemented the ability to add plugins to the configuration,\nand the ability to search these plugins via a search bar.\nSometimes though we would like to filter these plugins based on their usage,\npopularity, stars etc. Hence we have added a certain set of filters to these plugins.\nWe support only four major filters for now. They are:\n\nTitle\n\nMost installed\n\nRelevance\n\nTrending\n\nFilter implementation\n\nThe major heavy lifting is done by the plugin api which takes in the necessary parameters\nand returns the relevant plugins in the form of a json object,\nhere is an example of the api call url: const url = https://plugins.jenkins.io/api/plugins?$params .\n\nFor details, see:\n\nFeature request #9\n\nPull Request #76\n\nCommunity Configurations\n\nOne major deliverable for the project was the ability for users to share the configurations developed by them, so that they can be used widely within the community.\nFor example we see quite a lot of jenkins configurations involve being run on AWS and kubernetes and so on. Therefore it would be really good for the community to have a place to find and run\nthese configurations right out of the box.\n\nDesign Decision\n\nThe major design decision taken here was whether to include the configurations inside\nthe repository or to have them in a completely new repository.\nLet us talk about both these approaches.\n\nHaving the configurations in the current repository:\n\nThis allows us to have all of the relevant configurations inside the repository itself,\nand so users would not have to go fetch this in different repositories.\nWe could have issues with the release cycle and dependencies since,\nit would have to happen along with the custom distribution service project releases.\n\nHaving the configurations in a different repository:\n\nThis allows us to manage all of the configurations and the relevant dependencies separately and easily,\nthus avoiding any release conflict with the current repository.\nHowever it would be a bit difficult if users were to not find this repository.\n\nDecision : We still cannot quite agree on what is the best method so for now,\nI have included the url from which the community configurations are picked up as a\nconfiguration variable in the.env file which can be configured later and\ntherefore it can be up to the user to configure. Another advantage of having it configurable,\nis that the user can decide to load configurations which are private to his organization as well.\n\nFor details, see:\n\nIssue #6161\n\nPull Request #73\n\nBack-End\n\nWar Generation\n\nThe ability to generate and download war files has finally been achieved,\nthe reason this feature took so long to complete is because we had some difficulty\nin implementing the war generation and its tests. However this has been completed\nand can now be tested successfully.\n\nThings to take care while generating war files\n\nIn its current state the war generation cannot include casc.yml or groovy files\nif they are included in the configuration they would have to be added externally.\nThere is an issue opened here.\nThe war file generation would yell at you if you tried to build a war file with a jcasc file configuration.\n\nFor details, see:\n\nIssue #60\n\nPull Request #68\n\nPull Request Creation\n\nThis feature was included in the design document that I created after my GSoC selection.\nIt involves the ability to create pull requests via the front-end of the service.\nThe User Story behind this feature was that If I want to share a configuration with the community and I do not quite know how to use github or I do not want to do it via the terminal.\nThis feature includes creation of a bot that handles the creation of pull requests in the repository.\nThis bot would have to be installed by the jenkins organization in this repository and the bot would handle the rest.\n\nFor details, see:\n\nIssue #59\n\nPull Request #72\n\nDisclaimer:\n\nThis feature has however been put on the back-burner for now because\nwe are focusing on getting the project to be self hosted and therefore\nwould like to implement this once we have a clear path for the project to be hosted by the jenkins-infra team.If you would like to participate in the discussion here are the links for the pull requests,\nPR 1 and link: PR 2, or you can even jump in our gitter channel.\n\nIf you have been following my posts,\nI mentioned in my second week blog post that pulling in the json file consisting of more than\n1600 plugins took a bit more time that my liking.\nWe managed to solve that issue using a caching mechanism,\nso now the files are pulled in the first time you start the service and downloaded in a temporary folder. The next time you want to view the plugin cards they are pulled in directly from the temp directory bam ! thereby reducing time.\n\nFor details see Pull Request #90\n\nFixes and improvements\n\nPort 8080\n\nPort 8080 now does have a message instead of a whitelabel error message which is present\nby default in the spring-boot tomcat server setup.\nTurns out it requires overriding a particular class, and inserting a custom message\n\nFor details, see:\n\nPull Request #92\n\nWar Generation\n\nTill now while you were generating the war file,\nif something went wrong during genration the service would not complain it would just swallow the error and throw back a corrupted war file,\nhowever now we have added an error support feature\nthat will alert you when something goes wrong, the error is not very informative as of now,\nbut we are working on making it more informative in the future.\n\nFor details, see:\n\nWar generation error handling #91\n\nAdd Github controller and jwt helper #66\n\nDockerfile\n\nOne of the major milestones of this phase was to have a project that can be self hosted,\nneedless to say we needed the dockerfile i.e docker-compose.yml to spin the project with a few commands.\nThe major issue we faced here was that there was a bit of a problem making the two containers talk to each other. Let me give you a little bit of context here.\nOur docker-compose is constructed using two separate dockerfiles one for the backend of the service and the other for the front-end.\nThe backend makes api calls to the front-end via the proxy url i.e localhost:8080.\nWe now had to change this since the network bridge between the two containers spoke to each other via the backend-server name i.e app-server.\nTo brige that gap we have this PR that ensured that the docker compose works flawlessly.\n\nFor details, see:\n\nPull Request #82\n\nHowever there is a minor draw-back of the above approach was now the entire\nproject just relied on the docker compose and could not run using the simple\ncombination of npm and maven since the proxy was different.\nIn order to fix this I decided to follow a multiple environment approach,\nwhere we have multiple environment files that pick up the correct proxy and insert it at build time,\nto elaborate further we have two environment files,\n(using the env-cmd library ).env and the docker.env and we insert,\nthe correct file depending on how you want to build the project.\nFor instance if you want to run it using the dockerfile the command that is run under the hood is something along these lines‚Äâ‚Äî npm --env-cmd -f docker.env start scripts.\n\nFor details, see:\n\nPull Request #88\n\nOther links\n\nGitter Channel Link\nGSoC Proposal\nDesign Document\nDaily Notes\nDemo","title":"Custom Distribution Service : Phase 2 Blogpost","tags":["service","distribution","cloud-native","gsoc","gsoc2020","packaging","platform-sig"],"authors":[{"avatar":null,"blog":null,"github":"sladyn98","html":"<div class=\"paragraph\">\n<p>Sladyn is a Computer Science student at Mumbai University, India.\nHe is participating in Community Bridge 2019 to provide development tools to JCasC plugin in the form of IDE integrations, schema architecture improvements and configuration extension points <a href=\"https://github.com/jenkinsci/configuration-as-code-plugin\">Configuration as Code Plugin</a>.</p>\n</div>","id":"sladyn98","irc":null,"linkedin":null,"name":"Sladyn Nunes","slug":"/blog/authors/sladyn98","twitter":"SladynN"}]}},{"node":{"date":"2020-07-27T00:00:00.000Z","id":"28af9b14-9cf1-5cb2-94df-b2869b9e73fc","slug":"/blog/2020/07/27/custom-distribution-service/","strippedHtml":"Hello,\nAfter an eventful community bonding period we finally entered into the coding phase. This blog post will summarize the work done till the midterm of the coding phases i.e. week 6. If some of the topics here require a more detailed explanation, I will write a separate blog post. These blogs posts will not have a very defined format but would cover all of the user stories or features implemented.\n\nProject Summary\n\nThe main idea behind the project is to build a customizable jenkins distribution service that could be used to build tailor-made jenkins distributions. The service would provide users with a simple interface to select the configurations they want to build the instance with eg: plugins, authorization matrices etc. Furthermore it would include a section for sharing community created distros so that users can find and download already built jenkins war/configuration files to use out of the box.\n\nQuick review\n\nPull Requests Opened\n38\n\nGithub Issues completed\n36\n\nDetails\n\nI have written separate blog posts for every week in GSoC and the intricate details for each of them can be found at their respective blog pages. I am including a summary for every phase supported with the respective links.\n\nCommunity Bonding\n\nThis year GSoC had a longer community bonding than any of the previous editions due to the Coronavirus pandemic and therefore this gave me a lot of time to explore, so I spent it by building a prototype for my project. I realised some of the blockages I might face early on, and therefore it gave me more clarity in terms of how I can proceed. I also spent this time preparing a design document which you can find here.\n\nCommunity Bonding Blog\n\nWeek 1\n\nIn week one, I spent time getting used to the tech stack I would be using, I was pretty familiar with Spring Boot but React was something I was going to be using for the first time, so I spent time studying more about it. I also got the project page ready, the issues I was going to tackle and the milestones that I had to achieve before the evaluation. I also spent a bit of time setting up the home page and a bit of front-end components.\n\nWeek 1 Blog\n\nWeek 2\n\nOnce we were done with the initial setup, it was time to work on the core of the project.\nIn the second week, I worked on generating the package configuration and the plugin list dummy display page setup.\nI also ran into issues with the Jenkinsfile so the majority of time was spent fixing it.\nFinally I managed to get around those problems.\nYou can read more about it in the Week 2 Blog post.\n\nWeek 2 Blog\n\nWeek 3\n\nThe last week was spent cleaning up most of the code and getting the remaining milestones in. This was probably the hardest part of phase 1 because it involved connecting the front and back end of the project.You can read more about it here.\n\nWeek 3\n\nMidterm Update\n\nThe second phase has been going on for the past 3 weeks and we have already accomplished a majority of the deliverables including community configurations, war downloading and filtering of plugins. More details about the mid term report can be found here.\n\nMidterm Update\n\nGetting the Code\n\nThe Custom Distribution Service was created from scratch during GSoC and can be found here on Github.\n\nOther links\n\nGSoC Proposal\nDesign Document\nDaily Notes\nDemo\n\nFeedback channel\n\nGitter Channel Link.","title":"Custom Distribution Service : Midterm Summary","tags":["service","distribution","cloud-native","gsoc","gsoc2020","packaging","platform-sig"],"authors":[{"avatar":null,"blog":null,"github":"sladyn98","html":"<div class=\"paragraph\">\n<p>Sladyn is a Computer Science student at Mumbai University, India.\nHe is participating in Community Bridge 2019 to provide development tools to JCasC plugin in the form of IDE integrations, schema architecture improvements and configuration extension points <a href=\"https://github.com/jenkinsci/configuration-as-code-plugin\">Configuration as Code Plugin</a>.</p>\n</div>","id":"sladyn98","irc":null,"linkedin":null,"name":"Sladyn Nunes","slug":"/blog/authors/sladyn98","twitter":"SladynN"}]}},{"node":{"date":"2020-07-24T00:00:00.000Z","id":"4bb5ba32-d613-5603-8d83-2dabce9481fa","slug":"/blog/2020/07/24/external-fingerprint-storage-phase-2/","strippedHtml":"As another great phase for the\nExternal Fingerprint Storage Project\ncomes to an end, we summarise the work done during this phase in this blog post.\nIt was an exciting and fruitful journey, just like the previous phase, and offered some great learning experience.\n\nTo understand what the project is about and the past progress, please refer to the\nphase 1 blog post.\n\nNew Stories Completed\n\nWe targeted four stories in this phase, namely fingerprint cleanup, fingerprint migration, refactoring the current\nimplementation to use descriptors, and improved testing of the Redis Fingerprint Storage Plugin.\nWe explain these stories in detail below.\n\nFingerprint Cleanup\n\nhttps://github.com/jenkinsci/jenkins/pull/4817\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/23\n\nThis story involved extending the FingerprintStorage API to allow external storage plugins to perform and configure\ntheir own fingerprint cleanup strategies.\nWe added the following functionalities to Jenkins core API:\n\nFingerprintStorage#iterateAndCleanupFingerprints(TaskListener taskListener)\n\nThis allows external fingerprint storage implementations to implement their own custom fingerprint cleanup.\nThe method is called periodically by Jenkins core.\n\nFingerprintStorage#cleanFingerprint(Fingerprint fingerprint, TaskListener taskListener)\n\nThis is a reference implementation which can be called by external storage plugins to clean up a fingerprint.\nIt is upto the plugin implementation to decide whether to use this method.\nThey may choose to write a custom implementation.\n\nWe consume these new API functionalities in the\nRedis Fingerprint Storage plugin.\nThe plugin uses cursors to traverse the fingerprints, updating the build information, and deleting the build-less\nfingerprints.\n\nEarlier, fingerprint cleanup was always run periodically and there was no way to turn it off.\nWe also added an option to allow the user to turn off fingerprint cleanup.\n\nThis was done because it may be the case that keeping redundant fingerprints in memory might be cheaper than the\ncleanup operation (especially in the case of external storages, which are cheaper these days).\n\nFingerprint Migration\n\nhttps://github.com/jenkinsci/jenkins/pull/4825\n\nEarlier, there was no support for fingerprints stored in the local storage.\nIn this phase, we introduce migration support for users.\nThe old fingerprints are now migrated to the new configured external storage whenever they are used (lazy migration).\nThis allows gradual migration of old fingerprints from local disk storage to the new external storage.\n\nRefactor FingerprintStorage to use descriptors\n\nhttps://github.com/jenkinsci/jenkins/pull/4834\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/36\n\nEarlier, whenever an external fingerprint storage plugin was installed, it was enabled by default.\nWe refactored the implementation to make use of Descriptor pattern so the fingerprint engine can now be selected\nas a dropdown from the Jenkins configuration page.\nThe dropdown is shown only when multiple fingerprint storage engines are configured on the system.\nRedis Fingerprint Storage Plugin was refactored\nto use this new implementation.\n\nStrengthened testing for the Redis Fingerprint Storage Plugin\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/33\n\nWe introduced new connection tests in the\nRedis Fingerprint Storage Plugin.\nThese tests allow testing of cases like slow connection, breakage of connection to Redis, etc.\nThese were implemented using the Toxiproxy module inside Testcontainers.\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/31\n\nWe introduced test for Configuration-as-code (JCasC) compatibility with the plugin.\nThe documentation for configuring the plugin using JCasC was also added.\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/39\n\nWe introduced a suite of authentication tests, to verify the proper working of the Redis authentication system.\nAuthentication uses the credentials plugin.\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/32\n\nhttps://github.com/jenkinsci/redis-fingerprint-storage-plugin/pull/36\n\nWe strengthened our web UI testing to ensure that the configuration page for the plugin works properly as planned.\n\nOther miscellaneous tasks\n\nPlease refer to the Jira Epic for this phase.\n\nReleases üöÄ\n\nChanges in the Jenkins core (except migration) were released in Jenkins 2.248.\n\nWe drafted 1.0-rc-1\nrelease for the Redis Fingerprint Storage Plugin\nto deliver the changes.\nThis was an increment from the alpha release\nwe had drafted at the end of the previous phase.\nThe plugin is now available at https://plugins.jenkins.io/redis-fingerprint-storage/!\n\nTrying out the new features!\n\nThe latest release for the plugin can be downloaded from the update center, instructions for which can be\nfound in the README\nof the plugin.\nWe appreciate you trying out the plugin, and welcome any suggestions, feature requests, bug reports, etc.\n\nAcknowledgements\n\nThe Redis Fingerprint Storage plugin is built and maintained by the Google Summer of Code (GSoC) Team for\nExternal Fingerprint Storage for\nJenkins. Special thanks to Oleg Nenashev,\nAndrey Falko, Mike Cirioli,\nTim Jacomb, and the entire Jenkins community for all the contribution to this project.\n\nFuture Work\n\nSome of the topics we aim to tackle in the next phase include a new reference implementation (possibly backed\nby PostgreSQL), tracing, etc.\n\nReaching Out\n\nFeel free to reach out to us for any questions, feedback, etc. on the project‚Äôs Gitter Channel or the Jenkins\nDeveloper Mailing list.\nWe use Jenkins Jira to track issues.\nFeel free to file issues under redis-fingerprint-storage-plugin component.\n\nOther Links\n\nRedis Fingerprint Storage Plugin\n\nIssue Tracker for Phase 2\n\njep:226[]\n\nGitter Channel\n\nProject Page\n\nPhase 1 Blog Post","title":"External Fingerprint Storage Phase-2 Updates","tags":["plugins","fingerprint","cloud-native","external-storage","developer","redis","gsoc","gsoc2020"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/19e71/stellargo.jpg","srcSet":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/77b35/stellargo.jpg 32w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/d4a57/stellargo.jpg 64w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/19e71/stellargo.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/ef6ff/stellargo.webp 32w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/8257c/stellargo.webp 64w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/6766a/stellargo.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://medium.com/@sumitsarinofficial","github":"stellargo","html":"<div class=\"paragraph\">\n<p>Jenkins Google Summer of Code 2020 student. Sumit is an engineering student (senior) at Netaji Subhas Institute of Technology, University of Delhi. He started his journey of contributing to Jenkins in December 2019. His tiny contribution revolved around the Jenkins Fingerprint engine. He is currently working on building <a href=\"https://www.jenkins.io/projects/gsoc/2020/projects/external-fingerprint-storage\">External Fingerprint Storage for Jenkins</a>.</p>\n</div>","id":"stellargo","irc":null,"linkedin":"sumit-sarin","name":"Sumit Sarin","slug":"/blog/authors/stellargo","twitter":null}]}},{"node":{"date":"2020-06-27T00:00:00.000Z","id":"a288c37b-abcd-5bdc-8b5b-012344f2934c","slug":"/blog/2020/06/27/external-fingerprint-storage/","strippedHtml":"Externalizing fingerprint storage for Jenkins is a  Google Summer of Code 2020 project.\nWe are working on building a pluggable storage engine for fingerprints (see jep:226[]).\n\nFile fingerprinting is a way to track which version of a file is being used by a job/build, making dependency tracking easy. The fingerprint engine of Jenkins can track usages of artifacts, credentials, files, etc. within the system. Currently, it does this by maintaining a local XML-based database which leads to dependence on the physical disk of the Jenkins controller.\n\nAllowing fingerprint storage to be moved to external storages decreases the dependence of Jenkins instances on the physical disk space and also allows for tracking the flow of fingerprints across instances of Jenkins connected to the same external storage.\n\nAdvantages of using external storage drivers:\n\nRemove dependence on Jenkins controller disk storage\n\nCan configure pay-as-you-use cloud storages\n\nEasy Backup Management\n\nBetter Reliability and Availability\n\nFingerprints can be tracked across Jenkins instances\n\nAlong with this API, we are also working on a reference implementation in the form of a plugin, powered by Redis.\n\nAs phase 1 of this project comes to an end, this blog post serves as a summary of the progress we made to the entire Jenkins community.\n\nCurrent State\n\nThe new API introduced in Jenkins core is under review. Once merged, it will offer developers to extend it to build external fingerprint storage plugins.\n\nThe Redis Fingerprint Storage Plugin is alpha release ready. We would immensely appreciate any feedback.\n\nExternal Fingerprint Storage Demo\n\nIntroducing the new API for plugin developers\n\nWith PR-4731, we introduce a new fingerprint storage API, allowing configuring custom storage engines.\nWe exposed the following methods in the new FingerprintStorage class:\n\nvoid save()\n\nSaves the given Fingerprint in the storage.\n\nFingerprint load(String id)\n\nReturns the Fingerprint with the given unique ID. The unique ID for a fingerprint is defined by Fingerprint#getHashString().\n\nvoid delete(String id)\n\nDeletes the Fingerprint with the given unique ID.\n\nboolean isReady()\n\nReturns true if there is some data in the fingerprint database corresponding to the particular Jenkins instance.\n\nIntroducing Redis Fingerprint Storage Plugin\n\nRedis Fingerprint Storage Plugin uses the new External Fingerprint Storage API to store the fingerprints in a Redis instance.\n\nInstallation:\n\nThe alpha release (version 0.1-alpha-1) for the plugin was drafted, and can be installed using the experimental update center.\n\nFollow along the following steps after running Jenkins to download and install the plugin:\n\nSelect Manage Jenkins\n\nSelect Manage Plugins\n\nGo to Advanced tab\n\nConfigure the Update Site URL as: https://updates.jenkins.io/experimental/update-center.json\n\nClick on Submit, and then press the Check Now button.\n\nGo to Available tab.\n\nSearch for Redis Fingerprint Storage Plugin and check the box along it.\n\nClick on Install without restart\n\nThe plugin should now be installed on your system.\n\nUsage\n\nOnce the plugin has been installed, you can configure the Redis server details by following the steps below:\n\nSelect Manage Jenkins\n\nSelect Configure System\n\nScroll to the section Redis Fingerprint Storage Configuration and fill in the required details:\n\nHost - Enter hostname where Redis is running\n\nPort - Specify the port on which Redis is running\n\nSSL - Click if SSL is enabled\n\nDatabase - Redis supports integer indexed databases, which can be specified here.\n\nConnection Timeout - Set the connection timeout duration in milliseconds.\n\nSocked Timeout - Set the socket timeout duration in milliseconds.\n\nCredentials - Configure authentication using username and password to the Redis instance.\n\nEnabled - Check this to enable the plugin (Note: This is likely to be removed very soon, and will be enabled by default.)\n\nUse the Test Redis Connection to verify that the details are correct and Jenkins is able to connect to the Redis instance.\n\nPress the Save button.\n\nNow, all the fingerprints produced by this Jenkins instance should be saved in the configured Redis server!\n\nFuture Work\n\nSome of the topics we aim to tackle in the next phases include extending the API, fingerprint cleanup, migrations (internal‚Üíexternal, external‚Üíinternal, external‚Üíexternal), tracing, ORM, implementing the saveable listener, etc.\n\nAcknowledgements\n\nThe Redis Fingerprint Storage plugin is built and maintained by the Google Summer of Code (GSoC) Team for\nExternal Fingerprint Storage for Jenkins.\n\nSpecial thanks to Oleg Nenashev, Andrey Falko, Mike Cirioli, Jesse Glick, and the entire Jenkins community for all the contribution to this project.\n\nReaching Out\n\nFeel free to reach out to us for any questions, feedback, etc. on the project‚Äôs Gitter Channel or the Jenkins Developer Mailing list\n\nWe use Jenkins Jira to track issues.\nFeel free to file issues under redis-fingerprint-storage-plugin component.\n\nOther Links\n\nPhase 1 demo\n\nPresentation slides\n\nRedis Fingerprint Storage Plugin\n\nIssue Tracker for Phase 1\n\njep:226[]\n\nGitter Channel\n\nProject Page","title":"External Fingerprint Storage Phase-1 Updates","tags":["plugins","fingerprint","cloud-native","external-storage","developer","redis","gsoc","gsoc2020"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/19e71/stellargo.jpg","srcSet":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/77b35/stellargo.jpg 32w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/d4a57/stellargo.jpg 64w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/19e71/stellargo.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/ef6ff/stellargo.webp 32w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/8257c/stellargo.webp 64w,\n/gatsby-jenkins-io/static/57deb704d1eb39e35b9de4a8c22ea56e/6766a/stellargo.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://medium.com/@sumitsarinofficial","github":"stellargo","html":"<div class=\"paragraph\">\n<p>Jenkins Google Summer of Code 2020 student. Sumit is an engineering student (senior) at Netaji Subhas Institute of Technology, University of Delhi. He started his journey of contributing to Jenkins in December 2019. His tiny contribution revolved around the Jenkins Fingerprint engine. He is currently working on building <a href=\"https://www.jenkins.io/projects/gsoc/2020/projects/external-fingerprint-storage\">External Fingerprint Storage for Jenkins</a>.</p>\n</div>","id":"stellargo","irc":null,"linkedin":"sumit-sarin","name":"Sumit Sarin","slug":"/blog/authors/stellargo","twitter":null}]}}]}},"pageContext":{"tag":"cloud-native","limit":8,"skip":0,"numPages":2,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}