{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/docker/page/2",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-05-15T00:00:00.000Z","id":"355e4b5a-0c27-5f01-94a5-7a981139c2fb","slug":"/blog/2017/05/15/kubernetes-journey-on-azure/","strippedHtml":"With the\nongoing migration to Azure,\nI would like to share my thoughts regarding one of the biggest challenges we\nhave faced thus far: orchestrating container infrastructure. Many of the\nJenkins project’s applications are run as Docker containers, making Kubernetes\na logical choice as far as running our containers, but it presents its own set\nof challenges. For example, what would the workflow from development to\nproduction look like?\n\nBefore going deeper into the challenges, let’s review the requirements we\nstarted with:\n\nGit\n\nWe found it mandatory to keep track of all the infrastructure changes in Git\nrepositories, including secrets, in order to facilitate reviewing,\nvalidation, rollback, etc of all infra changes.\n\nTests\n\nInfrastructure contributors are geographically distributed and in different\ntimezones.  Getting feedback can take time, so we heavily rely on a lot of\ntests before any changes can be merged.\n\nAutomation\n\nThe change submitter is not necessarily the person who will deploy it.\nRepetitive tasks are error prone and a waste of time.\nFor these reasons, all steps must be automated and stay as simple as possible.\n\nA high level overview of our \"infrastructure as code\" workflow would look like:\n\nInfrastructure as Code Workflow\n\n__________       _________       ______________\n  |         |      |        |      |             |\n  | Changes | ---->|  Test  |----->| Deployment  |\n  |_________|      |________|  ^   |_____________|\n                               |\n                        ______________\n                       |             |\n                       | Validation  |\n                       |_____________|\n\nWe identified two possible approaches for implementing our container\norchestration with Kubernetes:\n\nThe Jenkins Way: Jenkins is triggered by a Git commit, runs the tests, and\nafter validation, Jenkins deploys changes into production.\n\nThe Puppet Way: Jenkins is triggered by a Git commit, runs the tests, and\nafter validation, it triggers Puppet to deploy into production.\n\nLet’s discuss these two approaches in detail.\n\nThe Jenkins Way\n\nWorkflow\n\n_________________       ____________________       ______________\n  |                |      |                   |      |             |\n  |    Github:     |      |     Jenkins:      |      |   Jenkins:  |\n  | Commit trigger | ---->| Test & Validation | ---->|  Deployment |\n  |________________|      |___________________|      |_____________|\n\nIn this approach, Jenkins is used to test, validate, and deploy our Kubernetes\nconfiguration files. kubectl can be run on a directory and is idempotent.\nThis means that we can run it as often as we want: the result will not change.\nTheoretically, this is the simplest way. The only thing needed is to run\nkubectl command each time Jenkins detects changes.\n\nThe following Jenkinsfile gives an example of this workflow.\n\nJenkinsfile\n\npipeline {\n    agent any\n    stages {\n      stage('Init'){\n        steps {\n          sh 'curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl'\n        }\n      }\n      stage('Test'){\n        steps {\n          sh 'Run tests'\n        }\n      }\n      stage('Deploy'){\n        steps {\n          sh './kubectl apply -R true -f my_project'\n        }\n      }\n    }\n  }\n\nThe devil is in the details of course, and it was not as easy as it looked at\nfirst sight.\n\nOrder matters\n\nSome resources needed to be deployed before others. A workaround was to use\nnumbers as file names. But this added extra logic at file name level, for\nexample:\n\nproject/00-nginx-ingress\nproject/09-www.jenkins.io\n\nPortability\n\nThe deployment environments needed to be the same across development machines\nand the Jenkins host. Although this a well-known problem, it was not easy to\nsolve.  The more the project grew, the more our scripts needed additional tools\n( make, bats, jq gpg, etc).  The more tools we used, the more issues\nappeared because of the different versions used.\n\nAnother challenge that emerged when dealing with different environments was:\nhow should we manage environment-specific configurations (dev, prod, etc)?\nWould it be better to define different configuration files per environment?\nPerhaps, but this means code duplication, or using file templates which would require\nmore tools ( sed, jinja2, erb), and more work.\n\nThere wasn’t a golden rule we discovered, and the answer is probably somewhere in between.\n\nIn any case, the good news is that a Jenkinsfile provides an easy way to\nexecute tasks from a Docker image, and an image can contain all the necessary\ntools in our environment. We can even use different Docker images for each\nstage along the way.\n\nIn the following example, I use the my_env Docker image. It contains all the\ntools needed to test, validate, and deploy changes.\n\nJenkinsfile\n\npipeline{\n  agent {\n    docker{\n      image 'my_env:1.0'\n    }\n  }\n  options{\n    buildDiscarder(logRotator(numToKeepStr: '10'))\n    disableConcurrentBuilds()\n    timeout(time: 1, unit: 'HOURS')\n  }\n  triggers{\n    pollSCM('* * * * *')\n  }\n  stages{\n    stage('Init'){\n      steps{\n        // Init everything required to deploy our infra\n        sh 'make init'\n      }\n    }\n    stage('Test'){\n      steps{\n       // Run tests to validate changes\n       sh 'make test'\n      }\n    }\n    stage('Deploy'){\n      steps{\n       // Deploy changes in production\n       sh 'make deploy'\n      }\n    }\n  }\n  post{\n    always {\n      sh 'make notify'\n    }\n  }\n}\n\nSecret credentials\n\nManaging secrets is a big subject and brings with it many different\nrequirements which are very hard to fulfill.  For obvious reasons, we couldn’t\npublish the credentials used within the infra project.  On the other hand, we\nneeded to keep track and share them, particularly for the Jenkins node that\ndeploys our cluster.  This means that we needed a way to encrypt or decrypt\nthose credentials depending on permissions, environments, etc.  We analyzed two\ndifferent approaches to handle this:\n\nStoring secrets in a key management tool like Key Vault or Vault and use them like a Kubernetes \"secret\" type of resource.\n→ Unfortunately, these tools are not yet integrated in Kubernetes. But we may come back to this option later.\nKubernetes issue: 10439\n\nPublishing and encrypting using a public GPG key.\nThis means that everybody can encrypt credentials for the infrastructure project but only the owner of the private key can decrypt credentials.\nThis solution implies:\n\nScripting: as secrets need to be decrypted at deployment time.\n\nTemplates: as secret values will change depending on the environment.\n→ Each Jenkins node should only have the private key to decrypt secrets associated to its environment.\n\nScripting\n\nFinally, the system we had built was hard to work with.  Our initial\nJenkinsfile which only ran one kubectl command slowly become a bunch of\nscripts to accommodate for:\n\nResources needing to be updated only in some situations.\n\nSecrets needing to be encrypted/decrypted.\n\nTests needing to be run.\n\nIn the end, the amount of scripts required to deploy the Kubernetes resources\nstarted to become unwieldy and we began asking ourselves: \"aren’t we\nre-inventing the wheel?\"\n\nThe Puppet Way\n\nThe Jenkins project already uses Puppet, so we decided to look at using Puppet\nto orchestrate our container deployment with Kubernetes.\n\nWorkflow\n\n_________________       ____________________       _____________\n  |                |      |                   |      |            |\n  |    Github:     |      |     Jenkins:      |      | Puppet:    |\n  | Commit trigger | ---->| Test & Validation | ---->| Deployment |\n  |________________|      |___________________|      |____________|\n\nIn this workflow, Puppet is used to template and deploy all Kubernetes\nconfigurations files needed to orchestrate our cluster.\nPuppet is also used to automate basic kubectl operations such as 'apply' or\n'remove' for various resources based on file changes.\n\nPuppet workflow\n\n______________________\n|                     |\n|  Puppet Code:       |\n|    .                |\n|    ├── apply.pp     |\n|    ├── kubectl.pp   |\n|    ├── params.pp    |\n|    └── resources    |\n|        ├── lego.pp  |\n|        └── nginx.pp |\n|_____________________|\n          |                                        _________________________________\n          |                                       |                                |\n          |                                       |  Host: Prod orchestrator       |\n          |                                       |    /home/k8s/                  |\n          |                                       |    .                           |\n          |                                       |    └── resources               |\n          | Puppet generate workspace             |        ├── lego                |\n          └-------------------------------------->|        │   ├── configmap.yaml  |\n            Puppet apply workspaces' resources on |        │   ├── deployment.yaml |\n          ----------------------------------------|        │   └── namespace.yaml  |\n          |                                       |        └── nginx               |\n          v                                       |            ├── deployment.yaml |\n ______________                                   |            ├── namespace.yaml  |\n |     Azure:  |                                  |            └── service.yaml    |\n | K8s Cluster |                                  |________________________________|\n |_____________|\n\nThe main benefit of this approach is letting Puppet manage the environment and run\ncommon tasks. In the following example, we define a Puppet class for Datadog.\n\nPuppet class for resource Datadog\n\n# Deploy datadog resources on kubernetes cluster\n#   Class: profile::kubernetes::resources::datadog\n#\n#   This class deploy a datadog agent on each kubernetes node\n#\n#   Parameters:\n#     $apiKey:\n#       Contain datadog api key.\n#       Used in secret template\nclass profile::kubernetes::resources::datadog (\n    $apiKey = base64('encode', $::datadog_agent::api_key, 'strict')\n  ){\n  include ::stdlib\n  include profile::kubernetes::params\n  require profile::kubernetes::kubectl\n\n  file { \"${profile::kubernetes::params::resources}/datadog\":\n    ensure => 'directory',\n    owner  => $profile::kubernetes::params::user,\n  }\n\n  profile::kubernetes::apply { 'datadog/secret.yaml':\n    parameters => {\n        'apiKey' => $apiKey\n    },\n  }\n  profile::kubernetes::apply { 'datadog/daemonset.yaml':}\n  profile::kubernetes::apply { 'datadog/deployment.yaml':}\n\n  # As secrets change do not trigger pods update,\n  # we must reload pods 'manually' in order to use updated secrets.\n  # If we delete a pod defined by a daemonset,\n  # this daemonset will recreate pods automatically.\n  exec { 'Reload datadog pods':\n    path        => [\"${profile::kubernetes::params::bin}/\"],\n    command     => 'kubectl delete pods -l app=datadog',\n    refreshonly => true,\n    environment => [\"KUBECONFIG=${profile::kubernetes::params::home}/.kube/config\"] ,\n    logoutput   => true,\n    subscribe   => [\n      Exec['apply datadog/secret.yaml'],\n      Exec['apply datadog/daemonset.yaml'],\n    ],\n  }\n}\n\n→\nMore \"resources\" examples\n\nLet’s compare the Puppet way with the challenges discovered with the Jenkins\nway.\n\nOrder Matters\n\nWith Puppet, it becomes easier to define priorities as\nPuppet provides relationship meta parameters and the function 'require' (see\nalso:\nPuppet\nrelationships).\n\nIn our Datadog example, we can be sure that deployment will respect the following order:\n\ndatadog/secret.yaml -> datadog/daemonset.yaml -> datadog/deployment.yaml\n\nCurrently, our Puppet code only applies configuration when it detects file\nchanges.  It would be better to compare local files with the cluster\nconfiguration in order to trigger the required updates, but we haven’t found a\ngood way to implement this yet.\n\nPortability\n\nAs Puppet is used to configure working environments, it becomes easier to be\nsure that all tools are present and correctly configured.  It’s also easier to\nreplicate environments and run tests on them with tools like\nRSpec-puppet, Serverspec or\nVagrant.\n\nIn our Datadog example, we can also easily change the Datadog API key depending\non the environment with Hiera.\n\nSecret credentials\n\nAs we were already using Hiera GPG\nwith Puppet, we decided to continue to use it, making managing secrets for\ncontainers very simple.\n\nScripting\n\nOf course the Puppet DSL is used, and even if it seems harder at the beginning,\nPuppet simplifies a lot the management of Kubernetes configuration files.\n\nConclusion\n\nIt was much easier to bootstrap the project with a full CI workflow within\nJenkins as long as the Kubernetes project itself stays basic. But as soon as\nthe project grew, and we started deploying different applications with\ndifferent configurations per environment, it became easier to delegate\nKubernetes management to Puppet.\n\nIf you have any comments feel free to send a message to\nJenkins Infra mailing list.\n\nThanks\n\nThanks to Lindsay Vanheyste, Jean Marc Meessen, and Damien Duportal for their feedback.","title":"A journey to Kubernetes on Azure","tags":["puppet","kubernetes","docker","azure"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"olblak","html":"<div class=\"paragraph\">\n<p>Olivier is the Jenkins infrastructure officer and Senior Operations Engineer at CloudBees.\nAs a regular contributor to the Jenkins infrastructure projects, he works on a wide range of tasks from services reliability to applications maintenance.</p>\n</div>","id":"olblak","irc":"olblak","linkedin":null,"name":"Olivier Vernin","slug":"blog/author/olblak","twitter":"0lblak"}]}},{"node":{"date":"2016-04-07T00:00:00.000Z","id":"dc2d5625-7a35-5883-9c50-152fda1c584a","slug":"/blog/2016/04/07/jenkins-community-survey-results-blog/","strippedHtml":"This is a guest post by Brian\nDawson at CloudBees, where he works as a DevOps Evangelist responsible for\ndeveloping and sharing continuous delivery and DevOps best practices. He also\nserves as the CloudBees Product Marketing Manager for Jenkins.\n\nLast fall CloudBees asked attendees at the Jenkins User Conference – US West\n(JUC), and other in the Jenkins community to take a survey.  Almost 250 people\ndid – and thanks to their input, we have results which provided interesting\ninsights into how Jenkins is being used.\n\nBack in 2012, at the time of the last community survey, 83% of respondents felt\nthat Jenkins was mission-critical. By 2015, the percentage saying that\nJenkins was mission-critical was 92%. Additionally, echoing the\nimportance of Jenkins, 89% of respondents said their use of Jenkins had\nincreased over the last year, while 11% said it had stayed the same. 0%\nsaid that it had decreased.\n\nThe trend in the industry over the last couple of years has been to adopt\ncontinuous delivery (CD), thus pushing automation further down the pipeline –\nfrom development all the way into production.  Jenkins being an automation\nengine applicable to any phase of the software delivery lifecycle, is readily\nsupporting this trend. Jenkins' extensible architecture and unparalleled plugin\necosystem enables integration with and orchestration of practically any tool in\nany phase of software delivery.\n\nThe trend towards adoption of CD is clearly reflected amongst the community: 59%\nof respondents are using Jenkins for continuous integration (CI), but an\nadditional 30% have extended CI into CD and are manually deploying code to\nproduction.  Finally, 11% are practicing continuous deployment – they have\nextended CI to CD and are deploying code automatically into production.\n\nAnother trend tied to the adoption of CD and DevOps is the frequent deployment\nof incremental releases to production. 26% of those respondents using continuous\ndelivery practices are deploying code at least once per day.  Another 37% are\ndeploying code at least once per week.\n\nIn keeping with the move to CD, 30% of survey takers are already using the\nrelatively new Pipeline plugin to automate their\nsoftware delivery pipelines.  Of those not using the Pipeline plugin, 79% plan\nto adopt it in the next 12 months.\n\nSurvey respondents are also using Jenkins for many different activities.  97% of\nsurvey takers use it for \"build\" – no surprise, since that is where Jenkins got\nits start - but 58% now also use it for their deployment.\n\nWhen the 2012 community survey was conducted, container technology was not as\nwell understood as it is today,  and many didn’t know what a “Docker” was. A\nshort four years later, 96% of survey respondents who use Linux containers are\nusing Docker.  Container technology has seen impressive adoption and arguably is\nrevolutionizing the way application infrastructure is delivered.  When coupled\nwith Jenkins as an automation engine, containers help accelerate software\ndelivery by providing rapid access to lightweight environments.  The Jenkins\ncommunity has recognized and embraced the power of containers by\nproviding plugins for Docker and Kubernetes.\n\nThe Jenkins improvements which survey respondents desired the most were\nquality/timely bug fixes, a better UI and more documentation/examples.\nInterestingly, Jenkins 2.0 - which is just about to officially launch,\nprovides UI improvements and the new Jenkins.io website\nprovides improved, centralized documentation.\n\nFinally, the respondents favorite Star Wars character was R2-D2, followed by\nObi-Wan and Darth Vader. Yoda and Han Solo also got a fair amount of votes. The\nvotes for Jar-Jar Binks and Jabba the Hutt left us puzzled. Notably, BB-8 had a\nwrite-in vote despite the fact the new Star Wars movie hadn’t been released yet.\n\nAs to where the community is headed, our prediction is that by the next Jenkins Community Survey:\n\nMore Jenkins users will have transitioned from just continuous\nintegration to continuous delivery with some evening practicing continuous\ndeployment\n\nPipeline plugin adoption and improvements will continue, leading to\npipeline-as-code becoming an essential solution for automating the software\n(and infrastructure) delivery process\n\nThere will be a significant increase in use of the Docker plugin to support\nelastic Jenkins infrastructure and continuous delivery of containers using\nsoftware development best practices\n\nBB-8 will be the next favorite Star Wars character! <3</p>\n\nSee you at Jenkins World, September 13-15, in Santa Clara, California!\nRegister now for the largest Jenkins event on the planet in 2016 – and get the Early Bird discount. The Call for Papers is still open – so submit a talk and share your knowledge with the community about Jenkins.\n\n2015 Community Survey Results (PDF)\n\nState of Jenkins Infographic (PDF)","title":"Jenkins Community Survey Results","tags":["continuousdelivery","pipeline","docker"],"authors":[{"avatar":null,"blog":null,"github":"bvdawson","html":"<div class=\"paragraph\">\n<p>DevOps dude at CloudBees.\nJenkins Marketing Manager.\nTools geek.</p>\n</div>","id":"bvdawson","irc":null,"linkedin":null,"name":"Brian Dawson","slug":"blog/author/bvdawson","twitter":"brianvdawson"}]}},{"node":{"date":"2015-10-02T00:00:00.000Z","id":"e12d694f-12f6-5a91-8fb8-5f594f21f900","slug":"/blog/2015/10/02/winners-of-docker-global-hack-day-3-are/","strippedHtml":"+\nimage:https://jenkins-ci.org/sites/default/files/images/docker-hack-day_0.preview.jpg[image,width=320] +\n\n+\n+\n\nOver 2,000 members of the Docker community attended Docker Hack Day events around the world. One of the forty-two Docker Hacks has some familiar names attached…​\n\n+\n+\n\nNicolas De Loof and Yoann Dubreuil from Docker Rennes, who are also active in our community, waved the Jenkins flag in this event and produced Jenkins docker agents plugin.\n\n+\n+\n\n+\nThis plugin lets you run builds inside containers, and in that sense it's similar to https://wiki.jenkins.io/display/JENKINS/Docker+Plugin[the Docker plugin] and https://wiki.jenkins.io/display/JENKINS/CloudBees+Docker+Custom+Build+Environment+Plugin[the Docker custom build environment plugin]. But internally it uses a quite interesting approach. +\n\n+\n+\n\n+\nThis fresh new implementation relies on a set of docker containers (aka ‘pod’) to setup a build executor, letting development team customize the build environment for their need without any constraint or prerequisite, and relying on docker containers to host test resources.\n\n+\n+\n\n+\nThis project https://blog.docker.com/2015/09/docker-global-hack-day-3-winners/[won the 3rd place in the Freestyle category of Docker Hack Day]. Congratulations to Nicolas and Yoann on their win! Jenkins + Docker is a winning pair and this plugin will make a huge difference in your projects.","title":"Winners of Docker Global Hack Day #3 are...","tags":["general","plugins","jenkinsci","docker"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"","id":"hinman","irc":null,"linkedin":null,"name":"Hannah Inman","slug":"blog/author/hinman","twitter":null}]}},{"node":{"date":"2015-08-20T00:00:00.000Z","id":"d1860023-e5b8-5452-a7f4-ba23d5ca66a3","slug":"/blog/2015/08/20/upcoming-office-hour-on-kubernetes/","strippedHtml":"Nicolas De Loof will host an office hour next Wednesday 11 AM PDT on integrating Kubernetes with Jenkins. Kubernetes is an open-source project by Google that provides a platform for managing Docker containers as a cluster.\n\nDuring this session, Nicolas will introduce Kubernetes, explain how it can benefit Jenkins and demonstrate the Kubernetes Plugin.\nThen he will discuss the design of the Kubernetes plugin and plans he has for future improvements.\n\nParticipate in the Hangout on Air or watch live on YouTube.","title":"Upcoming office hour on Kubernetes","tags":["general","plugins","screencast","tutorial","docker"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"blog/author/daniel-beck","twitter":null}]}},{"node":{"date":"2014-08-12T00:00:00.000Z","id":"4d06a8ac-058a-5589-bb0d-1d1c493fbfd1","slug":"/blog/2014/08/12/official-jenkins-lts-docker-image/","strippedHtml":"+\n(This is a guest post from https://twitter.com/michaelneale[Michael Neale]) +\n\n+\n+\n\n+\nRecently at the Docker Conference (DockerCon) the https://hub.docker.com[Docker Hub] was announced.\n\n+\n+\n\nThe hub (which includes their image building and storage service) also provides some \"official\" images (sometimes they call them repositories - they are really just sets of images).\n\n+\nSo after talking with all sorts of people we decided to create an official https://registry.hub.docker.com/_/jenkins/[Jenkins image] - which is hosted by the docker hub simply as \"jenkins\".\n\n+\n+\n\nSo when you run \"docker pull jenkins\" - it will be grabbing this image. This is based on the current LTS (and will be kept up to date with the LTS) - but does not include the weekly releases (yet). Having a jenkins image that is fairly basic (it includes enough to run some basic builds, as well as jenkins itself) built on the LTS, on the latest LTS of Ubuntu seemed quite convenient - and easy to maintain using the official Ubuntu/Debian packaging of Jenkins.\n\n+\n\n+\nDocker is a great way to try and use server based systems - it brings all the dependencies needed and the images actually are portable (ie anywhere docker runs you can run docker images). There are official images for many popular server platforms (redis, mysql, all the linux distros and so on) so it seemed crazy to not include Jenkins along with this list. +\n\"docker run -p 8080:8080 jenkins\" is all you need to get going with LTS Jenkins now. +\nYou can also use \"docker run jenkins:1.554\" to get the latest of that lineage of LTS releases, or pick a specific one: \"docker run jenkins:1.554.3\" if you like. Leaving off a version assumes the latest. Check the https://registry.hub.docker.com/_/jenkins/tags/manage/[tags] page to see what is available. +\n\n+\n+\n\n+\nYou can read more and see how you https://registry.hub.docker.com/_/jenkins/[can use it here.] +\n\n+\n+\n\n+\nThere has been some questions and discussions on how to make use of Jenkins with the docker hub for creating new and interesting docker image based workflows for deployment. +\nIn fact, Jenkins featured in one of the first slides of the first keynote of docker con: +\n +\nimage:https://3.bp.blogspot.com/-qAC-f6ceVho/U5rfqpzj3VI/AAAAAAAAC8w/Ta4pzEhm-8A/s1600/Screen+Shot+2014-06-13+at+8.34.10+pm.png[image] +\n +\nTo make this dream a reality some additional https://wiki.jenkins.io/display/JENKINS/DockerHub+Plugin[plugins] had to be created - but this leaves the possibility of working with the docker hub (builds, stores images) and Jenkins (workflow, testing, deployment) to build out some kind of a continuous pipeline for handling docker based apps. I attempted to describe this more https://developer-blog.cloudbees.com/2014/07/announcing-dockerhub-jenkins-plugin.html[here]. +\n\n+\n+\n\n+\nThis image is maintained in this github https://github.com/cloudbees/jenkins-ci.org-docker[repo] and the official images are build by the https://github.com/docker/stackbrew[\"stackbrew\" system]. (We may move this repo to the jenkinsci github group shortly so keep an eye out). +\n\n+\n+\n\nIt will be interesting to watch this grow and change.\n\n+","title":"Official Jenkins LTS docker image","tags":["development","core","lts","docker"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"blog/author/kohsuke","twitter":"kohsukekawa"}]}}]}},"pageContext":{"tag":"docker","limit":8,"skip":8,"numPages":2,"currentPage":2}},
    "staticQueryHashes": ["3649515864"]}