{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/declarative",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2019-11-22T00:00:00.000Z","id":"e5f5bc1a-7d2f-5807-8b41-7478e232a4f1","slug":"/blog/2019/11/22/welcome-to-the-matrix/","strippedHtml":"I often find myself needing to run the same actions on a bunch of different configurations.\nUp to now, that meant I had to make multiple copies of the same stages in my pipelines.\nWhen I needed to make changes, I had to make the same changes in multiple places throughout my pipeline.\nMaintaining even a small number of configuration was difficult for larger pipelines.\n\nDeclarative Pipeline 1.5.0-beta1 (now available from the\nJenkins Experimental Update site) adds a new matrix section that lets me specify a list stages once and then run that same list in parallel on multiple configurations.\nLet’s take a look!\n\nSingle configuration pipeline\n\nI’ll start with a simple pipeline with build and test stages.\nI’m using echo steps as placeholders for my build and test actions.\n\nJenkinsfile\n\npipeline {\n    agent none\n    stages {\n        stage('BuildAndTest') {\n            agent any\n            stages {\n                stage('Build') {\n                    steps {\n                        echo 'Do Build'\n                    }\n                }\n                stage('Test') {\n                    steps {\n                        echo 'Do Test'\n                    }\n                }\n            }\n        }\n    }\n}\n\nPipeline for multiple platforms and browsers\n\nI’d like to run my build and tests on a combination of platforms and browsers.\nThe new matrix directive lets me specify a set of axes.\nEach axis has a name and a list of one or more values.\nWhen the pipeline is run, Jenkins will take those and run my stages on all possible combinations of values from each axis.\nAll cells in a matrix run in parallel (limited only by the number of available agents).\nStages within each cell are run sequentially.\n\nMy matrix has two axes: PLATFORM and BROWSER.\nI have three values for PLATFORM and four values for BROWSER resulting in my stages being run with twelve different combinations.\nI’ve changed my echo steps to use the axis values for each cell.\n\nJenkinsfile\n\npipeline {\n    agent none\n    stages {\n        stage('BuildAndTest') {\n            matrix {\n                agent any\n                axes {\n                    axis {\n                        name 'PLATFORM'\n                        values 'linux', 'windows', 'mac'\n                    }\n                    axis {\n                        name 'BROWSER'\n                        values 'firefox', 'chrome', 'safari', 'edge'\n                    }\n                }\n                stages {\n                    stage('Build') {\n                        steps {\n                            echo \"Do Build for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                    stage('Test') {\n                        steps {\n                            echo \"Do Test for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nLog output (truncated)\n\n...\n[Pipeline] stage\n[Pipeline] { (BuildAndTest)\n[Pipeline] parallel\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'edge') (hide)\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'edge')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'edge')\n...\nDo Build for linux - safari\nDo Build for linux - firefox\nDo Build for windows - firefox\nDo Test for linux - firefox\nDo Build for mac - firefox\nDo Build for linux - chrome\nDo Test for windows - firefox\n...\n\nExcluding invalid combinations\n\nNow that I have my basic matrix created, I’ve noticed that I have some invalid combinations.\nMicrosoft Edge only runs on Windows and there isn’t a Linux version of Safari.\n\nI can remove invalid cells from my matrix using exclude directives. Each exclude has one or more axis directives with name and values.\nThe axis directives inside an exclude generate a set of combinations (similar to generating the matrix cells).\nThe matrix cells that match all the values from an exclude combination are removed from the matrix.\nIf I have more than one exclude directive, each are evaluated separately to remove cells.\n\nWhen dealing with a long lists of values to exclude, I can use notValues instead of values to specify axis values we don’t want excluded.\nYes, that’s a double negative, so it can get a little confusing.\nI try to use it only when I really need it.\n\nIn my sample pipeline below, I specifically exclude the linux, safari combination and I also exclude any platform that is not windows with the edge browser.\n\nThis pipeline uses two axes but there is no limit on the number of axis directives.\n\nAlso, in this pipeline each exclude specifies values for both axes, but that is not required.\nIf we wanted to run only \"linux\" cells, we could use the following exclude :\n\nexclude {\n    axis {\n        name 'PLATFORM'\n        notValues 'linux'\n    }\n}\n\npipeline {\n    agent none\n    stages {\n        stage('BuildAndTest') {\n            matrix {\n                agent any\n                axes {\n                    axis {\n                        name 'PLATFORM'\n                        values 'linux', 'windows', 'mac'\n                    }\n                    axis {\n                        name 'BROWSER'\n                        values 'firefox', 'chrome', 'safari', 'edge'\n                    }\n                }\n                excludes {\n                    exclude {\n                        axis {\n                            name 'PLATFORM'\n                            values 'linux'\n                        }\n                        axis {\n                            name 'BROWSER'\n                            values 'safari'\n                        }\n                    }\n                    exclude {\n                        axis {\n                            name 'PLATFORM'\n                            notValues 'windows'\n                        }\n                        axis {\n                            name 'BROWSER'\n                            values 'edge'\n                        }\n                    }\n                }\n                stages {\n                    stage('Build') {\n                        steps {\n                            echo \"Do Build for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                    stage('Test') {\n                        steps {\n                            echo \"Do Test for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nLog output (truncated)\n\n...\n[Pipeline] stage\n[Pipeline] { (BuildAndTest)\n[Pipeline] parallel\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'edge')\n...\nDo Build for linux - firefox\n...\n\nControlling cell behavior at runtime\n\nInside the matrix directive I can also add \"per-cell\" directives.\nThese are the same directives that I would add to a stage and they let me control the behavior of each cell in the matrix.\nThese directives can use the axis values from their cell as part of their inputs, allowing me to customize the behavior of each cell to match its axis values.\n\nOn my Jenkins server I have configured agents with labels that match the OS for each agent (\"linux-agent\", \"windows-agent\", and \"mac-agent\").\nTo run each cell in my matrix on the appropriate operating system, I configure the label for that cell using Groovy string templating.\n\nmatrix {\n    axes { ... }\n    excludes { ... }\n    agent {\n        label \"${PLATFORM}-agent\"\n    }\n    stages { ... }\n    // ...\n}\n\nOccasionally I run my pipeline manually from the Jenkins Web UI.\nWhen I do that, I’d like to be able to select just one platform to run.\nThe axis and exclude directives define the static set of cells that make up the matrix.\nThat set of combinations is generated before the start of the run, before any parameters are processed.\nWhat this means is that I can’t add or remove cells from a matrix after the job has started.\n\nThe \"per-cell\" directives, on the other hand, are evaluated at runtime.\nI can use the \"per-cell\" when directive inside matrix to control which cells in the matrix are executed.\nI’ll add a choice parameter with the list of platforms, and add conditions to the when directive, which will either let all platforms execute, or only execute cells that match my selected platform.\n\npipeline {\n    parameters {\n        choice(name: 'PLATFORM_FILTER', choices: ['all', 'linux', 'windows', 'mac'], description: 'Run on specific platform')\n    }\n    agent none\n    stages {\n        stage('BuildAndTest') {\n            matrix {\n                agent {\n                    label \"${PLATFORM}-agent\"\n                }\n                when { anyOf {\n                    expression { params.PLATFORM_FILTER == 'all' }\n                    expression { params.PLATFORM_FILTER == env.PLATFORM }\n                } }\n                axes {\n                    axis {\n                        name 'PLATFORM'\n                        values 'linux', 'windows', 'mac'\n                    }\n                    axis {\n                        name 'BROWSER'\n                        values 'firefox', 'chrome', 'safari', 'edge'\n                    }\n                }\n                excludes {\n                    exclude {\n                        axis {\n                            name 'PLATFORM'\n                            values 'linux'\n                        }\n                        axis {\n                            name 'BROWSER'\n                            values 'safari'\n                        }\n                    }\n                    exclude {\n                        axis {\n                            name 'PLATFORM'\n                            notValues 'windows'\n                        }\n                        axis {\n                            name 'BROWSER'\n                            values 'edge'\n                        }\n                    }\n                }\n                stages {\n                    stage('Build') {\n                        steps {\n                            echo \"Do Build for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                    stage('Test') {\n                        steps {\n                            echo \"Do Test for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nIf I run this Pipeline from the Jenkins UI and set the PLATFORM_FILTER parameter to mac, I’ll get something like the output below:\n\nLog output (truncated - PLATFORM_FILTER = 'mac' )\n\n...\n[Pipeline] stage\n[Pipeline] { (BuildAndTest)\n[Pipeline] parallel\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'firefox')\n[Pipeline] { (Branch: Matrix - OS = 'linux', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'chrome')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'mac', BROWSER = 'safari')\n[Pipeline] { (Branch: Matrix - OS = 'windows', BROWSER = 'edge')\n...\nStage \"Matrix - OS = 'linux', BROWSER = 'chrome'\" skipped due to when conditional\nStage \"Matrix - OS = 'linux', BROWSER = 'firefox'\" skipped due to when conditional\n...\nDo Build for mac - firefox\nDo Build for mac - chrome\nDo Build for mac - safari\n...\nStage \"Matrix - OS = 'windows', BROWSER = 'chrome'\" skipped due to when conditional\nStage \"Matrix - OS = 'windows', BROWSER = 'edge'\" skipped due to when conditional\n...\nDo Test for mac - safari\nDo Test for mac - firefox\nDo Test for mac - chrome\n\nCome join me at DevOps World | Jenkins World 2019 for \" Declarative Pipeline 2019: Tips, Tricks and What’s Next \".\nI’ll go over what’s been added to Pipeline in the last year (including matrix) and discuss ideas about where pipeline should go next.\n\nConclusion\n\nIn this blog post, we’ve looked at how to use the matrix directive to make concise but powerful declarative pipelines.\nAn equivalent pipeline created without matrix would easily be several times larger, and much harder to understand and maintain.\n\nMatrix is now available from the experimental update center.\nIt will be released to the main update center as soon as we’re done putting the finishing touches on the documentation and online help.\n\nLinks\n\nJenkins Experimental Update Center\n\nUsing the Jenkins Experimental Update Center","title":"Welcome to the Matrix","tags":["pipeline","plugins","declarative","matrix"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2018-04-09T00:00:00.000Z","id":"3494cf73-5468-5673-9163-ca20378f0110","slug":"/blog/2018/04/09/whats-in-declarative/","strippedHtml":"Last week we released the latest version of Declarative Pipelines, version\n1.2.8. With that out, we thought now would be a good time to introduce you to\nthe new features and options that have been added to Declarative since the\nbeginning of 2018. These are all available now in the Update Center, with\nversion 1.2.8.\n\nDeclarative Directive Generator\n\nThis is something we’re really happy about - if you go to the \"Pipeline Syntax\"\nlink from your Pipeline’s page in Jenkins, you’ll see a couple new links on the\nleft, including \"Declarative Directive Generator\". The Directive Generator is\nmuch like the Snippet Generator that’s been in Pipeline for a couple years now,\nbut where the Snippet Generator is just for filling out a form for a step and\ngenerating the Pipeline code that configuration maps to, the Directive\nGenerator is built to help you write your Declarative Pipeline directives, like\nagent, options, stage, and more!\n\nThis is the first release to include the Directive Generator, and it’s\ndefinitely going to see more polish going forward, but we think it should be\nquite helpful for you already. We’ll be putting up another blog post looking at\nthe Directive Generator in more detail in the near future.\n\nNew when conditions\n\nWe’ve added a number of new when conditions, providing you more control over\nwhether your stages get executed.\n\nequals - Compares two values - strings, variables, numbers, booleans - and\nreturns true if they’re equal. I’m honestly not sure how we missed adding\nthis earlier! You can do \"not equals\" comparisons using the not { equals …​\n} combination too.\n\nchangeRequest - In its simplest form, this will return true if this\nPipeline is building a change request, such as a GitHub pull request. You can\nalso do more detailed checks against the change request, allowing you to ask\n\"is this a change request against the master branch?\" and much more.\n\nbuildingTag - A simple condition that just checks if the Pipeline is\nrunning against a tag in SCM, rather than a branch or a specific commit\nreference.\n\ntag - A more detailed equivalent of buildingTag, allowing you to check\nagainst the tag name itself.\n\nIn addition, we’ve added a new option to when : beforeAgent. This allows you\nto specify that the when conditions should be evaluated before entering the\nagent for the stage, rather than the normal behavior of evaluating when\nconditions after entering the agent. When beforeAgent true is specified,\nyou will not have access to the agent’s workspace, but you can avoid\nunnecessary SCM checkouts and waiting for a valid `agent to be available. This\ncan speed up your Pipeline’s execution in some cases.\n\nNew post conditions\n\nThe changed condition has always been a bit confusing, and to be\nhonest, it wasn’t our best work. changed will fire any time the current run’s\nstatus is different than the previous run’s status - whether the current run is\nhealthier than the previous one, or the other way around. That’s…​not actually\nvery useful. So now we’ve added two new post conditions that should provide\nyou with a lot more value than changed has.\n\nfixed - This will check to see if the current run is successful, and if the\nprevious run was either failed or unstable.\n\nregression - This will check to see if the current run’s status is worse\nthan the previous run’s status. So if the previous run was successful, and\nthe current run is unstable, this will fire and its block of steps will\nexecute. It will also run if the previous run was unstable, and the current\nrun is a failure, etc.\n\nNew options\n\nThe options directive in Declarative can contain a number of different kinds\nof configuration: traditional Jenkins job properties, like buildDiscarder,\nwrapper steps to execute the entire Pipeline within, like timeout, and\nDeclarative-specific options that can switch from some default behaviors of\nDeclarative execution. We’ve added two new Declarative-specific options in the\nlast few releases.\n\ncheckoutToSubdirectory - Allows you to override the location that the\nautomatic SCM checkout will use. Using checkoutToSubdirectory(\"foo\"), your\nPipeline will checkout your repository to\"$WORKSPACE/foo\", rather than the\ndefault of\"$WORKSPACE\".\n\nnewContainerPerStage - If you’re using a top-level docker or dockerfile\nagent, and want to ensure that each of your stages run in a fresh container\nof the same image, you can use this option. Any stage without its own\nagent specified will run in a new container using the image you’ve\nspecified or built, on the same computer and with access to the same\nworkspace.\n\nStage options\n\nSometimes, you may only want to disable automatic checkout of your repository,\nusing the skipDefaultCheckout(true) option, for one specific stage in your\nPipeline. Or perhaps you want to have a timeout that covers an entire\nstage, including time spent waiting for a valid agent, post condition\nexecution, or the new input directive for stages (see further down for more\ndetails on that!). To make those things possible, we’ve added a new options\ndirection to stage. You can use a subset of the top-level options content\nin a stage’s `options - wrapper steps, and Declarative-specific options that\nare marked as legal in a stage.\n\nInput\n\nYou’ve always been able to run the input step inside a stage’s `steps\nblock, but we’ve found that approach can lose out on some of the value that the\ninput step provides.\n\nTo help with that, we’ve added a new input directive\nto stage, with the same parameters as the input step. When you use the\nstage input directive rather than using the step directly, any parameters\nyou’ve specified for the input will be made available in the stage’s\nenvironment, meaning you can reference parameters from the `input in when\nconditions, or in environment variables.\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Example') {\n            input {\n                message \"Should we continue?\"\n                ok \"Yes, we should.\"\n                submitter \"alice,bob\"\n                parameters {\n                    string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n                }\n            }\n            agent any\n            steps {\n                echo \"Hello, ${PERSON}, nice to meet you.\"\n            }\n        }\n    }\n}\n// Script //\n\nAlso, the input directive is evaluated before you enter any agent specified\non this stage, so if you are using a top-level agent none and each stage\nhas its own agent specified, you can avoid consuming an executor while\nwaiting for the input to be submitted.\n\nLastly, you can use timeout in the stage options, as\nmentioned above, to time-out the input if too much time has passed without a\nresponse.\n\nI hope you find these new features and options for Declarative Pipelines\nhelpful, and I look forward to the rest of 2018 as we continue to invest and\nimprove in Jenkins Pipeline!","title":"The new things arriving in Declarative Pipeline!","tags":["pipeline","declarative"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2017-10-02T00:00:00.000Z","id":"3c59e404-8125-5869-a3c8-98dd83976f14","slug":"/blog/2017/10/02/pipeline-templates-with-shared-libraries/","strippedHtml":"This is a guest post by Philip Stroh, Software Architect at\nTimoCom.\n\nWhen building multiple microservices - e.g. with Spring Boot - the integration\nand delivery pipelines of your services will most likely be very similar.\nSurely, you don’t want to copy-and-paste Pipeline code from one Jenkinsfile\nto another if you develop a new service or if there are adaptions in your\ndelivery process. Instead you would like to define something like a pipeline\n\"template\" that can be applied easily to all of your services.\n\nThe requirement for a common pipeline that can be used in multiple projects does not only emerge in microservice architectures. It’s valid for all areas where applications are\nbuilt on a similar technology stack or deployed in a standardized way (e.g. pre-packages as containers).\n\nIn this blog post I’d like to outline the possibility to create such a pipeline \"template\" using Jenkins Shared Libraries. If\nyou’re not yet familiar with Shared Libraries I’d recommend having a look at\nthe documentation.\n\nThe following code shows a (simplified) integration and delivery Pipeline for a\nSpring Boot application in declarative syntax.\n\nJenkinsFile\n\npipeline {\n    agent any\n    environment {\n        branch = 'master'\n        scmUrl = 'ssh://git@myScmServer.com/repos/myRepo.git'\n        serverPort = '8080'\n        developmentServer = 'dev-myproject.mycompany.com'\n        stagingServer = 'staging-myproject.mycompany.com'\n        productionServer = 'production-myproject.mycompany.com'\n    }\n    stages {\n        stage('checkout git') {\n            steps {\n                git branch: branch, credentialsId: 'GitCredentials', url: scmUrl\n            }\n        }\n\n        stage('build') {\n            steps {\n                sh 'mvn clean package -DskipTests=true'\n            }\n        }\n\n        stage ('test') {\n            steps {\n                parallel (\n                    \"unit tests\": { sh 'mvn test' },\n                    \"integration tests\": { sh 'mvn integration-test' }\n                )\n            }\n        }\n\n        stage('deploy development'){\n            steps {\n                deploy(developmentServer, serverPort)\n            }\n        }\n\n        stage('deploy staging'){\n            steps {\n                deploy(stagingServer, serverPort)\n            }\n        }\n\n        stage('deploy production'){\n            steps {\n                deploy(productionServer, serverPort)\n            }\n        }\n    }\n    post {\n        failure {\n            mail to: 'team@example.com', subject: 'Pipeline failed', body: \"${env.BUILD_URL}\"\n        }\n    }\n}\n\nThis Pipeline builds the application, runs unit as well as integration tests and deploys the application to\nseveral environments. It uses a global variable \"deploy\" that is provided within a Shared Library. The deploy method\ncopies the JAR-File to a remote server and starts the application. Through the handy REST endpoints of Spring Boot\nActuator a previous version of the application is stopped beforehand. Afterwards the deployment is verified via the\nhealth status monitor of the application.\n\nvars/deploy.groovy\n\ndef call(def server, def port) {\n    httpRequest httpMode: 'POST', url: \"http://${server}:${port}/shutdown\", validResponseCodes: '200,408'\n    sshagent(['RemoteCredentials']) {\n        sh \"scp target/*.jar root@${server}:/opt/jenkins-demo.jar\"\n        sh \"ssh root@${server} nohup java -Dserver.port=${port} -jar /opt/jenkins-demo.jar &\"\n    }\n    retry (3) {\n        sleep 5\n        httpRequest url:\"http://${server}:${port}/health\", validResponseCodes: '200', validResponseContent: '\"status\":\"UP\"'\n    }\n}\n\nThe common approach to reuse pipeline code is to put methods like \"deploy\" into\na Shared Library. If we now start developing the next application of the same\nfashion we can use this method for deployments as well. But often there are\neven more similarities within projects of one company. E.g. applications are\nbuilt, tested and deployed in the same way into the same environments\n(development, staging and production). In this case it is possible to define\nthe whole Pipeline as a global variable within a Shared Library. The next code\nsnippet defines a Pipeline \"template\" for all of our Spring Boot applications.\n\nvars/myDeliveryPipeline.groovy\n\ndef call(Map pipelineParams) {\n\n    pipeline {\n        agent any\n        stages {\n            stage('checkout git') {\n                steps {\n                    git branch: pipelineParams.branch, credentialsId: 'GitCredentials', url: pipelineParams.scmUrl\n                }\n            }\n\n            stage('build') {\n                steps {\n                    sh 'mvn clean package -DskipTests=true'\n                }\n            }\n\n            stage ('test') {\n                steps {\n                    parallel (\n                        \"unit tests\": { sh 'mvn test' },\n                        \"integration tests\": { sh 'mvn integration-test' }\n                    )\n                }\n            }\n\n            stage('deploy developmentServer'){\n                steps {\n                    deploy(pipelineParams.developmentServer, pipelineParams.serverPort)\n                }\n            }\n\n            stage('deploy staging'){\n                steps {\n                    deploy(pipelineParams.stagingServer, pipelineParams.serverPort)\n                }\n            }\n\n            stage('deploy production'){\n                steps {\n                    deploy(pipelineParams.productionServer, pipelineParams.serverPort)\n                }\n            }\n        }\n        post {\n            failure {\n                mail to: pipelineParams.email, subject: 'Pipeline failed', body: \"${env.BUILD_URL}\"\n            }\n        }\n    }\n}\n\nNow we can setup the Pipeline of one of our applications with the following method call:\n\nJenkinsfile\n\nmyDeliveryPipeline(branch: 'master', scmUrl: 'ssh://git@myScmServer.com/repos/myRepo.git',\n                   email: 'team@example.com', serverPort: '8080',\n                   developmentServer: 'dev-myproject.mycompany.com',\n                   stagingServer: 'staging-myproject.mycompany.com',\n                   productionServer: 'production-myproject.mycompany.com')\n\nThe Shared library documentation mentions the ability to encapsulate\nsimilarities between several Pipelines with a global variable. It shows how we\ncan enhance our template approach and build a higher-level DSL step:\n\nvars/myDeliveryPipeline.groovy\n\ndef call(body) {\n    // evaluate the body block, and collect configuration into the object\n    def pipelineParams= [:]\n    body.resolveStrategy = Closure.DELEGATE_FIRST\n    body.delegate = pipelineParams\n    body()\n\n    pipeline {\n        // our complete declarative pipeline can go in here\n        ...\n    }\n}\n\nNow we can even use our own DSL-step to set up the integration and deployment Pipeline of our project:\n\nJenkinsfile\n\nmyDeliveryPipeline {\n    branch = 'master'\n    scmUrl = 'ssh://git@myScmServer.com/repos/myRepo.git'\n    email = 'team@example.com'\n    serverPort = '8080'\n    developmentServer = 'dev-myproject.mycompany.com'\n    stagingServer = 'staging-myproject.mycompany.com'\n    productionServer = 'production-myproject.mycompany.com'\n}\n\nThe blog post showed how a common Pipeline template can be developed using the\nShared Library functionality in Jenkins. The approach allows to create a\nstandard Pipeline that can be reused by applications that are built in a\nsimilar way.\n\nIt works for Declarative and Scripted Pipelines as well. For declarative\npipelines the ability to define a Pipeline block in a Shared Library is\nofficial supported since version 1.2 (see the recent blog post on\nDeclarative Pipeline 1.2).","title":"Share a standard Pipeline across multiple projects with Shared Libraries","tags":["pipeline","declarative","microservices"],"authors":[{"avatar":null,"blog":null,"github":"pstrh","html":"","id":"pstrh","irc":null,"linkedin":null,"name":"Philip Stroh","slug":"/blog/authors/pstrh","twitter":null}]}},{"node":{"date":"2017-09-25T00:00:00.000Z","id":"ec7b8ed5-f69c-5e84-9b65-735961d0c5cf","slug":"/blog/2017/09/25/declarative-1.2-released/","strippedHtml":"After a few months of work on its key features, I’m happy to announce the\n1.2 release of\nDeclarative Pipeline!\nOn behalf of the contributors developing Pipeline, I thought it would be\nhelpful to discuss three of the key changes.\n\nParallel Stages\n\nFirst, we’ve added syntax support for parallel stages. In earlier versions of\nDeclarative Pipeline, the only way to run chunks of Pipeline code in parallel\nwas to use the parallel step inside the steps block for a stage, like this:\n\n/* .. snip .. */\nstage('run-parallel-branches') {\n  steps {\n    parallel(\n      a: {\n        echo \"This is branch a\"\n      },\n      b: {\n        echo \"This is branch b\"\n      }\n    )\n  }\n}\n/* .. snip .. */\n\nWhile this works, it doesn’t integrate well with the rest of the Declarative\nPipeline syntax. For example, to run each parallel branch on a different agent,\nyou need to use a node step, and if you do that, the output of the parallel\nbranch won’t be available for post directives (at a stage or pipeline\nlevel). Basically the old parallel step required you to use Scripted Pipeline\nwithin a Declarative Pipeline.\n\nBut now with Declarative Pipeline 1.2, we’ve introduced a true Declarative\nsyntax for running stages in parallel:\n\nJenkinsfile\n\npipeline {\n    agent none\n    stages {\n        stage('Run Tests') {\n            parallel {\n                stage('Test On Windows') {\n                    agent {\n                        label \"windows\"\n                    }\n                    steps {\n                        bat \"run-tests.bat\"\n                    }\n                    post {\n                        always {\n                            junit \"**/TEST-*.xml\"\n                        }\n                    }\n                }\n                stage('Test On Linux') {\n                    agent {\n                        label \"linux\"\n                    }\n                    steps {\n                        sh \"run-tests.sh\"\n                    }\n                    post {\n                        always {\n                            junit \"**/TEST-*.xml\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nYou can now specify either steps or parallel for a stage, and within\nparallel, you can specify a list of stage directives to run in parallel,\nwith all the configuration you’re used to for a stage in Declarative\nPipeline. We think this will be really useful for cross-platform builds and\ntesting, as an example. Support for parallel stages will be in the\nsoon-to-be-released Blue Ocean Pipeline Editor 1.3 as well.\n\nYou can find more documentation on parallel stages in the\nUser Handbook.\n\nDefining Declarative Pipelines in Shared Libraries\n\nUntil the 1.2 release, Declarative Pipelines did not officially support\ndefining your pipeline blocks in a shared library. Some of you may have tried\nthat out and found that it could work in some cases, but since it was never an\nofficially supported feature, it was vulnerable to breaking due to necessary\nchanges for the supported use cases of Declarative. But with 1.2, we’ve added\nofficial support for defining pipeline blocks in src/.groovy files in your\nshared libraries. Within your src/.groovy file’s call method, you can\ncall pipeline { …​ }, or possibly different pipeline { …​ } blocks\ndepending on if conditions and the like. Note that only one pipeline { …​ }\nblock can actually be executed per run - you’ll get an error if a second one\ntries to execute!\n\nMajor Improvements to Parsing and Environment Variables\n\nHopefully, you’ll never actually care about this change, but we’re very happy\nabout it nonetheless. The original approach used for actually taking the\npipeline { …​ } block and executing its contents was designed almost two\nyears ago, and wasn’t very well suited to how you all are actually using\nDeclarative Pipelines. In our attempts to work around some of those limitations,\nwe made the parsing logic even more complicated and fragile, resulting in an\nimpressive\nnumber of bugs, mainly relating to inconsistencies and bad behavior with\nenvironment variables.\n\nIn Declarative 1.2, we’ve replaced the runtime parsing logic completely with a\nfar more robust system, which also happens to fix most of those bugs at the\nsame time! While not every issue has been resolved, you may find that you can\nuse environment variables in more places, escaping is more consistent,\nWindows paths are no longer handled incorrectly, and a lot more. Again, we’re\nhoping you’ve never had the misfortune to run into any of these bugs, but if\nyou have, well, they’re fixed now, and it’s going to be a lot easier for us to\nfix any future issues that may arise relating to environment variables, when\nexpressions, and more. Also, the parsing at the very beginning of your build\nmay be about 0.5 seconds faster. =)\n\nMore to Come!\n\nWhile we don’t have any concrete plans for what will be going into Declarative\nPipelines 1.3, rest assured that we’ve got some great new features in mind, as\nwell as our continuing dedication to fixing the bugs you encounter and report.\nSo please do keep opening tickets for\nissues and feature requests. Thanks!","title":"Parallel stages with Declarative Pipeline 1.2","tags":["pipeline","declarative"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2017-02-23T00:00:00.000Z","id":"4617d4e9-51f3-58b1-8cf1-558aa14ce01d","slug":"/blog/2017/02/23/declarative-saucelabs-xunit/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the fourth post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe integrated several notification services into a Declarative Pipeline.\nWe kept our Pipeline clean and easy to understand\nby using a shared library to make a custom step called sendNotifications\nthat we called at the start and end of our Pipeline.\n\nIn this blog post, we’ll start by translating the Scripted Pipeline in the sample project I worked with\nin\n\" Browser-testing with Sauce OnDemand and Pipeline\"\nand\n\" xUnit and Pipeline\"\nto Declarative.\nWe’ll make our Pipeline clearer by adding an environment directive\nto define some environment variables, and then moving some code to a shared library.\nFinally, we’ll look at using the when directive to add simple conditional behavior to our Pipeline.\n\nSetup\n\nThe setup for this post uses the same repository as the two posts above,\nmy fork\nof the\nJS-Nightwatch.js sample project.\nI’ve once again created a branch specifically for this blog post,\nthis time called\nblog/declarative/sauce .\n\nLike the two posts above, this Pipeline will use the\nxUnit and\nSauce OnDemand plugins.\nThe xUnit plugin only needs to be installed, the Sauce OnDemand needs additional configuration.\nFollow\nSauce Labs' configuration instructions\nto create an account with Sauce Labs and add your Sauce Labs credentials to Jenkins.\nThe Sauce OnDemand plugin will automatically install\nSauce Connect\nfor us when we call it from our Pipeline.\n\nBe sure to you have the latest version of the\nSauce OnDemand plugin (1.160 or newer).\nIt has several fixes required for this post.\n\nFor a shared library, I’ve still got the one from the\nprevious post.\nTo set up this \"Global Pipeline Library,\" navigate to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", add a new library.\nThen set the name to bitwiseman-shared, point it at my repository,\nand set the default branch for the library to master.\n\nReducing Complexity with Declarative\n\nIf you’ve been following along through this series,\nthis first step will be quite familiar by now.\nWe’ll start from the Pipeline we had at the end of the xUnit post\nand translate it to Declarative.\n\n// Declarative //\npipeline {\n    agent any\n    options {\n        // Nightwatch.js supports color ouput, so wrap add his option\n        ansiColor colorMapName: 'XTerm'\n    }\n    stages {\n        stage (\"Build\") {\n            steps {\n                // Install dependencies\n                sh 'npm install'\n            }\n        }\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e chrome,firefox,ie,edge --test tests/guineaPig.js || true\"\n                    }\n                }\n            }\n            post {\n                always {\n                    step([$class: 'XUnitBuilder',\n                        thresholds: [\n                            [$class: 'SkippedThreshold', failureThreshold: '0'],\n                            // Allow for a significant number of failures\n                            // Keeping this threshold so that overwhelming failures are guaranteed\n                            //     to still fail the build\n                            [$class: 'FailedThreshold', failureThreshold: '10']],\n                        tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n                    saucePublisher()\n                }\n            }\n        }\n    }\n// Scripted //\nnode {\n    stage \"Build\"\n    checkout scm\n\n    // Install dependencies\n    sh 'npm install'\n\n    stage \"Test\"\n    // Add sauce credentials\n    sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n        // Start sauce connect\n        sauceconnect() {\n\n            // List of browser configs we'll be testing against.\n            def platform_configs = [\n                'chrome',\n                'firefox',\n                'ie',\n                'edge'\n            ].join(',')\n\n            // Nightwatch.js supports color ouput, so wrap this step for ansi color\n            wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm']) {\n                // Run selenium tests using Nightwatch.js\n                // Ignore error codes. The junit publisher will cover setting build status.\n                sh \"./node_modules/.bin/nightwatch -e ${platform_configs} --test tests/guineaPig.js || true\"\n            }\n\n            step([$class: 'XUnitBuilder',\n                thresholds: [\n                    [$class: 'SkippedThreshold', failureThreshold: '0'],\n                    // Allow for a significant number of failures\n                    // Keeping this threshold so that overwhelming failures are guaranteed\n                    //     to still fail the build\n                    [$class: 'FailedThreshold', failureThreshold: '10']],\n                tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n            saucePublisher()\n        }\n    }\n}\n\nBlue Ocean doesn’t support displaying SauceLabs test reports yet\n(see JENKINS-42242).\nTo view the report above, I had to switch back to the stage view of this run.\n\nElevating Settings using environment\n\nEach time we’ve moved a project from Scripted Pipeline to Declarative,\nwe’ve found the cleaner format of Declarative Pipeline highlights the less\nclear parts of the existing Pipeline.\nIn this case, the first thing that jumps out at me is that the parameters of the\nSaucelabs and Nightwatch execution are hardcoded and buried down in the middle of our Pipeline.\nThis is a relatively short Pipeline, so it isn’t terribly hard to find them,\nbut as this pipeline grows and changes it would be better if those values were kept separate.\nIn Scripted, we’d have defined some variables,\nbut Declarative doesn’t allow us to define variables in the usual Groovy sense.\n\nThe environment directive let’s us set some environment variables\nand use them later in our pipeline.\nAs you’d expect, the environment directive is just a set of name-value pairs.\nEnvironment variables are accessible in Pipeline via env.variableName (or just variableName)\nand in shell scripts as standard environment variables, typically $variableName.\n\nLet’s move the list of browsers, the test filter, and the sauce credential string to environment variables.\n\nJenkinsfile\n\nenvironment {\n        saucelabsCredentialId = 'f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a'\n        sauceTestFilter = 'tests/guineaPig.js'\n        platformConfigs = 'chrome,firefox,ie,edge'\n    }\n    stages {\n        /* ... unchanged ... */\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce(saucelabsCredentialId) {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e ${env.platformConfigs} --test ${env.sauceTestFilter} || true\" (1)\n}\n                }\n            }\n            post { /* ... unchanged ... */ }\n        }\n    }\n}\n\n1\nThis double-quoted string causes Groovy to replace the variables with their\nliteral values before passing to sh.\nThis could also be written using singe-quotes:\nsh './node_modules/.bin/nightwatch -e $platformConfigs --test $sauceTestFilter || true'.\nWith a single quoted string, the string is passed as written to the shell,\nand then the shell does the variable substitution.\n\nMoving Complex Code to Shared Libraries\n\nNow that we have settings separated from the code, we can do some code clean up.\nUnlike the previous post, we don’t have any repeating code,\nbut we do have some distractions.\nThe nesting of sauce, sauceconnect, and sh nightwatch seems excessive,\nand that xUnit step is a bit ugly as well.\nLet’s move those into our shared library as custom steps with parameters.\nWe’ll change the Jenkinsfile in our main project,\nand add the custom steps to a branch named\nblog/declarative/sauce in our library repository.\n\nJenkinsfile\n\n@Library('bitwiseman-shared@blog/declarative/sauce') _\n\n/* ... unchanged ... */\n\nstage (\"Test\") {\n    steps {\n        sauceNightwatch saucelabsCredentialId,\n            platformConfigs,\n            sauceTestFilter\n    }\n    post {\n        always {\n            xUnitPublishResults 'reports/**',\n                /* failWhenSkippedExceeds */ 0,\n                /* failWhenFailedExceeds */ 10\n\n            saucePublisher()\n        }\n    }\n}\n\nvars/sauceNightwatch.groovy\n\ndef call(String sauceCredential, String platforms = null, String testFilter = null) {\n    platforms = platforms ? \"-e '\" + platforms + \"'\" : ''\n    testFilter = testFilter ? \"--test '\" + testFilter + \"'\" : ''\n\n    // Add sauce credentials\n    sauce(sauceCredential) {\n        // Start sauce connect\n        sauceconnect() {\n            // Run selenium tests using Nightwatch.js\n            // Ignore error codes. The junit publisher will cover setting build status.\n            sh \"./node_modules/.bin/nightwatch ${platforms} ${testFilter} || true\" (1)\n}\n    }\n}\n\n1\nIn this form, this could not be written using a literal single-quoted string.\nHere, platforms and testFilter are groovy variables, not environment variables.\n\nvars/xUnitPublishResults.groovy\n\ndef call(String pattern, Integer failWhenSkippedExceeds,\n        Integer failWhenFailedExceeds) {\n    step([$class: 'XUnitBuilder',\n        thresholds: [\n            [$class: 'SkippedThreshold', failureThreshold: failWhenSkippedExceeds.toString()],\n            // Allow for a significant number of failures\n            // Keeping this threshold so that overwhelming failures are guaranteed\n            //     to still fail the build\n            [$class: 'FailedThreshold', failureThreshold: failWhenFailedExceeds.toString()]],\n        tools: [[$class: 'JUnitType', pattern: pattern]]])\n}\n\nRunning Conditional Stages using when\n\nThis is a sample web testing project.\nWe probably wouldn’t deploy it like we would production code,\nbut we might still want to deploy somewhere,\nby publishing it to an artifact repository, for example.\nThis project is hosted on GitHub and uses feature branches and pull requests to make changes.\nI’d like to use the same Pipeline for feature branches, pull requests, and the master branch,\nbut I only want to deploy from master.\n\nIn Scripted, we’d wrap a stage in an if-then and check if the branch for\nthe current run is named \"master\".\nDeclarative doesn’t support that kind of general conditional behavior.\nInstead, it provides a\nwhen directive\nthat can be added to stage sections.\nThe when directive supports several types of conditions, including a branch condition,\nwhere the stage will run when the branch name matches the specified pattern.\nThat is exactly what we need here.\n\nJenkinsfile\n\nstages {\n    /* ... unchanged ... */\n    stage ('Deploy') {\n        when {\n            branch 'master'\n        }\n        steps {\n             echo 'Placeholder for deploy steps.'\n        }\n    }\n}\n\nWhen we run our Pipeline with this new stage, we get the following outputs:\n\nLog output for 'feature/test' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\nStage 'Deploy' skipped due to when conditional\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nLog output for 'master' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\n[Pipeline] echo\nPlaceholder for deploy steps.\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nConclusion\n\nI have to say, our latest Declarative Pipeline turned out extremely well.\nI think someone coming from Freestyle jobs, with little to no experience with Pipeline or Groovy,\nwould still be able to look at this Declarative Pipeline and make sense of what it is doing.\nWe’ve added new functionality to our Pipeline while making it easier to understand\nand maintain.\n\nI hope you’ve learned as much as I have during this blog series.\nI’m excited to see that even in the the short time since Declarative 1.0 was released,\nteams are already using it in make improvements similar to what those we’ve covered in this series.\nThanks for reading!\n\nLinks\n\nxUnit\n\nSauce OnDemand\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Browser testing and conditional logic in Declarative Pipeline","tags":["pipeline","plugins","xunit","nightwatch","saucelabs","selenium","declarative"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-15T00:00:00.000Z","id":"76a4ff94-6194-5d56-a94c-3287ec832681","slug":"/blog/2017/02/15/declarative-notifications/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the third post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe converted a Scripted Pipeline to a Declarative Pipeline, adding descriptive stages\nand post sections.  In one of those post blocks, we included a placeholder for\nsending notifications.\n\nIn this blog post, we’ll repeat what I did in\n\" Sending Notifications in Pipeline\nbut this time in Declarative Pipeline.\nFirst we’ll integrate calls to notification services Slack, HipChat, and Email into our Pipeline.\nThen we’ll refactor those calls into a single Step in a Shared Library, which\nwe’ll reuse as needed, keeping our Jenkinsfile concise and understandable.\n\nSetup\n\nThe setup for this post is almost the same as\nmy previous Declarative Pipeline post.\nI’ve used a new branch in\nmy fork of the\nHermann project :\nblog/declarative/notifications .\nI’d already set up a Multibranch Pipeline and pointed it at my repository,\nso the new branch will be picked up and built automatically.\n\nI still have my notification targets (where we’ll send notifications) that I created for the\n\" Sending Notifications in Pipeline\" blog post.\nTake a look at that post to review how I setup the\nSlack,\nHipChat,\nand Email-ext\nplugins to use those channels.\n\nAdding Notifications\n\nWe’ll start from the same Pipeline we had at the end of the previous post.\n\nThis Pipeline works quite well, except it doesn’t print anything at the start of\nthe run, and that final always directive only prints a message to the console log.\nLet’s start by getting the notifications working like we did in the original post.\nWe’ll just copy-and-paste the three notification steps (with different parameters)\nto get the notifications working for started, success, and failure.\n\npipeline {\n  /* ... unchanged ... */\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        slackSend (color: '#FFFF00', message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n        // send to HipChat\n        hipchatSend (color: 'YELLOW', notify: true,\n            message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n          )\n\n        // send to email\n        emailext (\n            subject: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n            body: \"\"\" STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n            recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n          )\n      }\n    }\n    /* ... unchanged ... */\n  }\n  post {\n    success {\n      slackSend (color: '#00FF00', message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'GREEN', notify: true,\n          message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n\n    failure {\n      slackSend (color: '#FF0000', message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'RED', notify: true,\n          message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n  }\n}\n\nMoving Notifications to Shared Library\n\nThis new Pipeline works and our Declarative Pipeline sends notifications; however,\nit is extremely ugly. In the original post using Scripted Pipeline,\nI defined a single method that I called at both the start and end of the pipeline.\nI’d like to do that here as well, but Declarative doesn’t support creating methods\nthat are accessible to multiple stages.\nFor this, we’ll need to turn to\nShared Libraries.\n\nShared Libraries, as the name suggests,\nlet Jenkins Pipelines share code instead of copying it to each new project.\nShared Libraries are not specific to Declarative; they were released in their\ncurrent form several months ago and were useful in Scripted Pipeline.\nDue to Declarative Pipeline’s lack of support for defining methods,\nShared Libraries take on a vital role.  They are the only supported way within\nDeclarative Pipeline to define methods or classes that we want to use in more than one stage.\n\nThe lack of support for defining methods that are accessible in multiple stages,\nis a known issue, with at least two JIRA tickets:\nJENKINS-41335 and\nJENKINS-41396.\nFor this series, I chose to stick to using features that are fully supported\nin Declarative Pipeline at this time.\nThe internet has plenty of hacked together solutions that happen to work today,\nbut I wanted to highlight current best practices and dependable solutions.\n\nSetting up a Shared Library\n\nI’ve created a simple shared library repository for this series of posts, called\njenkins-pipeline-shared.\nThe shared library functionality has too many configuration options to cover in one post.\nI’ve chosen to configure this library as a \"Global Pipeline Library,\"\naccessible from any project on my Jenkins controller.\nTo setup a \"Global Pipeline Library,\" I navigated to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", I added a new library.\nI then set the name to bitwiseman-shared, pointed it at my repository,\nand set the default branch for the library to master,\nbut I’ll override that in my Jenkinsfile.\n\nMoving the Code to the Library\n\nAdding a Step to a library involves creating a file with the name of our Step,\nadding our code to a call() method inside that file,\nand replacing the appropriate code in our Jenkinsfile with the new Step calls.\nLibraries can be set to load \"implicitly,\"\nmaking their default branch automatically available to all Pipelines,\nor they can be loaded manually using a @Library annotation.\nThe branch for implicitly loaded libraries can also be overridden using the @Library annotation.\n\nThe minimal set of dependencies for sendNotifications means we can\nbasically copy-and-paste the code from the original blog post.\nWe’ll check this change into a branch in the library named\nblog/declarative/notifications, the same as my branch in the hermann repository.\nThis will let us make changes on the master branch later without breaking this example.\nWe’ll then use the @Library directive to tell Jenkins to use that branch’s version\nof the library with this Pipeline.\n\nJenkinsfile\n\n// Declarative //\n#!groovy\n@Library('bitwiseman-shared@blog/declarative/notifications') _ (1)\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        sendNotifications 'STARTED'\n      }\n    }\n    stage ('Install') {\n      steps {\n        // install required bundles\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      sendNotifications currentBuild.result\n    }\n  }\n}\n// Scripted //\n\n1\nThe _ here is intentional.\nJava/Groovy Annotations\nsuch as @Library must be applied to an element.\nThat is often a using statement, but that isn’t needed here so by convention we use an \\_.\n\nvars/sendNotifications.groovy\n\n#!/usr/bin/env groovy\n\n/**\n * Send notifications based on build status string\n */\ndef call(String buildStatus = 'STARTED') {\n  // build status of null means successful\n  buildStatus = buildStatus ?: 'SUCCESS'\n\n  // Default values\n  def colorName = 'RED'\n  def colorCode = '#FF0000'\n  def subject = \"${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\"\n  def summary = \"${subject} (${env.BUILD_URL})\"\n  def details = \"\"\" ${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\"\n\n  // Override default values based on build status\n  if (buildStatus == 'STARTED') {\n    color = 'YELLOW'\n    colorCode = '#FFFF00'\n  } else if (buildStatus == 'SUCCESS') {\n    color = 'GREEN'\n    colorCode = '#00FF00'\n  } else {\n    color = 'RED'\n    colorCode = '#FF0000'\n  }\n\n  // Send notifications\n  slackSend (color: colorCode, message: summary)\n\n  hipchatSend (color: color, notify: true, message: summary)\n\n  emailext (\n      to: 'bitwiseman@bitwiseman.com',\n      subject: subject,\n      body: details,\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nConclusion\n\nIn this post we added notifications to our Declarative Pipeline.\nWe wanted to move our repetitive notification code into a method;\nhowever, Declarative Pipeline prevented us from defining a method in our Jenkinsfile.\nInstead, with the help of the Shared Library feature,\nwe were able to define a sendNotifications Step that we could call from our Jenkinsfile.\nThis maintained the clarity of our Pipeline and will let us easily reuse this Step in other projects.\nI was pleased to see how little the resulting Pipeline differed from where we started.\nThe changes were restricted to the start and end of the file with no reformatting elsewhere.\n\nIn the next post, we’ll cover more about shared libraries and how to\nrun Sauce OnDemand with xUnit Reporting in Declarative Pipeline.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nShared Library reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Declarative Pipeline: Notifications and Shared Libraries","tags":["tutorial","pipeline","declarative","plugins","notifications","slack","hipchat","emailext"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-15T00:00:00.000Z","id":"65c5d55a-edbc-5f25-8301-7393341de88e","slug":"/blog/2017/02/15/pipeline-editor-preview/","strippedHtml":"Back in September 2016 we announced the availability of the Blue Ocean beta\nand the forthcoming Visual Pipeline Editor. We are happy to announce that you can try\nthe Pipeline Editor preview release today.\n\nWhat is it?\n\nThe Visual Pipeline Editor is the simplest way for anyone wanting to get started with\ncreating Pipelines in Jenkins. It’s also a great way for advanced Jenkins users\nto start adopting pipeline. It allows developers to break up their pipeline into different\n stages and parallelize tasks that can occur at the same time - graphically.\n The rest is up to you.\n\nA pipeline you create visually will produce a Declarative Pipeline Jenkinsfile for you and\n the Jenkinsfile is stored within a Git repository where it is versioned with your application code.\n\nIf you are not sure what a Jenkins Pipeline or a Jenkinsfile is, why not check out the new guided tour to learn more about it?\n\nWhat are we doing next?\n\nWe are working hard to provide feature parity between the Declarative Pipeline syntax and the visual editor. The next phase is to integrate the editor into Blue Ocean so that you don’t have to leave the UI and commit the Jenkinsfile to your repository to complete authoring your pipeline.\n\nIn Blue Ocean, you will be able to edit a Jenkinsfile\nfor a branch directly from within the user interface using the Visual Pipeline Editor. When you are done authoring your pipeline, the pipeline definition will be saved back to your repository as a Jenkinsfile. You can edit the Pipeline again using the Visual Editor or from your favorite text editor.\n\nWe are hoping to deliver this level of integration into Blue Ocean and the\nVisual Pipeline Editor over the next few months, so be sure to check regularly for updates in\nthe Jenkins plugin manager.\n\nGet the Preview\n\nThe Visual Pipeline Editor is available in preview today.\n\nTo try it out today:\n\nInstall the Blue Ocean beta and Blue Ocean Pipeline Editor from the Jenkins plugin manager\n\nClick on the Open Blue Ocean button and then the Pipeline Editor in the main navigation\n\nWe are looking forward to your feedback to help make the Visual Pipeline Editor\nthe easiest way to get started with Jenkins Pipeline. To report bugs or to\nrequest features please follow the instructions on the project page.\n\nAnd don’t forget to join us on our Gitter community chat\n- drop by and say hello!","title":"Say Hello to the Blue Ocean Pipeline Editor","tags":["blueocean","editor","declarative","pipeline"],"authors":[{"avatar":null,"blog":null,"github":"i386","html":"","id":"i386","irc":null,"linkedin":null,"name":"James Dumay","slug":"/blog/authors/i386","twitter":"i386"}]}},{"node":{"date":"2017-02-10T00:00:00.000Z","id":"06a04f0b-7823-5a11-8c3a-d385a336b68c","slug":"/blog/2017/02/10/declarative-html-publisher/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the second post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious blog post,\nwe created a simple Declarative Pipeline.\nIn this blog post, we’ll go back and look at the Scripted Pipeline for the\nPublishing HTML Reports in Pipeline blog post.\nWe’ll convert that Pipeline to Declarative syntax (including properties), go\ninto more detail on the post section, and then we’ll use the agent\ndirective to switch our Pipeline to run in Docker.\n\nSetup\n\nFor this post, I’m going to use the\nblog/add-declarative/html\nbranch of\nmy fork of the\nhermann project.\nI’ve set up a Multibranch Pipeline and pointed it at my repository\nthe same as did it previous post.\nAlso the same as before, I’ve set this Pipeline’s Git configuration to\nautomatically \"Clean after checkout\".\n\nThis time we already have a Pipeline checked in.\nI’ll run it a few times to get a baseline.\n\nConverting to Declarative\n\nLet’s start by converting the Scripted Pipeline straight to Declarative.\n\n// Declarative //\npipeline {\n  agent any // <1> (2)\noptions {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10')) (3)\n}\n  stages {\n    stage ('Build') { (4)\nsteps {\n        // install required gems\n        sh 'bundle install'\n\n        // build and run tests with coverage\n        sh 'bundle exec rake build spec'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\nproperties([[$class: 'BuildDiscarderProperty',\n                strategy: [$class: 'LogRotator', numToKeepStr: '10']]]) (3)\n\nnode { (1)\nstage ('Build') { (4)\n\n// Checkout\n    checkout scm (2)\n\n// install required gems\n    sh 'bundle install'\n\n    // build and run tests with coverage\n    sh 'bundle exec rake build spec'\n\n    // Archive the built artifacts\n    archive includes: 'pkg/*.gem'\n\n    // publish html\n    publishHTML [\n        allowMissing: false,\n        alwaysLinkToLastBuild: false,\n        keepAll: true,\n        reportDir: 'coverage',\n        reportFiles: 'index.html',\n        reportName: 'RCov Report'\n      ]\n\n  }\n}\n\n1\nSelect where to run this Pipeline, in this case \"any\" agent, regardless of label.\n\n2\nDeclarative automatically performs a checkout of source code on the agent,\nwhereas Scripted Pipeline users must explicitly call checkout scm.\n\n3\nSet the Pipeline option to preserve the ten most recent runs.\nThis overrides the default behavior from the Multibranch parent of this Pipeline.\n\n4\nRun the \"Build\" stage.\n\nNow that we have this Pipeline in Declarative form, let’s take a minute to do a\nlittle clean up.  We’ll split out the bundle actions a little more and move\nsteps into logically grouped stages.  Rather than having one monolithic \"Build\"\nstage, we’ll have details for each stage.  As long as we’re prettying things\nup, let’s switch to using Blue Ocean to view our\nbuilds, as well.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\n\nUsing post sections\n\nThis looks pretty good, but if we think about it\nthe archive and publishHTML steps are really post-stage actions.\nThey should only occur when the rest of their stage succeeds.\nAs our Pipeline gets more complex we might need to add actions that always happen\neven if a stage or the Pipeline as a whole fail.\n\nIn Scripted Pipeline, we would use try-catch-finally,\nbut we cannot do that in Declarative.\nOne of the defining features of the Declarative Pipeline\nis that it does not allow script-based control structures\nsuch as for loops, if-then-else blocks, or try-catch-finally blocks.\nOf course, internally Step implementations can still contain whatever conditional logic they want,\nbut the Declarative Pipeline cannot.\n\nInstead of free-form conditional logic,\nDeclarative Pipeline provides a set of Pipeline-specific controls:\nwhen directives, which we’ll look at in\na later blog post in this series, control whether to execute the steps in a stage,\nand\npost sections\ncontrol which actions to take based on result of a single stage\nor a whole Pipeline. post supports a number of\nrun conditions,\nincluding always (execute no matter what) and changed\n(execute when the result differs from previous run).\nWe’ll use success to run archive and publishHTML when their respective stages complete.\nWe’ll also use an always block with a placeholder for sending notifications,\nwhich I’ll implement in the next blog post.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      echo \"Send notifications for result: ${currentBuild.result}\"\n    }\n  }\n}\n// Scripted //\n\nSwitching agent to run in Docker\n\nagent can actually accept\nseveral other parameters instead of any.\nWe could filter on label \"some-label\", for example,\nwhich would be the equivalent of node ('some-label') in Scripted Pipeline.\nHowever, agent also lets us just as easily switch to using a Docker container,\nwhich replaces a more complicated set of changes in Scripted Pipeline:\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  /* ... unchanged ... */\n}\n\nIf I needed to, I could add a label filter under docker\nto select a node to host the Docker container.\nI already have Docker available on all my agents, so I don’t need label -\nthis works as is.\nAs you can see below, the Docker container spins up at the start of the run\nand the pipeline runs inside it.  Simple!\n\nConclusion\n\nAt first glance, the Declarative Pipeline’s removal of control structures seems\nlike it would be too constrictive.  However, it replaces those structures with\nfacilities like the post section, that give us reasonable control over the\nflow our our Pipeline while still improving readability and maintainability.\nIn the next blog post, we’ll add notifications to this pipeline\nand look at how to use Shared Libraries with Declarative\nPipeline to share code and keep Pipelines easy to understand.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post","title":"Declarative Pipeline: Publishing HTML Reports","tags":["tutorial","pipeline","declarative","plugins","ruby"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"tag":"declarative","limit":8,"skip":0,"numPages":2,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}