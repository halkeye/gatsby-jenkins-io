{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/plugins/page/7",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-08-07T00:00:00.000Z","id":"7ba8b0b9-e907-55d4-a2a2-ca447df4c528","slug":"/blog/2017/08/07/security-advisory/","strippedHtml":"Multiple Jenkins plugins received updates today that fix several security vulnerabilities, including multiple high severity ones.\n\nWe strongly recommend updating the following plugins as soon as possible:\n\nBlue Ocean\n\nPipeline: Groovy Plugin\n\nScript Security Plugin\n\nLess severe security updates have been released for these plugins:\n\nConfig File Provider Plugin\n\nDatadog Plugin\n\nDeploy to container Plugin\n\nDRY Plugin\n\nPipeline: Input Step Plugin\n\nStatic Analysis Utilities Plugin\n\nAdditionally, the OWASP Dependency-Check Plugin recently also received a security update.\n\nFor an overview of what was fixed, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important future notifications related to Jenkins security.","title":"Important security updates for multiple Jenkins plugins","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2017-07-10T00:00:00.000Z","id":"8686ea9f-8c07-53fb-867e-e9ea74741ecf","slug":"/blog/2017/07/10/security-advisory/","strippedHtml":"Multiple Jenkins plugins received updates today that fix several security vulnerabilities, including high severity ones:\n\nDocker Commons Plugin\n\nGit Plugin\n\nGitHub Branch Source Plugin\n\nParameterized Trigger Plugin\n\nPeriodic Backup Plugin\n\nPipeline: Build Step Plugin\n\nPipeline: Groovy Plugin\n\nPoll SCM Plugin\n\nRole-based Authorization Strategy Plugin\n\nScript Security Plugin\n\nSidebar Link Plugin\n\nSubversion Plugin\n\nAdditionally, the SSH Plugin received a security update a few days ago.\n\nFor an overview of what was fixed, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for multiple Jenkins plugins","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2017-04-11T00:00:00.000Z","id":"a9284a81-2902-5a91-9618-c11ceca70747","slug":"/blog/2017/04/11/new-cli/","strippedHtml":"In response to the zero-day vulnerability we fixed in November, I wrote the following:\n\nMoving forward, the Jenkins security team is revisiting the design of the Jenkins CLI over the coming weeks to prevent this class of vulnerability in the future.\nIf you are interested in participating in that discussion, please join in on the jenkinsci-dev@ mailing list.\n\nIn early February, several project contributors met after FOSDEM for a one day hackathon.\nI looked into the feasibility of a purely SSH-based CLI.\nWhile I considered the experiment to be a success, it was far from ready to be used in a production environment.\n\nA few weeks later, long-time contributor and Jenkins security team member Jesse Glick took over, and published a detailed proposal for a new, simple CLI protocol without remoting.\n\nIn just a month, he implemented his proposal, and I’m very happy to announce that this new implementation of the Jenkins CLI has now made it into 2.54!\n\nExisting jenkins-cli.jar clients should continue working as before, unless an administrator disables the remoting connection mode in Configure Global Security.\nThat said, we recommend you download the new jenkins-cli.jar in Jenkins, and use its new -http mode.\nWith few (now deprecated) exceptions, CLI commands work like before.\nThis will allow you to disable the remoting mode for the CLI on the Jenkins controller to prevent similar vulnerabilities in the future.\n\nSSH-based CLI use should be unaffected by this change.\nNote that new Jenkins instances now start with the SSH server port disabled, and the configuration option for that was moved into Configure Global Security.\n\nYou can learn all about the CLI and its new behavior in the Jenkins handbook.","title":"New, safer CLI in 2.54","tags":["plugins","security","remoting"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2017-04-10T00:00:00.000Z","id":"2ff77860-9123-5dcf-b79a-b4d987a5169e","slug":"/blog/2017/04/10/security-advisory/","strippedHtml":"These are not security fixes you can apply blindly. We strongly recommend you read this post, as well as the security advisory to understand what the vulnerabilities are, whether and how they affect you, and what to expect when upgrading plugins.\n\nMultiple Jenkins plugins received updates today that fix several security vulnerabilities or other security-related issues:\n\nEmail Extension (Email-ext)\n\nEnvironment Injector (EnvInject)\n\nExtensible Choice Parameter\n\nGroovy\n\nJob DSL\n\nLockable Resources\n\nMatrix Authorization\n\nRole Strategy\n\nWarnings\n\nWe also included some plugins that received security fixes in the past that haven’t been mentioned in a security advisory before:\n\nActive Choices (uno-choice)\n\nExtended Choice Parameter\n\nGroovy Postbuild\n\nGroovy Label Assignment\n\nAdditionally, we included other plugins in the advisory that are not getting updated today, but whose vulnerabilities are similar to those of plugins getting fixed.\nIn total, over 30 plugins are part of the advisory.\n\nWhile there are fixes for other vulnerabilities as well, the majority of the advisory (and the rest of this blog post) is about arbitrary code execution vulnerabilities in Jenkins plugins.\n\nBackground\n\nJenkins administrators have long been able to use the Groovy script console and related functionality to execute arbitrary code in Jenkins for diagnostic or otherwise administrative purposes.\nRather than having to rely on plugins implementing the desired functionality, experienced Jenkins admins were able to run a number of scripts as needed to implement various administrative features.\n\nThis bled over into plugins:\nIt’s just easy for a plugin developer to build on top of Groovy and let the users figure out exactly what they want to do.\nUnfortunately, for a long time, there was no technology in Jenkins to limit what could be done in Groovy scripts, so anywhere Groovy would be executed, arbitrary code could be executed.\n\nWe were treating this as a security issue for the first time in the fix for SECURITY-125, about two years ago, something that first required splitting off the Matrix Project type from core into a plugin, and making use of Script Security Plugin.\n\nUnfortunately, other plugins weren’t integrating with Script Security plugin.\nAnd even diligent administrators who understand the problem of arbitrary code execution via Groovy scripts may not be able to tell whether a given plugin is affected:\nIn some cases, you’d need to dive into the source code to see whether, and how, it uses Groovy in a way that can be exploited by regular users to perform actions they otherwise wouldn’t be allowed to do.\n\nAbout the advisory\n\nBroadly speaking, there are three levels of severity for scripting related vulnerabilities in Jenkins:\n\nThe lowest severity ones are those that confuse Overall/Administer and Overall/Run Scripts permissions.\nThese are irrelevant for most Jenkins instances.\nMore on that later.\n\nThe next level up are vulnerabilities that effectively grant the ability to run arbitrary scripts to users who are able to configure jobs.\nWhile these users aren’t administrators, they have a nontrivial level of permissions, so are somewhat trusted.\nThis is often a difficult configuration to adequately secure, but it’s a supported configuration, and any plugin that undermines the security of this configuration will be treated as having a vulnerability.\n\nThe most severe ones are those that require little or no access to Jenkins to successfully exploit.\nThis typically does require the Overall/Read permission to access certain endpoints, but Pipeline as Code may allow people with SCM commit access to exploit scripting related weaknesses as well.\n\nArbitrary code execution is a serious enough issue that publishing a security advisory for just a few plugins would actually be detrimental to overall security:\nMalicious users would be able to review the fixes we do publish, and try to find other plugins affected by a similar vulnerability.\n\nThe advisory issued today lists all plugins we could find that implement any arbitrary code execution vulnerability (i.e. all three levels described above).\nAs this affects over 30 plugins, many of them not actively maintained, the problem exceeds the capacity of the Jenkins security team to address them all.\n\nFor that reason, the Jenkins security team decided that we would fix as many of the plugins as we can handle, and leaving the others to their maintainers.\n\nHow to proceed\n\nWe strongly advise administrators to review the list of affected plugins in the advisory, and look for any plugins that are installed on their instances.\nIt is very likely there’s at least one plugin installed that is affected by this.\nIf you’re on Jenkins 2.40 or newer, or Jenkins LTS 2.32.2 or newer, a warning will appear that informs you about vulnerable plugins you currently have installed.\n\nOnce you’ve determined which plugins you use are included in the advisory, you need to determine whether it is something that affects your particular setup.\n\nIf the vulnerability confuses Overall/Administer and Overall/Run Scripts, but all administrators of your Jenkins instance are able to run scripts anyway, this vulnerability is not a problem for you.\nThis is the case in the vast majority of Jenkins instances.\nOnly custom setups, typically to allow for hosted Jenkins services, don’t grant Overall/Run Scripts permission to administrators.\n\nIf the vulnerability allows users with the permission to e.g. configure jobs to execute arbitrary code, it is only a problem if there are users that have the lower permission (e.g. Item/Configure) but not the higher ( Overall/Run Scripts).\nSimple authorization strategies like Logged in users can do anything are therefore not affected by this issue.\n\nEven vulnerabilities that require no notable permissions in Jenkins may have prerequisites to be exploitable.\nFor example, Overall/Read access may be required, but only granted to users who are also administrators, or in Pipeline as Code setups, everyone with SCM commit access may also be a Jenkins administrator.\n\nThe above should guide your decision how urgently you should upgrade affected plugins with a fix, or disable affected plugins without a fix.\nRemember that you may decide in the future to reconfigure Jenkins in a way that makes previously irrelevant permission distinctions a huge problem, so it is not a good idea to continue using vulnerable plugin versions indefinitely.\n\nAfter deciding to upgrade a plugin, review the advisory and the plugin documentation for information about the migration.\nThe scripts provided in this GitHub repository may help you in determining whether you’re using affected features.\nIf you’re not using any of the affected features, it’s likely that there won’t be any problems and you can just upgrade.\nIf you are using affected features, you should carefully read the documentation on how the upgrade works: Affected plugin features may effectively be disabled until an administrator approves the scripts in use, potentially resulting in build failures.\n\nDistributing vulnerable plugins\n\nFinally, there’s the issue of distribution:\nThe Jenkins project historically has performed little to no oversight over the plugins that are being published.\nThis is a direct consequence of the governance document, which gives plugin maintainers a lot of control over their plugins.\n\nThat said, in exceptional circumstances, the Jenkins project can, and should, protect its users:\nIf a plugin maintainer were to upload a clearly malicious plugin, we wouldn’t stand by the side and continue distributing it.\nIn the case of plugins with known (unintended) vulnerabilities, this obviously becomes more difficult.\nThis has been discussed in the abstract a while back on the jenkinsci-dev mailing list, and the majority of participants in that discussion agreed that we should suspend distribution of vulnerable plugins if the security team doesn’t have the capacity to address the problem, and the vulnerability would remain unfixed otherwise.\n\nWe decided to temporarily suspend distribution of plugins via the Jenkins project update sites if they allow users with lower privileges (no Overall/Administer) to execute arbitrary code.\nUsers who really need to download these plugins can do so via our Artifactory Maven repository.\nOnce an affected plugin receives a fix, we’d of course resume distribution via the update sites.\n\nPlugins that mistake Overall/Administer and Overall/Run Scripts continue being distributed, albeit with a warning shown to Jenkins administrators, as the setup required for this to make a difference is pretty rare.\n\nUnfortunately, we were unable to adequately inform all plugin maintainers before publication of the advisory, so there are several plugins with fewer than 500 installations that are actively maintained but whose maintainers we didn’t contact prior to this advisory.\nFor that, I am really sorry, and can only ask for understanding from the maintainers of affected plugins.\nThe number of affected plugins and the coordination and review required simply exceeded our capabilities.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Important Scripting-related Security Advisory","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2017-03-20T00:00:00.000Z","id":"6fbbc66f-434f-5721-89f0-d9f144eac41e","slug":"/blog/2017/03/20/security-updates/","strippedHtml":"Multiple Jenkins plugins received updates today that fix several security vulnerabilities:\n\nActive Directory\n\nDistributed Fork\n\nEmail Extension (Email-ext)\n\nMailer\n\nSSH Build Agents\n\nFor an overview of what was fixed, see the security advisory.\n\nAdditionally, we also published a security notice for the following plugin and recommend that users disable and uninstall it:\n\nPipeline: Classpath Step\n\nThis plugin is not part of the Pipeline suite of plugins, despite its name. It’s installed on just several hundred instances.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for multiple Jenkins plugins","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2017-02-23T00:00:00.000Z","id":"4617d4e9-51f3-58b1-8cf1-558aa14ce01d","slug":"/blog/2017/02/23/declarative-saucelabs-xunit/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the fourth post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe integrated several notification services into a Declarative Pipeline.\nWe kept our Pipeline clean and easy to understand\nby using a shared library to make a custom step called sendNotifications\nthat we called at the start and end of our Pipeline.\n\nIn this blog post, we’ll start by translating the Scripted Pipeline in the sample project I worked with\nin\n\" Browser-testing with Sauce OnDemand and Pipeline\"\nand\n\" xUnit and Pipeline\"\nto Declarative.\nWe’ll make our Pipeline clearer by adding an environment directive\nto define some environment variables, and then moving some code to a shared library.\nFinally, we’ll look at using the when directive to add simple conditional behavior to our Pipeline.\n\nSetup\n\nThe setup for this post uses the same repository as the two posts above,\nmy fork\nof the\nJS-Nightwatch.js sample project.\nI’ve once again created a branch specifically for this blog post,\nthis time called\nblog/declarative/sauce .\n\nLike the two posts above, this Pipeline will use the\nxUnit and\nSauce OnDemand plugins.\nThe xUnit plugin only needs to be installed, the Sauce OnDemand needs additional configuration.\nFollow\nSauce Labs' configuration instructions\nto create an account with Sauce Labs and add your Sauce Labs credentials to Jenkins.\nThe Sauce OnDemand plugin will automatically install\nSauce Connect\nfor us when we call it from our Pipeline.\n\nBe sure to you have the latest version of the\nSauce OnDemand plugin (1.160 or newer).\nIt has several fixes required for this post.\n\nFor a shared library, I’ve still got the one from the\nprevious post.\nTo set up this \"Global Pipeline Library,\" navigate to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", add a new library.\nThen set the name to bitwiseman-shared, point it at my repository,\nand set the default branch for the library to master.\n\nReducing Complexity with Declarative\n\nIf you’ve been following along through this series,\nthis first step will be quite familiar by now.\nWe’ll start from the Pipeline we had at the end of the xUnit post\nand translate it to Declarative.\n\n// Declarative //\npipeline {\n    agent any\n    options {\n        // Nightwatch.js supports color ouput, so wrap add his option\n        ansiColor colorMapName: 'XTerm'\n    }\n    stages {\n        stage (\"Build\") {\n            steps {\n                // Install dependencies\n                sh 'npm install'\n            }\n        }\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e chrome,firefox,ie,edge --test tests/guineaPig.js || true\"\n                    }\n                }\n            }\n            post {\n                always {\n                    step([$class: 'XUnitBuilder',\n                        thresholds: [\n                            [$class: 'SkippedThreshold', failureThreshold: '0'],\n                            // Allow for a significant number of failures\n                            // Keeping this threshold so that overwhelming failures are guaranteed\n                            //     to still fail the build\n                            [$class: 'FailedThreshold', failureThreshold: '10']],\n                        tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n                    saucePublisher()\n                }\n            }\n        }\n    }\n// Scripted //\nnode {\n    stage \"Build\"\n    checkout scm\n\n    // Install dependencies\n    sh 'npm install'\n\n    stage \"Test\"\n    // Add sauce credentials\n    sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n        // Start sauce connect\n        sauceconnect() {\n\n            // List of browser configs we'll be testing against.\n            def platform_configs = [\n                'chrome',\n                'firefox',\n                'ie',\n                'edge'\n            ].join(',')\n\n            // Nightwatch.js supports color ouput, so wrap this step for ansi color\n            wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm']) {\n                // Run selenium tests using Nightwatch.js\n                // Ignore error codes. The junit publisher will cover setting build status.\n                sh \"./node_modules/.bin/nightwatch -e ${platform_configs} --test tests/guineaPig.js || true\"\n            }\n\n            step([$class: 'XUnitBuilder',\n                thresholds: [\n                    [$class: 'SkippedThreshold', failureThreshold: '0'],\n                    // Allow for a significant number of failures\n                    // Keeping this threshold so that overwhelming failures are guaranteed\n                    //     to still fail the build\n                    [$class: 'FailedThreshold', failureThreshold: '10']],\n                tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n            saucePublisher()\n        }\n    }\n}\n\nBlue Ocean doesn’t support displaying SauceLabs test reports yet\n(see JENKINS-42242).\nTo view the report above, I had to switch back to the stage view of this run.\n\nElevating Settings using environment\n\nEach time we’ve moved a project from Scripted Pipeline to Declarative,\nwe’ve found the cleaner format of Declarative Pipeline highlights the less\nclear parts of the existing Pipeline.\nIn this case, the first thing that jumps out at me is that the parameters of the\nSaucelabs and Nightwatch execution are hardcoded and buried down in the middle of our Pipeline.\nThis is a relatively short Pipeline, so it isn’t terribly hard to find them,\nbut as this pipeline grows and changes it would be better if those values were kept separate.\nIn Scripted, we’d have defined some variables,\nbut Declarative doesn’t allow us to define variables in the usual Groovy sense.\n\nThe environment directive let’s us set some environment variables\nand use them later in our pipeline.\nAs you’d expect, the environment directive is just a set of name-value pairs.\nEnvironment variables are accessible in Pipeline via env.variableName (or just variableName)\nand in shell scripts as standard environment variables, typically $variableName.\n\nLet’s move the list of browsers, the test filter, and the sauce credential string to environment variables.\n\nJenkinsfile\n\nenvironment {\n        saucelabsCredentialId = 'f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a'\n        sauceTestFilter = 'tests/guineaPig.js'\n        platformConfigs = 'chrome,firefox,ie,edge'\n    }\n    stages {\n        /* ... unchanged ... */\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce(saucelabsCredentialId) {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e ${env.platformConfigs} --test ${env.sauceTestFilter} || true\" (1)\n}\n                }\n            }\n            post { /* ... unchanged ... */ }\n        }\n    }\n}\n\n1\nThis double-quoted string causes Groovy to replace the variables with their\nliteral values before passing to sh.\nThis could also be written using singe-quotes:\nsh './node_modules/.bin/nightwatch -e $platformConfigs --test $sauceTestFilter || true'.\nWith a single quoted string, the string is passed as written to the shell,\nand then the shell does the variable substitution.\n\nMoving Complex Code to Shared Libraries\n\nNow that we have settings separated from the code, we can do some code clean up.\nUnlike the previous post, we don’t have any repeating code,\nbut we do have some distractions.\nThe nesting of sauce, sauceconnect, and sh nightwatch seems excessive,\nand that xUnit step is a bit ugly as well.\nLet’s move those into our shared library as custom steps with parameters.\nWe’ll change the Jenkinsfile in our main project,\nand add the custom steps to a branch named\nblog/declarative/sauce in our library repository.\n\nJenkinsfile\n\n@Library('bitwiseman-shared@blog/declarative/sauce') _\n\n/* ... unchanged ... */\n\nstage (\"Test\") {\n    steps {\n        sauceNightwatch saucelabsCredentialId,\n            platformConfigs,\n            sauceTestFilter\n    }\n    post {\n        always {\n            xUnitPublishResults 'reports/**',\n                /* failWhenSkippedExceeds */ 0,\n                /* failWhenFailedExceeds */ 10\n\n            saucePublisher()\n        }\n    }\n}\n\nvars/sauceNightwatch.groovy\n\ndef call(String sauceCredential, String platforms = null, String testFilter = null) {\n    platforms = platforms ? \"-e '\" + platforms + \"'\" : ''\n    testFilter = testFilter ? \"--test '\" + testFilter + \"'\" : ''\n\n    // Add sauce credentials\n    sauce(sauceCredential) {\n        // Start sauce connect\n        sauceconnect() {\n            // Run selenium tests using Nightwatch.js\n            // Ignore error codes. The junit publisher will cover setting build status.\n            sh \"./node_modules/.bin/nightwatch ${platforms} ${testFilter} || true\" (1)\n}\n    }\n}\n\n1\nIn this form, this could not be written using a literal single-quoted string.\nHere, platforms and testFilter are groovy variables, not environment variables.\n\nvars/xUnitPublishResults.groovy\n\ndef call(String pattern, Integer failWhenSkippedExceeds,\n        Integer failWhenFailedExceeds) {\n    step([$class: 'XUnitBuilder',\n        thresholds: [\n            [$class: 'SkippedThreshold', failureThreshold: failWhenSkippedExceeds.toString()],\n            // Allow for a significant number of failures\n            // Keeping this threshold so that overwhelming failures are guaranteed\n            //     to still fail the build\n            [$class: 'FailedThreshold', failureThreshold: failWhenFailedExceeds.toString()]],\n        tools: [[$class: 'JUnitType', pattern: pattern]]])\n}\n\nRunning Conditional Stages using when\n\nThis is a sample web testing project.\nWe probably wouldn’t deploy it like we would production code,\nbut we might still want to deploy somewhere,\nby publishing it to an artifact repository, for example.\nThis project is hosted on GitHub and uses feature branches and pull requests to make changes.\nI’d like to use the same Pipeline for feature branches, pull requests, and the master branch,\nbut I only want to deploy from master.\n\nIn Scripted, we’d wrap a stage in an if-then and check if the branch for\nthe current run is named \"master\".\nDeclarative doesn’t support that kind of general conditional behavior.\nInstead, it provides a\nwhen directive\nthat can be added to stage sections.\nThe when directive supports several types of conditions, including a branch condition,\nwhere the stage will run when the branch name matches the specified pattern.\nThat is exactly what we need here.\n\nJenkinsfile\n\nstages {\n    /* ... unchanged ... */\n    stage ('Deploy') {\n        when {\n            branch 'master'\n        }\n        steps {\n             echo 'Placeholder for deploy steps.'\n        }\n    }\n}\n\nWhen we run our Pipeline with this new stage, we get the following outputs:\n\nLog output for 'feature/test' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\nStage 'Deploy' skipped due to when conditional\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nLog output for 'master' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\n[Pipeline] echo\nPlaceholder for deploy steps.\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nConclusion\n\nI have to say, our latest Declarative Pipeline turned out extremely well.\nI think someone coming from Freestyle jobs, with little to no experience with Pipeline or Groovy,\nwould still be able to look at this Declarative Pipeline and make sense of what it is doing.\nWe’ve added new functionality to our Pipeline while making it easier to understand\nand maintain.\n\nI hope you’ve learned as much as I have during this blog series.\nI’m excited to see that even in the the short time since Declarative 1.0 was released,\nteams are already using it in make improvements similar to what those we’ve covered in this series.\nThanks for reading!\n\nLinks\n\nxUnit\n\nSauce OnDemand\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Browser testing and conditional logic in Declarative Pipeline","tags":["pipeline","plugins","xunit","nightwatch","saucelabs","selenium","declarative"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-15T00:00:00.000Z","id":"76a4ff94-6194-5d56-a94c-3287ec832681","slug":"/blog/2017/02/15/declarative-notifications/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the third post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe converted a Scripted Pipeline to a Declarative Pipeline, adding descriptive stages\nand post sections.  In one of those post blocks, we included a placeholder for\nsending notifications.\n\nIn this blog post, we’ll repeat what I did in\n\" Sending Notifications in Pipeline\nbut this time in Declarative Pipeline.\nFirst we’ll integrate calls to notification services Slack, HipChat, and Email into our Pipeline.\nThen we’ll refactor those calls into a single Step in a Shared Library, which\nwe’ll reuse as needed, keeping our Jenkinsfile concise and understandable.\n\nSetup\n\nThe setup for this post is almost the same as\nmy previous Declarative Pipeline post.\nI’ve used a new branch in\nmy fork of the\nHermann project :\nblog/declarative/notifications .\nI’d already set up a Multibranch Pipeline and pointed it at my repository,\nso the new branch will be picked up and built automatically.\n\nI still have my notification targets (where we’ll send notifications) that I created for the\n\" Sending Notifications in Pipeline\" blog post.\nTake a look at that post to review how I setup the\nSlack,\nHipChat,\nand Email-ext\nplugins to use those channels.\n\nAdding Notifications\n\nWe’ll start from the same Pipeline we had at the end of the previous post.\n\nThis Pipeline works quite well, except it doesn’t print anything at the start of\nthe run, and that final always directive only prints a message to the console log.\nLet’s start by getting the notifications working like we did in the original post.\nWe’ll just copy-and-paste the three notification steps (with different parameters)\nto get the notifications working for started, success, and failure.\n\npipeline {\n  /* ... unchanged ... */\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        slackSend (color: '#FFFF00', message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n        // send to HipChat\n        hipchatSend (color: 'YELLOW', notify: true,\n            message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n          )\n\n        // send to email\n        emailext (\n            subject: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n            body: \"\"\" STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n            recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n          )\n      }\n    }\n    /* ... unchanged ... */\n  }\n  post {\n    success {\n      slackSend (color: '#00FF00', message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'GREEN', notify: true,\n          message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n\n    failure {\n      slackSend (color: '#FF0000', message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'RED', notify: true,\n          message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n  }\n}\n\nMoving Notifications to Shared Library\n\nThis new Pipeline works and our Declarative Pipeline sends notifications; however,\nit is extremely ugly. In the original post using Scripted Pipeline,\nI defined a single method that I called at both the start and end of the pipeline.\nI’d like to do that here as well, but Declarative doesn’t support creating methods\nthat are accessible to multiple stages.\nFor this, we’ll need to turn to\nShared Libraries.\n\nShared Libraries, as the name suggests,\nlet Jenkins Pipelines share code instead of copying it to each new project.\nShared Libraries are not specific to Declarative; they were released in their\ncurrent form several months ago and were useful in Scripted Pipeline.\nDue to Declarative Pipeline’s lack of support for defining methods,\nShared Libraries take on a vital role.  They are the only supported way within\nDeclarative Pipeline to define methods or classes that we want to use in more than one stage.\n\nThe lack of support for defining methods that are accessible in multiple stages,\nis a known issue, with at least two JIRA tickets:\nJENKINS-41335 and\nJENKINS-41396.\nFor this series, I chose to stick to using features that are fully supported\nin Declarative Pipeline at this time.\nThe internet has plenty of hacked together solutions that happen to work today,\nbut I wanted to highlight current best practices and dependable solutions.\n\nSetting up a Shared Library\n\nI’ve created a simple shared library repository for this series of posts, called\njenkins-pipeline-shared.\nThe shared library functionality has too many configuration options to cover in one post.\nI’ve chosen to configure this library as a \"Global Pipeline Library,\"\naccessible from any project on my Jenkins controller.\nTo setup a \"Global Pipeline Library,\" I navigated to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", I added a new library.\nI then set the name to bitwiseman-shared, pointed it at my repository,\nand set the default branch for the library to master,\nbut I’ll override that in my Jenkinsfile.\n\nMoving the Code to the Library\n\nAdding a Step to a library involves creating a file with the name of our Step,\nadding our code to a call() method inside that file,\nand replacing the appropriate code in our Jenkinsfile with the new Step calls.\nLibraries can be set to load \"implicitly,\"\nmaking their default branch automatically available to all Pipelines,\nor they can be loaded manually using a @Library annotation.\nThe branch for implicitly loaded libraries can also be overridden using the @Library annotation.\n\nThe minimal set of dependencies for sendNotifications means we can\nbasically copy-and-paste the code from the original blog post.\nWe’ll check this change into a branch in the library named\nblog/declarative/notifications, the same as my branch in the hermann repository.\nThis will let us make changes on the master branch later without breaking this example.\nWe’ll then use the @Library directive to tell Jenkins to use that branch’s version\nof the library with this Pipeline.\n\nJenkinsfile\n\n// Declarative //\n#!groovy\n@Library('bitwiseman-shared@blog/declarative/notifications') _ (1)\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        sendNotifications 'STARTED'\n      }\n    }\n    stage ('Install') {\n      steps {\n        // install required bundles\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      sendNotifications currentBuild.result\n    }\n  }\n}\n// Scripted //\n\n1\nThe _ here is intentional.\nJava/Groovy Annotations\nsuch as @Library must be applied to an element.\nThat is often a using statement, but that isn’t needed here so by convention we use an \\_.\n\nvars/sendNotifications.groovy\n\n#!/usr/bin/env groovy\n\n/**\n * Send notifications based on build status string\n */\ndef call(String buildStatus = 'STARTED') {\n  // build status of null means successful\n  buildStatus = buildStatus ?: 'SUCCESS'\n\n  // Default values\n  def colorName = 'RED'\n  def colorCode = '#FF0000'\n  def subject = \"${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\"\n  def summary = \"${subject} (${env.BUILD_URL})\"\n  def details = \"\"\" ${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\"\n\n  // Override default values based on build status\n  if (buildStatus == 'STARTED') {\n    color = 'YELLOW'\n    colorCode = '#FFFF00'\n  } else if (buildStatus == 'SUCCESS') {\n    color = 'GREEN'\n    colorCode = '#00FF00'\n  } else {\n    color = 'RED'\n    colorCode = '#FF0000'\n  }\n\n  // Send notifications\n  slackSend (color: colorCode, message: summary)\n\n  hipchatSend (color: color, notify: true, message: summary)\n\n  emailext (\n      to: 'bitwiseman@bitwiseman.com',\n      subject: subject,\n      body: details,\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nConclusion\n\nIn this post we added notifications to our Declarative Pipeline.\nWe wanted to move our repetitive notification code into a method;\nhowever, Declarative Pipeline prevented us from defining a method in our Jenkinsfile.\nInstead, with the help of the Shared Library feature,\nwe were able to define a sendNotifications Step that we could call from our Jenkinsfile.\nThis maintained the clarity of our Pipeline and will let us easily reuse this Step in other projects.\nI was pleased to see how little the resulting Pipeline differed from where we started.\nThe changes were restricted to the start and end of the file with no reformatting elsewhere.\n\nIn the next post, we’ll cover more about shared libraries and how to\nrun Sauce OnDemand with xUnit Reporting in Declarative Pipeline.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nShared Library reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Declarative Pipeline: Notifications and Shared Libraries","tags":["tutorial","pipeline","declarative","plugins","notifications","slack","hipchat","emailext"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-10T00:00:00.000Z","id":"06a04f0b-7823-5a11-8c3a-d385a336b68c","slug":"/blog/2017/02/10/declarative-html-publisher/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the second post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious blog post,\nwe created a simple Declarative Pipeline.\nIn this blog post, we’ll go back and look at the Scripted Pipeline for the\nPublishing HTML Reports in Pipeline blog post.\nWe’ll convert that Pipeline to Declarative syntax (including properties), go\ninto more detail on the post section, and then we’ll use the agent\ndirective to switch our Pipeline to run in Docker.\n\nSetup\n\nFor this post, I’m going to use the\nblog/add-declarative/html\nbranch of\nmy fork of the\nhermann project.\nI’ve set up a Multibranch Pipeline and pointed it at my repository\nthe same as did it previous post.\nAlso the same as before, I’ve set this Pipeline’s Git configuration to\nautomatically \"Clean after checkout\".\n\nThis time we already have a Pipeline checked in.\nI’ll run it a few times to get a baseline.\n\nConverting to Declarative\n\nLet’s start by converting the Scripted Pipeline straight to Declarative.\n\n// Declarative //\npipeline {\n  agent any // <1> (2)\noptions {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10')) (3)\n}\n  stages {\n    stage ('Build') { (4)\nsteps {\n        // install required gems\n        sh 'bundle install'\n\n        // build and run tests with coverage\n        sh 'bundle exec rake build spec'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\nproperties([[$class: 'BuildDiscarderProperty',\n                strategy: [$class: 'LogRotator', numToKeepStr: '10']]]) (3)\n\nnode { (1)\nstage ('Build') { (4)\n\n// Checkout\n    checkout scm (2)\n\n// install required gems\n    sh 'bundle install'\n\n    // build and run tests with coverage\n    sh 'bundle exec rake build spec'\n\n    // Archive the built artifacts\n    archive includes: 'pkg/*.gem'\n\n    // publish html\n    publishHTML [\n        allowMissing: false,\n        alwaysLinkToLastBuild: false,\n        keepAll: true,\n        reportDir: 'coverage',\n        reportFiles: 'index.html',\n        reportName: 'RCov Report'\n      ]\n\n  }\n}\n\n1\nSelect where to run this Pipeline, in this case \"any\" agent, regardless of label.\n\n2\nDeclarative automatically performs a checkout of source code on the agent,\nwhereas Scripted Pipeline users must explicitly call checkout scm.\n\n3\nSet the Pipeline option to preserve the ten most recent runs.\nThis overrides the default behavior from the Multibranch parent of this Pipeline.\n\n4\nRun the \"Build\" stage.\n\nNow that we have this Pipeline in Declarative form, let’s take a minute to do a\nlittle clean up.  We’ll split out the bundle actions a little more and move\nsteps into logically grouped stages.  Rather than having one monolithic \"Build\"\nstage, we’ll have details for each stage.  As long as we’re prettying things\nup, let’s switch to using Blue Ocean to view our\nbuilds, as well.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\n\nUsing post sections\n\nThis looks pretty good, but if we think about it\nthe archive and publishHTML steps are really post-stage actions.\nThey should only occur when the rest of their stage succeeds.\nAs our Pipeline gets more complex we might need to add actions that always happen\neven if a stage or the Pipeline as a whole fail.\n\nIn Scripted Pipeline, we would use try-catch-finally,\nbut we cannot do that in Declarative.\nOne of the defining features of the Declarative Pipeline\nis that it does not allow script-based control structures\nsuch as for loops, if-then-else blocks, or try-catch-finally blocks.\nOf course, internally Step implementations can still contain whatever conditional logic they want,\nbut the Declarative Pipeline cannot.\n\nInstead of free-form conditional logic,\nDeclarative Pipeline provides a set of Pipeline-specific controls:\nwhen directives, which we’ll look at in\na later blog post in this series, control whether to execute the steps in a stage,\nand\npost sections\ncontrol which actions to take based on result of a single stage\nor a whole Pipeline. post supports a number of\nrun conditions,\nincluding always (execute no matter what) and changed\n(execute when the result differs from previous run).\nWe’ll use success to run archive and publishHTML when their respective stages complete.\nWe’ll also use an always block with a placeholder for sending notifications,\nwhich I’ll implement in the next blog post.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      echo \"Send notifications for result: ${currentBuild.result}\"\n    }\n  }\n}\n// Scripted //\n\nSwitching agent to run in Docker\n\nagent can actually accept\nseveral other parameters instead of any.\nWe could filter on label \"some-label\", for example,\nwhich would be the equivalent of node ('some-label') in Scripted Pipeline.\nHowever, agent also lets us just as easily switch to using a Docker container,\nwhich replaces a more complicated set of changes in Scripted Pipeline:\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  /* ... unchanged ... */\n}\n\nIf I needed to, I could add a label filter under docker\nto select a node to host the Docker container.\nI already have Docker available on all my agents, so I don’t need label -\nthis works as is.\nAs you can see below, the Docker container spins up at the start of the run\nand the pipeline runs inside it.  Simple!\n\nConclusion\n\nAt first glance, the Declarative Pipeline’s removal of control structures seems\nlike it would be too constrictive.  However, it replaces those structures with\nfacilities like the post section, that give us reasonable control over the\nflow our our Pipeline while still improving readability and maintainability.\nIn the next blog post, we’ll add notifications to this pipeline\nand look at how to use Shared Libraries with Declarative\nPipeline to share code and keep Pipelines easy to understand.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post","title":"Declarative Pipeline: Publishing HTML Reports","tags":["tutorial","pipeline","declarative","plugins","ruby"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"tag":"plugins","limit":8,"skip":48,"numPages":14,"currentPage":7}},
    "staticQueryHashes": ["3649515864"]}