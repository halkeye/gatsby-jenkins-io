{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/plugins/page/5",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2019-06-21T00:00:00.000Z","id":"b06db1a3-a822-5949-960f-cb7f3e69c3da","slug":"/blog/2019/06/21/performance-testing-jenkins/","strippedHtml":"I have been working on improving the performance of the Role Strategy Plugin as a part of my Google Summer of Code project.\nSince there was no existing way to measure performance and do benchmarks on Jenkins Plugins,\nmy work for the first phase of the project was to create a framework for running\nbenchmarks in Jenkins plugins with a Jenkins instance available. To make our job a bit easier,\nwe chose Java Microbenchmark Harness for running these benchmarks. This\nallows us to reliably measure performance of our time-critical functions and will help make Jenkins perform faster\nfor everyone.\n\nThe micro-benchmarking framework was recently released in the Jenkins Unit Test Harness 2.50.\nThe blog post below shows how to run benchmarks in your plugins.\n\nIntroduction\n\nThe framework runs works by starting a temporary Jenkins instance for each fork of the JMH benchmark,\njust like JenkinsRule from Jenkins Test Harness. Benchmarks are run directly from your JUnit Tests which allows\nyou to fail builds on the fly and easily run benchmarks from your IDE, just like unit tests. You can easily\nconfigure your benchmarks by either using your Java methods, or by using Jenkins Configuration-as-Code plugin\nand passing the path to your YAML file.\n\nTo run benchmarks from your plugins, you need to do the following:\n\nbump up the minimum required Jenkins version to 2.60.3 or above\n\nbump Plugin-POM to a version ≥ 3.46 or manually upgrade to Jenkins Test Harness ≥ 2.51.\n\nNow, to run the benchmarks, you need to have a benchmark runner that contains a @Test so it can run\nlike a JUnit test. From inside a test method, you can use the OptionsBuilder provided by JMH to\nconfigure your benchmarks. For example:\n\npublic class BenchmarkRunner {\n    @Test\n    public void runJmhBenchmarks() throws Exception {\n        ChainedOptionsBuilder options = new OptionsBuilder()\n                .mode(Mode.AverageTime)\n                .forks(2)\n                .result(\"jmh-report.json\");\n\n        // Automatically detect benchmark classes annotated with @JmhBenchmark\n        new BenchmarkFinder(getClass()).findBenchmarks(options);\n        new Runner(options.build()).run();\n    }\n}\n\nSample benchmarks\n\nNow, you can write your first benchmark:\n\nWithout any special setup\n\n@JmhBenchmark\npublic class JmhStateBenchmark {\n    public static class MyState extends JmhBenchmarkState {\n    }\n\n    @Benchmark\n    public void benchmark(MyState state) {\n        // benchmark code goes here\n        state.getJenkins().setSystemMessage(\"Hello world\");\n    }\n}\n\nUsing Configuration as Code\n\nTo use configuration as code, apart from the dependencies above you also need to add the following\nto your pom.xml :\n\nio.jenkins\nconfiguration-as-code\n1.21\ntrue\n\nio.jenkins\nconfiguration-as-code\n1.21\ntests\ntest\n\nNow configuring a benchmark is as simple as providing path to your YAML file and specifying the class\ncontaining the benchmark state.\n\n@JmhBenchmark\npublic class SampleBenchmark {\n    public static class MyState extends CascJmhBenchmarkState {\n        @NonNull\n        @Override\n        protected String getResourcePath() {\n            return \"config.yml\";\n        }\n\n        @NonNull\n        @Override\n        protected Class getEnclosingClass() {\n            return SampleBenchmark.class;\n        }\n    }\n\n    @Benchmark\n    public void benchmark(MyState state) {\n        Jenkins jenkins = state.getJenkins(); // jenkins is configured and ready to be benchmarked.\n        // your benchmark code goes here...\n    }\n}\n\nMore Samples\n\nAs a part of this project, a few benchmarks have been created in the Role Strategy Plugin which show\nconfiguring the instances for various situations. You can find them\nhere.\n\nRunning Benchmarks\n\nRunning benchmarks from Maven\n\nTo easily run benchmarks from Maven, a Maven profile to run the benchmarks has been created\nand is available starting Plugin-POM version 3.45. You can then run your benchmarks from the\ncommand line using mvn test -Dbenchmark.\n\nRunning benchmarks on ci.jenkins.io\n\nIf you have your plugins hosted on ci.jenkins.io, you can easily run benchmarks directly from your Jenkinsfile\nby using the runBenchmarks() method after the buildPlugin() step in your which is now available in\nJenkins Pipeline library.\nThis function also accepts the path to your generated JMH benchmark reports as an optional\nparameter and archives the benchmark results. Running benchmarks in pull request builds allows you to constantly\nmonitor the performance implications of a given change. For example, the Jenkinsfile from Role Strategy Plugin:\n\nbuildPlugin()\nrunBenchmarks('jmh-report.json')\n\nVisualizing benchmark results\n\nBenchmark reports generated (in JSON) can be visualized using the either the JMH Report Plugin\nor by passing the benchmark reports to the JMH visualizer web service. As an example, here is\na visualized report of some benchmarks from the Role Strategy Plugin:\n\nThese improvements seen above were obtained through a small pull request\nto the plugin and shows how even seemingly small changes can bring major performance improvements. Microbenchmarks\nhelp to find these hot-spots and estimate the impact of changes.\n\nSome tips and tricks\n\nSince BenchmarkRunner class name in the example above does not qualify as a test according to Maven surefire plugin’s\nnaming conventions, the benchmarks will not interfere with your JUnit tests.\n\nBenchmark methods need to be annotated by @Benchmark for JMH to detect them.\n\nClasses containing benchmarks are found automatically by the BenchmarkFinder\nwhen annotated with @JmhBenchmark.\n\nA reference to the Jenkins instance is available through either JmhBenchmarkState#getJenkins() or through\nJenkins.getInstance() like you would otherwise do.\n\nJmhBenchmarkState provides setup() and tearDown() methods which can be overridden to configure the\nJenkins instance according to your benchmark’s requirements.\n\nThe benchmark builds on ci.jenkins.io are currently throttled because of the limited availability of highmem nodes.\n\nThe benchmark framework was made available in Jenkins Test Harness 2.50, it is recommended to use version 2.51 as it includes some bug fixes.\n\nLinks and Feedback\n\nIf you have any feedback, comments or questions, please feel free to reach out to me through either\nthe Role Strategy Plugin Gitter chat or through\nthe Jenkins Developer Mailing list.\n\nPresentation slides\n\nDemo at Platform SIG meeting\n\nDocumentation for the micro-benchmark framework:\n\nWriting benchmarks (Jenkins Test Harness)\n\nPreconfiguring benchmarks using JCasC\n\nRunning benchmarks using Plugin POM profile\n\nBuild Step for running benchmarks on ci.jenkins.io","title":"Micro-benchmarking Framework for Jenkins Plugins","tags":["jmh","plugins","benchmark","performance","developer","gsoc","gsoc2019"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#d8d8d8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/ff5b9/abhyudayasharma.jpg","srcSet":"/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/f4523/abhyudayasharma.jpg 32w,\n/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/1e7bb/abhyudayasharma.jpg 64w,\n/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/ff5b9/abhyudayasharma.jpg 128w,\n/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/b48b6/abhyudayasharma.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/1fd06/abhyudayasharma.webp 32w,\n/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/9edd6/abhyudayasharma.webp 64w,\n/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/f5f75/abhyudayasharma.webp 128w,\n/gatsby-jenkins-io/static/a1ce355d937f34af4ad5cbf6a6d79f30/05d06/abhyudayasharma.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":142}}},"blog":null,"github":"AbhyudayaSharma","html":"<div class=\"paragraph\">\n<p>Abhyudaya is a Computer Science student at Shiv Nadar University, India.\nHe is participating in Google Summer of Code 2019 to improve the performance\nof the <a href=\"https://github.com/jenkinsci/role-strategy-plugin\">Role Strategy Plugin</a>.</p>\n</div>","id":"abhyudayasharma","irc":null,"linkedin":null,"name":"Abhyudaya Sharma","slug":"/blog/authors/abhyudayasharma","twitter":null}]}},{"node":{"date":"2019-04-03T00:00:00.000Z","id":"1e16c395-d668-5169-973c-ecab9af0f1b0","slug":"/blog/2019/04/03/security-advisory/","strippedHtml":"Today we published a security advisory that mostly informs about issues in Jenkins plugins that have no fixes.\nWhat’s going on?\n\nThe Jenkins security team triages incoming reports both to Jira and our non-public mailing list.\nOnce we’ve determined it is a plugin not maintained by any Jenkins security team members, we try to inform the plugin maintainer about the issue, offering our help in developing, reviewing, and publishing any fixes.\nSometimes the affected plugin is unmaintained, or maintainers don’t respond in a timely manner to the notifications or the followup emails we send.\n\nIn such cases, we publish security advisories informing users about these issues, even if there’s no new release with a fix.\nDoing so allows administrators to make an informed decision about the continued use of plugins with unresolved security vulnerabilities.\nToday’s advisory is overwhelmingly such an advisory.\n\nSee a plugin you love on this list and want to help out? Learn about adopting plugins.","title":"Security spring cleaning","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2019-02-06T00:00:00.000Z","id":"ed5dfb33-f5e6-565b-a671-f4ae47d2c691","slug":"/blog/2019/02/06/ssh-steps-for-jenkins-pipeline/","strippedHtml":"Pipeline-as-code or defining the deployment pipeline through code rather than manual job creation through UI, provides tremendous benefits for teams automating builds and deployment infrastructure across their environments.\n\nSource of image: https://jenkins.io/doc/book/pipeline/\n\nJenkins Pipelines\n\nJenkins is a well-known open source continuous integration and continuous deployment automation tool. With the latest 2.0 release, Jenkins introduced the Pipeline plugin that implements Pipeline-as-code. This plugin lets you define delivery pipelines using concise scripts which deal elegantly with jobs involving persistence and asynchrony.\n\nThe Pipeline-as-code’s script is also known as a Jenkinsfile.\n\nJenkinsfiles uses a domain specific language syntax based on the Groovy programming language. They are persistent files which can be checked in and version-controlled along with the rest of their project source code. This file can contain the complete set of encoded steps (steps, nodes, and stages) necessary to define the entire application life-cycle, becoming the intersecting point between development and operations.\n\nMissing piece of the puzzle\n\nOne of the most common steps defined in a basic pipeline job is the Deploy step. The deployment stage encompasses everything from publishing build artifacts to pushing code into pre-production and production environments. This deployment stage usually involves both development and operations teams logging onto various remote nodes to run commands and/or scripts to deploy code and configuration. While there are a couple of existing ssh plugins for Jenkins, they currently don’t support the functionality such as logging into nodes for pipelines. Thus, there was a need for a plugin that supports these steps.\n\nIntroducing SSH Steps\n\nRecently, our team at Cerner started working on a project to automate deployments through Jenkins pipelines to help facilitate running commands on over one thousand nodes. We looked at several options including existing plugins, internal shared Jenkins libraries, and others. In the end, we felt it was best to create and open source a plugin to fill this gap so that it can be used across Cerner and beyond.\n\nThe initial version of this new plugin SSH Steps supports the following:\n\nsshCommand : Executes the given command on a remote node.\n\nsshScript : Executes the given shell script on a remote node.\n\nsshGet : Gets a file/directory from the remote node to current workspace.\n\nsshPut : Puts a file/directory from the current workspace to remote node.\n\nsshRemove : Removes a file/directory from the remote node.\n\nUsage\n\nBelow is a simple demonstration on how to use above steps. More documentation can be found on GitHub.\n\ndef remote = [:]\nremote.name = \"node\"\nremote.host = \"node.abc.com\"\nremote.allowAnyHosts = true\n\nnode {\n    withCredentials([usernamePassword(credentialsId: 'sshUserAcct', passwordVariable: 'password', usernameVariable: 'userName')]) {\n        remote.user = userName\n        remote.password = password\n\n        stage(\"SSH Steps Rocks!\") {\n            writeFile file: 'test.sh', text: 'ls'\n            sshCommand remote: remote, command: 'for i in {1..5}; do echo -n \\\"Loop \\$i \\\"; date ; sleep 1; done'\n            sshScript remote: remote, script: 'test.sh'\n            sshPut remote: remote, from: 'test.sh', into: '.'\n            sshGet remote: remote, from: 'test.sh', into: 'test_new.sh', override: true\n            sshRemove remote: remote, path: 'test.sh'\n        }\n    }\n}\n\nConfiguring via YAML\n\nAt Cerner, we always strive to have simple configuration files for CI/CD pipelines whenever possible. With that in mind, my team built a wrapper on top of these steps from this plugin. After some design and analysis, we came up with the following YAML structure to run commands across various remote groups:\n\nconfig:\n  credentials_id: sshUserAcct\n\nremote_groups:\n  r_group_1:\n    - name: node01\n      host: node01.abc.net\n    - name: node02\n      host: node02.abc.net\n  r_group_2:\n    - name: node03\n      host: node03.abc.net\n\ncommand_groups:\n  c_group_1:\n    - commands:\n        - 'ls -lrt'\n        - 'whoami'\n    - scripts:\n        - 'test.sh'\n  c_group_2:\n    - gets:\n        - from: 'test.sh'\n          to: 'test_new.sh'\n    - puts:\n        - from: 'test.sh'\n          to: '.'\n    - removes:\n        - 'test.sh'\n\nsteps:\n  deploy:\n    - remote_groups:\n        - r_group_1\n      command_groups:\n        - c_group_1\n    - remote_groups:\n        - r_group_2\n      command_groups:\n        - c_group_2\n\nThe above example runs commands from c_group_1 on remote nodes within r_group_1 in parallel before it moves on to the next group using sshUserAcct (from the Jenkins Credentials store) to logon to nodes.\n\nShared Pipeline Library\n\nWe have created a shared pipeline library that contains a sshDeploy step to support the above mentioned YAML syntax. Below is the code snippet for the sshDeploy step from the library. The full version can be found here on Github.\n\n#!/usr/bin/groovy\ndef call(String yamlName) {\n    def yaml = readYaml file: yamlName\n    withCredentials([usernamePassword(credentialsId: yaml.config.credentials_id, passwordVariable: 'password', usernameVariable: 'userName')]) {\n        yaml.steps.each { stageName, step ->\n            step.each {\n                def remoteGroups = [:]\n                def allRemotes = []\n                it.remote_groups.each {\n                    remoteGroups[it] = yaml.remotes.\"$it\"\n                }\n\n                def commandGroups = [:]\n                it.command_groups.each {\n                    commandGroups[it] = yaml.commands.\"$it\"\n                }\n                def isSudo = false\n                remoteGroups.each { remoteGroupName, remotes ->\n                    allRemotes += remotes.collect { remote ->\n                        if(!remote.name)\n                            remote.name = remote.host\n                        remote.user = userName\n                        remote.password = password\n                        remote.allowAnyHosts = true\n                        remote.groupName = remoteGroupName\n                        remote\n                    }\n                }\n                if(allRemotes) {\n                    if(allRemotes.size() > 1) {\n                        def stepsForParallel = allRemotes.collectEntries { remote ->\n                            [\"${remote.groupName}-${remote.name}\" : transformIntoStep(stageName, remote.groupName, remote, commandGroups)]\n                        }\n                        stage(stageName) {\n                            parallel stepsForParallel\n                        }\n                    } else {\n                        def remote = allRemotes.first()\n                        stage(stageName + \"\\n\" + remote.groupName + \"-\" + remote.name) {\n                            transformIntoStep(stageName, remote.groupName, remote, commandGroups).call()\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nBy using the step (as described in the snippet above) from this shared pipeline library, a Jenkinsfile can be reduced to:\n\n@Library('ssh_deploy') _\n\nnode {\n  checkout scm\n  sshDeploy('dev/deploy.yml');\n}\n\nAn example execution of the above pipeline code in Blue Ocean looks like this:\n\nWrapping up\n\nSteps from the SSH Steps Plugin are deliberately generic enough that they can be used for various other use-cases as well, not just for deploying code. Using SSH Steps has significantly reduced the time we spend on deployments and has given us the possibility of easily scaling our deployment workflows to various environments.\n\nHelp us make this plugin better by contributing. Whether it is adding or suggesting a new feature, bug fixes, or simply improving documentation, contributions are always welcome.","title":"SSH Steps for Jenkins Pipeline","tags":["pipeline","plugins","ssh","steps"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg","srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/77b35/nrayapati.jpg 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/d4a57/nrayapati.jpg 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/68974/nrayapati.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/ef6ff/nrayapati.webp 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/8257c/nrayapati.webp 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/6766a/nrayapati.webp 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/22bfc/nrayapati.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"nrayapati","html":"<div class=\"paragraph\">\n<p>Software Architect at <a href=\"https://www.cerner.com/\">Cerner Corporation</a>. Passionate about Agile, DevOps &amp; Continuous Delivery, and all things Automation.\nOSS Contributor, he is maintaining couple of Jenkins plugins since past several years. <a href=\"https://plugins.jenkins.io/ssh-steps\">SSH Steps</a> - <a href=\"https://plugins.jenkins.io/jira-steps\">JIRA Steps</a> - <a href=\"https://plugins.jenkins.io/hubot-steps\">Hubot Steps</a></p>\n</div>","id":"nrayapati","irc":null,"linkedin":null,"name":"Naresh Rayapati","slug":"/blog/authors/nrayapati","twitter":"nrayapati"}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"e4121dfc-f5a5-57b7-b1e0-733189f8140a","slug":"/blog/2018/08/17/code-coverage-api-plugin-1.0-release/","strippedHtml":"I am happy to announce availability of Code Coverage API. These plugins have been recently released as 1.0, and they are now available in the Jenkins Update Center. In this blogpost I will introduce the features and project structure of Code Coverage API plugin.\n\nMy name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.\n\nOverview\n\nCode Coverage API plugin is one of GSoC 2018 Jenkins projects.\n\nThere are a lot of plugins which currently implement code coverage; however, they all use similar config, charts, and content. So it would be much better if we could have an API plugin which does the most repeated work for those plugins and offers a unified API which can be consumed by other plugins and external tools.\n\nMy mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.\n\nSupported Coverage Formats\n\nEmbedded\n\nJaCoCo\n\nOther plugins as an Extension of Code Coverage API plugin\n\nCobertura ( Cobertura Plugin)\n\nllvm-cov ( llvm-cov Plugin)\n\nFeatures\n\nModernized coverage chart\n\nCoverage trend\n\nSource code navigation\n\nParallel pipeline support\n\nReports combining\n\nREST API\n\nFailed conditions and flexible threshold setting\n\nOther small features\n\nModernized Coverage Chart\n\nIn the summary chart we can see the coverage summary of current coverage metric.\n\nIn the child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size. If we want to see coverage details of the child, we can click the child name to see more information.\n\nCoverage Trend\n\nWe also support coverage trend to show coverage metrics changing between builds.\n\nSource Code Navigation\n\nYou can enable source code navigation by specifying Source File Storing Level to save last build source files (enable source files navigation in current and last build) or save all build source files (enable source files navigation in all builds).\n\nYou can see source file with coverage information on File level coverage page.\n\nParallel Pipeline Support\n\nWe support parallel pipeline. You can call the Code Coverage API plugin in different branches like this:\n\nnode {\n    parallel firstBranch: {\n        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')]\n}, secondBranch: {\n        publishCoverage adapters: [jacocoAdapter('jacoco.xml')]\n    }\n}\n\nReports Combining\n\nYou can add tag on publishCoverage and Code Coverage API plugin will combine reports have same tag\n\nnode {\n    parallel firstBranch: {\n        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')], tag: ‘t’\n}, secondBranch: {\n        publishCoverage adapters: [jacocoAdapter('jacoco.xml')], tag: ‘t’\n    }\n}\n\nREST API\n\nWe provide a REST API to retrieve coverage data:\n\nCoverage result:…​/{buildNumber}/coverage/…​/result/api/\\{json|xml\\}\n\nTrend result:…​/{buildNumber}/coverage/…​/trend/api/\\{json|xml\\}\n\nCoverage result of last build:…​/{buildNumber}/coverage/…​/last/result/api/\\{json|xml\\}\n\nTrend result of last build:…​/{buildNumber}/coverage/…​/last/trend/api/\\{json|xml\\}\n\nFailed Conditions and Flexible Threshold Setting\n\nYou can set different failed conditions and threholds to control build result.\n\nIf the thresholds satisfy the failed conditions, it will fail the build.\n\nOther Small Features\n\nWe also have other small features like auto detecting reports, coverage filters, etc. You can find more information about these features in the plugin documentation.\n\nArchitecture\n\nThis API plugin will mainly do these things:\n\nFind coverage reports according to the user’s config.\n\nUse adapters to convert reports into the our standard format.\n\nParse standard format reports, and aggregate them.\n\nShow parsed result in a chart.\n\nSo, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing - convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.\n\nThe below diagram show the architecture of Code Coverage API plugin\n\nImplementing a New Coverage Plugin\n\nWe can implement a coverage plugin by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement JaCoCo simple like this:\n\npublic final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {\n\n    @DataBoundConstructor\n    public JacocoReportAdapter(String path) {\n        super(path);\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getXSL() {\n        return \"jacoco-to-standard.xsl\";\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getXSD() {\n        return null;\n    }\n\n    @Symbol(\"jacoco\")\n    @Extension\n    public static final class JacocoReportAdapterDescriptor extends JavaCoverageReportAdapterDescriptor {\n\n        public JacocoReportAdapterDescriptor() {\n            super(JacocoReportAdapter.class);\n        }\n\n        @NonNull\n        @Override\n        public String getDisplayName() {\n            return Messages.JacocoReportAdapter_displayName();\n        }\n    }\n}\n\nAll we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our standard format. There are also other extension points which are under development.\n\nIf you want implement a new coverage format that we did not provide abstract layer, you need to register `CoverageElement`s and implement an simple parser. See llvm-cov Plugin to get more details.\n\nFuture Tasks\n\nSupport more coverage tools ( JENKINS-52467, JENKINS-52469 and etc.)\n\nMake the UI extensible ( JENKINS-51738)\n\nImprove performance ( JENKINS-52982)\n\nPhase 3 Presentation Slides\n\nPhase 3 Presentation Video\n\nLinks\n\nJIRA Component\n\nProject Page\n\nProject Repository","title":"Code Coverage API plugin: 1.0 Release","tags":["plugins","gsoc","gsoc2018"],"authors":[{"avatar":null,"blog":null,"github":"cizezsy","html":"<div class=\"paragraph\">\n<p>Shenyu comes from China. He is a third year student now, and his major is\nComputer Science and technology. He has participated in GSoC 2018 for\n<a href=\"https://jenkins.io/projects/gsoc/2018/code-coverage-api-plugin/\">Code Coverage API Plugin</a></p>\n</div>","id":"shenyu_zheng","irc":"cizezsy","linkedin":null,"name":"Shenyu Zheng","slug":"/blog/authors/shenyu_zheng","twitter":null}]}},{"node":{"date":"2018-07-23T00:00:00.000Z","id":"c28896d2-8e68-54bb-a656-dea6d6148131","slug":"/blog/2018/07/23/remoting-kafka-plugin-1.0-release/","strippedHtml":"I am very excited to announce that we have recently released 1.0 version of Remoting Kafka Plugin under Jenkins Plugin. You can check the CHANGELOG to see the features included in this release.\n\nAbout me\n\nMy name is Pham Vu Tuan, I am a final year undergraduate student from Singapore. This is the first time I participate in Google Summer of Code and contribute to an open-source organization.\n\nMentors\n\nI have GSoC mentors who help me in this project Oleg Nenashev and Supun Wanniarachchi. Besides that, I also receive great support from developers in remoting project Devin Nusbaum and Jeff Thompson.\n\nOverview\n\nCurrent versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.\n\nThis project aims to develop a plugin in order to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins.\n\nBenefits to the community\n\nProvide a new method to connect agent to controller using Kafka besides existing methods such as JNLP or SSH Build Agents plugin.\n\nHelp to resolve the existing issues with the TCP protocol between controller and agent communication in Jenkins.\n\nHelp to resolve traffic prioritization and multi-agent communications issue in Jenkins.\n\nWhy Kafka?\n\nWhen planning for this project, we want to use traditional message queue system such as ActiveMQ or RabbitMQ. However, after some discussion, we decided to have a try with Kafka with more suitable features with this project:\n\nKafka itself is not a queue like ActiveMQ or RabbitMQ, it is a distributed, replicated commit log. This helps to remove message delivery complexity we have in traditional queue system.\n\nWe need to support data streaming as a requirement, and Kafka is good at this aspect, which RabbitMQ is lack of.\n\nKafka is said to have a better scalability and good support from the development community.\n\nArchitecture Overview\n\nThe project consists of multiple components:\n\nKafka Client Library - new command transport implementation, producer and consumer client logic.\n\nRemoting Kafka Plugin - plugin implementation with KafkaGlobalConfiguration, KafkaComputerLauncher and KafkaSecretManager.\n\nRemoting Kafka Agent - A custom JAR agent with remoting JAR packaged together with a custom Engine implementation to setup a communication channel with Kafka. The agent is also packaged as a Docker image in DockerHub.\n\nAll the components are packaged together with Docker Compose.\n\nThe below diagram is the overview of the current architecture:\n\nWith this design, controller is not communicating with agent using direct TCP communication anymore, all the communication commands are transfered with Kafka.\n\nFeatures\n\nThe project is now under the third coding phase and we have some features available in 1.0 release.\n\n1. Kafka Global Configuration with support of credentials plugin to store secrets.\n\n2. Launch agent with Kafka Launcher.\n\n3. Launch agent from CLI using agent JAR with secret provided to ensure security.\n\n4. Run jobs, pipeline using Kafka agent.\n\n5. Kafka communication between controller and agent.\n\nRemoting operations are being executed over Kafka. In the log you may see:\n\nCommand execution (SlaveInstallerFactoryImpl.isWindows())\n\nClassloading (Classloader.fetch())\n\nLog streaming (Pipe.chunk())\n\nHow to run demo\n\nWe have setup a ready-to-fly demo for this plugin. You can try to run a demo of the plugin by following this instruction.\nFeatures in the demo:\n\nDocker Compose starts preconfigured controller and agent instance, they connect automatically using Kafka launcher.\n\nKafka is secured and encrypted with SSL.\n\nThere few demo jobs in the instance so that a user can launch a job on the agent.\n\nKakfa Manager supported in localhost:9000 to support monitoring of Kafka cluster.\n\nPhase 2 Presentation Slides\n\nPhase 2 Presentation Video\n\nLinks\n\nGitHub Repository\n\nWiki\n\nPlugin Site\n\nProject Info\n\nIntroduction Blogpost\n\nPhase 1 Evaluation Slides\n\nPhase 2 Evaluation Slides\n\nPhase 1 Evaluation Video\n\nPhase 2 Evaluation Video","title":"Remoting Kafka Plugin 1.0: A new method to connect agents","tags":["plugins","gsoc","gsoc2018","remoting","kafka"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg","srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/77b35/pvtuan10.jpg 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/d4a57/pvtuan10.jpg 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/ef6ff/pvtuan10.webp 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/8257c/pvtuan10.webp 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/6766a/pvtuan10.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"pvtuan10","html":"<div class=\"paragraph\">\n<p>Pham Vu Tuan is a developer from Singapore.\nHe starts contributing to Jenkins from Google Summer of Code 2018 for <a href=\"https://jenkins.io/projects/gsoc/2018/remoting-over-message-bus/\">Jenkins Remoting over Message Bus/Queue</a></p>\n</div>","id":"pvtuan10","irc":"pvtuan10","linkedin":null,"name":"Pham Vu Tuan","slug":"/blog/authors/pvtuan10","twitter":null}]}},{"node":{"date":"2018-07-05T00:00:00.000Z","id":"b1c89781-ce73-5eec-8d31-bf7f51174f63","slug":"/blog/2018/07/05/remoting-over-message-bus-alpha-release/","strippedHtml":"I am happy to announce that we have recently released an alpha version of Remoting Kafka Plugin to the Experimental Update Center. You can check the CHANGELOG to see the features included in this initial release.\n\nOverview\n\nCurrent versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.\n\nRemoting Kafka Plugin is a plugin developed under Jenkins Google Summer of Code 2018. The plugin is developed to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins. A quick introduction of the project can be found in this introduction blogpost.\n\nHow to use the plugin?\n\nThe instructions to run the plugin in alpha version are written here. Feel free to have a try and let us know your feedback on Gitter or the mailing list.\n\nLinks\n\nAlpha Changelog\n\nIntroduction Blogpost\n\nGitHub Repository\n\nProject Page\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Update: Alpha release of Remoting Kafka Plugin","tags":["plugins","gsoc","gsoc2018","remoting","alpha-release"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg","srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/77b35/pvtuan10.jpg 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/d4a57/pvtuan10.jpg 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/ef6ff/pvtuan10.webp 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/8257c/pvtuan10.webp 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/6766a/pvtuan10.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"pvtuan10","html":"<div class=\"paragraph\">\n<p>Pham Vu Tuan is a developer from Singapore.\nHe starts contributing to Jenkins from Google Summer of Code 2018 for <a href=\"https://jenkins.io/projects/gsoc/2018/remoting-over-message-bus/\">Jenkins Remoting over Message Bus/Queue</a></p>\n</div>","id":"pvtuan10","irc":"pvtuan10","linkedin":null,"name":"Pham Vu Tuan","slug":"/blog/authors/pvtuan10","twitter":null}]}},{"node":{"date":"2018-06-18T00:00:00.000Z","id":"88647b04-059d-549e-a712-a9dfe1d2427e","slug":"/blog/2018/06/18/remoting-over-message-bus/","strippedHtml":"About me\n\nMy name is Pham Vu Tuan, I am a final year undergraduate student from Singapore. This is the first time I participate in Google Summer of Code and contribute to an open-source organization. I am very excited to contribute this summer.\n\nMentors\n\nI have GSoC mentors who help me in this project Oleg Nenashev and Supun Wanniarachchi. Besides that, I also receive great support from developers in remoting project Devin Nusbaum and Jeff Thompson.\n\nOverview\n\nCurrent versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.\n\nThis project aims to develop a plugin in order to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins.\n\nWhy Kafka?\n\nWhen planning for this project, we want to use traditional message queue system such as ActiveMQ or RabbitMQ. However, after some discussion, we decided to have a try with Kafka with more suitable features with this project:\n\nKafka itself is not a queue like ActiveMQ or RabbitMQ, it is a distributed, replicated commit log. This helps to remove message delivery complexity we have in traditional queue system.\n\nWe need to support data streaming as a requirement, and Kafka is good at this aspect, which RabbitMQ is lack of.\n\nKafka is said to have a better scalability and good support from the development community.\n\nCurrent State\n\nThe project is reaching the end of the first phase and here are things we have achieved so far:\n\nSetup project as a set of Docker Compose components: Kafka cluster, Jenkins controller (with plugin) and a custom agent (JAR).\n\nCreate a PoC with new command transport implementation to support Kafka, which involves of command invocation, RMI, classloading and data streaming.\n\nMake neccessary changes in Remoting and Jenkins core to make them extensible for the use of this project.\n\nDecide to use Kafka as a suitable final implementation.\n\nWe planned to release an alpha version of this plugin by the end of this phase, but decided to move this release to the second phase because we need to wait for remoting and core patches to be released.\n\nArchitecture Overview\n\nThe project consists of multiple components:\n\nKafka Client Library - new command transport implementation, producer and consumer client logic.\n\nRemoting Kafka Plugin - plugin implementation with KafkaGlobalConfiguration and KafkaComputerLauncher.\n\nRemoting Kafka Agent - A custom JAR agent with remoting JAR packaged together with a custom Engine implementation to setup a communication channel with Kafka.\n\nAll the components are packaged together with Docker Compose.\n\nThe below diagram is the overview of the current architecture:\n\nWith this design, controller is not communicating with agent using direct TCP communication anymore, all the communication commands are transfered with Kafka.\n\nFeatures\n\n1. Kafka Global Configuration\n\n2. Custom agent start up as a JAR\n\nUser can start running an agent with the following command:\n\n3. Launch agents with Kafka\n\n4. Commands transferred between controller and agent over Kafka\n\nRemoting operations are being executed over Kafka. In the log you may see:\n\nClassloading (Classloader.fetch())\n\nLog streaming (Pipe.chunk())\n\n5. Run jobs with remoting Kafka\n\nIt is possible to run jobs on Agents connected over Kafka\n\nNext Phase Plan\n\nHere are the tasks planned for the next phase:\n\nSupport security for controller-agent connection:\n\nKafka authentication/authorization ( JENKINS-51472, JENKINS-51473).\n\nAgent secrets ( JENKINS-51470).\n\nImprove Kafka producer-consumer model to ensure reliability ( JENKINS-51942).\n\nBug fixing.\n\nRelease alpha version and address feedback ( JENKINS-51713).\n\nHow to run demo\n\nYou can try to run a demo of the plugin by following the instruction.\n\nLinks\n\nGitHub Repository\n\nProject Page\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Intro: Jenkins Remoting over Message Bus/Queue","tags":["plugins","gsoc","gsoc2018","remoting"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg","srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/77b35/pvtuan10.jpg 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/d4a57/pvtuan10.jpg 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/ef6ff/pvtuan10.webp 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/8257c/pvtuan10.webp 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/6766a/pvtuan10.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"pvtuan10","html":"<div class=\"paragraph\">\n<p>Pham Vu Tuan is a developer from Singapore.\nHe starts contributing to Jenkins from Google Summer of Code 2018 for <a href=\"https://jenkins.io/projects/gsoc/2018/remoting-over-message-bus/\">Jenkins Remoting over Message Bus/Queue</a></p>\n</div>","id":"pvtuan10","irc":"pvtuan10","linkedin":null,"name":"Pham Vu Tuan","slug":"/blog/authors/pvtuan10","twitter":null}]}},{"node":{"date":"2018-06-13T00:00:00.000Z","id":"a1c90a56-ed3d-57e4-bd0b-1397798cc5ea","slug":"/blog/2018/06/13/code-coverage-api-plugin/","strippedHtml":"About me\n\nMy name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.\n\nI am very excited that I can participate in GSoC to work on Code Coverage API plugin with the Jenkins community and to contribute to the open source world. It is my greatest pleasure to write a plugin that many developers will use.\n\nMy mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.\n\nAbstract\n\nThere are a lot of plugins which currently implement code coverage, however, they all use similar config, charts, and content. So it will be much better if we can have an API plugin which does the most repeated work for those plugins and offers a unified APIs which can be consumed by other plugins and external tools.\n\nThis API plugin will mainly do these things:\n\nFind coverage reports according to the user’s config.\n\nUse adapters to convert reports into the our standard format.\n\nParse standard format reports, and aggregate them.\n\nShow parsed result in a chart.\n\nSo, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing — convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.\n\nCurrent Progress - Alpha Version\n\nI have developed an alpha version for this plugin. It currently integrates two different coverage tools - Cobertura and Jacoco. Also, it implements many basic functionalities like threshold, auto-detect, trend chart and so on.\n\nConfiguration Page\n\nconfig plugin\n\nWe can input the path pattern for auto detect, so that plugin will automatically find reports and group them using a corresponding converter. That makes config simpler and the user doesn’t need to fully specify the report name. Also, if we want, we can manually specify each coverage report.\n\nWe also have global and per-report threshold configurations, which makes the plugin more flexible than existing plugins (e.g. global threshold for a multi-language project that has several reports).\n\nPipeline Support\n\nIn addition to configuring the Code Coverage API plugin from the UI page, we also have pipeline support.\n\nnode {\n   publishCoverage(autoDetectPath: '**/*.xml', adapters: [jacoco(path: 'jacoco.xml')], globalThresholds: [[thresholdTarget: 'GROUPS', unhealthyThreshold: 20.0, unstableThreshold: 0.0]])\n}\n\nReport Defects\n\nAs we can see in Configuration page, we can set healthy threshold and stable threshold for each metric. The Code Coverage API plugin will report healthy score according to the healthy threshold we set.\n\nthreshold config\n\nresult\n\nAlso, we have a group of options which can fail the build if coverage falls below a particular threshold.\n\nCoverage Result Page\n\nThe coverage result page now has a modernized UI which shows coverage results more clearly.\nThe result page includes three parts - Trend chart, Summary chart, Child Summary chart.\n\nTrend Chart\n\nIn the Trend chart, we can see the coverage trend of the selected coverage metrics.\n\nSummary Chart\n\nIn the summary chart we can see the coverage summary of current coverage metric.\n\nChild Summary Chart\n\nIn the Child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size.\n\nBy using those more modernized chart components, we can easily focus on the information we want to know.\n\nExtensibility\n\nWe provide several extension points to make our plugin more extensible and flexible. Also, we have a series of abstract layers to help us implementing these extension points much easier.\n\nCoverageReportAdapter\n\nWe can implement a coverage tool by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement Jacoco simple like this:\n\npublic final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {\n\n    @DataBoundConstructor\n    public JacocoReportAdapter(String path) {\n        super(path);\n    }\n\n    @Override\n    public String getXSL() {\n        return \"jacoco-to-standard.xsl\";\n    }\n\n    @Override\n    public String getXSD() {\n        return null;\n    }\n\n    @Symbol(\"jacoco\")\n    @Extension\n    public static final class JacocoReportAdapterDescriptor extends CoverageReportAdapterDescriptor {\n\n        public JacocoReportAdapterDescriptor() {\n            super(JacocoReportAdapter.class, \"jacoco\");\n        }\n    }\n}\n\nAll we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our Java standard format. There are also other extension points which are under development.\n\nOther Extension points\n\nWe also plan to provide extension points for coverage threshold and report detector. Once it completed, we can have more control over our coverage report process.\n\nNext Phase Plan\n\nThe Alpha version now has many parts which still need to be implemented before the final release. So in next phase, I will mainly do those things.\n\nAPIs which can be used by others\n\nIntegrate Cobertura Plugin with Code Coverage API (JENKINS-51424).\n\nProvide API for getting coverage information. E.g. summary information about coverage (percentages, trends) (JENKINS-51422), (JENKINS-51423).\n\nImplementing abstract layer for other report formats like JSON. (JENKINS-51732).\n\nSupporting converters for non-Java languages. (JENKINS-51924).\n\nSupporting combining reports within a build(e.g. after parallel() execution in Pipeline) (JENKINS-51926).\n\nAdding source code navigation in Coverage Result Page (JENKINS-51988).\n\nRefactoring the configuration page to make it more user-friendly (JENKINS-51927).\n\nHow to Try It Out\n\nAlso, I have released the Alpha version in the Experimental Update Center. If you can give me some of your valuable advice about it, I will very appreciate.\n\nLinks\n\nJIRA Component\n\nProject Page\n\nProject Repository\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Intro: Code Coverage API Plugin","tags":["plugins","gsoc","gsoc2018"],"authors":[{"avatar":null,"blog":null,"github":"cizezsy","html":"<div class=\"paragraph\">\n<p>Shenyu comes from China. He is a third year student now, and his major is\nComputer Science and technology. He has participated in GSoC 2018 for\n<a href=\"https://jenkins.io/projects/gsoc/2018/code-coverage-api-plugin/\">Code Coverage API Plugin</a></p>\n</div>","id":"shenyu_zheng","irc":"cizezsy","linkedin":null,"name":"Shenyu Zheng","slug":"/blog/authors/shenyu_zheng","twitter":null}]}}]}},"pageContext":{"tag":"plugins","limit":8,"skip":32,"numPages":14,"currentPage":5}},
    "staticQueryHashes": ["3649515864"]}