{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/jenkins2",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-12-31T00:00:00.000Z","id":"3267c8fe-f10e-530a-9caa-bae9eeb34fb0","slug":"/blog/2016/12/31/what-a-year/","strippedHtml":"I do not think it is an exaggeration to say: 2016 was the best year yet for the\nJenkins project. Since the first commit in 2006, the project has reached a\nnumber of significant milestones in its ten years but we have never experienced\nthe breadth of major milestones in such a short amount of time. From\nJenkins 2\nand\nBlue Ocean\nto the\nGoogle Summer of Code\nand\nJenkins World,\n\nI wanted to take a moment and celebrate the myriad of accomplishments which\ncouldn’t have happened without the help from everybody who participates in the\nJenkins project. The 1,300+ contributors to the\njenkinsci GitHub organization,\nthe 4,000+ members of the\ndevelopers mailing list,\nthe 8,000+ members of the\nusers mailing list,\nand countless others who have reported issues, submitted pull requests, and\npresented at meetups and conferences.\n\nJenkins 2\n\nThrough the course of 2016, the Jenkins project published 16\nLTS releases\nand 54\nWeekly releases.\nOf those 70 releases, the most notable may have been the\nJenkins 2.0 release\nwhich was published in April.\n\nJenkins 2 made Pipeline as Code front-and-center in the user experience,\nintroduced a new \"Getting Started\" experience, and included a number of other\nsmall UI improvements, all while maintaining backwards compatibility with\nexisting Jenkins environments.\n\nSince April, we have released a number of LTS\nreleases using Jenkins 2 as a baseline, meaning the Jenkins project no longer\nmaintains any 1.x release lines.\n\nThe\nPipeline\nefforts have continuted to gain steam since April, covered on this blog with a\nnumber of\nposts tagged \"pipeline\". Closing out 2016 with the\nannouncement of the beta for\nDeclarative Pipeline syntax\nwhich is expected in early 2017.\n\nBlue Ocean\n\nHot on the heels of Jenkins 2 announcement\"Blue Ocean, a new user experience for Jenkins\",\nwas\nopen sourced in May.\nBlue Ocean is a new project that rethinks the user experience of Jenkins.\nDesigned from the ground up for Jenkins Pipeline and compatible with Freestyle\njobs. The goal for the project is to reduce clutter and increase clarity for\nevery member of a team using Jenkins.\n\nThe Blue Ocean beta can be installed from the Update Center and can be run in\nproduction Jenkins environments alongside the existing UI. It adds the new user experience under\n/blue in the environment but does not disturb the existing UI.\n\nBlue Ocean is expected to reach \"1.0\" in the first half of 2017.\n\nAzure\n\nAlso in May of 2016, the Jenkins project announced an exciting\nPartnership with Microsoft\nto run our project infrastructure on\nAzure. While the migration of Jenkins project\ninfrastructure into Azure is still on-going, there have been some notable\nmilestones reached already:\n\nEnd-to-end TLS encrypted delivery for Debian/openSUSE/Red Hat repositories which are\nconfigured to use https://pkg.jenkins.io by the end-user.\n\nMajor capacity improvements to\nci.jenkins.io\nproviding on-demand Ubuntu and Windows build/test infrastructure.\n\nA full continuous delivery Pipeline for all Azure-based infrastructure using\nTerraform from Jenkins.\n\nThe migration to Azure is expected to complete in 2017.\n\nGoogle Summer of Code\n\nFor the first time in the history of the project, Jenkins was accepted into\nGoogle Summer of Code\n2016. Google Summer of Code (GSoC) is an annual, international, program\nwhich encourages college-aged students to participate with open source projects\nduring the summer break between classes. Students accepted into the program\nreceive a stipend, paid by Google, to work well-defined projects to improve or\nenhance the Jenkins project.\n\nIn exchange, numerous Jenkins community members volunteered as \"mentors\" for\nstudents to help integrate them into the open source community and succeed in\ncompleting their summer projects.\n\nA lot was learned during the summer which we look forward to applying to Google\nSummer of Code 2017\n\nJenkins World\n\nIn September, over one thousand people attended\nJenkins World,\nin Santa Clara, California.\n\nFollowing the event,\nLiam\nposted a series of blog posts which highlight some of the fantastic content\nshared by Jenkins users and contributors from around the world, such as:\n\nThe demos from the \"Experts\"\n\nSessions on Scaling Jenkins\n\nUsing Jenkins Pipeline\n\nThe Contributor Summit\n\nJenkins World was the first global event of its kind for Jenkins, it brought users\nand contributors together to exchange ideas on the current state of the\nproject, celebrate accomplishments of the past year, and look ahead at all the\nexiting enhancements coming down the pipe(line).\n\nIt was such a smashing success that\nJenkins World 2017\nis already scheduled for August 30-31st in San Francisco, California.\n\nJAM\n\nFinally, 2016 saw tremendous growth in the number of\nJenkins Area Meetups\n(JAMs) hosted around the world. JAMs are local meetups intended to bring\nJenkins users and contributors together for socializing and learning. JAMs are\norganized by local Jenkins community members who have a passion for sharing new\nJenkins concepts, patterns and tools.\n\nDriven by current Jenkins Events Officer,\nAlyssa Tong,\nand the dozens of passionate organizers, JAMs have become a great way to meet\nother Jenkins users near you.\n\nWhile we don’t yet have JAMs on each of the seven continents, you can always join the\nJenkins Online Meetup.\nThough we’re hoping more groups will be founded near you in 2017!\n\nI am personally grateful for the variety and volume of contributions made by\nthousands of people to the Jenkins project this year. I believe I can speak for\nproject founder,\nKohsuke Kawaguchi,\nin stating that the Jenkins community has grown beyond our anything we could\nhave imagined five years ago, let alone ten!\n\nThere are number of ways to\nparticipate\nin the Jenkins project, so if you didn’t have an opportunity to join in during\n2016, we hope to see you next year!","title":"Thank you for an amazing 2016","tags":["jam","jenkins2","pipeline","blueocean","azure","gsoc","new-year-blogpost"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-07-14T00:00:00.000Z","id":"a5b6f4b0-0b11-53a8-a751-ef9f1b23e787","slug":"/blog/2016/07/14/2-7-1-re-release/","strippedHtml":"We created new native packages for Jenkins 2.7.1 today. These replace the existing packages. Due to a release process issue, the packaging (RPM, etc.) was created the same way as Jenkins 1.x LTS, resulting in problems starting Jenkins on some platforms: While we dropped support for AJP in Jenkins 2.0, some 1.x packages had it enabled by default, resulting in an exception during startup.\n\nThese new packages for Jenkins 2.7.1, dated July 14, have the same scripts and parameters as Jenkins 2.x and should allow starting up Jenkins without problems. If you notice any further problems with the packaging, please report them in the packaging component.","title":"New packages for Jenkins 2.7.1","tags":["jenkins2","lts"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2016-07-07T00:00:00.000Z","id":"d6aef4a7-7579-5619-b25e-5569e48f5464","slug":"/blog/2016/07/07/jenkins-2.7.1/","strippedHtml":"It’s been almost three months since we’ve released Jenkins 2.0, the first ever major version upgrade for this 10 year old project. The 2.x versions since then has been adopted by more than 20% of the users, but one segment of users who haven’t seen the benefits of Jenkins 2 is those who has been running LTS releases.\n\nBut that is no more! The new version of Jenkins LTS release we just released is 2.7.1, and now LTS users get to finally enjoy Jenkins 2.\n\nThis release also officially marks the end-of-life for Jenkins 1.x. There won’t be any future release of Jenkins 1.x beyond this point. If you are worried about the upgrade, don’t be! The core of Jenkins is still the same, and all the plugins & existing configuration will just work.","title":"Jenkins 2 hits LTS","tags":["lts","jenkins2"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg","srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/f81fe/kohsuke.jpg 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/01b1b/kohsuke.jpg 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/035c3/kohsuke.webp 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/273f8/kohsuke.webp 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/e3840/kohsuke.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":148}}},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"/blog/authors/kohsuke","twitter":"kohsukekawa"}]}},{"node":{"date":"2016-05-10T00:00:00.000Z","id":"e79a5ee4-9a52-50ad-875a-d0e23f888bab","slug":"/blog/2016/05/10/jenkins-20-vjam/","strippedHtml":"Last week we hosted our first ever\nOnline JAM with the debut\ntopic of: Jenkins 2.0. Alyssa, our\nEvents officer, and I pulled together a\nseries of\nsessions focusing on some of the most notable aspects of Jenkins 2 with:\n\nA Jenkins 2.0 keynote from project founder\nKohsuke Kawaguchi\n\nAn overview of \"Pipeline as Code\" from Patrick\nWolf\n\nA deep-dive into Pipeline and related plugins like Multibranch, etc from\nJesse Glick and\nKishore Bhatia\n\nAn overview of new user experience changes in 2.0 from\nKeith Zantow\n\nA quick lightning talk about documentation by yours truly\n\nWrapping up the sessions, was Kohsuke again, talking about the road beyond\nJenkins 2.0 and what big projects he sees on the horizon.\n\nThe event was really interesting for me, and I hope informative for those who\nparticipated in the live stream and Q&A session. I look forward to hosting more\nVirtual JAM events in the future, and I hope you will\njoin us!\n\nQuestions and Answers\n\nBelow are a collection of questions and answers, that were posed during the\nVirtual JAM. Many of these were answered during the course of the sessions, but\nfor posterity all are included below.\n\nPipeline\n\nWhat kind of DSL is used behind pipeline as code? Groovy or allow freely use\ndifferent languages as a user prefer?\n\nPipeline uses a Groovy-based domain specific language.\n\nHow do you test your very own pipeline DSL?\n\nReplay helps in testing/debugging while creating pipelines and at the branch\nlevel. There are some ideas which Jesse Glick\nhas proposed for testing Jenkinsfile and Pipeline libraries captured in\nJENKINS-33925.\n\nIsn’t \"Survive Jenkins restart\" exclusive to [CloudBees] Jenkins Enterprise?\n\nNo, this feature does not need\nCloudBees\nJenkins Enterprise. All features shown\nduring the virtual JAM are free and open source. CloudBees' Jenkins Enterprise\nproduct does support restarting from a specified stage however, and that is not\nopen source.\n\nHow well is jenkins 2.0 integrate with github for tracking job definitions?\n\nUsing the\nGitHub\nOrganization Folder plugin, Jenkins can automatically detect a Jenkinsfile in\nsource repositories to create Pipeline projects.\n\nPlease make the ability for re-run failed stages Open Source too :)\n\nThis has been passed on to our friends at CloudBees for consideration :)\n\nIf Jenkinsfile is in the repo, co-located with code, does this mean Jenkins can\nauto-detect new jobs for different branches?\n\nThis is possible using the\nPipeline Multibranch plugin.\n\nWhat documentation sources are there for Pipeline?\n\nOur documentation section contains a number of pagesaround Pipeline.\nThere is also additional documentation and examples in the plugin’s\ngit repository and the\njenkinsci/pipeline-examples\nrepository. (contributions welcome!)\n\nWhere we can find the DSL method documentation?\n\nThere is generated documentation on jenkins.io which\nincldues steps from all public plugins. Inside of a running Jenkins instance,\nyou can also navigate to\nJENKINS_URL/workflow-cps-snippetizer/dslReference\nto see the documentation for the plugins which are installed in that instance.\n\nIf Pipeline is not support some plugins (there is a lot actually), I needed\nSonarQube Runner but unfortunately it’s not supported yet, in Job DSL plugin i\ncan use \"Configure Block\" and cover any plugin via XML, how i can achieve the\nsame with a Pipeline?\n\nNot at this time\n\nIs there a possibility to create custom tooltips i.e. with a quick reference or\na link to internal project documentation? Might be useful i.e. for junior team\nmembers who need to refer to external docs.\n\nNot generally. Though in the case of Pipeline global libraries, you can create\ndescriptions of vars/functions like standardBuild in the demo, and these will\nappear in Snippet Generator under Global Variables.\n\nOh pipeline supports joining jobs? It’s really good, but I cannot find document\nat https://jenkins.io/doc/ could you tell me where is it?\n\nThere is a build step, but the Pipeline system is optimized for single-job\npipelines\n\nWe have multiple projects that we would like to follow the same pipeline.  How\nwould I write a common pipeline that can be shared across multiple projects.\n\nYou may want to look at implementing some additional steps using the\nPipeline Global\nLibrary feature. This would allow you to define\norganization-specific extensions to the Pipeline DSL to abstract away common\npatterns between projects.\n\nHow much flexibility is there with creating context / setting environment\nvariables or changing / modifying build tool options when calling a web hook /\napi to parameterize pipelines for example to target deployments to different env\nusing same pipeline\n\nVarious environment variables are exposed under the env variable in the Groovy\nDSL which would allow you to construct logic as simple or as complex as\nnecessary to achieve your goal.\n\nWhen you set up the job for the first time, does it build every branch in git,\nor is there a way to stop it from building old branches?\n\nNot at this time, the best way to prevent older branches from being built is to\nremove the Jenkinsfile in those branches. Alternatively, you could use the\n\"include\" or \"exclude\" patterns when setting up the SCM configuration of your\nmultibranch Pipeline. See also\nJENKINS-32396.\n\nSimilar to GitHub organizations, will BitBucket \"projects\" (ways of organizing\ncollections of repos) be supported?\n\nYes, these are supported via the\nBitbucket\nBranch Source plugin.\n\nHow do you handle build secrets with the pipeline plugin? Using unique\ncredentials stored in the credentials plugin per project and/or branch?\n\nThis can be accomplished by using the\nCredentials\nBinding plugin.\n\nSimilar to GitHub Orgs, are Gitlab projects supported in the same way?\n\nGitLab projects are not explicitly supported at this time, but the extension\npoints which the GitHub Organization Folder plugin uses could be extended in a\nsimilar manner for GitLab. See also JENKINS-34396\n\nIs Perforce scm supported by the Pipeline plugin?\n\nAs a SCM source for discovering a Jenkinsfile, not at this time. The\nP4\nplugin does provide some p4 steps which can be used in a Pipeline script\nhowever, see here for documentation.\n\nIs Mercurial supported with multibranch?\n\nYes, it is.\n\nCan Jenkinsfile detect when it’s running against a pull request vs an approved commit, so that it can perform a different type of build?\n\nYes, via the env variables provided in the DSL scope. Using an if statement,\none could guard specific behaviors with:\n\nif (env.CHANGE_ID != null) {\n    /* do things! */\n}\n\nLet’s say I’m building RPMs with Jenkins and use build number as an RPM\nversion/release number. Is there a way to maintain build numbers and leverage\nversioning of Jenkinsfile?\n\nThrough the env variable, it’s possible to utilize env.BUILD_NUMBER or the\nSCM commit ID, etc.\n\nLove the snippet generator! Any chance of separating it out from the pipeline\ninto a separate page on its own, available in the left nav?\n\nYes, this is tracked in\nJENKINS-31831\n\nAny tips on pre-creating the admin user credential and selecting plugins to\nautomate the Jenkins install?\n\nThere are various configuration\nmanagement modules which provide parts of this functionality.\n\nI’m looking at the pipeline syntax (in Jenkins 2.0) how do I detect a\nstep([…​]) has failed and create a notification inside the Jenkinsfile?\n\nThis can be done by wrapping a step invocation with a Groovy try/catch block.\nSee also JENKINS-28119\n\nUser Interface/Experience\n\nIs the user experience same as before when we replace the Jenkins.war(1.x to\n2.x) in an existing (with security in place) installation?\n\nYou will get the new UI features like redesigned configuration forms, but the\ninitial setup wizard will be skipped. In its stead, Jenkins will offer to\ninstall Pipeline-related functionality.\n\nIs it possible to use custom defined syntax highlighting ?\n\nWithin the Pipeline script editor itself, no. It is using the\nACE editor system,\nso it may be possible for a plugin to change the color scheme used.\n\nCan you elaborate on what the Blue Ocean UI is? Is there a link or more\ninformation on it?\n\nBlue Ocean is the name of user experience an design project, unfortunately at\nthis point in time there is not more information available on it.\n\nGeneral\n\nHow well this integrate with cloud environment?\n\nThe Jenkins controller and agents can run easily in any public cloud environment\nthat supports running Java applications. Through the\nEC2,\nJClouds,\nAzure, or\nany other plugins which extend the cloud\nextension\npoint, it is possible to dynamically provision new build agents on a configured\ncloud provider.\n\nAre help texts and other labels and messages updated for other localizations /\nlanguages as well?\n\nPractically every string in Jenkins core is localizable. The extent to which those\nstrings have been translated depends on contributors by speakers of those\nlanguages to the project. If you want to contribute translations, this\nwiki\npage should get you started.\n\nAny additional WinRM/Windows remoting functionality in 2.0?\n\nNo\n\nIs there a CLI to find all the jobs created by a specific user?\n\nNo, out-of-the-box Jenkins does not keep track of which user created which jobs.\nThe functionality provided by the\nOwnership\nplugin may be of interest though.\n\nPlease consider replacing terms like \"master\" and \"slave\" with \"primary\" and\n\"secondary\".\n\n\"slave\" has been replaced with \"agent\" in Jenkins 2.0.\n\nUpdated 2020-09-18 : The term \"master\" is being replaced with \"controller\".\n\nWe’ve been making tutorial videos on Jenkins for awhile (mostly geared toward\npassing the upcoming CCJPE). Because of that we’re using 1.625.2 (since that is\nwhat is listed on the exam), but should we instead base the videos on 2.0?\n\nAs of right now all of the\nJenkins Certification work done by CloudBees is\nfocused around the Jenkins LTS 1.625.x.","title":"Jenkins 2.0 Online JAM Wrap-up","tags":["jenkins2","jam","meetup"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-26T00:00:00.000Z","id":"8d1a1951-ad97-5021-a398-24ee5d471516","slug":"/blog/2016/04/26/jenkins-20-is-here/","strippedHtml":"Over the past 10 years, Jenkins has really\ngrown to a\nde-facto standard tool that millions of people use to handle automation in\nsoftware development and beyond.  It is quite remarkable for a project that\noriginally started as a hobby project under a different name. I’m very proud.\n\nAround this time last year,\nwe’ve\ncelebrated 10 years, 1000 plugins, and 100K installations. That was a good time\nto retrospect, and we started thinking about the next 10 years of Jenkins and\nwhat’s necessary to meet that challenge.  This project has long been on a\nweekly \"train\" release model, so it was useful to step back and think about a\nbig picture.\n\nThat is where three pillars of Jenkins 2.0 have emerged from.\n\nFirst, one of the challenges our users are facing today is that the automation\nthat happens between a commit and a production has significantly grown in its\nscope. Because of this, the clothing that used to fit (aka \"freestyle project\",\nwhich was the workhorse of Jenkins) no longer fits. We now need something that\nbetter fits today’s use cases like \"continuous delivery pipeline.\" This is why\nin 2.0 we’ve added the pipeline capability. This 2 year old effort allows you\nto describe your chain of automation in a textual form. This allows you to\nversion control it, put it alongside your source tree, etc. It is also actually\na domain specific language (DSL) of Groovy, so when your pipeline grows in\ncomplexity/sophistication, you can manage its complexity and keep it\nunderstandable far more easily.\n\nSecond, over time, Jenkins has developed the \"assembly required before initial\nuse\" feeling. As the project has grown, the frontier of interesting development\nhas shifted to plugins, which is how it should be, but we have left it up to\nusers to discover & use them. As a result, the default installation became very\nthin and minimal, and every user has to find several plugins before Jenkins\nbecomes really functional. This created a paradox of choice and unnecessarily\nhurt the user experience. In 2.0, we reset this thinking and tried to create\nmore sensible out of the box experience that solves 80% use cases for 80% of\npeople. You get something useful out of the box, and you can get some\nconsiderable mileage out of it before you start feeling the need of plugins.\nThis allows us to focus our development & QA effort around this base\nfunctionality, too. By the way, the focus on the out of the box experience\ndoesn’t stop at functionality, either. The initial security setup of Jenkins is\nimproved, too, to prevent unprotected Jenkins instances from getting abused by\nbotnets and attacks.\n\nThird, we were fortunate to have a number of developers with UX background\nspend some quality time on Jenkins, and they have made a big dent in improving\nvarious parts of Jenkins web UI. The setup wizard that implements the out of\nthe box experience improvement is one of them, and it also includes other parts\nof Jenkins that you use all the time, such as job configuration pages and new\nitem pages. This brings much needed attention to the web UI.\n\nAs you can see, 2.0 brings a lot of exciting features on the table, but this is\nan evolutionary release, built on top of the same foundation, so that your\nexisting installations can upgrade smoothly. After this initial release, we’ll\nget back to our usual weekly release march.  Improvements will be made\nto those pillars and others in coming months and years continuously. If you’d\nlike to get a more in-depth look at Jenkins 2.0, please join us in our virtual\nJenkins meetup 2.0 launch event.\n\nThank you very much for everyone who made Jenkins 2.0 possible. There are\ntoo many of you\nto thank individually, but you know who you are. I wanted to thank CloudBees in\nparticular for sponsoring the time of many of those people. Ten years ago, all I\ncould utilize was my own night & weekend time. Now I’ve got a team of smart\npeople working with me to carry this torch forward, and a big effort like 2.0\nwouldn’t have been possible without such organized effort.","title":"Jenkins 2.0 is here!","tags":["jenkins2"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg","srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/f81fe/kohsuke.jpg 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/01b1b/kohsuke.jpg 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/035c3/kohsuke.webp 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/273f8/kohsuke.webp 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/e3840/kohsuke.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":148}}},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"/blog/authors/kohsuke","twitter":"kohsukekawa"}]}},{"node":{"date":"2016-04-22T00:00:00.000Z","id":"4e17de3e-4be0-59e9-b38e-1f1bbf9188e4","slug":"/blog/2016/04/22/pipeline-2.x/","strippedHtml":"Those of you who routinely apply all plugin updates may already have noticed that the version numbers of the plugins in the Pipeline suite have switched to a 2.x scheme. Besides aligning better with the upcoming Jenkins 2.0 core release, the plugins are now being released with independent lifecycles.\n\n“Pipeline 1.15” (the last in the 1.x line) included simultaneous releases of a dozen or so plugins with the 1.15 version number (and 1.15+ dependencies on each other). All these plugins were built out of a single workflow-plugin repository. While that was convenient in the early days for prototyping wide-ranging changes, it has become an encumbrance now that the Pipeline code is fairly mature, and more people are experimenting with additions and patches.\n\nAs of 2.0, all the plugins in the system live in their own repositories on GitHub—named to match the plugin code name, which in most cases uses the historical workflow term, so for example workflow-job-plugin. Some complex steps were moved into their own plugins, such as pipeline-build-step-plugin. The 1.x changelog is closed; now each plugin keeps a changelog in its own wiki, for example here for the Pipeline Job plugin.\n\nAmong other benefits, this change makes it easier to cut new plugin releases for even minor bug fixes or enhancements, or for developers to experiment with patches to certain plugins. It also opens the door for the “aggregator” plugin (called simply Pipeline) to pull in dependencies on other plugins that seem broadly valuable, like the stage view.\n\nThe original repository has been renamed pipeline-plugin and for now still holds some documentation, which might later be moved to jenkins.io.\n\nYou need not do anything special to “move” to the 2.x line; 1.642.x and later users can just accept all Pipeline-related plugin updates. Note that if you update Pipeline Supporting APIs you must update Pipeline, or at least install/update some related plugins as noted in the wiki.","title":"Pipeline 2.x plugins","tags":["pipeline","jenkins2"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}},{"node":{"date":"2016-04-15T00:00:00.000Z","id":"fa2f2d1b-91d5-5e2e-9783-72c7059face6","slug":"/blog/2016/04/15/the-need-for-pipeline/","strippedHtml":"This is a cross-post of\nan article authored\nby Viktor Farcic on the\nCloudBees blog. Viktor is also the author\nof The DevOps 2.0 Toolkit, which\nexplores Jenkins, the Pipeline plugin, and the ecosystem\naround it in much more detail.\n\nOver the years, Jenkins has become the undisputed ruler among continuous\nintegration (CI), delivery and deployment (CD) tools. It, in a way, defined the\nCI/CD processes we use today. As a result of its leadership, many other products\nhave tried to overthrow it from its position. Among others, we got Bamboo and\nTeam City attempting to get a piece of the market. At the same time, new\nproducts emerged with a service approach (as opposed to on-premises). Some of\nthem are Travis, CircleCI and Shippable. Be that as it may, none managed to get\neven close to Jenkins' adoption. Today, depending on the source we use, Jenkins\nholds between 50-70% of the whole CI/CD tools market. The reason behind such a\nhigh percentage is its dedication to open source principles set from the very\nbeginning by Kohsuke Kawaguchi. Those same principles were the reason he forked\nJenkins from Hudson. The community behind the project, as well as commercial\nentities behind enterprise versions, are continuously improving the way it works\nand adding new features and capabilities. They are redefining not only the way\nJenkins behaves but also the CI/CD practices in a much broader sense. One of\nthose new features is the Jenkins Pipeline plugin. Before we\ndive into it, let us take a step back and discuss the reasons that led us to\ninitiate the move away from Freestyle jobs and towards the Pipeline.\n\nThe Need for Change\n\nOver time, Jenkins, like most other self-hosted CI/CD tools, tends to accumulate\na vast number of jobs. Having a lot of them causes quite an increase in\nmaintenance cost. Maintaining ten jobs is easy. It becomes a bit harder (but\nstill bearable) to manage a hundred. When the number of jobs increases to\nhundreds or even thousands, managing them becomes very tedious and time\ndemanding.\n\nIf you are not proficient with Jenkins (or other CI/CD tools) or you do not work\nfor a big project, you might think that hundreds of jobs is excessive. The truth\nis that such a number is reached over a relatively short period when teams\nare practicing continuous delivery or deployment. Let’s say that an average\nCD flow has the following set of tasks that should be run on each commit:\nbuilding, pre-deployment testing, deployment to a staging environment,\npost-deployment testing and deployment to production. That’s five groups of\ntasks that are often divided into, at least, five separate Jenkins jobs. In\nreality, there are often more than five jobs for a single CD flow, but let\nus keep it an optimistic estimate. How many different CD flows does a medium\nsized company have? With twenty, we are already reaching a three digits\nnumber. That’s quite a lot of  jobs to cope with even though the estimates\nwe used are too optimistic for all but the smallest entities.\n\nNow, imagine that we need to change all those jobs from, let’s say, Maven to\nGradle. We can choose to start modifying them through the Jenkins UI, but that\ntakes too much time. We can apply changes directly to Jenkins XML files that\nrepresent those jobs but that is too complicated and error prone. Besides,\nunless we write a script that will do the modifications for us, we would\nprobably not save much time with this approach. There are quite a few plugins\nthat can help us to apply changes to multiple jobs at once, but none of them is\ntruly successful (at least among free plugins). They all suffer from one\ndeficiency or another. The problem is not whether we have the tools to perform\nmassive changes to our jobs, but whether jobs are defined in a way that they can\nbe easily maintained.\n\nBesides the sheer number of Jenkins jobs, another critical Jenkins' pain point\nis centralization. While having everything in one location provides a lot of\nbenefits (visibility, reporting and so on), it also poses quite a few\ndifficulties. Since the emergence of agile methodologies, there’s been a huge\nmovement towards self-sufficient teams. Instead of horizontal organization with\nseparate development, testing, infrastructure, operations and other groups, more\nand more companies are moving (or already moved) towards self-sufficient teams\norganized vertically. As a result, having one centralized place that defines all\nthe CD flows becomes a liability and often impedes us from splitting teams\nvertically based on projects. Members of a team should be able to collaborate\neffectively without too much reliance on other teams or departments. Translated\nto CD needs, that means that each team should be able to define the deployment\nflow of the application they are developing.\n\nFinally, Jenkins, like many other tools, relies heavily on its UI. While that is\nwelcome and needed as a way to get a visual overview through dashboards and\nreports, it is suboptimal as a way to define the delivery and deployment flows.\nJenkins originated in an era when it was fashionable to use UIs for everything.\nIf you worked in this industry long enough you probably saw the swarm of tools\nthat rely completely on UIs, drag & drop operations and a lot of forms that\nshould be filled. As a result, we got tools that produce artifacts that cannot\nbe easily stored in a code repository and are hard to reason with when anything\nbut simple operations are to be performed. Things changed since then, and now we\nknow that many things (deployment flow being one of them) are much easier to\nexpress through code. That can be observed when, for example, we try to define a\ncomplex flow through many Jenkins jobs. When deployment complexity requires\nconditional executions and some kind of a simple intelligence that depends on\nresults of different steps, chained jobs are truly complicated and often\nimpossible to create.\n\nAll things considered, the major pain points Jenkins had until recently are as\nfollows.\n\nTendency to create a vast number of jobs\n\nRelatively hard and costly maintenance\n\nCentralization of everything\n\nLack of powerful and easy ways to specify deployment flow through code\n\nThis list is, by no means, unique to Jenkins. Other CI/CD tools have at least\none of the same problems or suffer from deficiencies that Jenkins solved a long\ntime ago. Since the focus of this article is Jenkins, I won’t dive into a\ncomparison between the CI/CD tools.\n\nLuckily, all those, and many other deficiencies are now a thing of the past.\nWith the emergence of the\nPipeline\nplugin and many others that were created on\ntop of it, Jenkins entered a new era and proved itself as a dominant player in\nthe CI/CD market. A whole new ecosystem was born, and the door was opened for\nvery exciting possibilities in the future.\n\nBefore we dive into the Jenkins Pipeline and the toolset that surrounds it, let\nus quickly go through the needs of a modern CD flow.\n\nContinuous Delivery or Deployment Flow with Jenkins\n\nWhen embarking on the CD journey for the first time, newcomers tend to think\nthat the tasks that constitute the flow are straightforward and linear. While\nthat might be true with small projects, in most cases things are much more\ncomplicated than that. You might think that the flow consists of building,\ntesting and deployment, and that the approach is linear and follows the\nall-or-nothing rule. Build invokes testing and testing invokes deployment. If\none of them fails, the developer gets a notification, fixes the problem and\ncommits the code that will initiate the repetition of the process.\n\nIn most instances, the process is far more complex. There are many tasks to run,\nand each of them might produce a failure. In some cases, a failure should only\nstop the process. However, more often than not, some additional logic should be\nexecuted as part of the after-failure cleanup. For example, what happens if\npost-deployment tests fail after a new release was deployed to production? We\ncannot just stop the flow and declare the build a failure. We might need to\nrevert to the previous release, rollback the proxy, de-register the service and\nso on. I won’t go into many examples of situations that require complex flow\nwith many tasks, conditionals that depend on results, parallel execution and so\non. Instead, I’ll share a diagram of one of the flows I worked on.\n\nSome tasks are run in one of the testing servers (yellow) while others are run\non the production cluster (blue). While any task might produce an error, in some\ncases such an outcome triggers a separate set of tasks. Some parts of the flow\nare not linear and depend on task results. Some tasks should be executed in\nparallel to improve the overall time required to run them. The list goes on and\non. Please note that this discussion is not about the best way to execute the\ndeployment flow but only a demonstration that the complexity can be, often, very\nhigh and cannot be solved by a simple chaining of Freestyle jobs. Even in cases\nwhen such chaining is possible, the maintenance cost tends to be very high.\n\nOne of the CD objectives we are unable to solve through chained jobs, or is\nproved to be difficult to implement, is conditional logic. In many cases, it is\nnot enough to simply chain jobs in a linear fashion. Often, we do not want only\nto create a job A that, once it’s finished running, executes job B, which, in\nturn, invokes job C. In real-world situations, things are more complicated than\nthat. We want to run some tasks (let’s call them job A), and, depending on the\nresult, invoke jobs B1 or B2, then run in parallel C1, C2 and C3, and, finally,\nexecute job D only when all C jobs are finished successfully. If this were a\nprogram or a script, we would have no problem accomplishing something like that,\nsince all modern programming languages allow us to employ conditional logic in a\nsimple and efficient way. Chained Jenkins jobs, created through its UI, pose\ndifficulties to create even a simple conditional logic. Truth be told, some\nplugins can help us with conditional logic. We have Conditional Build Steps,\nParameterised Trigger, Promotions and others. However, one of the major issues\nwith these plugins is configuration. It tends to be scattered across multiple\nlocations, hard to maintain and with little visibility.\n\nResource allocation needs a careful thought and is, often, more complicated than\na simple decision to run a job on a predefined agent. There are cases when agent\nshould be decided dynamically, workspace should be defined during runtime and\ncleanup depends on a result of some action.\n\nWhile a continuous deployment process means that the whole pipeline ends with\ndeployment to production, many businesses are not ready for such a goal or have\nuse-cases when it is not appropriate. Any other process with a smaller scope, be\nit continuous delivery or continuous integration, often requires some human\ninteraction. A step in the pipeline might need someone’s confirmation, a failed\nprocess might require a manual input about reasons for the failure, and so on.\nThe requirement for human interaction should be an integral part of the pipeline\nand should allow us to pause, inspect and resume the flow. At least, until we\nreach the true continuous deployment stage.\n\nThe industry is, slowly, moving towards microservices architectures. However,\nthe transformation process might take a long time to be adopted, and even more\nto be implemented. Until then, we are stuck with monolithic applications that\noften require a long time for deployment pipelines to be fully executed. It is\nnot uncommon for them to run for a couple of hours, or even days. In such cases,\nfailure of the process, or the whole node the process is running on, should not\nmean that everything needs to be repeated. We should have a mechanism to\ncontinue the flow from defined checkpoints, thus avoiding costly repetition,\npotential delays and additional costs. That is not to say that long-running\ndeployment flows are appropriate or recommended. A well-designed CD process\nshould run within minutes, if not seconds. However, such a process requires not\nonly the flow to be designed well, but also the architecture of our applications\nto be changed. Since, in many cases, that does not seem to be a viable option,\nresumable points of the flow are a time saver.\n\nAll those needs, and many others, needed to be addressed in Jenkins if it was to\ncontinue being a dominant CI/CD tool. Fortunately, developers behind the project\nunderstood those needs and, as a result, we got the Jenkins Pipeline plugin. The\nfuture of Jenkins lies in a transition from Freestyle chained jobs to a single\npipeline expressed as code. Modern delivery flows cannot be expressed and easily\nmaintained through UI drag 'n drop features, nor through chained jobs. They can\nneither be defined through YAML (Yet Another Markup Language) definitions\nproposed by some of the newer tools (which I’m not going to name). We need to go\nback to code as a primary way to define not only the applications and services\nwe are developing but almost everything else. Many other types of tools adopted\nthat approach, and it was time for us to get that option for CI/CD processes as\nwell.","title":"The Need For Jenkins Pipeline","tags":["jenkins2","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-14T00:00:00.000Z","id":"44aa3a43-715d-549b-b0d2-cc5c5bd94725","slug":"/blog/2016/04/14/replay-with-pipeline/","strippedHtml":"This is a cross-post of\nan article authored by\nPipeline plugin maintainer Jesse Glick on the\nCloudBees blog.\n\nFor those of you not checking their Updates tab obsessively, Pipeline 1.14 [up\nto 2.1 now] was\nreleased\na couple of weeks ago and I wanted to highlight the major feature in this\nrelease: JENKINS-32727,\nor replay. Some folks writing \"Jenkinsfiles\" in the field had grumbled that it\nwas awkward to develop the script incrementally, especially compared to jobs\nusing inline scripts stored in the Jenkins job configuration: to try a change to\nthe script, you had to edit Jenkinsfile in SCM, commit it (perhaps to a\nbranch), and then go back to Jenkins to follow the output. Now this is a little\neasier. If you have a Pipeline build which did not proceed exactly as you\nexpected, for reasons having to do with Jenkins itself (say, inability to find &\npublish test results, as opposed to test failures you could reproduce locally),\ntry clicking the Replay link in the build’s sidebar. The quickest way to try\nthis for yourself is to run the\nstock CD demo in its\nlatest release:\n\n$ docker run --rm -p 2222:2222 -p 8080:8080 -p 8081:8081 -p 9418:9418 -ti jenkinsci/workflow-demo:1.14-3\n\nWhen you see the page Replay\n#1 , you are shown two\n(Groovy) editor boxes: one for the main\nJenkinsfile , one for a library script\nit loaded\n( servers.groovy , introduced to help demonstrate this feature). You\ncan make edits to either or both. For example, the original demo allocates a\ntemporary web application with a random name like\n9c89e9aa-6ca2-431c-a04a-6599e81827ac for the duration of the functional tests.\nPerhaps you wished to prefix the application name with tmp- to make it obvious\nto anyone encountering the Jetty index page that these\nURLs are transient. So in the second text area, find the line\n\ndef id = UUID.randomUUID().toString()\n\nand change it to read\n\ndef id = \"tmp-${UUID.randomUUID()}\"\n\nthen click Run. In\nthe new build’s log\nyou will now see\n\nReplayed #1\n\nand later something like\n\n… test -Durl=http://localhost:8081/tmp-812725bb-74c6-41dc-859e-7d9896b938c3/ …\n\nwith the improved URL format. Like the result? You will want to make it\npermanent. So jump to the [second build’s index\npage]( http://localhost:8080/job/cd/branch/master/2/) where you will see a note\nthat this build > Replayed #1 (diff) If you\nclick on diff you\nwill see:\n\n--- old/Script1\n+++ new/Script1\n@@ -8,7 +8,7 @@\n }\n\n def runWithServer(body) {\n-    def id = UUID.randomUUID().toString()\n+    def id = \"tmp-${UUID.randomUUID()}\"\n     deploy id\n     try {\n         body.call id\n\nso you can know exactly what you changed from the last-saved version. In fact if you replay #2 and change tmp to temp in the loaded script, in the diff view for #3 you will see the diff from the first build, the aggregate diff:\n\n--- old/Script1\n+++ new/Script1\n@@ -8,7 +8,7 @@\n }\n\n def runWithServer(body) {\n-    def id = UUID.randomUUID().toString()\n+    def id = \"temp-${UUID.randomUUID()}\"\n     deploy id\n     try {\n         body.call id\n\nAt this point you could touch up the patch to refer to servers.groovy\n( JENKINS-31838), git\napply it to a clone of your repository, and commit. But why go to the trouble\nof editing Groovy in the Jenkins web UI and then manually copying changes back\nto your IDE, when you could stay in your preferred development environment from\nthe start?\n\n$ git clone git://localhost/repo\nCloning into 'repo'...\nremote: Counting objects: 23, done.\nremote: Compressing objects: 100% (12/12), done.\nremote: Total 23 (delta 1), reused 0 (delta 0)\nReceiving objects: 100% (23/23), done.\nResolving deltas: 100% (1/1), done.\nChecking connectivity... done.\n$ cd repo\n$ $EDITOR servers.groovy\n# make the same edit as previously described\n$ git diff\ndiff --git a/servers.groovy b/servers.groovy\nindex 562d92e..63ea8d6 100644\n--- a/servers.groovy\n+++ b/servers.groovy\n@@ -8,7 +8,7 @@ def undeploy(id) {\n }\n\n def runWithServer(body) {\n-    def id = UUID.randomUUID().toString()\n+    def id = \"tmp-${UUID.randomUUID()}\"\n     deploy id\n     try {\n         body.call id\n$ ssh -p 2222 -o StrictHostKeyChecking=no localhost replay-pipeline cd/master -s Script1 webapp-naming\n\nUsing the replay-pipeline CLI command (in this example via\nSSH)\nyou can prepare, test, and commit changes to your Pipeline script code without\ncopying anything to or from a browser. That is all for now. Enjoy!","title":"Replay a Pipeline with script edits","tags":["jenkins2","pipeline"],"authors":[]}}]}},"pageContext":{"tag":"jenkins2","limit":8,"skip":0,"numPages":3,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}