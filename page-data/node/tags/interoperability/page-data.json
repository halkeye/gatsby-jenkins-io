{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/interoperability",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2021-08-02T00:00:00.000Z","id":"4b818957-350e-52f3-a687-d86ebc43405d","slug":"/blog/2021/08/02/cloudevents-plugin-phase-I/","strippedHtml":"The What, Why and How of Interoperability\n\nWith workloads and teams becoming more diverse and complex, there is an increasing need to automate various tasks in the CI/CD ecosystem of an application as a way to decrease complexity that can come with CI/CD.\n\nA more diverse team working across different aspects of the application requires a diverse suite of CI/CD tools too, to test and deliver to a wide range of users. More often than not, we need these tools to work together and exchange data to form an effective CI/CD pipeline. However, chaining multiple services together can very easily increase complexity.\n\nHow? Each of these services use a different \"language\" to communicate and represent the entity(an event) which occured inside that service. In order for another service to understand this \"language\", the service might need to develop customized clients and agents which specialize in understanding, traversing and taking-actions based on what was transmitted to it by the first service.\n\nOne can think of it as a translator who specializes in a language called ABC, and each service who wants to communicate with the service who uses ABC will have to employ this translator, or perhaps get another trained translator. And there is no guarantee that this translator will also help communicate with other services speaking a completely different language.\n\nWe can see how easily that can grow in cost and maintenance. A preferred way is to have a common language each of these services use and understand as a way to communicate amongst each other. This way, an event which is emitted using this common language will be available to any of the interested receiver without that receiver needing a special agent. This way of communication which uses a common/standard language also creates a way for agnostic communication where the sender or the receiver are sending and receiving data without creating a tight coupling between the two.\n\nCloudEvents specification is enabling that loosely-coupled, event-driven communication between services by enforcing a common language which defines how an event should be emitted and transferred between systems.\n\nCloudEvents and Jenkins\n\nA specification for describing event data in a common way\n\nConsistency\n\nConsistent across tools and services.\n\nAccessibility\n\nCommon event format means common libraries, tooling, and infrastructure for delivering event data across environments can be used to develop with CloudEvents.\n\nPortability\n\nEasily port event-data across tools, truly leveraging event-driven architecture.\n\nThe CloudEvents plugin for Jenkins is developed as an effort to make interoperability between Jenkins and CI/CD tools much easier. The CloudEvents plugin for Jenkins is a GSoC project, and with the help from an amazing team of mentors, this project is aimed at enhancing event-driven interoperability between cloud-native CI/CD tools, making it easier for developers to include Jenkins in their CI/CD pipelines.\n\nWith this plugin, Jenkins can send and receive CloudEvents-compliant events to and from a wide variety of CI/CD tools using CloudEvents as their event format. This plugin makes chaining Jenkins with multiple tools like Tekton, Keptn, Knative and more, very easy.\n\nGSoC Phase 1 - CloudEvents Plugin\n\nUsing CloudEvents plugin for Jenkins\n\nThis plugin allows Jenkins to be configured as a source and sink, which can emit and consume CloudEvents from a range of tools simultaneously.\n\nJenkins as a Source\n\nConfiguring Jenkins as a Source enables Jenkins to send CloudEvents to a CloudEvents sink. For Phase-I of this project, there is support for HTTP Sinks, however CloudEvents supports various protocol bindings. Moving forward, there will also be support for other protocol bindings supported by CloudEvents.\n\nTo use Jenkins as a Source, the following configuration is needed:\n\nClick on Manage Jenkins in the Root-Actions menu on the left.\n\nInside the Manage Jenkins UI, search for Configure System under System Configuration.\n\nIn the Configure System UI, scroll down to the CloudEvents plugin section, and this is where all the plugin configuration will be present. Here, you will have to enter the following information:\n\nSink Type (For now, HTTP Protocol Binding for CloudEvent and HTTP Sink is supported.)\n\nSink URL (URL of the Sink where you want the cloudevents sent.)\n\nEvents you want sent to the CloudEvents sink URL.\n\nStep 1: Manage Jenkins\n\nStep 2: Configure System\n\nStep 3: Configure CloudEvents Sink\n\nWith Jenkins as a Source configured, Jenkins will send a POST request to the configured sink right as the selected event occurs inside Jenkins. Each event has a different payload specific to the type of the event emitted.\n\nEvent Types, Payload and Metadata\n\nCloudEvents emitted by Jenkins follow the Binary-structure supported by CloudEvents, where the CloudEvents metadata is present inside the header, and the event-data is serialized as JSON, and present under request-body. This is the HTTP Protocol Binding for CloudEvents. Each protocol binding for CloudEvents follows a definition specific to the binding protocol.\n\nFor now, the following Jenkins events are supported in the CloudEvents Plugin-Jenkins as a Source:\n\nQueue Events\n\nQueue Entered Waiting\n\nQueue Left\n\nBuild Events\n\nJob Started\n\nJob Completed\n\nJob Finalized\n\nJob Failed\n\nJob Events\n\nJob Created\n\nJob Updated\n\nNode Events\n\nNode Online\n\nNode Offline\n\nFollowing is a table of the queue-entered waiting cloudevents metadata:\n\nEvent Metadata Headers Key\nEvent Metadata Headers Value\n\nce-specversion\n1.0\n\nce-type\norg.jenkinsci.queue.entered_waiting\n\nce-source\njob/test\n\nce-id\n123-456-789\n\nAll of these fields will be present inside the HTTP-request headers since the CloudEvents format used here is the Binary structure.\n\nHere’s also an example of event payload for the queue-entered event:\n\n{\n  \"ciUrl\": \"http://3.101.116.80/\",\n  \"displayName\": \"test2\",\n  \"entryTime\": 1626611053609,\n  \"exitTime\": null,\n  \"startedBy\": \"shruti chaturvedi\",\n  \"jenkinsQueueId\": 25,\n  \"status\": \"ENTERED_WAITING\",\n  \"duration\": 0,\n  \"queueCauses\": [\n    {\n    \"reasonForWaiting\": \"In the quiet period. Expires in 0 ms\",\n    \"type\": \"entered_waiting\"\n    }\n  ]\n}\n\nTry the Plugin\n\nThe plugin will soon be releasing as the CloudEvents Plugin under https://plugins.jenkins.io/!!\n\nHere’s the GitHub Repo of the Plugin: CloudEvents Plugin GitHub Repo\n\nDemo\n\nHere is a video of the CloudEvents plugin with SockEye demoed at CDF GSoC Midterm Demos. SockEye is an open-source tool which is designed as a way to visulaize cloudevents which are sent from a sink. In this demo, we will take a look at how Jenkins installed in a multi-node K8s environment work with the CloudEvents plugin as a Source, sending events over HTTP to the SockEye sink.\n\nNext Steps\n\nJenkins as a Sink to allow Jenkins to trigger various actions as cloudevents are received from other tools.\n\nEnabling filtering on CloudEvents metadata to only act upon a certain kind of events recieved.\n\nSupport for other protocol bindings in CloudEvents.\n\nFeedback\n\nWe would absolutely love to hear your suggestions and feedback. This will help us understand the various use-cases for the plugin, and iterate to support a variety of bindings and formats.\n\nFeel free to log an issue at the CloudEvents Plugin GitHub repository. We are on CDF slack under gsoc-2021-jenkins-cloudevents-plugin. You can also start a discussion on community.jenkins.io. I also love emails! Drop me one on: shrutichaturvedi16.sc@gmail.com","title":"CloudEvents Plugin for Jenkins: Interoperability between Jenkins and other CI/CD Tools","tags":["gsoc","gsoc2021","cloudevents","interoperability","cloud-native"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"ShrutiC-git","html":"<div class=\"paragraph\">\n<p>Shruti Chaturvedi is the <strong>Founding Engineer</strong> for Klara, a startup to revolutionalize the shopping experience for beauty products.\nShe is an <strong>Oracle Certified Cloud Practitioner</strong>, and is developing solutions on Cloud where CI/CD is her primary focus. She has worked with Jenkins as a User, and is very excited to contribute to Jenkins and be a part of the community.</p>\n</div>","id":"ShrutiC-git","irc":null,"linkedin":null,"name":"Shruti Chaturvedi","slug":"blog/author/shrutic-git","twitter":"shruti_tech"}]}},{"node":{"date":"2021-04-21T00:00:00.000Z","id":"be129944-4fa0-5e51-a899-a198162b78c4","slug":"/blog/2021/04/21/tekton-plugin/","strippedHtml":"What is Tekton?\n\nTekton is a powerful and flexible open-source framework for creating CI/CD systems, allowing developers to build, test, and deploy across cloud providers and on-premises systems.\n\nWhy use Tekton?\n\nTekton pipelines have a number of benefits:\n\nthey are cloud native and designed from the ground up for kubernetes\n\neach Tekton Pipeline is fully declarative and completely self described; it does not depend on any separate out of band Jenkins controllers, plugins or plugin/controller configurations\n\neach Pipeline Task runs as a stand alone kubernetes Pod which is completely independent of any other pods and pipelines and are fully scheduled by Kubernetes to maximise resilience and optimize resource usage. A bad pipeline cannot take down another one & the kubernetes scheduler manages them all\n\neach step can be any command in any container image with whatever secrets, volume mounts, environment variables and resource limits you need\n\nthere is no need to bundle a JVM or Jenkins Remoting container into the pod so you can keep resources and cost down\n\nWhy use Jenkins and Tekton together?\n\nJenkins is the most popular open source automation server around. Lots of developers use it every day to get things done.\nJenkins can now be used to automate Tekton pipelines too which helps teams digitally transform to more cloud native solutions for their CI and CD.\nIn such a case, you can use Tekton pipeline engine while getting all benefits from Jenkins as an orchestrator, user interface and the reporting engine.\n\nIntroducing the Tekton Plugin for Jenkins\n\nThe Tekton Client plugin for Jenkins lets you easily use Jenkins to automate creating and running Tekton pipelines.\nIt bridges the Kubernetes learning gap and allows invoking Tekton Pipelines and resources through Jenkins.\nThis allows users to not have much of the Kubernetes specific knowledge beforehand and work.\n\nIts a single Jenkins plugin to install - so it’s easy to use.\n\nFor background check out the  blog post Bridging the Gap with Tekton-client-plugin for Jenkins by the founder of the plugin Vibhav Bobade.\n\nRequirements\n\nThe Tekton Client plugin for jenkins assumes you have access to a kubernetes cluster.\n\nThe kubernetes cluster should have Tekton pipelines installed.\n\nIf you have not yet installed Tekton you could use this tekton helm chart\n\nThe Jenkins controller should also have kubernetes RBAC access to be able to create Tekton resources and watch them and their associated pods and pod logs.\n\nIf you are running your Jenkins controller inside Kubernetes then an easy way to setup the RBAC is to install the Jenkins Resource Helm Chart in the same namespace as your Jenkins controller.\n\nAnother option is to use an installation of Jenkins X and let it setup a Jenkins controller via GitOps\n\nSpecifying the Tekton pipelines\n\nYou can configure the Tekton pipeline via:\n\na file path in a git clone block\n\na URL to a tekton YAML file\n\na block of YAML\n\nWe recommend defining Tekton pipelines as YAML files and checking them into a git repository so that you can use GitOps and follow the Pipeline As Code pattern.\n\nThis means that you can version your pipelines in git. It also means you can benefit from the various IDE plugins available for Tekton such as VS Code and IDEA so that you get auto completion, formatting and validation while editing the YAML.\n\nSo you can use the usual Git provider support in Jenkins to clone the git repository that contains then Tekton YAML file then reference the file by name.\n\nReusing Pipelines from the Tekton Catalog\n\nThe Tekton Catalog defines a ton of Tekton Tasks you can reuse in your pipelines\n\nWe have found when it comes to a microsevices style architecture you end up with lots of repositories and pipelines. Then using a Pipeline As Code pattern with GitOps we want to Version Everything but also make it easy for any repository to use any version of any task or pipeline.\n\ne.g. you may have many repositories using the current version of a pipeline but want to try out a new change to the pipeline in just 1 repository to verify it works well; then if it does, incrementally roll that change out to more repositories.\n\nThis can make it hard trying to reuse as much as you can across the different git repositories while also minimising the number of versions and forks of git repositories you have and simplifying the maintenance of all of the pipelines.\n\nWe have found on the Jenkins X project that a nice way to do this via GitOps such that we reference versioned Tekton Tasks and Pipelines in git so that they are easy to reuse or override.\n\nSo we reuse Tasks and Pipelines via the uses: image notation which lets us keep all of our Tekton Tasks and Pipelines in vanilla Tekton YAML; so that the IDE completion and validation works - but we can easily reuse Tasks or steps from libraries while also Versioning Everything\n\nNote that if wish to reuse steps/tasks via the uses: image notation then you must click the Tekton Catalog flag in your Job definition which will then resolve the uses: clause with the actual step/task.\n\nWhat is Jenkins X?\n\nThe Jenkins X project automates your CI/CD on kubernetes to help you accelerate :\n\nAutomated CI/CD pipelines lets you focus on your actually application code while Jenkins X automatically creates battle tested Tekton CI/CD pipelines for your project which are managed via GitOps so that its super easy to keep your pipelines up to date across your repositories or to upgrade or override pipelines or steps for specific repositories.\n\nAutomatic promotion of versioned artifacts via GitOps through your Environments such as Staging, Pre-production and Production whether they are running in the same kubernetes cluster or you are using multiple clusters for your environments\n\nPreview Environments lets you propose code changes via Pull Requests and have a Preview Environment automatically created, running your code in kubernetes to get fast feedback from your team before agreeing to merge changes to the main branch\n\nChatOps comment on Pull Requests to give feedback, approve/hold changes, trigger optional pipelines for additional testing and other ChatOps commands\n\nAll of the above is implemented in reusable Tekton pipelines.\n\nReusing Jenkins X Pipelines\n\nSo how can we reuse automated CI/CD pipelines from Jenkins X project from Jenkins?\n\nMake sure you have the Tekton Client plugin for Jenkins installed in your Jenkins server.\n\nUsing a working template\n\nIf you want to start with a working example then\n\nCreate A Git Repository From This Template\n\nadd a new Frestyle project to your Jenkins server\n\nenable the Git source code management for your new github.com repository\n\nclick Add build Step (near the bottom of the page) and then select Tekton : Create Resource (Raw)\n\nmake sure that FILE is selected for the input and enter the name.lighthouse/jenkins-x/release.yaml for the file name\n\nif you are using a Jenkins X cluster enter jx for the namespace\n\nensure that Enable Tekton Catalog is checked\n\nnow save the pipeline - it should look something like this:\n\nNow if you trigger the pipeline you should see it create a Tekton Pipeline and you should see the output of the tekton pipeline in the Jenkins console. The pipeline is actually running as a completely separate Pod in kubernetes; the Jenkins controller just tails the log into the console.\n\nIn a Jenkins X cluster this pipeline should just work (reusing all the cloud resources and IAM roles setup by the Terraform) but in an arbitrary kubernetes cluster you may get issues around not being able to push images or promote due to lack of GitOps environments being defined which we can help you work through via the Jenkins X slack room\n\nUsing an existing repository\n\nYou can configure a Pull Request or Release pipeline in your project by copying the YAML file for the language pack you wish to use.\n\ne.g. if you are using maven then copy pullrequest.yaml or release.yaml into your projects source code then reference it from your Jenkins Job:\n\nThen follow the above instructions for setting up a Freestyle project for your git repository and referencing the file name for your pipeline.\n\nOverriding steps\n\nBeing able to reuse steps from libraries of pipelines is awesome; but sometimes you need to change things. The assumptions, commands, arguments, environment variables or approaches used for every step in a library may not quite match what you need on a specific application. You may need to run steps before/after steps in the library or you may need to override a specific step to do something different.\n\nYou can easily customize any inherited step in any shared pipeline or add custom steps before/after any step.\n\nThe fact that all the Tekton YAML is fully declarative makes it super easy to modify things via your IDE with validation and smart completion and not have to use a scripting language and understand complex shared pipeline libraries.\n\nThe easiest way to try overriding a step is to install the jx binary to your $PATH then use the jx pipeline override command which will create a new locally overridden step you can then just edit in your IDE.\n\nThen at any time you can view the effective pipeline when you make local changes\n\nComparing the Kubernetes and Tekton plugins\n\nThose of you using Jenkins on a Kubernetes cluster are probably using the kubernetes plugin right now.\n\nHere is an example of how to use a Jenkinsfile with a pod YAML file so that you can run commands in different containers in the pod.\n\nWhat this means is that:\n\na kubernetes pod is created based on the pod YAML file which is scheduled by kubernetes\n\nthe Jenkinsfile runs on the Jenkins controller talking over Jenkins remoting to the pod to tell it to run commands in different containers. The pod includes the jnlp container which does the remoting between the Jenkins controller and the pod\n\nThis has a few issues:\n\neach container in the pod must have a shell so that jnlp can invoke commands. This may mean you have to create your own images\n\nit can be a little slow to start since there is chattiness with the Jenkins controller and the pod - whereas with Tekton pods just start and run locally without any coodination with the Jenkins controller\n\nyou have to maintain 2 files: the Jenkinsfile and the pod.yaml and it’s hard to share/override both of those files across multiple repositories as you need to make changes (e.g. overriding environment variables/images/commands/resource limits on demand on steps).\n\nThough one downside of the tekton approach is that by default there is no automatic synchronisation of state; after a Task in tekton completes there’s no automatic upload of state to the Jenkins controllers disk. You can always add a step in your Task to upload workspace state to the Jenkins controller if that’s what you want.\n\nThough remember that tekton plugin doesn’t take anything away; so you can mix and match the kubernetes and tekton plugins to suit your needs.\n\nConclusion\n\nWe are really excited about the combination of Jenkins, Tekton and Jenkins X letting developers pick the best tool for the job while becoming more cloud native and increasing the automation help reduce the amount of manual work creating and maintaining pipelines while also helping to improve the quality and practices of our CI/CD.\n\nPlease try it out and let us know how you get on!","title":"Easily reuse Tekton and Jenkins X from Jenkins","tags":["jenkins-x","kubernetes","pipeline","tekton","gitops","interoperability"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"jstrachan","html":"<div class=\"paragraph\">\n<p>James is a long time open source contributor, created the Groovy programming language and Apache Camel integration framework.\nFor the past few years he&#8217;s been working on CI/CD with Kubernetes.</p>\n</div>","id":"jstrachan","irc":null,"linkedin":null,"name":"James Strachan","slug":"blog/author/jstrachan","twitter":"jstrachan"}]}}]}},"pageContext":{"tag":"interoperability","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}