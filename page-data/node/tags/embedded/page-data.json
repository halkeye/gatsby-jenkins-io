{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/embedded",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-04-07T00:00:00.000Z","id":"bb46e899-10f9-583c-862c-a664e9eb81b4","slug":"/blog/2016/04/07/pipeline-for-runs-on-hardware/","strippedHtml":"In addition to Jenkins development, during last 8 years I’ve been involved into continuous integration for hardware and embedded projects.\nAt JUC2015/London\nI have conducted a talk about common automation challenges in the area.\n\nIn this blog post I would like to concentrate on Pipeline (formerly known as Workflow), which is a new ecosystem in Jenkins that allows implementing jobs in a domain specific language.\nIt is in the suggested plugins list in the upcoming Jenkins 2.0 release.\n\nThe first time I tried Pipeline two and half years ago, it unfortunately did not work for my use-cases at all.\nI was very disappointed but tried it again a year later.\nThis time, the plugin had become much more stable and useful.\nIt had also attracted more contributors and started evolving more rapidly with the development of plugins extending the Pipeline ecosystem.\n\nCurrently, Pipeline a powerful tool available for Jenkins users to implement a variety of software delivery pipelines in code.\nI would like to highlight several Pipeline features which may be interesting to Jenkins users working specifically with embedded and hardware projects.\n\nIntroduction\n\nIn Embedded projects it’s frequently required to run tests on specific hardware peripherals: development boards, prototypes, etc.\nIt may be required for both software and hardware areas, and especially for products involving both worlds.\nCI and CD methodologies require continuous integration and system testing, and Jenkins comes to help here.\nJenkins is an automation framework, which can be adjusted to reliably work with hardware attached to its nodes.\n\nArea challenges\n\nGenerally, any peripheral hardware device can be attached to a Jenkins node.\nSince Jenkins nodes require Java only, almost every development machine can be attached.\nBelow you can find a common connection scheme:\n\nAfter the connection, Jenkins jobs could invoke common EDA tools via command-line interfaces.\nIt can be easily done by a Execute shell build steps in free-style projects.\nSuch testing scheme is commonly affected by the following issues:\n\nNodes with peripherals are being shared across several projects.\nJenkins must ensure the correctness of access (e.g. by throttling the access).\n\nIn a single Freestyle project builds utilize the node for a long period. If you synthesize the item before the run, much of the peripheral utilization file may be wasted.\n\nThe issue can be solved by one of concurrency management plugins:\nThrottle Concurrent Builds, Lockable Resources\nor\nExclusions.\n\nTest parallelization on multiple nodes requires using of multiple projects or\nMatrix configurations, so it causes job chaining again.\n\nThese build chains can be created via\nParameterized Trigger and\nCopy Artifacts, but it complicates job management and build history investigation.\n\nHardware infrastructure is usually flaky.\nIf it fails during the build due to any reason, it’s hard to diagnose the issue and re-run the project if the issue comes from hardware.\n\nBuild Failure Analyzer allows to identify the root cause of a build failure (e.g. by build log parsing).\n\nConditional Build Step and\nFlexible Publish plugins allow altering the build flow according to the analysis results.\n\nCombination of the plugins above is possible, but it makes job configurations extremely large.\n\nTests on hardware peripherals may take much time.\nIf an infrastructure fails, we may have to restart the run from scratch.\nSo the builds should be robust against infrastructure issues including network failures and Jenkins controller restarts.\n\nTests on hardware should be reproducible, so the environment and input parameters should be controlled well.\n\nJenkins supports\ncleaning workspaces, so it can get rid of temporary files generated by previous runs.\n\nJenkins provides support of agents connected via containers (e.g.\nDocker) or VMs, which allow creating clean environments for every new run.\nIt’s important for 3rd-party tools, which may modify files outside the workspace: user home directory, temporary files, etc.\n\nThese environments still need to be connected to hardware peripherals, which may be a serious obstacle for Jenkins admins\n\nThe classic automation approaches in Jenkins are based on Free-style and Multi-configuration project types.\nLinks to various articles on this topic are collected on the\nHW/Embedded Solution page Embedded on the Jenkins website.\nTests automation on hardware peripherals has been covered in several publications by Robert Martin, Steve Harris, JL Gray, Gordon McGregor, Martin d’Anjou, and Sarah Woodall.\nThere is also a top-level overview of classic approaches made by me at JUC2015/London (a bit outdated now).\n\nOn the other hand, there is no previous publications, which would address Pipeline usage for the Embedded area.\nIn this post I want to address this use-case.\n\nPipeline as Code for test runs on hardware\n\nPipeline as Code is an approach for describing complex automation flows in software lifecycles: build, delivery, deployment, etc.\nIt is being advertised in Continuous Delivery and DevOps methodologies.\n\nIn Jenkins there are two most popular plugins:\nPipeline and Job DSL.\nJobDSL Plugin internally generates common freestyle jobs according to the script, so it’s functionality is similar to the classic approaches.\nPipeline is fundamentally different, because it provides a new engine controlling flows independently from particular nodes and workspaces.\nSo it provides a higher job description level, which was not available in Jenkins before.\n\nBelow you can find an example of Pipeline scripts, which runs tests on FPGA board. The id of this board comes from build parameters ( fpgaId). In this script we also presume that all nodes have pre-installed tools (Xilinx ISE in this case).\n\n// Run on node having my_fpga label\nnode(\"linux && ml509\") {\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  sh \"make all\"\n}\n\nBut such scenario could be also implemented in a Free-style project.\nWhat would we get from Pipeline plugin?\n\nGetting added-value from Pipeline as code\n\nPipeline provides much added-value features for hardware-based tests.\nI would like to highlight the following advantages:\n\nRobustness against restarts of Jenkins controller.\n\nRobustness against network disconnects. sh() steps are based on the\nDurable Task plugin, so Jenkins can safely continue the execution flow once the node reconnects to the controller.\n\nIt’s possible to run tasks on multiple nodes without creating complex flows based on job triggers and copy artifact steps, etc. It can be achieved via combination of parallel() and node() steps.\n\nAbility to store the shared logic in standalone Pipeline libraries\n\netc.\n\nFirst two advantages allow to improve the robustness of Jenkins nodes against infrastructure failures.\nIt is critical for long-running tests on hardware.\n\nLast two advantages address the flexibility of Pipeline flows.\nThere are also plugins for freestyle projects, but they are not flexible enough.\n\nUtilizing Pipeline features\n\nThe sample Pipeline script above is very simple.\nWe would like to get some added value from Jenkins.\n\nGeneral improvements\n\nLet’s enhance the script by using several features being provided by pipeline in order to get visualization of stages, report publishing and build notifications.\n\nWe also want to minimize the time being spent on the node with the attached FPGA board.\nSo we will split the bitfile generation and further runs to two different nodes in this case: a general purpose linux node, and the node with the hardware attached.\n\nYou can find the resulting Pipeline script below:\n\n// Synthesize on any node\ndef imageId=\"\"\nnode(\"linux\") {\n  stage \"Prepare environment\"\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  // Construct the bitfile image ID from commit ID\n  sh 'git rev-parse HEAD > GIT_COMMIT'\n  imageId= \"myprj-${fpgaId}-\" + readFile('GIT_COMMIT').take(6)\n\n  stage \"Synthesize project\"\n  sh \"make FPGA_TYPE=$fpgaId synthesize_for_fpga\"\n  /* We archive the bitfile before running the test, so it won't be lost it if something happens with the FPGA run stage. */\n  archive \"target/image_${fpgaId}.bit\"\n  stash includes: \"target/image_${fpgaId}.bit\", name: 'bitfile'\n}\n\n/* Run on a node with 'my_fpga' label.\nIn this example it means that the Jenkins node contains the attacked FPGA of such type.*/\nnode (\"linux && $fpgaId\") {\n  stage \"Blast bitfile\"\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  def artifact='target/image_'+fpgaId+'.bit'\n  echo \"Using ${artifact}\"\n  unstash 'bitfile'\n  sh \"make FPGA_TYPE=$fpgaId impact\"\n\n  /* We run automatic tests.\n  Then we report test results from the generated JUnit report. */\n  stage \"Auto Tests\"\n  sh \"make FPGA_TYPE=$fpgaId tests\"\n  sh \"perl scripts/convertToJunit.pl --from=target/test-results/* --to=target/report_${fpgaId}.xml --classPrefix=\\\"myprj-${fpgaId}.\\\"\"\n  junit \"target/report_${fpgaId}.xml\"\n\n  stage \"Finalization\"\n  sh \"make FPGA_TYPE=$fpgaId flush_fpga\"\n  hipchatSend(\"${imageId} testing has been completed\")\n}\n\nAs you may see, the pipeline script mostly consists of various calls of command-line tools via the sh() command.\nAll EDA tools provide great CLIs, so we do not need special plugins in order to invoke common operations from Jenkins.\n\nMakefile above is a sample stuff for demo purposes.\nIt implements a set of unrelated routines merged into a single file without dependency declarations.\nNever write such makefiles.\n\nIt is possible to continue expanding the pipeline in such way.\nPipeline Examples\ncontain examples for common cases: build parallelization, code sharing between pipelines, error handling, etc.\n\nLessons learned\n\nDuring last 2 years I’ve been using Pipeline for Hardware test automation several times.\nThe first attempts were not very successful, but the ecosystem has been evolving rapidly.\nI feel Pipeline has become a really powerful tool, but there are several missing features.\nI would like to mention the following ones:\n\nShared resource management across different pipelines.\n\nRuns of a single Pipeline job can be synchronized using the concurrency parameter of the stage() step\n\nIt can be done by the incoming Pipeline integration in the\nLockable Resources plugin\n( JENKINS-30269).\n\nAnother case is integration with\nThrottle Concurrent Builds plugin, which is an effective engine for limiting the license utilization in automation infrastructures\n( JENKINS-31801).\n\nBetter support of CLI tools.\n\nEDA tools frequently need a complex environment, which should be deployed on nodes somehow.\n\nIntegration with\nCustom Tools Plugin seems to be the best option, especially in the case of multiple tool versions\n( JENKINS-30680).\n\nPipeline package manager ( JENKINS-34186)\n\nSince there is almost no plugins for EDA tools in Jenkins, developers need to implement similar tasks at multiple jobs.\n\nA common approach is to keep the shared \"functions\" in libraries.\n\nPipeline Global Library and\nPipeline Remote Loader can be used, but they do not provide features like dependency management.\n\nPipeline debugger ( JENKINS-34185)\n\nHardware test runs are very slow, so it is difficult to troubleshoot and fix issues in the Pipeline code if you have to run every build from scratch.\n\nThere are several features in Pipeline, which simplify the development, but we still need an IDE-alike implementation for complex scripts.\n\nConclusions\n\nJenkins is a powerful automation framework, which can be used in many areas.\nEven though Jenkins has no dedicated plugins for test runs on hardware, it provides many general-purpose \"building blocks\", which allow implementing almost any flow.\nThat’s why Jenkins is so popular in the hardware and embedded areas.\n\nPipeline as code can greatly simplify the implementation of complex flows in Jenkins.\nIt continues to evolve and extend support of use-cases.\nif you’re developing embedded projects, consider Pipeline as a durable, extensible and versatile means of implementing your automation.\n\nWhat’s next?\n\nJenkins automation server dominates in the HW/Embedded area, but unfortunately there is not so much experience sharing for these use-cases.\nSo Jenkins community encourages everybody to share the experience in this area by writing docs and articles for Jenkins website and other resources.\n\nThis is just a a first blog post on this topic.\nI am planning to provide more examples of Pipeline usage for Embedded and Hardware tests in the future posts.\nThe next post will be about concurrency and shared resource management in Pipelines.\n\nI am also going to talk about running tests on hardware at the\nupcoming Automotive event in Stuttgart on April 26th.\nThis event is being held by\nCloudBees, but there will be several talks addressing Jenkins open-source as well.\n\nIf you want to share your experience about Jenkins usage in Hardware/Embedded areas, consider submitting a talk for the\nJenkins World conference or join/organize a\nJenkins Area Meetup in your city.\nThere is also a\nJenkins Online Meetup.\n\nLinks\n\nRelated articles and events:\n\nHW/Embedded Solution page\n\nJenkins-Based CI for Heterogeneous Hardware/Software Projects\n\nAccelerating Automotive Innovation with Continuous Integration & Delivery - meetup in Stuttgart\n\nPipeline:\n\nPipeline page\n\nJenkins 2.0 and Pipeline as code overview\n\nPipeline Tutorial\n\nPipeline Examples","title":"Automating test runs on hardware with Pipeline as Code","tags":["jenkins2","pipeline","embedded"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/author/oleg_nenashev","twitter":"oleg_nenashev"}]}}]}},"pageContext":{"tag":"embedded","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}