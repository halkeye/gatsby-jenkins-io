{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/scalability",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2020-10-21T00:00:00.000Z","id":"7c9b1586-7a87-5fd5-8543-1a27aa94a68f","slug":"/blog/2020/10/21/a-sustainable-pattern-with-shared-library/","strippedHtml":"Table of Contents\n\nContext\nThe Problems\nThe Solution\n\nShared Library\nDuplication\nDocumentation\nScalability\nInstallation Agnostic\nFeature Toggling\n\nThis post will describe how I use a shared library in Jenkins. Typically when using multibranch pipeline.\n\nIf possible (if not forced to) I implement the pipelines without multibranch. I previously wrote about how I do that with my Generic Webhook Trigger Plugin in a previous post. But this will be my second choice, If I am not allowed to remove the Jenkinsfile :s from the repositories entirely.\n\nContext\n\nWithin an organization, you typically have a few different kinds of repositories. Each repository versioning one application. You may use different techniques for different kinds of applications. The Jenkins organization on GitHub is an example with 2300 repositories.\n\nThe Problems\n\nLarge Jenkinsfiles in every repository containing duplicated code. It seems common that the Jenkinsfile :s in every repository contains much more than just the things that are unique for that repository. The shared libraries feature may not be used, or it is used but not with an optimal pattern.\n\nInstallation specific Jenkinsfile:s that only work with one specific Jenkins installation. Sometimes I see multiple Jenkinsfile :s, one for each purpose or Jenkins installation.\n\nNo documentation and/or no natural place to write documentation.\n\nDevelopment is slow. Adding new features to repositories is a time consuming task. I want to be able to push features to 1000+ repositories without having to update their Jenkinsfile :s.\n\nNo flexible way of doing feature toggling. When maintaining a large number of repositories it is sometimes nice to introduce a feature to a subset of those repositories. If that works well, the feature is introduced to all repositories.\n\nThe Solution\n\nMy solution is a pattern that is inspired by how the Jenkins organization on GitHub does it with its buildPlugin(). But it is not exactly the same.\n\nShared Library\n\nHere is how I organize my shared libraries.\n\nJenkinsfile\n\nI put this in the Jenkinsfile :s:\n\nbuildRepo()\n\nDefault Configuration\n\nI provide a default configuration that any repository will get, if no other configuration is given in buildRepo().\n\nI create a vars/getConfig.groovy with:\n\ndef call(givenConfig = [:]) {\n  def defaultConfig = [\n    /**\n      * The Jenkins node, or label, that will be allocated for this build.\n      */\n    \"jenkinsNode\": \"BUILD\",\n    /**\n      * All config specific to NPM repo type.\n      */\n    \"npm\": [\n      /**\n        * Whether or not to run Cypress tests, if there are any.\n        */\n      \"cypress\": true\n    ],\n    \"maven\": [\n      /**\n        * Whether or not to run integration tests, if there are any.\n        */\n      \"integTest\": true\n    ]\n  ]\n  // https://e.printstacktrace.blog/how-to-merge-two-maps-in-groovy/\n  def effectiveConfig merge(defaultConfig, givenConfig)\n  println \"Configuration is documented here: https://whereverYouHos/getConfig.groovy\"\n  println \"Default config: \" + defaultConfig\n  println \"Given config: \" + givenConfig\n  println \"Effective config: \" + effectiveConfig\n  return effectiveConfig\n}\n\nBuild Plan\n\nI construct a build plan as early as possible. Taking decisions on what will be done in this build. So that the rest of the code becomes more streamlined.\n\nI try to rely as much as possible on conventions. I may provide configuration that lets users turn off features, but they are otherwise turned on if they are detected.\n\nI create a vars/getBuildPlan.groovy with:\n\ndef call(effectiveConfig = [:]) {\n  def derivedBuildPlan = [\n    \"repoType\": \"NOT DETECTED\"\n    \"npm\": [],\n    \"maven\": []\n  ]\n\n  node {\n    deleteDir()\n    checkout([$class: 'GitSCM',\n      branches: [[name: '*/branchName']],\n      extensions: [\n          [$class: 'SparseCheckoutPaths',\n            sparseCheckoutPaths:\n            [[$class:'SparseCheckoutPath', path:'package.json,pom.xml']]\n          ]\n      ],\n      userRemoteConfigs: [[credentialsId: 'someID',\n      url: 'git@link.git']]\n    ])\n\n    if (fileExists('package.json')) {\n      def packageJSON = readJSON file: 'package.json'\n      derivedBuildPlan.repoType = \"NPM\"\n      derivedBuildPlan.npm.cypress = effectiveConfig.npm.cypress && packageJSON.devDependencies.cypress\n      derivedBuildPlan.npm.eslint = packageJSON.devDependencies.eslint\n      derivedBuildPlan.npm.tslint = packageJSON.devDependencies.tslint\n    } else if (fileExists('pom.xml')) {\n      derivedBuildPlan.repoType = \"MAVEN\"\n      derivedBuildPlan.maven.integTest = effectiveConfig.maven.integTest && fileExists('src/integtest')\n    } else {\n      throw RuntimeException('Unable to detect repoType')\n    }\n\n    println \"Build plan: \" + derivedBuildPlan\n    deleteDir()\n  }\n  return derivedBuildPlan\n}\n\nPublic API\n\nThis is the public API, this is what I want the users of this library to actually invoke.\n\nI implement a buildRepo() method that will use that default configuration. It can also be called with a subset of the default configuration to tweak it.\n\nI create a vars/buildRepo.groovy with:\n\ndef call(givenConfig = [:]) {\n  def effectiveConfig = getConfig(givenConfig)\n  def buildPlan = getBuildPlan(effectiveConfig)\n\n  if (effectiveConfig.repoType == 'MAVEN')\n    buildRepoMaven(buildPlan);\n  } else if (effectiveConfig.repoType == 'NPM')\n    buildRepoNpm(buildPlan);\n  }\n}\n\nA user can get all the default behavior with:\n\nbuildRepo()\n\nA user can also choose not to run Cypress, even if it exists in the repository:\n\nbuildRepo([\n  \"npm\": [\n    \"cypress\": false\n  ]\n])\n\nSupporting Methods\n\nThis is usually much more complex, but I put some code here just to have a complete implementation.\n\nI create a vars/buildRepoNpm.groovy with:\n\ndef call(buildPlan = [:]) {\n  node(buildPlan.jenkinsNode) {\n    stage(\"Install\") {\n      sh \"npm install\"\n    }\n    stage(\"Build\") {\n      sh \"npm run build\"\n    }\n    if (buildPlan.npm.tslint) {\n      stage(\"TSlint\") {\n        sh \"npm run tslint\"\n      }\n    }\n    if (buildPlan.npm.eslint) {\n      stage(\"ESlint\") {\n        sh \"npm run eslint\"\n      }\n    }\n    if (buildPlan.npm.cypress) {\n      stage(\"Cypress\") {\n        sh \"npm run e2e:cypress\"\n      }\n    }\n  }\n}\n\nI create a vars/buildRepoMaven.groovy with:\n\ndef call(buildPlan = [:]) {\n  node(buildPlan.jenkinsNode) {\n    if (buildPlan.maven.integTest) {\n      stage(\"Verify\") {\n        sh \"mvn verify\"\n      }\n    } else {\n      stage(\"Package\") {\n        sh \"mvn package\"\n      }\n    }\n  }\n}\n\nDuplication\n\nThe Jenkinsfile :s are kept extremely small. It is only when they, for some reason, diverge from the default config that they need to be changed.\n\nDocumentation\n\nThere is one single point where documentation is written, the getConfig.groovy -file. It can be referred to whenever someone asks for documentation.\n\nScalability\n\nThis is a highly scalable pattern. Both with regards to performance and maintainability in code.\n\nIt scales in performance because the Jenkinsfile :s can be used by any Jenkins installation. So that you can scale by adding several completely separate Jenkins installations, not only nodes.\n\nIt scales in code because it adds just a tiny Jenkinsfile to repositories. It relies on conventions instead, like the existence of attributes in package.json and location of integration tests in src/integtest.\n\nInstallation Agnostic\n\nThe Jenkinsfile :s does not point at any implementation of this API. It just invokes it and it is up to the Jenkins installation to implement it, with a shared libraries.\n\nIt can even be used by something that is not Jenkins. Perhaps you decide to do something in a Docker container, you can still parse the Jenkinsfile with Groovy or (with some magic) with any language.\n\nFeature Toggling\n\nThe shared library can do feature toggling by:\n\nLetting some feature be enabled by default for every repository with name starting with x.\n\nOr, adding some default config saying\"feature-x-enabled\": false, while some repos change their Jenkinsfile :s to buildRepo([\"feature-x-enabled\": true]).\n\nWhenever the feature feels stable, it can be enabled for everyone by changing only the shared library.","title":"A sustainable pattern with shared library","tags":["pipeline","scalability","sharedlibrary","infrastructure"],"authors":[]}},{"node":{"date":"2019-12-14T00:00:00.000Z","id":"646ce24b-257b-5341-bb67-a06739313fd5","slug":"/blog/2019/12/14/generic-webhook-trigger-plugin/","strippedHtml":"Table of Contents\n\nThe Problem\n\nCode Duplication And Security\nA Branch Is Not A Feature\nDocumentation\n\nThe Solution\n\nCode Duplication And Security\nA Branch Is Not A Feature\nDocumentation\n\nThis post will describe some common problems I’ve had with Jenkins and how I solved them by developing Generic Webhook Trigger Plugin.\n\nThe Problem\n\nI was often struggling with the same issues when working with Jenkins:\n\nCode duplication and security - Jenkinsfiles in every repository.\n\nA branch is not a feature - Parameterized jobs on master branch often mix parameters relevant for different features.\n\nPoorly documented trigger plugins - Proper documented services but poorly documented consuming plugins.\n\nCode Duplication And Security\n\nHaving Jenkinsfiles in every Git repository allows developers to let those files diverge. Developers pushes forward with their projects and it is hard to maintain patterns to share code.\n\nI have, almost, solved code duplication with shared libraries but it does not allow me to setup a strict pattern that must be followed. Any developer can still decide to not invoke the features provided by the shared library.\n\nThere is also the security aspect of letting developers run any code from the Jenkinsfiles. Developers might, for example, print passwords gathered from credentials. Letting developers execute any code on the Jenkins nodes just does not seem right to me.\n\nA Branch Is Not A Feature\n\nIn Bitbucket there are projects and each project has a collection of git repositories. Something like this:\n\nPROJ_1\n\nREPO_1\n\nREPO_2\n\nPROJ_2\n\nREPO_3\n\nLets think about some features we want to provide for these repositories:\n\nPull request verification\n\nBuilding snapshot (or pre release if you will)\n\nBuilding releases\n\nIf the developers are use to the repositories being organized like this in Bitbucket, should we not organize them the same way in Jenkins? And if they browse Jenkins should they not find one job per feature, like pull-request, snapshot and release? Each job with parameters only relevant for that feature. I think so! Like this:\n\n/ - Jenkins root\n\n/PROJ_1 - A folder, lists git repositories\n\n/PROJ_1/REPO_1 - A folder, lists jobs relevant for that repo.\n\n/PROJ_1/REPO_1/release - A job, performs releases.\n\n/PROJ_1/REPO_1/snapshot - A job, performs snapshot releases.\n\n/PROJ_1/REPO_1/pull-request - A job, verifies pull requests.\n\n…​\n\nIn this example, both snapshot and release jobs might work with the same git branch. The difference is the feature they provide. Their parameters can be well documented as you don’t have to mix parameters relevant for releases and those relevant for snapshots. This cannot be done with Multibranch Pipeline Plugin where you specify parameters as properties per branch.\n\nDocumentation\n\nWebhooks are often well documented in the services providing them. See:\n\nBitbucket Cloud\n\nBitbucket Server\n\nGitHub\n\nGitLab\n\nGogs and Gitea\n\nAssembla\n\nJira\n\nIt bothered me that, even if I understood these webhooks, I was unable to use them. Because I needed to perform development in the plugin I was using in order to provide whatever value from the webhook to the build. That process could take months from PR to actual release. Such a simple thing should really not be an issue.\n\nThe Solution\n\nMy solution is pretty much back to basics : We have an automation server (Jenkins) and we want to trigger it on external webhooks. We want to gather information from that webhook and provide it to our build. In order to support it I have created the Generic Webhook Trigger Plugin.\n\nThe latest docs are available in the repo and I also have a fully working example with GitLab implemented using configuration-as-code. See the repository here.\n\nCode Duplication And Security\n\nI establish a convention that all developers must follow. Instead of letting the developers explicitly invoke the infrastructure from Jenkinsfiles. There are rules to follow, like:\n\nAll git repositories should be built from the root of the repo.\n\nIf it contains a gradlew\n\nBuild is done with./gradlew build\n\nRelease is done with./gradlew release\n\n…​ and so on\n\nIf it contains a package.json\n\nBuild is done with npm run build\n\nRelease is done with npm run release\n\n…​ and so on\n\nWith these rules, pipelines can be totally generic and no Jenkinsfiles are needed in the repositories. Some git repositories may, for some reason, need to disable test cases. That can be solved by allowing repositories to add a special file, perhaps jenkins-settings.json, let the infrastructure discover and act on its content.\n\nThis also helps the developers even when not doing CI. When they clone a new, to them unknown, repository they will know what commands can be issued and their semantics.\n\nA Branch Is Not A Feature\n\nI implement:\n\nJenkins job configurations - With Job DSL.\n\nJenkins build process - With Pipelines and Shared Library.\n\nBy integrating with the git service from Job DSL I can automatically find the git repositories. I create jobs dynamically organized in folders. Also invoking the git service to setup webhooks triggering those jobs. The jobs are ordinary pipelines, not multibranch, and they don’t use Jenkinsfile from Git but instead Jenksinfile configured in the job using Job DSL. So that all job configurations and pipelines are under version control. This is all happening here.\n\nDocumentation\n\nThe plugin uses JSONPath, and also XPath, to extract values from JSON and provide them to the build. Letting the user pick whatever is needed from the webhook. It also has a regular expression filter to allow not triggering for some conditions.\n\nThe plugin is not very big, just being the glue between the webhook, JSONPath / XPath and regular expression. All these parts are very well documented already and I do my best supporting the plugin. That way this is a very well documented solution to use!","title":"Generic Webhook Trigger Plugin","tags":["webhooks","trigger","pipeline","security","scalability"],"authors":[]}},{"node":{"date":"2018-09-10T00:00:00.000Z","id":"3cfe2a34-ab7c-5a8e-baa2-c46178e12dd1","slug":"/blog/2018/09/10/scaling-network-connections/","strippedHtml":"Oleg Nenashev and I will be speaking at DevOps World | Jenkins World in San Francisco this year about\nScaling Network Connections from the Jenkins Controller.\nOver the years there have been many efforts to analyze, optimize, and fortify the “Remoting channel”\nthat allows a controller to orchestrate agent activity and receive build results.\nTechniques such as tuning the agent launcher can improve service,\nbut qualitative change can only come from fundamentally reworking what gets transmitted and how.\n\nIn March, jira:27035[] introduced a framework for inspecting the traffic on a Remoting channel at a high level.\nPreviously, developers could only use generic low-level tools such as Wireshark,\nwhich cannot identify the precise piece of Jenkins code responsible for traffic.\n\nOver the past few months, the\nCloud Native SIG\nhas been making progress in addressing root causes.\nThe\nArtifact Manager on S3 plugin\nhas been released and integrated with Jenkins Evergreen,\nallowing upload and download of large artifacts to happen entirely between the agent and Amazon servers.\nPrototype plugins allow all build log content generated by an agent (such as in sh steps)\nto be streamed directly to external storage services such as AWS CloudWatch Logs.\nWork has also begun on uploading JUnit-format test results, which can sometimes get big,\ndirectly from an agent to database storage.\nAll these efforts can reduce the load on the Jenkins controller and local network\nwithout requiring developers to touch their Pipeline scripts.\n\nOther approaches are on the horizon.\nWhile “one-shot” agents run in fresh VMs or containers greatly improve reproducibility,\nthey suffer from the need to transmit megabytes of Java code for every build,\nso Jenkins features will need to be built to precache most or all of it.\nWork is underway to use Apache Kafka to make channels more robust against network failures.\nMost dramatically, the proposed\nCloud Native Jenkins MVP\nwould eliminate the bottleneck of a single Jenkins controller service handling hundreds of builds.\n\nCome meet Jesse, Oleg, and other Cloud Native SIG members at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Scaling Network Connections from the Jenkins Controller","tags":["jenkinsworld","jenkinsworld2018","cloud-native","performance","scalability","remoting"],"authors":[]}},{"node":{"date":"2018-02-22T00:00:00.000Z","id":"d0c104fc-7582-5b71-ae72-ad7781b4796d","slug":"/blog/2018/02/22/cheetah/","strippedHtml":"Table of Contents\n\nIntroducing \"Project Cheetah\"\nYes, but what does it DO?\nHow Do I Set Speed/Durability Settings?\n\n1. Globally, you can choose a global default durability setting:\n2. Each Pipeline can get a custom Durability Setting:\n3. Multibranch Projects can use a new BranchProperty to customize the Durability Setting.\n\nWill Performance-Optimized Mode Help Me?\nOther Goodies\nHow Did You Do It?\nWhat Next?\n\nSince it launched, Pipeline has had a bit of a Dr. Jekyll and Mr. Hyde performance problem.  In certain circumstances, Pipeline can turn from a mild-mannered CI/CD assistant into a monster.  It will happily eat storage read/write capacity like popcorn without caring about the other concerns of our friendly butler.  When combined with other additional factors, this can result in real-world stability problems.  For example, combining slow storage with a spike in running Pipelines has brought down production Jenkins at more than one organization.  Similarly, users see issues if a busy controller gets hit with an extra source of stress; past culprits have been heavy automated (ab)use of Jenkins APIs, now-solved user lookup bugs, backup jobs, and plugins run crazy that load excessive numbers of builds.  Symptoms ranged from visible slowdowns in the UI to unresponsive jobs and \"hung\" controllers.\n\nNow I’m not saying this to scare people or to criticize the technology we’ve built. Implementing Pipeline scalability best practices coupled with SSD storage keeps Jenkins in a happy place.  We just need context on the weaknesses to see why it’s important to address them.\n\nIntroducing \"Project Cheetah\"\n\nToday we’re announcing the first major results of \"Project Cheetah\", our long-running effort to address these challenges and improve Pipeline scalability.  More broadly, Cheetah aims to help in 3 places:\n\nSmall-scale containers: Pipeline needs to run leanly in resource-constrained containers, to enable easy scale-out without consuming excessive resources on shared container hosts.\n\nEnterprise systems: Pipeline needs to effectively serve high-scale Jenkins instances that are central to many large companies.\n\nGeneral case: run Pipelines a bit more quickly on average, and allow users to get much-stronger performance in worst-case scenarios.\n\nThese changes are implemented across many of the Pipeline plugins.\n\nYes, but what does it DO?\n\nProject Cheetah offers several things, but the most important is Durability Settings for all Pipelines, and especially the Performance-Optimized setting.  This setting avoids several potentially unexpected performance \"surprises\" that may strike users.  In the general case, it greatly reduces the disk IO needs for Pipeline.  How much?  Below is a graph of storage utilization with legacy Pipeline versions (think early 2017) and with the latest version using the Performance-Optimized mode.  These are tested on an AWS instance backed by an EBS volume provisioned with 300 IOPs.\n\nBefore and After:\n\nAs you can see, storage utilization goes down by a lot.  While the exact number will vary, across the benchmark testcases this results in Pipeline throughput of 2x to 6x the previous before becoming IO-bound. This also increases stability of Jenkins controllers because they will tolerate unexpected load.\n\nThis comes with a major drop in CPU IOWait as well:\n\nAnd of course the rate at which data is written to disk and number of writes/s is also reduced:\n\nFor enterprise users, timing stats often show 10-20% of normal builds is serializing the Program and writing the record of steps run (\"FlowNodes\") - the performance optimized durability setting will cut this to almost nothing (for standard pipelines, 1/100 or less) - so builds will complete faster, especially complex ones.\n\nPlease see the Pipeline Scalability documentation for deeper information on the new Durability Settings, how to use them, and which plugin versions are required to gain these features.\n\nAlso, users may see a reduction in hung Pipelines because new test utilities made it possible to identify and correct a variety of bugs.\n\nHow Do I Set Speed/Durability Settings?\n\nThere are 3 ways to configure the durability setting:\n\n1. Globally, you can choose a global default durability setting:\n\nUnder \"Manage Jenkins\" > \"Configure System\", labelled \"Pipeline Speed/Durability Settings\".  You can override these with the more specific settings below.\n\n2. Each Pipeline can get a custom Durability Setting:\n\nThis is one of the job properties located at the top of the job configuration, labelled \"Custom Pipeline Speed/Durability Level.\" This overrides the global setting. Or, use a \"properties\" step - the setting will apply to the NEXT run after the step is executed (same result).\n\n// Script //\nproperties([durabilityHint('PERFORMANCE_OPTIMIZED')])\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n    options {\n        durabilityHint('PERFORMANCE_OPTIMIZED')\n    }\n}\n\n3. Multibranch Projects can use a new BranchProperty to customize the Durability Setting.\n\nUnder the SCM you can configure a custom Branch Property Strategy and add a property for Custom Pipeline Speed/Durability Level.  This overrides the global Durability Setting and will apply to each branch at the next run.  You can also use a \"properties\" step to override the setting, but remember that you may have to run the step again to undo this.\n\nDurability settings will take effect with the next applicable Pipeline run, not immediately.  The setting will be displayed in the log.\n\nThere is a slight durability trade-off for using the Performance-Optimized mode — the appropriate section of the Pipeline Scalability documentation has the specifics.\nFor most uses we do not expect this to be important, but there are a few specific cases where users may wish to use a slower/higher-durability setting. The Best Practices are documented.\n\nWe recommend using Performance-Optimized by default, but because it does represent a slight behavioral change the initial \"Cheetah\" plugin releases defaults to maintain previous behavior. We expect to switch this default in the future with appropriate notice once people have a chance to get used to the new settings.\n\nWill Performance-Optimized Mode Help Me?\n\nYes, if your Jenkins instance uses NFS, magnetic storage, runs many Pipelines at once, or shows high iowait (above 5%)\n\nYes, if you are running Pipelines with many steps (more than several hundred).\n\nYes, if your Pipeline stores large files or complex data to variables in the script, keeps that variable in scope for future use, and then runs steps.  This sounds oddly specific but happens more than you’d expect.\n\nFor example: readFile step with a large XML/JSON file, or using configuration information from parsing such a file with One of the Utility Steps.\n\nAnother common pattern is a \"summary\" object containing data from many branches (logs, results, or statistics). Often this is visible because you’ll be adding to it often via an add/append or Map.put() operations.\n\nLarge arrays of data or Maps of configuration information are another common example of this situation.\n\nNo, if your Pipelines spend almost all their time waiting for a few shell/batch steps to finish.  This ISN’T a magic \"go fast\" button for everything!\n\nNo, if Pipelines are writing massive amounts of data to logs (logging is unchanged).\n\nNo, if you are not using Pipelines, or your system is loaded down by other factors.\n\nNo, if you don’t enable higher-performance modes for pipelines.  See above for how!\n\nOther Goodies\n\nUsers can now set an optional job property so that individual Pipelines fail cleanly rather than resuming upon restarting the controller.  This is useful for niche cases where some Pipelines are considered disposable and users would value a clean restart over Pipeline durability.\n\nWe’ve reduced classloading and reflection quite significantly, which improves scaling and reduces CPU use:\n\nScript Security (as of version 1.41) has gotten optimizations to reduce the performance overhead of Sandbox mode and eliminate lock contention so Pipeline multithreads better.\n\nPipeline Step data uses up less space on disk (regardless of the durability setting) - this should be 30% smaller.  Assume it’s a few MB per 1000 steps - but for every build after the change.\n\nEven in the low-performance/high-durability modes, some redundant writes have been removed, which decreases the number of writes by 10-20%.\n\nHow Did You Do It?\n\nThat’s probably material for another blog post or Jenkins World talk.\n\nThe short answer is: first we built a tool to simulate a full production environment and provide detailed metrics collection at scale.  Then we profiled Jenkins to identify bottlenecks and attacked them.  Rinse and repeat.\n\nWhat Next?\n\nThe next big change, which I’m calling Cheetah Part 2 is to address Pipeline’s logging. For every Step run, Pipeline writes one or more small log files. These log files are then copied into the build log content, but are retained to make it possible to easily fetch logs for each step.\n\nThis copying process means every log line is written twice, greatly reducing performance, and writing to many small files is orders of magnitude slower than appending to one big log file.\n\nWe’re going to remove this duplication and data fragmentation and use a more efficient mechanism to find per-step logs. This should further improve the ability to run Pipelines on NFS mounts and hard-drive-backed storage, and should significantly improve performance at scale.\n\nBesides this, there’s a variety of different tactical improvements to improve scaling behavior and reduce resource needs.\n\nThe Project Cheetah work doesn’t free users to completely ignore Pipeline scaling best practices and previous suggestions.  Nor does it eliminate the need for efficient GC settings.  But this and other enhancements from the last year can significantly improve the storage situation for most users and reduce the penalties for worst-case behaviors.  When you add all the pieces together, the result is a faster, leaner, more reliable Pipeline experience.","title":"Project Cheetah - Faster, Leaner Pipeline That Can Keep Up With Demand","tags":["pipeline","performance","scalability"],"authors":[]}},{"node":{"date":"2017-02-01T00:00:00.000Z","id":"aa509c7b-3f24-5cce-8519-dda84cd1233e","slug":"/blog/2017/02/01/pipeline-scalability-best-practice/","strippedHtml":"This is a guest post by Sam Van Oort,\nSoftware Engineer at CloudBees and contributor to\nthe Jenkins project.\n\nToday I’m going to show you best practices to write scalable and robust Jenkins Pipelines. This is drawn from a\ncombination of work with the internals of Pipeline and observations with large-scale users.\n\nPipeline code works beautifully for its intended role of automating\nbuild/test/deploy/administer tasks.  As it is pressed into more complex roles\nand unanticipated uses, some users hit issues.  In these cases, applying the\nbest practices can make the difference between:\n\nA single controller running\nhundreds\nof concurrent builds on low end hardware (4 CPU cores and 4 GB of\nheap)\n\nRunning a couple dozen builds and bringing a controller to its knees or\ncrashing it…​even with 16+ CPU cores and 20+ GB of heap!\n\nThis has been seen in the wild.\n\nFundamentals\n\nTo understand Pipeline behavior you must understand a few points about\nhow it executes.\n\nExcept for the steps themselves, all of the Pipeline logic, the Groovy conditionals, loops, etc execute on the controller. Whether simple or complex! Even inside a node block!\n\nSteps may use executors to do work where appropriate, but each\nstep has a small on-controller overhead too.\n\nPipeline code is written as Groovy but the execution model is\nradically transformed at compile-time to Continuation Passing Style\n(CPS).\n\nThis transformation provides valuable safety and durability\nguarantees for Pipelines, but it comes with trade-offs:\n\nSteps can invoke Java and execute fast and efficiently, but Groovy\nis much slower to run than normal.\n\nGroovy logic requires far more memory, because an object-based\nsyntax/block tree is kept in memory.\n\nPipelines persist the program and its state frequently to be able to\nsurvive failure of the controller.\n\nFrom these we arrive at a set of best practices to make pipelines more\neffective.\n\nBest Practices For Pipeline Code\n\nThink of Pipeline code as glue: just enough Groovy code to connect\ntogether the Pipeline steps and integrate tools, and no more.\n\nThis makes code easier to maintain, more robust against bugs, and\nreduces load on controllers.\n\nKeep it simple: limit the amount of complex logic embedded in the\nPipeline itself (similarly to a shell script) and avoid treating it as a\ngeneral-purpose programming language.\n\nPipeline restricts all variables to Serializable types, so keeping\nPipeline logic simple helps avoid a NotSerializableException - see\nappendix at the bottom.\n\nUse @NonCPS -annotated functions for slightly more complex work.\nThis means more involved processing, logic, and transformations. This\nlets you leverage additional Groovy & functional features for more\npowerful, concise, and performant code.\n\nThis still runs on controllers so be mindful of complexity, but is much\nfaster than native Pipeline code because it doesn’t provide durability\nand uses a faster execution model. Still, be mindful of the CPU cost and\noffload to executors for complex work (see below).\n\n@NonCPS functions can use a much broader subset of the Groovy\nlanguage, such as iterators and functional features, which makes them\nmore terse and fast to write.\n\n@NonCPS functions should not use Pipeline steps internally, however\nyou can store the result of a Pipeline step to a variable and use it\nthat as the input to a @NonCPS function.\n\nGotcha: It’s not guaranteed that use of a step will generate an\nerror (there is an open RFE to implement that), but you should not rely\non that behavior. You may see improper handling of exceptions, in\nparticular.\n\nWhile normal Pipeline is restricted to serializable local variables\n(see appendix at bottom), @NonCPS functions can use more complex,\nnonserializable types internally (for example regex matchers, etc). Parameters\nand return types should still be Serializable, however.\n\nGotcha: improper usages are not guaranteed to raise an error with\nnormal Pipeline (optimizations may mask the issue), but it is unsafe to\nrely on this behavior.\n\nPrefer external scripts/tools for complex or CPU-expensive\nprocessing rather than Groovy language features. This offloads work\nfrom the controller to external executors, allowing for easy scale-out of\nhardware resources. It is also generally easier to test because these\ncomponents can be tested in isolation without the full on-controller\nexecution environment.\n\nMany software vendors will provide easy command-line clients for\ntheir tools in various programming languages. These are often robust,\nperformant, and easy to use. Plugins offer another option (see below).\n\nShell or batch steps are often the easiest way to integrate these\ntools, which can be written in any language. For example: sh “java -jar\nclient.jar $endPointUrl $inputData” for a Java client, or sh “python\njiraClient.py $issueId $someParam” for a Python client.\n\nGotcha: especially avoid Pipeline XML or JSON parsing using Groovy’s XmlSlurper and JsonSlurper!  Strongly prefer command-line tools or scripts.\n\nThe Groovy implementations are complex and as a result more brittle in Pipeline use.\n\nXmlSlurper and JsonSlurper can carry a high memory and CPU cost in pipelines\n\nxmllint and xmlstartlet are command-line tools offering XML extraction via xpath\n\njq offers the same functionality for JSON\n\nThese extraction tools may be coupled to curl or wget for fetching information from an HTTP API\n\nExamples of other places to use command-line tools:\n\nTemplating large files\n\nNontrivial integration with external APIs (for bigger vendors,\nconsider a Jenkins plugin if a quality offering exists)\n\nSimulations/complex calculations\n\nBusiness logic\n\nConsider existing plugins for external integrations. Jenkins has a\nwealth of plugins, especially for source control, artifact management,\ndeployment systems, and systems automation. These can greatly reduce the\namount of Pipeline code to maintain. Well-written plugins may be\nfaster and more robust than Pipeline equivalents.\n\nConsider both plugins and command-line clients (above) — one may be\neasier than the other.\n\nPlugins may be of widely varying quality. Look at the number of installations and how frequently and recently updates appear in the changelog. Poorly-maintained plugins\nwith limited installations may actually be worse than writing a little\ncustom Pipeline code.\n\nAs a last resort, if there is a good-quality plugin that is not\nPipeline-enabled, it is fairly easy to write a Pipeline wrapper to\nintegrate it or write a custom step that will invoke it.\n\nAssume things will go wrong: don’t rely on workspaces being clean\nof the remnants from previous executions, clean explicitly where needed.\nMake use of timeouts and retry steps (that’s what they’re there for).\n\nWithin a git repository, git clean -fdx is a good way to\naccomplish this and reduces the amount of SCM cloning\n\nDO use parameterized Pipelines and variables to make your Pipeline\nscripts more reusable. Passing in parameters is especially helpful for\nhandling different environments and should be preferred to applying\nconditional lookup logic; however, try to limit parameterized pipelines invoking each other.\n\nTry to limit business logic embedded in Pipelines. To some extent\nthis is inevitable, but try to focus on tasks to complete instead,\nbecause this yields more maintainable, reusable, and often more\nperformant Pipeline code.\n\nOne code smell that points to a problem is many hard-coded\nconstants. Consider taking advantage of the options above to refactor\ncode for better composability.\n\nFor complex cases, consider using Jenkins integration options\n(plugins, Jenkins API calls, invoking input steps externally) to offload\nimplementation of more complex business rules to an external system if\nthey fit more naturally there.\n\nPlease, think of these as guidelines, not strict rules – Jenkins\nPipeline provides a great deal of power and flexibility, and it’s there\nto be used.\n\nBreaking enough of these rules at scale can cause controllers to fail by\nplacing an unsustainable load on them.\n\nFor additional guidance, I also recommend\nthis\nJenkins World talk\non how to engineer Pipelines for speed and performance:\n\nAppendix: Serializable vs. Non-Serializable Types:\n\nTo assist with Pipeline development, here are common serializable and\nnon-serializable types, to assist with deciding if your logic can be CPS\nor should be in a @NonCPS function to avoid issues.\n\nCommon Serializable Types (safe everywhere):\n\nAll primitive types and their object wrappers: byte, boolean, int,\ndouble, short, char\n\nStrings\n\nenums\n\nArrays of serializable types\n\nArrayLists and normal Groovy Lists\n\nSets: HashSet\n\nMaps: normal Groovy Map, HashMap, TreeMap\n\nExceptions\n\nURLs\n\nDates\n\nRegex Patterns (compiled patterns)\n\nCommon non-Serializable Types (only safe in @NonCPS functions):\n\nIterators: this is a common problem. You need to use C-style loop, i.e.\nfor(int i=0; i\n\nRegex Matchers (you can use the\nbuilt-in functions in String, etc, just not the Matcher itself)\n\nImportant: JsonObject, JsonSlurper, etc in Groovy 2+ (used in some 2.x+\nversions of Jenkins).\n\nThis is due to an internal implementation change — earlier versions may serialize.","title":"Best Practices for Scalable Pipeline Code","tags":["pipeline","performance","scalability"],"authors":[]}},{"node":{"date":"2016-11-21T00:00:00.000Z","id":"bf6fcc51-7017-5159-91de-3d955a72998d","slug":"/blog/2016/11/21/gc-tuning/","strippedHtml":"This is a\ncross\npost by Sam Van Oort, Software Engineer at\nCloudBees and contributor to the Jenkins project.\n\nToday I’m going to show you how easy it is to tune Jenkins Java settings to\nmake your controllers more responsive and stable, especially with large heap sizes.\n\nThe Magic Settings:\n\nBasics: -server -XX:+AlwaysPreTouch\n\nGC Logging: -Xloggc:$JENKINS_HOME/gc-%t.log -XX:NumberOfGCLogFiles=5 -XX:+UseGCLogFileRotation -XX:GCLogFileSize=20m -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCCause -XX:+PrintTenuringDistribution -XX:+PrintReferenceGC -XX:+PrintAdaptiveSizePolicy\n\nG1 GC settings: -XX:+UseG1GC -XX:+ExplicitGCInvokesConcurrent -XX:+ParallelRefProcEnabled -XX:+UseStringDeduplication -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20 -XX:+UnlockDiagnosticVMOptions -XX:G1SummarizeRSetStatsPeriod=1\n\nHeap settings: set your minimum heap size ( -Xms) to at least 1/2 of your maximum size ( -Xmx).\n\nNow, let’s look at where those came from!  We’re going to focus on garbage\ncollection (GC) here and dig fast and deep to strike for gold; if you’re not\nfamiliar with GC fundamentals\ntake a look at this source.\n\nBecause performance tuning is data driven, I’m going to use real-world data\nselected three very large Jenkins instances that I help support.\n\nWhat we’re not going to do: Jenkins basics, or play with max heap.  See the\nsection \"what should I do before tuning.\"  This is for cases where we really\ndo need a big heap and can’t easily split our Jenkins controllers into smaller\nones.\n\nThe Problem: Hangups\n\nSymptom: Users report that the Jenkins instance periodically hangs, taking\nseveral seconds to handle normally fast requests.  We may even see lockups or\ntimeouts from systems communicating with the Jenkins controller (build agents,\netc).  In long periods of heavy load, users may report Jenkins running slowly.\nApplication monitoring shows that during lockups all or most of the CPU cores\nare fully loaded, but there’s not enough activity to justify it.  Process and\nJStack dumps will reveal that the most active Java threads are doing garbage\ncollection.\n\nWith Instance A, they had this problem.  Their Jenkins Java arguments are very\nclose to the default, aside from sizing the heap:\n\n24 GB max heap, 4 GB initial, default GC settings (ParallelGC)\n\nA few flags set (some coming in as defaults): -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:+ReduceSignalUsage -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation\n\nAfter enabling garbage collection (GC) logging we see the following rough stats:\n\n.\n\nDiving deeper, we get this chart of GC pause durations:\n\nKey stats:\n\nThroughput: 99.64%  (percent of time spent executing application code, not doing garbage collection)\n\nAverage GC time: 348 ms (ugh!)\n\nGC cycles over 2 seconds: 36 (2.7%)\n\nMinor/Full GC average time: 263 ms / 2.803 sec\n\nObject creation & promotion rate: 42.4 MB/s & 1.99 MB/s\n\nExplanations:\n\nAs you can see, young GC cycles very quickly clear away freshly-created\ngarbage, but the deeper old-gen GC cycles run very slowly: 2-4 seconds. This is\nwhere our problems happen.  The default Java garbage collection algorithm\n(ParallelGC) pauses everything when it has to collect garbage (often called a\n\"stop the world pause\"). During that period, Jenkins is fully halted: normally\n(with small heaps) these pauses are too brief to be an issue.  With heaps of 4\nGB or larger, the time required becomes long enough to be a problem: several\nseconds over short windows, and over a longer interval you occasionally see\nmuch longer pauses (tens of seconds, or minutes.)\n\nThis is where the user-visible hangs and lock-ups happen.  It also adds\nsignificant latency to those build/deploy tasks.  In periods of heavy load, the\nsystem was even experiencing hangs of 30+ seconds for a single full GC cycle.\nThis was long enough to trigger network timeouts (or internal Jenkins thread\ntimeouts) and cause even larger problems.\n\nFortunately there’s a solution: the concurrent low-pause garbage collection\nalgorithms, Concurrent Mark Sweep (CMS) and Garbage First (G1). These attempt\nto do much of the garbage collection concurrently with application threads,\nresulting in much shorter pauses (at a slight cost in extra CPU use).  We’re\ngoing to focus on G1, because it is slated to become the default in Java 9 and\nis the official recommendation for large heap sizes.\n\nLet’s see what happens when someone uses G1 on a similarly-sized Jenkins\ncontroller with Instance B (17 GB heap):\n\nTheir settings:\n\n16 GB max heap, 0.5 GB initial size\n\nJava flags (mostly defaults, except for G1): -XX:+UseG1GC -XX:+UseCompressedClassPointers -XX:+UseCompressedOops\n\nAnd the GC log analysis:\n\nKey stats:\n\nThroughput: 98.76%  (not great, but still only slowing things down a bit)\n\nAverage GC time: 128 ms\n\nGC cycles over 2 seconds: 11, 0.27%\n\nMinor/Full GC average time: 122 ms / 1 sec 232 ms\n\nObject creation & promotion rate: 132.53 MB/s & 522 KB/s\n\nOkay, much better : some improvement may be expected from a 30% smaller\nheap, but not as much as we’ve seen.  Most of the GC pauses are well\nunder 2 seconds, but we have 11 outliers - long Full GC pauses of 2-12 seconds.\nThose are troubling; we’ll take a deeper dive into their causes in a second.\nFirst, let’s look at the big picture and at how Jenkins behaves with G1 GC for\na second instance.\n\nG1 Garbage Collection with Instance C (24 GB heap):\n\nTheir settings:\n\n24 GB max heap, 24 GB initial heap, 2 GB max metaspace\n\nSome custom flags: `-XX:+UseG1GC -XX:+AlwaysPreTouch -XX:+UseStringDeduplication  -XX:+UseCompressedClassPointers -XX:+UseCompressedOops `\n\nClearly they’ve done some garbage collection tuning and optimization.  The\nAlwaysPreTouch pre-zeros allocated heap pages, rather than waiting until\nthey’re first used. This is suggested especially for large heap sizes, because\nit trades slightly slower startup times for improved runtime performance.  Note\nalso that they pre-allocated the whole heap.  This is a common optimization.\n\nThey also enabled StringDeduplication, a G1 option introduced in Java 8 Update\n20 that transparently replaces identical character arrays with pointers to the\noriginal, reducing memory use (and improving cache performance).  Think of it\nlike String.intern() but it silently happens during garbage collection.  This\nis a concurrent operation added on to normal GC cycles, so it doesn’t pause the\napplication.  We’ll look at its impacts later.\n\nLooking at the basics:\n\nSimilar picture to Instance B, but it’s hidden by the sheer number of points\n(this is a longer period here, 1 month).  Those same occasional Full GC\noutliers are present!\n\nKey stats:\n\nThroughput: 99.93%\n\nAverage GC time: 127 ms\n\nGC cycles over 2 seconds: 235 (1.56%)\n\nMinor/Full GC average time: 56 ms / 3.97 sec\n\nObject creation & promotion rate: 34.06 MB/s & 286 kb/s\n\nOverall fairly similar to Instance B: ~100 ms GC cycles, all the minor GC\ncycles are very fast.  Object promotion rates sound similar.\n\nRemember those random long pauses?\n\nLet’s find out what caused them and how to get rid of them.  Instance B had 11\nsuper-long pause outliers.  Let’s get some more detail, by opening GC Logs in\nGCViewer.\nThis tool gives a tremendous amount of information.  Too much, in fact —  I\nprefer to use\nGCEasy.io\nexcept where needed.  Since GC logs do not contain compromising information\n(unlike heap dumps or some stack traces), web apps are a great tool for\nanalysis.\n\nWhat we care about are at the Full GC times in the middle (highlighted).  See\nhow much longer they are vs. the young and concurrent GC cycles up top (2\nseconds or less)?\n\nNow, I lied a bit earlier - sorry!  For concurrent garbage collectors, there\nare actually 3 modes: young GC, concurrent GC, and full GC.  Concurrent GC\nreplaces the Full GC mode in Parallel GC with a faster concurrent operation\nthat runs in parallel with the application.  But in a few cases, we are\nforced to fall back to a non-concurrent Full GC operation, which will use the\nserial  (single-threaded) garbage collector.  That means that even if we have\n30+ CPU cores, only one is working. This is what is happening here, and on a\nlarge-heap, multicore system it is S  L  O  W.  How slow?  280 MB/s vs. 12487\nMB/s for Instance B (for instance C, the difference is also about 50:1).\n\nWhat triggers a full GC instead of concurrent:\n\nExplicit calls to System.gc() (most common culprit, often tricky to trace down)\n\nMetadata GC Threshold: Metaspace (used for Class data mostly) has hit the\ndefined size to force garbage collection or increase it.  Documentation is\nterrible for this,\nStack Overflow\nwill be your friend.\n\nConcurrent mode failure: concurrent GC can’t complete fast enough to keep up\nwith objects the application is creating (there are JVM arguments to trigger\nconcurrent GC earlier)\n\nHow do we fix this?\n\nFor explicit GC:\n\n-XX:+DisableExplicitGC will turn off Full GC triggered by System.gc().  Often set in production, but the below option is safer.\n\nWe can trigger a concurrent GC in place of a full one with -XX:+ExplicitGCInvokesConcurrent - this will take the explicit call as a hint to do deeper cleanup, but with less performance cost.\n\nGotcha for people who’ve used CMS: if you have used CMS in the past, you\nmay have used the option -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses — which does what it says.  This option will silently fail in G1, meaning you\nstill see the very long pauses from Full GC cycles as if it wasn’t set (no\nwarning is generated).  I have logged a JVM bug for this issue.\n\nFor the Metadata GC threshold:\n\nIncrease your initial metaspace to the final amount to avoid resizing. For example: -XX:MetaspaceSize=500M\n\nInstance C also suffered the same problem with explicit GC calls, with almost\nall our outliers accounted for (230 out of 235) by slow, nonconcurrent Full GC\ncycles (all from explicit System.gc() calls, since they tuned metaspace):\n\nHere’s what GC pause durations look like if we remove the log entries for the\nexplicit System.gc() calls, assuming that they’ll blend in with the other\nconcurrent GC pauses (not 100% accurate, but a good approximation):\n\nInstance B:\n\nThe few long Full GC cycles at the start are from metaspace expansion — they\ncan be removed by increasing initial Metaspace size, as noted above. The\nspikes?  That’s when we’re about to resize the Java heap, and memory pressure\nis high. You can avoid this by setting the minimum/initial heap to at least\nhalf of the maximum, to limit resizing.\n\nStats:\n\nThroughput: 98.93%\n\nAverage GC time: 111 ms\n\nGC cycles over 2 seconds: 3\n\nMinor & Full or concurrent GC average time: 122 ms / 25 ms (yes, faster than minor!)\n\nObject creation & promotion rate: 132.07 MB/s & 522 kB/s\n\nInstance C:\n\nStats:\n\nThroughput: 99.97%\n\nAverage GC time: 56 ms\n\nGC cycles over 2 seconds: 0 (!!!)\n\nMinor & Full or concurrent GC average time: 56 ms & 10 ms (yes, faster than minor!)\n\nObject creation & promotion rate: 33.31 MB/s & 286 kB/s\n\nSide point: GCViewer is claiming GC performance of 128 GB/s (not unreasonable, we clear ~10 GB of young generation in under 100 ms usually)\n\nOkay, so we’ve tamed the long worst-case pauses!\n\nBut What About Those Long Minor GC Pauses We Saw?\n\nOkay, now we’re in the home stretch!  We’ve tamed the old-generation GC pauses\nwith concurrent collection, but what about those longer young-generation\npauses?  Lets look at stats for the different phases and causes again in\nGCViewer.\n\nHighlighted in yellow we see the culprit: the remark phase of G1 garbage\ncollection. This stop-the-world phase ensures we’ve identified all live\nobjects, and process references (\nmore info).\n\nLet’s look at a sample execution to get more info:\n\n2016-09-07T15:28:33.104+0000: 26230.652: [GC remark 26230.652: [GC ref-proc, 1.7204585 secs], 1.7440552 secs]\n\n [Times: user=1.78 sys=0.03, real=1.75 secs]\n\nThis turns out to be typical for the GC log: the longest pauses are spent in\nreference processing. This is not surprising because Jenkins internally uses\nreferences heavily for caching, especially weak references, and the default\nreference processing algorithm is single-threaded.  Note that user (CPU) time\nmatches real time, and it would be higher if we were using multiple cores.\n\nSo, we add the GC flag -XX:+ParallelRefProcEnabled which enables us to use the multiple cores more effectively.\n\nTuning young-generation GC further based on Instance C:\n\nBack to GCViewer we go, to see what’s time consuming with the GC for Instance C.\n\nThat’s good, because most of the time is just sweeping out the trash\n(evacuation pause).  But the 1.8 second pause looks odd.  Let’s look at the raw\nGC log for the longest pause:\n\n2016-09-24T16:31:27.738-0700: 106414.347: [GC pause (G1 Evacuation Pause) (young), 1.8203527 secs]\n[Parallel Time: 1796.4 ms, GC Workers: 8]\n [GC Worker Start (ms): Min: 106414348.2, Avg: 106414348.3, Max: 106414348.6, Diff: 0.4]\n[Ext Root Scanning (ms): Min: 0.3, Avg: 1.7, Max: 5.7, Diff: 5.4, Sum: 14.0]\n  [Update RS (ms): Min: 0.0, Avg: 7.0, Max: 19.6, Diff: 19.6, Sum: 55.9]\n    [Processed Buffers: Min: 0, Avg: 45.1, Max: 146, Diff: 146, Sum: 361]\n [Scan RS (ms): Min: 0.2, Avg: 0.4, Max: 0.7, Diff: 0.6, Sum: 3.5]\n [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.2]\n [Object Copy (ms): Min: 1767.1, Avg: 1784.4, Max: 1792.6, Diff: 25.5, Sum: 14275.2]\n [Termination (ms): Min: 0.3, Avg: 2.4, Max: 3.5, Diff: 3.2, Sum: 19.3]\n    [Termination Attempts: Min: 11, Avg: 142.5, Max: 294, Diff: 283, Sum: 1140]\n [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.4, Diff: 0.3, Sum: 0.8]\n [GC Worker Total (ms): Min: 1795.9, Avg: 1796.1, Max: 1796.2, Diff: 0.3, Sum: 14368.9]\n [GC Worker End (ms): Min: 106416144.4, Avg: 106416144.5, Max: 106416144.5, Diff: 0.1]\n\n…​oh, well dang. Almost the entire time (1.792 s out of 1.820) is walking\nthrough the live objects and copying them.  And wait, what about this line,\nshowing the summary statistics:\n\nEden: 13.0G(13.0G)->0.0B(288.0M) Survivors: 1000.0M->936.0M Heap: 20.6G(24.0G)->7965.2M(24.0G)]\n\nGood grief, we flushed out 13 GB (!!!) of freshly-allocated garbage in one\nswoop and compacted the leftovers!  No wonder it was so slow.  I wonder how we\naccumulated so much…​\n\nOh, right…​ we set up for 24 GB of heap initially, and each minor GC clears\nmost of the young generation.  Okay, so we’ve set aside tons of space for trash\nto collect, which means longer but less frequent GC periods.  This also gets\nthe best performance from Jenkins memory caches which are using WeakReferences\n(survives until collected by GC) and SoftReferences (more long-lived). Those\ncaches boost performance a lot.\n\nWe could take actions to prevent those rare longer pauses. The best ways are to\nlimit total heap size or reduce the value of -XX:MaxGCPauseMillis=200 from\nits default (200).  A more advanced way (if those don’t help enough) is to\nexplicitly set the maximum size of the young generation smaller (say\n-XX:G1MaxNewSizePercent=45 instead of the default of 60).  We could also\nthrow more CPUs at the problem.\n\nBut if we look up, most pauses are around 100 ms (200 ms is the default value\nfor MaxGCPauseMillis).  For Jenkins on this hardware, this appears to work\njust fine and a rare longer pause is OK as long as they don’t get too\nbig.  Also remember, if this happens often, G1 GC will try to autotune for\nlower pauses and more predictable performance.\n\nA Few Final Settings\n\nWe mentioned StringDeduplication was on with Instance C, what is the impact?\nThis only triggers on Strings that have survived a few generations (most of our\ngarbage does not), has limits on the CPU time it can use, and replaces\nduplicate references to their immutable backing character arrays.\nFor more info, look here.\nSo, we should be trading a little CPU time for improved memory efficiently\n(similarly to string interning).\n\nAt the beginning, this has a huge impact:\n\n[GC concurrent-string-deduplication, 375.3K->222.5K(152.8K), avg 63.0%, 0.0     024966 secs]\n[GC concurrent-string-deduplication, 4178.8K->965.5K(3213.2K), avg 65.3%, 0     .0272168 secs]\n[GC concurrent-string-deduplication, 36.1M->9702.6K(26.6M), avg 70.3%, 0.09     65196 secs]\n[GC concurrent-string-deduplication, 4895.2K->394.9K(4500.3K), avg 71.9%, 0     .0114704 secs]\n\nThis peaks at an average of about ~90%:\n\nAfter running for a month, less of an impact - many of the strings that can be\ndeduplicated already are:\n\n[GC concurrent-string-deduplication, 138.7K->39.3K(99.4K), avg 68.2%, 0.0007080 secs]\n[GC concurrent-string-deduplication, 27.3M->21.5M(5945.1K), avg 68.1%, 0.0554714 secs]\n[GC concurrent-string-deduplication, 304.0K->48.5K(255.5K), avg 68.1%, 0.0021169 secs]\n[GC concurrent-string-deduplication, 748.9K->407.3K(341.7K), avg 68.1%, 0.0026401 secs]\n[GC concurrent-string-deduplication, 3756.7K->663.1K(3093.6K), avg 68.1%, 0.0270676 secs]\n[GC concurrent-string-deduplication, 974.3K->17.0K(957.3K), avg 68.1%, 0.0121952 secs]\n\nHowever it’s cheap to use: in average, each dedup cycle takes 8.8 ms and\nremoves 2.4 kB of duplicates.  The median takes 1.33 ms and removes 17.66 kB\nfrom the old generation.  A small change per cycle, but in aggregate it adds up\nquickly — in periods of heavy load, this can save hundreds of megabytes of\ndata. But that’s still small, relative to multi-GB heaps.\n\nConclusion: turn string deduplication on string deduplication is fairly\ncheap to use, and reduces the steady-state memory needed for Jenkins.  That\nfrees up more room for the young generation, and should overall reduce GC time\nby removing duplicate objects.  I think it’s worth turning on.\n\nSoft reference flushing: Jenkins uses soft references for caching build\nrecords and in pipeline FlowNodes.  The only guarantee for these is that they\nwill be removed instead of causing an OutOfMemoryError…​ however Java\napplications can slow to a crawl from memory pressure long before that happens.\nThere’s an option that provides a hint to the JVM based on time & free memory,\ncontrolled by -XX:SoftRefLRUPolicyMSPerMB (default 1000).  The SoftReferences\nbecome eligible for garbage collection after this many milliseconds have\nelapsed since last touch…​ per MB of unused heap (vs the maximum).  The\nreferenced objects don’t count towards that target.  So, with 10 GB of heap\nfree and the default 1000 ms setting, soft references stick around for ~2.8\nhours (!).\n\nIf the system is continuously allocating more soft references, it may trigger\nheavy GC activity, rather than clearing out soft references. See the open bug\nJDK-6912889\nfor more details.\n\nIf Jenkins consumes excessive old generation memory, it may help to make soft\nreferences easier to flush  by reducing -XX:SoftRefLRUPolicyMSPerMB from its\ndefault (1000) to something smaller (say 10-200).  The catch is that\nSoftReferences are often used for objects that are relatively expensive to\nload, such lazy-loaded build records and pipeline FlowNode data.\n\nCaveats\n\nG1 vs. CMS:\n\nG1 was available on later releases of JRE 7, but unstable and slow. If you\nuse it you absolutely must be using JRE 8, and the later the release the better\n(it’s gotten a lot of patches).  Googling around will show horrible G1 vs CMS\nbenchmarks from around 2014: these are probably best ignored, since the G1\nimplementation was still immature then. There’s probably a niche for CMS use\nstill, especially on midsized heaps (1-3 GB) or where settings are already\ntuned.  With appropriate tuning it can still perform generally well for\nJenkins (which mostly generates short-lived garbage), but CMS eventually suffer\nfrom heap fragmentation and need a slow, non-concurrent Full GC to clear this.\nIt also needs considerably more tuning than G1.\n\nGeneral GC tuning caveats :\n\nNo single setting is perfect for everybody.  We avoid tweaking settings that we\ndon’t have strong evidence for here, but there are of course many additional\nsettings to tweak.  One shouldn’t change them without evidence though, because\nit can cause unexpected side effects.  The GC logs we enabled earlier will\ncollect this evidence.  The only setting that jumps out as a likely candidate\nfor further tuning is G1 region size (too small and there are many humungous\nobject allocations, which hurt performance).  Running on smaller systems,\nI’ve seen evidence that regions shouldn’t be smaller than 4 MB because\nthere are 1-2 MB objects allocated somewhat regularly — but it’s not\nenough to make solid guidance without more data.\n\nWhat Should I Do Before Tuning Jenkins GC:\n\nIf you’ve seen\nStephen Connolly’s excellent Jenkins World talk,\nyou know that most Jenkins instances can and should get by with 4 GB or less of\nallocated heap, even up to very large sizes.  You will want to turn on GC\nlogging (suggested above) and look at stats over a few weeks (remember\nGCeasy.io).\nIf you’re not seeing periodic longer pause times, you’re probably okay.\n\nFor this post we assume we’ve already done the basic performance work for Jenkins:\n\nJenkins is running on fast, SSD-backed storage.\n\nWe’ve set up build rotation for your Jobs, to delete old builds so they don’t pile up.\n\nThe weather column is already disabled for folders.\n\nAll builds/deploys are running on build agents not on the controller. If the controller has executors allocated, they are exclusively used for backup tasks.\n\nWe’ve verified that Jenkins really does need the large heap size and can’t easily be split into separate controllers.\n\nIf not, we need to do that FIRST before looking at GC tuning, because those will have larger impacts.\n\nConclusions\n\nWe’ve gone from:\n\nAverage 350 ms pauses (bad user experience) including less frequent 2+ second generation pauses\n\nTo an average pause of ~50 ms, with almost all under 250 ms\n\nReduced total memory footprint from String deduplication\n\nHow:\n\nUse Garbage First (G1) garbage collection, which performs generally very well for Jenkins.  Usually there’s enough spare CPU time to enable concurrent running.\n\nEnsure explicit System.gc() and metaspace resizing do not trigger a Full GC because this can trigger a very long pause\n\nTurn on parallel reference processing for Jenkins to use all CPU cores fully.\n\nUse String deduplication, which generates a tidy win for Jenkins\n\nEnable GC logging, which can then be used for the next level of tuning and diagnostics, if needed.\n\nThere’s still a little unpredictability, but using appropriate settings gives a\nmuch more stable, responsive CI/CD server…​ even up to 20 GB heap sizes!\n\nFurther Reading:\n\nG1GC fundamentals\n\nMechanicalSympathy: Garbage Collection Distilled\n\nOracle Garbage First Garbage Collector Tuning\n\nOne additional thing\n\nI’ve added -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20 to our\noptions above.  This is covering a complex and usually infrequent case where G1\nself-tuning can trigger bad performance for Jenkins — but that’s material for\nanother post…​","title":"Tuning Jenkins GC For Responsiveness and Stability with Large Instances","tags":["performance","scalability","administration"],"authors":[]}},{"node":{"date":"2016-06-15T00:00:00.000Z","id":"92e6efae-588c-5a80-886a-8fe7822dcea3","slug":"/blog/2016/06/15/jenkins-pipeline-scalability/","strippedHtml":"This is a guest post by Damien\nCoraboeuf, Jenkins project contributor and Continuous Delivery consultant.\n\nImplementing a CI/CD solution based on Jenkins has become very easy. Dealing\nwith hundreds of jobs? Not so much. Having to scale to thousands of jobs?\nNow this is a real challenge.\n\nThis is the story of a journey to get out of the jungle of jobs…​\n\nStart of the journey\n\nAt the beginning of the journey there were several projects using roughly the same\ntechnologies. Those projects had several\nbranches, for maintenance of releases, for new features.\n\nIn turn, each of those branches had to be carefully built, deployed on different\nplatforms and versions, promoted so they could be tested for functionalities,\nperformances and security, and then promoted again for actual delivery.\n\nAdditionally, we had to offer the test teams the means to deploy any version of\ntheir choice on any supported platform in order to carry out some manual tests.\n\nThis represented, for each branch, around 20 jobs. Multiply this by the number of\nbranches and projects, and there you are: more than two years after the start\nof the story, we had more than 3500 jobs.\n\n3500 jobs. Half a dozen people to manage them all…​\n\nPreparing the journey\n\nHow did we deal with this load?\n\nWe were lucky enough to have several assets:\n\ntime - we had time to design a solution before the scaling went really out of\ncontrol\n\nforecast - we knew that the scaling would occur and we were not taken by\nsurprise\n\ntooling - the Jenkins Job DSL\nwas available, efficient and well documented\n\nWe also knew that, in order to scale, we’d have to provide a solution with the\nfollowing characteristics:\n\nself-service - we could not have a team of 6 people become a bottleneck for\nenabling CI/CD in projects\n\nsecurity - the solution had to be secure enough in order for it to be used by\nremote developers we never met and didn’t know\n\nsimplicity - enabling CI/CD had to be simple so that people having\nnever heard of it could still use it\n\nextensibility - no solution is a one-size-fits-all and must be flexible\nenough to allow for corner cases\n\nAll the mechanisms described in this article are available through the\nJenkins Seed plugin.\n\nCreating pipelines using the Job DSL and embedding the scripts in the code was\nsimple enough. But what about branching? We needed a mechanism to allow the\ncreation of pipelines per branch, by downloading the associated DSL and to\nrun it in a dedicated folder.\n\nBut then, all those projects, all those branches, they were mostly using the\nsame pipelines, give or take a few configurable items. Going this way would\nhave lead to a terrible duplication of code, transforming a job maintenance\nnightmare into a code maintenance nightmare.\n\nPipeline as configuration\n\nOur trick was to transform this vision of \"pipeline as code\" into a \"pipeline\nas configuration\":\n\nby maintaining well documented and tested \"pipeline libraries\"\n\nby asking projects to describe their pipeline not as code, but as property\nfiles which would:\n\ndefine the name and version of the DSL pipeline library to use\n\nuse the rest of the property file to configure the pipeline library, using\nas many sensible default values as possible\n\nPiloting the pipeline from the SCM\n\nOnce this was done, the only remaining trick was to automate the creation,\nupdate, start and deletion of the pipelines using SCM events. By enabling SCM\nhooks (in GitHub, BitBucket or even in Subversion), we could:\n\nautomatically create a pipeline for a new branch\n\nregenerate a pipeline when the branch’s pipeline description was modified\n\nstart the pipeline on any other commit on the branch\n\nremove the pipeline when the branch was deleted\n\nOnce a project wants to go in our ecosystem, the Jenkins team \"seeds\" the\nproject into Jenkins, by running a job and giving a few parameters.\n\nIt will create a folder for the project and grant proper authorisations, using\nActive Directory group names based on the project name.\n\nThe hook for the project must be registered into the SCM and you’re up and\nrunning.\n\nConfiguration and code\n\nMixing the use of strong pipeline libraries configured by properties and the\ndirect use of the Jenkins Job DSL is still possible. The Seed plugin\nsupports all kinds of combinations:\n\nuse of pipeline libraries only - this can even be enforced\n\nuse a DSL script which can in turn use some classes and methods defined in\na pipeline library\n\nuse of a Job DSL script only\n\nUsually, we tried to have a maximum reuse, through only pipeline libraries, for\nmost of our projects, but in other circumstances, we were less strict and\nallowed some teams to develop their own pipeline script.\n\nEnd of the journey\n\nIn the end, what did we achieve?\n\nSelf service ✔︎\n\nPipeline automation from SCM - no intervention from the Jenkins team but for\nthe initial bootstrapping\n\nGetting a project on board of this system can be done in a few minutes only\n\nSecurity ✔︎\n\nProject level authorisations\n\nNo code execution on the controller\n\nSimplicity ✔︎\n\nProperty files\n\nExtensibility ✔︎\n\nPipeline libraries\n\nDirect job DSL still possible\n\nSeed and Pipeline plugin\n\nNow, what about the Pipeline plugin? Both\nthis plugin and the Seed plugin have common functionalities:\n\nWhat we have found in our journey is that having a \"pipeline as configuration\"\nwas the easiest and most secure way to get a lot of projects on board, with\ndevelopers not knowing Jenkins and even less the DSL.\n\nThe outcome of the two plugins is different:\n\none pipeline job for the Pipeline plugin\n\na list of orchestrated jobs for the Seed plugin\n\nIf time allows, it would be probably a good idea to find a way to integrate the\nfunctionalities of the Seed plugin into the pipeline framework, and to keep\nwhat makes the strength of the Seed plugin:\n\npipeline as configuration\n\nreuseable pipeline libraries, versioned and tested\n\nLinks\n\nYou can find additional information about the Seed plugin and its usage at the\nfollowing links:\n\nthe Seed plugin itself\n\nJUC London, June 2015\n\nBruJUG Brussels, March 2016","title":"Jenkins Pipeline Scalability in the Enterprise","tags":["jenkins","scalability","dsl"],"authors":[]}}]}},"pageContext":{"tag":"scalability","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}