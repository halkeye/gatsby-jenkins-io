{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/evergreen",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-09-18T00:00:00.000Z","id":"05f18d70-cabf-59fd-91c1-537a47157934","slug":"/blog/2018/09/18/automatically-upgrading-with-evergreen/","strippedHtml":"When I first wrote about Jenkins\nEvergreen, which was then referred to as \"Jenkins Essentials\", I mentioned a\nnumber of future developments which in the subsequent months have become\nreality. At this year’s DevOps World - Jenkins World in San Francisco, I will\nbe sharing more details on the philosophy behind Jenkins Evergreen, show off\nhow far we have come, and discuss where we’re going with this radical\ndistribution of Jenkins.\n\nAs discussed in my first blog post, and\nJEP-300,\nthe first two pillars of Jenkins Evergreen have been the primary focus of our\nefforts.\n\nAutomatically Updated Distribution\n\nPerhaps unsurprisingly, implementing the mechanisms necessary for safely and\nautomatically updating a Jenkins distribution, which includes core and plugins,\nwas and continues to be a sizable amount of work. In\nBaptiste’s talk\nhe will be speaking about the details which make Evergreen \"go\" whereas\nI will be speaking about why an automatically updating distribution is\nimportant.\n\nAs continuous integration and continuous delivery have become more commonplace,\nand fundamental to modern software engineering, Jenkins tends to live two\ndifferent lifestyles depending on the organization. In some organizations,\nJenkins is managed and deployed methodically with automation tools like Chef,\nPuppet, etc. In many other organizations however, Jenkins is treated much more\nlike an appliance, not unlike the office wireless router. Installed and so\nlong as it continues to do its job, people won’t think about it too much.\n\nJenkins Evergreen’s distribution makes the \"Jenkins as an Appliance\" model much\nbetter for everybody by ensuring the latest feature updates, bug and security\nfixes are always installed in Jenkins.\n\nAdditionally, I believe Evergreen will serve another group we don’t adequately\nserve at the moment: those who want Jenkins to behave much more like a\nservice. We typically don’t consider \"versions\" of GitHub.com, we receive\nincremental updates to the site and realize the benefits of GitHub’s on-going\ndevelopment without ever thinking about an \"upgrade.\"\n\nI believe Jenkins Evergreen can, and will provide that same experience.\n\nAutomatic Sane Defaults\n\nThe really powerful thing about Jenkins as a platform is the broad variety of\npatterns and practices different organizations may adopt. For newer users, or\nusers with common use-cases, that significant amount of flexibility can result\nin a paradox of choice. With Jenkins Evergreen, much of the most common\nconfiguration is automatically configured out of the box.\n\nIncluded is Jenkins Pipeline and Blue Ocean, by default. We also removed some\nlegacy functionalities from Jenkins while we were at it.\n\nWe are also utilizing some of the fantastic\nConfiguration as Code\nwork, which recently had its 1.0 release, to automatically set sane defaults in\nJenkins Evergreen.\n\nStatus Quo\n\nThe effort has made significant strides thus far this year, and we’re really\nexcited for people to start trying out Jenkins Evergreen. As of today,\nJenkins Evergreen\nis ready for early adopters. We do not yet recommend using Jenkins\nEvergreen for a production environment.\n\nIf you’re at DevOps World - Jenkins World in San Francisco please come see\nBaptiste’s talk Wednesday at 3:45pm in Golden Gate Ballroom A. Or\nmy talk at 11:15am in Golden Gate Ballroom B.\n\nIf you can’t join us here in San Francisco, we hope to hear your feedback and thoughts in our\nGitter channel!","title":"Continuously delivering an easy-to-use Jenkins with Evergreen","tags":["jenkinsworld","jenkinsworld2018","evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-09-13T00:00:00.000Z","id":"e528d035-a68d-5607-bf76-e95c721d6e49","slug":"/blog/2018/09/13/speaker-blog-evergreen-safely-upgrading/","strippedHtml":"Evergreen is a distribution of Jenkins we are working on that provides an easy to use and automatically upgrading experience.\nThis year at the conference, there will be not just one, but two talks to present Evergreen to the Jenkins community:\n\nContinuously Delivering an Easy-to-Use Jenkins with Jenkins Evergreen, by R. Tyler Croy.\n\nSafely Upgrading Jenkins Every Single Day, by Baptiste Mathus.\n\nTyler will present the overall Jenkins Evergreen architecture, its inception and how this aims at making it much simpler for people to just use Jenkins to build their projects, without having to become Jenkins admins.\n\nOn the last conference day, during my own talk I will focus on the improved developer experience, and zoom into how we implemented some important features.\n\nWe will dig together into the Error Telemetry system put in place, allowing us to actually fix errors and warnings people see in production environments.\nHow instances are automatically reporting errors to the Evergreen backend, and how we then centralize and analyze them using Sentry.\nWe will explain how the Incrementals system allows developers a very short roundtrip, between a merged pull-request and a release we can push out to all instances.\nWe will see concrete examples of issues we already fixed and released to Evergreen instances in just a few days after we opened an alpha version to the world.\n\nI will show you how an instance starts up and gets upgraded by discussing with the backend it’s constantly connected to.\nHow the backend knows what it should instruct an instance to download and install, or how we trigger an automated data snapshot.\n\nYou will obviously see a demo of all this showing in particular how Evergreen can already run on a Docker host, or on AWS (more environments to come!), using some of the so-called flavors for Jenkins Evergreen.\n\nCome meet us at\nDevOps World | Jenkins World 2018 on September 16-19th in San Francisco.\nWe will be hanging out around the OSS space, eager to answer more questions.\n\nRegister with the code JWFOSS for a 30% discount off your pass.","title":"Speaker blogpost: Jenkins Evergreen At DevOps World | Jenkins World 2018","tags":["jenkinsworld","jenkinsworld2018","evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://batmat.net","github":"batmat","html":"<div class=\"paragraph\">\n<p>Baptiste has been using and contributing to Jenkins since it was called differently, and is a huge proponent of the Agile, Devops &amp; Continuous Delivery movements.\nHe loves to discuss not only the technical aspects, but also the even more essential cultural aspects of this all, working together to improve the value provided to customers in a great inclusive and blameless environment.</p>\n</div>","id":"batmat","irc":null,"linkedin":null,"name":"Baptiste Mathus","slug":"/blog/author/batmat","twitter":"bmathus"}]}},{"node":{"date":"2018-07-10T00:00:00.000Z","id":"b0312033-b8b4-5dbc-b5a3-6c06dd49dcb5","slug":"/blog/2018/07/10/jenkins-essentials-on-aws/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nJenkins Essentials is about providing a distribution of Jenkins in less than five minutes and five clicks.\nOne of the main ideas to make this a reality is that Jenkins will be autoconfigured with sane defaults for the environment it is running in.\n\nWe are happy to report we recently merged the change that provides this feature for AWS.\nWe use an AWS CloudFormation template to provision a working version of Jenkins Essentials, automatically configured to:\n\ndynamically provision EC2 agents, using the EC2 plugin;\n\nuse the Artifact Manager on S3 plugin, so that artifacts are not stored anymore on the controller’s file system, but directly in an S3 bucket.\n\nI recorded a short demo video last week showing the basics of this:\n\nWhile there are still many items to complete to provide a usable version for end-users, we are making steady progress towards it.\n\nYou can learn more about Jenkins Essentials from the\nGitHub repository, or join us\non our\nGitter channel.","title":"Jenkins Essentials flavor for AWS","tags":["jenkinsevergreen","evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://batmat.net","github":"batmat","html":"<div class=\"paragraph\">\n<p>Baptiste has been using and contributing to Jenkins since it was called differently, and is a huge proponent of the Agile, Devops &amp; Continuous Delivery movements.\nHe loves to discuss not only the technical aspects, but also the even more essential cultural aspects of this all, working together to improve the value provided to customers in a great inclusive and blameless environment.</p>\n</div>","id":"batmat","irc":null,"linkedin":null,"name":"Baptiste Mathus","slug":"/blog/author/batmat","twitter":"bmathus"}]}},{"node":{"date":"2018-06-26T00:00:00.000Z","id":"40137c5d-c5ac-54d7-87d1-c1c8460bf136","slug":"/blog/2018/06/26/jenkins-essentials-at-eclipsecon-france/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nIt’s been far too long since we posted an update on\nJenkins Essentials. While it’s not\nquite ready for users to start trying it out, we\ncontinue hacking away on all\nmanner of changes to support the safe and automatic upgrades of a running\nJenkins environment. In the meantime, Jenkins contributor\nBaptiste Mathus took some time to introduce and\ndemonstrate Jenkins Essentials at the recently held\nEclipseCon France,\n\nFrom the talk’s abstract:\n\nThe Jenkins Project is working on providing its users with a brand new,\nstrongly opinionated, and continuously delivered distribution of Jenkins:\nJenkins Essentials. Constantly self-updating, including auto-rollback, with\nan aggressive subset of verified plugins.\n\nIn this talk, we will detail how this works: how we run and upgrade Jenkins\nitself. How instances are continuously sending health data back to help\nautomated decision-making about the quality of given new release, and decide to\ngeneralize a given version of Jenkins to the whole fleet, or roll it back.\n\nWe will end giving an overview of the status of the project: how it’s managed\nin a fully open manner, from design to code and its infrastructure, and all the\nradical solutions to imagine and the upcoming challenges for the next months.\n\nI hope you enjoy the video\n\nYou can learn more about Jenkins Essentials from\nGitHub repository, or join us\non our\nGitter channel.","title":"Presenting Jenkins Essentials at EclipseCon France","tags":["jenkinsevergreen","evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-05-15T00:00:00.000Z","id":"85458a0f-8ad5-53fb-a455-a4b6ae133fb4","slug":"/blog/2018/05/15/incremental-deployment/","strippedHtml":"A couple of weeks ago, Tyler mentioned some\ndeveloper improvements in Essentials\nthat had been recently introduced:\nthe ability for\nci.jenkins.io\nbuilds to get deployed automatically to an “Incrementals” Maven repository,\nas described in\nJEP-305.\nFor a plugin maintainer, you just need to\nturn on this support\nand you are ready to both deploy individual Git commits from your repository\nwithout the need to run heavyweight traditional Maven releases,\nand to depend directly on similar commits of Jenkins core or other plugins.\nThis is a stepping stone toward continuous delivery, and ultimately deployment, of Jenkins itself.\n\nHere I would like to peek behind the curtain a bit at how we did this,\nsince the solution turns out to be very interesting for people thinking about security in Jenkins.\nI will gloss over the Maven arcana required to get the project version to look like 1.40-rc301.87ce0dd8909b\n(a real example from the\nCopy Artifact plugin)\nrather than the usual 1.40-SNAPSHOT, and why this format is even useful.\nSuffice it to say that if you had enough permissions, you could run\n\nmvn -Dset.changelist -DskipTests clean deploy\n\nfrom your laptop to publish your latest commit.\nIndeed as\nmentioned in the JEP,\nthe most straightforward server setup would be to run more or less that command\nfrom the buildPlugin function called from a typical Jenkinsfile,\nwith some predefined credentials adequate to upload to the Maven repository.\n\nUnfortunately, that simple solution did not look very secure.\nIf you offer deployment credentials to a Jenkins job,\nyou need to trust anyone who might configure that job (here, its Jenkinsfile)\nto use those credentials appropriately.\n(The withCredentials step will mask the password from the log file, to prevent accidental disclosures.\nIt in no way blocks deliberate misuse or theft.)\nIf your Jenkins service runs inside a protected network and works with private repositories,\nthat is probably good enough.\n\nFor this project, we wanted to permit incremental deployments from any pull request.\nJenkins will refuse to run Jenkinsfile modifications from people\nwho would not normally be able to merge the pull request or push directly,\nand those people would be more or less trustworthy Jenkins developers,\nbut that is of no help if a pull request changes pom.xml\nor other source files used by the build itself.\nIf the server administrator exposes a secret to a job,\nand it is bound to an environment variable while running some open-ended command like a Maven build,\nthere is no practical way to control what might happen.\n\nThe lesson here is that the unit of access control in Jenkins is the job.\nYou can control who can configure a job, or who can edit files it uses,\nbut you have no control over what the job does or how it might use any credentials.\nFor JEP-305, therefore, we wanted a way to perform deployments from builds considered as black boxes.\nThis means a division of responsibility:\nthe build produces some artifacts, however it sees fit;\nand another process picks up those artifacts and deploys them.\n\nThis worked was tracked in\nINFRA-1571.\nThe idea was to create a “serverless function” in Azure\nthat would retrieve artifacts from Jenkins at the end of a build,\nperform a set of validations to ensure that the artifacts follow an expected repository path pattern,\nand finally deploy them to Artifactory using a trusted token.\nI prototyped this in Java, Tyler\nrewrote it in JavaScript,\nand together we brought it into production.\n\nThe crucial bit here is what information (or misinformation!) the Jenkins build can send to the function.\nAll we actually need to know is the build URL, so the\ncall site from Jenkins\nis quite simple.\nWhen the function is called with this URL,\nit starts off by performing input validation:\nit knows what the Jenkins base URL is,\nand what a build URL from inside an organization folder is supposed to look like:\nhttps://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/ , for example.\n\nThe next step is to call back to Jenkins and ask it for some metadata about that build.\nWhile we do not trust the build, we trust the server that ran it to be properly configured.\nAn obstacle here was that the ci.jenkins.io server had been configured to disable the Jenkins REST API;\nwith Tyler’s guidance I was able to amend this policy to permit API requests from registered users\n(or, in the case of the Incrementals publisher, a bot).\n\nIf you want to try this at home, get an\nAPI token,\npick a build of an “incrementalified” plugin or Jenkins core,\nand run something like\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/api/json?pretty&tree=actions[revision[hash,pullHash]]'\n\nYou will see a hash or pullHash corresponding to the main commit of that build.\n(This information was added to the Jenkins REST API to support this use case in\nJENKINS-50777.)\nThe main commit is selected when the build starts\nand always corresponds to the version of Jenkinsfile in the repository for which the job is named.\nWhile a build might checkout any number of repositories,\ncheckout scm always picks “this” repository in “this” version.\nTherefore the deployment function knows for sure which commit the sources came from,\nand will refuse to deploy artifacts named for some other commit.\n\nNext it looks up information about the Git repository at the folder level (again from JENKINS-50777):\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/api/json?pretty&tree=sources[source[repoOwner,repository]]'\n\nThe Git repository now needs to be correlated to a list of Maven artifact paths that this component is expected to produce.\nThe\nrepository-permissions-updater\n(RPU) tool already had a list of artifact paths used to perform permission checks on regular release deployments to Artifactory; in\nINFRA-1598\nI extended it to also record the GitHub repository name, as can be seen\nhere.\nNow the function knows that the CI build in this example may legitimately create artifacts in the org/jenkins-ci/plugins/git/ namespace\nincluding 38c569094828 in their versions.\nThe build is expected to have produced artifacts in the same structure as mvn install sends to the local repository,\nso the function downloads everything associated with that commit hash:\n\ncurl -sg 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/artifact/**/*-rc*.38c569094828/*-rc*.38c569094828*/*zip*/archive.zip' | jar t\n\nWhen all the artifacts are indeed inside the expected path(s),\nand at least one POM file is included (here org/jenkins-ci/plugins/git/3.9.0-rc1671.38c569094828/git-3.9.0-rc1671.38c569094828.pom),\nthen the ZIP file looks good—ready to send to Artifactory.\n\nOne last check is whether the commit has already been deployed (perhaps this is a rebuild).\nIf it has not, the function uses the Artifactory REST API to atomically upload the ZIP file\nand uses the GitHub Status API to associate a message with the commit\nso that you can see right in your pull request that it got deployed:\n\nOne more bit of caution was required.\nJust because we successfully published some bits from some PR does not mean they should be used!\nWe also needed a tool which lets you select the newest published version of some artifact\nwithin a particular branch, usually master.\nThis was tracked in\nJENKINS-50953\nand is available to start with as a Maven command operating on a pom.xml :\n\nmvn incrementals:update\n\nThis will check Artifactory for updates to relevant components.\nWhen each one is found, it will use the GitHub API to check whether the commit has been merged to the selected branch.\nOnly matches are offered for update.\n\nPutting all this together, we have a system for continuously delivering components\nfrom any of the hundreds of Jenkins Git repositories\ntriggered by the simple act of filing a pull request.\nSecuring that system was a lot of work\nbut highlights how boundaries of trust interact with CI/CD.","title":"Automatic deployment of “incremental” commits to Jenkins core and plugins","tags":["evergreen","developer"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/author/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-04-27T00:00:00.000Z","id":"3e9f5209-666c-54d9-9dcf-8fcbc3620a51","slug":"/blog/2018/04/27/essentials-versions-are-numbered/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nA couple weeks ago, I\nwrote about the Jenkins Essentials\neffort, on which we’ve been making steady progress. Personally, the most\nexciting challenge of this project is defining the machinery to drive\nautomatic updates\nof Jenkins Essentials, which viewed from a high level, are classic continuous\ndelivery challenges.\n\nIn this post, I wanted to dive into a bit of the gritty details of how we’re\ngoing to be delivering Jenkins Essentials with automatic updates, which has\nsome really interesting requirements for the development of Jenkins itself.\n\nThe traditional Jenkins core and plugin development workflow involves a\ndeveloper working on changes for some amount of time, then when they’re ready,\nthey \"create a release\" which typically involves publishing artifacts to our\nArtifactory, and then on a timer (typically every 15 minutes) the Update Center will\nre-generate a file called update-center.json. Once the new Update Center has\nbeen generated, it is published and consumed by Jenkins installations within\n24 hours. Of course, only after Jenkins administrators recognize that there is\nan update available, can they install it. All in all, it can take quite a long\ntime from when a developer publishes a release, to when it is successfully used\nby an end-user.\n\nWith our desire to make Jenkins Essentials updates seamless and automatic, the\nstatus quo clearly was not going to work. Our shift in thinking has required a\ncouple simultaneous efforts to make this more continuously delivered approach\nviable.\n\nDeveloper Improvements\n\nStarting from the developer’s workflow,\nJesse Glick\nhas been working on publishing \"incremental builds\" of artifacts into a\nspecial Maven repository\nin Artifactory. Much of his work is described in the very thorough\nJenkins Enhancement Proposal 305.\nThis support, which is now live on\nci.jenkins.io\nallows plugin developers to publish versioned changes from pull requests and\nbranches to the incrementals repository. Not only does this make it much\neasier for Jenkins Essentials to deliver changes closer to the HEAD of\nmaster branches, it also unlocks lots of flexibility for Jenkins developers\nwho coordinate changes across matrices of plugins and core, as occasionally is\nnecessary for Jenkins Pipeline, Credentials, Blue Ocean, and a number of other\nfoundational components of a modern Jenkins install.\n\nIn a follow-up blog post, Jesse is going to go into much more detail on some of\nthe access control and tooling changes he had to solve to make this\nincrementals machinery work.\n\nOf course, incremental builds are only a piece of the puzzle, with those\nartifacts, Jenkins Essentials has to be able to do something useful with them!\n\nUpdate Improvements\n\nThe number one requirement, from my perspective, for the automatically updated\ndistribution is that it is safe. \"Safe\" means that a user doesn’t need to\nbe involved in the update process, and if something goes wrong, the\ninstance recovers without the user needing to do anything to remediate a\n\"bad code deploy.\"\n\nIn my previous post on the subject, I mentioned Baptiste’s work on\nJenkins Enhancement\nProposal 302 which describes the \"data safety\" system for safely applying\nupdates, and in case of failure, rolling back.\n\nThe next obvious question is \"what’s failure?\" which Baptiste spent some time\nexploring and implementing in two more designs:\n\nJEP-304: Essentials Client Error Telemetry Logging\n\nJEP-306: Essentials Instance Client Health Checking\n\nOn the server side, of which there is substantial work for Jenkins Essentials,\nthese concepts integrate with the concept of an\nUpdate Lifecycle\nbetween the server and client. In essence, the server side must be able to\ndeliver the right updates to the right clients, and avoid delivering tainted\nupdates (those with known problems) to clients. While this part of the work is\nstill on-going, tremendous progress has been made over the past couple weeks\nin ensuring that updates can be safely, securely, and automatically delivered.\n\nWith the ability to identify \"bad code deploys\", and having a mechanism for\nsafely rolling back, not only does Jenkins Essentials allow seamless\nupdates, but it enables Jenkins developers to deliver features and bugfixes\nmuch more quickly than our current distribution model allows.\n\nWhile Jenkins Essentials does not have a package ready for broad consumption\nyet, we’re rapidly closing in on the completion of our first milestone which\nties all of these automatic update components together and builds the\nfoundation for continuous delivery of all subsequent improvements.\n\nYou can follow our progress in the\njenkins-infra/evergreen\nrepository, or join us in our\nGitter chat!","title":"Jenkins Essentials: The days of versions are numbered","tags":["evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-04-06T00:00:00.000Z","id":"f074f9a0-3eb3-5f51-9a32-4b65a80079ce","slug":"/blog/2018/04/06/jenkins-essentials/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nIn his presentation at the 2017 Jenkins World Contributor Summit,\nKohsuke\nchallenged us to continue the work started with Jenkins 2 of making Jenkins\neasier to install and easier to use. \"A user should be successful with Jenkins\nin under five minutes and five clicks.\" At that same Contributor Summit, a few\nof us discussed the idea of a distribution which had \"batteries\nincluded\", which\nAndrew\nproudly named \"Jenkins Essentials.\" At the time I was certainly not as excited\nabout the project as I am now, I thought to myself \"we built a Setup Wizard in\nJenkins 2, nobody needs a Setup Wizard++.\"\n\nAs Kohsuke and I continued to discuss the idea, more and more ideas came up.\nTowards the end of 2017 the picture became much clearer: Jenkins Essentials\nwould be a comprehensive, low-maintenance distribution to help new and\nexisting users be successful with Jenkins, without needing to be Jenkins\nexperts. This will of course not replace the existing distribution of Jenkins core and\nits plugins, which allow many of us large amounts of flexibility, but rather it\nwill make Jenkins easier for users who don’t want to \"build it themselves.\"\n\nThe more I thought about it, the more excited about the idea I became: Jenkins\nEssentials could open the door to new improvements and features in Jenkins\nwhich had been left in the \"idea and design\" phase going back almost two\nyears! Really, I checked, some of the concepts adopted into the design of\nJenkins Essentials were first conceived of in early 2016!\n\nKohsuke briefly discussed the project in\nhis previous blog post\nbut in post I wanted to expand on what Jenkins Essentials is, and our\nprogress has been in its development.\n\nWhat’s in Jenkins Essentials\n\nA few months ago I prepared\nthis presentation\nfor the\nFOSDEM 2018\nJenkins Contributor Summit, which outlines the following \"pillars\" or Jenkins\nEssentials, which are also described in\nJEP-300 :\n\nAutomatically Updated Distribution\n\nAutomatic Sane Defaults\n\nConnected\n\nObvious Path to User Success\n\nAutomatically Updated Distribution\n\nIn order to provide an easier-to-use and easier-to-manage Jenkins environment,\nJenkins Essentials will be distributed as an automatically self-updating\ndistribution, containing Jenkins core and a version-locked set of plugins\nconsidered \"essential.\" Rather than attempting to mirror the existing Weekly\nand LTS release lines for core, plus some plugin version matrix, Jenkins\nEssentials will update in a manner similar to Google Chrome.\n\nThis automatically updating distribution will mean that Jenkins Essentials will\nrequire significantly less overhead to manage, receiving improvements and bug\nfixes without any user involvement. From the user perspective, their Jenkins\nwill appear to automatically improve over time.\n\nThere is really interesting work being pioneered by\nBaptiste Mathus\nwith\nJEP-302\nto ensure that these automatic upgrades can be performed safely.\n\nAutomatic Sane Defaults\n\nProviding a core along with \"essential\" plugins is a good first step to helping\nJenkins users successfully automate their CI/CD workloads, but requires\nadditional \"smoothing\" over some of the numerous options and configurations\nplugins. Jenkins Essentials will perform some amount of \"automatic\nenvironment-based self-configuration.\"\n\nFor example, clicking a \"Launch Stack\" button from the Download\npage would launch an AWS-flavored Jenkins Essentials which, out of the box\nattempts to set up AWS-specific configuration with S3 and EC2 services.\n\nConnected\n\nIn order to provide a more seamless experience for end-users, and ensure that\nJenkins project developers receive useful error and usage telemetry to drive\nfurther improvements in Jenkins, Jenkins Essentials must necessarily be viewed\nas a \" Connected\" application. This means some yet-to-be-specified number of\nserver-side applications to coordinate updates, receive and process telemetry,\nbroker 3rd-party service authentications, relay webhooks, etc.\n\nObvious Path to User Success\n\nThe final pillar in Jenkins Essentials, is to ensure that Jenkins provides an\nobvious path for a user to configure and use it successfully. This largely\nentails in-application documentation, examples, and disabling legacy\nfunctionality within the application. All with the end goal of preventing users\nfrom inadvertently choosing legacy, or poorly supported, options when\nconfiguring their CI/CD workloads.\n\nProgress thus far\n\nSuffice it to say, Jenkins Essentials is a hugely ambitious project! We have\nbeen making steady progress however, as you can see in the\njenkins-infra/evergreen\nrepository on GitHub. We have been adamantly following the\nJenkins Enhancement Proposal\nprocess, and have been making sure our designs and implementations are clear as\nwe build them. Thus far we’ve written designs and implemented:\n\nJEP-300: Jenkins Essentials\n\nJEP-301: Evergreen packaging for Jenkins Essentials\n\nJEP-302: Evergreen snapshotting data safety system\n\nJEP-303: Evergreen Client Registration and Authentication\n\nJEP-304: Essentials Client Error Telemetry Logging\n\nUnfortunately we don’t yet have the first parts of the Automatically Updated Distribution working,\nwhich means you cannot download Jenkins Essentials today and get started with\nit. We’re still building the Jenkins-side and server-side components necessary\nto make the full feedback loop operate, without which we would not be able to\nsafely deliver new upgrades to Jenkins Essentials installations.\n\nIf you’re interested in getting involved, you can check out our\nGitter channel\nor our\nJira issues board.\n\nJenkins Essentials is just one major initiative going on in the Jenkins project\nthis year, so I hope you’re as excited as I am for the future of Jenkins!","title":"Jenkins Essentials: five minutes, five clicks","tags":["evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-03-20T00:00:00.000Z","id":"62b57ba0-b3a6-537c-a4d3-5430fc151996","slug":"/blog/2018/03/20/evolving-mission-of-jenkins/","strippedHtml":"Lately, perhaps subtle but exciting changes are starting to happen in the Jenkins project.\n\nThe past few weeks have seen the birth of two new initiatives in Jenkins:\nJenkins Essentials and\nJenkins X.  Each is\nexciting in its own right, and I encourage interested parties to take a look at\ntheir goals and missions and participate in them.  But in this post, I want to\ndiscuss why together these two dots form an important arc, which actually\nstarted in the introduction of Jenkins 2 and continued with Blue Ocean.\n\nIn Jenkins 2, we changed Jenkins so that it starts with richer functionality\nand more sensible security setup, among other things.  This was the first step\nin a new direction for Jenkins.  We changed our focus from “we’ll write plugins\nand you figure out the rest” to “we’ll write plugins, we’ll assemble them, and\nwe’ll help you be more productive.”\n\nBlue Ocean was another step on this journey.  We focused on important\ncontinuous delivery use cases in Jenkins, and aimed to provide a great\nuser-experience for those use cases.  Aside from obvious productivity boost for\nusers, it also decidedly blended together feature areas that are internally\nprovided by a whole bunch of different plugins, but users see much less seam\nbetween them.\n\nJenkins Essentials, which R Tyler Croy proposed in\nrecent weeks, is another step forward.  That project aims to take an even\nbigger responsibility in keeping people’s Jenkins instances up and running.\nLike Blue Ocean, Jenkins Essentials focuses on delivering a comprehensive\nJenkins user experience rather than a collection of unrelated plugins which\nusers have to figure out how to wire together.  It also creates an exciting\nvehicle for contributors, in which we can develop and deliver features quite\ndifferently, and more rapidly, than how we deliver them today.\n\nJenkins X, which was proposed by James Strachan a\nfew weeks after Jenkins Essentials, is the latest point on this same arc.\nJenkins X brings a different aspect to building a solution — it focuses on a\nspecific vertical area, namely Kubernetes application development, and\ndrastically simplifies the software development in that domain by bringing\ntogether Jenkins, a whole bunch of plugins, and an opinionated best practice of\nhow one should use Kubernetes.\n\nCollectively, the arc that these efforts form aims to solve the most important\nand consistent concerns for Jenkins users — ease of use, plugin complexity,\nfear of upgrade, etc.\n\nIn the early days of Jenkins, it was up to each and every Jenkins admin to find\nthe right way to assemble pieces into a solution for their organizations, but\nthis hard work remained largely private.  Now, these newer projects are\nbringing this back into the community.  They are making Jenkins more valuable\nto existing users, and more approachable and useful to a whole new set of users\nwho are not currently using Jenkins.\n\nFrom that perspective, I hope more projects like them will follow, pushing us\nbeyond “just writing plugins”, taking even bigger steps to make users\nproductive.  This is a little bit like how I watched Eclipse evolve from just a\nJava IDE to an umbrella of projects.\n\nExciting times!","title":"Evolving Mission of Jenkins","tags":["jenkins-x","evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"/blog/author/kohsuke","twitter":"kohsukekawa"}]}}]}},"pageContext":{"tag":"evergreen","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}