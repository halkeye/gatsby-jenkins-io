{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/pipeline/page/3",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2019-02-06T00:00:00.000Z","id":"ed5dfb33-f5e6-565b-a671-f4ae47d2c691","slug":"/blog/2019/02/06/ssh-steps-for-jenkins-pipeline/","strippedHtml":"Pipeline-as-code or defining the deployment pipeline through code rather than manual job creation through UI, provides tremendous benefits for teams automating builds and deployment infrastructure across their environments.\n\nSource of image: https://jenkins.io/doc/book/pipeline/\n\nJenkins Pipelines\n\nJenkins is a well-known open source continuous integration and continuous deployment automation tool. With the latest 2.0 release, Jenkins introduced the Pipeline plugin that implements Pipeline-as-code. This plugin lets you define delivery pipelines using concise scripts which deal elegantly with jobs involving persistence and asynchrony.\n\nThe Pipeline-as-code’s script is also known as a Jenkinsfile.\n\nJenkinsfiles uses a domain specific language syntax based on the Groovy programming language. They are persistent files which can be checked in and version-controlled along with the rest of their project source code. This file can contain the complete set of encoded steps (steps, nodes, and stages) necessary to define the entire application life-cycle, becoming the intersecting point between development and operations.\n\nMissing piece of the puzzle\n\nOne of the most common steps defined in a basic pipeline job is the Deploy step. The deployment stage encompasses everything from publishing build artifacts to pushing code into pre-production and production environments. This deployment stage usually involves both development and operations teams logging onto various remote nodes to run commands and/or scripts to deploy code and configuration. While there are a couple of existing ssh plugins for Jenkins, they currently don’t support the functionality such as logging into nodes for pipelines. Thus, there was a need for a plugin that supports these steps.\n\nIntroducing SSH Steps\n\nRecently, our team at Cerner started working on a project to automate deployments through Jenkins pipelines to help facilitate running commands on over one thousand nodes. We looked at several options including existing plugins, internal shared Jenkins libraries, and others. In the end, we felt it was best to create and open source a plugin to fill this gap so that it can be used across Cerner and beyond.\n\nThe initial version of this new plugin SSH Steps supports the following:\n\nsshCommand : Executes the given command on a remote node.\n\nsshScript : Executes the given shell script on a remote node.\n\nsshGet : Gets a file/directory from the remote node to current workspace.\n\nsshPut : Puts a file/directory from the current workspace to remote node.\n\nsshRemove : Removes a file/directory from the remote node.\n\nUsage\n\nBelow is a simple demonstration on how to use above steps. More documentation can be found on GitHub.\n\ndef remote = [:]\nremote.name = \"node\"\nremote.host = \"node.abc.com\"\nremote.allowAnyHosts = true\n\nnode {\n    withCredentials([usernamePassword(credentialsId: 'sshUserAcct', passwordVariable: 'password', usernameVariable: 'userName')]) {\n        remote.user = userName\n        remote.password = password\n\n        stage(\"SSH Steps Rocks!\") {\n            writeFile file: 'test.sh', text: 'ls'\n            sshCommand remote: remote, command: 'for i in {1..5}; do echo -n \\\"Loop \\$i \\\"; date ; sleep 1; done'\n            sshScript remote: remote, script: 'test.sh'\n            sshPut remote: remote, from: 'test.sh', into: '.'\n            sshGet remote: remote, from: 'test.sh', into: 'test_new.sh', override: true\n            sshRemove remote: remote, path: 'test.sh'\n        }\n    }\n}\n\nConfiguring via YAML\n\nAt Cerner, we always strive to have simple configuration files for CI/CD pipelines whenever possible. With that in mind, my team built a wrapper on top of these steps from this plugin. After some design and analysis, we came up with the following YAML structure to run commands across various remote groups:\n\nconfig:\n  credentials_id: sshUserAcct\n\nremote_groups:\n  r_group_1:\n    - name: node01\n      host: node01.abc.net\n    - name: node02\n      host: node02.abc.net\n  r_group_2:\n    - name: node03\n      host: node03.abc.net\n\ncommand_groups:\n  c_group_1:\n    - commands:\n        - 'ls -lrt'\n        - 'whoami'\n    - scripts:\n        - 'test.sh'\n  c_group_2:\n    - gets:\n        - from: 'test.sh'\n          to: 'test_new.sh'\n    - puts:\n        - from: 'test.sh'\n          to: '.'\n    - removes:\n        - 'test.sh'\n\nsteps:\n  deploy:\n    - remote_groups:\n        - r_group_1\n      command_groups:\n        - c_group_1\n    - remote_groups:\n        - r_group_2\n      command_groups:\n        - c_group_2\n\nThe above example runs commands from c_group_1 on remote nodes within r_group_1 in parallel before it moves on to the next group using sshUserAcct (from the Jenkins Credentials store) to logon to nodes.\n\nShared Pipeline Library\n\nWe have created a shared pipeline library that contains a sshDeploy step to support the above mentioned YAML syntax. Below is the code snippet for the sshDeploy step from the library. The full version can be found here on Github.\n\n#!/usr/bin/groovy\ndef call(String yamlName) {\n    def yaml = readYaml file: yamlName\n    withCredentials([usernamePassword(credentialsId: yaml.config.credentials_id, passwordVariable: 'password', usernameVariable: 'userName')]) {\n        yaml.steps.each { stageName, step ->\n            step.each {\n                def remoteGroups = [:]\n                def allRemotes = []\n                it.remote_groups.each {\n                    remoteGroups[it] = yaml.remotes.\"$it\"\n                }\n\n                def commandGroups = [:]\n                it.command_groups.each {\n                    commandGroups[it] = yaml.commands.\"$it\"\n                }\n                def isSudo = false\n                remoteGroups.each { remoteGroupName, remotes ->\n                    allRemotes += remotes.collect { remote ->\n                        if(!remote.name)\n                            remote.name = remote.host\n                        remote.user = userName\n                        remote.password = password\n                        remote.allowAnyHosts = true\n                        remote.groupName = remoteGroupName\n                        remote\n                    }\n                }\n                if(allRemotes) {\n                    if(allRemotes.size() > 1) {\n                        def stepsForParallel = allRemotes.collectEntries { remote ->\n                            [\"${remote.groupName}-${remote.name}\" : transformIntoStep(stageName, remote.groupName, remote, commandGroups)]\n                        }\n                        stage(stageName) {\n                            parallel stepsForParallel\n                        }\n                    } else {\n                        def remote = allRemotes.first()\n                        stage(stageName + \"\\n\" + remote.groupName + \"-\" + remote.name) {\n                            transformIntoStep(stageName, remote.groupName, remote, commandGroups).call()\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nBy using the step (as described in the snippet above) from this shared pipeline library, a Jenkinsfile can be reduced to:\n\n@Library('ssh_deploy') _\n\nnode {\n  checkout scm\n  sshDeploy('dev/deploy.yml');\n}\n\nAn example execution of the above pipeline code in Blue Ocean looks like this:\n\nWrapping up\n\nSteps from the SSH Steps Plugin are deliberately generic enough that they can be used for various other use-cases as well, not just for deploying code. Using SSH Steps has significantly reduced the time we spend on deployments and has given us the possibility of easily scaling our deployment workflows to various environments.\n\nHelp us make this plugin better by contributing. Whether it is adding or suggesting a new feature, bug fixes, or simply improving documentation, contributions are always welcome.","title":"SSH Steps for Jenkins Pipeline","tags":["pipeline","plugins","ssh","steps"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg","srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/77b35/nrayapati.jpg 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/d4a57/nrayapati.jpg 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/68974/nrayapati.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/ef6ff/nrayapati.webp 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/8257c/nrayapati.webp 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/6766a/nrayapati.webp 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/22bfc/nrayapati.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"nrayapati","html":"<div class=\"paragraph\">\n<p>Software Architect at <a href=\"https://www.cerner.com/\">Cerner Corporation</a>. Passionate about Agile, DevOps &amp; Continuous Delivery, and all things Automation.\nOSS Contributor, he is maintaining couple of Jenkins plugins since past several years. <a href=\"https://plugins.jenkins.io/ssh-steps\">SSH Steps</a> - <a href=\"https://plugins.jenkins.io/jira-steps\">JIRA Steps</a> - <a href=\"https://plugins.jenkins.io/hubot-steps\">Hubot Steps</a></p>\n</div>","id":"nrayapati","irc":null,"linkedin":null,"name":"Naresh Rayapati","slug":"/blog/authors/nrayapati","twitter":"nrayapati"}]}},{"node":{"date":"2019-01-08T00:00:00.000Z","id":"058588ed-0d18-5d03-bd6b-e2e62be7093b","slug":"/blog/2019/01/08/mpl-modular-pipeline-library/","strippedHtml":"Despite speeding up development with deployment automation, one of our clients\nwas experiencing slow time-to-market due to a lack of collaboration in DevOps.\nWhile they had invested in DevOps, every production pipeline was set up\nindividually, forcing teams to remake the wheel for each project. Making matters\nworse, there was no cross-team collaboration, so any bug in the platform was\npresent in each new pipeline. Many of our clients have similar issues, so we\ndecided that we should develop a common tool which would both help current\nclients, and be adaptable for use in the future. While the most obvious option\nwas standardizing the CI/CD platform with a common framework, this led to a\nmonolithic structure, which was inflexible and ultimately unworkable. Since each\nteam needed to work on their own pipelines, we developed a solution that would\nstore each reusable part of the DevOps pipeline for later use: a Jenkins-powered\nmodular pipeline library.\n\nSolution: a modular pipeline library\n\nThe modular pipeline library ( MPL) we\ncreated is a highly-flexible shared library for a Jenkins Pipeline that enables\neasy sharing of best practices across the entire company. It has a clear modular\nstructure, an advanced testing framework, multi-level nesting, a pipeline\nconfiguration system, improved error handling, and many other useful components.\n\nWe will take a look under the hood and explain how our solution works in several\nparts:\n\nExplore the technologies and tools we used to build the MPL\n\nReview the MPL, and illustrate why it’s effective\n\nFollow a step-by-step guide to operate the MPL on a sample pipeline\n\nDive into some of the more important components of the solution, such as the test framework and nested libraries\n\nSo now let’s jump right into an explanation of the crucial features we used to\nbuild our solution.\n\nBuilding the MPL with shared libraries and Jenkins pipelines\n\nJenkins, our main automation platform, recently received some updates to\nJenkins Pipeline. These updates allow us to\ncreate one Jenkinsfile that\ndescribes the entire pipeline, and the steps that need to be executed with a\nseries of self-explanatory scripts. This increases the visibility of CI/CD\nautomation processes for end users, and improves supportability by DevOps teams.\n\nHowever, there’s a large issue with Pipeline: it’s hard to support multiple\nJenkinsfiles (and therefore multiple projects) with unique pipelines. We need to\nstore the common logic somewhere, which is where\nJenkins Shared Libraries\ncome in. They are included in the Jenkinsfile, and allow the use of prepared\ninterfaces to simplify automation and store common pieces.\n\nWhile shared libraries allow you to store logic and manipulate Jenkins, they\ndon’t provide a good way to utilize all the common information. Therefore, the\nMPL optimizes the pipeline and shared libraries by allowing users to create\neasy-to-follow descriptions for processes, which are then stored for later use\nby other teams.\n\nThe MPL works to create collaborative DevOps processes across teams\n\nWith the MPL, we are now able to collaborate and share our DevOps practices\nacross teams, easily adopt existing pipelines for specific projects, and debug\nand test features before we actually integrate them into the library. Each team\ncan create a nested library, add a number of pipelines and modules inside, and\nuse it with pipeline automation to create great visibility of the processes for\nthe end user. The MPL can also work on any project to prepare a Jenkinsfile, and\nmanage it as flexibly as the project team wants.\n\nAt its core, the MPL provides a simple way to:\n\nSeparate pipelines and steps by introducing modules\n\nDescribe steps in the modules with an easy configuration interface\n\nTest the described modules and share the results with other pipelines and projects\n\nThere are a lot of other features in the MPL, but it’s essentially a platform to\nsolve general DevOps collaboration issues. To simplify development and manual\ntesting, the MPL provides modules overriding and an inheritance model, allowing\nusers to test specific fixes in the project without affecting anything else. In\nJenkins, a module is a file with scripted steps and logic to reach a simple goal\n(build an artifact, run tests, create an image, etc.). These modules are\ncombined in the pipeline stages, and are easily readable for anyone who knows\nthe Jenkins Pipeline syntax.\n\nThe MPL allows users to use the core features of the library (structure,\nmodules, pipelines) and create nested libraries for specific DevOps team needs.\nA DevOps team can prepare complete pipelines with any custom logic and use it\nfor their projects. They can also override and inherit the core MPL modules in a\nnumber of ways, or prepare custom modules which are easy to share with other\nteams. Check out the infographic below to see how modules fit in:\n\nYou can also specify certain pipeline required poststeps in a module. For\nexample, a dynamic deployment module creates the test environment, which needs\nto be destroyed when the pipeline ends. To take a closer look at the MPL calling\nprocess, check out the infographic below:\n\nThis infographic shows how calls are executed in the MPL. First, you need a job\non your Jenkins, which will call a Jenkinsfile (for example, when the source\ncode is changed), after which the Jenkinsfile will call a pipeline. The pipeline\ncould be described on the MPL side, in the pipeline script in the job, in the\nnested library, or in the project Jenkinsfile. Finally, the stages of the\npipeline will call the modules, and these modules will use features, which could\nbe groovy logic, pipeline steps, or steps in the shared libraries.\n\nNow that we’ve done an overview of the solution, let’s take a look at a simple\npipeline execution to see how the MPL works in action.\n\nAn example of a pipeline execution in the MPL\n\nFor example, let’s say you have a common Java Maven project. You are creating a\nJenkinsfile in the repo, and want to use the default pipeline prepared by your\nDevOps team. The MPL already has a simple pipeline: the core MPLPipeline. It’s\na really simple pipeline, but it’s a good start for anyone who wants to try the\nMPL. Let’s look at a simple Jenkinsfile:\n\n@Library('mpl') _\nMPLPipeline {}\n\nThis Jenkinsfile contains a single line to load the MPL, and another line to run\nthe pipeline. Most of the shared libraries implement an interface like this,\ncalling one step and providing some parameters. MPLPipeline is merely a custom\nPipeline step, as it lies in the vars directory, and its structure is very\nsimple, following these steps:\n\nInitialize the MPL\nThe MPL uses the MPLManager singleton object to control the pipeline\n\nMerge configuration with default and store it\nA default configuration needed to specify stages and predefine some useful configs\n\nDefine a declarative pipeline with 4 stages and poststeps:\n\nCheckout - Getting the project sources\n\nBuild - Compiling, validation of static, unit tests\n\nDeploy - Uploading artifacts to the dynamic environment and running the app\n\nTest - Checking integration with other components\n\nPoststeps - Cleaning dynamic environment, sending notifications, etc.\n\nRunning the defined pipeline\nThis is where the MPL starts to work its magic and actually runs\n\nStages of the main MPL usually have just one step, the MPLModule .\nThis step contains the core functionality of the MPL: executing the modules\nwhich contain the pipeline logic. You can find default modules in the MPL\nrepository, which are placed in resources/com/griddynamics/devops/mpl/modules.\nSome of the folders include: Checkout, Build, Deploy, and Test, and in each of\nthem we can find Groovy files with the actual logic for the stages. This\ninfographic is a good example of a simplified MPL repository\nstructure:\n\nWhen the Checkout stage starts, MPLModule loads the module by name (by default\na stage name), and runs the Checkout/Checkout.groovy\nlogic:\n\nif( CFG.'git.url' )\n  MPLModule('Git Checkout', CFG)\nelse\n  MPLModule('Default Checkout', CFG)\n\nIf the configuration contains the git.url option, it will load a Git Checkout\nmodule; otherwise, it will run the Default Checkout module. All the called\nmodules use the same configuration as the parent module, which is why CFG was\npassed to the MPLModule call. In this case, we have no specific configuration,\nso it will run the\nCheckout/DefaultCheckout.groovy\nlogic. The space in the name is a separator to place the module into a specific\nfolder.\n\nIn the Default Checkout module, there is just one line with checkout scm\nexecution, which clones the repository specified in the Jenkins job. That’s all\nthe Checkout stage does, as the MPL functionality is excessive for such a small\nstage, and we only need to talk about it here to show how the MPL works in\nmodules.\n\nThe same process applies to the Build stage, as the pipeline runs the\nMaven Build\nmodule:\n\nwithEnv([\"PATH+MAVEN=${tool(CFG.'maven.tool_version' ?: 'Maven 3')}/bin\"]) {\n  def settings = CFG.'maven.settings_path' ? \"-s '${CFG.'maven.settings_path'}'\" : ''\n  sh \"\"\"mvn -B ${settings} -DargLine='-Xmx1024m -XX:MaxPermSize=1024m' clean install\"\"\"\n}\n\nThis stage is a little bit more complicated, but the action is simple: we take\nthe tool with the default name Maven 3, and use it to run mvn clean install.\nThe modules are scripted pipelines, so you can do the same steps usually\navailable in the Jenkins Pipeline. The files don’t need any specific and\ncomplicated syntax, just a plain file with steps and CFG as a predefined\nvariable with a stage configuration. The MPL modules inherited the sandbox from\nthe parent, so your scripts will be safe and survive the Jenkins restart, just\nlike a plain Jenkins pipeline.\n\nIn the Deploy folder, we find the sample structure of the Openshift Deploy\nmodule. Its main purpose here is to show how to use poststep definitions in the\nmodules:\n\nMPLPostStep('always') {\n  echo \"OpenShift Deploy Decommission poststep\"\n}\necho 'Executing Openshift Deploy process'\n\nFirst, we define the always poststep. It is stored in the MPLManager, and is\ncalled when poststeps are executed. We can call MPLPostStep with always as\nmany times as we want: all the poststeps will be stored and executed in FILO\norder. Therefore, we can store poststep logic for actions that need to be done,\nand then undone, in the same module, such as the decommission of the dynamic\nenvironment. This ensures that the actions will be executed when the pipeline\nis complete.\n\nAfter the deploy stage, the pipeline executes the Test stage, but nothing too\ninteresting happens there. However, there is an aspect of testing which is very\nimportant, and that’s the testing framework of the MPL itself.\n\nTesting of the MPL\n\nThe testing framework of the MPL is based on the\nJenkinsPipelineUnit\nfrom LesFurets, with the one small difference being its ability to test the MPL\nmodules. Testing the whole pipeline doesn’t work, as pipelines can be really\ncomplicated, and writing tests for such monsters is a Sisyphean task. It is much\neasier to test a black box with a small amount of steps, ensuring that this\nparticular task is working correctly.\n\nIn the MPL, you can find Build module testing examples: all the tests are\nstored in the\ntest/groovy/com/griddynamics/devops/mpl/modules\ndirectory, and you can find the\nBuild/BuildTest.groovy\nfile with a number of test cases there. Tests are executed during the MPL build\nprocess, allowing users to see traces like this:\n\nLoading shared library mpl with version snapshot\n  MPLModule.call(Build, {maven={tool_version=Maven 2}})\n    Build.run()\n      Build.MPLModule(Maven Build, {maven.tool_version=Maven 2})\n        MavenBuild.run()\n          MavenBuild.tool(Maven 2)\n          MavenBuild.withEnv([PATH+MAVEN=Maven 2_HOME/bin], groovy.lang.Closure)\n            MavenBuild.sh(mvn -B  -DargLine='-Xmx1024m -XX:MaxPermSize=1024m' clean install)\n      Build.fileExists(openshift)\n\nThe test runs the MPLModule with custom configuration and mocked steps to\ncheck that, during execution, the tool was changed to Maven 2 according to the\nprovided configuration. We cover all test cases with such tests, ensuring that\nthe modules are working as expected, and that the pipeline will work properly.\nYou can test the whole pipeline if you want, but testing by modules is just an\nadditional way to simplify the testing process.\n\nNow that we’ve looked at how to test the MPL modules, it’s time to look at one\nof the key features of the MPL, which is nested libraries.\n\nThe benefits of nested libraries\n\nWhen working with a large company, supporting one big library makes no sense.\nEach department requires multiple configuration options and tuning for a\nsomewhat standard pipeline, which creates extra work. The MPL solves such\nproblems by introducing nested libraries. This infographic displays how a nested\nlibrary compares to just using the main library:\n\nA nested library is the same as a shared library that imports the MPL and uses\nits functionality, modules, and pipelines. Also, it allows the separation of\nsome team-related logic from the company common logic. Here is the structure of\nthe MPL with nested libraries:\n\nYou can import the MPL in the overridden pipeline, specify the path of some\nadditional modules, override module logic, and use Jenkins power moves: there\nare no limitations. When another team needs your unique module, you can just\ncreate a change request to the basic company MPL repo, and share your functional\nmodule with the others.\n\nWith nested libraries, it’s possible to debug and modify MPL-provided steps\n( MPLModule for example) and pipelines. This is because nested libraries can\noverride low-level functionalities of the MPL or the Jenkins Pipeline. There are\nno limitations to what you can or can’t change, as these overrides only affect\nyour own pipeline. This enables experimentation to be done, and then discussed\nwith other teams to see if it will work in other nested libraries as well.\n\nThere are also no limits to the number of nesting levels created, but we\nrecommend using just two (MPL and nested), because additional levels make\nconfiguration and testing of the nested libraries on lower levels very\ncomplicated.\n\nThe power of module overriding\n\nFurther into the nested libraries or project-side modules, it’s possible to\nstore a module with the same name as one in the upper-level library. This is a\ngood way to override the logic - you can just replace Build/Build.groovy with\nyour own - as the functional module will be executed instead of the upper-level\nmodule. For example, this infographic shows module overriding:\n\nEven better, one of the strengths of the MPL is that you still can use the\nupper-level module! The MPL has mechanisms to prevent loops, so the same module\ncan’t be executed in the same executing branch again. However, you can easily\ncall the original module a name from another module to use the upper-level\nlogic.\n\nThe Petclinic-Selenium example above uses the default MPLPipeline (you can\nfind it on the MPL Wiki-page), and\ncontains project-side modules in a.jenkins directory. These modules will be\ncalled before the library modules. For example, the Checkout module is not\nplaced on the project side, so it will be called from the MPL, but the Build\nmodule exists in a.jenkins directory on the project side, and it will be\ncalled:\n\nMPLPostStep('always') {\n  junit 'target/surefire-reports/*.xml'\n}\n\nMPLModule('Build', CFG)\n\nif( fileExists('Dockerfile') ) {\n  MPLModule('Docker Build', CFG)\n}\n\nAs you can see, the Build module from the project registers the poststep,\ncalls the original Build module from the MPL, and then calls the additional\nDocker Build module. The following stages of the pipeline are more\ncomplicated, but all module overriding essentially works like this. Some\nprojects can be tricky, and need some small tunings for the existing modules.\nHowever, you can easily implement those changes on the project level, and think\nabout how to move the functionality to the nested library or MPL later.\n\nConclusion: what the MPL brings to DevOps\n\nMany DevOps teams and companies work with bloated, restrictive, and buggy CI/CD\nautomation platforms. These increase the learning curve for users, cause teams\nto work slower, and raise production costs. DevOps teams frequently run into\nsimilar issues on different projects, but a lack of collaboration means that\nthey have to be individually fixed each time.\n\nHowever, with the MPL, DevOps teams have a shared, simple, and flexible CI/CD\nplatform to improve user support, collaboration, and overall project source code\nto the production process. By utilizing the MPL, your company can find an\nautomation consensus, reach cross-company collaboration goals, and reuse the\nbest practices from a large community, all with open source tools. If you’re\ninterested in building an MPL, please contact us to learn more!\n\nAdditional resources\n\nJenkins Pipeline Engine\n\nJenkins Shared Libraries\n\nMPL GitHub repository\n\nOverview & demo videos:\n\nIntroduction\n\nOverview\n\nDemo of the MPL Build\n\nDemo of the Nested Library\n\nDemo of the Petclinic Pipeline","title":"MPL - Modular Pipeline Library","tags":["jenkinsfile","pipeline","sharedlibrary"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#d8d8d8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/bf8e1/sparshev.png","srcSet":"/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/914ee/sparshev.png 32w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/1c9ce/sparshev.png 64w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/bf8e1/sparshev.png 128w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/acb7c/sparshev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/ef6ff/sparshev.webp 32w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/8257c/sparshev.webp 64w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/6766a/sparshev.webp 128w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/22bfc/sparshev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://www.state-of-the-art.io/","github":"sparshev","html":"<div class=\"paragraph\">\n<p>Sergei is a DevOps engineer and using Jenkins as a main automation tool since 2011.\nWants to automate everything to make sure that there no more room for boring tasks.</p>\n</div>","id":"sparshev","irc":null,"linkedin":null,"name":"Sergei Parshev","slug":"/blog/authors/sparshev","twitter":null}]}},{"node":{"date":"2018-11-07T00:00:00.000Z","id":"f78fd338-8583-5f00-82a2-c7210a261909","slug":"/blog/2018/11/07/Validate-Jenkinsfile/","strippedHtml":"In my daily work I often have to create or modify Jenkinsfiles and more often than I would like, I make mistakes. It is a very tedious workflow when you make a change to your Jenkinsfile, create a commit, push the commit and wait for your Jenkins Server to tell you, that you have missed a bracket.\n\nThe Command-line Pipeline Linter ( https://jenkins.io/doc/book/pipeline/development/) does a great job of reducing the turnaround times when writing a Jenkinsfile, but its usage has its own inconveniences. You need tools like curl or ssh to make a connection to your Jenkins Server and you need to remember the correct command to validate your Jenkinsfile. I still did not like the solution.\n\nAs VS Code is my daily driver, I started to look at writing extensions for it and out of it came a little extension which makes validating Jenkinsfiles just a little bit more comfortable.\n\nWhat the 'Jenkins Pipeline Linter Connector' does is, that it takes the file that you have currently opened, pushes it to your Jenkins Server and displays the validation result in VS Code.\n\n​You can find the extension from within the VS Code extension browser or at the following url: https://marketplace.visualstudio.com/items?itemName=janjoerke.jenkins-pipeline-linter-connector\n\nThe extension adds four settings entries to VS Code which you have to use to configure the Jenkins Server you want to use for validation.\n\njenkins.pipeline.linter.connector.url is the endpoint at which your Jenkins Server expects the POST request, containing your Jenkinsfile which you want to validate. Typically this points to /pipeline-model-converter/validate\" class=\"bare\">http:// /pipeline-model-converter/validate .\n\njenkins.pipeline.linter.connector.user allows you to specify your Jenkins username.\n\njenkins.pipeline.linter.connector.pass allows you to specify your Jenkins password.\n\njenkins.pipeline.linter.connector.crumbUrl has to be specified if your Jenkins Server has CRSF protection enabled. Typically this points to /crumbIssuer/api/xml?xpath=concat(//crumbRequestField,%22:%22,//crumb\" class=\"bare\">http:// /crumbIssuer/api/xml?xpath=concat(//crumbRequestField,%22:%22,//crumb).\n​","title":"Validate your Jenkinsfile from within VS Code","tags":["jenkinsfile","validation","vscode","pipeline","pipeline authoring","development"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#887878","images":{"fallback":{"src":"/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/5236e/janjoerke.jpg","srcSet":"/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/534e5/janjoerke.jpg 32w,\n/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/99887/janjoerke.jpg 64w,\n/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/5236e/janjoerke.jpg 128w,\n/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/76fd4/janjoerke.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/59a6b/janjoerke.webp 32w,\n/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/cbb78/janjoerke.webp 64w,\n/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/1a93d/janjoerke.webp 128w,\n/gatsby-jenkins-io/static/a8787b55a793681f4a2418b0594f7055/50511/janjoerke.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":170}}},"blog":null,"github":"janjoerke","html":"<div class=\"paragraph\">\n<p>Software Engineer from northern Germany.</p>\n</div>","id":"janjoerke","irc":null,"linkedin":null,"name":"Jan Jörke","slug":"/blog/authors/janjoerke","twitter":"janjoerke"}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"003e40e9-a1b3-5859-a18a-60017d86c651","slug":"/blog/2018/08/17/speaker-blog-brent-laster/","strippedHtml":"More and more today, continuous delivery (CD) pipelines are making use of containers.\nIn many implementations, the primary workflow/orchestration tool for CD pipelines is Jenkins.\nAnd the primary container orchestration tool is Docker.\nTogether these two applications provide a powerful, yet simple to understand and use, model for leveraging containers in your CD pipeline.\n\nWhen creating a pipeline script in Jenkins, there are multiple ways to incorporate Docker into your CD pipeline.\nThey include:\n\nManually running a predefined Docker image as a separate Jenkins agent\n\nAutomatically provisioning a Docker image, when needed, as a part of a “cloud” configuration\n\nReferencing a “docker” global variable that can be invoked via the Jenkins DSL\n\nCalling the Docker executable directly via a shell call in the Jenkins DSL\n\nFor this article, we’ll focus on the third item in this list given that it provides the most flexibility and convenience for Docker use in the pipeline.\nMore details on the other three can be found in the upcoming “Continuous Delivery and Containerization” workshop at Jenkins World/DevOps World 2018.\n\nFirst, we’ll provide some background on a couple of terms for those who may not be familiar with Jenkins 2.\nIf you already are familiar with it, feel free to skip ahead to the Global Variables section.\n\nBackground\n\nWhen we talk about Jenkins here, we’re referring to “Jenkins 2” - a name we use to generally refer to the 2.0 and beyond versions of Jenkins.\nJenkins 2 offers a powerful evolution of Jenkins over prior versions.\nIn particular, it provides full integration for “pipeline-as-code” (PAC).\nPAC refers to being able to write your pipeline in a scripting language, much like source code for any program.\nThe code you write becomes the program that defines your pipeline.\nIt is also the code that gets executed when your pipeline is initiated.\nListing 1 shows a simple example pipeline.\nNotice that this is very different from the classic way of creating pipelines in Jenkins.\nHere you are writing code - rather than the more traditional approaches, such as filling in web forms to configure a Freestyle job.\n\n// Scripted Pipeline //\nnode('worker') {\n    stage('Source') { // Get code\n        // Get code from our git repository\n        git 'git@diyvb2:/home/git/repositories/workshop.git'\n    }\n    stage('Compile') { // Compile and do unit testing\n        // Run gradle to execute compile and unit testing\n        sh \"gradle clean compileJava test\"\n    }\n}\n// Declarative //\n\nListing 1: Example Jenkins 2 pipeline\n\nThe language that we write the Jenkins pipeline code in is a Domain-Specific Language (DSL).\nYou can think of it as the “programming language” for Jenkins pipelines.\nThere are two variants of it.\nThe style we saw in figure 1 is called “scripted syntax”.\nIt is a mixture of elements from the Groovy programming language and special Jenkins “steps”.\nThe Jenkins steps are provided by the plugins that are installed in the current system.\nA built-in tool called the Snippet Generator provides a wizard interface to allow users to pick the step and options they want.\nThen, the user can click on a button to have Jenkins automatically generate the correct DSL code in the large text box (figure 1).\nThe DSL code can be copied from there and pasted into the pipeline script.\n\nFigure 1. The Snippet Generator\n\nA second type of syntax is called “declarative syntax.”  We won’t go into detail on it here.\nBut it is a much more structured syntax that focuses on having users declare what they want in a pipeline, rather than writing the logic to make it happen.\n\nGlobal Variables\n\nIn addition to the steps that are provided by plugins, additional functionality for pipelines can be provided by global variables.\nThe simplest way to think of a global variable is as an object with methods that can be invoked on it.\nSeveral of these are built in to Jenkins, such as the Docker global variable.\nOthers can be created by users as part of the structure of a shared source code repository called a “shared pipeline library.”\n\nTo get a list of the global variables that are currently available to your Jenkins instance, you can go to the Snippet Generator screen.\nImmediately below the box for the generated pipeline script is a section titled Global Variables.\nThere, within the small print, is a link to get to the actual section (figure 2).\n\nFigure 2. Link to Global Variables Reference section.\n\nClicking on that link takes us to a list of currently available Global Variables.\nIf you have the Docker Pipeline Plugin installed, you will see one at the top for Docker. (Figure 3).\n\nFigure 3. Docker global variable specifics.\n\nBroadly, the docker global variable includes methods that can be applied to the Docker application, Docker images, and Docker containers.\n\nWe’ll focus first on a couple of the Docker image methods as shown in figure 4.\n\nFigure 4. Key methods for getting a Docker image.\n\nThere are multiple ways you can use these methods to create a new image.\nListing 2 shows a basic example of assigning and pulling an image using the image method.\n\nmyImage = docker.image(\"bclaster/jenkins-node:1.0\")\nmyImage.pull()\n\nListing 2: Assigning a image to a variable and pulling it down.\n\nThis can also be done in a single statement as shown in listing 3.\n\ndocker.image(\"bclaster/jenkins-node:1.0\").pull()\n\nListing 3: Shorthand version of previous call.\n\nYou can also download a Dockerfile and build an image based on it.(See listing 4.)\n\nnode() {\n    def myImg\n    stage (\"Build image\") {\n        // download the dockerfile to build from\n        git 'git@diyvb:repos/dockerResources.git'\n\n        // build our docker image\n        myImg = docker.build 'my-image:snapshot'\n    }\n}\n\nListing 4: Pipeline code to download a Dockerfile and build an image from it.\n\nFigure 5 shows the actual output from running that “Build image” stage.\nNote that the docker.build step was translated into an actual Docker build command.\n\nFigure 5. Actual Docker output from running the download and build\n\nThe Inside Command\n\nAnother powerful method available for the Docker global variable is the inside method.\nWhen executed, this method will do the following:\n\nGet an agent and a workspace to execute on\n\nIf the Docker image is not already present, pull it down\n\nStart the container with that image\n\nMount the workspace from Jenkins\n\nExecute the build steps\n\nMounting the workspace means that the Jenkins workspace will appear as a volume inside the container.\nAnd it will have the same file path.\nSo, things running in the container will have direct access to the same location.\nHowever, this can only be done if the container is running on the same underlying system - such that it can directly access the path.\n\nIn terms of executing the build steps, the inside method acts as a scoping method.\nThis means that the environment it sets up is in effect for any statement that happens within its scope (within the block under it bounded by {}).\nThe practical application here is that any pipeline “sh” steps (a call to the shell to execute something) are automatically run in the container.\nBehind the scenes, this is done by wrapping the calls with “docker exec”.\n\nWhen executed, the calls with the global variable are translated (by Jenkins) into actual Docker call invocations.\nListing 5 shows an example of using this in a script, along with the output from the first invocation of the “inside” method.\nYou can see in the output the docker commands that are generated from the inside method call.\n\nstage (\"Get Source\") {\n        // run a command to get the source code download\n        myImg.inside('-v /home/git/repos:/home/git/repos') {\n            sh \"rm -rf gradle-greetings\"\n            sh \"git clone --branch test /home/git/repos/gradle-greetings.git\"\n        }\n    }\n    stage (\"Run Build\") {\n        myImg.inside() {\n            sh \"cd gradle-greetings && gradle -g /tmp clean build -x test\"\n        }\n    }\n\nListing 5: Example inside method usage.\n\nFigure 6. Example inside method Docker command output.\n\nOnce completed, the inside step will stop the container,\nget rid of the storage, and create a record that this image was used for the build.\nThat record facilitates image traceability, updates, etc.\n\nAs you can see, the combination of using the Docker “global variable” and its “inside” method provide a simple and powerful way to spin up and work with containers in your pipeline.\nIn addition, since you are not having to make the direct Docker calls, you can invoke steps like sh within the scope of the inside method, and have them executed by Docker transparently.\n\nAs we mentioned, this is only one of several ways you can interact with Docker in your pipeline code.\nTo learn about the other methods and get hands-on practice, join me at DevOps World/Jenkins World in San Francisco or Nice for the workshop\n\" Creating a Deployment Pipeline with Jenkins 2\".\nHope to see you there!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Using the Docker Global Variable in Your Jenkins Pipeline","tags":["event","jenkinsworld","jenkinsworld2018","pipeline","docker"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg","srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/77b35/brentlaster.jpg 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/d4a57/brentlaster.jpg 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/68974/brentlaster.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/ef6ff/brentlaster.webp 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/8257c/brentlaster.webp 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/6766a/brentlaster.webp 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/22bfc/brentlaster.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"brentlaster","html":"<div class=\"paragraph\">\n<p>Brent Laster is a Senior Manager in the Research and Development division at SAS in Cary, North Carolina. He manages several groups involved with release engineering processes, best practices, and tooling. He also serves as a resource for the use of open-source technologies and conducts internal training classes in technologies such as Git, Gerrit, Gradle, and Jenkins, both in the U.S. and abroad.</p>\n</div>\n<div class=\"paragraph\">\n<p>Brent Laster is the author of \"Professional Git\"\n(a comprehensive guide to Git for users ranging from beginners to advanced)\nand \"Jenkins 2 – Up and Running:  Evolve Your Pipeline for Next-Generation Automation\".</p>\n</div>","id":"brentlaster","irc":null,"linkedin":null,"name":"Brent Laster","slug":"/blog/authors/brentlaster","twitter":"brentclaster"}]}},{"node":{"date":"2018-08-14T00:00:00.000Z","id":"2fa297fb-b9d2-5c87-846c-6ac7d68adea3","slug":"/blog/2018/08/14/simple-pull-request-plugin-final-evaluation/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of reports at conventional locations,\nand publish them automatically. If the reports are not present at their respective conventional\nlocation, the location of the report can be configured in the YAML file.\n\nMy mentors are\nOleg Nenashev (Org Admin),\nMartin d’Anjou,\nKristin Whetstone,\nJeff Knurek\n\nProject Repository\n\nProject repository\n\nCode changes\n\nAll the pull requests made can be found here\n\nList of major pull requests.\n\nPhase 1\n\nPR-5 : Git wrappers like clone, pull, checkout,\npullChangesOfPullrequest, merge, deleteBranch and merge added.\n\nPR-6 : Yaml to Declarative Pipeline code generation.\n\nPlease see Phase 1 blog post\n\nPhase 2\n\nPR-11 : Implemented StepConfigurator\nusing Jenkins configuration as code plugin.\n\nPR-19 : Unit tests created for agent and yaml to pipeline generation.\n\nPlease see Phase 2 blog post\n\nPhase 3\n\nPR-25 : Declarative pipeline code generator code\nexported to extensions for extensibility and support of custom sections\n\nJenkinsfile.yaml example\n\nDocumentation of Jenkinsfile.yaml and yaml format can be found here\n\nTasks completed in Coding Phase 3\n\nAdd unit tests, JenkinsRule tests JENKINS-52495\n\nRefactor snippet generator to extensions ( JENKINS-52491)\n\nPlugin overview (Present in README.md)\n\nFuture tasks\n\nPhase 3 Jira Epic\n\nRelease 1.0 ( JENKINS-52519)\n\nSupport the “when” Declarative Pipeline directive ( JENKINS-52520)\n\nNice2have: Support hierarchical report types ( JENKINS-52521)\n\nAcceptance Test Harness tests JENKINS-52496\n\nAutomatic Workspace Cleanup when PR is closed ( JENKINS-51897)\n\nTest Multi-Branch Pipeline features support:\n\nSupport for webhooks ( JENKINS-51941)\n\nCheck if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)\n\nFinalize documentation ( JENKINS-52518)\n\nTest the integration with various platforms Bitbucket, Gitlab, Github.\n\nPhase 3 evaluation presentation video\n\nVideo: Link to video evaluation\n\nPhase 3 evaluation presentation slides\n\nLink to presentation slides\n\nMy GSoC experience\n\nStudent applications started on March 12 16:00 UTC and ended on March 27 16:00 UTC. Application period allowed me to explore\nmany new technology and platforms that are making peoples life easy.\n\nBefore starting of the application\nperiod I did not know anything about Jenkins. I found Jenkins organisation on the GSoC organisations page\nand came to know that I is a CI/CD platform that is used automate various things related to software development. I studied\nabout Jenkins online and went through the problem statements provided by some mentors.\n\nI decided that to work on Simple Pull-Request Job Plugin project.\nThen I wrote a draft proposal for this project and received many comments to refactor the proposal and enhance its quality from the mentors,\nthen finally I submitted my final proposal to Google.\n\nI was able to complete most of the tasks decided in Phase 1 and 2. After Phase 2 I was not able to give time to the project because\nof the placement season in the my college. I modified the code so that other plugin developers can contribute to it by Jenkins extensions.\n\nAll the mentors made themselves available for most of the weekly calls and provided many valuable suggestions during the\nentire period of GSoC. Sometimes I was not able to communicate effectively. As communication is the key while working remotely, mentors\nsuggested to communicate more thorough gitter chat.\n\nMy overall experience of GSoC was good and all the mentors helped me as they can all times. This project allowed me to explore\nJenkins and the services offered by it. I am allowed to work on the project after GSoC ends (This is a good thing).\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository","title":"alpha-3 release Pipeline as YAML (Simple pull request plugin)","tags":["gsoc2018","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/authors/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-08-06T00:00:00.000Z","id":"e7cd7824-744d-512b-9ee1-51257e0c567a","slug":"/blog/2018/08/06/serverless-cicd-jenkins/","strippedHtml":"Everyone is talking about serverless.\n\nAs with any new hyped-technology the term 'serverless' is often overloaded with different meanings.\nSometimes serverless is oversimplified to mean function-as-a-service(faas).\nBut there is more to it than that.\nAlso, not many people are talking about doing CI/CD with serverless,\neven though where there is code there still in need of continuous integration and continuous delivery.\nSo I was excited to hear about this talk by\nAnubhav Mishra on\nBuilding a CI/CD Pipeline for Serverless Applications.\n\nIn the talk Anubhav proposes a new definition for serverless:\n\n\"\"\nServerless is a technology pattern that provides services and concepts to minimize operational overhead that comes with managing servers.\nIt is a powerful abstraction when used can result in an increased focus on business value.\n\"\"\n\nThe talk then goes on to demo Jenkins on AWS Fargate (a platform for running containers without managing servers or clusters).\nThe main focus is on increased elasticity/scaling.\n\nThe advantages of this approach are:\n\nNo nodes/servers to manage\n\nLaunch 10,000+ builds/containers in seconds\n\nNo cost for idle time\n\nThe real headline is the cost saving, which is 2 orders of magnitude better with serverless.\nA cost comparison is done based on 1 vCPU & 2GB memory:\n\nWith Jenkins on Fargate: 100 builds * 5 mins = $0.633/month\n\nWith Jenkins on EC2 Instances: ~50/month\n\nThis huge potential cost saving is one of the things that makes serverless incredibly compelling.\nNot to mention you don’t have to think much upfront about scaling the system.\n\nBut there are drawbacks with this approach, noted as:\n\nCold starts - slower boot times for clients\n\nLarge container images (~1G)\n\nNo root access\n\nEphemeral storage (default)\n\nThis is an area where Jenkins can continue to evolve to make the most of serverless architectures.\nI highly recommend you check out the\nslides for yourself.\nThe best part is that, in the true spirit of open source, Anubvha shared the code\nhere.\nSo you can give it a try yourself and build your own serverless CI/CD pipeline with Jenkins.","title":"Building a Serverless CI/CD Pipeline with Jenkins","tags":["serverless","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg","srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/6105b/tracymiranda.jpg 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/9d80c/tracymiranda.jpg 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a5e1e/tracymiranda.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a4758/tracymiranda.webp 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fec68/tracymiranda.webp 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fe590/tracymiranda.webp 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/c2c8e/tracymiranda.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":116}}},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"/blog/authors/tracymiranda","twitter":"tracymiranda"}]}},{"node":{"date":"2018-07-17T00:00:00.000Z","id":"2629d18c-2a10-59b8-8b11-b24bb8b2b87d","slug":"/blog/2018/07/17/simple-pull-request-plugin/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of reports at conventional locations,\nand publish them automatically. If the reports are not present at their respective conventional\nlocation, the location of the report can be configured in the YAML file.\n\nMy mentors are\nOleg Nenashev (Org Admin),\nMartin d’Anjou,\nKristin Whetstone,\nJeff Knurek\n\nBenefits to the community\n\nProject administrators will be able to handle pull request builds more easily.\n\nBuild specifications for pull requests can be written in a concise declarative format.\n\nBuild reports will be automatically published to Github, Bitbucket, etc.\n\nBuild status updates will be sent to git servers automatically.\n\nUsers will not have to deal with pipeline code.\n\nIf there will be no merge conflicts or build failures, the PR can be merged into target branch.\n\nPhase 1 blog post\n\nPlease see Phase 1 blog post\n\nImplementations till now\n\nAlpha version of the plugin is released. It supports all features of Multi-Branch Pipeline and offers the following features.\n\nBuild description is defined via YAML file stored within the SCM repo. This plugin\nwill depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be\nusing respective platforms for their repositories.\n\nConversion of YAML to Declarative Pipeline: A class YamlToPipeline\nis written which will load the \"Jenkinsfile.yaml\" and make use of PipelineSnippetGenerator class\nto generate Declarative pipeline code.\n\nReporting of results, only xml report types is supported for now.\n\nUse of Yaml file (Jenkinsfile.yaml) from target branch.\n\nGit Push step: To push the changes of pull request to the target branch. This is implemented\nusing git-plugin, PushCommand is used for this from git-plugin. credentialId,\nbranch name and repository url for interacting with Github, Bitbucket, etc\nwill be taken automatically from \"Branch-Source\" (Users have to fill this\ndetails of branch source in job configuration UI). (You can see\nHow to run the demo)\n\nStepConfigurator: To generate pipeline code for all supported steps in Jenkins. This is using\nJenkins configuration-as-code plugin (JCasC plugin) to configure a particular step object and\nthen that step object is passed to Snippetizer.object2Groovy() method to generate the script of that step.\n\nJenkinsfile.yaml example\n\nFor the phase 1 prototype demonstration, the following yaml file was used.\nNote that this format is subject to change in the next phases of the project,\nas we formalise the yaml format definition.\n\n#  Docker image agent example\nagent:\n label: my_label\n customWorkspace: path_to_workspace\n dockerImage: maven:3-alpine\n args: -v /tmp:/tmp\n\n  tools:\n    maven : maven_3.0.1\n    jdk : jdk8\n\nconfiguration:\n  # Push PR changes to the target branch if the build succeeds.\n  # default value is false\n  pushPrOnSuccess: false\n\n  # Trusted user to approve pull requests\n  prApprovers:\n    - username1\n    - username2\n    - username3\n\nenvironment:\n  variables:\n    variable_1: value_1\n    variable_2: value_2\n\n  # Credentials contains only two fields. credentialId must be present in the Jenkins Credentials\n  credentials:\n    - credentialId : fileCredentialId\n      variable : FILE\n\n      # In user scripts Username and Password can be accessed by LOGIN_USR and LOGIN_PSW\n      # respectively as environment variales\n    - credentialId : dummyGitRepo\n      variable : LOGIN\n\nstages:\n  - name: stage1\n    agent: any\n    steps:\n      - sh: \"scripts/hello\"\n      - sleep:\n          time: 2\n          unit: SECONDS\n      - sleep: 2\n      - junit:\n          testResults: \"target/**.xml\"\n          allowEmptyResults: true\n          testDataPublishers:\n            - AutomateTestDataPublisher\n            - JunitResultPublisher:\n                urlOverride: \"urlOverride\"\n    # Post section for \"stage1\". All Conditions which are available in Jenkins\n    # declarative pipeline are supported\n    post:\n      failure:\n        - sh: \"scripts/hello\"\n\n# Outer post section. Just like declarative pipeline.\npost:\n  always:\n    - sh: \"scripts/hello\"\n\nCoding Phase 2 plans (Completed)\n\nDecide a proper YAML format to use for Jenkinsfile.yaml\n\nCreate Step Configurator for SPRP plugin. JENKINS-51637.\nThis will enable users to use Pipeline steps in Jenkinsfile.yaml.\n\nAutomatic indentation generation in the generated PipelineSnippetGenerator class.\n\nWrite tests for the plugin.\n\nCoding Phase 3 plans\n\nTest Multi-Branch Pipeline features support:\n\nSupport for webhooks ( JENKINS-51941)\n\nCheck if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)\n\nFinalize documentation ( JENKINS-52518)\n\nRelease 1.0 ( JENKINS-52519)\n\nPlugin overview blog post\n\nCoding Phase 3 plans after release\n\nSupport the “when” Declarative Pipeline directive ( JENKINS-52520)\n\nNice2have: Support hierarchical report types ( JENKINS-52521)\n\nAdd unit tests, JenkinsRule tests, and ATH tests ( JENKINS-52495, JENKINS-52496)\n\nAutomatic Workspace Cleanup when PR is closed ( JENKINS-51897)\n\nRefactor snippet generator to extensions ( JENKINS-52491)\n\nPhase 3 Jira Epic\n\nPhase 2 evaluation presentation video\n\nVideo:\n\nPhase 2 evaluation presentation slides\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository\n\nPhase 2 Presentation video (July 12, 2018)\n\nPhase 2 Presentation Slides (July 12, 2018)","title":"Pipeline as YAML: Alpha release","tags":["gsoc2018","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/authors/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-07-02T00:00:00.000Z","id":"44cd4bd6-4c8f-5fdd-8f54-c99da078882e","slug":"/blog/2018/07/02/whats-new-declarative-piepline-13x-sequential-stages/","strippedHtml":"We recently released version 1.3 of Declarative Pipelines, which includes a couple significant new features. We’re\ngoing to cover these features in separate blog posts. The next post will show the new ability to restart a completed\nPipeline run starting from a stage partway through the Pipeline, but first, let’s look at the new sequential stages\nfeature.\n\nSequential Stages\n\nIn Declarative 1.2, we added the ability to define stages to run in parallel\nas part of the Declarative syntax. Now in Declarative 1.3, we’ve added another way to specify stages nested within other\nstages, which we’re calling \"sequential stages\".\n\nRunning Multiple Stages in a Parallel Branch\n\nOne common use case is running build and tests on multiple platforms. You could already do that with parallel stages,\nbut now you can run multiple stages in each parallel branch giving you more visibility into the progress of your\nPipeline without having to check the logs to see exactly which step is currently running where, etc.\n\nYou can also\nuse stage directives, including post, when, agent, and all the others covered in the\nPipeline Syntax reference\nin your sequential stages, letting you control behavior for different parts of each parallel branch.\n\nIn the example below, we are running builds on both Windows and Linux, but only want to deploy if we’re on the master branch.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and deploy on Windows and Linux\") {\n            parallel {\n                stage(\"windows\") {\n                    agent {\n                        label \"windows\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                bat \"run-build.bat\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                            when {\n                                branch \"master\"\n                            }\n                            steps {\n                                bat \"run-deploy.bat\"\n                            }\n                        }\n                    }\n                }\n\n                stage(\"linux\") {\n                    agent {\n                        label \"linux\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                sh \"./run-build.sh\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                             when {\n                                 branch \"master\"\n                             }\n                             steps {\n                                sh \"./run-deploy.sh\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nRunning Multiple Stages with the Same agent, or environment, or options\n\nWhile the sequential stages feature was originally driven by users wanting to have multiple stages in parallel branches,\nwe’ve found that being able to group multiple stages together with the same agent, environment, when, etc has a lot\nof other uses. For example, if you are using multiple agents in your Pipeline, but would like to be sure that stages using\nthe same agent use the same workspace, you can use a parent stage with an agent directive on it, and then all the stages\ninside its stages directive will run on the same executor, in the same workspace. Another example is that until now, you\ncould only set a timeout for the entire Pipeline or an individual stage. But by using a parent stage with nested stages,\nyou can define a timeout in the parent’s options directive, and that timeout will be applied for the execution of the\nparent, including its nested stages. You may also want to conditionally control the execution of multiple stages. For example,\nyour deployment process may be spread across multiple stages, and you don’t want to run any of those stages unless you’re on\na certain branch or some other criteria is satisified. Now you can group all those related stages together in a parent\nstage, within its stages directive, and have a single when condition on that parent, rather than having to copy an\nidentical when condition to each of the relevant stages.\n\nOne of my favorite use cases is shown in the example below. In Declarative 1.2.6, we added the input directive for stages.\nThis will pause the execution of the Pipeline until a user confirms that the Pipeline should continue, using the Scripted\nPipeline input step. The input directive is evaluated before the stage enters its agent, if it has one specified, and\nbefore the stage’s when condition, if specified, is evaluated. But if you’re using a top-level agent for most of your\nstages, you’re still going to be using that agent’s executor while waiting for input, which can be a waste of resources.\nWith sequential stages, you can instead use agent none at the top-level of the Pipeline, and group the stages using a common\nagent and running before the stage with the input directive together under a parent stage with the required agent\nspecified. Then, when your Pipeline reaches the stage with input, it will no longer be using an agent’s executor.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and test the project\") {\n            agent {\n                docker \"our-build-tools-image\"\n            }\n            stages {\n               stage(\"build\") {\n                   steps {\n                       sh \"./build.sh\"\n                   }\n               }\n               stage(\"test\") {\n                   steps {\n                       sh \"./test.sh\"\n                   }\n               }\n            }\n            post {\n                success {\n                    stash name: \"artifacts\", includes: \"artifacts/**/*\"\n                }\n            }\n        }\n\n        stage(\"deploy the artifacts if a user confirms\") {\n            input {\n                message \"Should we deploy the project?\"\n            }\n            agent {\n                docker \"our-deploy-tools-image\"\n            }\n            steps {\n                sh \"./deploy.sh\"\n            }\n        }\n    }\n}\n\nThese are just a few example of the power of the new sequential stages feature in Declarative 1.3.\nThis new feature adds another set of significant use cases that can be handled smoothly using Declarative Pipeline.\nIn my next post, I’ll show the another highly requested feature - the new ability to restart a Pipeline run from any stage in that Pipeline.","title":"What's New in Declarative Pipeline 1.3: Sequential Stages","tags":["pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}}]}},"pageContext":{"tag":"pipeline","limit":8,"skip":16,"numPages":13,"currentPage":3}},
    "staticQueryHashes": ["3649515864"]}