{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/pipeline/page/11",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-04-07T00:00:00.000Z","id":"dc2d5625-7a35-5883-9c50-152fda1c584a","slug":"/blog/2016/04/07/jenkins-community-survey-results-blog/","strippedHtml":"This is a guest post by Brian\nDawson at CloudBees, where he works as a DevOps Evangelist responsible for\ndeveloping and sharing continuous delivery and DevOps best practices. He also\nserves as the CloudBees Product Marketing Manager for Jenkins.\n\nLast fall CloudBees asked attendees at the Jenkins User Conference – US West\n(JUC), and other in the Jenkins community to take a survey.  Almost 250 people\ndid – and thanks to their input, we have results which provided interesting\ninsights into how Jenkins is being used.\n\nBack in 2012, at the time of the last community survey, 83% of respondents felt\nthat Jenkins was mission-critical. By 2015, the percentage saying that\nJenkins was mission-critical was 92%. Additionally, echoing the\nimportance of Jenkins, 89% of respondents said their use of Jenkins had\nincreased over the last year, while 11% said it had stayed the same. 0%\nsaid that it had decreased.\n\nThe trend in the industry over the last couple of years has been to adopt\ncontinuous delivery (CD), thus pushing automation further down the pipeline –\nfrom development all the way into production.  Jenkins being an automation\nengine applicable to any phase of the software delivery lifecycle, is readily\nsupporting this trend. Jenkins' extensible architecture and unparalleled plugin\necosystem enables integration with and orchestration of practically any tool in\nany phase of software delivery.\n\nThe trend towards adoption of CD is clearly reflected amongst the community: 59%\nof respondents are using Jenkins for continuous integration (CI), but an\nadditional 30% have extended CI into CD and are manually deploying code to\nproduction.  Finally, 11% are practicing continuous deployment – they have\nextended CI to CD and are deploying code automatically into production.\n\nAnother trend tied to the adoption of CD and DevOps is the frequent deployment\nof incremental releases to production. 26% of those respondents using continuous\ndelivery practices are deploying code at least once per day.  Another 37% are\ndeploying code at least once per week.\n\nIn keeping with the move to CD, 30% of survey takers are already using the\nrelatively new Pipeline plugin to automate their\nsoftware delivery pipelines.  Of those not using the Pipeline plugin, 79% plan\nto adopt it in the next 12 months.\n\nSurvey respondents are also using Jenkins for many different activities.  97% of\nsurvey takers use it for \"build\" – no surprise, since that is where Jenkins got\nits start - but 58% now also use it for their deployment.\n\nWhen the 2012 community survey was conducted, container technology was not as\nwell understood as it is today,  and many didn’t know what a “Docker” was. A\nshort four years later, 96% of survey respondents who use Linux containers are\nusing Docker.  Container technology has seen impressive adoption and arguably is\nrevolutionizing the way application infrastructure is delivered.  When coupled\nwith Jenkins as an automation engine, containers help accelerate software\ndelivery by providing rapid access to lightweight environments.  The Jenkins\ncommunity has recognized and embraced the power of containers by\nproviding plugins for Docker and Kubernetes.\n\nThe Jenkins improvements which survey respondents desired the most were\nquality/timely bug fixes, a better UI and more documentation/examples.\nInterestingly, Jenkins 2.0 - which is just about to officially launch,\nprovides UI improvements and the new Jenkins.io website\nprovides improved, centralized documentation.\n\nFinally, the respondents favorite Star Wars character was R2-D2, followed by\nObi-Wan and Darth Vader. Yoda and Han Solo also got a fair amount of votes. The\nvotes for Jar-Jar Binks and Jabba the Hutt left us puzzled. Notably, BB-8 had a\nwrite-in vote despite the fact the new Star Wars movie hadn’t been released yet.\n\nAs to where the community is headed, our prediction is that by the next Jenkins Community Survey:\n\nMore Jenkins users will have transitioned from just continuous\nintegration to continuous delivery with some evening practicing continuous\ndeployment\n\nPipeline plugin adoption and improvements will continue, leading to\npipeline-as-code becoming an essential solution for automating the software\n(and infrastructure) delivery process\n\nThere will be a significant increase in use of the Docker plugin to support\nelastic Jenkins infrastructure and continuous delivery of containers using\nsoftware development best practices\n\nBB-8 will be the next favorite Star Wars character! <3</p>\n\nSee you at Jenkins World, September 13-15, in Santa Clara, California!\nRegister now for the largest Jenkins event on the planet in 2016 – and get the Early Bird discount. The Call for Papers is still open – so submit a talk and share your knowledge with the community about Jenkins.\n\n2015 Community Survey Results (PDF)\n\nState of Jenkins Infographic (PDF)","title":"Jenkins Community Survey Results","tags":["continuousdelivery","pipeline","docker"],"authors":[{"avatar":null,"blog":null,"github":"bvdawson","html":"<div class=\"paragraph\">\n<p>DevOps dude at CloudBees.\nJenkins Marketing Manager.\nTools geek.</p>\n</div>","id":"bvdawson","irc":null,"linkedin":null,"name":"Brian Dawson","slug":"blog/author/bvdawson","twitter":"brianvdawson"}]}},{"node":{"date":"2016-04-07T00:00:00.000Z","id":"bb46e899-10f9-583c-862c-a664e9eb81b4","slug":"/blog/2016/04/07/pipeline-for-runs-on-hardware/","strippedHtml":"In addition to Jenkins development, during last 8 years I’ve been involved into continuous integration for hardware and embedded projects.\nAt JUC2015/London\nI have conducted a talk about common automation challenges in the area.\n\nIn this blog post I would like to concentrate on Pipeline (formerly known as Workflow), which is a new ecosystem in Jenkins that allows implementing jobs in a domain specific language.\nIt is in the suggested plugins list in the upcoming Jenkins 2.0 release.\n\nThe first time I tried Pipeline two and half years ago, it unfortunately did not work for my use-cases at all.\nI was very disappointed but tried it again a year later.\nThis time, the plugin had become much more stable and useful.\nIt had also attracted more contributors and started evolving more rapidly with the development of plugins extending the Pipeline ecosystem.\n\nCurrently, Pipeline a powerful tool available for Jenkins users to implement a variety of software delivery pipelines in code.\nI would like to highlight several Pipeline features which may be interesting to Jenkins users working specifically with embedded and hardware projects.\n\nIntroduction\n\nIn Embedded projects it’s frequently required to run tests on specific hardware peripherals: development boards, prototypes, etc.\nIt may be required for both software and hardware areas, and especially for products involving both worlds.\nCI and CD methodologies require continuous integration and system testing, and Jenkins comes to help here.\nJenkins is an automation framework, which can be adjusted to reliably work with hardware attached to its nodes.\n\nArea challenges\n\nGenerally, any peripheral hardware device can be attached to a Jenkins node.\nSince Jenkins nodes require Java only, almost every development machine can be attached.\nBelow you can find a common connection scheme:\n\nAfter the connection, Jenkins jobs could invoke common EDA tools via command-line interfaces.\nIt can be easily done by a Execute shell build steps in free-style projects.\nSuch testing scheme is commonly affected by the following issues:\n\nNodes with peripherals are being shared across several projects.\nJenkins must ensure the correctness of access (e.g. by throttling the access).\n\nIn a single Freestyle project builds utilize the node for a long period. If you synthesize the item before the run, much of the peripheral utilization file may be wasted.\n\nThe issue can be solved by one of concurrency management plugins:\nThrottle Concurrent Builds, Lockable Resources\nor\nExclusions.\n\nTest parallelization on multiple nodes requires using of multiple projects or\nMatrix configurations, so it causes job chaining again.\n\nThese build chains can be created via\nParameterized Trigger and\nCopy Artifacts, but it complicates job management and build history investigation.\n\nHardware infrastructure is usually flaky.\nIf it fails during the build due to any reason, it’s hard to diagnose the issue and re-run the project if the issue comes from hardware.\n\nBuild Failure Analyzer allows to identify the root cause of a build failure (e.g. by build log parsing).\n\nConditional Build Step and\nFlexible Publish plugins allow altering the build flow according to the analysis results.\n\nCombination of the plugins above is possible, but it makes job configurations extremely large.\n\nTests on hardware peripherals may take much time.\nIf an infrastructure fails, we may have to restart the run from scratch.\nSo the builds should be robust against infrastructure issues including network failures and Jenkins controller restarts.\n\nTests on hardware should be reproducible, so the environment and input parameters should be controlled well.\n\nJenkins supports\ncleaning workspaces, so it can get rid of temporary files generated by previous runs.\n\nJenkins provides support of agents connected via containers (e.g.\nDocker) or VMs, which allow creating clean environments for every new run.\nIt’s important for 3rd-party tools, which may modify files outside the workspace: user home directory, temporary files, etc.\n\nThese environments still need to be connected to hardware peripherals, which may be a serious obstacle for Jenkins admins\n\nThe classic automation approaches in Jenkins are based on Free-style and Multi-configuration project types.\nLinks to various articles on this topic are collected on the\nHW/Embedded Solution page Embedded on the Jenkins website.\nTests automation on hardware peripherals has been covered in several publications by Robert Martin, Steve Harris, JL Gray, Gordon McGregor, Martin d’Anjou, and Sarah Woodall.\nThere is also a top-level overview of classic approaches made by me at JUC2015/London (a bit outdated now).\n\nOn the other hand, there is no previous publications, which would address Pipeline usage for the Embedded area.\nIn this post I want to address this use-case.\n\nPipeline as Code for test runs on hardware\n\nPipeline as Code is an approach for describing complex automation flows in software lifecycles: build, delivery, deployment, etc.\nIt is being advertised in Continuous Delivery and DevOps methodologies.\n\nIn Jenkins there are two most popular plugins:\nPipeline and Job DSL.\nJobDSL Plugin internally generates common freestyle jobs according to the script, so it’s functionality is similar to the classic approaches.\nPipeline is fundamentally different, because it provides a new engine controlling flows independently from particular nodes and workspaces.\nSo it provides a higher job description level, which was not available in Jenkins before.\n\nBelow you can find an example of Pipeline scripts, which runs tests on FPGA board. The id of this board comes from build parameters ( fpgaId). In this script we also presume that all nodes have pre-installed tools (Xilinx ISE in this case).\n\n// Run on node having my_fpga label\nnode(\"linux && ml509\") {\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  sh \"make all\"\n}\n\nBut such scenario could be also implemented in a Free-style project.\nWhat would we get from Pipeline plugin?\n\nGetting added-value from Pipeline as code\n\nPipeline provides much added-value features for hardware-based tests.\nI would like to highlight the following advantages:\n\nRobustness against restarts of Jenkins controller.\n\nRobustness against network disconnects. sh() steps are based on the\nDurable Task plugin, so Jenkins can safely continue the execution flow once the node reconnects to the controller.\n\nIt’s possible to run tasks on multiple nodes without creating complex flows based on job triggers and copy artifact steps, etc. It can be achieved via combination of parallel() and node() steps.\n\nAbility to store the shared logic in standalone Pipeline libraries\n\netc.\n\nFirst two advantages allow to improve the robustness of Jenkins nodes against infrastructure failures.\nIt is critical for long-running tests on hardware.\n\nLast two advantages address the flexibility of Pipeline flows.\nThere are also plugins for freestyle projects, but they are not flexible enough.\n\nUtilizing Pipeline features\n\nThe sample Pipeline script above is very simple.\nWe would like to get some added value from Jenkins.\n\nGeneral improvements\n\nLet’s enhance the script by using several features being provided by pipeline in order to get visualization of stages, report publishing and build notifications.\n\nWe also want to minimize the time being spent on the node with the attached FPGA board.\nSo we will split the bitfile generation and further runs to two different nodes in this case: a general purpose linux node, and the node with the hardware attached.\n\nYou can find the resulting Pipeline script below:\n\n// Synthesize on any node\ndef imageId=\"\"\nnode(\"linux\") {\n  stage \"Prepare environment\"\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  // Construct the bitfile image ID from commit ID\n  sh 'git rev-parse HEAD > GIT_COMMIT'\n  imageId= \"myprj-${fpgaId}-\" + readFile('GIT_COMMIT').take(6)\n\n  stage \"Synthesize project\"\n  sh \"make FPGA_TYPE=$fpgaId synthesize_for_fpga\"\n  /* We archive the bitfile before running the test, so it won't be lost it if something happens with the FPGA run stage. */\n  archive \"target/image_${fpgaId}.bit\"\n  stash includes: \"target/image_${fpgaId}.bit\", name: 'bitfile'\n}\n\n/* Run on a node with 'my_fpga' label.\nIn this example it means that the Jenkins node contains the attacked FPGA of such type.*/\nnode (\"linux && $fpgaId\") {\n  stage \"Blast bitfile\"\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  def artifact='target/image_'+fpgaId+'.bit'\n  echo \"Using ${artifact}\"\n  unstash 'bitfile'\n  sh \"make FPGA_TYPE=$fpgaId impact\"\n\n  /* We run automatic tests.\n  Then we report test results from the generated JUnit report. */\n  stage \"Auto Tests\"\n  sh \"make FPGA_TYPE=$fpgaId tests\"\n  sh \"perl scripts/convertToJunit.pl --from=target/test-results/* --to=target/report_${fpgaId}.xml --classPrefix=\\\"myprj-${fpgaId}.\\\"\"\n  junit \"target/report_${fpgaId}.xml\"\n\n  stage \"Finalization\"\n  sh \"make FPGA_TYPE=$fpgaId flush_fpga\"\n  hipchatSend(\"${imageId} testing has been completed\")\n}\n\nAs you may see, the pipeline script mostly consists of various calls of command-line tools via the sh() command.\nAll EDA tools provide great CLIs, so we do not need special plugins in order to invoke common operations from Jenkins.\n\nMakefile above is a sample stuff for demo purposes.\nIt implements a set of unrelated routines merged into a single file without dependency declarations.\nNever write such makefiles.\n\nIt is possible to continue expanding the pipeline in such way.\nPipeline Examples\ncontain examples for common cases: build parallelization, code sharing between pipelines, error handling, etc.\n\nLessons learned\n\nDuring last 2 years I’ve been using Pipeline for Hardware test automation several times.\nThe first attempts were not very successful, but the ecosystem has been evolving rapidly.\nI feel Pipeline has become a really powerful tool, but there are several missing features.\nI would like to mention the following ones:\n\nShared resource management across different pipelines.\n\nRuns of a single Pipeline job can be synchronized using the concurrency parameter of the stage() step\n\nIt can be done by the incoming Pipeline integration in the\nLockable Resources plugin\n( JENKINS-30269).\n\nAnother case is integration with\nThrottle Concurrent Builds plugin, which is an effective engine for limiting the license utilization in automation infrastructures\n( JENKINS-31801).\n\nBetter support of CLI tools.\n\nEDA tools frequently need a complex environment, which should be deployed on nodes somehow.\n\nIntegration with\nCustom Tools Plugin seems to be the best option, especially in the case of multiple tool versions\n( JENKINS-30680).\n\nPipeline package manager ( JENKINS-34186)\n\nSince there is almost no plugins for EDA tools in Jenkins, developers need to implement similar tasks at multiple jobs.\n\nA common approach is to keep the shared \"functions\" in libraries.\n\nPipeline Global Library and\nPipeline Remote Loader can be used, but they do not provide features like dependency management.\n\nPipeline debugger ( JENKINS-34185)\n\nHardware test runs are very slow, so it is difficult to troubleshoot and fix issues in the Pipeline code if you have to run every build from scratch.\n\nThere are several features in Pipeline, which simplify the development, but we still need an IDE-alike implementation for complex scripts.\n\nConclusions\n\nJenkins is a powerful automation framework, which can be used in many areas.\nEven though Jenkins has no dedicated plugins for test runs on hardware, it provides many general-purpose \"building blocks\", which allow implementing almost any flow.\nThat’s why Jenkins is so popular in the hardware and embedded areas.\n\nPipeline as code can greatly simplify the implementation of complex flows in Jenkins.\nIt continues to evolve and extend support of use-cases.\nif you’re developing embedded projects, consider Pipeline as a durable, extensible and versatile means of implementing your automation.\n\nWhat’s next?\n\nJenkins automation server dominates in the HW/Embedded area, but unfortunately there is not so much experience sharing for these use-cases.\nSo Jenkins community encourages everybody to share the experience in this area by writing docs and articles for Jenkins website and other resources.\n\nThis is just a a first blog post on this topic.\nI am planning to provide more examples of Pipeline usage for Embedded and Hardware tests in the future posts.\nThe next post will be about concurrency and shared resource management in Pipelines.\n\nI am also going to talk about running tests on hardware at the\nupcoming Automotive event in Stuttgart on April 26th.\nThis event is being held by\nCloudBees, but there will be several talks addressing Jenkins open-source as well.\n\nIf you want to share your experience about Jenkins usage in Hardware/Embedded areas, consider submitting a talk for the\nJenkins World conference or join/organize a\nJenkins Area Meetup in your city.\nThere is also a\nJenkins Online Meetup.\n\nLinks\n\nRelated articles and events:\n\nHW/Embedded Solution page\n\nJenkins-Based CI for Heterogeneous Hardware/Software Projects\n\nAccelerating Automotive Innovation with Continuous Integration & Delivery - meetup in Stuttgart\n\nPipeline:\n\nPipeline page\n\nJenkins 2.0 and Pipeline as code overview\n\nPipeline Tutorial\n\nPipeline Examples","title":"Automating test runs on hardware with Pipeline as Code","tags":["jenkins2","pipeline","embedded"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"blog/author/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2015-12-21T00:00:00.000Z","id":"7ab2189c-9e15-5a58-9230-a1a13f92071b","slug":"/blog/2015/12/21/december-jam-world-tour-toulouse-france/","strippedHtml":"On December 15, the Toulouse\nJAM\nwas co-hosted with the Toulouse\nJUG and Toulouse\nDevOps. Indeed it made sense since Jenkins is\nwritten in Java, makes use of Groovy code in many places (system groovy script,\njob dsl, workflow…​), and it also made sense to co-organize with the local\nDevOps community since Jenkins is also a great tool to enable Continuous\nIntegration, Continuous Delivery and automation in general. There were 103\nRSVPs, with 80 to 90 people in attendance.\n\nThere were 3 talks planned for the evening:\n\nJob DSL\nIntro [fr], by Ghislain Mahieux\n\nVideo recording\n\nWorkflow plugin [fr], by Michaël Pailloncy (co-maintainer of the Build Trigger Badge plugin)\n\nVideo recording\n\nFeedback on almost 10 years of CI and what’s upcoming [fr], demo with Jenkins build scaling with Docker Swarm, by Baptiste Mathus\n\nVideo recording\n\nPhotos can be found here","title":"December JAM World Tour: Toulouse, France","tags":["general","meetup","jenkinsci","pipeline","workflow"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"","id":"hinman","irc":null,"linkedin":null,"name":"Hannah Inman","slug":"blog/author/hinman","twitter":null}]}},{"node":{"date":"2015-12-16T00:00:00.000Z","id":"c4dd7873-a1dc-5a87-918b-4c7455812df3","slug":"/blog/2015/12/16/workflow-best-practices-and-examples-repo-on-github/","strippedHtml":"A lot of people are using the Workflow plugin, but as with any scripting environment, users often have to start from scratch and learn the same lessons and shortcuts that other users have already learned. While there are blog posts from developers and users in various places, and some samples in the Workflow plugin documentation, more examples and tips and tricks are always, always useful. To help with that, we’ve created the workflow-examples repository on GitHub, as a place to store community-developed Workflow scripts that can help new users get started, show how to accomplish some non-trivial goals, and find tips and trick for taking your Workflow pipeline to the next level.\n\nThe repository has four directories:\n\ndocs/ - documentation, guides, and more. Including a Best Practices document. We’d love to see more contributions to that doc, as well as any new ones that would be helpful to Workflow users!\n\nworkflow-examples/ - general Workflow examples, showing how to use a given plugin with Workflow, quirks of the Workflow DSL syntax, and more.\n\nglobal-library-examples/ - examples of how to write code for the Workflow global library.\n\njenkinsfile-examples/ - Sample Jenkinsfiles or other Workflow scripts from SCM .\n\nDuring Hacksgiving some initial content was added, but not everything is covered yet, which is why I’m posting this - more is needed. We’d love to see your tips, examples, gotchas and more. If you’ve got Workflow scripts you’d like to contribute, please read the README and send a pull request. Thanks!","title":"Workflow Best Practices and Examples repo on GitHub","tags":["general","jenkinsci","pipeline","workflow"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"blog/author/abayer","twitter":"abayer"}]}},{"node":{"date":"2015-12-03T00:00:00.000Z","id":"51e550d9-2ab9-5be8-be79-96bef6d8ca1a","slug":"/blog/2015/12/03/pipeline-as-code-with-multibranch-workflows-in-jenkins/","strippedHtml":"Note: This is a guest post by Kishore Bhatia. Kishore works for CloudBees, building custom frameworks with Open Source software and helping customers solve engineering problems around continuous delivery and DevOps at scale.\n\nThis year some great new Jenkins features came out of the butler’s goodie bag - amongst them, the most important one being the ability to realize continuous delivery pipeline as code!\nThe features like Workflow Multibranch, pipeline-as-code (with a marker file that Jenkins looks for in your application’s SCM repository/branch, aptly named Jenkinsfile) are the foundations to making Jenkins super intelligent to automagically create workflows (rather, a CI/CD pipeline) to build your code and orchestrate the work required to drive your application from concept to delivery!\n\nOverview\n\nThe Workflow Multibranch feature (provided by the workflow plugin) provides the following key abilities:\n\nAutomatic Workflow (job) creation in Jenkins per new branch in the repo (assuming webhooks are registered from GH to Jenkins).\n\nBuild specific to that child-branch and its unique scm change and build history.\n\nAutomatic job pruning/deletion for branches deleted from the repository, according to the settings.\n\nFlexibility to individually configure branch properties, by overriding the parent properties, if required.\n\nJenkins pipeline-as-code (concept) enables you to maintain your CI/CD workflow logic in the project/application source code repo with no additional configuration to be maintained per branch in Jenkins.\n\nThe Workflow script to build/test/deploy your code is always synchronized with the rest of the source code you are working on.\n\nTo demonstrate the concept here - Let’s use a basic Java Web application project with a Maven pom.xml as shown in the structure below (this is using GitHub as the SCM but you can do this on SVN or Mercurial too).\n\nThis project has a marker file for Jenkins in the repo - Jenkinsfile. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic1.png\n\nSo, what’s a Jenkinsfile? The Jenkinsfile is essentially your Jenkins Workflow, a script, that defines the CI/CD pipeline logic for a project with steps to build/test/deploy etc. captured in various stages.\n\nSo for our sample Java web application, a basic Jenkinsfile could be something like -\n\nnode {\n   // Mark the code checkout 'stage'....\n   stage 'Checkout'\n\n   // Checkout code from repository\n   checkout scm\n\n   // Get the maven tool.\n   // ** NOTE: This 'M3' maven tool must be configured\n   // **       in the global configuration.\n   def mvnHome = tool 'M3'\n\n   // Mark the code build 'stage'....\n   stage 'Build'\n   // Run the maven build\n   sh \"${mvnHome}/bin/mvn clean install\"\n}\n\nJust having this file in the source code repo root would mean that -\n\nJenkins will automatically recognize this branch and create appropriate jobs by itself.\n\nQuick, 1-step code checkout using: “checkout scm” in your workflow\n\nEvery time a new change is pushed to this branch, the branch is built and the commit status gets updated.\n\nWhen the branch is destroyed in the repository, or if Jenkinsfile is removed, the corresponding job gets destroyed from Jenkins automatically ( You can retain these jobs and/or archive the builds for audit/compliance requirements using the retention property - Orphan Item strategy)\n\nthere are various mechanisms to promote reuse of Workflow scripts, such as the Workflow Global Library.\n\nRequired Jenkins configuration\n\nMake sure you’ve the latest Workflow and (v1.11 as of writing this blog) Workflow Multibranch plugins installed on your Jenkins instance image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic2.png\n\nAlso, ensure that other dependencies, like SCM plugins and build tools, are met:\n\nEither SVN/Git/Mercurial (depending on your SCM)\n\nGitHub Branch Source Plugin (optimized to use the GitHub API and improve performance)\n\nMaven build tool\n\nFinally, make sure you’ve created the required Webhook from your SCM (Github in this case) to Jenkins.\nHere’s how to do that:\n\nSetting up GitHub Webhooks in Jenkins\n\nStep-by-step guide to setting up Jenkins for GitHub projects\n\nThen create a new Multibranch Workflow Job with configuration as shown below - mainly selecting the Branch Sources (Git, in this example) and providing the branch/repo URL with credentials.\n\nBranch sources (Git) - https://github.com/kishorebhatia/pipeline-as-code-demo (or a repo where you’ve cloned this source code with Jenkinsfile)\n\nLeave all other properties default and Save. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic3.png\n\nYou’ll observe that Jenkins would perform Branch Indexing on that “cd” job folder and start the workflow for the master branch, with an automatically created new job, named master, under the “cd” folder.\n\nThe workflow does a dummy step for application deploys to the environments in this sequence Staging -> Waits for manual approval -> PROD\n\nNow, let’s create a new branch off of this master branch in your cloned git repo:\n\n$ git branch newBranch (create a newBranch)\n\n$ git checkout newBranch (switches to newBranch)\n\n$ git push --set-upstream origin newBranch (pushes newBranch)\n\nYou’ll observe that your Jenkins instance automatically picks up this newBranch and starts running the workflow (with the Jenkinsfile in this newBranch) to build/test/deploy the code. image:https://web.archive.org/web/*/https://agentdero.cachefly.net/continuousblog/pipeline-as-code-guest-blog/Pic4.png\n\nNext, if you now delete this newBranch ( git branch -D newBranch), Jenkins will automatically remove the orphan Workflow job for newBranch. You can retain these jobs even after the branches are deleted using the Orphaned Item Strategy property in the main \"cd\" job’s configuration.\n\nSo we observed the following benefits of this pipeline-as-code approach:\n\nOverall job definition is a script (Jenkinsfile)\n\nCalls your build tools and scripts for details\n\nThe build script can be versioned alongside project sources\n\nJenkins handles feature/experimental branches automatically\n\nKeep less configuration in $JENKINS_HOME\n\nDockerized Demo environment\n\nYou can also use the following docker image to run this demo with a preconfigured Jenkins environment and the sample job: jenkinsci/workflow-demo (i.e. docker pull jenkinsci/workflow-demo)\n\nThis docker container includes Jenkins with Workflow and Workflow Multibranch plugins, a local git repo with the aforementioned Java web application and Jetty to demonstrate a continuous delivery pipeline of this application deployed and tested across multiple environments in the pipeline with an approval gate before promoting to PROD (like QA, Staging and PROD).\n\nThere’s a \"cd\" job pre-configured as a multibranch Workflow job.\n\nLaunch the docker demo as: docker run -p 8080:8080 -p 8081:8081 -p 9418:9418 -ti jenkinsci/workflow-demo\n\nNow, you can access Jenkins on port 8080 and Jetty on port 8081 from localhost or the IP of your boot2docker/docker-machine environment.\n\nThe demo container has a local git repo so you can clone: git://localhost/repo. When creating new branches, each branch automatically creates a matching subproject in Jenkins and triggers the build for that branch. The workflow:\n\nChecks out source code from the same repository and commit as Jenkinsfile.\n\nBuilds sources via Maven with unit testing.\n\nRuns two parallel integration tests that involve deploying the app to ephemeral server instances, which get thrown away when tests are done (this is done by using auto-deployment of Jetty)\n\nOnce integration tests are successful, the webapp gets to the staging server at localhost:8081/staging (or your docker-machine/boot2docker instance IP)\n\nrequires a human to Manually inspect the staging instance, and when ready, approves the deployment to the production server at http://localhost:8081/production/\n\nReferences\n\nDeveloper blog by jglick introducing multibranch support\n\nworkflow plugin tutorial\n\nworkflow plugin presentations\n\nworkflow plugin demo readme","title":"Pipeline-as-code with Multibranch Workflows in Jenkins","tags":["general","guest post","tutorial","pipeline","workflow"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2015-12-02T00:00:00.000Z","id":"225e35ac-aaf9-5523-a569-3d9679163b6e","slug":"/blog/2015/12/02/hacksgiving-left-overs/","strippedHtml":"Last week we hosted our first Hacksgiving event, a two-day virtual hackathon with a number of recorded sessions and plenty of pull requests submitted, I would say it was a success! I would like to thank everybody who took the time to watch, chat and present in the Hacker Hangout.\n\nNow that everybody has had time to recover from the turkey and travel, we have some videos of the sessions sliced out and ready for publication.\n\nIn addition to the recorded sessions, there were a number of notes captured with useful links associated with practically each session. You can find those notes at the bottom of the Hacksgiving page.\n\nThe following videos are all available in this YouTube playlist\n\nIntro to the Jenkins project\n\nThis session was hosted by rtyler and meant to provide a cursory overview of where to get started with contributing to the Jenkins project\n\nIntro to Plugin Development Workshop\n\nThis session was given both days of Hacksgiving by schristou and does a really great job of introducing the viewer to getting started with developing a Jenkins plugin with Java.\n\nWorkflow Q&A and Demo Session\n\nThis session was not originally scheduled, but some folks on the Jenkins IRC channel had some Workflow questions and Jesse Glick jumped into the Hacker Hangout to help us out!\n\nInternationalization Live Coding / Q&A\n\nAnother impromptu session, this time with danielbeck hosting. In this session Daniel walks through a plugin he was working on for Hacksgiving and adds internationalization support while answering a few questions here and there.\n\nIntro to the new static site\n\nKicking off day two of Hacksgiving, rtyler hosted a session on the new statically-generated Jenkins site. The new site will dramatically lower the barrier to entry for contribution to Jenkins documentation and blogs, by pushing everything through GitHub.\n\nPlugin Developer Open Q&A\n\nThis was the last session of Hacksgiving, hosted by abayer and ended up being more like a casual discussion of the current status and future work in the plugin development ecosystem.","title":"Hacksgiving Left-overs","tags":["general","meetup","video","pipeline","workflow"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2015-10-28T00:00:00.000Z","id":"f9383f6c-7ac4-510a-ba69-7c342cd84479","slug":"/blog/2015/10/28/jenkins-2-0-proposal-pipeline-as-code-front-and-center/","strippedHtml":"We have been featuring a few proposals this week for what \" Jenkins\n2.0\" is going to include, today we’re discussing my personal favorite, which I believe will have a tremendously positive impact for years to come (not to be too biased!): moving the \"Pipeline as Code\" support in Jenkins to the front and center.\n\nThus far in this blog series we have reviewed proposals covering:\n\nIntroducing a policy for API deprecation\n\nSplitting Groovy out of 'core'\n\nToday’s proposal comes from project founder Kohsuke Kawaguchi titled \" Pipeline as code front and center \" and represents perhaps the most important and dramatic shift we hope to make in Jenkins 2.0.\n\nThis functionality has existed through the workflow plugin, which we have discussed at various Jenkins events before but if you’re not aware of some of the power behind it, check out this presentation from Jesse Glick :\n\nThe proposal in JENKINS-31152 expands on the problem we aim to address:\n\nThe default interaction model with Jenkins has been very web UI driven, requiring users to manually create jobs, then manually fill in the details through a web browser. This requires large amounts of effort to create and manage jobs to test and build multiple projects and keeps the actual configuration of a job to build/test/deploy a project separate from the actual code being built/tested/deployed. This prevents users from applying their existing CI/CD best practices to the job configurations themselves.\n\nTo address this, Kohsuke is proposing that we :\n\nIntroduce a new subsystem in Jenkins that:\n\nlets you design a whole pipeline, not just a single linear set of tasks\n\nstores the said pipeline configuration as human-editable Jenkinsfile in your SCM\n\nmakes it automatic to set up new pipelines when Jenkinsfile is added\n\ndifferentiates multiple branches in the same repository\n\nThis is the key new feature that positions Jenkins for continuous delivery use cases and other more complex automations of today.\n\nKohsuke’s proposal is largely about bringing together a lot of already existing pieces together to provide a very compelling experience for new and existing users alike. I hope it is clear now why this proposal is so exciting to me.\n\nProviding Feedback\n\nWe’re asking you to read the proposal in\nJENKINS-31152, which itself have some additional tickets linked under it, and provide\nfeedback if you have it.\n\nIf you have ever logged in to the issue\ntracker or the\nwiki, you have a \"Jenkins user account\" which\nmeans you’ll be able to log into the issue tracker and vote for, or comment on\nthe issue linked above.\n\n( note : if you have forgotten your password, use the account\napp to reset it.)\n\nWe’re going to review feedback, make any necessary adjustments and either\napprove or reject the proposal two weeks from today.\n\nStay tuned for a couple more posts covering proposals to improve the Jenkins interface and user experience!","title":"Jenkins 2.0 Proposal: Pipeline as Code front and center","tags":["general","core","pipeline","workflow","feedback"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2015-09-30T00:00:00.000Z","id":"431cf8b3-f367-5fd0-b8fe-a612aca17838","slug":"/blog/2015/09/30/bay-area-jam/","strippedHtml":"+\nimage:https://jenkins-ci.org/sites/default/files/images/Screen%20Shot%202015-09-30%20at%202.15.54%20PM_0.png[image,width=320] +\n\n+\n+\n\nLast week, the first Jenkins Area Meetup (JAM) took place in San Jose, CA on Wednesday, Sept 23. What a way to kick off the first JAM other than to have Docker, John Willis as our guest speaker. John talked about immutable infrastructure and its benefits and role of containers.\n\n+\n+\n\nKohsuke discussed Jenkins Workflow, the motivation behind the same and latest features of Jenkins Workflow like multi branch support followed by docker use cases. The highlight of the meetup was definitely Kohsuke breaking the news about Jenkins 2.0 and his vision and motivation behind it.\n\n+\n+\n\nThe next Bay Area JAM is slated for Oct 21. Be sure to check HERE for the agenda. We’d love to have you join us if you’re in the area. If you’re interested in speaking, or become a food & bev, venue, or recording sponsor please send email to the organizer or events@lists.jenkins-ci.org.","title":"Bay Area JAM","tags":["general","cia","meetup","pipeline","workflow"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"blog/author/alyssat","twitter":null}]}}]}},"pageContext":{"tag":"pipeline","limit":8,"skip":80,"numPages":13,"currentPage":11}},
    "staticQueryHashes": ["3649515864"]}