{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/pipeline/page/4",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-05-16T00:00:00.000Z","id":"33bc69d0-dfa9-5c28-bfe5-208f3373b7f9","slug":"/blog/2018/05/16/pipelines-with-git-tags/","strippedHtml":"One common pattern for automated releases I have seen and used relies on Git\ntags as the catalyst for a release process. The immutable nature of releases\nand the immutable nature of tags can definitely go hand in hand, but up until\nfew months ago Jenkins Pipeline was not able to trigger effectively off of Git\ntags.\n\nIn this post I want to briefly share how to use tags to drive behaviors in\nJenkins Pipeline. Consider the following contrived Jenkinsfile, which\ncontains the three basic stages of Build, Test, and Deploy:\n\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make package'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'make check'\n            }\n        }\n        stage('Deploy') {\n            when { tag \"release-*\" }\n            steps {\n                echo 'Deploying only because this commit is tagged...'\n                sh 'make deploy'\n            }\n        }\n    }\n}\n\nOf particular note is the\nwhen\ncondition on the \"Deploy\" stage which is applying the tag criteria. This\nmeans the stage would only execute when the Pipeline has been triggered from a\ntag in Git matching the release-* Ant-style wildcard.\n\nIn practice, this means that all pull requests, and branch-based Pipeline Runs\nresult in the stage being skipped:\n\nWhen I push a release-1.0 tag, the Pipeline will then be triggerd and run the\n\"Deploy\" stage:\n\nOut of the box, Pipelines won’t trigger off of the presence of tags, which\nmeans that a Multibranch Pipeline must have a configuration update to know that\nit must Discover Tags.\n\nConfiguring\n\nFrom the configuration screen of a Multibranch Pipeline (or GitHub Organization\nFolder), Discovering tags can be enabled by adding the appropriate \"Behavior\"\nto the Branch Source configuration:\n\nWith these changes, the Jenkinsfile in the tagged versions of my source\nrepository can now drive distinct deployment behavior which is not otherwise\nenabled in the Pipeline.","title":"When using tags in Jenkins Pipeline","tags":["pipeline","git"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-05-08T00:00:00.000Z","id":"29ad061f-dba2-536d-91b4-878d290af36d","slug":"/blog/2018/05/08/jenkins-x-anchore/","strippedHtml":"Anchore provides docker image analysis for user defined acceptance policies to allow automated image validation and acceptance.\n\nAs developers we would like to know if a change we are proposing introduces a\nCommon Vulnerability and Exposure (CVE).\nAs operators we would like to know what running applications are affected if a new CVE is discovered.\n\nNow in Jenkins X pipelines, if we find an\nAnchore engine service running we will add the preview and release images to be analyzed.\nThis means we can look at any environment including previews (created from Pull Requests)\nto see if your application contains a CVE.\n\nUpgrade\n\nStart by checking your current Jenkins X version:\n\njx version\n\nIf your Jenkins X platform is older than 0.0.903, then first you will need to upgrade to at least 0.0.922:\n\njx upgrade cli\njx upgrade platform\n\nInstall addon\n\nYou can install the\nAnchore engine addon\nwhen you are in your Jenkins X team home environment.\n\njx env dev\njx create addon anchore\n\nThis will install the engine in a seperate anchore namespace\nand create a service link in the current team home environment\nso our pipeline builds can add docker images to Anchore for analysis.\n\nCreate an application\n\nYou can now create a new quickstart:\n\njx create quickstart\n\nList any CVEs\n\nOnce the build has run you will be able to check for CVEs in any environment incluing previews created for pull requests.\n\njx get cve --environment staging\n\nDemo\n\nHere’s a 4 minute video that demonstrates the steps above:\n\nUpgrading existing pipelines\n\nIf you have an existing application pipeline and and want enable image analysis you can update your Jenkinsfile,\nin the preview stage after the skaffold step add the line\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:$PREVIEW_VERSION\"\n\nIn the master stage the add this line after the skaffold step\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:\\$(cat VERSION)\"\n\nFor any questions please find us - we mainly hang out on Slack at\n#jenkins-x-dev - or see\njenkins-x.io/community for other channels.","title":"Jenkins X: Announcing CVE docker image analysis with Anchore","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"blog/author/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-04-16T00:00:00.000Z","id":"5bccde5f-c4ec-5989-8dc2-3f6097a019eb","slug":"/blog/2018/04/16/jenkins-x-explained-part1/","strippedHtml":"Jenkins X is an opinionated platform for providing CI / CD on top of\nKubernetes.\nWe’ve chosen a set of core applications that we install and wire together so things work out-of-the-box, providing a\nturn key experience. This blog aims to build on previous introductions to Jenkins X and provide a deeper\ninsight to what you get when you install Jenkins X.\n\nSo what happens? After downloading the jx CLI you will now be able to create clusters with public cloud providers\nor install onto an existing Kubernetes cluster.\n\nThis command will create a cluster on your cloud provider of choice.\n\njx create cluster\n\nAlternatively you can bring your own Kubernetes cluster and install Jenkins X on it:\n\njx install\n\nThat said, we’ve found that creating a new cluster on a public cloud such as GKE\nis a lot way easier to start as we can be sure of the state of the cluster.\nFor example we know that storage, networking and loadbalancers will be working as expected.\nCreating a cluster on GKE takes only a few minutes so it’s a great way to try things out as well as run your\nenterprise workloads.\n\nFor now lets assume we are using GKE. When jx create cluster has finished you will see some output in the\nterminal that also includes the default admin password to use when logging into the core applications below.\nThere is a flag --default-admin-password you can use to set this password yourself.\n\nAccessing applications\n\nWe automatically install an Nginx ingress controller running with an external loadbalancer pointing at it’s\nKubernetes service. We also generate all the Kubernetes Ingress rules using a golang library called\n\" exposecontroller\".\nThis runs as a Kubernetes Job triggered by a\nHelm hook once any application is installed to the cluster.\n\nUsing \"exposecontroller\" means we can control all the ingress rules for an environment using a single set of\nconfigurations, rather than each application needing to know how to expose the kubernetes service to the outside world.\nThis also means we can easily switch between HTTP and HTTPS plus support intregration with projects like\ncert-manager for auto generation of signed TLS certificates.\n\nEnvironments\n\nOne important point to make is Jenkins X aims to use terminology that developers are familiar with. That’s not\nto say we are changing Kubernetes fundamentals, it’s more that if you don’t know Kubernetes concepts then we aim\nto help you still adopt the cloud technology and pull back the curtain as you gain confidence and experience.\nTo that point, a core part of Jenkins X are \"environments\". An environment can have one or more applications running\nin it. In Kubernetes term an \"environment\" maps to the concept of a \"namespace\" in code.\n\nThe installation by default created three environments, this is customisable but by default we have a \"dev\", a \"staging\"\nand a \"production environment\". To list, select, or switch between these environments run:\n\njx env\n\nJenkins X core applications\n\nIn the \"dev\" environment we have installed a number of core applications we believe are required at a minimum\nto start folks off with CI/CD on Kubernetes. We can easily add to these core apps using Jenkins X addons but\nfor now lets focus on the core apps. Jenkins X comes with configuration that wires these services together,\nmeaning everything works together straight away. This dramatically reduces the time to get started with Kubernetes\nas all the passwords, environment variables and config files are all setup up to work with each other.\n\nJenkins — provides both CI and CD automation. There is an effort to decompose Jenkins over time to\nbecome more cloud native and make use of Kubernetes concepts around CRDs, storage and scaling for example.\n\nNexus — acts as a dependency cache for Nodejs and Java applications to dramatically improve build\ntimes. After an initial build of a SpringBoot application the build time is reduced from 12 mins to 4. We\nhave not yet but intend to demonstrate swapping this with Artifactory soon.\n\nDocker Registry — an in cluster docker registry where our pipelines push application images, we will\nsoon switch to using native cloud provider registries such as Google Container Registry, Azure Container\nRegistry or Amazon Elastic Container Registry (ECR) for example.\n\nChartmuseum — a registry for publishing Helm charts\n\nMonocular — a UI used for discovering and running Helm charts\n\nHelm\n\nWe learned a lot in our early days with fabric8 on Kubernetes and there were some projects from the ecosystem\nthat either weren’t around or (at the time) didn’t work with OpenShift, therefore we were restricted when\nmaking some design decisions. A couple of years on and now with Jenkins X we were able to look at other OSS\nprojects that have been flourishing, so I was very happy to start looking at Helm.\nHelm is a package manager for Kubernetes and allows easy installation and upgrades of applications.\n\nIt was pretty clear that for Jenkins to evolve and include deployments to the cloud we should embrace Helm\nand provide an opinionated experience that helps teams and developers. The core applications mentioned above\nmeans Jenkins X provides an out of the box integrated CI/CD solution for Helm.\n\nWe know that helm has limitations but with the work on\nHelm 3, the focus of the Kubernetes\nsig-apps group, the Kubernetes community and investment we see from key organisations such as Microsoft, we feel Helm\nis currently the best way to install and upgrade applications on Kubernetes.\n\nGitOps\n\nWe mentioned earlier that we setup three environments by default. What this means is for the staging and production\nenvironments we created:\n\nKubernetes namespace\n\nAn environment resource ( CustomResourceDefinition)\nin the dev environment which includes details of how applications are promoted to it and includes various team\nsettings.\n\nA git repository that we store what applications and their versions should be present in that environment.\nThese are stored in a Helm requirements.yaml file\n\nA Jenkins Pipeline job: explained in more detail below\n\nCI/CD for Environments\n\nHaving a Jenkins Pipeline Job for each environment means that Pull Requests to the git repo trigger a CI\njob.  For now that job performs basic validation but in the future will include ‘gates’ to ensure a change to that\nenvironment has passed expected checks such as QA tasks, gain enough approvals from the correct people, etc -\nYES CI for environments!\n\nOnce CI checks have passed the new application or version change can be merged. Only users that have karma\ncan merge the Pull Request and therefore we get RBAC plus traceability for our environment deployments.\n\nThis means every application manifest, their version and configuration including storage requirements, resource\nneeds and secrets for your environments are stored in Git repositories. Given a disaster recovery scenario this\nis exactly what you want.\n\nDid I just say secrets in Git? Yes! We will be providing a nicer experience to helps folks get set up but we\nourselves encrypt our secrets and  store them in Git, then decrypt them when we come to install and upgrade.\n\nHere’s our Git repo https://github.com/jenkins-x/cloud-environments/blob/a1edcc6/env-jx-infra/secrets.yaml.\n\nWe do all this with the help of a Helm wrapper called helm secrets.\nI’m working on a followup blog post with examples, better explanations and how to guides + add better integration\nwith JX in the coming weeks.\n\nFancy getting involved?\n\nWe mainly hangout in the jenkins-x Kubernetes slack channels and for tips on\nbeing more involved with Jenkins X take a look at our contributing docs\n\nIf you’ve not already seen it here’s a video showing the create cluster explained in this blog.","title":"Jenkins X Explained Part 1 - an integrated CI/CD solution for Kubernetes","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"blog/author/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-04-13T00:00:00.000Z","id":"31f8965a-bc62-54ab-a155-4d858e063b0e","slug":"/blog/2018/04/13/jenkins-x-23-days-later/","strippedHtml":"Its been 24 days since we\nannounced Jenkins X,\na CI/CD solution for modern cloud applications on Kubernetes.\nI’m truly blown away by the response and feedback from the community - thank you!\n\nWe’ve also had lots of folks report they’ve successfully used Jenkins X\non a number of clouds including GKE, AWS and AKS along with on-premises clusters which is great to hear!\n\nHere’s a brief overview of the changes in the last 24 days from the\nRoadmap :\n\nwe now fully support GitHub and GitHub enterprise. BitBucket cloud and gitea is almost there too.\nHopefully BitBucketServer and Gitlab are not too far away either. For more detail see\nsupporting different git servers\n\nFor issue tracking we support GitHub, GitHub Enterprise and JIRA. For more detail see\nsupporting issue trackers\n\nGradle support is now available from jx create spring\nor by importing gradle apps\n\nGo, Node and Rust build packs are now available with more planned\n\nNew addons for anchore and kubeless\n\nAlso we’ve made it a little bit easier to keep your jx binary up to date continuously. Just type one of the following:\n\njx version will prompt you if there is a new version available\nand if prompted, it will upgrade itself\n\njx upgrade cli will upgrade the jx binary if its available or\njx upgrade platform for the platform\n\nFor more detail on the changes over the last 24 days with metrics please see the\nchangelog generated by Jenkins X\n\nWe’d love to hear your feedback what you think of\nJenkins X and the\nRoadmap - please\njoin the community.\n\nLinks\n\nJenkins X website\n\nDemos\n\nJenkins X JEP proposal","title":"Jenkins X making awesome progress after 24 days","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"jstrachan","html":"<div class=\"paragraph\">\n<p>James is a long time open source contributor, created the Groovy programming language and Apache Camel integration framework.\nFor the past few years he&#8217;s been working on CI/CD with Kubernetes.</p>\n</div>","id":"jstrachan","irc":null,"linkedin":null,"name":"James Strachan","slug":"blog/author/jstrachan","twitter":"jstrachan"}]}},{"node":{"date":"2018-04-10T00:00:00.000Z","id":"de012828-154d-5d83-8b81-e1199eaa8685","slug":"/blog/2018/04/10/opinionated-cd-jenkins-x/","strippedHtml":"I\nrecently wrote\nabout how all the cloud platforms are all in Kubernetes and so are developers.\nIt is an exciting time, but the problem for many is that this is\na huge blank sheet of paper for how to build and deploy applications.\nA white space, a void, a limitless canvas of possibilities.\nInsert metaphors here.\n\nThe problem, as you may guess, is that few people really like or are able to start with a blank canvas.\nI know I prefer to start with something working and iterate towards a solution,\nor be given some rails to stay on (again with the metaphors).\n\nThat’s where the Jenkins X project comes in.\nJenkins X is a Kubernetes-native continuous integration and continuous delivery platform\nfor developing cloud native applications that was recently introduced as a\nJenkins Enhancement Proposal,\nsponsored by James Strachan.\n\nThere is a lot to take in but at it’s heart,\nthis is an open source opinionated way to do continuous delivery with Kubernetes,\nnatively, without necessarily having to learn all the things I talked about in my last blog post.\nI shall attempt to explain what this is all about and why it matters to developers.\nAs someone said on the jenkins-dev mailing list\n“We have the two glued together with baling wire and twine” -\nJenkins X aims to simplify how to work with continuous delivery and Kubernetes.\n\nFirst and most importantly, let’s see the logo:\n\nYou can see the nautical theme leaking through (and Kubernetes).\nWhilst it is called Jenkins X, it is about quite a lot more than Jenkins.\n\nJenkins X makes decisions for you\n\nJenkins X presents itself to you initially as a handy sleek command line\n(a native binary you can install called jx - the debate is on as to how pronounce it).\nLet’s take a tour (sail?):\n\njx import my-app\n\nIf you have an existing project, this will detect what type of project it is, build a pipeline for you (and a bunch of Kubernetes things, like Helm Charts), add it to your project and set it up in GitHub, WebHooks and all, build the project (run the pipeline) and deploy a version to a “staging” environment.\n\nIf it looks ok, you can promote it to production:\n\njx promote --env production --version 1.0.1 my-app\n\nIf something went wrong in production, you can roll back an app to any version (the version numbers are made for you):\n\njx promote --env production --version 1.0.0 my-app\n> jx get apps # list versions\n\nAn environment is a well-established concept for web developers using\ncontinuous delivery: out of the box Jenkins X makes three of them for you\n(dev, staging and production), but you can make as many as you like.\nEnvironments have rules around how things are promoted into them\n(and they also have their own extensible pipelines,\nbut you can just use them as-is to start).\n\nYou can also create a Spring Boot microservice app:\n\njx create spring\n\nAnswer a few questions and it will set everything up for you.\n\nAny changes you make to your app automatically are built,\nand if the build looks good, they go through to the staging environment.\nWebHooks are setup for you (if you are using GitHub) to smooth this over.\n\nFor those looking at starting from pre-made apps, there are \"quickstarts\":\n\njx create quickstart\n\nThey are based on a growing set of starter apps, in a variety of languages and tech stacks.\n\nReview apps for your changes: Each pull request is built/tested,\nand a “review app” is made available in a temporary environment.\nThat means each proposed change, before it goes to the default branch (master),\nhas an environment made (temporary) that it can be tried out in.\nIn GitHub, this shows up as a comment in the pull request:\n\nProject type detection\n\nAs you can see, so far there is no editing or manual creation of pipelines,\nor scripting or setup, just importing or creating your app and go.\nThis is powered by\nDraft “packs”\n(a handy project that came out of Azure).\n What you end up with is a Jenkinsfile in your project repository.\n You may want to edit it one day, or you may be happy with it as is!\n Jenkins is famous for being un-opinionated in what you do,\n but Jenkins X has strong opinions (but you can extend and customise).\n\nimage::/images/jenkins-x/draft-logo.png[Draft Logo, width=300]\n\nDeploying or promoting to environments\n\nDeploying happens via pipelines behind the scenes -\nwhen a change is pushed, or a version promoted.\nYou don’t need to directly interact with Kubernetes if you don’t need to.\nA tool called Helm does the heavy lifting:\nHelm is used to package and perform installations and upgrade for your apps.\n\nThere is a little more magic going on here with environments, which you don’t see at first.\nEach environment, for a team, is represented by a Git repository behind the scenes.\nConfiguration as code is a well-established best practice these days,\nso why not use it to track deployments and initiate deployments.\nI also mentioned in my previous post how declarative Kubernetes is:\nit is perfect for keeping all config in a repository, of the desired system state.\n\nEach promotion is actually a pull request to a per-environment repository.\nThis repository is made and managed for you (and kept outside of the\nmain application code repository), you don’t have to look at it,\nbut you can extend things there should you need to.\nSpecific environment repositories may have different access rules,\nor be controlled by a different team (perhaps even deploy to a different cluster).\nSome have coined the term for this as “GitOps.”\nI first came across this concept on a\nWeaveWorks blog.\n\nI’ll try and explain this one with a diagram:\n\nThe pipeline is actually split in the middle.\nOn the left is the more familiar continuous integration pipeline.\nThis works on pull requests, pre-release version of things\nand is all about testing(automated and manual review).\nThe source of truth for this is the configuration in the\napplications repository: branches, pull requests and so on.\n\nThe right-hand side is the continuous delivery pipeline.\nThis kicks in when the application is ready to be updated with a new release.\nThis is the “GitOps” repo behind the scenes that controls the state of things in Kubernetes.\nA promotion on this side is a pull request, and then a merge,\nfrom the staging repository to the production repository.\n\nInstalling Jenkins X\n\nThe jx command line has a jx install command that installs it into a Kubernetes cluster.\n\nThe best experience initially is using Google’s excellent GKE service:\n\njx create cluster gke\n\nThis will ask a few questions, and go and set it all up for you in a\ncluster set aside for Jenkins X (recommended).\nJenkins X runs entirely as services on top of a Kubernetes cluster.\n\njx install\n\nIs designed to work with a Kubernetes cluster (if it already exists,\nrecommendation is to have a cluster put aside for Jenkins X if possible).\nAmazon EKS support is coming (mostly it is around testing),\nthat service is in beta/early access so it is still a work in progress,\nas is Microsoft Azures excellent AKS service.\n\nSo where is Jenkins?\n\nGood question, thanks for asking. Well, it is behind the scenes.\nAs you have seen, there was no direct interaction with Jenkins,\nbut it is there, running the pipelines for continuous integration and\ncontinuous delivery of the respective repositories, and orchestrating things with Kubernetes.\n\nIf you run jx get pipelines you can see URLs to the various pipelines\nthat have been setup for you are part of interacting with Jenkins X.\n\nBy the way,\nJames Strachan has written an extensive blog on jenkins.io\nthat really explores the Jenkins X project in-depth.\nOnce you finish reading this blog, take a stroll on over there and read James'.\nHe also provides several ways you can get involved in the project.\n\nWhat else can I do with the command line?\n\nLots, the jx command line has built in help:\n\njx open\n\nopen apps, services or pipelines in your browser\n\njx activity\n\nexplains how things got to where they are, a history\n\njx get environments\n\nlist environments\n\njx get apps\n\nshow the state of applications, what versions are in what environments.\n\nWhat’s next\n\nThere is a whole lot more to this, and lots more moving parts and services\nthat are set up for you that are very useful, but it is best to head over\nto jenkins-x.io and have a look.\n\nThis project is obviously in early stages (it is stll a Draft JEP after all) and there is lots happening.\nCheck out the Jenkins X community\nif you want to chat on slack, IRC, issues or email.\nAlso, read the\nJenkins Enhancement Proposal doc.","title":"Opinionated Kubernetes and Jenkins X","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"blog/author/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2018-04-09T00:00:00.000Z","id":"3494cf73-5468-5673-9163-ca20378f0110","slug":"/blog/2018/04/09/whats-in-declarative/","strippedHtml":"Last week we released the latest version of Declarative Pipelines, version\n1.2.8. With that out, we thought now would be a good time to introduce you to\nthe new features and options that have been added to Declarative since the\nbeginning of 2018. These are all available now in the Update Center, with\nversion 1.2.8.\n\nDeclarative Directive Generator\n\nThis is something we’re really happy about - if you go to the \"Pipeline Syntax\"\nlink from your Pipeline’s page in Jenkins, you’ll see a couple new links on the\nleft, including \"Declarative Directive Generator\". The Directive Generator is\nmuch like the Snippet Generator that’s been in Pipeline for a couple years now,\nbut where the Snippet Generator is just for filling out a form for a step and\ngenerating the Pipeline code that configuration maps to, the Directive\nGenerator is built to help you write your Declarative Pipeline directives, like\nagent, options, stage, and more!\n\nThis is the first release to include the Directive Generator, and it’s\ndefinitely going to see more polish going forward, but we think it should be\nquite helpful for you already. We’ll be putting up another blog post looking at\nthe Directive Generator in more detail in the near future.\n\nNew when conditions\n\nWe’ve added a number of new when conditions, providing you more control over\nwhether your stages get executed.\n\nequals - Compares two values - strings, variables, numbers, booleans - and\nreturns true if they’re equal. I’m honestly not sure how we missed adding\nthis earlier! You can do \"not equals\" comparisons using the not { equals …​\n} combination too.\n\nchangeRequest - In its simplest form, this will return true if this\nPipeline is building a change request, such as a GitHub pull request. You can\nalso do more detailed checks against the change request, allowing you to ask\n\"is this a change request against the master branch?\" and much more.\n\nbuildingTag - A simple condition that just checks if the Pipeline is\nrunning against a tag in SCM, rather than a branch or a specific commit\nreference.\n\ntag - A more detailed equivalent of buildingTag, allowing you to check\nagainst the tag name itself.\n\nIn addition, we’ve added a new option to when : beforeAgent. This allows you\nto specify that the when conditions should be evaluated before entering the\nagent for the stage, rather than the normal behavior of evaluating when\nconditions after entering the agent. When beforeAgent true is specified,\nyou will not have access to the agent’s workspace, but you can avoid\nunnecessary SCM checkouts and waiting for a valid `agent to be available. This\ncan speed up your Pipeline’s execution in some cases.\n\nNew post conditions\n\nThe changed condition has always been a bit confusing, and to be\nhonest, it wasn’t our best work. changed will fire any time the current run’s\nstatus is different than the previous run’s status - whether the current run is\nhealthier than the previous one, or the other way around. That’s…​not actually\nvery useful. So now we’ve added two new post conditions that should provide\nyou with a lot more value than changed has.\n\nfixed - This will check to see if the current run is successful, and if the\nprevious run was either failed or unstable.\n\nregression - This will check to see if the current run’s status is worse\nthan the previous run’s status. So if the previous run was successful, and\nthe current run is unstable, this will fire and its block of steps will\nexecute. It will also run if the previous run was unstable, and the current\nrun is a failure, etc.\n\nNew options\n\nThe options directive in Declarative can contain a number of different kinds\nof configuration: traditional Jenkins job properties, like buildDiscarder,\nwrapper steps to execute the entire Pipeline within, like timeout, and\nDeclarative-specific options that can switch from some default behaviors of\nDeclarative execution. We’ve added two new Declarative-specific options in the\nlast few releases.\n\ncheckoutToSubdirectory - Allows you to override the location that the\nautomatic SCM checkout will use. Using checkoutToSubdirectory(\"foo\"), your\nPipeline will checkout your repository to\"$WORKSPACE/foo\", rather than the\ndefault of\"$WORKSPACE\".\n\nnewContainerPerStage - If you’re using a top-level docker or dockerfile\nagent, and want to ensure that each of your stages run in a fresh container\nof the same image, you can use this option. Any stage without its own\nagent specified will run in a new container using the image you’ve\nspecified or built, on the same computer and with access to the same\nworkspace.\n\nStage options\n\nSometimes, you may only want to disable automatic checkout of your repository,\nusing the skipDefaultCheckout(true) option, for one specific stage in your\nPipeline. Or perhaps you want to have a timeout that covers an entire\nstage, including time spent waiting for a valid agent, post condition\nexecution, or the new input directive for stages (see further down for more\ndetails on that!). To make those things possible, we’ve added a new options\ndirection to stage. You can use a subset of the top-level options content\nin a stage’s `options - wrapper steps, and Declarative-specific options that\nare marked as legal in a stage.\n\nInput\n\nYou’ve always been able to run the input step inside a stage’s `steps\nblock, but we’ve found that approach can lose out on some of the value that the\ninput step provides.\n\nTo help with that, we’ve added a new input directive\nto stage, with the same parameters as the input step. When you use the\nstage input directive rather than using the step directly, any parameters\nyou’ve specified for the input will be made available in the stage’s\nenvironment, meaning you can reference parameters from the `input in when\nconditions, or in environment variables.\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Example') {\n            input {\n                message \"Should we continue?\"\n                ok \"Yes, we should.\"\n                submitter \"alice,bob\"\n                parameters {\n                    string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n                }\n            }\n            agent any\n            steps {\n                echo \"Hello, ${PERSON}, nice to meet you.\"\n            }\n        }\n    }\n}\n// Script //\n\nAlso, the input directive is evaluated before you enter any agent specified\non this stage, so if you are using a top-level agent none and each stage\nhas its own agent specified, you can avoid consuming an executor while\nwaiting for the input to be submitted.\n\nLastly, you can use timeout in the stage options, as\nmentioned above, to time-out the input if too much time has passed without a\nresponse.\n\nI hope you find these new features and options for Declarative Pipelines\nhelpful, and I look forward to the rest of 2018 as we continue to invest and\nimprove in Jenkins Pipeline!","title":"The new things arriving in Declarative Pipeline!","tags":["pipeline","declarative"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"blog/author/abayer","twitter":"abayer"}]}},{"node":{"date":"2018-03-19T00:00:00.000Z","id":"13be0610-c1c9-59de-ab77-d3fdaf0d1add","slug":"/blog/2018/03/19/introducing-jenkins-x/","strippedHtml":"We are excited to share and invite the community to join us on a project we’ve been thinking about over the last few months called Jenkins X which extends the Jenkins ecosystem to solve the problem of automating CI/CD in the cloud.\n\nBackground\n\nThe last few years have seen massive changes in the software industry:\n\nuse of immutable container images for distributing software which are smaller, easier to work with and lead to cheaper infrastructure costs than VMs alone (approx 20% less on average)\n\nKubernetes has become the defacto way of installing, upgrading, operating and managing containers at scale on any public or hybrid cloud\n\n2018 is the year all the major public clouds, operating system vendors and PaaS offerings support Kubernetes natively\n\nwe now have an open source industry standard for distributing, installing and managing applications on any cloud!\n\nincreased adoption of microservices and cloud native applications leading to massive increase in the number of components which require CI/CD along with increased release frequency\n\nimprovements in DevOps practices coming from the community such as the State of DevOps Report which show the approach of high performing teams\n\nincreasingly many businesses now realise that to compete you have to deliver value quickly via software\n\nteams need to become high performing if the business is to succeed\n\nAll of this adds up to an increased demand for teams to have a solution for cloud native CI/CD with lots of automation!\n\nIntroducing Jenkins X\n\nJenkins X is a project which rethinks how developers should interact with CI/CD in the cloud with a focus on making development teams productive through automation, tooling and DevOps best practices.\n\nJenkins X is open source and we invite you to give us feedback and to contribute to the project.\n\nWhats the big deal?\n\nFor many years Jenkins has been capable of doing pretty much anything in the CI/CD space; the challenge has always been figuring out how to get the right plugins, configuration and code to work together in your Jenkinsfile.\n\nFor me the big deal about Jenkins X is as a developer you can type one command jx create or jx import and get your source code, git repository and application created, automatically built and deployed to Kubernetes on each Pull Request or git push with full CI/CD complete with Environments and Promotion via GitOps!\n\nDevelopers and teams don’t have to spend time figuring out how to package software as docker images, create the Kubernetes YAML to run their application on kubernetes, create Preview environments or even learn how to implement CI/CD pipelines with declarative pipeline-as-code Jenkinsfiles. It’s all automated for you out of the box! So you can focus instead on delivering value!\n\nAt the same time, Jenkins X doesn’t hide anything. If you do want to hack the Dockerfile, Jenkinsfile or Helm charts for your apps or their environments then go right ahead - those are all available versioned in git with the rest of your source code with full CI/CD on it all. GitOps FTW!\n\nJenkins X automates CI/CD and DevOps best practices for you - so you can become a faster performing team! Let your butler do more work for you!\n\nDemo\n\nHere’s a demonstration of Jenkins X running on GKE:\n\nYou can check out more demos here.\n\nJenkins X Features\n\nNow lets walk through the features of Jenkins X that we showed in the demo:\n\nAutomated CI/CD Pipelines\n\nCreate new Spring Boot projects, new quickstarts or import existing source code quickly into Jenkins X via the jx command line tool and:\n\nget a Pipeline automatically setup for you that implements best practice CI/CD features:\n\ncreates a Jenkinsfile for defining the CI/CD pipelines through declarative pipeline-as-code\n\ncreates a Dockerfile for packaging the application up as an immutable container image (for applications which generate images)\n\ncreates a Helm chart for deploying and running your application on Kubernetes\n\nensures your code is in a git repository (e.g. GitHub) with the necessary webhooks to trigger the Jenkins CI/CD pipelines on push events\n\ntriggers the first release pipeline to promote your application to your teams Staging Environment\n\nThen on each Pull Request:\n\na CI pipeline is triggered to build your application and run all the tests ensuring you keep the master branch in a ready to release state\n\nyour Pull Request is deployed to a Preview Environment (more on this later)\n\nWhen a Pull Request is merged to the master branch the Release pipeline is triggered to create a new release:\n\na new semantic version number is generated\n\nthe source code is modified for the new version (e.g. pom.xml files get their elements modified) and then tagged in git\n\nnew versioned artifacts are published including:\n\ndocker image, helm chart and any language specific artifacts (e.g. pom.xml and jar files for Java, npm packages for node or binaries for go etc)\n\nthe new version is promoted to Environments (more on this later)\n\nEnvironment Promotion via GitOps\n\nIn Jenkins X each team gets their own environments. The default environments are Staging and Production but teams can create as many environments as they wish and call them whatever they prefer.\n\nAn Environment is a place to deploy code and each Environment maps to a separate namespace in Kubernetes so they are isolated from each other and can be managed independently.\n\nWe use something called GitOps to manage environments and perform promotion. This means that:\n\nEach environment gets its own git repository to store all the environment specific configuration together with a list of all the applications and their version and configuration.\n\nPromotion of new versions of applications to an environment results in:\n\na Pull Request is created for the configuration change that triggers the CI pipeline tests on the Environment along with code review and approval\n\nonce the Pull Request is merged the release pipeline for the environment which updates the applications running in that environment by applying the helm chart metadata from the git repository.\n\nEnvironments can be configured to either promote automatically as part of a release pipeline or they can use manual promotion.\n\nThe defaults today are for the Staging environment to use automatic promotion; so all merges to master are automatically promoted to Staging. Then the Production environment is configured to use manual promotion; so you choose when do promote.\n\nHowever it is easy to change the  configuration of how many environments you need and how they are configured via the jx create environment and jx edit environment commands\n\nPreview Environments\n\nJenkins X lets you create Preview Environments for Pull Requests. Typically this happens automatically in the Pull Request Pipelines when a Pull Request is submitted but you can also perform this manually yourself via the jx preview command.\n\nThe following happens when a Preview Environment is created:\n\na new Environment of kind Preview is created along with a kubernetes namespace which show up the jx get environments command along with the jx environment and jx namespace commands so you can see which preview environments are active and switch into them to look around\n\nthe Pull Request is built as a preview docker image and chart and deployed into the preview environment\n\na comment is added to the Pull Request to let your team know the preview application is ready for testing with a link to open the application. So in one click your team members can try out the preview!\n\nThis is particularly useful if you are working on a web application or REST endpoint; it lets your team interact with the running Pull Request to help folks approve changes.\n\nFeedback\n\nIf the commit comments reference issues (e.g. via the text fixes #123) then Jenkins X pipelines will generate release notes like those of the jx releases.\n\nAlso, as the version associated with those new commits is promoted to Staging or Production, you will get automated comments on each fixed issue that the issue is now available for review in the corresponding environment along with a link to the release notes and a link to the app running in that environment. e.g.\n\nGetting started\n\nHopefully you now want to give Jenkins X a try. One of the great features of Jenkins is that it’s super easy to get started: install Java, download a war and run via java -jar jenkins.war.\n\nWith Jenkins X we’ve tried to follow a similarly simple experience. One complication is that Jenkins X has more moving pieces than a single JVM; it also needs a Kubernetes cluster :)\n\nFirst you need to download and install the jx command line tool so its on your PATH.\n\nThen you need to run a single command to create a new Kubernetes cluster and install Jenkins X (in this example, on GKE).\n\njx create cluster gke\n\nToday we support creating Kubernetes clusters and installing Jenkins X on Amazon (AWS), Google (GKE), Microsoft Azure, and even locally using minikube.\nWe plan to support AWS EKS soon.\n\nAt the time of this writing the easiest cloud to get started with is Google’s GKE so we recommend you start there unless you already use AWS or Azure. Amazon and Microsoft are working hard to make Kubernetes clusters as easy to create and manage as they are on GKE.\n\nAll the public clouds have a free tier so you should be able to spin up a Kubernetes cluster and install Jenkins X for a few hours then tear it down and it should be cheaper than a cup of coffee (probably free!). Just remember to tear down the cluster when you are done!\n\nHere’s a demo of creating a kuberentes cluster and installing Jenkins X :\n\nIf you really don’t want to use the public cloud, you can install Jenkins X on an existing kubernetes cluster (if it has RBAC enabled!). Or, if you can install and run minikube, then you should be able to install Jenkins X on it as well.\n\nRelationship between Jenkins and Jenkins X\n\nJenkins is the core CI/CD engine within Jenkins X. So Jenkins X is built on the massive shoulders of Jenkins and its awesome community.\n\nWe are proposing Jenkins X as a sub project within the Jenkins foundation as Jenkins X has a different focus: automating CI/CD for the cloud using Jenkins plus other open source tools like Kubernetes, Helm, Git, Nexus/Artifactory etc.\n\nOver time we are hoping Jenkins X can help drive some changes in Jenkins itself to become more cloud native, which will benefit the wider Jenkins community in addition to Jenkins X.\n\nPlease join us!\n\nSo I hope the above has given you a feel for the vision of where we are heading with Jenkins X and to show where we are today. The project is still very young, we have lots to do and we are looking for more input on where to go next and what to focus on. We’re also working on high level roadmap.\n\nTo make Jenkins X a success we’d love you to get involved, try it out and give us feedback in the community! We love contributions whether its email, chat, issues or even better Pull Requests ;).\n\nIf you’re thinking of contributing here’s some ideas:\n\nGive us feedback. What could we improve? Anything you don’t like or you think is missing?\n\nHelp improve the documentation so its more clear how to get started and use Jenkins X\n\nAdd your own quickstarts so the Jenkins X community can easily bootstrap new projects using your quickstart. If you work on an open source project is there a good quickstart we could add to Jenkins X?\n\nIf you’d like to contribute to the code then try browse the current issues.\n\nwe have marked issues help wanted or good first issue to save you hunting around too much\n\nin particular we would love help on getting Jenkins X working well on windows or the integrations with cloud services, git providers and issues trackers\n\nfor more long term goals we’ve the roadmap\n\nwe could always use more test cases and to improve test coverage!\n\nTo help get faster feedback we are using Jenkins X as the CI/CD platform to develop Jenkins X itself. For example Jenkins X creates all the releases and release notes. We’ll talk more about UpdateBot in a future blog post but you can see all the automated pull requests generated in the various Jenkins X pipelines via UpdateBot pushing version changes from upstream dependencies into downstream repositories.\n\nNote that the Jenkins community tends to use IRC for chat and the Kubernetes community uses Slack, so Jenkins X has rooms for both IRC and slack depending on which chat technology you prefer - as the Jenkins X community will be working closely with both the Jenkins community and the various Kubernetes communities (Kubernetes, Helm, Skaffold, Istio et al).\n\nOne of the most rewarding things about open source is being able to learn from others in the community. So I’m hoping that even if you are not yet ready to use Kubernetes in your day job or are not yet interested in automating your Continuous Delivery - that you’ll at least consider taking a look at Jenkins X, if for no other reason than to help you learn more about all these new ideas, technologies and approaches!\n\nThanks for listening and I’m looking forward to seeing you in the community.\n\nLinks\n\nJenkins X JEP proposal\n\nJenkins X website\n\nGetting Started Guide\n\nDemos","title":"Introducing Jenkins X: a CI/CD solution for modern cloud applications on Kubernetes","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"jstrachan","html":"<div class=\"paragraph\">\n<p>James is a long time open source contributor, created the Groovy programming language and Apache Camel integration framework.\nFor the past few years he&#8217;s been working on CI/CD with Kubernetes.</p>\n</div>","id":"jstrachan","irc":null,"linkedin":null,"name":"James Strachan","slug":"blog/author/jstrachan","twitter":"jstrachan"}]}},{"node":{"date":"2018-02-22T00:00:00.000Z","id":"d0c104fc-7582-5b71-ae72-ad7781b4796d","slug":"/blog/2018/02/22/cheetah/","strippedHtml":"Table of Contents\n\nIntroducing \"Project Cheetah\"\nYes, but what does it DO?\nHow Do I Set Speed/Durability Settings?\n\n1. Globally, you can choose a global default durability setting:\n2. Each Pipeline can get a custom Durability Setting:\n3. Multibranch Projects can use a new BranchProperty to customize the Durability Setting.\n\nWill Performance-Optimized Mode Help Me?\nOther Goodies\nHow Did You Do It?\nWhat Next?\n\nSince it launched, Pipeline has had a bit of a Dr. Jekyll and Mr. Hyde performance problem.  In certain circumstances, Pipeline can turn from a mild-mannered CI/CD assistant into a monster.  It will happily eat storage read/write capacity like popcorn without caring about the other concerns of our friendly butler.  When combined with other additional factors, this can result in real-world stability problems.  For example, combining slow storage with a spike in running Pipelines has brought down production Jenkins at more than one organization.  Similarly, users see issues if a busy controller gets hit with an extra source of stress; past culprits have been heavy automated (ab)use of Jenkins APIs, now-solved user lookup bugs, backup jobs, and plugins run crazy that load excessive numbers of builds.  Symptoms ranged from visible slowdowns in the UI to unresponsive jobs and \"hung\" controllers.\n\nNow I’m not saying this to scare people or to criticize the technology we’ve built. Implementing Pipeline scalability best practices coupled with SSD storage keeps Jenkins in a happy place.  We just need context on the weaknesses to see why it’s important to address them.\n\nIntroducing \"Project Cheetah\"\n\nToday we’re announcing the first major results of \"Project Cheetah\", our long-running effort to address these challenges and improve Pipeline scalability.  More broadly, Cheetah aims to help in 3 places:\n\nSmall-scale containers: Pipeline needs to run leanly in resource-constrained containers, to enable easy scale-out without consuming excessive resources on shared container hosts.\n\nEnterprise systems: Pipeline needs to effectively serve high-scale Jenkins instances that are central to many large companies.\n\nGeneral case: run Pipelines a bit more quickly on average, and allow users to get much-stronger performance in worst-case scenarios.\n\nThese changes are implemented across many of the Pipeline plugins.\n\nYes, but what does it DO?\n\nProject Cheetah offers several things, but the most important is Durability Settings for all Pipelines, and especially the Performance-Optimized setting.  This setting avoids several potentially unexpected performance \"surprises\" that may strike users.  In the general case, it greatly reduces the disk IO needs for Pipeline.  How much?  Below is a graph of storage utilization with legacy Pipeline versions (think early 2017) and with the latest version using the Performance-Optimized mode.  These are tested on an AWS instance backed by an EBS volume provisioned with 300 IOPs.\n\nBefore and After:\n\nAs you can see, storage utilization goes down by a lot.  While the exact number will vary, across the benchmark testcases this results in Pipeline throughput of 2x to 6x the previous before becoming IO-bound. This also increases stability of Jenkins controllers because they will tolerate unexpected load.\n\nThis comes with a major drop in CPU IOWait as well:\n\nAnd of course the rate at which data is written to disk and number of writes/s is also reduced:\n\nFor enterprise users, timing stats often show 10-20% of normal builds is serializing the Program and writing the record of steps run (\"FlowNodes\") - the performance optimized durability setting will cut this to almost nothing (for standard pipelines, 1/100 or less) - so builds will complete faster, especially complex ones.\n\nPlease see the Pipeline Scalability documentation for deeper information on the new Durability Settings, how to use them, and which plugin versions are required to gain these features.\n\nAlso, users may see a reduction in hung Pipelines because new test utilities made it possible to identify and correct a variety of bugs.\n\nHow Do I Set Speed/Durability Settings?\n\nThere are 3 ways to configure the durability setting:\n\n1. Globally, you can choose a global default durability setting:\n\nUnder \"Manage Jenkins\" > \"Configure System\", labelled \"Pipeline Speed/Durability Settings\".  You can override these with the more specific settings below.\n\n2. Each Pipeline can get a custom Durability Setting:\n\nThis is one of the job properties located at the top of the job configuration, labelled \"Custom Pipeline Speed/Durability Level.\" This overrides the global setting. Or, use a \"properties\" step - the setting will apply to the NEXT run after the step is executed (same result).\n\n// Script //\nproperties([durabilityHint('PERFORMANCE_OPTIMIZED')])\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n    options {\n        durabilityHint('PERFORMANCE_OPTIMIZED')\n    }\n}\n\n3. Multibranch Projects can use a new BranchProperty to customize the Durability Setting.\n\nUnder the SCM you can configure a custom Branch Property Strategy and add a property for Custom Pipeline Speed/Durability Level.  This overrides the global Durability Setting and will apply to each branch at the next run.  You can also use a \"properties\" step to override the setting, but remember that you may have to run the step again to undo this.\n\nDurability settings will take effect with the next applicable Pipeline run, not immediately.  The setting will be displayed in the log.\n\nThere is a slight durability trade-off for using the Performance-Optimized mode — the appropriate section of the Pipeline Scalability documentation has the specifics.\nFor most uses we do not expect this to be important, but there are a few specific cases where users may wish to use a slower/higher-durability setting. The Best Practices are documented.\n\nWe recommend using Performance-Optimized by default, but because it does represent a slight behavioral change the initial \"Cheetah\" plugin releases defaults to maintain previous behavior. We expect to switch this default in the future with appropriate notice once people have a chance to get used to the new settings.\n\nWill Performance-Optimized Mode Help Me?\n\nYes, if your Jenkins instance uses NFS, magnetic storage, runs many Pipelines at once, or shows high iowait (above 5%)\n\nYes, if you are running Pipelines with many steps (more than several hundred).\n\nYes, if your Pipeline stores large files or complex data to variables in the script, keeps that variable in scope for future use, and then runs steps.  This sounds oddly specific but happens more than you’d expect.\n\nFor example: readFile step with a large XML/JSON file, or using configuration information from parsing such a file with One of the Utility Steps.\n\nAnother common pattern is a \"summary\" object containing data from many branches (logs, results, or statistics). Often this is visible because you’ll be adding to it often via an add/append or Map.put() operations.\n\nLarge arrays of data or Maps of configuration information are another common example of this situation.\n\nNo, if your Pipelines spend almost all their time waiting for a few shell/batch steps to finish.  This ISN’T a magic \"go fast\" button for everything!\n\nNo, if Pipelines are writing massive amounts of data to logs (logging is unchanged).\n\nNo, if you are not using Pipelines, or your system is loaded down by other factors.\n\nNo, if you don’t enable higher-performance modes for pipelines.  See above for how!\n\nOther Goodies\n\nUsers can now set an optional job property so that individual Pipelines fail cleanly rather than resuming upon restarting the controller.  This is useful for niche cases where some Pipelines are considered disposable and users would value a clean restart over Pipeline durability.\n\nWe’ve reduced classloading and reflection quite significantly, which improves scaling and reduces CPU use:\n\nScript Security (as of version 1.41) has gotten optimizations to reduce the performance overhead of Sandbox mode and eliminate lock contention so Pipeline multithreads better.\n\nPipeline Step data uses up less space on disk (regardless of the durability setting) - this should be 30% smaller.  Assume it’s a few MB per 1000 steps - but for every build after the change.\n\nEven in the low-performance/high-durability modes, some redundant writes have been removed, which decreases the number of writes by 10-20%.\n\nHow Did You Do It?\n\nThat’s probably material for another blog post or Jenkins World talk.\n\nThe short answer is: first we built a tool to simulate a full production environment and provide detailed metrics collection at scale.  Then we profiled Jenkins to identify bottlenecks and attacked them.  Rinse and repeat.\n\nWhat Next?\n\nThe next big change, which I’m calling Cheetah Part 2 is to address Pipeline’s logging. For every Step run, Pipeline writes one or more small log files. These log files are then copied into the build log content, but are retained to make it possible to easily fetch logs for each step.\n\nThis copying process means every log line is written twice, greatly reducing performance, and writing to many small files is orders of magnitude slower than appending to one big log file.\n\nWe’re going to remove this duplication and data fragmentation and use a more efficient mechanism to find per-step logs. This should further improve the ability to run Pipelines on NFS mounts and hard-drive-backed storage, and should significantly improve performance at scale.\n\nBesides this, there’s a variety of different tactical improvements to improve scaling behavior and reduce resource needs.\n\nThe Project Cheetah work doesn’t free users to completely ignore Pipeline scaling best practices and previous suggestions.  Nor does it eliminate the need for efficient GC settings.  But this and other enhancements from the last year can significantly improve the storage situation for most users and reduce the penalties for worst-case behaviors.  When you add all the pieces together, the result is a faster, leaner, more reliable Pipeline experience.","title":"Project Cheetah - Faster, Leaner Pipeline That Can Keep Up With Demand","tags":["pipeline","performance","scalability"],"authors":[{"avatar":null,"blog":null,"github":"svanoort","html":"","id":"svanoort","irc":null,"linkedin":null,"name":"Sam Van Oort","slug":"blog/author/svanoort","twitter":null}]}}]}},"pageContext":{"tag":"pipeline","limit":8,"skip":24,"numPages":13,"currentPage":4}},
    "staticQueryHashes": ["3649515864"]}