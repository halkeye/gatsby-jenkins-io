{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/plugin",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2021-08-28T00:00:00.000Z","id":"1191945b-e68d-5ab5-8c0e-ef54d9699ba9","slug":"/blog/2021/08/28/conventional-commits-plugin-project-report/","strippedHtml":"This blog post is part 2 of the Introducing the Conventional Commits Plugin blog.\n\nThe goal of this blog is to showcase the work done during the Google Summer of Code 2021 coding phases.\n\nPlease refer the part 1 of the blog for a detailed description of the plugin.\n\nAbstract\n\nThe project/plugin aims to fully automate a release process.\n\nThe plugin tries to achieve this goal by automatically determining the next semantic version based on commit messages.\n\nThere were 2 coding phases in the GSoC 2021.\nI call the first phase - \"Read\" and the 2nd phase - \"Write\", let’s see why.\n\nPhase 1: Read\n\nIn this phase, the \"read\" aspect of the plugin was enhanced.\nThe plugin supported multiple project types (Maven, Gradle, NPM, Helm, Python, Make) and was able to read current version information from the configuration files of the supported project types.\n\nDeliverables\n\nSupport multiline comments\n\nSupport reading the current version from a maven pom.xml\n\nSupport reading the current version from a build.gradle\n\nSupport reading the current version from a Makefile\n\nSupport reading the current version from a package.json\n\nSupport reading the current version from a helm Chart.yaml\n\nResources\n\nList of related issues\n\nPhase 1 Demo and Presentation:\n\nPhase 2: Write\n\nIn this phase, some work was done in extending the \"write\" aspect of the plugin.\nA provision (optional parameter) to write back the calculated next semantic version to the configuration files of projects was added to the plugin.\nAlong with that, the plugin now can append \"Pre-Release\" and \"Build Metadata\" information to the calculated semantic version.\n\nDeliverables\n\nAdd prerelease information to the calculated/new version\n\nAdd build metadata to the calculated/new version\n\nWrite next version in pom.xml\n\nWrite next version in package.json\n\nHandle version mismatch between config file and latest tag\n\nResources\n\nLink to related Issues\n\nUsing optional parameters in the Conventional Commits Plugin\n\nPhase 2 Presentation\n\nNext Steps\n\nWrite back version for Python project.\n\nWrite back version for Gradle project.\n\nHandle remote workspaces\n\nFeedback\n\nWe would love to hear your feedback & suggestions for the plugin.\n\nPlease reach out on the plugin’s GitHub repository, the Gitter channel or start a discussion on community.jenkins.io.","title":"Work report for the Conventional Commits Plugin for Jenkins","tags":["gsoc","gsoc2021","conventionalcommits","plugin"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#688898","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/aaccd/adi10hero.png","srcSet":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/ff5a3/adi10hero.png 32w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/b18f9/adi10hero.png 64w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/aaccd/adi10hero.png 128w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/b9e30/adi10hero.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/8ba60/adi10hero.webp 32w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/a9ea7/adi10hero.webp 64w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/8c23b/adi10hero.webp 128w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/fc98a/adi10hero.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":131}},"publicURL":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/adi10hero.png"},"blog":null,"github":"adi10hero","html":"<div class=\"paragraph\">\n<p>Aditya is a curiosity driven individual striving to find ingenious solutions to real-world problems. He is an open-source enthusiast and a life long learner.</p>\n</div>","id":"adi10hero","irc":null,"linkedin":null,"name":"Aditya Srivastava","slug":"/blog/authors/adi10hero","twitter":"adi10hero"}]}},{"node":{"date":"2021-07-30T00:00:00.000Z","id":"ec28a413-ce25-5776-ac1c-84b03c9452d9","slug":"/blog/2021/07/30/introducing-conventional-commits-plugin-for-jenkins/","strippedHtml":"The conventional commits plugin is a Google Summer of Code project.\nSpecial thanks to the mentors Gareth Evans, Kristin Whetstone, Olivier Vernin and Allan Burdajewicz.\n\nWhat are Conventional Commits\n\nAccording to the official website, conventonal commits are, \"A specification for adding human and machine readable meaning to commit messages.\"\n\nConventional commits are a lightweight convention on top of commit messages.\n\nThe following table shows major structural elements offered by the conventional commits convention.\n\nStructural Element\nExample\n\nChore\nchore: improve logging\n\nFix\nfix: minor bug fix\n\nFeat\nfeat: add a new feature\n\nBreaking Change\nBREAKING CHANGE: reimplement\n\nWhy Conventional Commits\n\nAs the CI/CD world is moving more towards complete automation and minimal human interaction, the ability to fully automate a release is desired.\nConventional Commits enable the use of automated systems on top of commit messages.\nThese systems can \"truly\" automate a release with almost no human interaction.\n\nThe convention dovetails with semantic versioning.\nLet’s take an example, a maven project is currently versioned at 1.2.0.\nThe following table shows how conventional commits would bump the version depending on the type of the commit.\n\nCommit Message\nVersion Bump\nSemVer Equivalent\n\nchore: improve logging\n1.2.0 → 1.2.0\nNo version bump\n\nfix: minor bug fix\n1.2.0 → 1.2.1\nIncrement in the patch version\n\nfeat: add a new feature\n1.2.0 → 1.3.0\nIncrement in the minor version\n\nBREAKING CHANGE: reimplement\n1.2.0 → 2.0.0\nIncrement in the major version\n\nThe Conventional Commits Plugin\n\nThe conventional commits plugin is a Jenkins plugin to programatically determine the next semantic version of a git repository using:\n\nLast tagged version\n\nCommit message log\n\nCurrent version of the project\n\nHow it works?\n\nThe plugin will read the commit messages from the latest tag or the current version of the project till the latest commit.\nUsing this information it will determine what would be the next semantic Version for that particular project.\n\nSupported Project Types?\n\nCurrently the plugin can read the current version from various configuration files of the following project types:\n\nProject Type\nConfiguration File(s) Read\n\nMaven\npom.xml\n\nGradle\nbuild.gradle\n\nMake\nMakefile\n\nPython\nsetup.py\nsetup.cfg\npyproject.toml\n\nHelm\nCharts.yml\n\nNode (NPM)\npackage.json\n\nHow to request a project type support?\n\nPlease feel free to open an issue on the GitHub repository of the plugin.\n\nHow to use the plugin\n\nRecommended way of using the plugin is to add a step in a Jenkins Pipeline Project.\n\nnextVersion() is the pipeline step to be used.\n\nFor example:\n\npipeline {\n    agent any\n\n    environment {\n        NEXT_VERSION = nextVersion()\n    }\n\n    stages {\n        stage('Hello') {\n            steps {\n                echo \"next version = ${NEXT_VERSION}\"\n            }\n        }\n    }\n}\n\nTip: The pipeline step can also be generated with the help of the Snippet Generator.\nPlease select \"nextVersion\" in the Sample Step drop down and then click on \"Generate Pipeline Snippet\"\n\nThe plugin is released on every feature using JEP-229.\n\nThe plugin is available to download from the plugins site.\n\nDemo\n\nYou can watch the plugin in action in a demo presented at the GSoC Midterm Presentations\n\nNext Steps\n\nSupport for pre-release information. Example: 1.0.0-alpha, 1.0.0-beta, etc\n\nSupport for build metadata. Example: 1.0.0-beta+exp.sha.5114f85\n\nOptionally writing the calcuated \"Next Version\" into the project’s configuration file. Example: pom.xml for a maven project, setup.py for python.\n\nFeedback\n\nWe would love to hear your feedback & suggestions for the plugin.\n\nPlease reach out on the plugin’s GitHub repository, the Gitter channel or start a discussion on community.jenkins.io.","title":"Introducing the Conventional Commits Plugin for Jenkins","tags":["gsoc","gsoc2021","conventionalcommits","plugin"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#688898","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/aaccd/adi10hero.png","srcSet":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/ff5a3/adi10hero.png 32w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/b18f9/adi10hero.png 64w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/aaccd/adi10hero.png 128w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/b9e30/adi10hero.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/8ba60/adi10hero.webp 32w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/a9ea7/adi10hero.webp 64w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/8c23b/adi10hero.webp 128w,\n/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/fc98a/adi10hero.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":131}},"publicURL":"/gatsby-jenkins-io/static/fc2f266abaf2a1ff0059fbe0c236d007/adi10hero.png"},"blog":null,"github":"adi10hero","html":"<div class=\"paragraph\">\n<p>Aditya is a curiosity driven individual striving to find ingenious solutions to real-world problems. He is an open-source enthusiast and a life long learner.</p>\n</div>","id":"adi10hero","irc":null,"linkedin":null,"name":"Aditya Srivastava","slug":"/blog/authors/adi10hero","twitter":"adi10hero"}]}},{"node":{"date":"2019-09-23T00:00:00.000Z","id":"c729ed47-ed8f-594c-a5e9-e523cff8ffd2","slug":"/blog/2019/09/23/outreachy-audit-log-release/","strippedHtml":"Thanks to our Outreachy interns over the past year, I’m proud to announce the initial release of the Audit Log plugin for Jenkins.\nThis plugin is the first major project completed related to Outreachy, and I’d like to give a brief overview of the functionality that was developed for this release.\nThe primary goal of this plugin is to introduce an audit trail of various Jenkins events using structured logging and related audit logging standards.\nInitially, this plugin covers audit events related to core Jenkins concepts like user accounts, jobs, builds, nodes, and credentials usage.\nMore specifically, this tracks:\n\nUser login and logout events\n\nCredentials usage\n\nUser creation (when using the Jenkins user database as a security realm)\n\nUser password updates (ditto)\n\nStarts and ends of builds\n\nCreation/modification/deletion/copying of items (which correspond to projects, pipelines, folders, etc.)\n\nCreation/modification/deletion of nodes.\n\nThis plugin defines and exports standardized log event classes and schemas corresponding to these events.\nOther plugins can add audit-log as a dependency to define their own audit events using Apache Log4j Audit and its catalog editor; then they can use the Maven plugin for generating the audit event classes for use in the plugin.\n\nThe other major feature of this plugin is configuring where to output these audit logs.\nBy default, audit logs will be written in HTML files (rotated once per day) to $JENKINS_HOME/logs/html/audit.html which are viewable through the \"Audit Logs\" root action link.\nIn the system settings, a section for audit logging is added where the main audit log output can be configured.\nThis can initially be configured to output via either a JSON log file in $JENKINS_HOME/logs/audit.log by default or to a syslog server using RFC5424 encoding.\n\nOverall, this experience has been rather interesting.\nBesides having an opportunity to mentor new contributors, Outreachy has helped open my eyes to the struggles that developers from around the world are dealing with which can be improved upon to help expand our communities.\nFor example, many countries do not have reliable internet or electricity, so the use of synchronous videoconferencing and other heavyweight, synchronous processes common to more corporate-style development are inadequate in this international context.\nThis doesn’t even begin to account for the difference in timezones which is not always an issue, though both problems are addressable by using asynchronous communication methods like chat and email.\nThis notion of asynchronous communication is an important aspect of the Apache Way, for example, which emphasises processes that allow for vendor neutral communities to form and thrive around a project.\n\nThis mentoring project was valuable to myself as well.\nAs a software engineer myself, project management is not my specialty, so this gave me a great opportunity to develop my own PM skills and technical leadership.\nMy own typical discovery process for feature development involves experimenting directly with the code to see what features make sense to prioritize and which would take a vast effort to implement.\nChanging my own discovery process to avoid implementing the features myself was difficult to adjust to, though I did defer any of my own feature contributions to this plugin until after the initial release.\nIn order to appropriately scope the project, I still had to spend a bit of time reading through the Jenkins codebase to determine which tasks could be implemented simply (e.g., good newbie-friendly issues), which tasks might require changes to Jenkins itself (previously discovered to take too long for these relatively short Outreachy rounds), and which tasks would require intimate familiarity with Jenkins and would likely be infeasible for new developers to Jenkins.\nThanks to the work done in discovery and delivery, I’ve also identified potential features for Log4j itself which could be used in future versions of this plugin.\n\nOverall, I think we did a good job of balancing the scope of this project without spending too much time in any specific area.\nThe first release of this plugin is now available in the Jenkins Update Center.\nIn the future, I hope to learn more about developing Jenkins UI components so that we can create a more dynamic and Jenkins-like configuration page for choosing where logs are output.\nWhile I don’t intend on using this plugin for further Outreachy rounds, I do hope to see more interest in it over time as the more security-conscious users out there discover this new plugin.","title":"Audit Log Plugin for Jenkins Releases 1.0","tags":["outreachy","logging","security","plugin","community"],"authors":[{"avatar":null,"blog":"https://musigma.blog/","github":"jvz","html":"<div class=\"paragraph\">\n<p>Mathematician, software engineer, and free software evangelist.\nWorks for CloudBees on the <a href=\"https://jenkins.io/security/\">Jenkins Security Team</a> along with other Jenkins community work since 2018.\nPMC Chair of the <a href=\"https://logging.apache.org/\">Apache Logging Services project</a> and Secretary for the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.</p>\n</div>","id":"jvz","irc":null,"linkedin":null,"name":"Matt Sicker","slug":"/blog/authors/jvz","twitter":"jvz"}]}},{"node":{"date":"2019-09-10T00:00:00.000Z","id":"d5e0f766-e02d-50ec-a790-2201ba4d74b9","slug":"/blog/2019/09/10/introducing-the-jira-software-plugin-for-jenkins/","strippedHtml":"According to a recent survey we conducted, software & IT teams on average use 4+ tools to move code from development to customer-facing production. As a result, teams struggle with keeping the status of work updated and understanding the overall health of their delivery pipeline.\n\nTo solve this problem, I am excited to announce that we built an official Jenkins plugin for Jira Software Cloud. The plugin automatically associates build and deployment information from Jenkins with relevant Jira issues and exposes key information about your pipeline across Jira issues, boards and via JQL. This means you can use Jira Software to automatically update and track issues through your complete development pipeline, from backlog to release.\n\nI hope this plugin adds value to you and your team. If you are interested in contributing or forking this plug-in you can head over to our project on the Jenkins GitHub repo to get started.\n\nBetter collaboration between teams\n\nThis new information view is so powerful because historically it was dispersed across multiple tools only accessible to a few members of your team. Now anyone involved in the software delivery process can self-serve this information. For example, product managers, QA, and support teams can view which features have been deployed to customers and which are still waiting in staging environments.\n\nWith better information sharing between tools in your delivery stack, you can also improve cross-collaboration between teams. Teams such as QA and operations can collaborate in the software teams next sprint. For example, you can use build information in Jira Software to create a workflow between QA and developers and create a rapid feedback loop for testing at any point in your development process.\n\nUse Jira’s Querying Language for advanced views\n\nIn addition to building better ways to collaborate, these integrations also give your team deeper insight into the development pipeline from within Jira Software. You can now create powerful views into your delivery pipeline with JQL queries across multiple connected tools. For example, you can write a custom JQL query to report all Jira issues that have been deployed to production but still have an open PR.\n\ndeploymentEnvironmentType ~ “production“ AND development[pullrequests].open\n\nGet started\n\nIn Jira Software Cloud\n\nCreate OAuth credentials in Jira for Jenkins\n\nNavigate to Jira home > Jira settings > Apps.\n\nSelect OAuth credentials.\n\nSelect Create credentials.\n\nEnter the following details:\n\nApp name - Jenkins\n\nApp logo - A URL to the Jenkins logo, which will be used as an icon in the list of credentials. Eg: https://jenkins.yourcompany.com/logo.png\n\nServer base URL - The URL to your Jenkins server. Eg: https://jenkins.yourcompany.com\n\nIn Jenkins\n\nInstall the Jenkins plugin\n\nLogin to your Jenkins server and navigate to the Plugin Manager.\n\nSelect the 'Available' tab and search for 'Atlassian Jira Software Cloud' as the plugin name then install it.\n\nThe open-source plugin is hosted in the Jenkins GitHub account. You can check it out here.\n\nSet up Jenkins credentials\n\nIn Jenkins, go to Manage Jenkins > Configure System screen and scroll to the Jira Software Cloud integration section.\n\nSelect Add Jira Cloud Site > Jira Cloud Site. The Site name, ClientID, and Secret fields display.\n\nEnter the following details:\n\nSite name: The URL for your Jira Cloud site, for example yourcompany.atlassian.net.\n\nClient ID: Copy from OAuth credentials screen (Client ID column).\n\nSecret: Select Add > Jenkins.\n\nFor Kind, select Secret text.\n\nFor Secret, copy from OAuth credentials screen (Secret column).\n\nFor Description, provide a helpful description\n\nSelect Test settings to make sure your credentials are valid for your Jira site.\n\nHow to use the plugin\n\nTo start using the integration:\n\nGo into a specific pipeline in Jenkins ( Note: Your pipeline must be a 'Multibranch Pipeline' ).\n\nFrom the left-hand menu, select Pipeline Syntax.\n\nIn the Snippet Generator, select jiraSendDeploymentInfo or jiraSendBuildInfo from the dropdown list of Sample Steps and fill in the relevant details.\n\nSelect Generate Pipeline Script and copy/paste the output into your Jenkinsfile on the relevant Repository you are using. This will be used to notify Jira when you run that pipeline on that repo.\n\nFor sending build information\n\nThis is an example snippet of a very simple ‘build’ stage set up in a Jenkinsfile. After the pipeline is run, it will post the build information to your Jira Cloud site by looking at the branch name. If there is a Jira issue key (e.g. “TEST-123”) in the branch name, it will send the data over to Jira.\n\nJenkinsfile example\n\npipeline {\n     agent any\n     stages {\n         stage('Build') {\n             steps {\n                 echo 'Building...'\n             }\n             post {\n                 always {\n                     jiraSendBuildInfo site: 'example.atlassian.net'\n                 }\n             }\n         }\n     }\n }\n\nFor sending deployment information\n\nThis is an example snippet of two stages that run on any change to the staging or master branch. Again, we use a post step to send deployment data to Jira and the relevant issues. Here, the environmentId, environmentName, and environmentType need to be set to whatever you want to appear in Jira.\n\nJenkinsfile example\n\npipeline {\n     agent any\n     stages {\n         stage('Deploy - Staging') {\n             when {\n                 branch 'master'\n             }\n             steps {\n                 echo 'Deploying to Staging from master...'\n             }\n             post {\n                 always {\n                     jiraSendDeploymentInfo site: 'example.atlassian.net', environmentId: 'us-stg-1', environmentName: 'us-stg-1', environmentType: 'staging'\n                 }\n             }\n         }\n         stage('Deploy - Production') {\n            when {\n                branch 'master'\n            }\n            steps {\n                echo 'Deploying to Production from master...'\n            }\n            post {\n                always {\n                    jiraSendDeploymentInfo site: 'example.atlassian.net', environmentId: 'us-prod-1', environmentName: 'us-prod-1', environmentType: 'production'\n                }\n            }\n         }\n     }\n }\n\nThe entire Jenkinsfile may look something like this. This is only meant to represent an example of what the Jira snippets could look like within a stage or step.\n\nJenkinsfile example\n\npipeline {\n     agent any\n     stages {\n         stage('Build') {\n             steps {\n                 echo 'Building...'\n             }\n             post {\n                 always {\n                     jiraSendBuildInfo site: 'example.atlassian.net'\n                 }\n             }\n         }\n         stage('Deploy - Staging') {\n             when {\n                 branch 'master'\n             }\n             steps {\n                 echo 'Deploying to Staging from master...'\n             }\n             post {\n                 always {\n                     jiraSendDeploymentInfo site: 'example.atlassian.net', environmentId: 'us-stg-1', environmentName: 'us-stg-1', environmentType: 'staging'\n                 }\n             }\n         }\n         stage('Deploy - Production') {\n            when {\n                branch 'master'\n            }\n            steps {\n                echo 'Deploying to Production from master...'\n            }\n            post {\n                always {\n                    jiraSendDeploymentInfo site: 'example.atlassian.net', environmentId: 'us-prod-1', environmentName: 'us-prod-1', environmentType: 'production'\n                }\n            }\n         }\n     }\n }\n\nQuestions or feedback?\n\nIf you have any questions, please contact Atlassian support and they will route it to the correct team to help you.","title":"Introducing the Jira Software plugin for Jenkins","tags":["jira","plugin","pipeline"],"authors":[{"avatar":null,"blog":null,"github":"rafalmyslek","html":"","id":"rafalmyslek","irc":null,"linkedin":null,"name":"Rafal Myslek","slug":"/blog/authors/rafalmyslek","twitter":null}]}},{"node":{"date":"2019-08-19T00:00:00.000Z","id":"a8a6f50d-13d8-5ff0-b148-cd0ef7696ecf","slug":"/blog/2019/08/19/remoting-kafka-kubernetes-release-2.0/","strippedHtml":"I am Long Nguyen from FPT University, Vietnam. My project for Google Summer of Code 2019 is Remoting over Apache Kafka with Kubernetes features. After a successful Phase 1, finally the 2.0 version of the plugin has been released. The 2.0 version provides seamless integration with Kubernetes environment.\n\n2.0 version features\n\nStart a simple Apache Kafka server in Kubernetes.\n\nDynamically provision Remoting Kafka Agent in Kubernetes.\n\nHelm chart to bootstrap the whole system in Kubernetes.\n\nStart a simple Apache Kafka server in Kubernetes\n\nUse of the plugin requires that users have a configured Apache Zookeeper and Apache Kafka server, which could be intimidating for people who just want to try out the plugin. Now, users can start a simple, single-node Apache Kafka server in Kubernetes environment with just one button click.\n\nOn the Global Configuration page, users can input Kubernetes server information and credentials. When users click Start Kafka on Kubernetes button, Jenkins will create a Kubernetes client from the information and then apply Apache Zookeeper and Apache Kafka YAML specification files from resources. After downloading images and creating containers, it will automatically update Apache Zookeeper and Apache Kafka URLs into respective fields.\n\nDynamically provision Remoting Kafka Agent in Kubernetes\n\nWith previous version, users have to manually add/remove nodes so it is hard to scale builds quickly. Kubernetes plugin allows us to dynamically provision agents in Kubernetes but it is designed for JNLP agent. With this new version, Remoting Kafka agent can also be provisioned automatically in Kubernetes environment.\n\nUsers can find the new feature in Cloud section in /configure. Here users could input Kubernetes connection parameters and desired Remoting Kafka agent properties including labels. When new build with matching labels gets started and there are no free nodes, Cloud will automatically provision Remoting Kafka agent pod in Kubernetes to run the build.\n\nHelm Chart\n\nHelm chart for Remoting over Apache Kafka plugin is based on stable/jenkins chart and incubator/kafka chart. You can follow the instruction here to install a demo ready-to-use Helm release. Your kubectl get all should look like this:\n\nNAME                                READY   STATUS    RESTARTS   AGE\npod/demo-jenkins-64dbd87987-bmndf   1/1     Running   0          2m21s\npod/demo-kafka-0                    1/1     Running   0          2m21s\npod/demo-zookeeper-0                1/1     Running   0          2m21s\n\nNAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\nservice/demo-jenkins              NodePort    10.108.238.56 8080:30386/TCP               2m21s\nservice/demo-jenkins-agent        ClusterIP   10.98.85.184 50000/TCP                    2m21s\nservice/demo-kafka                ClusterIP   10.109.231.58 9092/TCP                     2m21s\nservice/demo-kafka-headless       ClusterIP   None 9092/TCP                     2m21s\nservice/demo-zookeeper            ClusterIP   10.103.2.231 2181/TCP                     2m21s\nservice/demo-zookeeper-headless   ClusterIP   None 2181/TCP,3888/TCP,2888/TCP   2m21s\n\nNAME                           READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/demo-jenkins   1/1     1            1           2m21s\n\nNAME                                      DESIRED   CURRENT   READY   AGE\nreplicaset.apps/demo-jenkins-64dbd87987   1         1         1       2m21s\n\nNAME                              READY   AGE\nstatefulset.apps/demo-kafka       1/1     2m21s\nstatefulset.apps/demo-zookeeper   1/1     2m21s\n\nHow to Contribute\n\nYou are welcome to try out the plugin and integrate it into your current setup. If you find out any bug or if you would like to request new feature, you can create ticket at JIRA. If you would like to contribute code directly, you can create pull requests in the GitHub page below.\n\nLinks\n\nPhase 2 Demo Video\n\nPhase 2 Presentation Slides\n\nPhase 1 Blog Post\n\nPhase 1 Demo Video\n\nPhase 1 Presentation Slides\n\nRemoting over Apache Kafka plugin source code\n\nProject Page\n\nGitter Channel","title":"Remoting over Apache Kafka 2.0: Built-in Kubernetes support","tags":["remoting","kafka","kubernetes","helm","plugin","gsoc","gsoc2019"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/19e71/longnguyen.jpg","srcSet":"/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/77b35/longnguyen.jpg 32w,\n/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/d4a57/longnguyen.jpg 64w,\n/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/19e71/longnguyen.jpg 128w,\n/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/68974/longnguyen.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/ef6ff/longnguyen.webp 32w,\n/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/8257c/longnguyen.webp 64w,\n/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/6766a/longnguyen.webp 128w,\n/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/22bfc/longnguyen.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/1100ce9c7d4d77539be043dff3d058aa/longnguyen.jpg"},"blog":null,"github":"longngn","html":"<div class=\"paragraph\">\n<p>Long is a Software Engineering student at FPT University, Vietnam. He started to contribute for Jenkins from Google Summer of Code 2019 for the project <a href=\"https://jenkins.io/projects/gsoc/2019/remoting-over-apache-kafka-docker-k8s-features/\">Remoting over Apache Kafka with Kubernetes features</a></p>\n</div>","id":"longnguyen","irc":null,"linkedin":null,"name":"Long Nguyen","slug":"/blog/authors/longnguyen","twitter":null}]}},{"node":{"date":"2019-07-25T00:00:00.000Z","id":"c8dcfc2d-fe9b-51ed-b1d8-8da5973e144c","slug":"/blog/2019/07/25/azure-artifact-manager/","strippedHtml":"Jenkins stores all generated artifacts on the controller server filesystem. This presents a couple of challenges especially when you try to run Jenkins in the cloud:\n\nAs the number of artifacts grow, your Jenkins controller will run out of disk space. Eventually, performance can be impacted.\n\nFrequent transfer of files between agents and controller may cause load, CPU or network issues which are always hard to diagnose.\n\nSeveral existing plugins allow you to manage your artifacts externally. To use these plugins, you need to know how they work and perform specific steps in your job’s configuration. And if you are new to Jenkins, you may find it hard to follow existing samples in Jenkins tutorial like Recording tests and artifacts.\n\nSo, if you are running Jenkins in Azure, you can consider automatically managing new artifacts on Azure Storage. The new Azure Artifact Management plugin allows you to store artifacts in Azure blob storage and simplify your existing Jenkins jobs that contain Jenkins general artifacts management steps. This approach will give you all the advantages of a cloud storage, with less effort on your part to maintain your Jenkins instance.\n\nConfiguration\n\nAzure storage account\n\nFirst, you need to have an Azure Storage account. You can skip this section if you already have one. Otherwise, create an Azure storage account for storing your artifacts. Follow this tutorial to quickly create one. Then navigate to Access keys in the Settings section to get the storage account name and one of its keys.\n\nExisting Jenkins instance\n\nFor existing Jenkins instance, make sure you install the Azure Artifact Manager plugin. Then you can go to your Jenkins System Configuration page and locate the Artifact Management for Builds section. Select the Add button to configure an Azure Artifact Storage. Fill in the following parameters:\n\nStorage Type: Azure storage supports several storage types like blob, file, queue etc. This plugin currently supports blob storage only.\n\nStorage Credentials: Credentials used to authenticate with Azure storage. If you do not have an existing Azure storage credential in you Jenkins credential store, click the Add button and choose Microsoft Azure Storage kind to create one.\n\nAzure Container Name: The container under which to keep your artifacts. If the container name does not exist in the blob, this plugin automatically creates one for you when artifacts are uploaded to the blob.\n\nBase Prefix: Prefix added to your artifact paths stored in your container, a forward slash will be parsed as a folder. In the following screenshot, all your artifacts will be stored in the “staging” folder in the container “Jenkins”.\n\nNew Jenkins instance\n\nIf you need to create a new Jenkins controller, follow this tutorial to quickly create an Jenkins instance on Azure. In the Integration Settings section, you can now set up Azure Artifact Manager directly. Note that you can change any of the configuration after your Jenkins instance is created. Azure storage account and credential, in this case, are still prerequisites.\n\nUsage\n\nJenkins Pipeline\n\nHere are a few commonly used artifact related steps in pipeline jobs; all are supported to push artifacts to the Azure Storage blob specified.\n\nYou can use archiveArtifacts step to archive target artifacts into Azure storage. For more details about archiveArtifacts step, see the Jenkins archiveArtifacts setp documentation.\n\nnode {\n  //...\n  stage('Archive') {\n    archiveArtifacts \"pattern\"\n  }\n}\n\nYou can use the unarchive step to retrieve the artifacts from Azure storage. For more details about unarchive step, please see unarchive step documentation.\n\nnode {\n  //...\n  stage('Unarchive') {\n    unarchive mapping: [\"pattern\": '.']\n  }\n}\n\nTo save a set of files so that you can use them later in the same build (generally on another node or workspace), you can use stash step to store files into Azure storage for later use. Stash step documentation can be found here.\n\nnode {\n  //...\n  stash name: 'name', includes: '*'\n}\n\nYou can use unstash step to retrieve the files saved with stash step from Azure storage to the local workspace. Unstash documentation can be found here.\n\nnode {\n  //...\n  unstash 'name'\n}\n\nFreeStyle Job\n\nFor a FreeStyle Jenkins job, you can use Archive the artifacts step in Post-build Actions to upload the target artifacts into Azure storage.\n\nThis Azure Artifact Manager plugin is also compatible with some other popular management plugins, such as the Copy Artifact plugin. You can still use these plugins without changing anything.\n\nTroubleshooting\n\nIf you have any problems or suggestions when using Azure Artifact Manager plugin, you can file a ticket on Jenkins JIRA for the azure-artifact-manager-plugin component.\n\nConclusion\n\nThe Azure Artifact Manager enables a more cloud-native Jenkins. This is the first step in the Cloud Native project. We have a long way to go to get Jenkins to run on cloud environments as a true “Cloud Native” application. We need help and welcome your participation and contributions to make Jenkins better. Please start contributing and/or give us feedback!","title":"Managing Jenkins Artifacts with the Azure Artifact Manager Plugin","tags":["general","azure","plugin"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/19e71/jshen.jpg","srcSet":"/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/77b35/jshen.jpg 32w,\n/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/d4a57/jshen.jpg 64w,\n/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/19e71/jshen.jpg 128w,\n/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/68974/jshen.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/ef6ff/jshen.webp 32w,\n/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/8257c/jshen.webp 64w,\n/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/6766a/jshen.webp 128w,\n/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/22bfc/jshen.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/5f4c376818aa25b85cee206264e2692f/jshen.jpg"},"blog":null,"github":"gavinfish","html":"<div class=\"paragraph\">\n<p>Software engineer at Microsoft. Focusing on DevOps and cloud native.</p>\n</div>","id":"jshen","irc":null,"linkedin":null,"name":"Jie Shen","slug":"/blog/authors/jshen","twitter":null}]}},{"node":{"date":"2019-05-09T00:00:00.000Z","id":"8e971fb0-7d4b-559d-a327-05b99fb4739e","slug":"/blog/2019/05/09/templating-engine/","strippedHtml":"Implementing DevSecOps practices at the enterprise scale is challenging. With multiple programming languages, automated testing frameworks, and security compliance tools being used by different applications within your organization, it becomes difficult to build and maintain pipelines for each team.\n\nMost pipelines are going to follow the same generic workflow regardless of which specific tech stack is employed by an application.  The Templating Engine Plugin (abbreviated as JTE for Jenkins Templating Engine) allows you to capture this efficiency by creating tool-agnostic, templated workflows to be reused by every team.\n\nAs technology consultants with clients in both the public and private sectors, at Booz Allen we found ourselves building DevSecOps pipelines from scratch for every new project.  Through developing the Jenkins Templating Engine, we’ve seen pipeline development decrease from months to days now that we can reuse tool integrations while bringing a new level of governance to Jenkins pipelines.\n\nPipeline Templating\n\nOrganizations benefit from letting application developers focus on what they do best: building applications. Supporting this means building a centralized DevOps team responsible for maintaining platform infrastructure and creating CI/CD pipelines utilized by development teams.\n\nWith the rise of microservice-based architectures, a centralized DevOps teams can support many different development teams simultaneously; all of whom may be leveraging different programming languages and automated testing tools.\n\nWhile the tools may differ between development teams, the workflow is often the same: unit test, static code analysis, build and publish an artifact, deploy it, and then perform different types of testing against the deployed application.\n\nThe Templating Engine Plugin allows you to remove the Jenkinsfile from each repository by defining a common workflow for teams to inherit.  Instead of an entire pipeline definition in each repository, teams supply a configuration file specifying which tools to use for the workflow.\n\nJTE in Action\n\nLet’s walk through a bare bones example to demonstrate the reusability of templates:\n\nExample Pipeline Template:\n\nunit_test()\nbuild()\nstatic_code_analysis()\n\nTemplates leverage Steps contributed by Libraries to outline a workflow teams must implement.  While a template does get executed just like any other Jenkinsfile (meaning that the standard scripted and declarative syntax is supported), the goal of a template should be to read like plain English and avoid any technical implementation.\n\nLeveraging templates in this way lets you separate the business logic (what should happen when) of your pipeline from the\ntechnical implementation (what’s actually going to happen).  The result of this is a CI/CD pipeline that’s proven to be\nsignificantly easier to manage when supporting multiple teams simultaneously.\n\nThe steps outlined by this template ( unit_test, build, and static_code_analysis) have been named generically on purpose. This way teams can specify different libraries to use while sharing the same pipeline.\n\nImplementing the Template\n\nImplementing a shareable pipeline with the Templating Engine requires a few key components:\n\nPipeline Template : Outline the workflow to be performed\n\nLibraries : Provide technical implementations of the steps of the workflow\n\nConfiguration Files : Specify which libraries to use and their configuration\n\nStep 1: Create a Pipeline Configuration Repository\n\nA Pipeline Configuration Repository is used to store common configurations and pipeline templates inherited by teams.\n\nThis example Pipeline Configuration Repository will later be configured as part of a Governance Tier : the mechanism in JTE that allows you to build hierarchical configurations representing your organization.\n\nA Governance Tier holds three things:\n\nPipeline Templates\n\nA list of Library Sources\n\nThe tier’s configuration file ( pipeline_config.groovy)\n\nThe pipeline templates and the configuration file for a Governance Tier are stored in the pipeline configuration repository.\n\nWhen configuring the Governance Tier in Jenkins, you will provide a source code management location for a repository that contains the above components as well as the base directory where these artifacts can be found.\n\nStep 2: Create the Pipeline Template\n\nNext, we’ll create a Jenkinsfile for the Governance Tier.  In JTE, the Jenkinsfile is the default pipeline template that an execution will use.\n\nJenkinsfile\n\nunit_test()\nbuild()\nstatic_code_analysis()\n\nStep 3: Create the Libraries\n\nThe Templating Engine Plugin has implemented a version of Jenkins Shared Libraries to enhance the reusability of libraries.  A library is a root directory within a source code repository that has been configured as a Library Source on a Governance Tier.\n\nIn our example, the pipeline template needs to perform unit testing, package an artifact, and run static code analysis.\n\nLet’s assume that we have some teams using gradle and some teams using maven to build and test their application but they will both use SonarQube to perform static code analysis.\n\nIn this scenario, we should create gradle, maven, and sonarqube libraries.\n\n|- gradle/\n  \\-- build.groovy\n  \\-- unit_test.groovy\n|- maven/\n  \\-- build.groovy\n  \\-- unit_test.groovy\n|- sonarqube/\n  \\-- static_code_analysis.groovy\n\nStep 4: Implement the Steps\n\nImplementing a library step is exactly the same as just writing regular global variables as part of the default Jenkins Shared Libraries.\n\nFor the purposes of this demonstration, we will just have each step print out the step name and contributing library.\n\ngradle/build.groovy\n\nvoid call(){\n    println \"gradle: build()\"\n}\n\nRead more about Library Development within JTE.\n\nStep 5: Create the Configuration Files\n\nThe configuration file for JTE is named pipeline_config.groovy.\n\nIn the Governance Tier we’ll create a configuration file specifying common configurations between the applications. In this case, both applications are using the sonarqube library:\n\npipeline_config.groovy\n\nlibraries{\n  merge = true // allow individual apps to contribute additional libraries\n  sonarqube\n}\n\nNext, we’ll create two more repositories representing the maven and gradle applications. Within those repositories all we’ll need is an application-specific pipeline_config.groovy file.\n\nThese repositories both contain an application pipeline_config.groovy configuration file.\n\nmaven app: pipeline_config.groovy\n\nlibraries{\n    maven\n}\n\ngradle app: pipeline_config.groovy\n\nlibraries{\n    gradle\n}\n\nStep 6: Configure the Governance Tier in Jenkins\n\nNow that we have a Pipeline Configuration Repository and a Library Source Repository, we can configure a Governance Tier in Jenkins:\n\nThis configuration shown in the image above can be found under Manage Jenkins >> Configure System\n\nThrough the Templating Engine, you can create a pipeline governance hierarchy matching your organization’s taxonomy by representing this structure via Folders in Jenkins.\n\nStep 7: Create a Multibranch Pipeline for Both Applications\n\nWhen creating Multibranch Pipeline Projects for each app, the Templating Engine plugin supplies a new Project Recognizer\ncalled Jenkins Templating Engine.  This sets the project to use the Templating Engine framework for all branches within the\nrepository.\n\nYou can also set the Jenkins Templating Engine project recognizer for a GitHub Organization project, enabling you to easily share the same pipeline across an entire Github Organization!\n\nStep 8: Run the Pipelines\n\nThat’s it!  Now, both applications will leverage the exact same pipeline template while having the flexibility to select which\ntools should be used during each phase of the workflow.\n\nBelow is sample output from the console log from both applications pipeline runs:\n\nGradle:\n\n[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-configuration\n[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-app-gradle.git\n[JTE] Loading Library sonarqube from git https://github.com/steven-terrana/example-jte-libraries.git\n[JTE] Loading Library gradle from git https://github.com/steven-terrana/example-jte-libraries.git\n...\n[JTE] Obtained Template Jenkinsfile from git https://github.com/steven-terrana/example-jte-configuration\n[JTE][Step - gradle/unit_test]\n[Pipeline] echo\ngradle: unit_test()\n[JTE][Step - gradle/build]\n[Pipeline] echo\ngradle: build()\n[JTE][Step - sonarqube/static_code_analysis]\n[Pipeline] echo\nsonarqube: static_code_analysis()\n[Pipeline] End of Pipeline\n\nMaven:\n\n[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-configuration\n[JTE] Obtained Template Configuration File pipeline_config.groovy from git https://github.com/steven-terrana/example-jte-app-maven.git\n[JTE] Loading Library sonarqube from git https://github.com/steven-terrana/example-jte-libraries.git\n[JTE] Loading Library maven from git https://github.com/steven-terrana/example-jte-libraries.git\n...\n[JTE] Obtained Template Jenkinsfile from git https://github.com/steven-terrana/example-jte-configuration\n[JTE][Step - maven/unit_test]\n[Pipeline] echo\nmaven: unit_test()\n[JTE][Step - maven/build]\n[Pipeline] echo\nmaven: build()\n[JTE][Step - sonarqube/static_code_analysis]\n[Pipeline] echo\nsonarqube: static_code_analysis()\n[Pipeline] End of Pipeline\n\nBenefits of the Templating Engine\n\nApply Organizational Governance\n\nLeveraging the Templating Engine Plugin will allow you to define enterprise-scale, approved\nworkflows that can be used by teams regardless of what tools are being used.  This top-down\napproach makes scaling and enforcing DevSecOps principles significantly easier within your organization.\n\nOptimize Code Reuse\n\nThere’s really no need for every team in your organization to figure out how to do the same things over\nand over again.  At Booz Allen, we have seen pipeline development time decrease from months to days as\nwe have continuously reused and expanded upon our Templating Engine library portfolio as part of our Solutions\nDelivery Platform.\n\nSimplify Pipeline Maintainability\n\nOften DevOps engineers find themselves building and supporting pipelines for multiple development teams at\nthe same time.  By decoupling the workflow from the technical implementation and consolidating the pipeline\ndefinition to a centralized location, the Templating Engine plugin allows DevOps engineers to scale much faster.\n\nGet Involved!\n\nThe Templating Engine Plugin has been open sourced and made available in the Jenkins Update Center.\n\nWe always appreciate feedback and contributions! If you have an interesting use case or would like to ask questions, try the templating-engine-plugin on Gitter.\n\nAdvanced Features\n\nConfiguration File Conditional Inheritance\n\nExternalize Library Configurations\n\nAspect Oriented LifeCycle Hooks\n\nMultiple Pipeline Templates\n\nDefault Step Implementation\n\nConfiguration File DSL Sandboxing\n\nMore Resources\n\nFor this Demonstration\n\nPipeline Configuration Repository\n\nSample Libraries\n\nSample Maven Repository\n\nSample Gradle Repository\n\nAdditional Resources\n\nTemplating Engine Documentation\n\nSource Code\n\nBooz Allen’s SDP Pipeline Libraries\n\nBooz Allen Hamilton","title":"Introducing the Jenkins Templating Engine!","tags":["general","pipeline","plugin","pipeline-authoring"],"authors":[{"avatar":null,"blog":null,"github":"steven-terrana","html":"","id":"steven-terrana","irc":null,"linkedin":null,"name":"Steven Terrana","slug":"/blog/authors/steven-terrana","twitter":null}]}},{"node":{"date":"2018-08-14T00:00:00.000Z","id":"2fa297fb-b9d2-5c87-846c-6ac7d68adea3","slug":"/blog/2018/08/14/simple-pull-request-plugin-final-evaluation/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of reports at conventional locations,\nand publish them automatically. If the reports are not present at their respective conventional\nlocation, the location of the report can be configured in the YAML file.\n\nMy mentors are\nOleg Nenashev (Org Admin),\nMartin d’Anjou,\nKristin Whetstone,\nJeff Knurek\n\nProject Repository\n\nProject repository\n\nCode changes\n\nAll the pull requests made can be found here\n\nList of major pull requests.\n\nPhase 1\n\nPR-5 : Git wrappers like clone, pull, checkout,\npullChangesOfPullrequest, merge, deleteBranch and merge added.\n\nPR-6 : Yaml to Declarative Pipeline code generation.\n\nPlease see Phase 1 blog post\n\nPhase 2\n\nPR-11 : Implemented StepConfigurator\nusing Jenkins configuration as code plugin.\n\nPR-19 : Unit tests created for agent and yaml to pipeline generation.\n\nPlease see Phase 2 blog post\n\nPhase 3\n\nPR-25 : Declarative pipeline code generator code\nexported to extensions for extensibility and support of custom sections\n\nJenkinsfile.yaml example\n\nDocumentation of Jenkinsfile.yaml and yaml format can be found here\n\nTasks completed in Coding Phase 3\n\nAdd unit tests, JenkinsRule tests JENKINS-52495\n\nRefactor snippet generator to extensions ( JENKINS-52491)\n\nPlugin overview (Present in README.md)\n\nFuture tasks\n\nPhase 3 Jira Epic\n\nRelease 1.0 ( JENKINS-52519)\n\nSupport the “when” Declarative Pipeline directive ( JENKINS-52520)\n\nNice2have: Support hierarchical report types ( JENKINS-52521)\n\nAcceptance Test Harness tests JENKINS-52496\n\nAutomatic Workspace Cleanup when PR is closed ( JENKINS-51897)\n\nTest Multi-Branch Pipeline features support:\n\nSupport for webhooks ( JENKINS-51941)\n\nCheck if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)\n\nFinalize documentation ( JENKINS-52518)\n\nTest the integration with various platforms Bitbucket, Gitlab, Github.\n\nPhase 3 evaluation presentation video\n\nVideo: Link to video evaluation\n\nPhase 3 evaluation presentation slides\n\nLink to presentation slides\n\nMy GSoC experience\n\nStudent applications started on March 12 16:00 UTC and ended on March 27 16:00 UTC. Application period allowed me to explore\nmany new technology and platforms that are making peoples life easy.\n\nBefore starting of the application\nperiod I did not know anything about Jenkins. I found Jenkins organisation on the GSoC organisations page\nand came to know that I is a CI/CD platform that is used automate various things related to software development. I studied\nabout Jenkins online and went through the problem statements provided by some mentors.\n\nI decided that to work on Simple Pull-Request Job Plugin project.\nThen I wrote a draft proposal for this project and received many comments to refactor the proposal and enhance its quality from the mentors,\nthen finally I submitted my final proposal to Google.\n\nI was able to complete most of the tasks decided in Phase 1 and 2. After Phase 2 I was not able to give time to the project because\nof the placement season in the my college. I modified the code so that other plugin developers can contribute to it by Jenkins extensions.\n\nAll the mentors made themselves available for most of the weekly calls and provided many valuable suggestions during the\nentire period of GSoC. Sometimes I was not able to communicate effectively. As communication is the key while working remotely, mentors\nsuggested to communicate more thorough gitter chat.\n\nMy overall experience of GSoC was good and all the mentors helped me as they can all times. This project allowed me to explore\nJenkins and the services offered by it. I am allowed to work on the project after GSoC ends (This is a good thing).\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository","title":"alpha-3 release Pipeline as YAML (Simple pull request plugin)","tags":["gsoc2018","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/abhishek_gautam.JPG"},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/authors/abhishek_gautam","twitter":null}]}}]}},"pageContext":{"tag":"plugin","limit":8,"skip":0,"numPages":2,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}