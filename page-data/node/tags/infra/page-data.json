{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/infra",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-06-29T00:00:00.000Z","id":"72dc398a-0c3a-5b36-949e-7687e6ecbefc","slug":"/blog/2016/06/29/from-freestyle-to-pipeline/","strippedHtml":"This is a guest post by R. Tyler Croy, who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\nCloudBees, Inc.\n\nFor ages I have used the \"Build After\" feature in Jenkins to cobble together\nwhat one might refer to as a \"pipeline\" of sorts. The Jenkins project itself, a\nmajor consumer of Jenkins, has used these daisy-chained Freestyle jobs to drive\na myriad of delivery pipelines in our infrastructure.\n\nOne such \"pipeline\" helped drive the complex process of generating the pretty\nblue charts on\nstats.jenkins.io.\nThis statistics generation process primarily performs two major tasks, on rather\nlarge sets of data:\n\nGenerate aggregate monthly \"census data.\"\n\nProcess the census data and create trend charts\n\nThe chained jobs allowed us to resume the independent stages of the pipeline,\nand allowed us to run different stages on different hardware (different\ncapabilities) as needed. Below is a diagram of what this looked like:\n\nThe infra_generate_monthly_json would run periodically creating the\naggregated census data, which would then be picked up by infra_census_push\nwhose sole responsibility was to take census data and publish it to the\nnecessary hosts inside the project’s infrastructure.\n\nThe second, semi-independent, \"pipeline\" would also run periodically. The\ninfra_statistics job’s responsibility was to use the census data, pushed\nearlier by infra_census_push, to generate the myriad of pretty blue charts\nbefore triggering the\ninfra_checkout_stats job which would make sure stats.jenkins.io was\nproperly updated.\n\nSuffice it to say, this \"pipeline\" had grown organically over a period time when\nmore advanced tools weren’t quite available.\n\nWhen we migrated to newer infrastructure for\nci.jenkins.io earlier this year I took the\nopportunity to do some cleaning up. Instead of migrating jobs verbatim, I pruned\nstale jobs and refactored a number of others into proper\nPipelines, statistics generation being an obvious\ntarget!\n\nOur requirements for statistics generation, in their most basic form, are:\n\nEnable a sequence of dependent tasks to be executed as a logical group (a\npipeline)\n\nEnable executing those dependent tasks on various pieces of infrastructure\nwhich support different requirements\n\nActually generate those pretty blue charts\n\nIf you wish to skip ahead, you can jump straight to the\nJenkinsfile\nwhich implements our new Pipeline.\n\nThe first iteration of the Jenkinsfile simply defined the conceptual stages we\nwould need:\n\nnode {\n    stage 'Sync raw data and census files'\n\n    stage 'Process raw logs'\n\n    stage 'Generate census data'\n\n    stage 'Generate stats'\n\n    stage 'Publish census'\n\n    stage 'Publish stats'\n}\n\nHow exciting! Although not terrifically useful. When I began actually\nimplementing the first couple stages, I noticed that the Pipeline might sync\ndozens of gigabytes of data every time it ran on a new agent in the cluster.\nWhile this problem will soon be solved by the\nExternal\nWorkspace Manager plugin, which is currently being developed. Until it’s ready,\nI chose to mitigate the issue by pinning the execution to a consistent agent.\n\n/* `census` is a node label for a single machine, ideally, which will be\n * consistently used for processing usage statistics and generating census data\n */\nnode('census && docker') {\n    /* .. */\n}\n\nRestricting a workload which previously used multiple agents to a single one\nintroduced the next challenge. As an infrastructure administrator, technically\nspeaking, I could just install all the system dependencies that I want on this\none special Jenkins agent. But what kind of example would that be setting!\n\nThe statistics generation process requires:\n\nJDK8\n\nGroovy\n\nA running MongoDB instance\n\nFortunately, with Pipeline we have a couple of useful features at our disposal:\ntool auto-installers and the\nCloudBees\nDocker Pipeline plugin.\n\nTool Auto-Installers\n\nTool Auto-Installers are exposed in Pipeline through the tool step and on\nci.jenkins.io we already had JDK8 and Groovy\navailable. This meant that the Jenkinsfile would invoke tool and Pipeline\nwould automatically install the desired tool on the agent executing the current\nPipeline steps.\n\nThe tool step does not modify the PATH environment variable, so it’s usually\nused in conjunction with the withEnv step, for example:\n\nnode('census && docker') {\n    /* .. */\n\n    def javaHome = tool(name: 'jdk8')\n    def groovyHome = tool(name: 'groovy')\n\n    /* Set up environment variables for re-using our auto-installed tools */\n    def customEnv = [\n        \"PATH+JDK=${javaHome}/bin\",\n        \"PATH+GROOVY=${groovyHome}/bin\",\n        \"JAVA_HOME=${javaHome}\",\n    ]\n\n    /* use our auto-installed tools */\n    withEnv(customEnv) {\n        sh 'java --version'\n    }\n\n    /* .. */\n}\n\nCloudBees Docker Pipeline plugin\n\nSatisfying the MongoDB dependency would still be tricky. If I caved in and installed\nMongoDB on a single unicorn agent in the cluster, what could I say the next time\nsomebody asked for a special, one-off, piece of software installed on our\nJenkins build agents?\n\nAfter doing my usual complaining and whining, I discovered that the CloudBees\nDocker Pipeline plugin provides the ability to run containers inside of a\nJenkinsfile. To make things even better, there are\nofficial MongoDB docker images readily\navailable on DockerHub!\n\nThis feature requires that the machine has a running Docker daemon which is\naccessible to the user running the Jenkins agent. After that, running a\ncontainer in the background is easy, for example:\n\nnode('census && docker') {\n    /* .. */\n\n    /* Run MongoDB in the background, mapping its port 27017 to our host's port\n     * 27017 so our script can talk to it, then execute our Groovy script with\n     * tools from our `customEnv`\n     */\n    docker.image('mongo:2').withRun('-p 27017:27017') { container ->\n        withEnv(customEnv) {\n            sh \"groovy parseUsage.groovy --logs ${usagestats_dir} --output ${census_dir} --incremental\"\n        }\n    }\n\n    /* .. */\n}\n\nThe beauty, to me, of this example is that you can pass a\nclosure to withRun which will\nexecute while the container is running. When the closure is finished executin,\njust the sh step in this case, the container is destroyed.\n\nWith that system requirement satisfied, the rest of the stages of the Pipeline\nfell into place. We now have a single source of truth, the\nJenkinsfile,\nfor the sequence of dependent tasks which need to be executed, accounting for\nvariations in systems requirements, and it actually generates\nthose pretty\nblue charts!\n\nOf course, a nice added bonus is the beautiful visualization of our\nnew Pipeline!\n\nLinks\n\nPipeline documentation\n\nCloudBees Docker Pipeline plugin documentation\n\nLive statistics Pipeline","title":"Migrating from chained Freestyle jobs to Pipelines","tags":["pipeline","infra"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-05-18T00:00:00.000Z","id":"3098cab4-cd65-52ec-a4a9-2b36e2ac20d7","slug":"/blog/2016/05/18/announcing-azure-partnership/","strippedHtml":"I am pleased to announce that we have partnered with Microsoft to migrate and\npower the Jenkins project’s infrastructure with\nMicrosoft Azure. The partnership comes\nat an important time, after the recent launch of Jenkins 2.0,\nJenkins users are more readily adopting Pipeline as\nCode and many other plugins at an increasing rate, elevating the importance of\nJenkins infrastructure to the overall success of the project. That strong and\ncontinued growth has brought new demands to our infrastructure’s design and\nimplementation, requiring the next step in its evolution. This partnership helps\nus grow with the rest of the project by unifying our existing infrastructure\nunder one comprehensive, modern and scalable platform.\n\nIn March we\ndiscussed\nthe potential partnership in our regularly scheduled\nproject\nmeeting,\nhighlighting some of the infrastructure challenges that we face:\n\nCurrently we have infrastructure in four different locations, with four\ndifferent infrastructure providers, each with their own APIs and tools for\nmanaging resources, each with varying capabilities and capacities.\n\nProject infrastructure is managed by a team of volunteers, operating\nmore than 15 different services and managing a number of additional external\nservices.\n\nOur current download/mirror network, while geographically distributed, is\nrelatively primitive and its implementation prevents us from using more modern\ndistribution best practices.\n\nIn essence, five years of tremendous growth for Jenkins has outpaced our\norganically grown, unnecessarily complex, project infrastructure. Migrating to\nAzure simplifies and improves our infrastructure in a dramatic way that would\nnot be possible without a comprehensive platform consisting of: compute, CDN,\nstorage and data-store services. Our partnership covers, at minimum, the next\nthree years of the project’s infrastructure needs, giving us a great home for\nthe future.\n\nAzure also enables a couple of projects that I\nhave long been dreaming of providing to Jenkins users and contributors:\n\nEnd-to-end TLS encrypted distribution of Jenkins packages, plugins and\nmetadata via the Azure CDN.\n\nMore complete build/test/release support and capacity on\nci.jenkins.io for plugin developers using\nAzure\nContainer Service and generic VMs.\n\nThe Jenkins infrastructure is all open\nsource which means  all of our Docker containers, Puppet code and many of our\ntools are all available on GitHub. Not\nonly can you watch the migration process to Azure as it happens, but I also\ninvite you to participate in making our project’s infrastructure better (join\nus in the #jenkins-infra channel on Freenode or our\nmailing list).\n\nSuffice it to say, I’m very excited about the bright [blue] future for the\nJenkins project and the infrastructure that powers it!","title":"Partnering with Microsoft to run Jenkins infrastructure on Azure","tags":["azure","infra","infrastructure"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-22T00:00:00.000Z","id":"be010022-b98d-5767-afad-a1578cc4e23f","slug":"/blog/2016/04/22/possible-infra-compromise/","strippedHtml":"Last week, the infrastructure team identified the potential compromise of a key\ninfrastructure machine. This compromise could have taken advantage of, what\ncould be categorized as, an attempt to target contributors with elevated\naccess. Unfortunately, when facing the uncertainty of a potential compromise,\nthe safest option is to treat it as if it were an actual incident, and react\naccordingly. The machine in question had access to binaries published to our\nprimary and secondary mirrors, and to contributor account information.\n\nSince this machine is not the source of truth for Jenkins binaries, we verified\nthat the files distributed to Jenkins users: plugins, packages, etc, were not\ntampered with. We cannot, however, verify that contributor account information\nwas not accessed or tampered with and, as a proactive measure, we are issuing a\npassword reset for all contributor accounts. We have also spent significant effort\nmigrating all key services off of the potentially compromised machine to\n(virtual) hardware so the machine can be re-imaged or decommissioned entirely.\n\nWhat you should do now\n\nIf you have ever filed an issue in JIRA,\nedited a wiki page, released a plugin or\notherwise created an account via the Jenkins\nwebsite, you have a Jenkins community account. You should be receiving a\npassword reset email shortly, but if you have re-used your Jenkins account\npassword with other services we strongly encourage you to update your passwords\nwith those other services.  If you’re not already using one, we also encourage\nthe use of a password manager for generating and managing service-specific\npasswords.\n\nThe generated password sent out is temporary and will expire if you do not\nuse it to update your account. Once it expires you will need recover your\naccount with the password reset\nin the accounts app.\n\nThis does not apply to your own Jenkins installation, or any account that you\nmay use to log into it. If you do not have a Jenkins community account, there is\nno action you need to take.\n\nWhat we’re doing to prevent events like this in the future\n\nAs stated above, the potentially compromised machine is being removed from our\ninfrastructure. That helps address the immediate problem but doesn’t put\nguarantees in place for the future. To help prevent potential issues in the\nfuture we’re taking the following actions:\n\nIncorporating more security policy enforcement into our\nPuppet-driven infrastructure. Without a\nconfiguration management tool enforcing a given state for some legacy services,\nuser error and manual mis-configurations can adversely affect project security.\nAs of right now, all key services are managed by Puppet.\n\nBalkanizing our machine and permissions model more. The machine affected was\nliterally the first independent (outside of Sun) piece of project\ninfrastructure and like many legacy systems, it grew to host a multitude of\nservices. We are rapidly evolving away from that model with increasing levels\nof user and host separation for project services.\n\nIn a similar vein, we have also introduced a trusted zone in our\ninfrastructure which is not routable on the public internet, where sensitive\noperations, such as generating update center information, can be managed and\nsecured more effectively.\n\nWe are performing an infrastructure permissions audit. Some portions of our\ninfrastructure are 6+ years old and have had contributors come and go. Any\ninactive users with unnecessarily elevated permissions in the project\ninfrastructure will have those permissions revoked.\n\nI would like to extend thanks, on behalf of the Jenkins project, to\nCloudBees for their help in funding and\nmigrating this infrastructure.\n\nIf you have further questions about the Jenkins project infrastructure, you can\njoin us in the #jenkins-infra channel on Freenode\nor in an Infrastructure Q&A session I’ve scheduled for next Wednesday (April\n27) at 20:00 UTC (12:00 PST).","title":"Possible Jenkins Project Infrastructure Compromise","tags":["infra","security"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/author/rtyler","twitter":"agentdero"}]}}]}},"pageContext":{"tag":"infra","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}