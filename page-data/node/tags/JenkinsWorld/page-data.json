{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/JenkinsWorld",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-07-27T00:00:00.000Z","id":"92796c2d-9e8b-530e-82dd-441263269c06","slug":"/blog/2017/07/27/standardizing-builds-with-shared-libraries/","strippedHtml":"This is a guest post by Alvin Huang, DevOps Engineer at\nFireEye.\n\nAs a security company, FireEye relentlessly protects our customers from cyber attacks. To act\nquickly on intelligence and expertise learned, the feedback loop from the front lines to features\nand capabilities in software must be small. Jenkins helps us achieve this by allowing us to build,\ntest, and deploy to our hardware and software platforms faster, so we can stop the bad guys\nbefore they reach our customers.\n\nMore capabilities and functionalities in our product offerings means more applications and\nsystems, which means more software builds and jobs in Jenkins. Within the FaaS (FireEye as a\nService) organization, the tens of Jenkins jobs that were manageable manually in the web GUI\nquickly grew to hundreds of jobs that required more automation. Along the way, we outgrew\nour old legacy datacenter and were tasked with migrating 150+ Freestyle jobs on an old 1.x\nJenkins instance to a newer 2.x instance in the new datacenter in 60 days.\n\nCopying Freestyle job XML configuration files to the new server would leave\ntechnical debt.  Using Freestyle job templates would be better but for\ncomplicated jobs that require multiple templates, this would still create large\ndependency chains that would be hard to trace in the log output. Finally,\ndevelopers were not excited about having to replicate global changes, such as\nadd an email recipient when a new member joins the team, across tens of jobs\nmanually or using the\nConfiguration\nSlicer. We needed a way to migrate the jobs in a timely fashion while getting\nrid of as much technical debt as possible.\n\nJenkins Pipeline to the rescue! In 2.0, Jenkins added the capability to create pipelines as first-\nclass entities. At FireEye, we leveraged many of the features available in pipeline to aid in the\nmigration process including the ability to:\n\ncreate Pipeline as Code in a Jenkinsfile stored in SCM\n\ncreate Jenkins projects automatically when new branches or repos get added with a Jenkinsfile\n\ncontinue jobs after the Jenkins controller or build agent crashes\n\nand most importantly, build a Pipeline\nShared Library that keeps projects\nDRY and\nallows new applications to be on boarded into Jenkins within seconds\n\nHowever, Jenkins Pipeline came with a DSL that our users would have to learn to translate their\nFreestyle jobs to pipeline jobs. This would be a significant undertaking across multiple teams\njust to create Jenkins jobs. Instead, the DevOps team identified similarities across all the\nFreestyle jobs that we were migrating, learned the Jenkins DSL to become SMEs for the\norganization, and built a shared library of functions and wrappers that saved each Dev/QA\nengineer hours of time.\n\nBelow is an example function we created to promote builds in Artifactory:\n\nvars/promoteBuild.groovy\n\ndef call(source_repo, target_repo, build_name, build_number) {\n    stage('Promote to Production repo') {\n        milestone label: 'promote to production'\n        input 'Promote this build to Production?'\n\n        node {\n            Artifactory.server(getArtifactoryServerID()).promote([\n                'buildName'   : build_name,\n                'buildNumber' : build_number,\n                'targetRepo'  : target_repo,\n                'sourceRepo'  : source_repo,\n                'copy'        : true,\n            ])\n    }\n}\n\ndef call(source_repo, target_repo) {\n    buildInfo = getBuildInfo()\n\n    call(source_repo, target_repo, buildInfo.name, buildInfo.number)\n}\n\nRather than learning the Jenkins DSL and looking up how the Artifactory Plugin worked in\nPipeline, users could easily call this function and pass it parameters to do the promotion work\nfor them. In the Shared Library, we can also create build wrappers of opinionated workflows,\nthat encompasses multiple functions, based on a set of parameters defined in the Jenkinsfile.\nIn addition to migrating the jobs, we also had to migrate the build agents. No one knew the\nexact list of packages, versions, and build tools installed on each build server, so rebuilding\nthem would be extremely difficult. Rather than copying the VMs or trying to figure out what\npackages were on the build agents, we opted to use Docker to build containers with all\ndependencies needed for an application.\n\nI hope you will join me at my Jenkins World session:\nCodifying the Build and Release Process with a Jenkins\nPipeline Shared Library, as I deep dive into the inner workings of our Shared\nPipeline Library and explore how we integrated Docker into our CI/CD pipeline.\nCome see how we can turn a Jenkinsfile with just a set of parameters like this:\n\nJenkinsfile\n\nstandardBuild {\n    machine          = 'docker'\n    dev_branch       = 'develop'\n    release_branch   = 'master'\n    artifact_apttern = '*.rpm'\n    html_pattern     = [keepAll: true, reportDir: '.', reportFiles: 'output.html', reportName: 'OutputReport']\n    dev_repo         = 'pipeline-examples-dev'\n    prod_repo        = 'pipeline-examples-prod'\n    pr_script        = 'make prs'\n    dev_script       = 'make dev'\n    release_script   = 'make release'\n}\n\nand a Dockerfile like this:\n\nDockerfile\n\nFROM faas/el7-python:base\n\nRUN yum install -y python-virtualenv \\\n        rpm-build && \\\n        yum clean all\n\nInto a full Jenkins Pipeline like this:\n\nAs we look ahead at FireEye, I will explore how the Shared Library sets us up for easier future\nmigrations of other tools such as Puppet, JIRA, and Artifactory, and easier integration with new\ntools like Openshift. I will also cover our strategies for deployments and plans to move to\nDeclarative Pipeline.\n\nAlvin will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Codifying the Build and Release Process with a Pipeline Shared Library","tags":["event","JenkinsWorld"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/rtyler.jpeg"},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2017-07-17T00:00:00.000Z","id":"0116e3f0-03af-5f1b-b064-5d44aaf60398","slug":"/blog/2017/07/17/speaker-blog-care/","strippedHtml":"This is a guest post by Mandy Hubbard, Software Engineer/QA Architect at\nCare.com.\n\nImagine this: It’s 4:30pm on a Friday,\nyou have a major release on Monday, and your Jenkins server goes down.\nIt doesn’t matter if it experienced a hardware failure,\nfell victim to a catastrophic\nfat-finger error,\nor just got hit by a meteor - your Jenkins server is toast.\nHow long did it take to perfect your Pipeline,\nall your Continuous Delivery jobs, plugins, and credentials?\nHopefully you at least have a recent backup of your Jenkins home directory,\nbut you’re still going have to work over the weekend with IT to procure a new server,\ninstall it, and do full regression testing to be up and running by Monday morning.\nGo ahead and take a moment, go to your car and just scream.\nIt will help …​ a little.\n\nBut what if you could have a Jenkins environment that is completely disposable,\none that could be easily rebuilt at any time?\nUsing Docker and Joyent’s\nContainerPilot, the team at\nCare.com HomePay\nhas created a production Jenkins environment that is completely software-defined.\nEverything required to set up a new Jenkins environment is stored in source control,\nversioned, and released just like any other software.\nAt Jenkins World, I’ll do a developer deep-dive into this approach during my technical session,\nIndispensable, Disposable Jenkins,\nincluding a demo of bringing up a fully configured Jenkins server in a Docker container.\nFor now, let me give you a basic outline of what we’ve done.\n\nMandy will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.\n\nFirst, we add ContainerPilot to our Jenkins image by including it in the Dockerfile.\n\nDockerfile\n\n## ContainerPilot\n\nENV CONTAINERPILOT_VERSION 2.7.0\nENV CONTAINERPILOT_SHA256 3cf91aabd3d3651613942d65359be9af0f6a25a1df9ec9bd9ea94d980724ee13\nENV CONTAINERPILOT file:///etc/containerpilot/containerpilot.json\n\nRUN curl -Lso /tmp/containerpilot.tar.gz https://github.com/joyent/containerpilot/releases/download/${CONTAINERPILOT_VERSION}/containerpilot-${CONTAINERPILOT_VERSION}.tar.gz && \\\n    echo \"${CONTAINERPILOT_SHA256}  /tmp/containerpilot.tar.gz\" | sha256sum -c && \\\n    tar zxf /tmp/containerpilot.tar.gz -C /bin && \\\nrm /tmp/containerpilot.tar.gz\n\nThen we specify containerpilot as the Docker command in the docker-compose.yml\nand pass the Jenkins startup script as an argument.\nThis allows ContainerPilot to perform our preStart business before starting the Jenkins server.\n\ndocker-compose.yml\n\njenkins:\n    image: devmandy/auto-jenkins:latest\n    restart: always\n    mem_limit: 8g\n    ports:\n      - 80\n      - 22\n    dns:\n      - 8.8.8.8\n      - 127.0.0.1\n    env_file: _env\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - CONSUL=consul\n    links:\n      - consul:consul\n    ports:\n      - \"8080:80\"\n      - \"2222:22\"\n    command: >\n      containerpilot\n      /usr/local/bin/jenkins.sh\n\nConfiguration data is read from a Docker Compose _env file,\nas specified in the docker-compose.yml file,\nand stored in environment variables inside the container.\nThis is an example of our _env file:\n\n_env\n\nGITHUB_TOKEN=\nGITHUB_USERNAME=DevMandy\nGITHUB_ORGANIZATION=DevMandy\nDOCKERHUB_ORGANIZATION=DevMandy\nDOCKERHUB_USERNAME=DevMandy\nDOCKERHUB_PASSWORD=\nDOCKER_HOST=\nSLACK_TEAM_DOMAIN=DevMandy\nSLACK_CHANNEL=jenkinsbuilds\nSLACK_TOKEN=\nBASIC_AUTH=\nAD_NAME=\nAD_SERVER=\nPRIVATE_KEY=\n\nJenkins stores its credentials and plugin information in various xml files.\nThe preStart script modifies the relevant files,\nsubstituting the environment variables as appropriate,\nusing a set of command line utilities called xmlstarlet.\nHere is an example method from our preStart script that configures Github credentials:\n\ngithub_credentials_setup() {\n    ## Setting Up Github username in credentials.xml file\n    echo\n    echo -e \"Adding Github username to credentials.xml file for SSH key\"\n    xmlstarlet \\\n        ed \\\n        --inplace \\\n        -u '//com.cloudbees.jenkins.plugins.sshcredentials.impl.BasicSSHUserPrivateKey[id=\"github\"]/username' \\\n        -v ${GITHUB_USERNAME} \\\n        ${JENKINS_HOME}/credentials.xml\n\n    echo -e \"Adding Github username to credentials.xml file for Github token\"\n    xmlstarlet \\\n        ed \\\n         --inplace \\\n        -u '//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=\"github_token\"]/username' \\\n        -v ${GITHUB_USERNAME} \\\n        ${JENKINS_HOME}/credentials.xml\n\n    PASSWORD=${GITHUB_TOKEN}\n    echo -e \"Adding Github token to credentials.xml\"\n    xmlstarlet \\\n        ed \\\n        --inplace \\\n        -u '//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=\"github_token\"]/password' \\\n        -v ${PASSWORD} \\\n        ${JENKINS_HOME}/credentials.xml\n}\n\nThis approach can be used to automate all things Jenkins.\nThese are just a few of the things I’ll show you in my Jenkins World session,\nwhich you can build on to automate anything else your Jenkins environment needs.\n\nCreation of credentials sets for interacting with third party services\nlike Github, Docker Hub and Slack\n\nConfiguration of the Active Directory plugin\nand setup of matrix-based security\n\nConfiguration of the Github Organization plugin,\nwhich results in the automatic creation of all Jenkins pipeline jobs\nby scanning the organization for all repositories containing a Jenkinsfile\n\nConfiguration of the\nDocker Pipeline plugin, including creating templates for all custom build agents\n\nConfiguration of the Global Pipeline Libraries plugin\n\nConfiguration of the Slack Notifier plugin\n\nWith software-defined Jenkins, pipeline infrastructure\ngains the same flexibility and resiliency as the rest of the development pipeline.\nIf we decide to change our Jenkins configuration in any way –\nfor example installing a new plugin or upgrading an existing one,\nadding a new global library, or adding new Docker images for build agents –\nwe simply edit our preStart script to include these changes, build a new Docker image,\nand the Jenkins environment is automatically reconfigured when we start a new container.\nBecause the entire configuration specification lives in a Github repository,\nchanges are merged to the \"master\" branch using pull requests,\nand our Jenkins Docker image is tagged using\nsemantic versioning just like any other component.\nJenkins can be both indispensable and completely disposable at the same time.","title":"Indispensable, Disposable Jenkins","tags":["event","JenkinsWorld"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"","id":"hinman","irc":null,"linkedin":null,"name":"Hannah Inman","slug":"/blog/authors/hinman","twitter":null}]}}]}},"pageContext":{"tag":"JenkinsWorld","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}