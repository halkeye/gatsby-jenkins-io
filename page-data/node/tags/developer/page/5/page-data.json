{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/developer/page/5",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-05-15T00:00:00.000Z","id":"85458a0f-8ad5-53fb-a455-a4b6ae133fb4","slug":"/blog/2018/05/15/incremental-deployment/","strippedHtml":"A couple of weeks ago, Tyler mentioned some\ndeveloper improvements in Essentials\nthat had been recently introduced:\nthe ability for\nci.jenkins.io\nbuilds to get deployed automatically to an “Incrementals” Maven repository,\nas described in\nJEP-305.\nFor a plugin maintainer, you just need to\nturn on this support\nand you are ready to both deploy individual Git commits from your repository\nwithout the need to run heavyweight traditional Maven releases,\nand to depend directly on similar commits of Jenkins core or other plugins.\nThis is a stepping stone toward continuous delivery, and ultimately deployment, of Jenkins itself.\n\nHere I would like to peek behind the curtain a bit at how we did this,\nsince the solution turns out to be very interesting for people thinking about security in Jenkins.\nI will gloss over the Maven arcana required to get the project version to look like 1.40-rc301.87ce0dd8909b\n(a real example from the\nCopy Artifact plugin)\nrather than the usual 1.40-SNAPSHOT, and why this format is even useful.\nSuffice it to say that if you had enough permissions, you could run\n\nmvn -Dset.changelist -DskipTests clean deploy\n\nfrom your laptop to publish your latest commit.\nIndeed as\nmentioned in the JEP,\nthe most straightforward server setup would be to run more or less that command\nfrom the buildPlugin function called from a typical Jenkinsfile,\nwith some predefined credentials adequate to upload to the Maven repository.\n\nUnfortunately, that simple solution did not look very secure.\nIf you offer deployment credentials to a Jenkins job,\nyou need to trust anyone who might configure that job (here, its Jenkinsfile)\nto use those credentials appropriately.\n(The withCredentials step will mask the password from the log file, to prevent accidental disclosures.\nIt in no way blocks deliberate misuse or theft.)\nIf your Jenkins service runs inside a protected network and works with private repositories,\nthat is probably good enough.\n\nFor this project, we wanted to permit incremental deployments from any pull request.\nJenkins will refuse to run Jenkinsfile modifications from people\nwho would not normally be able to merge the pull request or push directly,\nand those people would be more or less trustworthy Jenkins developers,\nbut that is of no help if a pull request changes pom.xml\nor other source files used by the build itself.\nIf the server administrator exposes a secret to a job,\nand it is bound to an environment variable while running some open-ended command like a Maven build,\nthere is no practical way to control what might happen.\n\nThe lesson here is that the unit of access control in Jenkins is the job.\nYou can control who can configure a job, or who can edit files it uses,\nbut you have no control over what the job does or how it might use any credentials.\nFor JEP-305, therefore, we wanted a way to perform deployments from builds considered as black boxes.\nThis means a division of responsibility:\nthe build produces some artifacts, however it sees fit;\nand another process picks up those artifacts and deploys them.\n\nThis worked was tracked in\nINFRA-1571.\nThe idea was to create a “serverless function” in Azure\nthat would retrieve artifacts from Jenkins at the end of a build,\nperform a set of validations to ensure that the artifacts follow an expected repository path pattern,\nand finally deploy them to Artifactory using a trusted token.\nI prototyped this in Java, Tyler\nrewrote it in JavaScript,\nand together we brought it into production.\n\nThe crucial bit here is what information (or misinformation!) the Jenkins build can send to the function.\nAll we actually need to know is the build URL, so the\ncall site from Jenkins\nis quite simple.\nWhen the function is called with this URL,\nit starts off by performing input validation:\nit knows what the Jenkins base URL is,\nand what a build URL from inside an organization folder is supposed to look like:\nhttps://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/ , for example.\n\nThe next step is to call back to Jenkins and ask it for some metadata about that build.\nWhile we do not trust the build, we trust the server that ran it to be properly configured.\nAn obstacle here was that the ci.jenkins.io server had been configured to disable the Jenkins REST API;\nwith Tyler’s guidance I was able to amend this policy to permit API requests from registered users\n(or, in the case of the Incrementals publisher, a bot).\n\nIf you want to try this at home, get an\nAPI token,\npick a build of an “incrementalified” plugin or Jenkins core,\nand run something like\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/api/json?pretty&tree=actions[revision[hash,pullHash]]'\n\nYou will see a hash or pullHash corresponding to the main commit of that build.\n(This information was added to the Jenkins REST API to support this use case in\nJENKINS-50777.)\nThe main commit is selected when the build starts\nand always corresponds to the version of Jenkinsfile in the repository for which the job is named.\nWhile a build might checkout any number of repositories,\ncheckout scm always picks “this” repository in “this” version.\nTherefore the deployment function knows for sure which commit the sources came from,\nand will refuse to deploy artifacts named for some other commit.\n\nNext it looks up information about the Git repository at the folder level (again from JENKINS-50777):\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/api/json?pretty&tree=sources[source[repoOwner,repository]]'\n\nThe Git repository now needs to be correlated to a list of Maven artifact paths that this component is expected to produce.\nThe\nrepository-permissions-updater\n(RPU) tool already had a list of artifact paths used to perform permission checks on regular release deployments to Artifactory; in\nINFRA-1598\nI extended it to also record the GitHub repository name, as can be seen\nhere.\nNow the function knows that the CI build in this example may legitimately create artifacts in the org/jenkins-ci/plugins/git/ namespace\nincluding 38c569094828 in their versions.\nThe build is expected to have produced artifacts in the same structure as mvn install sends to the local repository,\nso the function downloads everything associated with that commit hash:\n\ncurl -sg 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/artifact/**/*-rc*.38c569094828/*-rc*.38c569094828*/*zip*/archive.zip' | jar t\n\nWhen all the artifacts are indeed inside the expected path(s),\nand at least one POM file is included (here org/jenkins-ci/plugins/git/3.9.0-rc1671.38c569094828/git-3.9.0-rc1671.38c569094828.pom),\nthen the ZIP file looks good—ready to send to Artifactory.\n\nOne last check is whether the commit has already been deployed (perhaps this is a rebuild).\nIf it has not, the function uses the Artifactory REST API to atomically upload the ZIP file\nand uses the GitHub Status API to associate a message with the commit\nso that you can see right in your pull request that it got deployed:\n\nOne more bit of caution was required.\nJust because we successfully published some bits from some PR does not mean they should be used!\nWe also needed a tool which lets you select the newest published version of some artifact\nwithin a particular branch, usually master.\nThis was tracked in\nJENKINS-50953\nand is available to start with as a Maven command operating on a pom.xml :\n\nmvn incrementals:update\n\nThis will check Artifactory for updates to relevant components.\nWhen each one is found, it will use the GitHub API to check whether the commit has been merged to the selected branch.\nOnly matches are offered for update.\n\nPutting all this together, we have a system for continuously delivering components\nfrom any of the hundreds of Jenkins Git repositories\ntriggered by the simple act of filing a pull request.\nSecuring that system was a lot of work\nbut highlights how boundaries of trust interact with CI/CD.","title":"Automatic deployment of “incremental” commits to Jenkins core and plugins","tags":["evergreen","developer"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-04-30T00:00:00.000Z","id":"b56ab05f-d077-5b8d-ab93-27f00b4c8c1e","slug":"/blog/2018/04/30/using-the-beta-annotation/","strippedHtml":"This sort of slid under the radar in the middle of some bigger changes\nfor the JEP-202\nreference implementation, so I wanted to call it out now. Arguably this could\ndeserve a retroactive JEP, though I would rather fold it into a JEP for\nJENKINS-49651 (see below).\n\nAs of Jenkins 2.118, or plugin parent POM 3.7, you can mark any Java member\n( class, method, constructor, field, or I suppose also interface,\nenum, or annotation) with API visibility ( protected or public) with an\nannotation :\n\n@Restricted(Beta.class)\n\nThe idea is to announce to potential users of the member that the API\nmay still be in flux and only code prepared to keep up should be using\nit. For an example, 2.118 added a VirtualFile.toExternalURL() method\nthat is being implemented in artifact-manager-s3 and (pending some\nPR merges) called in copyartifact and workflow-basic-steps. We do\nnot necessarily want this to be called yet by unknown parties out\nthere in the Jenkins ecosystem. To enforce that, any attempt to call\nor implement toExternalURL will produce a build failure, unless you\nadd this property to your plugin POM, as these plugins have done:\n\ntrue\n\nWhy? Because there is a chance the design is wrong and it might need\nto be changed—perhaps some upcoming bug fix would demand a boolean\nparameter be added, for example.\n\nUnder the conventional notion of Jenkins API deprecation and compatibility\npolicy, once an API like this makes it into a release version, that is it—we\nmight mark it @Deprecated but we need to maintain compatibility indefinitely,\nand find some way to migrate existing implementations / call sites.\n\nWith the @Beta annotation, that promise is not being made. If it needs\na boolean parameter for some reason, that will be added and those\nthree plugins updated to match; we are not going to bother retaining\nthe original overload and somehow delegating to the new one. This\nsimplification of the developer workflow is important to the use cases\nof Essentials (JEP-3xx), and I would expect the useBeta mark to\nbecome widespread among plugins included in Essentials. Such as the situation\nwhere one team needs to feel\ncomfortable refactoring code under its aegis freely, and the refactored result\nshould be deliverable as a unit to production via the Evergreen distribution\nsystem.\n\nSo that leaves two important questions:\n\nFirst, is the annotation\npermanent, and if not, when should it be removed? I do not think there\nis any hard policy, but the intention is that it should be removed\nonce the API is in more or less widespread use and has held up. For\nthis example, if people start using S3 artifacts, and especially if\nsomeone successfully writes an implementation of artifact storage in\nAzure that uses the API, the concept will have been reasonably proven.\nAt that point we want the API to be used wherever it would make sense,\nand if there is some very belated realization that the design is not\nquite right, we accept the burden of deprecating the original and\nmigrating callers compatibly.\n\nSecond, it is fine and well to say that someone changing the signature\nof a beta toExternalURL is on the hook to update the three plugins\nusing it, but what if a Jenkins admin ( not running Essentials, for\nshame) upgrades to (say) Jenkins 2.125 with the new signature but\ndeclines to accept the updates to those plugins (say,\nworkflow-basic-steps 2.9) which adapt to the change? It is not\nenough to say that it is their fault for holding back on the updates\narbitrarily; the plugin manager offers you updates but does nothing\nto tell you when they are required, so suddenly throwing\nNoSuchMethodError is not a helpful response.\n\nThe solution needs to be ironed out, but my expectation is to use\nJENKINS-49651\nfor this. For example, workflow-basic-steps 2.8,\nusing toExternalURL(), would have declared itself compatible with\nJenkins-Version: 2.118, and thus implicitly anything newer. The\ndeveloper doing the refactoring would also amend some 2.125 (and\nnewer) core metadata to say that it conflicts with anything older than\nthe 2.9 release of the plugin. The plugin manager would therefore\nblock the 2.8 plugin from even being loaded on the 2.125 core; the\nadmin would need to update before using it. In the case of an\nincompatible change made to a plugin API, rather than a core API, the\nUX is a little smoother since the plugin manager could just refuse to\nlet you update one without the other.\n\nIf you’re a plugin or core developer who is interested in using the @Beta\nannotations, or have questions about our motiviations, please join the\ndiscussion on\nthis mailing list thread.","title":"Using new core APIs with the Beta annotation","tags":["core","developer","plugin"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}}]}},"pageContext":{"tag":"developer","limit":8,"skip":32,"numPages":5,"currentPage":5}},
    "staticQueryHashes": ["3649515864"]}