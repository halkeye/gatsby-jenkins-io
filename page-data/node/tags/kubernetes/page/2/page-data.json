{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/kubernetes/page/2",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-12-10T00:00:00.000Z","id":"a9e14a72-e8bc-5d64-8f07-6daa5be4a88f","slug":"/blog/2018/12/10/kubecon-is-here/","strippedHtml":"The time has come - KubeCon + CloudNativeCon North America 2018 has arrived.\nThe conference has completely sold out and the schedule is jam packed with interesting talks.\n\nIf you’re among those with tickets, here are a couple Jenkins related events that might interest you:\n\nOn Wednesday at 3:40pm, Carlos Sanchez will be presenting\nJenkins X: Continuous Delivery for Kubernetes in\nTahoma 3/4 @ TCC.\n\nOn Tuesday at 2:35pm, Jonathan Hess & Loren Trout from\nSAP will discuss how\nMigrating Jenkins to Kubernetes Broke Our Brains in Room 606-609.\n\nI look forward to seeing you there!","title":"KubeCon + CloudNativeCon North America 2018 is Here!","tags":["cloud-native","kubernetes","kubecon"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/lnewman.jpeg"},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2018-09-14T00:00:00.000Z","id":"3853be51-02ed-55b0-8b3f-edbfcfe998c7","slug":"/blog/2018/09/14/kubernetes-and-secret-agents/","strippedHtml":"At long last, the way we build and deploy software is finally changing and significantly so.\nThe days of the persnickety, prima donna build machine where monolithic applications were built, tested, and deployed are numbered.\nAnd that is a \"Good Thing (tm)\" - a consequence of how we will meet the transformation goals of our businesses.\nModern applications consist of distributed services, often with multiple microservices that are developed and deployed independent of other services.\nHowever, the only way to build these services with their own dependencies and schedules is to bake in continuous integration and delivery from the beginning.\nAnd as usual, your Jenkins platform is your friend.\n\nBut let’s take a moment and think about that in the context of microservices, especially if you’ve only used Jenkins for monolithic applications.\nYou’ll be creating a greater number of individual Jenkins jobs that each run multiple times a day.\nThis is a significant process change, and it’s important to acknowledge this and change our approach to managing Jenkins to accommodate these changes.\nIt’s well within Jenkins’ capabilities, but you will need to think a little differently, and invest to close those last-mile deployment gaps.\n\nEvolution of my Jenkins Environment\n\nOne of the biggest challenges I’ve faced as a DevOps practitioner is a long and evolving set of options to manage my Jenkins agent infrastructure.\nWith only a few large jobs you don’t really need to worry too much about your agents.\nBut when you’re orchestrating the CI/CD pipelines for dozens or even hundreds of services, optimizing efficiency and minimizing cost becomes important.\nAnd that journey has allowed me to consider and test many different Jenkins build agent architectures over the years.\nThis journey may be familiar to you as well.\n\nThese are the types of Jenkins environments I’ve run over the years.\n\nExecute all the builds on the controller.\nConcentrate all the moving parts on one instance.\n(I call this Hello Jenkins)\n\nCreate a Jenkins EC2 agent with all the required tools for building every service, and then clone it if I need to “scale” Jenkins.\n(I call this the Monster Agent.)\n\nCreate an individual Jenkins EC2 agent for each service I need to build.\n(I call this the Snowflake Agent.)\n\nRun build steps in containers.\nFor example, launching agents in containers using the\nDocker Plugin or using multi-stage Dockerfiles to encapsulate all the logic for building, testing and packaging an application.\nThey are both good first steps in container abstraction and allow you to easily copy artifacts from one container to another.\nOf course, access to a Docker engine is required for either approach, and I’ve managed my Docker host(s) for running Jenkins agents several different ways:\n\nRun the Docker engine inside my Jenkins controller container - Docker in Docker (DinD)\n\nMount the Docker socket of the host on which my Jenkins controller container runs, allowing agents to run as sibling or sidecar containers - Docker outside of Docker (DooD)\n\nConfigure a single external EC2 Docker host for the Jenkins controller to use for launching builds in containers\n\nDynamically launch agents using the EC2 plugin with an AMI that contains the Docker Engine and then run all the steps in a multi-stage Dockerfile\n\nAll these approaches were attempts to get out of the business of curating and managing Jenkins agents and infrastructure, each with their own benefits and drawbacks.\nBut recently I begin working in a new Jenkins environment - Jenkins on Kubernetes.\n\nOnce you’ve come to view Jenkins, build agents and jobs as containerized services, migrating platforms becomes much more straightforward.\nAnd total disclaimer here - I had never used Kubernetes in my life, not even for side projects - when I set out to do this.\nThat said, it was surprisingly simple to create a Kubernetes cluster in Google Cloud Platform’s (GCP) GKE, launch a Jenkins controller using a\nHelm chart and begin running build steps in Jenkins agents running in containers on my new Kubernetes cluster.\n\nLaunch agents in Kubernetes from your pipeline scripts\n\nThe focus of this post and my Jenkins World talk for 2018, is to show you how to configure Jenkins to launch agents in Kubernetes from your pipeline scripts.\nMy examples assume you are launching your agents in the same Kubernetes cluster where your Jenkins controller is running, but there are other options.\nYou’ll begin by installing the\nKubernetes plugin.\nAs a bonus, when I installed Jenkins using the latest stable chart in the default Helm repository, the Kubernetes plugin was automatically installed for me.\n\nOnce you get the Jenkins controller running on your Kubernetes cluster, there are only a few configuration steps required and then you can begin launching ephemeral build agents on Kubernetes.\n\nConfigure the Jenkins controller\n\nYou’ll first need to create a credentials set for the Jenkins controller to access the Kubernetes cluster.\nTo do this, perform the following steps:\n\nIn the Jenkins UI, click the Credentials link in the left-hand navigation pane\n\nClick the arrow next to (global) in the Stores scoped to Jenkins table (you have to hover next to the link to see the arrow)\n\nClick Add Credentials\n\nUnder Kind, specify Kubernetes Service Account\n\nLeave the scope set to Global\n\nClick OK.\n\nThat’s it! This configuration allows the Jenkins controller to use a Kubernetes service account to access the Kubernetes API.\n\nCreate a Cloud Configuration on the Jenkins controller\n\nThe next step is to create a cloud configuration for your K8s cluster.\n(When I use K8s instead of Kubernetes it’s because it is quicker to type, not just for coolness.)\n\nIn the Jenkins UI, go to Manage Jenkins → Configure System\n\nScroll down until you see Cloud settings and click the Add a new cloud box and select kubernetes\n\nThe following parameters must be set:\n\nName : - This defaults to kubernetes\n\nKubernetes URL : https://kubernetes.default - This was automatically configured from the service account.\n\nKubernetes Namespace : default - Unless you are running your controller in another namespace\n\nCredentials :  Select the Kubernetes Service Account credentials you created in the previous step\n\nJenkins URL : http:// :8080\n\nJenkins tunnel : :5555 - This is the port that is used to communicate with an agent\n\nThese were the only parameters I had to set to launch an agent in my K8s cluster.\nYou can certainly modify other parameters to tweak your environment.\n\nNow that you’ve configured your Jenkins controller so that it can access your K8s cluster, it’s time to define some pods.\nA pod is the basic building block of Kubernetes and consists of one or more containers with shared network and storage.\nEach Jenkins agent is launched as a Kubernetes pod.\nIt will always contain the default JNLP container that runs the Jenkins agent jar and any other containers you specify in the pod definition.\nThere are at least two ways to configure pod templates – in the Jenkins UI and in your pipeline script.\n\nConfigure a Pod Template in the Jenkins UI\n\nIn the Jenkins UI, go to Manage Jenkins → Configure Systems\n\nScroll down to the cloud settings you configured in the previous step\n\nClick the Add Pod Template button and select Kubernetes Pod Template\n\nEnter values for the following parameters:\n\nName :\n\nNamespace : default - unless you configured a different namespace in the previous step\n\nLabels : - this will be used to identify the agent pod from your Jenkinsfiles\n\nUsage : Select \" Use this node as much as possible\" if you would like for this pod to be your default node when no node is specified.\nSelect \" Only build jobs with label matching expressions matching this node\" to use this pod only when its label is specified in the pipeline script\n\nThe name of the pod template to inherit from - you can leave this blank.\nIt will be useful once you gain experience with this configuration, but don’t worry about it for now.\n\nContainers : The containers you want to launch inside this pod.\nThis is described in detail below.\n\nEnvVars : The environment variables you would like to inject into your pod at runtime.\nThis is described in detail below.\n\nVolumes :  Any volumes you want to mount inside your pod.\nThis is described further below.\n\nRemember that a pod consists of one or more containers that live and die together.\nThe pod must always include a JNLP container, which is configured by default if you installed the controller using the Helm Chart.\nHowever, you will want to add containers with the tool chains required to build your application.\n\nAdd Your Own Container Template\n\nIn the Jenkins UI, return to the pod template you created in the last step\n\nClick the Add Container button and select Container Template\n\nEnter values in the following fields:\n\nName :\n\nDocker image : any Docker image you’d like\nFor example, if you are building an application written in Go, you can enter 'golang:1.11-alpine3.8'\n\nLabel : Enter any label strings you’d like to use to refer to this container template in your pipeline scripts\n\nAlways pull image : - Select this option if you want the plugin to pull the image each time a pod is created.\n\nYou can leave the default values for the other parameters, but you can see that the plugin gives you fine-grained control over your pod and the individual containers that run within it.\nAny values you might set in your Kubernetes pod configuration can be set via this plugin as well.\nYou can also inject your configuration data by entering raw YAML.\nI encourage you not to get distracted by the sheer number of options you can configure in this plugin.\nYou only have to configure a small subset of them to get a working environment.\n\nYou can click the Add Environment Variable button in the container template to inject environment variables into a specific container.\nYou can click the Add Environment Variable button in the pod template to inject environment variables into all containers in the pod.\nThe following environment variables are automatically injected into the default JNLP container to allow it to connect automatically to the Jenkins controller:\n\nJENKINS_URL : Jenkins web interface url\n\nJENKINS_JNLP_URL : url for the jnlp definition of the specific agent\n\nJENKINS_SECRET : the secret key for authentication\n\nJENKINS_NAME : the name of the Jenkins agent\n\nIf you click the Add Volume button in the pod template, you’ll see several options for adding volumes to your pod.\nI use the Host Path Volume option to mount the docker socket inside the pod.\nI can then run a container with the Docker client installed and use the host Docker socket to build and push Docker images.\n\nAt this point, we’ve created a cloud configuration for our Kubernetes cluster and defined a pod consisting of one or more containers.\nNow, how do we use this to run Jenkins jobs? We simply refer to the pod and containers by label in our Jenkins pipeline script.\nWe use the label we gave to the pod in the node block and the label for the container we wish to use in the container block.\nThe examples in this post use scripted pipeline, but you can achieve the same outcome using the declarative pipeline syntax:\n\nnode('test-pod') {\n    stage('Checkout') {\n        checkout scm\n    }\n    stage('Build'){\n        container('go-agent') {\n            // This is where we build our code.\n        }\n    }\n}\n\nDefining the Pod in the Jenkinsfile\n\nConfiguring a plugin through the UI is perfectly fine in a proof of concept.\nHowever, it does not result in a software-defined infrastructure that can be versioned and stored right alongside your source code.\nLuckily, you can create the entire pod definition directly in your Jenkinsfile.\nIs there anything you can’t do in a Jenkinsfile???\n\nAny of the configuration parameters available in the UI or in the YAML definition can be added to the podTemplate and containerTemplate sections.\nIn the example below, I’ve defined a pod with two container templates.\nThe pod label is used in the node block to signify that we want to spin up an instance of this pod.\nAny steps defined directly inside the node block but not in a container block with be run in the default JNLP container.\n\nThe container block is used to signify that the steps inside the block should be run inside the container with the given label.\nI’ve defined a container template with the label 'golang', which I will use to build the Go executable that I will eventually package into a Docker image.\nIn the volumes definition, I have indicated that I want to mount the Docker socket of the host, but I still need the Docker client to interact with it using the Docker API.\nTherefore, I’ve defined a container template with the label 'docker' which uses an image with the Docker client installed.\n\npodTemplate(\n    name: 'test-pod',\n    label: 'test-pod',\n    containers: [\n        containerTemplate(name: 'golang', image: 'golang:1.9.4-alpine3.7'),\n        containerTemplate(name: 'docker', image:'trion/jenkins-docker-client'),\n    ],\n    volumes: [\n        hostPathVolume(mountPath: '/var/run/docker.sock'),\n        hostPath: '/var/run/docker.sock',\n    ],\n    {\n        //node = the pod label\n        node('test-pod'){\n            //container = the container label\n            stage('Build'){\n                container('golang'){\n                    // This is where we build our code.\n                }\n            }\n            stage('Build Docker Image'){\n                container(‘docker’){\n                    // This is where we build the Docker image\n                }\n            }\n        }\n    })\n\nIn my Docker-based pipeline scripts, I was building Docker images and pushing them to a Docker registry, and it was important to me to replicate that exactly with my new Kubernetes setup.\nOnce I accomplished that, I was ready to build my image using gcloud, the Google Cloud SDK, and push that image to the Google Container Registry in anticipation of deploying to my K8s cluster.\n\nTo do this, I specified a container template using a gcloud image and changed my docker command to a gcloud command.\nIt’s that simple!\n\npodTemplate(\n    name: 'test-pod',\n    label: 'test-pod',\n    containers: [\n        containerTemplate(name: 'golang', image: 'golang:1.9.4-alpine3.7'),\n        containerTemplate(name: 'gcloud', image:'gcr.io/cloud-builders/gcloud'),\n    ],\n    {\n        //node = the pod label\n        node('test-pod'){\n            //container = the container label\n            stage('Build'){\n                container('golang'){\n                    // This is where we build our code.\n                }\n            }\n            stage('Build Docker Image'){\n                container(‘gcloud’){\n                    //This is where we build and push our Docker image.\n                }\n            }\n        }\n    })\n\nStanding up a Jenkins controller on Kubernetes, running ephemeral agents, and building and deploying a sample application only took me a couple of hours.\nI spent another weekend really digging in to better understand the platform.\nYou can be up and running in a matter of days if you are a quick study.\nThere are a wealth of resources available on running Jenkins on Kubernetes, and I hope this blog post helps to further that knowledge.\nEven better, come to\nmy session at Jenkins World and let’s talk in person.\n\nSo, what else do you want to know?\nHit me up on Twitter.\nI might even add your questions to my Jenkins World session.\nI suppose next up is Mesos?\n\nCome meet Mandy and other Jenkins and Kubernetes experts at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins and Kubernetes - Secret Agents in the Clouds","tags":["jenkinsworld","jenkinsworld2018","cloud-native","kubernetes"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#485858","images":{"fallback":{"src":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/19e71/devmandy.jpg","srcSet":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/77b35/devmandy.jpg 32w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/d4a57/devmandy.jpg 64w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/19e71/devmandy.jpg 128w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/68974/devmandy.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/ef6ff/devmandy.webp 32w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/8257c/devmandy.webp 64w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/6766a/devmandy.webp 128w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/22bfc/devmandy.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/devmandy.jpeg"},"blog":null,"github":"DevMandy","html":"<div class=\"paragraph\">\n<p>Mandy Hubbard has almost 20 years of professional QA experience,\nmost of which has been spent in fast-paced startup environments driving product quality.\nShe is passionate about ensuring quality through process improvements, test automation, following CI/CD best practices and all things DevOps.\nShe is currently a software engineer/QA architect at CS Disco, an innovative startup delivering a cloud-based eDiscovery platform.</p>\n</div>","id":"devmandy","irc":null,"linkedin":null,"name":"Mandy Hubbard","slug":"/blog/authors/devmandy","twitter":"DevMandy"}]}},{"node":{"date":"2018-08-30T00:00:00.000Z","id":"76fe30c4-d5ca-529d-af0c-044c46a5a864","slug":"/blog/2018/08/30/speaker-blog-kubernetes-plugin/","strippedHtml":"This is a guest blog by Niklas Tanskanen, consultant at\nEficode.\n\nKubernetes, the container orchestration platform is rapidly becoming popular. There are more and more workloads that you can run on top of Kubernetes. It’s becoming an enabling layer of your Hyper-convergenced infrastructure.\n\nIf you set up Kubernetes as a Cloud provider in Jenkins, you’ll get a very powerful couple for running your workloads.\nTo do that, you can simply install\nKubernetes plugin.\nKubernetes is able to run your Jenkins workloads as long as they are run in container.\nAnd containers are an awesome way if your workload is a build, because you can pack all your application and OS dependencies in a container and then run it anywhere!\n\nLet’s imagine that you have been running a Kubernetes cluster setup in your organisation for a while now.\nFirst it was all about proof of concept but now its becoming more popular within your developers and you have to think about scaling and orchestration.\nResource quotas are a part of that and every responsible operator should set those up both in both development and production clusters.\nOtherwise people will be lazy and just reserve all the resources of your cluster without actually using those resources for anything.\nBy introducing quotas into your cluster, you can control how many resources should each namespace have.\n\nQuotas are a mature feature of Kubernetes already.\nYou have the possibility to create very fine grained quotas for different hardware resources, whenever it’s fast disk, GPUs or CPU time.\nYou can also specify multiple scopes of quota per one namespace.\nFor example, you can have a quota for workloads that are to be run to the infinity like web servers or databases.\nOr have quota for workloads that are short lived like builds or test automation runs.\n\nTable 1. Scopes\n\nScope\nDescription\n\nTerminating\nMatch pods where.spec.activeDeadlineSeconds >= 0\n\nNotTerminating\nMatch pods where.spec.activeDeadlineSeconds is nil\n\nBestEffort\nMatch pods that have best effort quality of service.\n\nNotBestEffort\nMatch pods that do not have best effort quality of service.\n\nDifferent scopes of Kubernetes quota\n\nSince Jenkins is all about running short workloads, you should aim for the Terminating scope of quota.\nBut how do you specify workloads in Jenkins so that correct scope is used?\n\nIf you were to do this in Kubernetes, you have to specify.spec.activeDeadlineSeconds.\nThe same field can also be specified by the Kubernetes plugin when you are specifying a Pod Template.\n\nFigure 1. Specifying.spec.activeDeadlineSeconds in the Kubernetes plugin\n\nSame configuration is available in the Jenkinsfile as well if you don’t like static configurations.\n\npodTemplate(label: 'maven', activeDeadlineSeconds: 180, containers: [\n    containerTemplate(name: 'maven', image: 'maven:3.5.4-jdk-10-slim')\n  ]) {\n  // maven magic\n}\n\nThis was just a small sample of features of the Kubernetes plugin in Jenkins. For more, be sure to check out our\ntalk where we share more of how you can utilise Kubernetes with Jenkins!\n\nCome see Niklas Tanskanen and many other Jenkins experts and contributors at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Effectively using Kubernetes plugin with Jenkins","tags":["kubernetes","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":null,"blog":null,"github":"tanskann","html":"","id":"tanskann","irc":null,"linkedin":null,"name":"Niklas Tanskanen","slug":"/blog/authors/tanskann","twitter":null}]}},{"node":{"date":"2018-07-23T00:00:00.000Z","id":"bc08dba7-169b-5284-bbaa-6f3d64408472","slug":"/blog/2018/07/23/javadoc-service-improvements/","strippedHtml":"Jenkins infrastructure is continuously improving.\nThe latest service to get some attention and major improvement is the Jenkins javadoc.\n\nThere were a number of issues affecting that service:\n\nIrregular updates -\nDevelopers wouldn’t find the latest java documentation because of inadequate update frequence.\n\nBroken HTTPS support -\nwhen users would go to the Javadoc site they would get an unsafe site warning and then an incorrect redirection.\n\nObsolete content - Javadoc was not cleaned up correctly and plenty of obsolete pages remained which confused end users.\n\nAs Jenkins services\nmigrate to Azure infrastructure,\nsomething that needed to be done was to move the javadoc service there as a standalone service.\nI took the same approach as jenkins.io, putting data on an azure file storage, using a nginx proxy in front of it and running on kubernetes.\nThis approach brings multiple benefits:\n\nWe store static files on an azure file storage which brings data reliability, redundancy, etc.\n\nWe use Kubernetes Ingress to configure HTTP/HTTPS endpoint\n\nWe use Kubernetes Service to provide load balancing\n\nWe use Kubernetes deployment to deploy default nginx containers with azure file storage volume.\n\nHTTP/HTTPS workflow\n\n+----------------------+     goes on     +------------------------------+\n  |  Jenkins Developer   |---------------->+  https://javadoc.jenkins.io  |\n  +----------------------+                 +------------------------------+\n                                                                      |\n  +-------------------------------------------------------------------|---------+\n  | Kubernetes Cluster:                                               |         |\n  |                                                                   |         |\n  | +---------------------+     +-------------------+     +-----------v------+  |\n  | | Deployment: Javadoc |     | Service: javadoc  <-----| Ingress: javadoc |  |\n  + +---------------------+     +-------------------+     +------------------+  |\n  |                                           |                                 |\n  |                          -----------------+                                 |\n  |                          |                |                                 |\n  |                          |                |                                 |\n  | +------------------------v--+    +--------v------------------+              |\n  | | Pod: javadoc              |    | Pod: javadoc              |              |\n  | | container: \"nginx:alpine\" |    | container: \"nginx:alpine\" |              |\n  | | +-----------------------+ |    | +-----------------------+ |              |\n  | | | Volume:               | |    | | Volume:               | |              |\n  | | | /usr/share/nginx/html | |    | | /usr/share/nginx/html | |              |\n  | | +-------------------+---+ |    | +----+------------------+ |              |\n  | +---------------------|-----+    +------|--------------------+              |\n  |                       |                 |                                   |\n  +-----------------------|-----------------|-----------------------------------+\n                          |                 |\n                          |                 |\n                       +--+-----------------+-----------+\n                       |   Azure File Storage: javadoc  |\n                       +--------------------------------+\n\nThe javadoc static files are now generated by a Jenkins\njob regularly and then published from a trusted jenkins instance.\nWe only update what has changed and remove obsolete documents.\nMore information can be find\nhere\n\nThe next thing in continuously improving is also to look at the user experience of the javadoc to make it easier to discover javadoc for other components or versions.\n( Help Needed)\n\nThese changes all go towards improving the developer experience for those using javadocs and making life easier for core and plugin developers.\nSee the new and improved javadoc service here\nJenkins Javadoc.","title":"Jenkins Javadoc: Service Improvements","tags":["javadoc","azure","infrastructure","kubernetes"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/bf8e1/olblak.png","srcSet":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/914ee/olblak.png 32w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/1c9ce/olblak.png 64w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/bf8e1/olblak.png 128w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/acb7c/olblak.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/ef6ff/olblak.webp 32w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/8257c/olblak.webp 64w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/6766a/olblak.webp 128w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/22bfc/olblak.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/olblak.png"},"blog":null,"github":"olblak","html":"<div class=\"paragraph\">\n<p>Olivier is the Jenkins infrastructure officer and Senior Operations Engineer at CloudBees.\nAs a regular contributor to the Jenkins infrastructure projects, he works on a wide range of tasks from services reliability to applications maintenance.</p>\n</div>","id":"olblak","irc":"olblak","linkedin":null,"name":"Olivier Vernin","slug":"/blog/authors/olblak","twitter":"0lblak"}]}},{"node":{"date":"2018-07-19T00:00:00.000Z","id":"e791a263-9144-5400-9cc7-12e369131b87","slug":"/blog/2018/07/19/jenkins-x-accelerate/","strippedHtml":"Jenkins X uses Capabilities identified by the \"Accelerate:  The Science Behind Devops\"\n\nJenkins X is a reimagined CI/CD implementation for the Cloud which is heavily influence by the\nState of DevOps reports and more recently the book\n\"Accelerate: The Science Behind Devops\" by\nNicole Forsgren,\nJez Humble and\nGene Kim\n\nYears of gathering data from real world teams and organisations which has been analyzed by inspiring thought leaders and data\nscientists from the DevOps world, \"Accelerate\" recommends a number of capabilities that Jenkins X is implementing so\nusers gain the scientifically proven benefits, out of the box. We’ve started documenting the capabilities that are available\ntoday and will continue as more become available.\n\nCredit: thanks to tracymiranda for the image\n\nUse version control for all artifacts\n\nThe Weaveworks folks coined the term GitOps which we love.  Any change to an environment, whether it be a new application,\nversion upgrade, resource limit change or simple application configuration should be raised as a Pull Request to Git, have\nchecks run against it like a form of CI for environments and approved by a team that has control over what goes into the\nrelated environment.  We can now enable governance and have full traceability for any change to an environment.\n\nRelated Accelerate capability:  Use version control for all production artifacts\n\nAutomate your deployment process\n\nEnvironments\n\nJenkins X will automatically create Git backed environments during installation and makes it easy to add new ones using\njx create environment.  Additionally when creating new applications via a quickstart ( jx create quickstart), Java based\nSpringBoot ( jx create spring) or importing existing applications ( jx import), Jenkins X will both automatically add\nCI / CD pipelines and setup the jobs, git repos and webhooks to enable an automated deployment process.\n\nOut of the box Jenkins X creates Staging and Production (this is customisable) permanent environments as well as temporary\nenvironments for preview applications from Pull Requests.\n\nPreviews Environments\n\nWe are trying to move as much testing, security, validation and experimentation for a change before it’s merged to master.\nWith the use of temporary dynamically created Preview Environments any pull request can have a preview version built and\ndeployed, including libraries that feed into a downstream deployable application.  This means we can code review, test,\ncollaborate better with all teams that are involved in agreeing that change can go live.\n\nUltimately Jenkins X wants to provide a way that developers, testers, designers and product managers can be as sure as they\ncan that when a change is merged to master it works as expected.  We want to be confident the proposed change does not\nnegatively affect any service or feature as well as deliver the value it is intended to.\n\nWhere Preview Environments get really interesting is when we are able to progress a PR through various stages of maturity and\nconfidence where we begin to direct a percentage of real production traffic like beta users to it.  We can then analyse the\nvalue of the proposed change and possible run multiple automated experiments over time using Hypothesis Driven Development.\nThis helps give us better understanding of how the change will perform when released to all users.\n\nRelated Accelerate capability: Foster and enable team experimentation\n\nUsing preview environments is a great way to introduce better test automation.  While Jenkins X enables this we don’t yet\nhave examples of automated tests being run against a preview environment.  A simple test would be to ensure the application\nstarts ok and Kubernetes liveness check pass for an amount of time. This relates to\n\nRelated Accelerate capability: Implement Test Automation\nRelated Accelerate capability: Automate your deployment process\n\nPermanent Environments\n\nIn software development we’re used to working with multiple environments in the lead up to a change being promoted to a live\nproduction environment.  Whilst this seems business as usual it can cause significant delays to other changes if for any\nreason that it is deemed not fit via some process that didn’t happen pre merge to master.  Subsequent commits then become\nblocked and can cause delay of urgent changes being promoted to production.\n\nAs above Jenkins X wants any changes and experiments to be validated before it is merged to master.  We would like changes in\na staging environment to be held there for a short amount of time before being promoted, ideally in an automated fashion.\n\nThe default Jenkins X pipelines provide deployment automation via environments.  These are customisable to suite your own\nCI / CD pipeline requirements.\n\nJenkins X recommends Staging should act as a near as possible reflection on production, ideally with real production data\nshadowed to it using a service mesh to understand the behaviour.  This also helps when developing changes in preview where we\ncan link to non production services in staging.\n\nRelated Accelerate capability: Automate your deployment process\n\nUse trunk-based development\n\nThe Accelerate book found that teams which use trunk based development with short lived branches performed better.  This has\nalways worked for the Jenkins X core team members so this was an easy capability for Jenkins X to implement when setting up\nGit repositories and CI/CD jobs.\n\nImplement Continuous Integration\n\nJenkins X sees CI as the effort of validating a proposed change via pull requests before it is merged to controller.  Jenkins X\nwill automatically configure source code repositories, Jenkins and Kubernetes to provide Continuous Integration of the box.\n\nImplement Continuous Delivery\n\nJenkins X sees CD as the effort of taking that change after it’s been merged to controller through to running in a live\nenvironment.  Jenkins X automates many parts in a release pipeline:\n\nJenkins X advocates the use of semantic versioning.  We use git tags to calculate the next release version which means we\ndon’t need to store the latest release version in the controller branch.  Where release systems do store the last or next version\nin Git repos it means CD becomes hard, as a commit in a release pipeline back to controller triggers a new release.  This results\nin a recursive release trigger.  Using a Git tag helps avoid this situation which Jenkins X completely automates.\n\nJenkins X will automatically create a released version on every merge to master which can then potentially progress\nthrough to production.\n\nUse loosely coupled architecture\n\nBy targeting Kubernetes users of Jenkins X can take advantage of many of the cloud features that help design and develop\nloosely coupled solutions.  Service discovery, fault tolerance, scalability, health checks, rolling upgrades, container\nscheduling and orchestration to name just a few examples of where Kubernetes helps.\n\nArchitect for empowered teams\n\nJenkins X aims to help polyglot application developers.  Right now Jenkins X has quickstarts and automated CI/CD setup with\nlanguage detection for Golang, Java, NodeJS, .Net, React, Angular, Rust, Swift and more to come.  What this also does is\nprovide a consistent Way of Working so developers can concentrate on developing.\n\nJenkins X also provides many addons, for example Grafana and Prometheus for automated metrics collection and visualisation.\nIn this example centralised metrics help understand how your applications behave when built and deployed on Kubernetes.\n\nDevPods are another feature which enables developers to edit source code in their\nlocal IDE, behind the scenes it is then synced to the cloud and rapidly built and redeployed.\n\nJenkins X believes providing developers automation that helps them experiment in the cloud, with different technologies and\nfeedback empowers them to make the best decisions - faster.\n\nFancy a closer look?\n\nMyself, James Strachan and\nRob Davies are going to be presenting and running workshops at\nDevOps World  | Jenkins World.  We’ll also be hanging out at the Jenkins X demo\narea so come and say hello and see what’s the latest cool and exiting things to come out of Jenkins X.  Use JWFOSS for 30%\ndiscount off registration\n\nWant to get involved?\n\nJenkins X is open source, the community mainly hangs out in the\nJenkins X Kubernetes slack channels and for tips on being more involved with Jenkins X\ntake a look at our contributing docs.  We’ve been helping lots of folks get into open source, learn\nnew technoligies and languages like golang.  Why not get involved?\n\nDemo\n\nIf you’ve not already seen it here’s a video showing a spring boot quickstart with automatic CI/CD pipelines and preview environments.","title":"Accelerate with Jenkins X","tags":["jenkinsx","developer","kubernetes"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/jrawlings.jpeg"},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-05-08T00:00:00.000Z","id":"29ad061f-dba2-536d-91b4-878d290af36d","slug":"/blog/2018/05/08/jenkins-x-anchore/","strippedHtml":"Anchore provides docker image analysis for user defined acceptance policies to allow automated image validation and acceptance.\n\nAs developers we would like to know if a change we are proposing introduces a\nCommon Vulnerability and Exposure (CVE).\nAs operators we would like to know what running applications are affected if a new CVE is discovered.\n\nNow in Jenkins X pipelines, if we find an\nAnchore engine service running we will add the preview and release images to be analyzed.\nThis means we can look at any environment including previews (created from Pull Requests)\nto see if your application contains a CVE.\n\nUpgrade\n\nStart by checking your current Jenkins X version:\n\njx version\n\nIf your Jenkins X platform is older than 0.0.903, then first you will need to upgrade to at least 0.0.922:\n\njx upgrade cli\njx upgrade platform\n\nInstall addon\n\nYou can install the\nAnchore engine addon\nwhen you are in your Jenkins X team home environment.\n\njx env dev\njx create addon anchore\n\nThis will install the engine in a seperate anchore namespace\nand create a service link in the current team home environment\nso our pipeline builds can add docker images to Anchore for analysis.\n\nCreate an application\n\nYou can now create a new quickstart:\n\njx create quickstart\n\nList any CVEs\n\nOnce the build has run you will be able to check for CVEs in any environment incluing previews created for pull requests.\n\njx get cve --environment staging\n\nDemo\n\nHere’s a 4 minute video that demonstrates the steps above:\n\nUpgrading existing pipelines\n\nIf you have an existing application pipeline and and want enable image analysis you can update your Jenkinsfile,\nin the preview stage after the skaffold step add the line\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:$PREVIEW_VERSION\"\n\nIn the master stage the add this line after the skaffold step\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:\\$(cat VERSION)\"\n\nFor any questions please find us - we mainly hang out on Slack at\n#jenkins-x-dev - or see\njenkins-x.io/community for other channels.","title":"Jenkins X: Announcing CVE docker image analysis with Anchore","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/jrawlings.jpeg"},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-04-16T00:00:00.000Z","id":"5bccde5f-c4ec-5989-8dc2-3f6097a019eb","slug":"/blog/2018/04/16/jenkins-x-explained-part1/","strippedHtml":"Jenkins X is an opinionated platform for providing CI / CD on top of\nKubernetes.\nWe’ve chosen a set of core applications that we install and wire together so things work out-of-the-box, providing a\nturn key experience. This blog aims to build on previous introductions to Jenkins X and provide a deeper\ninsight to what you get when you install Jenkins X.\n\nSo what happens? After downloading the jx CLI you will now be able to create clusters with public cloud providers\nor install onto an existing Kubernetes cluster.\n\nThis command will create a cluster on your cloud provider of choice.\n\njx create cluster\n\nAlternatively you can bring your own Kubernetes cluster and install Jenkins X on it:\n\njx install\n\nThat said, we’ve found that creating a new cluster on a public cloud such as GKE\nis a lot way easier to start as we can be sure of the state of the cluster.\nFor example we know that storage, networking and loadbalancers will be working as expected.\nCreating a cluster on GKE takes only a few minutes so it’s a great way to try things out as well as run your\nenterprise workloads.\n\nFor now lets assume we are using GKE. When jx create cluster has finished you will see some output in the\nterminal that also includes the default admin password to use when logging into the core applications below.\nThere is a flag --default-admin-password you can use to set this password yourself.\n\nAccessing applications\n\nWe automatically install an Nginx ingress controller running with an external loadbalancer pointing at it’s\nKubernetes service. We also generate all the Kubernetes Ingress rules using a golang library called\n\" exposecontroller\".\nThis runs as a Kubernetes Job triggered by a\nHelm hook once any application is installed to the cluster.\n\nUsing \"exposecontroller\" means we can control all the ingress rules for an environment using a single set of\nconfigurations, rather than each application needing to know how to expose the kubernetes service to the outside world.\nThis also means we can easily switch between HTTP and HTTPS plus support intregration with projects like\ncert-manager for auto generation of signed TLS certificates.\n\nEnvironments\n\nOne important point to make is Jenkins X aims to use terminology that developers are familiar with. That’s not\nto say we are changing Kubernetes fundamentals, it’s more that if you don’t know Kubernetes concepts then we aim\nto help you still adopt the cloud technology and pull back the curtain as you gain confidence and experience.\nTo that point, a core part of Jenkins X are \"environments\". An environment can have one or more applications running\nin it. In Kubernetes term an \"environment\" maps to the concept of a \"namespace\" in code.\n\nThe installation by default created three environments, this is customisable but by default we have a \"dev\", a \"staging\"\nand a \"production environment\". To list, select, or switch between these environments run:\n\njx env\n\nJenkins X core applications\n\nIn the \"dev\" environment we have installed a number of core applications we believe are required at a minimum\nto start folks off with CI/CD on Kubernetes. We can easily add to these core apps using Jenkins X addons but\nfor now lets focus on the core apps. Jenkins X comes with configuration that wires these services together,\nmeaning everything works together straight away. This dramatically reduces the time to get started with Kubernetes\nas all the passwords, environment variables and config files are all setup up to work with each other.\n\nJenkins — provides both CI and CD automation. There is an effort to decompose Jenkins over time to\nbecome more cloud native and make use of Kubernetes concepts around CRDs, storage and scaling for example.\n\nNexus — acts as a dependency cache for Nodejs and Java applications to dramatically improve build\ntimes. After an initial build of a SpringBoot application the build time is reduced from 12 mins to 4. We\nhave not yet but intend to demonstrate swapping this with Artifactory soon.\n\nDocker Registry — an in cluster docker registry where our pipelines push application images, we will\nsoon switch to using native cloud provider registries such as Google Container Registry, Azure Container\nRegistry or Amazon Elastic Container Registry (ECR) for example.\n\nChartmuseum — a registry for publishing Helm charts\n\nMonocular — a UI used for discovering and running Helm charts\n\nHelm\n\nWe learned a lot in our early days with fabric8 on Kubernetes and there were some projects from the ecosystem\nthat either weren’t around or (at the time) didn’t work with OpenShift, therefore we were restricted when\nmaking some design decisions. A couple of years on and now with Jenkins X we were able to look at other OSS\nprojects that have been flourishing, so I was very happy to start looking at Helm.\nHelm is a package manager for Kubernetes and allows easy installation and upgrades of applications.\n\nIt was pretty clear that for Jenkins to evolve and include deployments to the cloud we should embrace Helm\nand provide an opinionated experience that helps teams and developers. The core applications mentioned above\nmeans Jenkins X provides an out of the box integrated CI/CD solution for Helm.\n\nWe know that helm has limitations but with the work on\nHelm 3, the focus of the Kubernetes\nsig-apps group, the Kubernetes community and investment we see from key organisations such as Microsoft, we feel Helm\nis currently the best way to install and upgrade applications on Kubernetes.\n\nGitOps\n\nWe mentioned earlier that we setup three environments by default. What this means is for the staging and production\nenvironments we created:\n\nKubernetes namespace\n\nAn environment resource ( CustomResourceDefinition)\nin the dev environment which includes details of how applications are promoted to it and includes various team\nsettings.\n\nA git repository that we store what applications and their versions should be present in that environment.\nThese are stored in a Helm requirements.yaml file\n\nA Jenkins Pipeline job: explained in more detail below\n\nCI/CD for Environments\n\nHaving a Jenkins Pipeline Job for each environment means that Pull Requests to the git repo trigger a CI\njob.  For now that job performs basic validation but in the future will include ‘gates’ to ensure a change to that\nenvironment has passed expected checks such as QA tasks, gain enough approvals from the correct people, etc -\nYES CI for environments!\n\nOnce CI checks have passed the new application or version change can be merged. Only users that have karma\ncan merge the Pull Request and therefore we get RBAC plus traceability for our environment deployments.\n\nThis means every application manifest, their version and configuration including storage requirements, resource\nneeds and secrets for your environments are stored in Git repositories. Given a disaster recovery scenario this\nis exactly what you want.\n\nDid I just say secrets in Git? Yes! We will be providing a nicer experience to helps folks get set up but we\nourselves encrypt our secrets and  store them in Git, then decrypt them when we come to install and upgrade.\n\nHere’s our Git repo https://github.com/jenkins-x/cloud-environments/blob/a1edcc6/env-jx-infra/secrets.yaml.\n\nWe do all this with the help of a Helm wrapper called helm secrets.\nI’m working on a followup blog post with examples, better explanations and how to guides + add better integration\nwith JX in the coming weeks.\n\nFancy getting involved?\n\nWe mainly hangout in the jenkins-x Kubernetes slack channels and for tips on\nbeing more involved with Jenkins X take a look at our contributing docs\n\nIf you’ve not already seen it here’s a video showing the create cluster explained in this blog.","title":"Jenkins X Explained Part 1 - an integrated CI/CD solution for Kubernetes","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/jrawlings.jpeg"},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-04-13T00:00:00.000Z","id":"31f8965a-bc62-54ab-a155-4d858e063b0e","slug":"/blog/2018/04/13/jenkins-x-23-days-later/","strippedHtml":"Its been 24 days since we\nannounced Jenkins X,\na CI/CD solution for modern cloud applications on Kubernetes.\nI’m truly blown away by the response and feedback from the community - thank you!\n\nWe’ve also had lots of folks report they’ve successfully used Jenkins X\non a number of clouds including GKE, AWS and AKS along with on-premises clusters which is great to hear!\n\nHere’s a brief overview of the changes in the last 24 days from the\nRoadmap :\n\nwe now fully support GitHub and GitHub enterprise. BitBucket cloud and gitea is almost there too.\nHopefully BitBucketServer and Gitlab are not too far away either. For more detail see\nsupporting different git servers\n\nFor issue tracking we support GitHub, GitHub Enterprise and JIRA. For more detail see\nsupporting issue trackers\n\nGradle support is now available from jx create spring\nor by importing gradle apps\n\nGo, Node and Rust build packs are now available with more planned\n\nNew addons for anchore and kubeless\n\nAlso we’ve made it a little bit easier to keep your jx binary up to date continuously. Just type one of the following:\n\njx version will prompt you if there is a new version available\nand if prompted, it will upgrade itself\n\njx upgrade cli will upgrade the jx binary if its available or\njx upgrade platform for the platform\n\nFor more detail on the changes over the last 24 days with metrics please see the\nchangelog generated by Jenkins X\n\nWe’d love to hear your feedback what you think of\nJenkins X and the\nRoadmap - please\njoin the community.\n\nLinks\n\nJenkins X website\n\nDemos\n\nJenkins X JEP proposal","title":"Jenkins X making awesome progress after 24 days","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/19e71/jstrachan.jpg","srcSet":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/77b35/jstrachan.jpg 32w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/d4a57/jstrachan.jpg 64w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/19e71/jstrachan.jpg 128w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/68974/jstrachan.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/ef6ff/jstrachan.webp 32w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/8257c/jstrachan.webp 64w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/6766a/jstrachan.webp 128w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/22bfc/jstrachan.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/jstrachan.jpeg"},"blog":null,"github":"jstrachan","html":"<div class=\"paragraph\">\n<p>James is a long time open source contributor, created the Groovy programming language and Apache Camel integration framework.\nFor the past few years he&#8217;s been working on CI/CD with Kubernetes.</p>\n</div>","id":"jstrachan","irc":null,"linkedin":null,"name":"James Strachan","slug":"/blog/authors/jstrachan","twitter":"jstrachan"}]}}]}},"pageContext":{"tag":"kubernetes","limit":8,"skip":8,"numPages":3,"currentPage":2}},
    "staticQueryHashes": ["3649515864"]}