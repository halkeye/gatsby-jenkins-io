{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/infrastructure",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2021-09-04T00:00:00.000Z","id":"38e8b09f-3f33-59fc-a9a2-2d18aa09a4fe","slug":"/blog/2021/09/04/wiki-attacked/","strippedHtml":"Earlier this week the Jenkins infrastructure team identified a successful attack against our deprecated Confluence service.\nWe responded immediately by taking the affected server offline while we investigated the potential impact.\nAt this time we have no reason to believe that any Jenkins releases, plugins, or source code have been affected.\n\nThus far in our investigation, we have learned that the Confluence CVE-2021-26084 exploit was used to install what we believe was a Monero miner in the container running the service.\nFrom there an attacker would not be able to access much of our other infrastructure.\nConfluence did integrate with our integrated identity system which also powers Jira, Artifactory, and numerous other services.\n\nThe trust and security in Jenkins core and plugin releases is our highest priority.\nWe do not have any indication that developer credentials were exfiltrated during the attack.\nAt the moment we cannot assert otherwise and are therefore assuming the worst.\nWe are taking actions to prevent releases at this time until we re-establish a chain of trust with our developer community.\nWe have reset passwords for all accounts in our integrated identity system.\nWe are improving the password reset system as part of this effort.\n\nAt this time, the Jenkins infrastructure team has permanently disabled the Confluence service, rotated privileged credentials, and taken proactive measures to further reduce the scope of access across our infrastructure.\nWe are working closely with our colleagues at the Linux Foundation and the Continuous Delivery Foundation to ensure that infrastructure which is not directly managed by the Jenkins project is also scrutinized.\n\nIn October 2019 we made the Confluence server read-only effectively deprecating it for day-to-day use within the project.\nAt that time, we began migrating documentation and changelogs from the wiki to GitHub repositories.\nThat migration has been ongoing, with hundreds of plugins and many other documentation pages moved from the wiki to GitHub repositories.\n\nWe are grateful for those of you who followed our responsible disclosure procedure and reached out to us about this vulnerability affecting the Jenkins project.\n\nWe will continue to take proactive measures to improve the security of our infrastructure and encourage you to follow us on Twitter for further updates.","title":"Jenkins project Confluence instance attacked","tags":["infrastructure","security"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"markewaite","html":"<div class=\"paragraph\">\n<p>Mark is the <a href=\"/project/team-leads/#documentation\">Jenkins Documentation Officer</a>, a long-time Jenkins user and contributor, and maintains the <a href=\"https://plugins.jenkins.io/git\">git plugin</a> and the <a href=\"https://plugins.jenkins.io/git-client\">git client plugin</a>.\nHe is active in <a href=\"/sigs/\">Jenkins special interest groups</a> including the <a href=\"/sigs/docs/\">Docs SIG</a>, <a href=\"/sigs/platform\">Platform SIG</a>, and <a href=\"/sigs/advocacy-and-outreach\">Advocacy SIG</a>.</p>\n</div>","id":"markewaite","irc":"markewaite","linkedin":"markwaite","name":"Mark Waite","slug":"blog/author/markewaite","twitter":"MarkEWaite"},{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2020-12-17T00:00:00.000Z","id":"9753ae32-51e9-5bc8-9342-e525dab1f74c","slug":"/blog/2020/12/17/jira-upgrade-for-the-jenkins-project/","strippedHtml":"The Jenkins project has used Jira to track issues for many years.\nJenkins core, Jenkins modules, Jenkins infrastructure, and many Jenkins plugins manage their issue reports with our Jira server.\n\nJira helps the Jenkins project manage issues and tasks related to over 250 000 Jenkins installations.\nIt tracks bugs, enhancement requests, tasks, and security issues.\nIt is used regularly by users around the world.\n\nWe’re grateful for the long-standing contribution that Atlassian provides by donating the Jira license to the Jenkins project.\nWe’re grateful to the Oregon State University Open Source Lab for their donation of equipment and bandwidth to host the server.\n\nUpgrade Timeline\n\nWe were running Jira 7.13 and had been managing that installation for a few years.\nAtlassian announced that Jira 7.13 would end its support life on November 28, 2020.\nWe needed to upgrade from Jira 7.13 to a more recent version of Jira.\nAs part of our membership in the Continuous Delivery Foundation, a Linux Foundation initiative, we could use their project services team to manage our Jira server.\nWe decided to move from hosting our own Jira server to having the Jira experts at the Linux Foundation host it.\n\nThe upgrade timeline looked like this:\n\nNovember 2019 - Infrastructure team begins discussions about the November 2020 end of support for Jira 7.13\n\nAugust 2020 - First conversations with Linux Foundation to host Jira for the Jenkins project.  Draft of the upgrade plan assembled and shared with the community\n\nSeptember 2020 - Schedule for testing week and final transition week proposed.  Authentication options evaluated and selected\n\nOctober 2020 - Test upgrade performed and tested\n\nNovember 2020 - Final upgrade completed and verified\n\nConfronting the Complications\n\nInitial discussions between the Jenkins infrastructure team and the Linux Foundation identified complications related to authentication and SSL certificates.\nWe planned, negotiated, and tested our assumptions throughout the project.\n\nAuthentication\n\nJira servers at the Linux Foundation typically use Linux Foundation accounts for user access.\nUnfortunately, the Jenkins LDAP database includes over 100,000 users and for many of them, Linux Foundation username doesn’t correspond to Jenkins account username.\nIt was not feasible to transition 100,000 user accounts from the Jenkins LDAP database to the Linux Foundation accounts system and still complete the Jira upgrade before the November 28, 2020 deadline.\n\nThe Linux Foundation Project Services team evaluated authentication alternatives and confirmed that they could use the Jenkins LDAP server.\nUsing the Jenkins LDAP server spared us from two transitions, LDAP and Jira, and kept the project timeline feasible.\n\nSSL Certificates\n\nJira servers at the Linux Foundation use Let’s Encrypt to generate SSL certificates for HTTPS.\nThe Linux Foundation uses the DNS method to obtain SSL certificates.\nUnfortunately, the Jenkins project uses the HTTP method to obtain SSL certificates.\n\nThankfully, Olivier Vernin of the Jenkins project and Anton Baranov of the Linux Foundation found a solution.\nThey created an ACME record in the Jenkins DNS server and pointed the issues.jenkins.io DNS record at the new Linux Foundation Jira server.\n\nBuilding the Prototype\n\nAnton Baranov created a prototype Jira server, restored an older Jenkins Jira backup, and upgraded it to Jira 8.13.\nThat first restore detected that we had not provided the Jira attachments or the Jira avatars.\nThat attachments and avatars added multiple gigabytes to the initial backup data and were vital to complete the update.\n\nTesting the Upgrade\n\nA group of volunteers including Jenkins users, security team members, and infrastructure team members tested the upgrade during the week of October 26, 2020.\nThe tests confirmed that authentication worked as expected and that the Jira prototype was functioning as expected.\n\nWe thank the test team, including:\n\nDaniel Beck\n\nTim Jacomb\n\nOlivier Vernin\n\nMark Waite\n\nThe tests included:\n\nCreating and routing issues\n\nCommenting on issues\n\nViewing dashboards with the expected content\n\nLDAP settings\n\nEmail notification\n\nThe tests detected minor issues that Anton was able to correct in preparation for the final upgrade.\nThe testing team agreed that the tests were successful.\n\nDeploying the Upgrade\n\nOlivier Vernin announced the final upgrade by email to the Jenkins infra list with details of the changes happening during the upgrade.\nMonday, November 9, 2020, the final backup of the existing Jira server was copied into the new Linux Foundation server.\n\nThe final upgrade encountered issues that we had not seen during the initial tests.\nThe \"bumps and bruises\" from the unexpected issues were resolved by Anton Baranov as he used a multi-step upgrade process.\nThe steps included:\n\nRestore the earlier backup to Jira 7.13\n\nRestore the most recent backup\n\nUpgrade to Jira 8.13\n\nInstall avatars, attachments, and other images\n\nUpdate DNS entries to point to the new Jenkins Jira server\n\nLessons from the Upgrade\n\nLessons were related to timing, estimation, and communication.\n\nScheduling the Upgrade\n\nThe test upgrade started the week of October 19, 2020.\nIt took several days longer than originally expected.\nThankfully, we had allowed an extra week between the test upgrade and the production upgrade.\n\nThe originally announced schedule for the final upgrade was intentionally placed in a week that would not include a long term support release.\nThat reduced the risk of disruption if the upgrade took longer than required or failed and we had to roll back.\n\nEstimating the Work\n\nDiscussions with the Jenkins project Jira administrators and the Linux Foundation Jira experts provided very reasonable estimates of time to complete the work.\nWe intentionally allowed additional time between first test and final upgrade.\nWe needed that additional time and used it well as the testing week.\n\nCommunicating the Plan\n\nThe distributed nature of the Jenkins project makes communication challenging for major changes.\nWe communicated plans at various stages but still found occasions where the communication was insufficient.\nIn this case, the adage held true that it is, \"impossible to communicate too much\".\n\nThanks for your patience during the upgrade and thanks to the Linux Foundation for administering the Jenkins Jira server.","title":"Jira upgrade for the Jenkins project","tags":["jenkins","infrastructure","jira"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"markewaite","html":"<div class=\"paragraph\">\n<p>Mark is the <a href=\"/project/team-leads/#documentation\">Jenkins Documentation Officer</a>, a long-time Jenkins user and contributor, and maintains the <a href=\"https://plugins.jenkins.io/git\">git plugin</a> and the <a href=\"https://plugins.jenkins.io/git-client\">git client plugin</a>.\nHe is active in <a href=\"/sigs/\">Jenkins special interest groups</a> including the <a href=\"/sigs/docs/\">Docs SIG</a>, <a href=\"/sigs/platform\">Platform SIG</a>, and <a href=\"/sigs/advocacy-and-outreach\">Advocacy SIG</a>.</p>\n</div>","id":"markewaite","irc":"markewaite","linkedin":"markwaite","name":"Mark Waite","slug":"blog/author/markewaite","twitter":"MarkEWaite"}]}},{"node":{"date":"2020-10-21T00:00:00.000Z","id":"7c9b1586-7a87-5fd5-8543-1a27aa94a68f","slug":"/blog/2020/10/21/a-sustainable-pattern-with-shared-library/","strippedHtml":"Table of Contents\n\nContext\nThe Problems\nThe Solution\n\nShared Library\nDuplication\nDocumentation\nScalability\nInstallation Agnostic\nFeature Toggling\n\nThis post will describe how I use a shared library in Jenkins. Typically when using multibranch pipeline.\n\nIf possible (if not forced to) I implement the pipelines without multibranch. I previously wrote about how I do that with my Generic Webhook Trigger Plugin in a previous post. But this will be my second choice, If I am not allowed to remove the Jenkinsfile :s from the repositories entirely.\n\nContext\n\nWithin an organization, you typically have a few different kinds of repositories. Each repository versioning one application. You may use different techniques for different kinds of applications. The Jenkins organization on GitHub is an example with 2300 repositories.\n\nThe Problems\n\nLarge Jenkinsfiles in every repository containing duplicated code. It seems common that the Jenkinsfile :s in every repository contains much more than just the things that are unique for that repository. The shared libraries feature may not be used, or it is used but not with an optimal pattern.\n\nInstallation specific Jenkinsfile:s that only work with one specific Jenkins installation. Sometimes I see multiple Jenkinsfile :s, one for each purpose or Jenkins installation.\n\nNo documentation and/or no natural place to write documentation.\n\nDevelopment is slow. Adding new features to repositories is a time consuming task. I want to be able to push features to 1000+ repositories without having to update their Jenkinsfile :s.\n\nNo flexible way of doing feature toggling. When maintaining a large number of repositories it is sometimes nice to introduce a feature to a subset of those repositories. If that works well, the feature is introduced to all repositories.\n\nThe Solution\n\nMy solution is a pattern that is inspired by how the Jenkins organization on GitHub does it with its buildPlugin(). But it is not exactly the same.\n\nShared Library\n\nHere is how I organize my shared libraries.\n\nJenkinsfile\n\nI put this in the Jenkinsfile :s:\n\nbuildRepo()\n\nDefault Configuration\n\nI provide a default configuration that any repository will get, if no other configuration is given in buildRepo().\n\nI create a vars/getConfig.groovy with:\n\ndef call(givenConfig = [:]) {\n  def defaultConfig = [\n    /**\n      * The Jenkins node, or label, that will be allocated for this build.\n      */\n    \"jenkinsNode\": \"BUILD\",\n    /**\n      * All config specific to NPM repo type.\n      */\n    \"npm\": [\n      /**\n        * Whether or not to run Cypress tests, if there are any.\n        */\n      \"cypress\": true\n    ],\n    \"maven\": [\n      /**\n        * Whether or not to run integration tests, if there are any.\n        */\n      \"integTest\": true\n    ]\n  ]\n  // https://e.printstacktrace.blog/how-to-merge-two-maps-in-groovy/\n  def effectiveConfig merge(defaultConfig, givenConfig)\n  println \"Configuration is documented here: https://whereverYouHos/getConfig.groovy\"\n  println \"Default config: \" + defaultConfig\n  println \"Given config: \" + givenConfig\n  println \"Effective config: \" + effectiveConfig\n  return effectiveConfig\n}\n\nBuild Plan\n\nI construct a build plan as early as possible. Taking decisions on what will be done in this build. So that the rest of the code becomes more streamlined.\n\nI try to rely as much as possible on conventions. I may provide configuration that lets users turn off features, but they are otherwise turned on if they are detected.\n\nI create a vars/getBuildPlan.groovy with:\n\ndef call(effectiveConfig = [:]) {\n  def derivedBuildPlan = [\n    \"repoType\": \"NOT DETECTED\"\n    \"npm\": [],\n    \"maven\": []\n  ]\n\n  node {\n    deleteDir()\n    checkout([$class: 'GitSCM',\n      branches: [[name: '*/branchName']],\n      extensions: [\n          [$class: 'SparseCheckoutPaths',\n            sparseCheckoutPaths:\n            [[$class:'SparseCheckoutPath', path:'package.json,pom.xml']]\n          ]\n      ],\n      userRemoteConfigs: [[credentialsId: 'someID',\n      url: 'git@link.git']]\n    ])\n\n    if (fileExists('package.json')) {\n      def packageJSON = readJSON file: 'package.json'\n      derivedBuildPlan.repoType = \"NPM\"\n      derivedBuildPlan.npm.cypress = effectiveConfig.npm.cypress && packageJSON.devDependencies.cypress\n      derivedBuildPlan.npm.eslint = packageJSON.devDependencies.eslint\n      derivedBuildPlan.npm.tslint = packageJSON.devDependencies.tslint\n    } else if (fileExists('pom.xml')) {\n      derivedBuildPlan.repoType = \"MAVEN\"\n      derivedBuildPlan.maven.integTest = effectiveConfig.maven.integTest && fileExists('src/integtest')\n    } else {\n      throw RuntimeException('Unable to detect repoType')\n    }\n\n    println \"Build plan: \" + derivedBuildPlan\n    deleteDir()\n  }\n  return derivedBuildPlan\n}\n\nPublic API\n\nThis is the public API, this is what I want the users of this library to actually invoke.\n\nI implement a buildRepo() method that will use that default configuration. It can also be called with a subset of the default configuration to tweak it.\n\nI create a vars/buildRepo.groovy with:\n\ndef call(givenConfig = [:]) {\n  def effectiveConfig = getConfig(givenConfig)\n  def buildPlan = getBuildPlan(effectiveConfig)\n\n  if (effectiveConfig.repoType == 'MAVEN')\n    buildRepoMaven(buildPlan);\n  } else if (effectiveConfig.repoType == 'NPM')\n    buildRepoNpm(buildPlan);\n  }\n}\n\nA user can get all the default behavior with:\n\nbuildRepo()\n\nA user can also choose not to run Cypress, even if it exists in the repository:\n\nbuildRepo([\n  \"npm\": [\n    \"cypress\": false\n  ]\n])\n\nSupporting Methods\n\nThis is usually much more complex, but I put some code here just to have a complete implementation.\n\nI create a vars/buildRepoNpm.groovy with:\n\ndef call(buildPlan = [:]) {\n  node(buildPlan.jenkinsNode) {\n    stage(\"Install\") {\n      sh \"npm install\"\n    }\n    stage(\"Build\") {\n      sh \"npm run build\"\n    }\n    if (buildPlan.npm.tslint) {\n      stage(\"TSlint\") {\n        sh \"npm run tslint\"\n      }\n    }\n    if (buildPlan.npm.eslint) {\n      stage(\"ESlint\") {\n        sh \"npm run eslint\"\n      }\n    }\n    if (buildPlan.npm.cypress) {\n      stage(\"Cypress\") {\n        sh \"npm run e2e:cypress\"\n      }\n    }\n  }\n}\n\nI create a vars/buildRepoMaven.groovy with:\n\ndef call(buildPlan = [:]) {\n  node(buildPlan.jenkinsNode) {\n    if (buildPlan.maven.integTest) {\n      stage(\"Verify\") {\n        sh \"mvn verify\"\n      }\n    } else {\n      stage(\"Package\") {\n        sh \"mvn package\"\n      }\n    }\n  }\n}\n\nDuplication\n\nThe Jenkinsfile :s are kept extremely small. It is only when they, for some reason, diverge from the default config that they need to be changed.\n\nDocumentation\n\nThere is one single point where documentation is written, the getConfig.groovy -file. It can be referred to whenever someone asks for documentation.\n\nScalability\n\nThis is a highly scalable pattern. Both with regards to performance and maintainability in code.\n\nIt scales in performance because the Jenkinsfile :s can be used by any Jenkins installation. So that you can scale by adding several completely separate Jenkins installations, not only nodes.\n\nIt scales in code because it adds just a tiny Jenkinsfile to repositories. It relies on conventions instead, like the existence of attributes in package.json and location of integration tests in src/integtest.\n\nInstallation Agnostic\n\nThe Jenkinsfile :s does not point at any implementation of this API. It just invokes it and it is up to the Jenkins installation to implement it, with a shared libraries.\n\nIt can even be used by something that is not Jenkins. Perhaps you decide to do something in a Docker container, you can still parse the Jenkinsfile with Groovy or (with some magic) with any language.\n\nFeature Toggling\n\nThe shared library can do feature toggling by:\n\nLetting some feature be enabled by default for every repository with name starting with x.\n\nOr, adding some default config saying\"feature-x-enabled\": false, while some repos change their Jenkinsfile :s to buildRepo([\"feature-x-enabled\": true]).\n\nWhenever the feature feels stable, it can be enabled for everyone by changing only the shared library.","title":"A sustainable pattern with shared library","tags":["pipeline","scalability","sharedlibrary","infrastructure"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://bjurr.com/","github":"tomasbjerre","html":"<div class=\"paragraph\">\n<p>Tomas Bjerre is an experienced fullstack software developer. Been working full time since 2010 after graduating with a masters degree in computer science from Lund University (Faculty of Engineering, LTH). Is currently working full time and maintaining a bunch of Jenkins plugins on his spare time.</p>\n</div>","id":"tomasbjerre","irc":null,"linkedin":"tomasbjerre","name":"Tomas Bjerre","slug":"blog/author/tomasbjerre","twitter":null}]}},{"node":{"date":"2020-06-17T00:00:00.000Z","id":"d04987cd-4df5-5758-b9a2-2f39da9d1862","slug":"/blog/2020/06/17/infra-and-aws-donation/","strippedHtml":"The Jenkins project relies heavily on its infrastructure.\nWe use websites like www.jenkins.io and plugins.jenkins.io, ticketing systems like issues.jenkins.io, CI/CD infrastructure like ci.jenkins.io, and many other services.\nJust to provide some context about the Jenkins infrastructure scale, here are some stats from April 2020:\n\nOver 600 000 people visited www.jenkins.io\n\nOver 250 000 Jenkins servers regularly checked the\nJenkins package server and the\nJenkins update server\n\nOver 43 000 continuous integration jobs ran on ci.jenkins.io\n\nOver 950 plugins ran their continuous integration pipelines on ci.jenkins.io\n\nCountry by country visitors to jenkins.io\n\nThe Jenkins project, as an open source project, is built and maintained by its awesome community.\nLike in any organization, there are specific people who make sure that those services are always up and running.\nEveryone is welcome to participate.\nInfrastructure is no exception, we are always looking for new contributors to the infrastructure!\n\nWhile we can’t share publicly everything like secrets and certificates,\nwe still try to be as transparent as possible so that everybody can understand and improve our infrastructure without having privileged access.\nWhat better way than using Git to manage infrastructure work?\n\nWho said GitOps?\n\nSince the creation of the Jenkins-infra organization on GitHub in March 2008, more than 650 people have contributed to over 80 git repositories.\nThose contributions make the Jenkins community what it is today.\nIf you can’t find something there, it probably means that some help is welcomed.\n\nMore recently, with help from Gavin Mogan, Tim Jacomb, and Alex Earl, big achievements have been possible on many fronts like automating Jenkins releases, refreshing plugins.jenkins.io, adding new agents to ci.jenkins.io, and maintaining our Kubernetes cluster.\nWe thank them for their help and for the infrastructure progress they have enabled.\n\nInfrastructure at Scale\n\nRunning infrastructure at the scale the Jenkins project does is expensive and sometimes quite challenging.\nWe are fortunate enough to be supported by many leading companies that provide us their expertise, their products, and their support.\n\nRecently, Amazon Web Services donated $60 000 to run Jenkins infrastructure on the AWS cloud.\nWe’re so grateful for their donation and for the flexibility it provides.\nWe’re running Linux agents with AMD64 and ARM64 architectures on AWS.\nWe’re using AWS cloud for our Windows agents.\nThe generous infrastructure donation from Amazon Web Services has increased our continuous integration capacity and broadened our platform coverage.\n\nOur Sponsors\n\nMajor sponsors of the Jenkins infrastructure include\nCloudBees,\nOregon State University Open Source Lab,\nContinuous Delivery Foundation,\nRed Hat,\nAmazon Web Services, and\nGitHub.\n\nAdditional sponsors of Jenkins infrastructure services and software include\nAtlassian,\nDatadog,\nFastly,\nIBM.\nJFrog,\nPagerduty,\nRackspace,\nSentry,\nServerion,\nSpinUp,\nTsinghua University, and\nXMission.\n\nEach of these organizations support the Jenkins project in their own way.\nWe thank them for their contributions, their support and for their willingness to help the Jenkins community.\n\nhttps://www.jenkins.io/projects/infrastructure/","title":"Jenkins Infrastructure: Stats, Updates, and AWS sponsorship","tags":["aws","community","infrastructure"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"olblak","html":"<div class=\"paragraph\">\n<p>Olivier is the Jenkins infrastructure officer and Senior Operations Engineer at CloudBees.\nAs a regular contributor to the Jenkins infrastructure projects, he works on a wide range of tasks from services reliability to applications maintenance.</p>\n</div>","id":"olblak","irc":"olblak","linkedin":null,"name":"Olivier Vernin","slug":"blog/author/olblak","twitter":"0lblak"}]}},{"node":{"date":"2018-09-14T00:00:00.000Z","id":"9d454b50-9959-5557-8c15-e1041ef6bff4","slug":"/blog/2018/09/14/speaker-blog-jenkins-builds-jenkins/","strippedHtml":"Next week Olivier Vernin from CloudBees and Brian Benz from Microsoft will be presenting a session at DevOps World | Jenkins World about how Microsoft has been working with Jenkins to build Jenkins plugins and produce Jenkins on Microsoft Azure.\nThese plugins run Jenkins on Azure Linux and Windows VMs, Kubernetes, azure App service, as well as deploy artifacts to those Azure platforms and more.\nAll are open source and available on GitHub.\n\nHere’s our session, where we’ll be sharing successes and challenges of getting the infrastructure up and running:\n\nTuesday, September 18\n\nSession: Developing and Delivering Jenkins in the cloud\n11:15am - 12:00pm Brian Benz with Olivier Vernin, CloudBees\n\nIn this session, we’ll discuss the real-life implementation of Jenkins' development and delivery infrastructure in the cloud as it has evolved from a mix of platforms to Microsoft Azure.\nExpect a frank discussion of how issues that were encountered along the way were overcome, how the architecture has evolved, and what’s on the roadmap.\nWe’ll share important tips and tricks for implementing your own Jenkins infrastructure on any cloud, based on Jenkins' own experience with their implementation.\n\nSee you in San Francisco!\n\nCome meet us at\nDevOps World | Jenkins World 2018 on September 16-19th in San Francisco.\nWe will be hanging out around the OSS space, eager to answer more questions.\n\nRegister with the code JWFOSS for a 30% discount off your pass.","title":"Want to know how Jenkins builds Jenkins? Catch this session at DevOps World | Jenkins World next week in San Francisco!","tags":["jenkinsworld","jenkinsworld2018","azure","infrastructure"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"olblak","html":"<div class=\"paragraph\">\n<p>Olivier is the Jenkins infrastructure officer and Senior Operations Engineer at CloudBees.\nAs a regular contributor to the Jenkins infrastructure projects, he works on a wide range of tasks from services reliability to applications maintenance.</p>\n</div>","id":"olblak","irc":"olblak","linkedin":null,"name":"Olivier Vernin","slug":"blog/author/olblak","twitter":"0lblak"}]}},{"node":{"date":"2018-07-23T00:00:00.000Z","id":"bc08dba7-169b-5284-bbaa-6f3d64408472","slug":"/blog/2018/07/23/javadoc-service-improvements/","strippedHtml":"Jenkins infrastructure is continuously improving.\nThe latest service to get some attention and major improvement is the Jenkins javadoc.\n\nThere were a number of issues affecting that service:\n\nIrregular updates -\nDevelopers wouldn’t find the latest java documentation because of inadequate update frequence.\n\nBroken HTTPS support -\nwhen users would go to the Javadoc site they would get an unsafe site warning and then an incorrect redirection.\n\nObsolete content - Javadoc was not cleaned up correctly and plenty of obsolete pages remained which confused end users.\n\nAs Jenkins services\nmigrate to Azure infrastructure,\nsomething that needed to be done was to move the javadoc service there as a standalone service.\nI took the same approach as jenkins.io, putting data on an azure file storage, using a nginx proxy in front of it and running on kubernetes.\nThis approach brings multiple benefits:\n\nWe store static files on an azure file storage which brings data reliability, redundancy, etc.\n\nWe use Kubernetes Ingress to configure HTTP/HTTPS endpoint\n\nWe use Kubernetes Service to provide load balancing\n\nWe use Kubernetes deployment to deploy default nginx containers with azure file storage volume.\n\nHTTP/HTTPS workflow\n\n+----------------------+     goes on     +------------------------------+\n  |  Jenkins Developer   |---------------->+  https://javadoc.jenkins.io  |\n  +----------------------+                 +------------------------------+\n                                                                      |\n  +-------------------------------------------------------------------|---------+\n  | Kubernetes Cluster:                                               |         |\n  |                                                                   |         |\n  | +---------------------+     +-------------------+     +-----------v------+  |\n  | | Deployment: Javadoc |     | Service: javadoc  <-----| Ingress: javadoc |  |\n  + +---------------------+     +-------------------+     +------------------+  |\n  |                                           |                                 |\n  |                          -----------------+                                 |\n  |                          |                |                                 |\n  |                          |                |                                 |\n  | +------------------------v--+    +--------v------------------+              |\n  | | Pod: javadoc              |    | Pod: javadoc              |              |\n  | | container: \"nginx:alpine\" |    | container: \"nginx:alpine\" |              |\n  | | +-----------------------+ |    | +-----------------------+ |              |\n  | | | Volume:               | |    | | Volume:               | |              |\n  | | | /usr/share/nginx/html | |    | | /usr/share/nginx/html | |              |\n  | | +-------------------+---+ |    | +----+------------------+ |              |\n  | +---------------------|-----+    +------|--------------------+              |\n  |                       |                 |                                   |\n  +-----------------------|-----------------|-----------------------------------+\n                          |                 |\n                          |                 |\n                       +--+-----------------+-----------+\n                       |   Azure File Storage: javadoc  |\n                       +--------------------------------+\n\nThe javadoc static files are now generated by a Jenkins\njob regularly and then published from a trusted jenkins instance.\nWe only update what has changed and remove obsolete documents.\nMore information can be find\nhere\n\nThe next thing in continuously improving is also to look at the user experience of the javadoc to make it easier to discover javadoc for other components or versions.\n( Help Needed)\n\nThese changes all go towards improving the developer experience for those using javadocs and making life easier for core and plugin developers.\nSee the new and improved javadoc service here\nJenkins Javadoc.","title":"Jenkins Javadoc: Service Improvements","tags":["javadoc","azure","infrastructure","kubernetes"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"olblak","html":"<div class=\"paragraph\">\n<p>Olivier is the Jenkins infrastructure officer and Senior Operations Engineer at CloudBees.\nAs a regular contributor to the Jenkins infrastructure projects, he works on a wide range of tasks from services reliability to applications maintenance.</p>\n</div>","id":"olblak","irc":"olblak","linkedin":null,"name":"Olivier Vernin","slug":"blog/author/olblak","twitter":"0lblak"}]}},{"node":{"date":"2016-05-18T00:00:00.000Z","id":"3098cab4-cd65-52ec-a4a9-2b36e2ac20d7","slug":"/blog/2016/05/18/announcing-azure-partnership/","strippedHtml":"I am pleased to announce that we have partnered with Microsoft to migrate and\npower the Jenkins project’s infrastructure with\nMicrosoft Azure. The partnership comes\nat an important time, after the recent launch of Jenkins 2.0,\nJenkins users are more readily adopting Pipeline as\nCode and many other plugins at an increasing rate, elevating the importance of\nJenkins infrastructure to the overall success of the project. That strong and\ncontinued growth has brought new demands to our infrastructure’s design and\nimplementation, requiring the next step in its evolution. This partnership helps\nus grow with the rest of the project by unifying our existing infrastructure\nunder one comprehensive, modern and scalable platform.\n\nIn March we\ndiscussed\nthe potential partnership in our regularly scheduled\nproject\nmeeting,\nhighlighting some of the infrastructure challenges that we face:\n\nCurrently we have infrastructure in four different locations, with four\ndifferent infrastructure providers, each with their own APIs and tools for\nmanaging resources, each with varying capabilities and capacities.\n\nProject infrastructure is managed by a team of volunteers, operating\nmore than 15 different services and managing a number of additional external\nservices.\n\nOur current download/mirror network, while geographically distributed, is\nrelatively primitive and its implementation prevents us from using more modern\ndistribution best practices.\n\nIn essence, five years of tremendous growth for Jenkins has outpaced our\norganically grown, unnecessarily complex, project infrastructure. Migrating to\nAzure simplifies and improves our infrastructure in a dramatic way that would\nnot be possible without a comprehensive platform consisting of: compute, CDN,\nstorage and data-store services. Our partnership covers, at minimum, the next\nthree years of the project’s infrastructure needs, giving us a great home for\nthe future.\n\nAzure also enables a couple of projects that I\nhave long been dreaming of providing to Jenkins users and contributors:\n\nEnd-to-end TLS encrypted distribution of Jenkins packages, plugins and\nmetadata via the Azure CDN.\n\nMore complete build/test/release support and capacity on\nci.jenkins.io for plugin developers using\nAzure\nContainer Service and generic VMs.\n\nThe Jenkins infrastructure is all open\nsource which means  all of our Docker containers, Puppet code and many of our\ntools are all available on GitHub. Not\nonly can you watch the migration process to Azure as it happens, but I also\ninvite you to participate in making our project’s infrastructure better (join\nus in the #jenkins-infra channel on Freenode or our\nmailing list).\n\nSuffice it to say, I’m very excited about the bright [blue] future for the\nJenkins project and the infrastructure that powers it!","title":"Partnering with Microsoft to run Jenkins infrastructure on Azure","tags":["azure","infra","infrastructure"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2015-08-13T00:00:00.000Z","id":"c7b1b0e4-16c6-597e-845e-0b1d30006db2","slug":"/blog/2015/08/13/update-wiki-and-issue-tracker-outage/","strippedHtml":"I recently wrote about the two day outage of our wiki and issue tracker :\n\nWhile this was a rather lengthy outage, it could have been much worse. We lost none of the data, after all.\n\nOSUOSL have since published their post mortem. I was really wrong about not losing any data:\n\nA further complication was that our backups were pointed at mysql2, which was out-of-date with mysql1, due to the initial synchronization failures. Fortunately, we had the binary logs from the 17th through the 30th. This means that though most data could be restored, some data from between the 15th and the 17th was lost.\n\nFor our issue tracker, that means that issues JENKINS-29432 to JENKINS-29468 were lost, as well as comments posted from about July 15 12:20 PM to July 17 2 AM (UTC). We know this thanks to the jenkinsci-issues mailing list where the lost issues and comments can be looked up for reposting.\n\nWe unfortunately don’t have such a record from our wiki.","title":"Update: Wiki and issue tracker outage","tags":["infrastructure"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"blog/author/daniel-beck","twitter":null}]}}]}},"pageContext":{"tag":"infrastructure","limit":8,"skip":0,"numPages":4,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}