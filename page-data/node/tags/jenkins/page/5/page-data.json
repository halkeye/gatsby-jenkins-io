{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/jenkins/page/5",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-09-09T00:00:00.000Z","id":"ebc932b1-1d9b-5ee9-80be-9c7081c78a03","slug":"/blog/2016/09/09/take-the-2016-jenkins-survey-blog/","strippedHtml":"This is a guest post by Brian\nDawson on behalf of CloudBees, where he works as a DevOps Evangelist\nresponsible for developing and sharing continuous delivery and DevOps best\npractices. He also serves as the CloudBees Product Marketing Manager for\nJenkins.\n\nOnce again it’s that time of year when CloudBees sponsors the\nJenkins Community Survey to\nassist the community with gathering objective insights into how jenkins is\nbeing used and what users would like to see in the Jenkins project.\n\nYour personal information (name, email address and company) will NOT be used by CloudBees for\nsales or marketing.\n\nAs an added incentive to take the survey, CloudBees will enter participants\ninto a drawing for a free pass to Jenkins World 2017 (1st prize) and a $100\nAmazon Gift Card (2nd prize). The survey will close at the end of September, so\nclick the link at the end of the blog post to get started!\n\nAll participants will be able to access reports summarizing survey results. If\nyou’re curious about what insights your input will provide, see the results of\nlast year’s 2015 survey:\n\n2015 Community Survey Results (PDF)\n\nState of Jenkins Infographic (PDF)\n\nYour feedback helps capture a bigger picture of\ncommunity trends and needs. There are laws that govern prize giveaways and\neligibility; CloudBees has compiled all those fancy\nterms and conditions here.\n\nPlease take the survey and let your voice be heard - it will take less than 10\nminutes.\n\nTake me to the survey","title":"Take the 2016 Jenkins Survey!","tags":["jenkins"],"authors":[{"avatar":null,"blog":null,"github":"bvdawson","html":"<div class=\"paragraph\">\n<p>DevOps dude at CloudBees.\nJenkins Marketing Manager.\nTools geek.</p>\n</div>","id":"bvdawson","irc":null,"linkedin":null,"name":"Brian Dawson","slug":"/blog/authors/bvdawson","twitter":"brianvdawson"}]}},{"node":{"date":"2016-06-15T00:00:00.000Z","id":"92e6efae-588c-5a80-886a-8fe7822dcea3","slug":"/blog/2016/06/15/jenkins-pipeline-scalability/","strippedHtml":"This is a guest post by Damien\nCoraboeuf, Jenkins project contributor and Continuous Delivery consultant.\n\nImplementing a CI/CD solution based on Jenkins has become very easy. Dealing\nwith hundreds of jobs? Not so much. Having to scale to thousands of jobs?\nNow this is a real challenge.\n\nThis is the story of a journey to get out of the jungle of jobs…​\n\nStart of the journey\n\nAt the beginning of the journey there were several projects using roughly the same\ntechnologies. Those projects had several\nbranches, for maintenance of releases, for new features.\n\nIn turn, each of those branches had to be carefully built, deployed on different\nplatforms and versions, promoted so they could be tested for functionalities,\nperformances and security, and then promoted again for actual delivery.\n\nAdditionally, we had to offer the test teams the means to deploy any version of\ntheir choice on any supported platform in order to carry out some manual tests.\n\nThis represented, for each branch, around 20 jobs. Multiply this by the number of\nbranches and projects, and there you are: more than two years after the start\nof the story, we had more than 3500 jobs.\n\n3500 jobs. Half a dozen people to manage them all…​\n\nPreparing the journey\n\nHow did we deal with this load?\n\nWe were lucky enough to have several assets:\n\ntime - we had time to design a solution before the scaling went really out of\ncontrol\n\nforecast - we knew that the scaling would occur and we were not taken by\nsurprise\n\ntooling - the Jenkins Job DSL\nwas available, efficient and well documented\n\nWe also knew that, in order to scale, we’d have to provide a solution with the\nfollowing characteristics:\n\nself-service - we could not have a team of 6 people become a bottleneck for\nenabling CI/CD in projects\n\nsecurity - the solution had to be secure enough in order for it to be used by\nremote developers we never met and didn’t know\n\nsimplicity - enabling CI/CD had to be simple so that people having\nnever heard of it could still use it\n\nextensibility - no solution is a one-size-fits-all and must be flexible\nenough to allow for corner cases\n\nAll the mechanisms described in this article are available through the\nJenkins Seed plugin.\n\nCreating pipelines using the Job DSL and embedding the scripts in the code was\nsimple enough. But what about branching? We needed a mechanism to allow the\ncreation of pipelines per branch, by downloading the associated DSL and to\nrun it in a dedicated folder.\n\nBut then, all those projects, all those branches, they were mostly using the\nsame pipelines, give or take a few configurable items. Going this way would\nhave lead to a terrible duplication of code, transforming a job maintenance\nnightmare into a code maintenance nightmare.\n\nPipeline as configuration\n\nOur trick was to transform this vision of \"pipeline as code\" into a \"pipeline\nas configuration\":\n\nby maintaining well documented and tested \"pipeline libraries\"\n\nby asking projects to describe their pipeline not as code, but as property\nfiles which would:\n\ndefine the name and version of the DSL pipeline library to use\n\nuse the rest of the property file to configure the pipeline library, using\nas many sensible default values as possible\n\nPiloting the pipeline from the SCM\n\nOnce this was done, the only remaining trick was to automate the creation,\nupdate, start and deletion of the pipelines using SCM events. By enabling SCM\nhooks (in GitHub, BitBucket or even in Subversion), we could:\n\nautomatically create a pipeline for a new branch\n\nregenerate a pipeline when the branch’s pipeline description was modified\n\nstart the pipeline on any other commit on the branch\n\nremove the pipeline when the branch was deleted\n\nOnce a project wants to go in our ecosystem, the Jenkins team \"seeds\" the\nproject into Jenkins, by running a job and giving a few parameters.\n\nIt will create a folder for the project and grant proper authorisations, using\nActive Directory group names based on the project name.\n\nThe hook for the project must be registered into the SCM and you’re up and\nrunning.\n\nConfiguration and code\n\nMixing the use of strong pipeline libraries configured by properties and the\ndirect use of the Jenkins Job DSL is still possible. The Seed plugin\nsupports all kinds of combinations:\n\nuse of pipeline libraries only - this can even be enforced\n\nuse a DSL script which can in turn use some classes and methods defined in\na pipeline library\n\nuse of a Job DSL script only\n\nUsually, we tried to have a maximum reuse, through only pipeline libraries, for\nmost of our projects, but in other circumstances, we were less strict and\nallowed some teams to develop their own pipeline script.\n\nEnd of the journey\n\nIn the end, what did we achieve?\n\nSelf service ✔︎\n\nPipeline automation from SCM - no intervention from the Jenkins team but for\nthe initial bootstrapping\n\nGetting a project on board of this system can be done in a few minutes only\n\nSecurity ✔︎\n\nProject level authorisations\n\nNo code execution on the controller\n\nSimplicity ✔︎\n\nProperty files\n\nExtensibility ✔︎\n\nPipeline libraries\n\nDirect job DSL still possible\n\nSeed and Pipeline plugin\n\nNow, what about the Pipeline plugin? Both\nthis plugin and the Seed plugin have common functionalities:\n\nWhat we have found in our journey is that having a \"pipeline as configuration\"\nwas the easiest and most secure way to get a lot of projects on board, with\ndevelopers not knowing Jenkins and even less the DSL.\n\nThe outcome of the two plugins is different:\n\none pipeline job for the Pipeline plugin\n\na list of orchestrated jobs for the Seed plugin\n\nIf time allows, it would be probably a good idea to find a way to integrate the\nfunctionalities of the Seed plugin into the pipeline framework, and to keep\nwhat makes the strength of the Seed plugin:\n\npipeline as configuration\n\nreuseable pipeline libraries, versioned and tested\n\nLinks\n\nYou can find additional information about the Seed plugin and its usage at the\nfollowing links:\n\nthe Seed plugin itself\n\nJUC London, June 2015\n\nBruJUG Brussels, March 2016","title":"Jenkins Pipeline Scalability in the Enterprise","tags":["jenkins","scalability","dsl"],"authors":[{"avatar":null,"blog":null,"github":"dcoraboeuf","html":"<div class=\"paragraph\">\n<p>I&#8217;ve started many years ago in the Java development before switching\nprogressively toward continuous delivery aspects.  I&#8217;m now a consultant\nimplementing CD solutions based on Jenkins. Implementation of the Pipeline\nas Code principles have allowed one of my clients to be able to manage more\nthan 3000 jobs, using a self service approach based on the Seed plugin.</p>\n</div>\n<div class=\"paragraph\">\n<p>I&#8217;m also a contributor for some Jenkins plugins and the author of the\nOntrack application, which allows the monitoring of continuous delivery\npipelines.</p>\n</div>","id":"dcoraboeuf","irc":null,"linkedin":null,"name":"Damien Coraboeuf","slug":"/blog/authors/dcoraboeuf","twitter":"DamienCoraboeuf"}]}},{"node":{"date":"2016-04-21T00:00:00.000Z","id":"d9ce8340-eedf-5dba-874d-c9eba3f8e717","slug":"/blog/2016/04/21/dsl-plugins/","strippedHtml":"In this post I will show how you can make your own DSL extensions and distribute\nthem as a plugin, using Pipeline Script.\n\nA quick refresher\n\nPipeline has a well kept secret: the ability to add your own DSL\nelements. Pipeline is itself a DSL, but you can extend it.\n\nThere are 2 main reasons I can think you may want to do this:\n\nYou want to reduce boilerplate by encapsulating common snippets/things you do\nin one DSL statement.\n\nYou want to provide a DSL that provides a prescriptive way that your builds\nwork - uniform across your organisations Jenkinsfiles.\n\nA DSL could look as simple as\n\nacmeBuild {\n    script = \"./bin/ci\"\n    environment = \"nginx\"\n    team = \"evil-devs\"\n    deployBranch = \"production\"\n}\n\nThis could be the entirety of your Jenkinsfile!\n\nIn this \"simple\" example, it could actually be doing a multi stage build with\nretries, in a specified docker container, that deploys only from the production\nbranch.  Detailed notifications are sent to the right team on important events\n(as defined by your org).\n\nTraditionally this is done via the\nglobal\nlibrary.  You take a snippet of DSL you want to want to make into a DSL, and\ndrop it in the git repo that is baked into Jenkins.\n\nA great trivial\nexample\nis this:\n\njenkinsPlugin {\n    name = 'git'\n}\n\nWhich is enabled by git pushing the following into vars/jenkinsPlugin.groovy\n\nThe name of the file is the name of the DSL expression you use in the Jenkinsfile\n\ndef call(body) {\n    def config = [:]\n    body.resolveStrategy = Closure.DELEGATE_FIRST\n    body.delegate = config\n    body()\n\n    // This is where the magic happens - put your pipeline snippets in here, get variables from config.\n    node {\n        git url: \"https://github.com/jenkinsci/${config.name}-plugin.git\"\n        sh \"mvn install\"\n        mail to: \"...\", subject: \"${config.name} plugin build\", body: \"...\"\n    }\n}\n\nYou can imagine many more pipelines, or even archetypes/templates of pipelines\nyou could do in this way, providing a really easy Jenkinsfile syntax for your\nusers.\n\nMaking it a plugin\n\nUsing the global DSL library is a handy thing if you have a single Jenkins, or\nwant to keep the DSLs local to a Jenkins instance.  But what if you want to\ndistribute it around your org, or, perhaps it is general purpose enough you want\nto share it with the world?\n\nWell this is possible, by wrapping it in a plugin. You use the same pipeline\nsnippet tricks you use in the global lib, but put it in the dsl directory of a\nplugin.\n\nMy simple\nbuild plugin shows how it is done.  To make your own plugin:\n\nCreate a new plugin project, either fork the simple build one, or add a\ndependency to it in your pom.xml / build.gradle file\n\nPut your dsl in the resources directory in a similar fashion to\nthis\n(note the \"package dsl\" declaration at the top)\n\nCreate the equivalent extension that just points to the DSL by name like\nthis\nThis is mostly \"boiler plate\" but it tells Jenkins there is a GlobalVariable extension available when Pipelines run.\n\nDeploy it to an Jenkins Update Center to share with your org, or everyone!\n\nThe advantage of delivering this DSL as a plugin is that it has a version (you\ncan also put tests in there), and distributable just like any other plugin.\n\nFor the more advanced, Andrew Bayer has a Simple\nTravis Runner plugin that\ninterprets and runs\ntravis.yml files which is also implemented in pipeline.\n\nSo, approximately, you can build plugins for pipeline that extend pipeline, in\npipeline script (with a teeny bit of boiler plate).\n\nEnjoy!","title":"Making your own DSL with plugins, written in Pipeline script","tags":["jenkins","dsl","pipeline","plugins"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg","srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/77b35/michaelneale.jpg 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/d4a57/michaelneale.jpg 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/ef6ff/michaelneale.webp 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/8257c/michaelneale.webp 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/6766a/michaelneale.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/authors/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2016-01-27T00:00:00.000Z","id":"71059d3b-342c-5d7f-bb17-4f49e709e88c","slug":"/blog/2016/01/27/jenkins-world-call-for-papers/","strippedHtml":"This is a guest post by Alyssa Tong.\nAlyssa works for CloudBees, helping to organize\nJenkins community events around the\nworld.\n\nPlanning is underway for Jenkins World, a major Jenkins event for developers,\nrelease engineers and others interested in automation. The conference will be\nheld from September 13th to 15th in Santa Clara, California and is being\norganized and sponsored in part by CloudBees.\nJust like the \"Jenkins User Conferences\" before it, this year’s event will\nfeature many experts from the Jenkins community that help make Jenkins\nthe most popular open source automation server on the planet. We’ve found that\nwe outgrew the popular multi-city one-day Jenkins User Conferences, so unlike\nprevious years Jenkins World will be a three-day event in one place with an\nincredible amount of great content.\n\nThe goal of the event is to bring Jenkins contributors and users of all levels\ntogether, from around the world, to discuss, share and learn from one another.\nStarting today we’re opening the\ncall for\nproposals . As a global event, users from all over the world are encouraged to\nsubmit a talk between now and May 1st, 2016 (11:59pm PST).\n\nWe look forward to receiving your amazing submission, and seeing you in Santa\nClara this fall.\n\nSubmit a\nproposal today!","title":"Jenkins World 2016: Call For Papers Is Open!","tags":["jenkins world","event","jenkins"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg","srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/8d248/alyssat.jpg 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/c004c/alyssat.jpg 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/9e67b/alyssat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/22924/alyssat.webp 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/89767/alyssat.webp 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/40d97/alyssat.webp 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/5028e/alyssat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":166}}},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"/blog/authors/alyssat","twitter":null}]}}]}},"pageContext":{"tag":"jenkins","limit":8,"skip":32,"numPages":5,"currentPage":5}},
    "staticQueryHashes": ["3649515864"]}