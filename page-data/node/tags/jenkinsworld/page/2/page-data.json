{
    "componentChunkName": "component---src-templates-tag-blog-list-template-js",
    "path": "/node/tags/jenkinsworld/page/2",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2019-03-01T00:00:00.000Z","id":"3a32be4f-441e-5dd8-a3ed-bf3e1d6e4048","slug":"/blog/2019/03/01/devops-world-jenkins-world-cfp-open/","strippedHtml":"The DevOps World | Jenkins World shuttle is ready for lift off once again. As usual, the sign of festivities looming begins with the Call for Speakers.\nThose who attended DevOps World | Jenkins World 2018 know that DevOps World | Jenkins World 2019 is coming back to San Francisco, and adding a stop in  Europe - Lisbon, Portugal.\n\nJenkins World USA | San Francisco | August 12 - 15, 2019\n\nJenkins World Europe | Lisbon | December 2 - 5, 2019*\n\nTo encourage open collaboration and stimulate discussions that will help advance Jenkins adoption and drive it forward, we invite Jenkins users, developers and industry experts to submit a speaking proposal to DevOps World | Jenkins World San Francisco and or Lisbon.\nSubmissions for both locations are being accepted now.\nThe submission deadline for San Francisco, CA has been extended through March 24, 2019, @ 11:59 PM Pacific and the submission deadline for Lisbon, Portugal is June 9, 2019, @ 11:59 PM Pacific.\n\nThe below Q&A will help you breeze through the submission process.\n\nWhere do I go to submit my proposal?\n\nSubmissions for both DevOps World | Jenkins World USA and Europe are accepted at:\n\nJenkins World USA\n\nJenkins World Europe\n\nCan I make proposal(s) to both conferences?\n\nYes, you can! Once you’ve created an account on the CFP website you will be given the option to make submission(s) to one conference or both conferences.\n\nWhen is the deadline for DevOps World | Jenkins World USA?\n\nSaturday March 24, 2019 @ 11:59PM Pacific\n\nWhen is the deadline for DevOps World | Jenkins World Europe?\n\nTuesday, June 9, 2019, @ 11:59 PM Pacific\n\nSan Francisco Important Dates:\n\nJanuary 9, 2019: Call for papers opens\n\nMarch 24, 2019: Call for papers closes\n\nApril 12, 2019: Submission decisions sent\n\nMay 1, 2019: Agenda published - San Francisco, CA\n\nMay 6, 2019: Speaker tasklist is sent out\n\nAugust 12-15, 2019: DevOps World | Jenkins World 2019 San Francisco\n\n*Due to the deadline extensions for DevOps World | Jenkins World 2019 San Francisco any talks submitted after March 10th will be subject to the important dates below:\n\nJanuary 9, 2019: Call for papers opens\n\nMarch 24, 2019: Call for papers closes\n\nWeek of April 1, 2019: Submission decisions sent\n\nWeek of April 29, 2019: Agenda published - San Francisco, CA\n\nMay 6, 2019: Speaker tasklist is sent out\n\nAugust 12-15, 2019: DevOps World | Jenkins World 2019 San Francisco\n\nLisbon Important Dates:\n\nJanuary 9, 2019: Call for papers opens\n\nJune 9, 2019: Call for papers closes\n\nJuly 19, 2019: Submission decisions sent\n\nAugust 19, 2019: Agenda published\n\nAugust 23, 2019: Speaker tasklist is sent out\n\nDecember 2-5, 2019: DevOps World | Jenkins World 2019 Lisbon, Portugal\n\n*All Dates Are Subject To Change.\n\nWe look forward to receiving your inspiring stories!","title":"DevOps World - Jenkins World 2019: Call for Papers is Open","tags":["event","jenkinsworld"],"authors":[{"avatar":null,"blog":null,"github":"svanalstine","html":"","id":"svanalstine","irc":null,"linkedin":null,"name":"Skylar VanAlstine","slug":"/blog/authors/svanalstine","twitter":null}]}},{"node":{"date":"2018-09-18T00:00:00.000Z","id":"05f18d70-cabf-59fd-91c1-537a47157934","slug":"/blog/2018/09/18/automatically-upgrading-with-evergreen/","strippedHtml":"When I first wrote about Jenkins\nEvergreen, which was then referred to as \"Jenkins Essentials\", I mentioned a\nnumber of future developments which in the subsequent months have become\nreality. At this year’s DevOps World - Jenkins World in San Francisco, I will\nbe sharing more details on the philosophy behind Jenkins Evergreen, show off\nhow far we have come, and discuss where we’re going with this radical\ndistribution of Jenkins.\n\nAs discussed in my first blog post, and\nJEP-300,\nthe first two pillars of Jenkins Evergreen have been the primary focus of our\nefforts.\n\nAutomatically Updated Distribution\n\nPerhaps unsurprisingly, implementing the mechanisms necessary for safely and\nautomatically updating a Jenkins distribution, which includes core and plugins,\nwas and continues to be a sizable amount of work. In\nBaptiste’s talk\nhe will be speaking about the details which make Evergreen \"go\" whereas\nI will be speaking about why an automatically updating distribution is\nimportant.\n\nAs continuous integration and continuous delivery have become more commonplace,\nand fundamental to modern software engineering, Jenkins tends to live two\ndifferent lifestyles depending on the organization. In some organizations,\nJenkins is managed and deployed methodically with automation tools like Chef,\nPuppet, etc. In many other organizations however, Jenkins is treated much more\nlike an appliance, not unlike the office wireless router. Installed and so\nlong as it continues to do its job, people won’t think about it too much.\n\nJenkins Evergreen’s distribution makes the \"Jenkins as an Appliance\" model much\nbetter for everybody by ensuring the latest feature updates, bug and security\nfixes are always installed in Jenkins.\n\nAdditionally, I believe Evergreen will serve another group we don’t adequately\nserve at the moment: those who want Jenkins to behave much more like a\nservice. We typically don’t consider \"versions\" of GitHub.com, we receive\nincremental updates to the site and realize the benefits of GitHub’s on-going\ndevelopment without ever thinking about an \"upgrade.\"\n\nI believe Jenkins Evergreen can, and will provide that same experience.\n\nAutomatic Sane Defaults\n\nThe really powerful thing about Jenkins as a platform is the broad variety of\npatterns and practices different organizations may adopt. For newer users, or\nusers with common use-cases, that significant amount of flexibility can result\nin a paradox of choice. With Jenkins Evergreen, much of the most common\nconfiguration is automatically configured out of the box.\n\nIncluded is Jenkins Pipeline and Blue Ocean, by default. We also removed some\nlegacy functionalities from Jenkins while we were at it.\n\nWe are also utilizing some of the fantastic\nConfiguration as Code\nwork, which recently had its 1.0 release, to automatically set sane defaults in\nJenkins Evergreen.\n\nStatus Quo\n\nThe effort has made significant strides thus far this year, and we’re really\nexcited for people to start trying out Jenkins Evergreen. As of today,\nJenkins Evergreen\nis ready for early adopters. We do not yet recommend using Jenkins\nEvergreen for a production environment.\n\nIf you’re at DevOps World - Jenkins World in San Francisco please come see\nBaptiste’s talk Wednesday at 3:45pm in Golden Gate Ballroom A. Or\nmy talk at 11:15am in Golden Gate Ballroom B.\n\nIf you can’t join us here in San Francisco, we hope to hear your feedback and thoughts in our\nGitter channel!","title":"Continuously delivering an easy-to-use Jenkins with Evergreen","tags":["jenkinsworld","jenkinsworld2018","evergreen"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-09-17T00:00:00.000Z","id":"f2d08709-df38-5689-9363-0cab0bbbd723","slug":"/blog/2018/09/17/jenkins-artwork/","strippedHtml":"Hi all, this is my first blogpost on jenkins.io.\nMy name is Kseniia Nenasheva, I work as a Graphics Designer at CloudBees.\nI have been using Jenkins since 2012 as a QA engineer, and I am happy to contribute to the project.\nI have also submitted some patches to the core and plugins,\nand probably you have seen some Jenkins logos created by me,\nand some of you may even have them on your laptops.\nBy the way, Ron Burgundy is my favorite Jenkins logo.\n\nThis year I am going to DevOps World | Jenkins World in San Francisco.\nDuring the conference I will be working at the Jenkins community booth\nand creating exclusive pictures with conference visitors and one of the Jenkins heroes.\nSo, if you come to our booth and share your Jenkins story, you can get a special picture.\n\nIf you are interested to get a logo for your Jenkins Area Meetup\nor an open-source project (including Jenkins plugins, of course),\nplease also stop by at the booth and share your ideas.\nAfter the conference I will try to implement the most interesting proposals.\n\nYou can also meet me at the contributor summit on September 17.\n\nCome meet Kseniia and other Jenkins contributors at\nJenkins World on September 16-19th in San Francisco and on October 22-25 in Nice.\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins Artwork at the DevOps World | Jenkins World 2018 Community Booth","tags":["jenkinsworld","jenkinsworld2018","artwork","community"],"authors":[{"avatar":null,"blog":null,"github":"ksenia-nenasheva","html":"","id":"ksenia-nenasheva","irc":null,"linkedin":null,"name":"Ksenia Nenasheva","slug":"/blog/authors/ksenia-nenasheva","twitter":null}]}},{"node":{"date":"2018-09-14T00:00:00.000Z","id":"3853be51-02ed-55b0-8b3f-edbfcfe998c7","slug":"/blog/2018/09/14/kubernetes-and-secret-agents/","strippedHtml":"At long last, the way we build and deploy software is finally changing and significantly so.\nThe days of the persnickety, prima donna build machine where monolithic applications were built, tested, and deployed are numbered.\nAnd that is a \"Good Thing (tm)\" - a consequence of how we will meet the transformation goals of our businesses.\nModern applications consist of distributed services, often with multiple microservices that are developed and deployed independent of other services.\nHowever, the only way to build these services with their own dependencies and schedules is to bake in continuous integration and delivery from the beginning.\nAnd as usual, your Jenkins platform is your friend.\n\nBut let’s take a moment and think about that in the context of microservices, especially if you’ve only used Jenkins for monolithic applications.\nYou’ll be creating a greater number of individual Jenkins jobs that each run multiple times a day.\nThis is a significant process change, and it’s important to acknowledge this and change our approach to managing Jenkins to accommodate these changes.\nIt’s well within Jenkins’ capabilities, but you will need to think a little differently, and invest to close those last-mile deployment gaps.\n\nEvolution of my Jenkins Environment\n\nOne of the biggest challenges I’ve faced as a DevOps practitioner is a long and evolving set of options to manage my Jenkins agent infrastructure.\nWith only a few large jobs you don’t really need to worry too much about your agents.\nBut when you’re orchestrating the CI/CD pipelines for dozens or even hundreds of services, optimizing efficiency and minimizing cost becomes important.\nAnd that journey has allowed me to consider and test many different Jenkins build agent architectures over the years.\nThis journey may be familiar to you as well.\n\nThese are the types of Jenkins environments I’ve run over the years.\n\nExecute all the builds on the controller.\nConcentrate all the moving parts on one instance.\n(I call this Hello Jenkins)\n\nCreate a Jenkins EC2 agent with all the required tools for building every service, and then clone it if I need to “scale” Jenkins.\n(I call this the Monster Agent.)\n\nCreate an individual Jenkins EC2 agent for each service I need to build.\n(I call this the Snowflake Agent.)\n\nRun build steps in containers.\nFor example, launching agents in containers using the\nDocker Plugin or using multi-stage Dockerfiles to encapsulate all the logic for building, testing and packaging an application.\nThey are both good first steps in container abstraction and allow you to easily copy artifacts from one container to another.\nOf course, access to a Docker engine is required for either approach, and I’ve managed my Docker host(s) for running Jenkins agents several different ways:\n\nRun the Docker engine inside my Jenkins controller container - Docker in Docker (DinD)\n\nMount the Docker socket of the host on which my Jenkins controller container runs, allowing agents to run as sibling or sidecar containers - Docker outside of Docker (DooD)\n\nConfigure a single external EC2 Docker host for the Jenkins controller to use for launching builds in containers\n\nDynamically launch agents using the EC2 plugin with an AMI that contains the Docker Engine and then run all the steps in a multi-stage Dockerfile\n\nAll these approaches were attempts to get out of the business of curating and managing Jenkins agents and infrastructure, each with their own benefits and drawbacks.\nBut recently I begin working in a new Jenkins environment - Jenkins on Kubernetes.\n\nOnce you’ve come to view Jenkins, build agents and jobs as containerized services, migrating platforms becomes much more straightforward.\nAnd total disclaimer here - I had never used Kubernetes in my life, not even for side projects - when I set out to do this.\nThat said, it was surprisingly simple to create a Kubernetes cluster in Google Cloud Platform’s (GCP) GKE, launch a Jenkins controller using a\nHelm chart and begin running build steps in Jenkins agents running in containers on my new Kubernetes cluster.\n\nLaunch agents in Kubernetes from your pipeline scripts\n\nThe focus of this post and my Jenkins World talk for 2018, is to show you how to configure Jenkins to launch agents in Kubernetes from your pipeline scripts.\nMy examples assume you are launching your agents in the same Kubernetes cluster where your Jenkins controller is running, but there are other options.\nYou’ll begin by installing the\nKubernetes plugin.\nAs a bonus, when I installed Jenkins using the latest stable chart in the default Helm repository, the Kubernetes plugin was automatically installed for me.\n\nOnce you get the Jenkins controller running on your Kubernetes cluster, there are only a few configuration steps required and then you can begin launching ephemeral build agents on Kubernetes.\n\nConfigure the Jenkins controller\n\nYou’ll first need to create a credentials set for the Jenkins controller to access the Kubernetes cluster.\nTo do this, perform the following steps:\n\nIn the Jenkins UI, click the Credentials link in the left-hand navigation pane\n\nClick the arrow next to (global) in the Stores scoped to Jenkins table (you have to hover next to the link to see the arrow)\n\nClick Add Credentials\n\nUnder Kind, specify Kubernetes Service Account\n\nLeave the scope set to Global\n\nClick OK.\n\nThat’s it! This configuration allows the Jenkins controller to use a Kubernetes service account to access the Kubernetes API.\n\nCreate a Cloud Configuration on the Jenkins controller\n\nThe next step is to create a cloud configuration for your K8s cluster.\n(When I use K8s instead of Kubernetes it’s because it is quicker to type, not just for coolness.)\n\nIn the Jenkins UI, go to Manage Jenkins → Configure System\n\nScroll down until you see Cloud settings and click the Add a new cloud box and select kubernetes\n\nThe following parameters must be set:\n\nName : - This defaults to kubernetes\n\nKubernetes URL : https://kubernetes.default - This was automatically configured from the service account.\n\nKubernetes Namespace : default - Unless you are running your controller in another namespace\n\nCredentials :  Select the Kubernetes Service Account credentials you created in the previous step\n\nJenkins URL : http:// :8080\n\nJenkins tunnel : :5555 - This is the port that is used to communicate with an agent\n\nThese were the only parameters I had to set to launch an agent in my K8s cluster.\nYou can certainly modify other parameters to tweak your environment.\n\nNow that you’ve configured your Jenkins controller so that it can access your K8s cluster, it’s time to define some pods.\nA pod is the basic building block of Kubernetes and consists of one or more containers with shared network and storage.\nEach Jenkins agent is launched as a Kubernetes pod.\nIt will always contain the default JNLP container that runs the Jenkins agent jar and any other containers you specify in the pod definition.\nThere are at least two ways to configure pod templates – in the Jenkins UI and in your pipeline script.\n\nConfigure a Pod Template in the Jenkins UI\n\nIn the Jenkins UI, go to Manage Jenkins → Configure Systems\n\nScroll down to the cloud settings you configured in the previous step\n\nClick the Add Pod Template button and select Kubernetes Pod Template\n\nEnter values for the following parameters:\n\nName :\n\nNamespace : default - unless you configured a different namespace in the previous step\n\nLabels : - this will be used to identify the agent pod from your Jenkinsfiles\n\nUsage : Select \" Use this node as much as possible\" if you would like for this pod to be your default node when no node is specified.\nSelect \" Only build jobs with label matching expressions matching this node\" to use this pod only when its label is specified in the pipeline script\n\nThe name of the pod template to inherit from - you can leave this blank.\nIt will be useful once you gain experience with this configuration, but don’t worry about it for now.\n\nContainers : The containers you want to launch inside this pod.\nThis is described in detail below.\n\nEnvVars : The environment variables you would like to inject into your pod at runtime.\nThis is described in detail below.\n\nVolumes :  Any volumes you want to mount inside your pod.\nThis is described further below.\n\nRemember that a pod consists of one or more containers that live and die together.\nThe pod must always include a JNLP container, which is configured by default if you installed the controller using the Helm Chart.\nHowever, you will want to add containers with the tool chains required to build your application.\n\nAdd Your Own Container Template\n\nIn the Jenkins UI, return to the pod template you created in the last step\n\nClick the Add Container button and select Container Template\n\nEnter values in the following fields:\n\nName :\n\nDocker image : any Docker image you’d like\nFor example, if you are building an application written in Go, you can enter 'golang:1.11-alpine3.8'\n\nLabel : Enter any label strings you’d like to use to refer to this container template in your pipeline scripts\n\nAlways pull image : - Select this option if you want the plugin to pull the image each time a pod is created.\n\nYou can leave the default values for the other parameters, but you can see that the plugin gives you fine-grained control over your pod and the individual containers that run within it.\nAny values you might set in your Kubernetes pod configuration can be set via this plugin as well.\nYou can also inject your configuration data by entering raw YAML.\nI encourage you not to get distracted by the sheer number of options you can configure in this plugin.\nYou only have to configure a small subset of them to get a working environment.\n\nYou can click the Add Environment Variable button in the container template to inject environment variables into a specific container.\nYou can click the Add Environment Variable button in the pod template to inject environment variables into all containers in the pod.\nThe following environment variables are automatically injected into the default JNLP container to allow it to connect automatically to the Jenkins controller:\n\nJENKINS_URL : Jenkins web interface url\n\nJENKINS_JNLP_URL : url for the jnlp definition of the specific agent\n\nJENKINS_SECRET : the secret key for authentication\n\nJENKINS_NAME : the name of the Jenkins agent\n\nIf you click the Add Volume button in the pod template, you’ll see several options for adding volumes to your pod.\nI use the Host Path Volume option to mount the docker socket inside the pod.\nI can then run a container with the Docker client installed and use the host Docker socket to build and push Docker images.\n\nAt this point, we’ve created a cloud configuration for our Kubernetes cluster and defined a pod consisting of one or more containers.\nNow, how do we use this to run Jenkins jobs? We simply refer to the pod and containers by label in our Jenkins pipeline script.\nWe use the label we gave to the pod in the node block and the label for the container we wish to use in the container block.\nThe examples in this post use scripted pipeline, but you can achieve the same outcome using the declarative pipeline syntax:\n\nnode('test-pod') {\n    stage('Checkout') {\n        checkout scm\n    }\n    stage('Build'){\n        container('go-agent') {\n            // This is where we build our code.\n        }\n    }\n}\n\nDefining the Pod in the Jenkinsfile\n\nConfiguring a plugin through the UI is perfectly fine in a proof of concept.\nHowever, it does not result in a software-defined infrastructure that can be versioned and stored right alongside your source code.\nLuckily, you can create the entire pod definition directly in your Jenkinsfile.\nIs there anything you can’t do in a Jenkinsfile???\n\nAny of the configuration parameters available in the UI or in the YAML definition can be added to the podTemplate and containerTemplate sections.\nIn the example below, I’ve defined a pod with two container templates.\nThe pod label is used in the node block to signify that we want to spin up an instance of this pod.\nAny steps defined directly inside the node block but not in a container block with be run in the default JNLP container.\n\nThe container block is used to signify that the steps inside the block should be run inside the container with the given label.\nI’ve defined a container template with the label 'golang', which I will use to build the Go executable that I will eventually package into a Docker image.\nIn the volumes definition, I have indicated that I want to mount the Docker socket of the host, but I still need the Docker client to interact with it using the Docker API.\nTherefore, I’ve defined a container template with the label 'docker' which uses an image with the Docker client installed.\n\npodTemplate(\n    name: 'test-pod',\n    label: 'test-pod',\n    containers: [\n        containerTemplate(name: 'golang', image: 'golang:1.9.4-alpine3.7'),\n        containerTemplate(name: 'docker', image:'trion/jenkins-docker-client'),\n    ],\n    volumes: [\n        hostPathVolume(mountPath: '/var/run/docker.sock'),\n        hostPath: '/var/run/docker.sock',\n    ],\n    {\n        //node = the pod label\n        node('test-pod'){\n            //container = the container label\n            stage('Build'){\n                container('golang'){\n                    // This is where we build our code.\n                }\n            }\n            stage('Build Docker Image'){\n                container(‘docker’){\n                    // This is where we build the Docker image\n                }\n            }\n        }\n    })\n\nIn my Docker-based pipeline scripts, I was building Docker images and pushing them to a Docker registry, and it was important to me to replicate that exactly with my new Kubernetes setup.\nOnce I accomplished that, I was ready to build my image using gcloud, the Google Cloud SDK, and push that image to the Google Container Registry in anticipation of deploying to my K8s cluster.\n\nTo do this, I specified a container template using a gcloud image and changed my docker command to a gcloud command.\nIt’s that simple!\n\npodTemplate(\n    name: 'test-pod',\n    label: 'test-pod',\n    containers: [\n        containerTemplate(name: 'golang', image: 'golang:1.9.4-alpine3.7'),\n        containerTemplate(name: 'gcloud', image:'gcr.io/cloud-builders/gcloud'),\n    ],\n    {\n        //node = the pod label\n        node('test-pod'){\n            //container = the container label\n            stage('Build'){\n                container('golang'){\n                    // This is where we build our code.\n                }\n            }\n            stage('Build Docker Image'){\n                container(‘gcloud’){\n                    //This is where we build and push our Docker image.\n                }\n            }\n        }\n    })\n\nStanding up a Jenkins controller on Kubernetes, running ephemeral agents, and building and deploying a sample application only took me a couple of hours.\nI spent another weekend really digging in to better understand the platform.\nYou can be up and running in a matter of days if you are a quick study.\nThere are a wealth of resources available on running Jenkins on Kubernetes, and I hope this blog post helps to further that knowledge.\nEven better, come to\nmy session at Jenkins World and let’s talk in person.\n\nSo, what else do you want to know?\nHit me up on Twitter.\nI might even add your questions to my Jenkins World session.\nI suppose next up is Mesos?\n\nCome meet Mandy and other Jenkins and Kubernetes experts at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins and Kubernetes - Secret Agents in the Clouds","tags":["jenkinsworld","jenkinsworld2018","cloud-native","kubernetes"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#485858","images":{"fallback":{"src":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/19e71/devmandy.jpg","srcSet":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/77b35/devmandy.jpg 32w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/d4a57/devmandy.jpg 64w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/19e71/devmandy.jpg 128w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/68974/devmandy.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/ef6ff/devmandy.webp 32w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/8257c/devmandy.webp 64w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/6766a/devmandy.webp 128w,\n/gatsby-jenkins-io/static/04dee4202a439e0bfaf32d7e1722f2b0/22bfc/devmandy.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"DevMandy","html":"<div class=\"paragraph\">\n<p>Mandy Hubbard has almost 20 years of professional QA experience,\nmost of which has been spent in fast-paced startup environments driving product quality.\nShe is passionate about ensuring quality through process improvements, test automation, following CI/CD best practices and all things DevOps.\nShe is currently a software engineer/QA architect at CS Disco, an innovative startup delivering a cloud-based eDiscovery platform.</p>\n</div>","id":"devmandy","irc":null,"linkedin":null,"name":"Mandy Hubbard","slug":"/blog/authors/devmandy","twitter":"DevMandy"}]}},{"node":{"date":"2018-09-14T00:00:00.000Z","id":"9d454b50-9959-5557-8c15-e1041ef6bff4","slug":"/blog/2018/09/14/speaker-blog-jenkins-builds-jenkins/","strippedHtml":"Next week Olivier Vernin from CloudBees and Brian Benz from Microsoft will be presenting a session at DevOps World | Jenkins World about how Microsoft has been working with Jenkins to build Jenkins plugins and produce Jenkins on Microsoft Azure.\nThese plugins run Jenkins on Azure Linux and Windows VMs, Kubernetes, azure App service, as well as deploy artifacts to those Azure platforms and more.\nAll are open source and available on GitHub.\n\nHere’s our session, where we’ll be sharing successes and challenges of getting the infrastructure up and running:\n\nTuesday, September 18\n\nSession: Developing and Delivering Jenkins in the cloud\n11:15am - 12:00pm Brian Benz with Olivier Vernin, CloudBees\n\nIn this session, we’ll discuss the real-life implementation of Jenkins' development and delivery infrastructure in the cloud as it has evolved from a mix of platforms to Microsoft Azure.\nExpect a frank discussion of how issues that were encountered along the way were overcome, how the architecture has evolved, and what’s on the roadmap.\nWe’ll share important tips and tricks for implementing your own Jenkins infrastructure on any cloud, based on Jenkins' own experience with their implementation.\n\nSee you in San Francisco!\n\nCome meet us at\nDevOps World | Jenkins World 2018 on September 16-19th in San Francisco.\nWe will be hanging out around the OSS space, eager to answer more questions.\n\nRegister with the code JWFOSS for a 30% discount off your pass.","title":"Want to know how Jenkins builds Jenkins? Catch this session at DevOps World | Jenkins World next week in San Francisco!","tags":["jenkinsworld","jenkinsworld2018","azure","infrastructure"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/bf8e1/olblak.png","srcSet":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/914ee/olblak.png 32w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/1c9ce/olblak.png 64w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/bf8e1/olblak.png 128w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/acb7c/olblak.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/ef6ff/olblak.webp 32w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/8257c/olblak.webp 64w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/6766a/olblak.webp 128w,\n/gatsby-jenkins-io/static/f6d731c7e61ff5c7f0ddc7f2b8a6671e/22bfc/olblak.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"olblak","html":"<div class=\"paragraph\">\n<p>Olivier is the Jenkins infrastructure officer and Senior Operations Engineer at CloudBees.\nAs a regular contributor to the Jenkins infrastructure projects, he works on a wide range of tasks from services reliability to applications maintenance.</p>\n</div>","id":"olblak","irc":"olblak","linkedin":null,"name":"Olivier Vernin","slug":"/blog/authors/olblak","twitter":"0lblak"}]}},{"node":{"date":"2018-09-13T00:00:00.000Z","id":"e528d035-a68d-5607-bf76-e95c721d6e49","slug":"/blog/2018/09/13/speaker-blog-evergreen-safely-upgrading/","strippedHtml":"Evergreen is a distribution of Jenkins we are working on that provides an easy to use and automatically upgrading experience.\nThis year at the conference, there will be not just one, but two talks to present Evergreen to the Jenkins community:\n\nContinuously Delivering an Easy-to-Use Jenkins with Jenkins Evergreen, by R. Tyler Croy.\n\nSafely Upgrading Jenkins Every Single Day, by Baptiste Mathus.\n\nTyler will present the overall Jenkins Evergreen architecture, its inception and how this aims at making it much simpler for people to just use Jenkins to build their projects, without having to become Jenkins admins.\n\nOn the last conference day, during my own talk I will focus on the improved developer experience, and zoom into how we implemented some important features.\n\nWe will dig together into the Error Telemetry system put in place, allowing us to actually fix errors and warnings people see in production environments.\nHow instances are automatically reporting errors to the Evergreen backend, and how we then centralize and analyze them using Sentry.\nWe will explain how the Incrementals system allows developers a very short roundtrip, between a merged pull-request and a release we can push out to all instances.\nWe will see concrete examples of issues we already fixed and released to Evergreen instances in just a few days after we opened an alpha version to the world.\n\nI will show you how an instance starts up and gets upgraded by discussing with the backend it’s constantly connected to.\nHow the backend knows what it should instruct an instance to download and install, or how we trigger an automated data snapshot.\n\nYou will obviously see a demo of all this showing in particular how Evergreen can already run on a Docker host, or on AWS (more environments to come!), using some of the so-called flavors for Jenkins Evergreen.\n\nCome meet us at\nDevOps World | Jenkins World 2018 on September 16-19th in San Francisco.\nWe will be hanging out around the OSS space, eager to answer more questions.\n\nRegister with the code JWFOSS for a 30% discount off your pass.","title":"Speaker blogpost: Jenkins Evergreen At DevOps World | Jenkins World 2018","tags":["jenkinsworld","jenkinsworld2018","evergreen"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8e8d8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/f1e03/batmat.jpg","srcSet":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/ede19/batmat.jpg 32w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/bc20c/batmat.jpg 64w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/f1e03/batmat.jpg 128w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/b691b/batmat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/8ba60/batmat.webp 32w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/a9ea7/batmat.webp 64w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/51559/batmat.webp 128w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/28f98/batmat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":130}}},"blog":"http://batmat.net","github":"batmat","html":"<div class=\"paragraph\">\n<p>Baptiste has been using and contributing to Jenkins since it was called differently, and is a huge proponent of the Agile, Devops &amp; Continuous Delivery movements.\nHe loves to discuss not only the technical aspects, but also the even more essential cultural aspects of this all, working together to improve the value provided to customers in a great inclusive and blameless environment.</p>\n</div>","id":"batmat","irc":null,"linkedin":null,"name":"Baptiste Mathus","slug":"/blog/authors/batmat","twitter":"bmathus"}]}},{"node":{"date":"2018-09-12T00:00:00.000Z","id":"25b519ed-5da4-5f9a-a173-6ea9a343b90a","slug":"/blog/2018/09/12/speaker-blog-a-cloud-native-jenkins/","strippedHtml":"A few months ago I published a\nblog post about\nCloud Native Special Interest Group (SIG)\nand ongoing projects related to Cloud Native Jenkins.\nNext week we will be presenting at DevOps World | Jenkins World together with Carlos Sanchez and Jesse Glick,\nso I would like to provide a heads up for\nour talk: “A Cloud Native Jenkins”.\n\nIn our talk, we will focus on the following topics: Pluggable Storage,\nour ephemeral Jenkins controllers experiments,\nand tools which may be used to implement single-shot controllers.\n\nPluggable Storage\n\nPluggable storage is one of the major areas we have been working on over the last few months.\nThere are a number of parallel stories which are summarized on\nthis page.\nThere has been significant progress in the areas of artifact storage, build logging and configuration storage.\nA number of Jenkins Enhancement Proposals were submitted and accepted,\nand there are plugin releases and prototypes for these stories.\n\nDuring our talk we will discuss the current status of these stories and future plans.\nIn particular, we will cover the following areas and reference implementations:\n\nStoring all your artifacts transparently, e.g. in a cloud service blob store like AWS S3.\n\nArtifact Manager for S3 Plugin is an implementation we have recently released\n\nProviding credentials from an external location.\n\nKubernetes Credentials Provider is one of the existing implementations for Kubernetes secrets\n\nSending and retrieving the build logs from a cloud service.\n\nWe are working on reference implementations for AWS CloudWatch Logs and\nElasticsearch\n\nStoring configuration data in external storage like Kubernetes Resources and SQL database\n\nStoring test results externally, e.g. in an SQL database or a specialized Test Management System\n\nThere are existing plugins for the areas above, but there is a difference in approach we have taken.\nInstead of creating new custom steps we extend Jenkins architecture in a way that the storage becomes transparent to users.\nFor example, with Artifact Manager for S3 Plugin common Archive Artifacts steps\nwork transparently with Remote storage, as well as Jenkins Pipeline’s stash() / unstash() steps.\n\nThe reference implementations intentionally use different technologies so that we cover more scenarios.\nWe regularly discuss the implementations in the Cloud Native SIG,\nand we would appreciate your feedback.\n\nEphemeral Jenkins controllers research\n\nWant something new?\nSeveral days ago Kohsuke Kawaguchi, the creator of Jenkins, posted the\nJenkins: Shifting Gears article to summarize the plan for Jenkins evolution.\nCloud Native Jenkins is a critical part of this plan, and it is not “just Jenkins X”.\nThere are various architectural changes in Jenkins required to make this vision happen,\nand we plan to work on these changes in the Cloud Native SIG.\n\nIn our presentation, we will talk about our experiment with ephemeral Jenkins and single-shot controllers.\nIn this story we are creating a headless single-shot controller which starts in a container,\nexecutes a Pipeline build and pushes all the results to remote storage so that the container can just be deleted after completion.\nSuch a controller bundles plugins and self-configuration logic using “Configuration as Code”,\nso that it can start executing Pipelines in just a few seconds.\nOnce packaged, it can be invoked from CLI as simply as…​\n\ndocker run --rm -v $PWD/demo/Jenkinsfile:/workspace/Jenkinsfile onenashev/cwp-jenkinsfile-runner-demo\n\nor, in Kubernetes:\n\nkubectl create configmap jenkinsfile --from-file=demo/Jenkinsfile\nkubectl create -f demo/kubernetes.yaml\n\nSuch a single-shot controller could also be made a part of a Cloud Native Jenkins system.\nStandard event handlers like Prow can invoke the builds on webhooks and report results back,\nso that the single-shot controller can be used to build pull requests or to run Continuous Delivery flows.\nExtra agents could also be connected to the controller on-demand, using the Kubernetes plugin or sidecar containers.\n\nTools\n\nIn order to make this experiment possible, we used a toolchain based on\nDocker,\nJenkinsfile Runner,\nConfiguration as Code Plugin (JCasC), and a\nCustom WAR Packager tool which glues all the things together.\n\nCustom WAR Packager is a new tool which takes various configurations (YAML specification defining core version, list of plugins, system properties, Groovy Hooks, JCasC YAMLs)…​\nand then bundles everything as a ready-to-fly WAR file or Docker image.\nStarting from version 1.2, Custom WAR Packager also supports packaging Jenkinsfile Runner images as an experimental feature.\nI will do a separate blogpost about this new tool later,\nbut there is already some documentation a number of demos in the project’s repo.\n\nOur demo\n\nYes, we will have a demo! We will show a single-shot controller running with Pluggable storage implementations for AWS environments (Amazon S3, AWS CloudWatch, EKS, etc.),\nwhich executes Jenkins Pipelines for Maven projects and provisions agents in Kubernetes on-demand.\n\nThe demo has to be published yes, but you can already find a more simple Jenkinsfile Runner demo\nhere.\n\nWant to know more?\n\nThe upcoming DevOps World | Jenkins World conferences\nare heavily packed with talks related to Cloud Native Jenkins,\nincluding war stories and presentations on projects like Jenkins X and Jenkins Evergreen.\nIt is a great chance to get more information about using Jenkins in cloud environments.\n\nIf you are a Jenkins contributor or just want to become a contributor,\nalso join the Contributor Summit (Sep 17 in US and Oct 23 in Nice) or visit the Jenkins community booth in the Exhibition hall.\nAt the Contributor Summit on Sep 17 we will also have a face-to-face Cloud Native SIG meeting.\nFeel free to contribute to the agenda here.\n\nCome meet Carlos, Jesse, Oleg, and other Cloud Native SIG members at\nJenkins World on September 16-19th in San Francisco and on October 22-25 in Nice.\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Speaker blogpost: A Cloud Native Jenkins","tags":["jenkinsworld","jenkinsworld2018","cloud-native","pluggable-storage","jenkinsfile-runner"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png","srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/914ee/oleg_nenashev.png 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/1c9ce/oleg_nenashev.png 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/acb7c/oleg_nenashev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/ef6ff/oleg_nenashev.webp 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/8257c/oleg_nenashev.webp 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/6766a/oleg_nenashev.webp 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/22bfc/oleg_nenashev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member, open source software and open hardware advocate, TOC chair in the Continuous Delivery Foundation.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he maintains [Jenkinsfile Runner](<a href=\"https://github.com/jenkinsci/jenkinsfile-runner/\" class=\"bare\">https://github.com/jenkinsci/jenkinsfile-runner/</a>),\ncontributes to several Jenkins <a href=\"/sigs\">SIGs</a> and outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>)\nand organizes <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works on open source programs and [Keptn](<a href=\"https://keptn.sh/\" class=\"bare\">https://keptn.sh/</a>) at the [Dynatrace](<a href=\"https://dynatrace.com\" class=\"bare\">https://dynatrace.com</a>), Open Source Program Office.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/authors/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2018-09-11T00:00:00.000Z","id":"023ce63a-1296-5fa9-b1fd-4c4141fdc95b","slug":"/blog/2018/09/11/speaker-blog-warnings-plugin/","strippedHtml":"Jenkins' Warnings plugin collects compiler warnings or issues reported by static analysis tools and visualizes the\nresults. The plugin (and the associated static analysis plugin suite) has been part of the Jenkins plugin eco-system\nfor more than ten years now. In order to optimize user experience and support Pipeline, a major rewrite of\nthe whole set of plugins was necessary. This new version (code name White Mountain) is now available as a public\nbeta. Please download and install this new version and help us to identify problems before the API is sealed.\n\nThe new release is available in the\nexperimental update center.\nIt has built-in support for almost hundred static analysis tools (including several compilers), see the list of\nsupported report formats.\n\nFeatures overview\n\nThe Warnings plugin provides the following features when added as a post build action (or step) to a job:\n\nThe plugin scans the console log of a Jenkins build or files in the workspace of your job for any kind of issues.\nThere are almost one hundred\nreport formats supported.\nAmong the problems it can detect:\n\nerrors from your compiler (C, C#, Java, etc.)\n\nwarnings from a static analysis tool (CheckStyle, StyleCop, SpotBugs, etc.)\n\nduplications from a copy-and-paste detector (CPD, Simian, etc.)\n\nvulnerabilities\n\nopen tasks in comments of your source files\n\nThe plugin publishes a report of the issues found in your build, so you can navigate to a summary report from the\nmain build page. From there you can also dive into the details:\n\ndistribution of new, fixed and outstanding issues\n\ndistribution of the issues by severity, category, type, module, or package\n\nlist of all issues including helpful comments from the reporting tool\n\nannotated source code of the affected files\n\ntrend charts of the issues\n\nIn the next sections, I’ll show the new and enhanced features in more detail.\n\nOne plugin for all tools\n\nPreviously the warnings plugin was part of the static analysis suite that provided the same set of features through\nseveral plugins (CheckStyle, PMD, Static Analysis Utilities, Analysis Collector etc.).\nIn order to simplify the user experience and the development process, these\nplugins and the core functionality have been merged into the warnings plugin. All other plugins are not required\nanymore and will not be supported in the future. If you currently use one of these plugins you should migrate\nto the new recorders and steps as soon as possible. I will still maintain the old code for a while,\nbut the main development effort will be spent into the new code base.\n\nThe following plugins have been integrated into the beta version of the warnings plugin:\n\nAndroid-Lint Plugin\n\nCheckStyle Plugin\n\nCCM Plugin\n\nDry Plugin\n\nPMD Plugin\n\nFindBugs Plugin\n\nAll other plugins still need to be integrated or need to be refactored to use the new API.\n\nNew pipeline support\n\nRequirements for using the Warnings plugin in Jenkins Pipeline can be complex and sometimes controversial.\nIn order to be as flexible as possible I decided to split the main step into two individual parts,\nwhich could then be used independently from each other.\n\nSimple pipeline configuration\n\nThe simple pipeline configuration is provided by the step recordIssues. This step is automatically derived from the\nFreeStyle job recorder: it scans for issues in a given set of files (or in the console log) and reports these issues\nin your build. You can use the snippet generator to create a working snippet that calls this step. A typical example\nof this step is shown in the following example:\n\nrecordIssues\n    enabledForFailure: true,\n    tools: [[pattern: '*.log', tool: [$class: 'Java']]],\n    filters: [includeFile('MyFile.*.java'), excludeCategory('WHITESPACE')]\n\nIn this example, the files '*.log' are scanned for Java issues. Only issues with a file name matching the\npattern 'MyFile.*.java' are included. Issues with category 'WHITESPACE' will be excluded. The\nstep will be executed even if the build failed. The recorded report of warnings will be published under the fixed\nURL 'https://[ your-jenkins ]/job/[ your-job ]/java'. URL or name of the report can be changed if required.\n\nAdvanced Pipeline Configuration\n\nSometimes publishing and reporting issues using a single step is not sufficient. For instance, if you build your\nproduct using several parallel steps and you want to combine the issues from all of these steps into\na single result. Then you need to split scanning and aggregation. Therefore, the plugin  provides the following\ntwo steps that are combined by using an intermediate result object:\n\nscanForIssues : this step scans a report file or the console log with a particular parser and creates an\nintermediate report object that contains the report.\n\npublishIssues : this step publishes a new report in your build that contains the aggregated results\nof one or several scanForIssues steps.\n\nYou can see the usage of these two steps in the following example:\n\ndef java = scanForIssues tool: [$class: 'Java']\ndef javadoc = scanForIssues tool: [$class: 'JavaDoc']\n\npublishIssues issues:[java, javadoc], filters:[includePackage('io.jenkins.plugins.analysis.*')]\n\ndef checkstyle = scanForIssues tool: [$class: 'CheckStyle'], pattern: '**/target/checkstyle-result.xml'\npublishIssues issues:[checkstyle]\n\ndef pmd = scanForIssues tool: [$class: 'Pmd'], pattern: '**/target/pmd.xml'\npublishIssues issues:[pmd]\n\npublishIssues id:'analysis', name:'White Mountains Issues', issues:[checkstyle, pmd],\n    filters:[includePackage('io.jenkins.plugins.analysis.*')]\n\nFiltering issues\n\nThe created report of issues can be filtered afterwards. You can specify an arbitrary number of include or exclude\nfilters. Currently, there is support for filtering issues by module name, package or namespace name, file name,\ncategory or type.\n\nAn example pipeline that uses such a filter is shown in the following snippet:\n\nrecordIssues\n    tools: [[pattern: '*.log', tool: [$class: 'Java']]],\n    filters: [includeFile('MyFile.*.java'), excludeCategory('WHITESPACE')]\n\nQuality gate configuration\n\nYou can define several quality gates that will be checked after the issues have been reported. These quality gates\nlet you to modify Jenkins' build status so that you immediately see if the desired quality of your product is met.\nA build can be set to unstable or failed for each of these quality gates. All quality gates use a simple metric:\nthe maximum number of issues that can be found and still pass a given quality gate.\n\nAn example pipeline that enables a quality gate for 10 warnings in total or 1 new warning is shown in the\nfollowing snippet:\n\nrecordIssues\n    tools: [[pattern: '*.log', tool: [$class: 'Java']]], unstableTotalHigh: 10, unstableNewAll: 1\n\nIssues history: new, fixed, and outstanding issues\n\nOne highlight of the plugin is the ability to categorize issues of subsequent builds as new, fixed and outstanding.\n\nUsing this feature makes it a lot easier to keep the quality of your project under control: you can focus\nonly on those warnings that have been introduced recently.\n\nNote: the detection of new warnings is based on a complex algorithm that tries to track the same warning in\ntwo two different versions of the source code. Depending on the extend of the modification of the source code\nit might produce some false positives, i.e., you might still get some new and fixed warnings even if there should\nbe none. The accuracy of this algorithm is still ongoing research and will be refined in the next couple of months.\n\nSeverities\n\nThe plugin shows the distribution of the severities of the issues in a chart. It defines the\nfollowing default severities, but additional ones might be added by plugins that extend the warnings plugin.\n\nError : Indicates an error that typically fails the build\n\nWarning (High, Normal, Low): Indicates a warning of the given priority. Mapping to the priorities\nis up to the individual parsers.\n\nNote that not every parser is capable of producing warnings with a different severity. Some of the parses simply\nuse the same severity for all issues.\n\nBuild Trend\n\nIn order to see the trend of the analysis results, a chart showing the number of issues per build is also\nshown. This chart is used in the details page as well as in the job overview. Currently, type and configuration\nof the chart is fixed. This will be enhanced in future versions of the plugin.\n\nIssues Overview\n\nYou can get a fast and efficient overview of the reported set of issues in several aggregation views.\nDepending on the number or type of issues you will see the distribution of issues by\n\nStatic Analysis Tool\n\nModule\n\nPackage or Namespace\n\nSeverity\n\nCategory\n\nType\n\nEach of these detail views are interactive, i.e. you can navigate into a subset of the categorized issues.\n\nIssues Details\n\nThe set of reported issues is shown in a modern and responsive table. The table is loaded on demand using an Ajax\ncall. It provides the following features:\n\nPagination : the number of issues is subdivided into several pages which can be selected by using the provided page\nlinks. Note that currently the pagination is done on the client side, i.e. it may take some time to obtain the whole table of\nissues from the server.\n\nSorting : the table content can be sorted by clicking on ony of the table columns.\n\nFiltering, Searching : you can filter the shown issues by entering some text in the search box.\n\nContent Aware : columns are only shown if there is something useful to display. I.e., if a tool does not report an\nissues category, then the category will be automatically hidden.\n\nResponsive : the layout should adapt to the actual screen size.\n\nDetails : the details message for an issue (if provided by the corresponding static analysis tool) is shown as\nchild row within the table.\n\nRemote API\n\nThe plugin provides two REST API endpoints.\n\nSummary of the analysis result\n\nYou can obtain a summary of a particular analysis report by using the URL [tool-id]/api/xml\n(or [tool-id]/api/json). The summary contains the number of issues, the quality gate status, and all\ninfo and error messages.\n\nDetails of the analysis result\n\nThe reported issues are also available as REST API. You can either query all issues or only the\nnew, fixed, or outstanding issues. The corresponding URLs are:\n\n[tool-id]/all/api/xml : lists all issues\n\n[tool-id]/fixed/api/xml : lists all fixed issues\n\n[tool-id]/new/api/xml : lists all new issues\n\n[tool-id]/outstanding/api/xml : lists all outstanding issues\n\nHow You Can Help\n\nI hope these new features are useful for everyone! Please download or install this new release and test it in your jobs:\n\nConvert some of your jobs to the new API and test the new (and old) features (based on your requirements).\n\nRead all labels carefully, I’m not a native speaker so some descriptions might be misleading or incorrect.\n\nCheck the new URLs and names of the parsers, see list of\nsupported report formats. These\ncan’t be changed after the beta testing.\n\nIf you find a problem, incorrect phrase, typo, etc. please report a bug in Jira (or even better: file a PR in GitHub).\n\nThis has been a brief overview of the new features of the Warnings plugin in Jenkins. For more, be sure to check out my\ntalk at \"DevOps World | Jenkins World\" where I show more details of the Warnings plugin!\n\nCome see Ullrich Hafner and many other Jenkins experts and contributors at\nDevOps World | Jenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Warnings Plugin 5.0 (White Mountain) Public Beta","tags":["warnings","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/19e71/uhafner.jpg","srcSet":"/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/77b35/uhafner.jpg 32w,\n/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/d4a57/uhafner.jpg 64w,\n/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/19e71/uhafner.jpg 128w,\n/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/68974/uhafner.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/ef6ff/uhafner.webp 32w,\n/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/8257c/uhafner.webp 64w,\n/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/6766a/uhafner.webp 128w,\n/gatsby-jenkins-io/static/0fb8b41130558af9f99633c80520b3dc/22bfc/uhafner.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"uhafner","html":"<div class=\"paragraph\">\n<p>Ullrich Hafner is an active contributor in the Jenkins project since 2007, mostly in the acceptance test harness and\nthe static code analysis suite (which is now replaced by the Warnings Next Generation Plugin).</p>\n</div>\n<div class=\"paragraph\">\n<p>He is a professor for Software Engineering at the University of Applied Sciences Munich. In his role as professor\nhe tries to win new Jenkins contributors by letting students develop new features and test cases in their student\nprojects and theses.</p>\n</div>","id":"uhafner","irc":null,"linkedin":null,"name":"Ullrich Hafner","slug":"/blog/authors/uhafner","twitter":null}]}}]}},"pageContext":{"tag":"jenkinsworld","limit":8,"skip":8,"numPages":8,"currentPage":2}},
    "staticQueryHashes": ["3649515864"]}