{
    "componentChunkName": "component---src-templates-post-js",
    "path": "/blog/2017/07/05/continuousdelivery-devops-artifactory/",
    "result": {"data":{"blog":{"html":"<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<i class=\"fa icon-note\" title=\"Note\"></i>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>This is a guest post by <a href=\"https://github.com/michaelhuettermann\">Michael Hüttermann</a>. Michael is an expert\nin Continuous Delivery, DevOps and SCM/ALM. More information about him at <a href=\"http://huettermann.net\">huettermann.net</a>, or\nfollow him on Twitter: <a href=\"https://twitter.com/huettermann\">@huettermann</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>In a past blog post <a href=\"/blog/2017/04/18/continuousdelivery-devops-sonarqube/\">Delivery Pipelines,\nwith Jenkins 2, SonarQube, and Artifactory</a>, we talked about pipelines which result in binaries for development versions. Now, in this blog post, I zoom in to different parts of the\nholistic pipeline and cover the handling of possible downstream steps once you have the binaries of development versions, in our example a Java EE WAR and a Docker image (which contains the WAR).\nWe discuss basic concept of staging software, including further information about quality gates, and show example toolchains. This contribution particularly examines the staging from binaries from\ndev versions to release candidate versions and from release candidate versions to final releases from the perspective of the automation server Jenkins, integrating with the binary\nrepository manager JFrog Artifactory and the distribution management platform JFrog Bintray, and ecosystem.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"staging-software\"><a class=\"anchor\" href=\"#staging-software\"></a>Staging software</h3>\n<div class=\"paragraph\">\n<p>Staging (also often called promoting) software is the process of completely and consistently transferring a release with all its configuration items\nfrom one environment to another. This is even more true with DevOps, where you want to accelerate the <em>cycle time</em> (see Michael Hüttermann, <em>DevOps for Developers</em> (Apress, 2012), 38ff).\nFor accelerating the cycle time, meaning to bring software to production, fast and in good quality, it is crucial to have fine processes and integrated tools to streamline the\ndelivery of software. The process of staging releases consists of deploying software to different staging levels, especially different test environments.\nStaging also involves configuring the software for various environments without needing to recompile or rebuild the software. Staging is necessary\nto transport the software to production systems in high quality. Many Agile projects make great experience with implementing a staging ladder in\norder to optimize the cycle time between development software and the point when the end user is able to use the software in production.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/01.png\" alt=\"01\" title=\"A typical stagging ladder, aka delivery pipeline.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Commonly, the staging ladder is illustrated on its side, with the higher rungs being the boxes further to the right. It’s good practice not to skip any rungs during staging.\nThe central development environment packages and integrates all respective configuration items and is the base for releasing. Software is staged over different environments by\nconfiguration, without rebuilding. All changes go through the entire staging process, although defined exception routines may be in place,\nfor details see Michael Hüttermann, <em>Agile ALM</em> (Manning, 2012).</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<i class=\"fa icon-note\" title=\"Note\"></i>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>To make concepts clearer, this blog post covers sample tools. Please note, that there are also alternative tools available. As one example: Sonatype Nexus is also able to host the covered binaries and also offers scripting functionality.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>We nowadays often talk about <em>delivery pipelines</em>. A pipeline is just a set of stages and transition rules between those stages. From a DevOps perspective, a pipeline bridges multiple\nfunctions in organizations, above all development and operations. A pipeline is a staging ladder. A change enters the pipeline at the beginning and leaves it at the end. The processing\ncan be triggered automatically (typical for delivery pipelines) or by a human actor (typical for special steps at overall pipelines, e.g. pulling and thus cherry-picking specific\nversions to promote them to be release candidates are final releases).</p>\n</div>\n<div class=\"paragraph\">\n<p>Pipelines often look different, because they strongly depend on requirements and basic conditions, and can contain further sub pipelines. In our scenario, we have two sub pipelines to\nmanage the promotion of continuous dev versions to release candidates and the promotion of release candidates to final release. A change typically waits at a stage for further processing\naccording to the transition rules, aligned with defined requirements to meet, which are the Quality Gates, explored next.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"quality-gates\"><a class=\"anchor\" href=\"#quality-gates\"></a>Quality Gates</h3>\n<div class=\"paragraph\">\n<p>Quality gates allow the software to pass through stages only if it meets their defined requirements. The next illustration shows a staging ladder with quality gates injected. You and\nother engaged developers commit code to the version control system (please, use VCS as an abbreviation, not SCM, because the latter is much more) in order to update the central test\nenvironment only if the code satisfies the defined quality requirements; for instance, the local build may need to run successfully and have all tests pass locally. Build, test, and\nmetrics should pass out of the central development environment, and then automated and manual acceptance tests are needed to pass the system test. In our case, the last quality gate\nto pass is the one from the  production mirror to production. Here, for example, specific production tests are done or relevant documents must be filled in and signed.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/02.png\" alt=\"02\" title=\"A pipeline with quality gates injected.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>It’s mandatory to define the quality requirements in advance and to resist customizing them after the fact, when the software has failed. Quality gates are different at lower and\nhigher stages; the latter normally consist of a more severe or broader set of quality requirements, and they often include the requirements of the lower gates. The binary repository\nmanager must underpin corresponding quality gates, while managing the binaries, what we cover next.</p>\n</div>\n<div class=\"admonitionblock tip\">\n<table>\n<tr>\n<td class=\"icon\">\n<i class=\"fa icon-tip\" title=\"Tip\"></i>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>This blog post illustrates typical concepts and sample toolchains. For more information, please consult the respective documentation, good books or attend top notch conferences, e.g.\n<a href=\"https://www.cloudbees.com/jenkinsworld/home\">Jenkins World, powered by CloudBees</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"binary-repository-manager\"><a class=\"anchor\" href=\"#binary-repository-manager\"></a>Binary repository manager</h3>\n<div class=\"paragraph\">\n<p>A central backbone of the staging ladder is the binary repository manager, e.g. JFrog Artifactory. The binary repository manager manages all binaries including the self-produced\nones (producing view) and the 3rd party ones (consuming view), across all artifact types, in our case a Java EE WAR file and a Docker image. Basic idea here is that the repo manager serves\nas a proxy, thus all developers access the repo manager, and not remote binary pools directly, e.g. Maven Central. The binary repository manager offers cross-cutting services,\ne.g. role-based access control on specific logical repositories, which may correspond to specific stages of the staging ladder.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/03.png\" alt=\"03\" title=\"JFrog Artifactory serves as a proxy.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Logical repositories can be generic ones (meaning they are agnostic regarding any tools and platforms, thus you can also just upload the menu of your local canteen) or repos\nspecific to tools and platforms. In our case, we need a repository for managing the Java EE WAR files and for the Docker images. This can be achieved by</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>a generic repository (preferred for higher stages) or a repo which is aligned with the layout of the Maven build tool, and</p>\n</li>\n<li>\n<p>a repository for managing Docker images, which serves as a Docker registry.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>In our scenario, preparing the staging of artifacts includes the following ramp-up activities</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Creating two sets of logical repositories, inside JFrog Artifactory, where each set has a repo for the WAR file and a repo for the Docker image, and one set is for managing dev\nversions and one set is for release candidate versions.</p>\n</li>\n<li>\n<p>Defining and implementing processes to promote the binaries from the one set of repositories (which is for dev versions) to the other set of repositories (which is for RC versions).\nPart of the process is defining roles, and JFrog Artifactory helps you to implement role-based access control.</p>\n</li>\n<li>\n<p>Setting up procedures or scripts to bring binaries from one set of repositories to the other set of repositories, reproducibly. Adding meta data to binaries is important if the degree of maturity\nof the binary cannot be easily derived from the context.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>The following illustration shows a JFrog Artifactory instance with the involved logical repos in place. In our simplified example, the repo promotions are supposed to go from\n<em>docker-local</em> to <em>docker-prod-local</em>, and from <em>libs-release-local</em> to <em>libs-releases-staging-local</em>. In our use case, we promote the software in version 1.0.0.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/04.png\" alt=\"04\" title=\"Logical repos, inside JFrog Artifactory.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Another type of binary repository manager is JFrog Bintray, which serves as a universal distribution platform for many technologies. JFrog Bintray can be an interesting choice\nif you have strong requirements for scalability and worldwide coverage including IP restrictions and handy features around statistics. Most of the concepts and ramp up activities\n are similar compared to JFrog Artifactory, thus I do not want to repeat them here. Bintray is used by lot of projects e.g. by Groovy, to host their deliverables in the public.\n But keep in mind that you can of course also host your release binaries in JFrog Artifactory.\n In this blog post, I&#8217;d like to introduce different options, thus we promote our release candidates to JFrog Artifactory and our releases to JFrog Bintray.\n Bintray has the concept of <em>products</em>, <em>packages</em> and <em>versions</em>. A product can have multiple packages and has different versions. In our example, the product has two packages, namely the Java EE WAR and\n the Docker image, and the concrete version that will be processed is 1.0.0.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<i class=\"fa icon-note\" title=\"Note\"></i>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Some tool features covered in this blog post are available as part of commercial offerings of tool vendors. Examples include the Docker support of JFrog Artifactory or the Firehose Event API of JFrog Bintray.\nPlease consult the respective documentation for more information.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>Now it is time to have a deeper look at the pipelines.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"implementing-pipelines\"><a class=\"anchor\" href=\"#implementing-pipelines\"></a>Implementing Pipelines</h3>\n<div class=\"paragraph\">\n<p>Our example pipelines are implemented with Jenkins, including its Blue Ocean and declarative pipelines facilities, JFrog Artifactory and JFrog Bintray. To derive your personal\npipelines, please check your individual requirements and basic conditions to come up with the best solution for your target architecture, and consult the respective documentation for\n more information, e.g. about scripting the tools.</p>\n</div>\n<div class=\"paragraph\">\n<p>In case your development versions are built with Maven, and have <em>SNAPSHOT</em> character, you need to either rebuild the software after setting the release version, as part of\nyour pipeline, or you solely use Maven releases from the very beginning. Many projects make great experience with morphing Maven snapshot versions into\nrelease versions, as part of the pipeline, by using a dedicated Maven plugin, and externalizing it into a Jenkins shared library. This can look like the following:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">sl.groovy (excerpt): A Jenkins shared library, to include in Jenkins pipelines.</div>\n<div class=\"content\">\n<pre class=\"nowrap\">    #!/usr/bin/groovy\n    def call(args) { <i class=\"conum\" data-value=\"1\"></i><b>(1)</b>\n       echo \"Calling shared library, with ${args}.\"\n       sh \"mvn com.huettermann:versionfetcher:1.0.0:release versions:set -DgenerateBackupPoms=false -f ${args}\"  <i class=\"conum\" data-value=\"2\"></i><b>(2)</b>\n    }</pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<table>\n<tr>\n<td><i class=\"conum\" data-value=\"1\"></i><b>1</b></td>\n<td>We provide a global variable/function to include it in our pipelines.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"2\"></i><b>2</b></td>\n<td>The library calls a Maven plugin, which dynamically morphs the snapshot version of a Maven project to a release version.</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>And including it into the pipeline is then also very straight forward:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">pipeline.groovy (excerpt): A stage calling a Jenkins shared library.</div>\n<div class=\"content\">\n<pre class=\"nowrap\">    stage('Produce RC') { <i class=\"conum\" data-value=\"1\"></i><b>(1)</b>\n        releaseVersion 'all/pom.xml' <i class=\"conum\" data-value=\"2\"></i><b>(2)</b>\n    }</pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<table>\n<tr>\n<td><i class=\"conum\" data-value=\"1\"></i><b>1</b></td>\n<td>This stage is part of a scripted pipeline and is dedicated to morphing a Maven snapshot version into a release version, dynamically.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"2\"></i><b>2</b></td>\n<td>We call the Jenkins shared library, with a parameter pointing to the Maven POM file, which can be a parent POM.</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>You can find the code of the underlying Maven plugin <a href=\"https://github.com/michaelhuettermann/sandbox/blob/master/versionfetcher/src/main/java/VersionFetcher/VersionFetcher.java\">here</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>Let&#8217;s now discuss how to proceed for the release candidates.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"release-candidate-rc\"><a class=\"anchor\" href=\"#release-candidate-rc\"></a>Release Candidate (RC)</h3>\n<div class=\"paragraph\">\n<p>The pipeline to promote a dev version to a RC version does contain a couple of different stages, including stages to certify the binaries (meaning labeling it or adding context information) and stages to process the concrete promotion.\nThe following illustration shows the successful run of the promotion, for software version 1.0.0.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/05.png\" alt=\"05\" title=\"Promotion to RC. Looks like it succeeded.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>We utilize Jenkins Blue Ocean that is a new user experience for Jenkins based on a personalizable, modern design that allows users to graphically create, visualize and diagnose\ndelivery pipelines. Besides the new approach in general, single Blue Ocean features help to boost productivity dramatically, e.g. to provide log information at your fingertips\nand the ability to search pipelines. The stages to perform the promote are as follows starting with the  Jenkins pipeline stage for promoting the WAR file. Keep in mind that all\nscripts are parameterized, including variables for versions and Artifactory domain names, which are either injected to the pipeline run by user input or set system wide in the Jenkins admin panel,\nand the underlying call is using the JFrog command line interface, <em>CLI</em> in short. JFrog Artifactory\nas well as JFrog Bintray can be used and managed by scripts, based on a <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">REST API</a>. The JFrog CLI\nis an abstraction on top of the JFrog REST API, and we show sample usages of both.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">pipeline.groovy (excerpt): Staging WAR file to different logical repository</div>\n<div class=\"content\">\n<pre class=\"nowrap\">    stage('Promote WAR') { <i class=\"conum\" data-value=\"1\"></i><b>(1)</b>\n       steps { <i class=\"conum\" data-value=\"2\"></i><b>(2)</b>\n          sh 'jfrog rt cp --url=https://$ARTI3 --apikey=$artifactory_key --flat=true libs-release-local/com/huettermann/web/$version/ ' + <i class=\"conum\" data-value=\"3\"></i><b>(3)</b>\n             'libs-releases-staging-local/com/huettermann/web/$version/'\n       }\n    }</pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<table>\n<tr>\n<td><i class=\"conum\" data-value=\"1\"></i><b>1</b></td>\n<td>The dedicated stage for running the promotion of the WAR file.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"2\"></i><b>2</b></td>\n<td>Here we have the steps which make up the stage, based on Jenkins declarative pipeline syntax.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"3\"></i><b>3</b></td>\n<td>Copying the WAR file, with JFrog CLI, using variables, e.g. the domain name of the Artifactory installation. Many options available, check the docs.</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>The second stage to explore more is the promotion of the Docker image. Here, I want to show you a different way how to achieve the goal, thus in this use case we utilize the JFrog REST API.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">pipeline.grovvy (excerpt): Promote Docker image</div>\n<div class=\"content\">\n<pre class=\"nowrap\">    stage('Promote Docker Image') {\n          sh '''curl -H \"X-JFrog-Art-Api:$artifactory_key\" -X POST https://$ARTI3/api/docker/docker-local/v2/promote ''' + <i class=\"conum\" data-value=\"1\"></i><b>(1)</b>\n             '''-H \"Content-Type:application/json\" ''' + <i class=\"conum\" data-value=\"2\"></i><b>(2)</b>\n             '''-d \\'{\"targetRepo\" : \"docker-prod-local\", \"dockerRepository\" : \"michaelhuettermann/tomcat7\", \"tag\": \"\\'$version\\'\", \"copy\": true }\\' <i class=\"conum\" data-value=\"3\"></i><b>(3)</b>\n             '''\n    }</pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<table>\n<tr>\n<td><i class=\"conum\" data-value=\"1\"></i><b>1</b></td>\n<td>The shell script to perform the staging of Docker image is based on JFrog REST API.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"2\"></i><b>2</b></td>\n<td>Part of parameters are sent in JSON format.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"3\"></i><b>3</b></td>\n<td>The payload tells the REST API endpoint what to to, i.e. gives information about <em>target repo</em> and <em>tag</em>.</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>Once the binaries are promoted (and hopefully deployed and tested on respective environments before), we can promote them to become final releases, which I like to call GA.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"general-availability-ga\"><a class=\"anchor\" href=\"#general-availability-ga\"></a>General Availability (GA)</h3>\n<div class=\"paragraph\">\n<p>In our scenario, JFrog Bintray serves as the distribution platform to manage and provide binaries for further usage. Bintray can also serve as a Docker registry, or can just\nprovide binaries for scripted or manual download. There are again different ways how to promote binaries, in this case from the RC repos inside JFrog Artifactory to the GA storage in JFrog Bintray, and I summarize one of those possible ways. First, let&#8217;s look at the Jenkins pipeline, showed in the next illustration. The processing is on its way, currently, and we again have a list of linked stages.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/06.png\" alt=\"06\" title=\"Promotion to GA is running &#8230;&#8203;\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Zooming in now to the key stages, we see that promoting the WAR file is a set of steps that utilize JFrog REST API. We download the binary from JFrog Artifactory, parameterized,\nand upload it to JFrog Bintray.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">pipeline.groovy (excerpt): Promote WAR to Bintray</div>\n<div class=\"content\">\n<pre class=\"nowrap\">    stage('Promote WAR to Bintray') {\n       steps {\n          sh '''\n             curl -u michaelhuettermann:${bintray_key} -X DELETE https://api.bintray.com/packages/huettermann/meow/cat/versions/$version <i class=\"conum\" data-value=\"1\"></i><b>(1)</b>\n             curl -u michaelhuettermann:${bintray_key} -H \"Content-Type: application/json\" -X POST https://api.bintray.com/packages/huettermann/meow/cat/$version --data \"\"\"{ \"name\": \"$version\", \"desc\": \"desc\" }\"\"\" <i class=\"conum\" data-value=\"2\"></i><b>(2)</b>\n             curl -T \"$WORKSPACE/all-$version-GA.war\" -u michaelhuettermann:${bintray_key} -H \"X-Bintray-Package:cat\" -H \"X-Bintray-Version:$version\" https://api.bintray.com/content/huettermann/meow/ <i class=\"conum\" data-value=\"3\"></i><b>(3)</b>\n             curl -u michaelhuettermann:${bintray_key} -H \"Content-Type: application/json\" -X POST https://api.bintray.com/content/huettermann/meow/cat/$version/publish --data '{ \"discard\": \"false\" }' <i class=\"conum\" data-value=\"4\"></i><b>(4)</b>\n          '''\n       }\n    }</pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<table>\n<tr>\n<td><i class=\"conum\" data-value=\"1\"></i><b>1</b></td>\n<td>For testing and demo purposes, we remove the existing release version.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"2\"></i><b>2</b></td>\n<td>Next we create the version in Bintray, in our case the created version is <em>1.0.0</em>. The value was insert by user while triggering the pipeline.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"3\"></i><b>3</b></td>\n<td>The upload of the WAR file.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"4\"></i><b>4</b></td>\n<td>Bintray needs a dedicated publish step to make the binary publicly available.</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>Processing the Docker image is as easy as processing the WAR. In this case, we just push the Docker image to the Docker registry, which is served by JFrog Bintray.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">pipeline.groovy (excerpt): Promote Docker image to Bintray</div>\n<div class=\"content\">\n<pre class=\"nowrap\">    stage('Promote Docker Image to Bintray') { <i class=\"conum\" data-value=\"1\"></i><b>(1)</b>\n       steps {\n          sh 'docker push $BINTRAYREGISTRY/michaelhuettermann/tomcat7:$version' <i class=\"conum\" data-value=\"2\"></i><b>(2)</b>\n       }\n    }</pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<table>\n<tr>\n<td><i class=\"conum\" data-value=\"1\"></i><b>1</b></td>\n<td>The stage for promoting the Docker image. Please note, depending on your setup, you may add further stages, e.g. to login to your Docker registry.</td>\n</tr>\n<tr>\n<td><i class=\"conum\" data-value=\"2\"></i><b>2</b></td>\n<td>The Docker push of the specific version. Note, that also here all variables are parameterized.</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>We now have promoted the binaries and uploaded them to JFrog Bintray. The overview page of our product lists two packages: the WAR file and the Docker image. Both can be downloaded\nnow and used, the Docker image can be pulled from the JFrog Bintray Docker registry with native Docker commands.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/07.png\" alt=\"07\" title=\"Distribution management platform JFrog Bintray holds our binaries: a WAR file and a Docker image, in version 1.0.0.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>As part of its graphical visualization capabilitites, Bintray is able to show the single layers of the uploaded Docker images.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/08.png\" alt=\"08\" title=\"Docker layers of our uploaded Docker image, visualized in JFrog Bintray.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Bintray can also display usage statistics, e.g. download details. Now guess where I&#8217;m sitting right now while downloading the binary?</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/09.png\" alt=\"09\" title=\"JFrog Bintray displays download statistics of our binaries.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Besides providing own statistics, Bintray provides the JFrog Firehose Event API. This API streams live usage data, which in turn can be integrated or aggregated with your ecosystem.\nIn our case, we visualize the data, particularly download, upload, and delete statistics, with the ELK stack, as part of a functional monitoring initiative.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/artifactory-jenkins/10.png\" alt=\"10\" title=\"The ELK stack visualizes real-time data delivered from JFrog Bintray, via JFrog Firehose Event API.\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Crisp, isn&#8217;t it?</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"summary\"><a class=\"anchor\" href=\"#summary\"></a>Summary</h3>\n<div class=\"paragraph\">\n<p>This closes are quick ride through the world of staging binaries, based on Jenkins. We&#8217;ve discussed concepts and example DevOps enabler tools, which can help to implement\n the concepts. Along the way, we discussed some more options how to integrate with ecosystem, e.g. releasing Maven snapshots and functional monitoring with dedicated tools.\n After this appetizer you may want to now consider to double-check your staging processes and toolchains, and maybe you find some room for further adjustments.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"references\"><a class=\"anchor\" href=\"#references\"></a>References</h3>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"http://huettermann.net/alm/\">'Agile ALM', Manning, 2011</a></p>\n</li>\n<li>\n<p><a href=\"https://binary-repositories-comparison.github.io/\">Binary Repository Manager Feature Matrix</a></p>\n</li>\n<li>\n<p><a href=\"http://huettermann.net/devops/\">'DevOps for Developers', Apress, 2012</a></p>\n</li>\n<li>\n<p><a href=\"https://www.docker.com/\">Docker</a></p>\n</li>\n<li>\n<p><a href=\"https://www.elastic.co\">ELK</a></p>\n</li>\n<li>\n<p><a href=\"https://www.jfrog.com/artifactory/\">JFrog Artifactory</a></p>\n</li>\n<li>\n<p><a href=\"https://www.jfrog.com/bintray/\">JFrog Bintray</a></p>\n</li>\n<li>\n<p><a href=\"https://www.jfrog.com/confluence/display/CLI/JFrog+CLI\">JFrog CLI</a></p>\n</li>\n<li>\n<p><a href=\"https://www.jfrog.com/confluence/display/RTF/Artifactory+REST+API\">JFrog REST API</a></p>\n</li>\n<li>\n<p><a href=\"https://www.sonatype.com/\">Sonatype Nexus</a></p>\n</li>\n</ul>\n</div>\n</div>","id":"fd2d8b89-b05f-5caf-a6b1-923d33960065","title":"Delivery pipelines, with Jenkins 2: how to promote Java EE and Docker binaries toward production.","date":"2017-07-05T00:00:00.000Z","slug":"/blog/2017/07/05/continuousdelivery-devops-artifactory/","links":{"discourse":""},"authors":[{"avatar":{"childImageSharp":null},"blog":"http://huettermann.net","github":"michaelhuettermann","html":"<div class=\"paragraph\">\n<p>Michael is expert in Continuous Delivery, DevOps and SCM/ALM supporting enterprises in implementing DevOps.\nMichael is Jenkins Ambassador.</p>\n</div>","id":"michaelhuettermann","irc":null,"linkedin":null,"name":"Michael Hüttermann","slug":"/blog/author/michaelhuettermann","twitter":"huettermann"}]}},"pageContext":{"next":"/blog/2017/07/07/jenkins-conan/","previous":"/blog/2017/07/03/contributor-summit/","id":"fd2d8b89-b05f-5caf-a6b1-923d33960065"}},
    "staticQueryHashes": ["1271460761","3649515864"]}