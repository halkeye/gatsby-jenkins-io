{
    "componentChunkName": "component---src-templates-post-js",
    "path": "/blog/2017/05/15/kubernetes-journey-on-azure/",
    "result": {"data":{"blog":{"html":"<div class=\"paragraph\">\n<p>With the\n<a href=\"/blog/2016/05/18/announcing-azure-partnership/\">ongoing migration to Azure</a>,\nI would like to share my thoughts regarding one of the biggest challenges we\nhave faced thus far: <strong>orchestrating container infrastructure</strong>. Many of the\nJenkins project&#8217;s applications are run as Docker containers, making Kubernetes\na logical choice as far as running our containers, but it presents its own set\nof challenges. For example, what would the workflow from development to\nproduction look like?</p>\n</div>\n<div class=\"paragraph\">\n<p>Before going deeper into the challenges, let&#8217;s review the requirements we\nstarted with:</p>\n</div>\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\">Git</dt>\n<dd>\n<p>We found it mandatory to keep track of all the infrastructure changes in Git\nrepositories, including secrets, in order to facilitate reviewing,\nvalidation, rollback, etc of all infra changes.</p>\n</dd>\n<dt class=\"hdlist1\">Tests</dt>\n<dd>\n<p>Infrastructure contributors are geographically distributed and in different\ntimezones.  Getting feedback can take time, so we heavily rely on a lot of\ntests before any changes can be merged.</p>\n</dd>\n<dt class=\"hdlist1\">Automation</dt>\n<dd>\n<p>The change submitter is not necessarily the person who will deploy it.\nRepetitive tasks are error prone and a waste of time.\nFor these reasons, all steps must be automated and stay as simple as possible.</p>\n</dd>\n</dl>\n</div>\n<div class=\"paragraph\">\n<p>A high level overview of our \"infrastructure as code\" workflow would look like:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Infrastructure as Code Workflow</div>\n<div class=\"content\">\n<pre class=\"nowrap\">  __________       _________       ______________\n  |         |      |        |      |             |\n  | Changes | ----&gt;|  Test  |-----&gt;| Deployment  |\n  |_________|      |________|  ^   |_____________|\n                               |\n                        ______________\n                       |             |\n                       | Validation  |\n                       |_____________|</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>We identified two possible approaches for implementing our container\norchestration with Kubernetes:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>The Jenkins Way: Jenkins is triggered by a Git commit, runs the tests, and\nafter validation, Jenkins deploys changes into production.</p>\n</li>\n<li>\n<p>The Puppet Way: Jenkins is triggered by a Git commit, runs the tests, and\nafter validation, it triggers Puppet to deploy into production.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>Let&#8217;s discuss these two approaches in detail.</p>\n</div>\n<div class=\"sect1\">\n<h2 id=\"the-jenkins-way\"><a class=\"anchor\" href=\"#the-jenkins-way\"></a>The Jenkins Way</h2>\n<div class=\"sectionbody\">\n<div class=\"listingblock\">\n<div class=\"title\">Workflow</div>\n<div class=\"content\">\n<pre class=\"nowrap\">  _________________       ____________________       ______________\n  |                |      |                   |      |             |\n  |    Github:     |      |     Jenkins:      |      |   Jenkins:  |\n  | Commit trigger | ----&gt;| Test &amp; Validation | ----&gt;|  Deployment |\n  |________________|      |___________________|      |_____________|</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In this approach, Jenkins is used to test, validate, and deploy our Kubernetes\nconfiguration files.  <code>kubectl</code> can be run on a directory and is idempotent.\nThis means that we can run it as often as we want: the result will not change.\nTheoretically, this is the simplest way. The only thing needed is to run\n<code>kubectl</code> command each time Jenkins detects changes.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following Jenkinsfile gives an example of this workflow.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Jenkinsfile</div>\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-groovy\" data-lang=\"groovy\">  pipeline {\n    agent any\n    stages {\n      stage('Init'){\n        steps {\n          sh 'curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl'\n        }\n      }\n      stage('Test'){\n        steps {\n          sh 'Run tests'\n        }\n      }\n      stage('Deploy'){\n        steps {\n          sh './kubectl apply -R true -f my_project'\n        }\n      }\n    }\n  }</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The devil is in the details of course, and it was not as easy as it looked at\nfirst sight.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"order-matters\"><a class=\"anchor\" href=\"#order-matters\"></a>Order matters</h3>\n<div class=\"paragraph\">\n<p>Some resources needed to be deployed before others. A workaround was to use\nnumbers as file names. But this added extra logic at file name level, for\nexample:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code>project/00-nginx-ingress\nproject/09-www.jenkins.io</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"portability\"><a class=\"anchor\" href=\"#portability\"></a>Portability</h3>\n<div class=\"paragraph\">\n<p>The deployment environments needed to be the same across development machines\nand the Jenkins host. Although this a well-known problem, it was not easy to\nsolve.  The more the project grew, the more our scripts needed additional tools\n(<code>make</code>, <code>bats</code>, <code>jq</code> <code>gpg</code>, etc).  The more tools we used, the more issues\nappeared because of the different versions used.</p>\n</div>\n<div class=\"paragraph\">\n<p>Another challenge that emerged when dealing with different environments was:\nhow should we manage environment-specific configurations (dev, prod, etc)?\nWould it be better to define different configuration files per environment?\nPerhaps, but this means code duplication, or using file templates which would require\nmore tools (<code>sed</code>, <code>jinja2</code>, <code>erb</code>), and more work.</p>\n</div>\n<div class=\"paragraph\">\n<p>There wasn&#8217;t a golden rule we discovered, and the answer is probably somewhere in between.</p>\n</div>\n<div class=\"paragraph\">\n<p>In any case, the good news is that a <code>Jenkinsfile</code> provides an easy way to\nexecute tasks from a Docker image, and an image can contain all the necessary\ntools in our environment. We can even use different Docker images for each\nstage along the way.</p>\n</div>\n<div class=\"paragraph\">\n<p>In the following example, I use the <code>my_env</code> Docker image. It contains all the\ntools needed to test, validate, and deploy changes.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Jenkinsfile</div>\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-groovy\" data-lang=\"groovy\">pipeline{\n  agent {\n    docker{\n      image 'my_env:1.0'\n    }\n  }\n  options{\n    buildDiscarder(logRotator(numToKeepStr: '10'))\n    disableConcurrentBuilds()\n    timeout(time: 1, unit: 'HOURS')\n  }\n  triggers{\n    pollSCM('* * * * *')\n  }\n  stages{\n    stage('Init'){\n      steps{\n        // Init everything required to deploy our infra\n        sh 'make init'\n      }\n    }\n    stage('Test'){\n      steps{\n       // Run tests to validate changes\n       sh 'make test'\n      }\n    }\n    stage('Deploy'){\n      steps{\n       // Deploy changes in production\n       sh 'make deploy'\n      }\n    }\n  }\n  post{\n    always {\n      sh 'make notify'\n    }\n  }\n}</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"secret-credentials\"><a class=\"anchor\" href=\"#secret-credentials\"></a>Secret credentials</h3>\n<div class=\"paragraph\">\n<p>Managing secrets is a big subject and brings with it many different\nrequirements which are very hard to fulfill.  For obvious reasons, we couldn&#8217;t\npublish the credentials used within the infra project.  On the other hand, we\nneeded to keep track and share them, particularly for the Jenkins node that\ndeploys our cluster.  This means that we needed a way to encrypt or decrypt\nthose credentials depending on permissions, environments, etc.  We analyzed two\ndifferent approaches to handle this:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Storing secrets in a key management tool like <a href=\"https://azure.microsoft.com/en-us/services/key-vault/\">Key Vault</a> or <a href=\"https://www.vaultproject.io/\">Vault</a> and use them like a Kubernetes \"secret\" type of resource.<br>\n&#8594; Unfortunately, these tools are not yet integrated in Kubernetes. But we may come back to this option later.\n<a href=\"https://Github.com/kubernetes/kubernetes/issues/10439\">Kubernetes issue: 10439</a></p>\n</li>\n<li>\n<p>Publishing and encrypting using a public GPG key.<br>\nThis means that everybody can encrypt credentials for the infrastructure project but only the owner of the private key can decrypt credentials.<br>\nThis solution implies:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Scripting: as secrets need to be decrypted at deployment time.</p>\n</li>\n<li>\n<p>Templates: as secret values will change depending on the environment.<br>\n&#8594; Each Jenkins node should only have the private key to decrypt secrets associated to its environment.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"scripting\"><a class=\"anchor\" href=\"#scripting\"></a>Scripting</h3>\n<div class=\"paragraph\">\n<p>Finally, the system we had built was hard to work with.  Our initial\n<code>Jenkinsfile</code> which only ran one <code>kubectl</code> command slowly become a bunch of\nscripts to accommodate for:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Resources needing to be updated only in some situations.</p>\n</li>\n<li>\n<p>Secrets needing to be encrypted/decrypted.</p>\n</li>\n<li>\n<p>Tests needing to be run.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>In the end, the amount of scripts required to deploy the Kubernetes resources\nstarted to become unwieldy and we began asking ourselves: \"aren&#8217;t we\nre-inventing the wheel?\"</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"the-puppet-way\"><a class=\"anchor\" href=\"#the-puppet-way\"></a>The Puppet Way</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>The Jenkins project already uses Puppet, so we decided to look at using Puppet\nto orchestrate our container deployment with Kubernetes.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Workflow</div>\n<div class=\"content\">\n<pre class=\"nowrap\">  _________________       ____________________       _____________\n  |                |      |                   |      |            |\n  |    Github:     |      |     Jenkins:      |      | Puppet:    |\n  | Commit trigger | ----&gt;| Test &amp; Validation | ----&gt;| Deployment |\n  |________________|      |___________________|      |____________|</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In this workflow, Puppet is used to template and deploy all Kubernetes\nconfigurations files needed to orchestrate our cluster.\nPuppet is also used to automate basic <code>kubectl</code> operations such as 'apply' or\n'remove' for various resources based on file changes.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Puppet workflow</div>\n<div class=\"content\">\n<pre class=\"nowrap\">______________________\n|                     |\n|  Puppet Code:       |\n|    .                |\n|    ├── apply.pp     |\n|    ├── kubectl.pp   |\n|    ├── params.pp    |\n|    └── resources    |\n|        ├── lego.pp  |\n|        └── nginx.pp |\n|_____________________|\n          |                                        _________________________________\n          |                                       |                                |\n          |                                       |  Host: Prod orchestrator       |\n          |                                       |    /home/k8s/                  |\n          |                                       |    .                           |\n          |                                       |    └── resources               |\n          | Puppet generate workspace             |        ├── lego                |\n          └--------------------------------------&gt;|        │   ├── configmap.yaml  |\n            Puppet apply workspaces' resources on |        │   ├── deployment.yaml |\n          ----------------------------------------|        │   └── namespace.yaml  |\n          |                                       |        └── nginx               |\n          v                                       |            ├── deployment.yaml |\n ______________                                   |            ├── namespace.yaml  |\n |     Azure:  |                                  |            └── service.yaml    |\n | K8s Cluster |                                  |________________________________|\n |_____________|</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The main benefit of this approach is letting Puppet manage the environment and run\ncommon tasks. In the following example, we define a Puppet class for Datadog.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Puppet class for resource Datadog</div>\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-puppet\" data-lang=\"puppet\"># Deploy datadog resources on kubernetes cluster\n#   Class: profile::kubernetes::resources::datadog\n#\n#   This class deploy a datadog agent on each kubernetes node\n#\n#   Parameters:\n#     $apiKey:\n#       Contain datadog api key.\n#       Used in secret template\nclass profile::kubernetes::resources::datadog (\n    $apiKey = base64('encode', $::datadog_agent::api_key, 'strict')\n  ){\n  include ::stdlib\n  include profile::kubernetes::params\n  require profile::kubernetes::kubectl\n\n  file { \"${profile::kubernetes::params::resources}/datadog\":\n    ensure =&gt; 'directory',\n    owner  =&gt; $profile::kubernetes::params::user,\n  }\n\n  profile::kubernetes::apply { 'datadog/secret.yaml':\n    parameters =&gt; {\n        'apiKey' =&gt; $apiKey\n    },\n  }\n  profile::kubernetes::apply { 'datadog/daemonset.yaml':}\n  profile::kubernetes::apply { 'datadog/deployment.yaml':}\n\n  # As secrets change do not trigger pods update,\n  # we must reload pods 'manually' in order to use updated secrets.\n  # If we delete a pod defined by a daemonset,\n  # this daemonset will recreate pods automatically.\n  exec { 'Reload datadog pods':\n    path        =&gt; [\"${profile::kubernetes::params::bin}/\"],\n    command     =&gt; 'kubectl delete pods -l app=datadog',\n    refreshonly =&gt; true,\n    environment =&gt; [\"KUBECONFIG=${profile::kubernetes::params::home}/.kube/config\"] ,\n    logoutput   =&gt; true,\n    subscribe   =&gt; [\n      Exec['apply datadog/secret.yaml'],\n      Exec['apply datadog/daemonset.yaml'],\n    ],\n  }\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>&#8594;\n<a href=\"https://Github.com/jenkins-infra/jenkins-infra/tree/staging/dist/profile/manifests/kubernetes/resources\">More \"resources\" examples</a></p>\n</div>\n<div class=\"paragraph\">\n<p>Let&#8217;s compare the Puppet way with the challenges discovered with the Jenkins\nway.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"order-matters-2\"><a class=\"anchor\" href=\"#order-matters-2\"></a>Order Matters</h3>\n<div class=\"paragraph\">\n<p>With Puppet, it becomes easier to define priorities as\nPuppet provides relationship meta parameters and the function 'require' (see\nalso:\n<a href=\"https://docs.puppet.com/puppet/4.9/lang_relationships.html\">Puppet\nrelationships</a>).</p>\n</div>\n<div class=\"paragraph\">\n<p>In our Datadog example, we can be sure that deployment will respect the following order:</p>\n</div>\n<div class=\"literalblock\">\n<div class=\"content\">\n<pre class=\"nowrap\">datadog/secret.yaml -&gt; datadog/daemonset.yaml -&gt; datadog/deployment.yaml</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Currently, our Puppet code only applies configuration when it detects file\nchanges.  It would be better to compare local files with the cluster\nconfiguration in order to trigger the required updates, but we haven&#8217;t found a\ngood way to implement this yet.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"portability-2\"><a class=\"anchor\" href=\"#portability-2\"></a>Portability</h3>\n<div class=\"paragraph\">\n<p>As Puppet is used to configure working environments, it becomes easier to be\nsure that all tools are present and correctly configured.  It&#8217;s also easier to\nreplicate environments and run tests on them with tools like\n<a href=\"https://rspec-puppet.com/\">RSpec-puppet</a>, <a href=\"https://serverspec.org/\">Serverspec</a> or\n<a href=\"https://www.vagrantup.com/\">Vagrant</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>In our Datadog example, we can also easily change the Datadog API key depending\non the environment with <a href=\"https://docs.puppet.com/hiera/\">Hiera</a>.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"secret-credentials-2\"><a class=\"anchor\" href=\"#secret-credentials-2\"></a>Secret credentials</h3>\n<div class=\"paragraph\">\n<p>As we were already using <a href=\"https://github.com/crayfishx/hiera-gpg\">Hiera GPG</a>\nwith Puppet, we decided to continue to use it, making managing secrets for\ncontainers very simple.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"scripting-2\"><a class=\"anchor\" href=\"#scripting-2\"></a>Scripting</h3>\n<div class=\"paragraph\">\n<p>Of course the Puppet DSL is used, and even if it seems harder at the beginning,\nPuppet simplifies a lot the management of Kubernetes configuration files.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\"></a>Conclusion</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>It was much easier to bootstrap the project with a full CI workflow within\nJenkins as long as the Kubernetes project itself stays basic. But as soon as\nthe project grew, and we started deploying different applications with\ndifferent configurations per environment, it became easier to delegate\nKubernetes management to Puppet.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you have any comments feel free to send a message to\n<a href=\"mailto:jenkins-infra@lists.jenkins-ci.org\">Jenkins Infra mailing list</a>.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"thanks\"><a class=\"anchor\" href=\"#thanks\"></a>Thanks</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Thanks to Lindsay Vanheyste, Jean Marc Meessen, and Damien Duportal for their feedback.</p>\n</div>\n</div>\n</div>","id":"355e4b5a-0c27-5f01-94a5-7a981139c2fb","title":"A journey to Kubernetes on Azure","date":"2017-05-15T00:00:00.000Z","slug":"/blog/2017/05/15/kubernetes-journey-on-azure/","links":{"discourse":""},"authors":[]}},"pageContext":{"next":"/blog/2017/05/18/pipeline-dev-tools/","previous":"/blog/2017/05/03/jenkinsworld-2017-awards/","id":"355e4b5a-0c27-5f01-94a5-7a981139c2fb"}},
    "staticQueryHashes": ["1271460761","3649515864"]}