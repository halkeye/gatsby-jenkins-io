{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/20",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2019-02-28T00:00:00.000Z","id":"9905a0f3-35a6-5676-b4b5-b69b913d1b36","slug":"/blog/2019/02/28/serverless-jenkins/","strippedHtml":"My job is to work on a Jenkins pipeline specific to SAP S/4HANA extensions running on SAP Cloud Platform.\nSee the original blog post here.\n\nJenkins is a powerful tool for automation, and we heavily rely on the codified pipeline syntax introduced in Jenkins 2.\n\nWith regards to operations, we minimized the need for care with the cx-server life-cycle management greatly.\nStill, you need to run that Jenkins server.\nThis means you’ll need to update the server and plugins (simplified by our life-cycle management), and scale as the number of builds grows.\nUser administration and backups are also required in a productive setup.\n\nIs this really required, or is there an alternative approach?\n\nIn this blog post, I’ll introduce a prototype I did to get rid of that long running pet Jenkins instance.\nRather, we’ll have cattle Jenkins instances, created and destroyed on demand.\n“Serverless” Jenkins in the sense that we don’t have to provision the server for Jenkins to run.\n\nThe setup described in this post is highly experimental. I encourage you to try this out in a demo project, but be very cautious until further notice to use this on productive code. In this proof of concept, I’ll use a public GitHub repository and the free open-source offering by TravisCI. This setup is not suitable for commercial software.\n\nThe pets vs cattle metaphor describes how approaches in managing servers differ.\nWhile you care for pets and treat them when they are unwell, cattle can be easily replaced.\nYour traditional Jenkins server is a pet because it is often configured manually, and replacing it is a major effort.\nFor more background on this metaphor, click here.\n\nBefore we’re getting into the technical details, let’s discuss why we would want to try this out in the first place.\nRunning Jenkins on arbitrary CI/CD services, such as TravisCI seems very odd on first sight.\nOn such services you’ll usually invoke your build tools like Maven or npm in a small script, and that will do your build.\nBut in the enterprise world, both inside SAP and in the community, Jenkins has a huge market share.\nThere are many shared libraries for Jenkins, providing pre-made build steps which would be expensive to re-implement for other platforms.\nAdditionally, SAP S/4HANA Cloud SDK Pipeline is a ready to use pipeline based on Jenkins where you as the developer of an SAP S/4HANA extension application do not need to write and maintain the pipeline yourself.\nThis means reduced costs and effort for you, while the quality of your application improves, for example due to the many cloud qualities which are checked out of the box.\n\nLet me show you an experiment to see if we can get the best of both worlds.\nThe goal is to get all the quality checks and the continuous delivery that the SAP S/4HANA Cloud SDK Pipeline provides us, without the need for a pet Jenkins server.\n\nHow do we do that? The Jenkins project has a project called Jenkinsfile runner.\nIt is a command line tool that basically boots up a stripped-down Jenkins instance, creates and runs a single job, and throws away that instance once the job is done. As you might guess, there is some overhead in that process.\nThis will add about 20 seconds to each build, which I found to be surprisingly fast, considering the usual startup time of a Jenkins server.\nFor convenient consumption, we have packaged Jenkinsfile runner as a Docker image which includes the Jenkins plugins that are required for SAP S/4HANA Cloud SDK Pipeline.\n\nWe also utilize the quite new Configuration as Code plugin for Jenkins, which allows to codify the Jenkins configuration as YAML files.\nAs you will see in a minute, both Jenkinsfile runner and Configuration as Code are a perfect match.\n\nIf you want to follow along, feel free to use our provided Address Manager example application.\nYou may fork the repository, or create your own repository and activate it on TravisCI.\n\nBased on the existing Address Manager, let’s add a small.travis.yml file to instruct the build:\n\nlanguage: minimal\nservices:\n- docker\nscript: docker run -v /var/run/docker.sock:/var/run/docker.sock -v ${PWD}:/workspace -v /tmp -e CASC_JENKINS_CONFIG=/workspace/jenkins.yml -e CF_PW -e ERP_PW -e BRANCH_NAME=$TRAVIS_BRANCH ppiper/jenkinsfile-runner\n\nThe script line has quite a few things going on, let’s see what is there.\n\nWe run a Docker container based on the ppiper/jenkinsfile-runner image.\nWe need to mount the Docker socket, so that our container can spawn sibling containers for tooling such as Maven or the CloudFoundry CLI.\nWe also need to mount the current directory (root of our project) to /workspace, and tell the Jenkins Configuration as Code Plugin where to find the configuration file.\nWe’ll come to that file in a minute. Also be sure to pass your secret variables here.\nTravis will mask them, so they are not in plain text in your build log.\nTake note to change the names of the variables according to your requirements.\nYou might wonder that we need a BRANCH_NAME environment variable.\nThis is required for the Pipeline to check if you’re working on the “productive branch”, where a productive deployment to SAP Cloud Platform is supposed to happen.\nIf you omit passing this variable, the pipeline will still run but never in the productive mode, and hence not deploy to SAP Cloud Platform.\n\nYou might need some secrets in the build, for example in integration tests or for deployment to SAP Cloud Platform.\nYou can make use of the travis command line tool to encrypt them on your local machine as documented here.\nTake care that this might add your secret in plain text to the shell history on your machine.\n\ntravis encrypt CF_PW=supersecret --add\ntravis encrypt ERP_PW=alsosupersecret --add\n\nThis command will add a line to your.travis.yml file with the encrypted secret value.\nBe sure to commit this change.\nAlso take note of the name of your variable, which must match the environment parameter, and your Jenkins configuration.\nYou should be aware of this TravisCI document on secrets.\n\nWe’ll also need to add a jenkins.yml file to our project.\nHere we need to configure two shared libraries which are required for the SAP S/4HANA Cloud SDK Pipeline, and the credentials that are required for our pipeline.\nBe sure not to put your secrets in plain text in here, but use the variables you used before via the travis cli tool.\nTravisCI will decrypt the password on the fly for you.\n\njenkins:\n  numExecutors: 10\nunclassified:\n  globallibraries:\n    libraries:\n    - defaultVersion: \"master\"\n      name: \"s4sdk-pipeline-library\"\n      retriever:\n        modernSCM:\n          scm:\n            git:\n              remote: \"https://github.com/SAP/cloud-s4-sdk-pipeline-lib.git\"\n    - defaultVersion: \"master\"\n      name: \"piper-library-os\"\n      retriever:\n        modernSCM:\n          scm:\n            git:\n              remote: \"https://github.com/SAP/jenkins-library.git\"\ncredentials:\n  system:\n    domainCredentials:\n      - credentials:\n          - usernamePassword:\n              scope: GLOBAL\n              id: \"MY-ERP\"\n              username: MY_USER\n              password: ${ERP_PW}\n          - usernamePassword:\n              scope: GLOBAL\n              id: \"cf\"\n              username: P12344223\n              password: ${CF_PW}\n\nYou might add more configuration to this file as you need it.\n\nCommit both files to your repo and push.\nIf the travis build works, you’ll see the build integration on GitHub.\n\nOn travis, you can follow the progress of your build live, and get the full text log of your Jenkins build.\nIf all went well, you will be greeted with a green build after a few minutes.\n\nCongratulations. You’re running a serverless Jenkins build with all the qualities checked by the SAP S/4HANA Cloud SDK Pipeline, without hosting your own Jenkins instance.\n\nKeep in mind this is a proof of concept at this point.\nThe serverless Jenkins ecosystem is currently evolving, and neither Jenkinsfile runner, nor Configuration as Code are in a mature state as of February 2019.\nOne downside of this approach is that we lose the Jenkins user interface, so we can’t see our pipeline in blue ocean, and we don’t get the nice build summary.\nWe can get the whole log output from TravisCI, so this can be mitigated, but this is arguable not the best user experience.\n\nBut on the contrary, we don’t have to care for our pet Jenkins, we don’t need to update plugins or backup the configuration or build logs.","title":"Run your Jenkins pipeline without operating a Jenkins instance","tags":["jenkins","serverless"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/79d32/fwilhe.jpg","srcSet":"/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/b8799/fwilhe.jpg 32w,\n/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/8532e/fwilhe.jpg 64w,\n/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/79d32/fwilhe.jpg 128w,\n/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/97a5e/fwilhe.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/c9eb6/fwilhe.webp 32w,\n/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/3ea93/fwilhe.webp 64w,\n/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/bf8fb/fwilhe.webp 128w,\n/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/e7a87/fwilhe.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":125}},"publicURL":"/gatsby-jenkins-io/static/7ee4588ea0f87b2f7130bee3a5fddd17/fwilhe.jpg"},"blog":null,"github":"fwilhe","html":"<div class=\"paragraph\">\n<p>Software Developer working on CI/CD at SAP Innovation Center in Potsdam. I am employed by SAP, but thoughts here are my own.\n---</p>\n</div>","id":"fwilhe","irc":null,"linkedin":null,"name":"Florian Wilhelm","slug":"/blog/authors/fwilhe/","twitter":"fwilhe"}]}},{"node":{"date":"2019-02-26T00:00:00.000Z","id":"c5e445a3-8d1e-5054-be35-b27be24516a0","slug":"/blog/2019/02/26/jenkins-alexa-voice-controlled-cicd/","strippedHtml":"Integrating Jenkins with Alexa to launch your pipelines and obtain results\nabout your deployments through voice is easier than you think.  Learn how Alexa\nChampion, Kesha Williams', latest side project teaches Alexa to deploy code to\nthe cloud.\n\nAlexa (named after the ancient library of Alexandria) is Amazon’s Artificial\nIntelligence (AI) powered intelligent voice assistant that runs in the cloud.\nSoftware engineers make Alexa smarter by creating apps, called skills.  From\nthe time that I developed my first Alexa skill, I dreamed of deploying my Java\nprojects to the cloud via voice.  For me, telling Alexa to deploy my code is\nthe ultimate level of cool!  I recently made my dream a reality when I devoted\na weekend to developing my newest Alexa skill, DevOps Pal.  In this blog, I\nwill show you how I developed DevOps Pal and hopefully inspire you to build\nyour own version.\n\nWhy Choose Voice to Deploy Code\n\nVoice-first technology is revolutionizing how we interact with technology because the interaction is simple, frictionless, and time-saving.\nFor me, voice is an easier way to control Jenkins and retrieve results about my deployments without having to touch a keyboard.\nIn this use case, voice is another access point for data and is a way to further automate the process of building, testing, and deploying a Java project to the cloud, improving efficiency.\n\nContinuous Integration and Continuous Delivery (CI/CD)\n\nIf you’re working with DevOps, you understand the need for Continuous Integration and Continuous Delivery (CI/CD) to automate the software delivery pipeline in a reproducible way.\nCI/CD is the practice of continuously building, testing, and deploying code once it’s committed to version control.\nDevOps and CI/CD provides software engineering teams with confidence in the code being pushed to production and shorter development lifecycles, which in the end produces happier users, clients, and customers.\n\nDevOps Pal Overview\n\nDevOps Pal is a private Alexa for Business skill that is used to kick off a Jenkins pipeline job.\nAlexa for Business was the perfect way for me to distribute DevOps Pal since I have the ability to enable the skill on an organization-by-organization basis, which gives me complete control over who has access.\nOnce DevOps Pal invokes the job, the pipeline status displays in real-time via the Blue Ocean Pipeline Run Details View Page.\n\nDevOps Pal Architecture\n\nI used several components and tools to create DevOps Pal. Let’s review the architecture in detail.\n\nThe flow begins by saying, \"Alexa, open DevOps Pal and deploy my code\", to the Echo device.\n\nThe Echo device listens for the wake word (e.g. Alexa, Echo, Computer, or Amazon), which employs deep learning technology running on the device to recognize the wake word the user has chosen.\nOnce the wake word is detected, what I say is recorded and sent to the Alexa Voice Service (AVS), which uses speech to text and natural language understanding (NLU) to identify my intent.\nMy intent is sent to DevOps Pal; the skill acts accordingly by kicking off the Jenkins job and sending a response back using text-to-speech synthesis (TTS), which makes the response natural sounding.\n\nLet’s explore each component in more detail:\n\nAlexa Voice Service (AVS) - I often refer to the Alexa Voice Service as the \"Alexa brain that runs in the cloud\". The AVS is a suite of services built around a voice-controlled AI assistant. The AVS is flexible enough to allow third parties to add intelligent voice control to any connected product that has a microphone and speaker, so Alexa is not limited to just Echo devices.\n\nAlexa Skills Kit (ASK) - ASK is the \"SDK\" (Software Development Kit) that allows developers to build custom skills for Alexa.\n\nAlexa Developer Portal - An Alexa skill includes a voice user interface, or VUI, to understand user intents, and a back-end cloud service to process intents by telling Alexa how to respond. The VUI and the integration with the back-end service is setup and configured through the Alexa Developer Portal.\n\nAWS Lambda - A chunk of code that runs in the cloud. Developers can run their code without having to provision or manage servers. Applications created with AWS Lambda are considered to be serverless. Lambda supports several popular languages like Python, Java, Node.js, Go, C#, etc.\n\nGitHub - A version control system for the Java project source code.\n\nJenkins on EC2 - I use Jenkins to build, test, and deploy my Java Application Programming Interface (API). Elastic Cloud Computer (EC2) is the virtual server where Jenkins is installed. Jenkins works alongside several other tools:\n\nMaven - A build automation tool for Java projects.\n\nJunit - A testing framework for Java projects.\n\nAWS Command Line Interface (CLI) - This is a command line tool that allows developers to access their Amazon Web Services (AWS) account.\n\nBlue Ocean - This is a plugin for Jenkins that provides an easy to use interface to create and monitor Jenkins pipelines.\n\nAWS Elastic Beanstalk - This is an orchestration service that allows developers to deploy and manage web applications in the AWS cloud.\n\nPostman - This is an HTTP client for testing APIs and web services.\n\nVoice Interaction Model\n\nThe Voice User Interface (VUI) describes the overall conversational flow and is setup via the Alexa Developer Console.\n\nA few important components of the VUI are the Invocation Name (how users launch your skill) and the Intents (phrases a user says to \"talk to\" or interact with your skill).\n\nSpecifically, the \"DeployCodeIntent\" is invoked when a user says one of several phrases (e.g. run jenkins pipeline, run jenkins job, deploy the code, deploy code, or deploy ) or a variation of the phrase like, \"deploy my code\".\n\nThe endpoint is the destination where the skill requests are sent for fulfillment.\nIn this case, the backend logic is an AWS Lambda authored in Python.\nThe business logic in the Python Lambda uses the Jenkins remote access API to trigger the job remotely.\nThe format of the URL to trigger the job is jenkins_url/job/job_name/build.\nThe API call uses BASIC authentication and a Jenkins Crumb passed in the HTTP request header for CSRF protection.\nAlternatively, since Jenkins 2.96, you can use an API token instead of a Jenkins Crumb and password to authenticate your API call.\n\nJenkins Job\n\nThe Jenkins job, 'alexa-cicd', is the job invoked from DevOps Pal.\nAlthough, the Jenkins Classic User Interface (UI) is functional, I prefer the Blue Ocean interface because it rethinks the user experience of Jenkins by making it visually intuitive.\nBlue Ocean is easily enabled via a plugin and leaves the option to continue using the Jenkins Classic UI should you so choose.\n\nAfter Alexa kicks off the 'alexa-cicd' job, I navigate to the Pipeline Run Details View Page, which allows me to watch the job status in realtime.\nThis job has four stages: Initialize, Build, Test, and Deploy.\nThe final stage, Deploy, uses the AWS Command Line Interface (CLI) on the Jenkins server to copy the artifact to Amazon Simple Storage Service (S3) and create a new Elastic Beanstalk application version based on the artifact located on S3.\n\nCool Features to Add\n\nThe ability to deploy code with voice is just the beginning.\nThere are several cool features that can easily be added:\n\nDevOps Pal can be updated to prompt the user for the specific Jenkins pipeline job name. This adds a level of flexibility that will really empower DevOps teams.\n\nAlexa Notifications can be integrated with DevOps Pal to send a notification to the Echo device when the Jenkins job is finished or when it fails. If the job fails, more information about where the job failed and exactly why will be provided. This will prove useful for long running jobs or for getting timely updates regarding the job status.\n\nDevOps Pal can be updated to answer direct questions about the real-time status of a specific job.\n\nWant to Learn More\n\nI hope you’ve enjoyed learning more about the architecture of DevOps Pal and deploying code to the cloud using Jenkins and voice.\nFor more detailed steps, I’ve collaborated with Cloud Academy to author a course, AWS Alexa for CI/CD on the subject.","title":"Jenkins + Alexa: Say Hello to Voice Controlled CI/CD","tags":["jenkins","alexa"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8e8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/f84e8/keshawilliams.jpg","srcSet":"/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/5c08a/keshawilliams.jpg 32w,\n/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/4a6e8/keshawilliams.jpg 64w,\n/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/f84e8/keshawilliams.jpg 128w,\n/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/d158b/keshawilliams.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/ad81f/keshawilliams.webp 32w,\n/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/10333/keshawilliams.webp 64w,\n/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/ba2bd/keshawilliams.webp 128w,\n/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/b679b/keshawilliams.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":179}},"publicURL":"/gatsby-jenkins-io/static/98fc8317a8d993f9d7e4610ea3fcc96f/keshawilliams.jpg"},"blog":"http://www.kesha.tech/","github":"ProfessorKesha","html":"<div class=\"paragraph\">\n<p>Kesha Williams is an award-winning software engineering manager at Chick-fil-A with over 20 years' experience.\nShe has trained and mentored thousands of software developers in the US, Europe, and Asia while teaching at the university level.\nShe routinely leads innovation teams in proving out emerging technologies and shares her learnings at conferences across the globe.\nShe has published several Alexa skills, was featured during Amazon&#8217;s \"Alexa Women of Voice\" campaign, and recently named an Alexa Champion.\nIn her spare time, she leads the Georgia chapter of Technovation and mentors women in tech.</p>\n</div>","id":"keshawilliams","irc":null,"linkedin":null,"name":"Kesha Williams","slug":"/blog/authors/keshawilliams/","twitter":"keshawillz"}]}},{"node":{"date":"2019-02-21T00:00:00.000Z","id":"ee6f71b5-7195-56bb-8a9e-87e021747a53","slug":"/blog/2019/02/21/credentials-masking/","strippedHtml":"In the Jenkins project, we ask that people report security issues to our private issue tracker.\nThis allows us to review issues and prepare fixes in private, often resulting in better, safer security fixes.\n\nAs a side effect of that, we also learn about common misconceptions and usability problems related to security in Jenkins.\nThis post is intended to address one of those:\nThe goal and limitations of credentials masking.\n\nThe Problem\n\nOne very common example of that is the role of credentials masking in Jenkins, typically involving a pipeline snippet that looks like this:\n\n// Scripted //\nwithCredentials([usernamePassword(credentialsId: 'topSecretCredentials', passwordVariable: 'PWD', usernameVariable: 'USR')])\n  sh './deploy.sh' // requires PWD and USR to be set\n}\n// Declarative //\n\nCredentials that are in scope are made available to the pipeline without limitation.\nTo prevent accidental exposure in the build log, credentials are masked from regular output, so an invocation of env (Linux) or set (Windows), or programs printing their environment or parameters would not reveal them in the build log to users who would not otherwise have access to the credentials.\n\nThe misconception here is that Jenkins will prevent other, perhaps deliberate ways to reveal the password.\nSome examples:\n\n// Scripted //\nwithCredentials([usernamePassword(credentialsId: 'topSecretCredentials', passwordVariable: 'PWD', usernameVariable: 'USR')])\n  sh 'echo $PWD | base64' // will print e.g. dDBwczNjcjN0Cg= which is trivially converted back to the top secret password\n}\n// Declarative //\n\n// Scripted //\nwithCredentials([usernamePassword(credentialsId: 'topSecretCredentials', passwordVariable: 'PWD', usernameVariable: 'USR')])\n  sh 'echo $PWD > myfile'\n  archiveArtifacts 'myfile' // then browse archived artifacts from the Jenkins UI\n}\n// Declarative //\n\nBoth of these snippets circumvent credentials masking in the build log, and show that people with control over the build script can use credentials in ways not necessarily intended or approved by admins.\n\nObviously these are just the most straightforward examples illustrating the problem.\nOthers could involve the proc file system, sending it to an HTTP server in response to a 401 authentication challenge, embedding it in the (otherwise legitimate) build result, etc.\n\nIt would be great if Jenkins could allow the flexible use of credentials with no risk of exposing them through straightforward build script modifications, but realistically, it is impossible for Jenkins to police use of the credential by a build script without the support of a very specific environment setup (e.g. restrictive network configuration).\n\nIt should also be noted that credentials aren’t just at risk from users able to control the pipeline, typically by editing the Jenkinsfile.\nActual build scripts invoked by pipelines, either shell scripts as in the example above, or more standard build tools such as Maven (controlled by pom.xml) are just as much of a risk if they are run inside a withCredentials block, or executing on the same agent as another block that passed such credentials.\n\nDisclosure of secrets can also happen inadvertently:\nJenkins will prevent exact matches of the password or other secret to appear in the log file.\nConsider that the secret may contain shell metacharacters that bash +x would escape by adding a \\ before those characters.\nThe sequence of characters to be printed is no longer identical to the secret, so would not be masked.\n\nThe Solution\n\nCredentials can be defined in different scopes:\nCredentials defined on the root Jenkins store (the default) will be available to all jobs on the instance.\nThe only exception are credentials with System scope, intended for the global configuration only, for example, to connect to agents.\nCredentials defined in a folder are only available within that folder (transitively, i.e. also in folders inside this folder).\n\nThis allows defining sensitive credentials, such as deployment credentials, on specific folders whose contents only users trusted with those credentials are allowed to configure:\nDirectly in Jenkins using Matrix Authorization Plugin and by limiting write access to repositories defining pipelines as code.\n\nPipelines inside this folder can use the (e.g. deployment) credentials without limitation, while they’re inaccessible to pipelines outside the folder.\nThose would need to use the build step or similar approaches to invoke the pipelines inside the folder to deploy their output.\n\nCaveats\n\nWhile the previous section outlines a solution to the problem of restricting access to credentials, care needs to be taken so that credentials are not captured anyway.\nFor example, a deployment pipeline that allows its users to define where to deploy to as a build parameter might still be used to send credentials to a maliciously set up host to capture them.\nA blog post explaining the design of some Jenkins project infrastructure discusses some of these concerns around trust.\n\nIt should also be noted that credential domains are a UI hint only — defining a credential to only be valid for github.com does not actually prevent its use elsewhere.","title":"Limitations of Credentials Masking","tags":["security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck/","twitter":null}]}},{"node":{"date":"2019-02-17T00:00:00.000Z","id":"a79ea93c-0082-5a4a-a338-9fde01ae88b1","slug":"/blog/2019/02/17/remoting-cli-removed/","strippedHtml":"Close to two years ago, we announced in\nNew, safer CLI in 2.54\nthat the traditional “Remoting” operation mode of the Jenkins command-line interface\nwas being deprecated for a variety of reasons, especially its very poor security record.\nToday in Jenkins 2.165 support for this mode is finally being removed altogether,\nin both the server and bundled jenkins-cli.jar client.\nThe projected June 5th LTS release will reflect this removal,\nat which point the Jenkins project will no longer maintain this feature\nnor investigate security vulnerabilities in it.\n\nThis change makes the code in Jenkins core related to the CLI considerably simpler and more maintainable.\n(There are still two transports —HTTP(S) and SSH—but they have similar capabilities and behavior.)\nIt also reduces the “attack surface” the Jenkins security team must consider.\nAmong other issues, a compromised server could freely attack a developer’s laptop if -remoting were used.\n\nThe\n2.46.x upgrade guide\nalready urged administrators to disable Remoting mode on the server.\nThose Jenkins users who rely on the CLI for remote scripting (as opposed to the HTTP(S) REST APIs)\nwould be affected only if they were still using the -remoting CLI flag,\nsince the default has long been to use HTTP(S) mode.\n\nMost CLI features have long worked fine without -remoting,\nin some cases using slightly different syntax such as requiring shell redirects to access local files.\nAs part of this change, some CLI commands, options, and option types in Jenkins core have been removed, other than -remoting itself:\n\nThe login and logout commands, and the --username and --password options.\n\nThe -p option to select a proxy. (The CLI in default -http mode accesses Jenkins no differently than any other HTTP client.)\n\nThe install-tool, set-build-parameter, and set-build-result commands relied on a fundamentally insecure idiom that is no longer supportable.\n\nCommand options or arguments which took either a local file or = for standard input/output (e.g., install-plugin, build -p, support) now only accept the latter.\n\nSome features of relatively little-used plugins will no longer work, such as:\n\nDistFork\n\nRemote Terminal Access\n\nBuild Env Propagator","title":"Remoting-based CLI removed from Jenkins","tags":["core","security","remoting"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick/","twitter":"tyvole"}]}},{"node":{"date":"2019-02-06T00:00:00.000Z","id":"ed5dfb33-f5e6-565b-a671-f4ae47d2c691","slug":"/blog/2019/02/06/ssh-steps-for-jenkins-pipeline/","strippedHtml":"Pipeline-as-code or defining the deployment pipeline through code rather than manual job creation through UI, provides tremendous benefits for teams automating builds and deployment infrastructure across their environments.\n\nSource of image: https://jenkins.io/doc/book/pipeline/\n\nJenkins Pipelines\n\nJenkins is a well-known open source continuous integration and continuous deployment automation tool. With the latest 2.0 release, Jenkins introduced the Pipeline plugin that implements Pipeline-as-code. This plugin lets you define delivery pipelines using concise scripts which deal elegantly with jobs involving persistence and asynchrony.\n\nThe Pipeline-as-code’s script is also known as a Jenkinsfile.\n\nJenkinsfiles uses a domain specific language syntax based on the Groovy programming language. They are persistent files which can be checked in and version-controlled along with the rest of their project source code. This file can contain the complete set of encoded steps (steps, nodes, and stages) necessary to define the entire application life-cycle, becoming the intersecting point between development and operations.\n\nMissing piece of the puzzle\n\nOne of the most common steps defined in a basic pipeline job is the Deploy step. The deployment stage encompasses everything from publishing build artifacts to pushing code into pre-production and production environments. This deployment stage usually involves both development and operations teams logging onto various remote nodes to run commands and/or scripts to deploy code and configuration. While there are a couple of existing ssh plugins for Jenkins, they currently don’t support the functionality such as logging into nodes for pipelines. Thus, there was a need for a plugin that supports these steps.\n\nIntroducing SSH Steps\n\nRecently, our team at Cerner started working on a project to automate deployments through Jenkins pipelines to help facilitate running commands on over one thousand nodes. We looked at several options including existing plugins, internal shared Jenkins libraries, and others. In the end, we felt it was best to create and open source a plugin to fill this gap so that it can be used across Cerner and beyond.\n\nThe initial version of this new plugin SSH Steps supports the following:\n\nsshCommand : Executes the given command on a remote node.\n\nsshScript : Executes the given shell script on a remote node.\n\nsshGet : Gets a file/directory from the remote node to current workspace.\n\nsshPut : Puts a file/directory from the current workspace to remote node.\n\nsshRemove : Removes a file/directory from the remote node.\n\nUsage\n\nBelow is a simple demonstration on how to use above steps. More documentation can be found on GitHub.\n\ndef remote = [:]\nremote.name = \"node\"\nremote.host = \"node.abc.com\"\nremote.allowAnyHosts = true\n\nnode {\n    withCredentials([usernamePassword(credentialsId: 'sshUserAcct', passwordVariable: 'password', usernameVariable: 'userName')]) {\n        remote.user = userName\n        remote.password = password\n\n        stage(\"SSH Steps Rocks!\") {\n            writeFile file: 'test.sh', text: 'ls'\n            sshCommand remote: remote, command: 'for i in {1..5}; do echo -n \\\"Loop \\$i \\\"; date ; sleep 1; done'\n            sshScript remote: remote, script: 'test.sh'\n            sshPut remote: remote, from: 'test.sh', into: '.'\n            sshGet remote: remote, from: 'test.sh', into: 'test_new.sh', override: true\n            sshRemove remote: remote, path: 'test.sh'\n        }\n    }\n}\n\nConfiguring via YAML\n\nAt Cerner, we always strive to have simple configuration files for CI/CD pipelines whenever possible. With that in mind, my team built a wrapper on top of these steps from this plugin. After some design and analysis, we came up with the following YAML structure to run commands across various remote groups:\n\nconfig:\n  credentials_id: sshUserAcct\n\nremote_groups:\n  r_group_1:\n    - name: node01\n      host: node01.abc.net\n    - name: node02\n      host: node02.abc.net\n  r_group_2:\n    - name: node03\n      host: node03.abc.net\n\ncommand_groups:\n  c_group_1:\n    - commands:\n        - 'ls -lrt'\n        - 'whoami'\n    - scripts:\n        - 'test.sh'\n  c_group_2:\n    - gets:\n        - from: 'test.sh'\n          to: 'test_new.sh'\n    - puts:\n        - from: 'test.sh'\n          to: '.'\n    - removes:\n        - 'test.sh'\n\nsteps:\n  deploy:\n    - remote_groups:\n        - r_group_1\n      command_groups:\n        - c_group_1\n    - remote_groups:\n        - r_group_2\n      command_groups:\n        - c_group_2\n\nThe above example runs commands from c_group_1 on remote nodes within r_group_1 in parallel before it moves on to the next group using sshUserAcct (from the Jenkins Credentials store) to logon to nodes.\n\nShared Pipeline Library\n\nWe have created a shared pipeline library that contains a sshDeploy step to support the above mentioned YAML syntax. Below is the code snippet for the sshDeploy step from the library. The full version can be found here on Github.\n\n#!/usr/bin/groovy\ndef call(String yamlName) {\n    def yaml = readYaml file: yamlName\n    withCredentials([usernamePassword(credentialsId: yaml.config.credentials_id, passwordVariable: 'password', usernameVariable: 'userName')]) {\n        yaml.steps.each { stageName, step ->\n            step.each {\n                def remoteGroups = [:]\n                def allRemotes = []\n                it.remote_groups.each {\n                    remoteGroups[it] = yaml.remotes.\"$it\"\n                }\n\n                def commandGroups = [:]\n                it.command_groups.each {\n                    commandGroups[it] = yaml.commands.\"$it\"\n                }\n                def isSudo = false\n                remoteGroups.each { remoteGroupName, remotes ->\n                    allRemotes += remotes.collect { remote ->\n                        if(!remote.name)\n                            remote.name = remote.host\n                        remote.user = userName\n                        remote.password = password\n                        remote.allowAnyHosts = true\n                        remote.groupName = remoteGroupName\n                        remote\n                    }\n                }\n                if(allRemotes) {\n                    if(allRemotes.size() > 1) {\n                        def stepsForParallel = allRemotes.collectEntries { remote ->\n                            [\"${remote.groupName}-${remote.name}\" : transformIntoStep(stageName, remote.groupName, remote, commandGroups)]\n                        }\n                        stage(stageName) {\n                            parallel stepsForParallel\n                        }\n                    } else {\n                        def remote = allRemotes.first()\n                        stage(stageName + \"\\n\" + remote.groupName + \"-\" + remote.name) {\n                            transformIntoStep(stageName, remote.groupName, remote, commandGroups).call()\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nBy using the step (as described in the snippet above) from this shared pipeline library, a Jenkinsfile can be reduced to:\n\n@Library('ssh_deploy') _\n\nnode {\n  checkout scm\n  sshDeploy('dev/deploy.yml');\n}\n\nAn example execution of the above pipeline code in Blue Ocean looks like this:\n\nWrapping up\n\nSteps from the SSH Steps Plugin are deliberately generic enough that they can be used for various other use-cases as well, not just for deploying code. Using SSH Steps has significantly reduced the time we spend on deployments and has given us the possibility of easily scaling our deployment workflows to various environments.\n\nHelp us make this plugin better by contributing. Whether it is adding or suggesting a new feature, bug fixes, or simply improving documentation, contributions are always welcome.","title":"SSH Steps for Jenkins Pipeline","tags":["pipeline","plugins","ssh","steps"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg","srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/77b35/nrayapati.jpg 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/d4a57/nrayapati.jpg 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/68974/nrayapati.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/ef6ff/nrayapati.webp 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/8257c/nrayapati.webp 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/6766a/nrayapati.webp 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/22bfc/nrayapati.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/nrayapati.jpeg"},"blog":null,"github":"nrayapati","html":"<div class=\"paragraph\">\n<p>Software Architect at <a href=\"https://www.cerner.com/\">Cerner Corporation</a>. Passionate about Agile, DevOps &amp; Continuous Delivery, and all things Automation.\nOSS Contributor, he is maintaining couple of Jenkins plugins since past several years. <a href=\"https://plugins.jenkins.io/ssh-steps\">SSH Steps</a> - <a href=\"https://plugins.jenkins.io/jira-steps\">JIRA Steps</a> - <a href=\"https://plugins.jenkins.io/hubot-steps\">Hubot Steps</a></p>\n</div>","id":"nrayapati","irc":null,"linkedin":null,"name":"Naresh Rayapati","slug":"/blog/authors/nrayapati/","twitter":"nrayapati"}]}},{"node":{"date":"2019-02-05T00:00:00.000Z","id":"9488675b-0d5a-5055-8c7d-1ab61e7ad642","slug":"/blog/2019/02/05/jenkins-new-year-in-china/","strippedHtml":"At the time of the Spring Festival. I want to make a summary of some activities in the last year.\nYou might already notice that more and more Chinese contributors emerge in the Jenkins community.\nWe have a GSoC champion who is Shenyu Zheng.\nHe is a great example for other students. With the effort of three skilled engineers,\nmany Jenkins users could learn the edge technologies and useful use cases.\nThey co-organized several Jenkins Meetups in a couple of cities in China.\n\nThere are two workshops about Jenkins and Jenkins X in the DevOps International Summit. James Rawlings gave us a wonderful view of the Jenkins X. Many people start to know this project. The Chinese website of jx would be helpful to those people.\n\nOn November 3rd, 2018 the Jenkins User Conference China(JUCC) was hosted in Shenzhen. More than 200 attendees gathered at JUCC to share and discuss Jenkins, DevOps, Continuous Delivery, Pipeline, and Agile.\n\nThere was a Jenkins workshop to teach users to develop a plugin in October. It was during the Hacktoberfest 2018. So some people got a beautiful T-shirt at this meetup. We’ll keep this event in 2019. I hope more users and developers could join us.\n\nThank you all folks. And other friendly contributors.\n\nChinese is our main communication language. A large number of the Jenkins users are not a proficient English speaker.\nSo letting most of Chinese Jenkins users could easily use Jenkins as their CI/CD platform is the final mission of Chinese Localization SIG.\nYou can find three participants on the page. But that’s not the full list.\nMore exciting thing is that Alauda giving a big support which as a startup company.\n\nWeChat is the greatest social media channel in China. WeChat has one billion users.\nAlmost everyone in China has a WeChat account. It must be a perfect place to publish articles and events.\nThere are over 1k people subscribed the Jenkins official WeChat Subscription Account in the last three months.\n\nIn the new year, I’m looking forward to growing up with you all!","title":"Jenkins new year in China","tags":["core","community","chinese"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#989898","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/19e71/linuxsuren.jpg","srcSet":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/77b35/linuxsuren.jpg 32w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/d4a57/linuxsuren.jpg 64w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/19e71/linuxsuren.jpg 128w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/68974/linuxsuren.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/ef6ff/linuxsuren.webp 32w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/8257c/linuxsuren.webp 64w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/6766a/linuxsuren.webp 128w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/22bfc/linuxsuren.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/linuxsuren.jpg"},"blog":null,"github":"LinuxSuRen","html":"<div class=\"paragraph\">\n<p>Rick is a big fan of Jenkins, also as a contributor leading the Jenkins China community.</p>\n</div>","id":"linuxsuren","irc":null,"linkedin":"linuxsuren","name":"赵晓杰(Rick)","slug":"/blog/authors/linuxsuren/","twitter":"LinuxSuRen"}]}},{"node":{"date":"2019-02-01T00:00:00.000Z","id":"16256d3b-178f-556d-93f1-d366b7ff53cb","slug":"/blog/2019/02/01/windows-installers/","strippedHtml":"The Windows Installer for Jenkins has been around for many years as a way for users to install a Jenkins controller on Windows as a service.\nSince it’s initial development, it has not received a lot of updates or features, but that is about to change.\n\nFirst, let’s take a look at the current installer experience.\n\nStep 1\n\nThis is the default look and feel for a Windows Installer using the WiX Toolset, not very pretty and doesn’t give\nmuch branding information as to what the installer is for.\n\nStep 2\n\nAgain, not much branding information.\n\nStep 3\n\nThe installer in general does not give many options for installing Jenkins, other than selecting the installation location.\n\nIssues\n\nThe current installer has a few issues that the Platform SIG wanted to fix in a new install experience for users.\n\nThe installer only supports 32-bit installations.\n\nThe user could not select ports or user accounts to run the service on.\n\nThe installer bundled a 32-bit version of the Java runtime instead of using a pre-existing JRE\n\nThe installer did not support the experimental support in Jenkins for Java 11\n\nThe JENKINS_HOME directory was not placed in a good spot for modern Windows\n\nThere is no branding in the installer.\n\nRoad Forward\n\nWith the experimental Jenkins Windows Installer, most of these issues have been resolved!\n\nThe installer will only support 64-bit systems going forward. This is the vast majority of Windows systems these days,\nso this will help more users install Jenkins using the installer package.\n\nThe user is now able to enter user information for the service and select the port that Jenkins will use and verify that the port is available.\n\nThe installer no longer bundles a JRE, but will search for a compatible JRE on the system. If the user wants to use a different JRE, they can specify during install.\n\nThe installer has support for running with a Java 11 JRE, including the components listed on the Java 11 Preview Page.\n\nthe JENKINS_HOME directory is placed in the LocalAppData directory for the user that the service will run as, this aligns with modern Windows file system layouts.\n\nThe installer has been updated with branding to make it look nicer and provide a better user experience.\n\nScreenshots\n\nBelow are screenshots of the new installer sequence:\n\nStep 1\n\nThe Jenkins logo is now a prominent part of the UI for the installer.\n\nStep 2\n\nThe Jenkins logo and name are now in the header during all phases of the installer.\n\nStep 3\n\nThe installer now allows you to specify the username/password for the account to run as and checks that the account has LogonAsService rights.\n\nStep 4\n\nThe installer also allows you to specify the port that Jenkins should run on and will not continue until a valid port is entered and tested.\n\nStep 5\n\nInstead of bundling a JRE, the installer now searches for a compatible JRE on the system (JRE 8 is the current search). If you want to use a different\nJRE on the system than the one found by the installer, you can browse and specify it. Only JRE 8 and JRE 11 runtimes are supported. The installer will\nautomatically add the necessary arguments and additional jar files for running under Java 11 if the selected JRE is found to be version 11.\n\nStep 6\n\nAll of the items that users can enter in the installer should be overridable on the command line for automated deployment as well. The full list of properties that\ncan be overridden will be available soon.\n\nNext Steps\n\nThe new installer is under review by the members of the Platform SIG, but we need people to test the installer and give feedback. If you are interested in testing\nthe new installer, please join the Platform SIG gitter room for more information.\n\nThere are still some things that are being researched and implemented in the new installer (e.g., keeping port and other selections when doing an upgrade), but it is\ngetting close to release.\n\nIn addition to updates to the MSI based Windows installer, the Platform SIG is working on taking over the Chocolatey Jenkins package and\nreleasing a version for each update.","title":"Windows Installer Updates","tags":["windows","platform-sig","installers"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#988878","images":{"fallback":{"src":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/19e71/slide_o_mix.jpg","srcSet":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/77b35/slide_o_mix.jpg 32w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/d4a57/slide_o_mix.jpg 64w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/19e71/slide_o_mix.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/ef6ff/slide_o_mix.webp 32w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/8257c/slide_o_mix.webp 64w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/6766a/slide_o_mix.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/slide_o_mix.jpg"},"blog":null,"github":"slide","html":"<div class=\"paragraph\">\n<p>Alex comes from a .NET background but likes to get his hands dirty in many different languages and frameworks. He currently\ndoes embedded development in a silicon validation group. He is an internal evangelist for Jenkins at his company. Alex\nis a community contributor to Jenkins, working on plugin hosting and maintaining several plugins. He is also involved in\na few SIGS. Alex enjoys working on open source software in his \"free\" time as well as spending time with his family.</p>\n</div>","id":"slide_o_mix","irc":null,"linkedin":null,"name":"Alex Earl","slug":"/blog/authors/slide_o_mix/","twitter":"alexcearl"}]}},{"node":{"date":"2019-01-21T00:00:00.000Z","id":"a737d1ad-0575-5b79-8f34-0dd038cbbc0f","slug":"/blog/2019/01/21/fosdem-2019/","strippedHtml":"FOSDEM 2019 (February 2 & 3) is a free event for software developers to meet, share ideas and collaborate.\nIt is an annual event that brings open source contributors from around the world for two days of presentations, discussions, and learning.\nWhile the Jenkins project won’t have a table at FOSDEM 2019, we will be well represented before, during, and after the event.\n\nFriday Day - Workshops and Jenkins Office Hours\n\nOn Friday, February 1, we’ll start off with a couple workshops:\n\nJenkins Pipeline Fundamentals\n(9:00 AM – 5:00 PM)\nLearn to create and run Declarative Pipelines!\nYou’ll learn the structure of Declarative Pipeline, how to control the flow of execution, how to save artifacts of the build, and get practice using some of the features that give fit and finish to your Pipeline.\nRegistration required - see the\nevent page\nfor details\n\nJenkins X, Kubernetes, and Friends\nTwo sessions: (9:00 AM – 12:00 PM) and (1:00pm to 4:00pm)\nBy combining the power of Jenkins, its community and the power of Kubernetes, the Jenkins X project provides a path to the future of continuous delivery for microservices and cloud-native applications.\nCome explore some of the features of Jenkins X through this hands-on workshop.\nRegistration required - see the\nevent page\nfor details\n\nAside from the workshops, from 9am to 5pm a bunch of people will be working out of Hilton Brussels Grand Place, hanging out as travelers come in.\nIt’ll be a casual, unstructured day. Sign up on this meetup page to be notified what meeting room we’re in.\n\nFriday Evening - Happy Hour\n\nAfter the office hours and workshops, we’ll have a happy hour Friday evening before FOSDEM at Cafe Le Roy d’Espagne.\nSee the meetup page for details.\n\nPresentations at FOSDEM\n\nHackers gotta eat: Building a Company Around an Open Source Project\nby Kohsuke Kawaguchi\n\nSetting up an HPC lab from scratch with Mr-Provisioner, Jenkins and Ansible\nby Renato Golin\n\nMulticloud CI/CD with OpenStack and Kubernetes by Maxime Guyot\n\nJenkins Hackfest after FOSDEM\n\nFinally, a Jenkins Hackfest will be held the day after FOSDEM 2019 on Monday (February 4).\nThose who would like to join us for the hackfest should register for the meetup.\n\nMeals, snacks, and beverages will be provided for the hackfest.  Come join us, and let’s write some code!\n\nQuestions? feel free to contact\nAlyssa Tong or\nBaptiste Mathus or join us on the\nadvocacy-and-outreach gitter channel.","title":"FOSDEM 2019!","tags":["community","events"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/lnewman.jpeg"},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman/","twitter":"bitwiseman"}]}}]}},"pageContext":{"limit":8,"skip":152,"numPages":100,"currentPage":20}},
    "staticQueryHashes": ["3649515864"]}