{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/29",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-06-15T00:00:00.000Z","id":"099fdcfb-2f30-562a-9c7c-67ed48398003","slug":"/blog/2018/06/15/simple-pull-request-plugin/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nMentors\n\nOleg Nenashev (Org Admin)\n\nMartin d’Anjou\n\nKristin Whetstone\n\nJeff Knurek\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of the report at conventional locations,\nand publish them automatically. If the reports are not present at conventional location,\ncan specify the location using the YAML file.\n\nBenefits to the community\n\nProject administrators will be able to handle builds for pull requests more easily.\n\nBuild specifications for pull request can be written in a concise declarative format.\n\nBuild reports will be automatically published to Github, Bitbucket, etc.\n\nBuild status updates will be sent to git servers automatically.\n\nUsers will not have to deal with pipeline code.\n\nIf there will be no merge conflicts or build failures, the PR can be merged into target branch.\n\nPrior work\n\nTravis YML Plugin :\nDesigned to run .travis.yml as Jenkins pipeline job.\nTravis-CI does not support external pull requests. Jenkins environment\nis different than Travis and does not always make sense to use configurations\ndefined for other environment in Jenkins. Also maintenance of this is slowed\ndown and last commit for this plugin was on 14 Nov 2016.\nClick here to check.\n\nCodeShip Plugin :\nThis plugin is designed to convert codeship \"steps.yaml\" and\n\"services.yaml\" to scripted pipeline code. This plugin has never been released.\n\nJenkins pipeline builder :\nThis is a external non-Java-based tool, which cannot be easily converted to a Jenkins plugin.\n\nDesign\n\nThis plugin will be developed on the top of the MultiBranch Pipeline plugin.\n\nFor now the plugin is bulding branches and Pull request both using Jenkinsfile.yaml,\nbut this plugin is inclined to use for pull requests. This will be fixed in next coding phase.\n\nThis plugin is following below steps for now:\n\nclone target repo\n\ncheckout to target branch\n\nfetch the source branch\n\nmerge source-branch\n\ncall user call user script to build the repo.\n\npush changes of pull request to target branch\n\npublish test reports\n\nPlugin will start above steps if and only if the pull request is\nmergeable, to avoid merge conflicts while merging the source branch to target\nbranch. Pull request’s payload contains information if the pull request changes\nare mergeable or not hence, the pull request is mergebale or not can also be\ndecided by the payload of webhook also.\n\nHow to run the Plugin\n\nSee How to run the demo\nand set credentials, owner and repository on your own and you will be good to go.\n\nExample branch-source configuration.\n\nPhase 1 features\n\nUsers are able to select the Jenkinsfile.yaml file as the source for the Pipeline configuration.\n\nGit Push step\n\nharvest results and reports (and post in the pull request)\n\njunit()\n\nfindbugs()\n\narchiveArtifacts()\n\nBasic interface to parse and get build specifications from YAML file.\n\nThings decided\n\nTo build the plugin on the top of multibranch pipeline plugin. As that plugin has implementation of\n\nNice interface to show different branch and pull requests build separately with use of suitable plugins like Github, Bitbucket.\n\nDetect trusted revisions in a repository.\n\nPublishing of build status to the repository.\n\nConvert the YAML configuration to declarative pipeline.\n\nUser will provide path to the script relative to the root directory of the repository\nwithout extension (.sh or .bat) in the YAML file. The plugin will generate pipeline script to detect the\nplatform and call .sh or .bat script.\n\nExample:\n  Path provided: ./scripts/hello\n  a. On UNIX machine “./scripts/hello.sh” will be called\n  b. On non-UNIX machine “./scripts/hello.bat” will be called.\n\nImplementations till now\n\nA first prototype of the plugin is ready. It supports all features of Multi-Branch Pipeline and offers the following features.\n\nBuild description is defined via YAML file stored within the SCM repo. This plugin\nwill depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be\nusing respective paltfroms for their repositories.\n\nBasic conversion of YAML to Declarative Pipeline: A class YamlToPipeline\nis written which will load the \"Jenkinsfile.yaml\" and make use of PipelineSnippetGenerator class\nto generate Declarative pipeline code.\n\nReporting of results.\n\nPlugin is using Yaml from target branch right now. (Maybe this needs some discussion, example:\nwhat if pull request contains changes in Jenkinsfile.yaml)\n\nGit Push step: To push the changes of pull request to the target branch. This is implemented\nusing git-plugin, PushCommand is used for this from git-plugin. credentialId,\nbranch name and repository url for intracting with Github, Bitbucket, etc\nwill be taken automatically from \"Branch-Source\" (Users have to fill thes\ndetails of branch source in job configuration UI). (You can see\nHow to run the demo)\n\nJenkinsfile.yaml example\n\nFor the phase 1 prototype demonstration, the following yaml file was used.\nNote that this format is subject to change in the next phases of the project,\nas we formalise the yaml format definition.\n\nagent:\n    dockerImage: maven:3.5.3-jdk-8\n    args: -v /tmp:/tmp\n\ntestResultPaths:\n    - target/surefire-reports/*.xml\n\nfindBugs: target/*.xml\n\nstages:\n    - name: First\n      scripts:\n        -   ./scripts/hello\n    - name: Build\n      scripts:\n        -   ./scripts/build\n    - name: Tests\n      scripts:\n        -   ./scripts/test\n\narchiveArtifacts:\n    - Jenkinsfile.yaml\n    - scripts/hello.sh\n\nFrom the yaml file shown above, the plugin generates the following pipeline code:\n\npipeline {\n  agent {\n    docker {\n      image 'maven:3.5.3-jdk-8'\n      args '-v /tmp:/tmp'\n      alwaysPull false\n      reuseNode false\n    }\n  }\n  stages {\n    stage('First') {\n      steps {\n        script {\n          if (isUnix()) {\n            sh './scripts/hello.sh'\n          } else {\n            bat './scripts/hello.bat'\n          }\n        }\n      }\n    }\n    stage('Build') {\n      steps {\n        script {\n          if (isUnix()) {\n            sh './scripts/build.sh'\n          } else {\n            bat './scripts/build.bat'\n          }\n        }pipeline\n      }\n      post {\n        success {\n          archiveArtifacts artifacts: '**/target/*.jar'\n          archiveArtifacts artifacts: 'Jenkinsfile.yaml'\n          archiveArtifacts artifacts: 'scripts/hello.sh'\n        }\n      }\n    }\n    stage('Tests') {\n      steps {\n        script {\n          if (isUnix()) {\n            sh './scripts/test.sh'\n          } else {\n            bat './scripts/test.bat'\n          }\n        }\n      }\n      post {\n        success {\n          junit 'target/surefire-reports/*.xml'\n        }\n        always {\n          findbugs pattern: 'target/*.xml'\n        }\n      }\n    }\n  }\n}\n\nPipeline view in Jenkins instance\n\nCoding Phase 2 plans\n\nDecide a proper YAML format to use for Jenkinsfile.yaml\n\nCreate Step Configurator for SPRP plugin. Jenkins-51637.\nThis will enable users to use Pipeline steps in Jenkinsfile.yaml.\n\nAutomatic indentation generation in the generated Pipeline SnipperGenerator class.\n\nWrite tests for the plugin.\n\nJira Epic\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nInitial proposal of the project\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository\n\nPhase 1 Presentation video (June 14, 2018)\n\nPhase 1 Presentation Slides (June 14, 2018)","title":"GSoC Project Intro: Pipeline as YAML","tags":["gsoc2018","gsoc","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/authors/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-06-13T00:00:00.000Z","id":"a1c90a56-ed3d-57e4-bd0b-1397798cc5ea","slug":"/blog/2018/06/13/code-coverage-api-plugin/","strippedHtml":"About me\n\nMy name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.\n\nI am very excited that I can participate in GSoC to work on Code Coverage API plugin with the Jenkins community and to contribute to the open source world. It is my greatest pleasure to write a plugin that many developers will use.\n\nMy mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.\n\nAbstract\n\nThere are a lot of plugins which currently implement code coverage, however, they all use similar config, charts, and content. So it will be much better if we can have an API plugin which does the most repeated work for those plugins and offers a unified APIs which can be consumed by other plugins and external tools.\n\nThis API plugin will mainly do these things:\n\nFind coverage reports according to the user’s config.\n\nUse adapters to convert reports into the our standard format.\n\nParse standard format reports, and aggregate them.\n\nShow parsed result in a chart.\n\nSo, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing — convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.\n\nCurrent Progress - Alpha Version\n\nI have developed an alpha version for this plugin. It currently integrates two different coverage tools - Cobertura and Jacoco. Also, it implements many basic functionalities like threshold, auto-detect, trend chart and so on.\n\nConfiguration Page\n\nconfig plugin\n\nWe can input the path pattern for auto detect, so that plugin will automatically find reports and group them using a corresponding converter. That makes config simpler and the user doesn’t need to fully specify the report name. Also, if we want, we can manually specify each coverage report.\n\nWe also have global and per-report threshold configurations, which makes the plugin more flexible than existing plugins (e.g. global threshold for a multi-language project that has several reports).\n\nPipeline Support\n\nIn addition to configuring the Code Coverage API plugin from the UI page, we also have pipeline support.\n\nnode {\n   publishCoverage(autoDetectPath: '**/*.xml', adapters: [jacoco(path: 'jacoco.xml')], globalThresholds: [[thresholdTarget: 'GROUPS', unhealthyThreshold: 20.0, unstableThreshold: 0.0]])\n}\n\nReport Defects\n\nAs we can see in Configuration page, we can set healthy threshold and stable threshold for each metric. The Code Coverage API plugin will report healthy score according to the healthy threshold we set.\n\nthreshold config\n\nresult\n\nAlso, we have a group of options which can fail the build if coverage falls below a particular threshold.\n\nCoverage Result Page\n\nThe coverage result page now has a modernized UI which shows coverage results more clearly.\nThe result page includes three parts - Trend chart, Summary chart, Child Summary chart.\n\nTrend Chart\n\nIn the Trend chart, we can see the coverage trend of the selected coverage metrics.\n\nSummary Chart\n\nIn the summary chart we can see the coverage summary of current coverage metric.\n\nChild Summary Chart\n\nIn the Child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size.\n\nBy using those more modernized chart components, we can easily focus on the information we want to know.\n\nExtensibility\n\nWe provide several extension points to make our plugin more extensible and flexible. Also, we have a series of abstract layers to help us implementing these extension points much easier.\n\nCoverageReportAdapter\n\nWe can implement a coverage tool by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement Jacoco simple like this:\n\npublic final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {\n\n    @DataBoundConstructor\n    public JacocoReportAdapter(String path) {\n        super(path);\n    }\n\n    @Override\n    public String getXSL() {\n        return \"jacoco-to-standard.xsl\";\n    }\n\n    @Override\n    public String getXSD() {\n        return null;\n    }\n\n    @Symbol(\"jacoco\")\n    @Extension\n    public static final class JacocoReportAdapterDescriptor extends CoverageReportAdapterDescriptor {\n\n        public JacocoReportAdapterDescriptor() {\n            super(JacocoReportAdapter.class, \"jacoco\");\n        }\n    }\n}\n\nAll we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our Java standard format. There are also other extension points which are under development.\n\nOther Extension points\n\nWe also plan to provide extension points for coverage threshold and report detector. Once it completed, we can have more control over our coverage report process.\n\nNext Phase Plan\n\nThe Alpha version now has many parts which still need to be implemented before the final release. So in next phase, I will mainly do those things.\n\nAPIs which can be used by others\n\nIntegrate Cobertura Plugin with Code Coverage API (JENKINS-51424).\n\nProvide API for getting coverage information. E.g. summary information about coverage (percentages, trends) (JENKINS-51422), (JENKINS-51423).\n\nImplementing abstract layer for other report formats like JSON. (JENKINS-51732).\n\nSupporting converters for non-Java languages. (JENKINS-51924).\n\nSupporting combining reports within a build(e.g. after parallel() execution in Pipeline) (JENKINS-51926).\n\nAdding source code navigation in Coverage Result Page (JENKINS-51988).\n\nRefactoring the configuration page to make it more user-friendly (JENKINS-51927).\n\nHow to Try It Out\n\nAlso, I have released the Alpha version in the Experimental Update Center. If you can give me some of your valuable advice about it, I will very appreciate.\n\nLinks\n\nJIRA Component\n\nProject Page\n\nProject Repository\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Intro: Code Coverage API Plugin","tags":["plugins","gsoc","gsoc2018"],"authors":[{"avatar":null,"blog":null,"github":"cizezsy","html":"<div class=\"paragraph\">\n<p>Shenyu comes from China. He is a third year student now, and his major is\nComputer Science and technology. He has participated in GSoC 2018 for\n<a href=\"https://jenkins.io/projects/gsoc/2018/code-coverage-api-plugin/\">Code Coverage API Plugin</a></p>\n</div>","id":"shenyu_zheng","irc":"cizezsy","linkedin":null,"name":"Shenyu Zheng","slug":"/blog/authors/shenyu_zheng","twitter":null}]}},{"node":{"date":"2018-06-08T00:00:00.000Z","id":"f46b46ad-a0ad-590a-a614-37ad7eaf1e7d","slug":"/blog/2018/06/08/jenkins-java10-hackathon/","strippedHtml":"On behalf of the Jenkins Events Team,\nI would like to invite you to the “Jenkins & Java 10 Online Hackathon” which will take place from June 18th to 22nd.\nWe will be working together on Jenkins core and plugins in order\nto find and fix compatibility issues, share experiences and have some fun.\nEverybody is welcome to join, independently of their Jenkins experience and amount of time they have available.\n\nIf you are interested in participating in the hackathon, please sign-up in\nthis form.\n\nBackground\n\nJava 9 has recently been end-of-lifed, Java 10 is in GA, and Java 11 is in early beta.\nJenkins project currently requires Java 8 to run reliably,\nand there are some known compatibility issues with higher Java versions.\n\nDuring the Jenkins World 2017 Hackathon,\nMark Waite and\nBaptiste Mathus spent some time exploring Java 9 compatibility in Jenkins.\nWe are currently tracking compatibility issues in the\nJENKINS-40689 EPIC,\nbut there are likely many unknown issues in Jenkins core, plugins and in libraries we use in the project.\nWe would like to continue their effort and work on Java 10+ support.\n\nObjectives and Scope\n\nAs I have said above,\nthe goals are to explore/fix compatibility issues, share experiences and have fun.\nWe DO NOT plan to make Jenkins fully compatible with Java 10+\nduring the hackathon,\nbut we will try to integrate fixes and make them available.\n\nSince the announcement of the Hackathon in the mailing list,\nwe have got a number of registrations from contributors working on several project areas.\nWe will split our work to several areas:\n\nJenkins core and Remoting\n\nPipeline Engine\n\nPlugins (e.g. Git plugin or any plugin you want to work on)\n\nExploratory testing for Java 10 and beyond\n\nIn order to organize the effort, we have created a\njava10_hackathon label\nin Jenkins JIRA.\nIf you are interested in particular tasks,\nplease assign them to yourself and add the label.\n\nOrganization\n\nCurrently the event is in the planning stage.\nWe will be using the Developer mailing list\nfor synchronization before the event.\n\nWhat will we have?\n\nCommunications in #jenkins-hackhouse IRC and in the\nJenkins Gitter channel\n\nDaily recorded sync-up calls in Hangouts\n\nKnowledge transfer sessions during the event\n\nWe also want to prepare some special swag for active participants.\nIf you have reached this part of the blogpost,\nyou have probably seen the logo ;)\n\nLinks\n\nRegistration\n\nDeveloper mailing list\n\nHackathon sync-up document\n\nRunning Jenkins with Java 10 and 11\n\nJIRA: Java 10 compatibility\n\nJIRA: Java 11 compatibility\n\nJIRA: Hackathon tasks","title":"Jenkins & Java 10+ Online Hackathon (Jun 18-22)","tags":["events","community","developer","java10","java11"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png","srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/914ee/oleg_nenashev.png 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/1c9ce/oleg_nenashev.png 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/acb7c/oleg_nenashev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/ef6ff/oleg_nenashev.webp 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/8257c/oleg_nenashev.webp 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/6766a/oleg_nenashev.webp 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/22bfc/oleg_nenashev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/authors/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2018-05-17T00:00:00.000Z","id":"ae3ff15b-6a37-56b0-89c0-ca24db87819d","slug":"/blog/2018/05/17/tracymiranda-intro/","strippedHtml":"I’m Tracy Miranda, and I’m really excited to have joined CloudBees this month leading the open source program. CloudBees’ contributions to Jenkins include developing Pipeline and Blue Ocean, staffing the infrastructure team, advocacy and events work, as well as security efforts. My focus is on making sure there is a great relationship between the Jenkins community and CloudBees, which means strong communication, help get traction on things the community wants, and generally working to make Jenkins and the community thrive and stay awesome in an ever-changing tech landscape.\n\nHere’s a little background on me: I come from an electronics/EDA background but switched to software early in my career when I first got involved with open source software. I’ve been part of the Eclipse community for around 15 years, definitely from before git was even a thing. I love being involved with all levels: project committer, conference chair, steering committee for working groups and more recently board of directors.\n\nOn a personal note, I …\n\nLive in the UK with my husband and 2 young kids\n\nGrew up in Kenya\n\nEnjoy playing badminton, love good food & am always first at any buffets\n\nI am looking forward to getting to know the Jenkins community well, and really getting a feel for your Jenkins stories, good and bad. Please feel free to let me know:\n\nWhat you love about the Jenkins community & how you are using Jenkins\n\nWhat you’re working on doing with Jenkins\n\nWhat you don’t like and want improved\n\nYou can find me on the mailing lists or via:\n\nTwitter @tracymiranda\n\nEmail: tmiranda@cloudbees.com\n\nIRC: tracymiranda\n\nAlso I’ll be at the upcoming events: DevOps World - Jenkins World in San Francisco, California and Nice, France so if you plan to attend do come and say hi. The Jenkins community is the real force behind Jenkins. And in turn Jenkins powers so much of the software out there. It is an honour to be joining this wonderful community.","title":"Introducing Tracy Miranda as the CloudBees Open Source Program Lead","tags":["community"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg","srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/6105b/tracymiranda.jpg 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/9d80c/tracymiranda.jpg 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a5e1e/tracymiranda.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a4758/tracymiranda.webp 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fec68/tracymiranda.webp 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fe590/tracymiranda.webp 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/c2c8e/tracymiranda.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":116}}},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"/blog/authors/tracymiranda","twitter":"tracymiranda"}]}},{"node":{"date":"2018-05-16T00:00:00.000Z","id":"33bc69d0-dfa9-5c28-bfe5-208f3373b7f9","slug":"/blog/2018/05/16/pipelines-with-git-tags/","strippedHtml":"One common pattern for automated releases I have seen and used relies on Git\ntags as the catalyst for a release process. The immutable nature of releases\nand the immutable nature of tags can definitely go hand in hand, but up until\nfew months ago Jenkins Pipeline was not able to trigger effectively off of Git\ntags.\n\nIn this post I want to briefly share how to use tags to drive behaviors in\nJenkins Pipeline. Consider the following contrived Jenkinsfile, which\ncontains the three basic stages of Build, Test, and Deploy:\n\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make package'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'make check'\n            }\n        }\n        stage('Deploy') {\n            when { tag \"release-*\" }\n            steps {\n                echo 'Deploying only because this commit is tagged...'\n                sh 'make deploy'\n            }\n        }\n    }\n}\n\nOf particular note is the\nwhen\ncondition on the \"Deploy\" stage which is applying the tag criteria. This\nmeans the stage would only execute when the Pipeline has been triggered from a\ntag in Git matching the release-* Ant-style wildcard.\n\nIn practice, this means that all pull requests, and branch-based Pipeline Runs\nresult in the stage being skipped:\n\nWhen I push a release-1.0 tag, the Pipeline will then be triggerd and run the\n\"Deploy\" stage:\n\nOut of the box, Pipelines won’t trigger off of the presence of tags, which\nmeans that a Multibranch Pipeline must have a configuration update to know that\nit must Discover Tags.\n\nConfiguring\n\nFrom the configuration screen of a Multibranch Pipeline (or GitHub Organization\nFolder), Discovering tags can be enabled by adding the appropriate \"Behavior\"\nto the Branch Source configuration:\n\nWith these changes, the Jenkinsfile in the tagged versions of my source\nrepository can now drive distinct deployment behavior which is not otherwise\nenabled in the Pipeline.","title":"When using tags in Jenkins Pipeline","tags":["pipeline","git"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-05-15T00:00:00.000Z","id":"85458a0f-8ad5-53fb-a455-a4b6ae133fb4","slug":"/blog/2018/05/15/incremental-deployment/","strippedHtml":"A couple of weeks ago, Tyler mentioned some\ndeveloper improvements in Essentials\nthat had been recently introduced:\nthe ability for\nci.jenkins.io\nbuilds to get deployed automatically to an “Incrementals” Maven repository,\nas described in\nJEP-305.\nFor a plugin maintainer, you just need to\nturn on this support\nand you are ready to both deploy individual Git commits from your repository\nwithout the need to run heavyweight traditional Maven releases,\nand to depend directly on similar commits of Jenkins core or other plugins.\nThis is a stepping stone toward continuous delivery, and ultimately deployment, of Jenkins itself.\n\nHere I would like to peek behind the curtain a bit at how we did this,\nsince the solution turns out to be very interesting for people thinking about security in Jenkins.\nI will gloss over the Maven arcana required to get the project version to look like 1.40-rc301.87ce0dd8909b\n(a real example from the\nCopy Artifact plugin)\nrather than the usual 1.40-SNAPSHOT, and why this format is even useful.\nSuffice it to say that if you had enough permissions, you could run\n\nmvn -Dset.changelist -DskipTests clean deploy\n\nfrom your laptop to publish your latest commit.\nIndeed as\nmentioned in the JEP,\nthe most straightforward server setup would be to run more or less that command\nfrom the buildPlugin function called from a typical Jenkinsfile,\nwith some predefined credentials adequate to upload to the Maven repository.\n\nUnfortunately, that simple solution did not look very secure.\nIf you offer deployment credentials to a Jenkins job,\nyou need to trust anyone who might configure that job (here, its Jenkinsfile)\nto use those credentials appropriately.\n(The withCredentials step will mask the password from the log file, to prevent accidental disclosures.\nIt in no way blocks deliberate misuse or theft.)\nIf your Jenkins service runs inside a protected network and works with private repositories,\nthat is probably good enough.\n\nFor this project, we wanted to permit incremental deployments from any pull request.\nJenkins will refuse to run Jenkinsfile modifications from people\nwho would not normally be able to merge the pull request or push directly,\nand those people would be more or less trustworthy Jenkins developers,\nbut that is of no help if a pull request changes pom.xml\nor other source files used by the build itself.\nIf the server administrator exposes a secret to a job,\nand it is bound to an environment variable while running some open-ended command like a Maven build,\nthere is no practical way to control what might happen.\n\nThe lesson here is that the unit of access control in Jenkins is the job.\nYou can control who can configure a job, or who can edit files it uses,\nbut you have no control over what the job does or how it might use any credentials.\nFor JEP-305, therefore, we wanted a way to perform deployments from builds considered as black boxes.\nThis means a division of responsibility:\nthe build produces some artifacts, however it sees fit;\nand another process picks up those artifacts and deploys them.\n\nThis worked was tracked in\nINFRA-1571.\nThe idea was to create a “serverless function” in Azure\nthat would retrieve artifacts from Jenkins at the end of a build,\nperform a set of validations to ensure that the artifacts follow an expected repository path pattern,\nand finally deploy them to Artifactory using a trusted token.\nI prototyped this in Java, Tyler\nrewrote it in JavaScript,\nand together we brought it into production.\n\nThe crucial bit here is what information (or misinformation!) the Jenkins build can send to the function.\nAll we actually need to know is the build URL, so the\ncall site from Jenkins\nis quite simple.\nWhen the function is called with this URL,\nit starts off by performing input validation:\nit knows what the Jenkins base URL is,\nand what a build URL from inside an organization folder is supposed to look like:\nhttps://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/ , for example.\n\nThe next step is to call back to Jenkins and ask it for some metadata about that build.\nWhile we do not trust the build, we trust the server that ran it to be properly configured.\nAn obstacle here was that the ci.jenkins.io server had been configured to disable the Jenkins REST API;\nwith Tyler’s guidance I was able to amend this policy to permit API requests from registered users\n(or, in the case of the Incrementals publisher, a bot).\n\nIf you want to try this at home, get an\nAPI token,\npick a build of an “incrementalified” plugin or Jenkins core,\nand run something like\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/api/json?pretty&tree=actions[revision[hash,pullHash]]'\n\nYou will see a hash or pullHash corresponding to the main commit of that build.\n(This information was added to the Jenkins REST API to support this use case in\nJENKINS-50777.)\nThe main commit is selected when the build starts\nand always corresponds to the version of Jenkinsfile in the repository for which the job is named.\nWhile a build might checkout any number of repositories,\ncheckout scm always picks “this” repository in “this” version.\nTherefore the deployment function knows for sure which commit the sources came from,\nand will refuse to deploy artifacts named for some other commit.\n\nNext it looks up information about the Git repository at the folder level (again from JENKINS-50777):\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/api/json?pretty&tree=sources[source[repoOwner,repository]]'\n\nThe Git repository now needs to be correlated to a list of Maven artifact paths that this component is expected to produce.\nThe\nrepository-permissions-updater\n(RPU) tool already had a list of artifact paths used to perform permission checks on regular release deployments to Artifactory; in\nINFRA-1598\nI extended it to also record the GitHub repository name, as can be seen\nhere.\nNow the function knows that the CI build in this example may legitimately create artifacts in the org/jenkins-ci/plugins/git/ namespace\nincluding 38c569094828 in their versions.\nThe build is expected to have produced artifacts in the same structure as mvn install sends to the local repository,\nso the function downloads everything associated with that commit hash:\n\ncurl -sg 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/artifact/**/*-rc*.38c569094828/*-rc*.38c569094828*/*zip*/archive.zip' | jar t\n\nWhen all the artifacts are indeed inside the expected path(s),\nand at least one POM file is included (here org/jenkins-ci/plugins/git/3.9.0-rc1671.38c569094828/git-3.9.0-rc1671.38c569094828.pom),\nthen the ZIP file looks good—ready to send to Artifactory.\n\nOne last check is whether the commit has already been deployed (perhaps this is a rebuild).\nIf it has not, the function uses the Artifactory REST API to atomically upload the ZIP file\nand uses the GitHub Status API to associate a message with the commit\nso that you can see right in your pull request that it got deployed:\n\nOne more bit of caution was required.\nJust because we successfully published some bits from some PR does not mean they should be used!\nWe also needed a tool which lets you select the newest published version of some artifact\nwithin a particular branch, usually master.\nThis was tracked in\nJENKINS-50953\nand is available to start with as a Maven command operating on a pom.xml :\n\nmvn incrementals:update\n\nThis will check Artifactory for updates to relevant components.\nWhen each one is found, it will use the GitHub API to check whether the commit has been merged to the selected branch.\nOnly matches are offered for update.\n\nPutting all this together, we have a system for continuously delivering components\nfrom any of the hundreds of Jenkins Git repositories\ntriggered by the simple act of filing a pull request.\nSecuring that system was a lot of work\nbut highlights how boundaries of trust interact with CI/CD.","title":"Automatic deployment of “incremental” commits to Jenkins core and plugins","tags":["evergreen","developer"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-05-09T00:00:00.000Z","id":"60f8a17b-1600-571d-a45d-9012801aa2b7","slug":"/blog/2018/05/09/security-advisory/","strippedHtml":"We just released security updates to Jenkins, versions 2.121 and 2.107.3, that fix multiple security vulnerabilities.\n\nAdditionally, we announce previously published security issues and corresponding fixes in these plugins:\n\nBlack Duck Hub\n\nGroovy Postbuild\n\nGitlab Hook (fix unreleased)\n\nFor an overview of what was fixed, see the security advisory.\nFor an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core and plugins","tags":["core","plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2018-05-08T00:00:00.000Z","id":"29ad061f-dba2-536d-91b4-878d290af36d","slug":"/blog/2018/05/08/jenkins-x-anchore/","strippedHtml":"Anchore provides docker image analysis for user defined acceptance policies to allow automated image validation and acceptance.\n\nAs developers we would like to know if a change we are proposing introduces a\nCommon Vulnerability and Exposure (CVE).\nAs operators we would like to know what running applications are affected if a new CVE is discovered.\n\nNow in Jenkins X pipelines, if we find an\nAnchore engine service running we will add the preview and release images to be analyzed.\nThis means we can look at any environment including previews (created from Pull Requests)\nto see if your application contains a CVE.\n\nUpgrade\n\nStart by checking your current Jenkins X version:\n\njx version\n\nIf your Jenkins X platform is older than 0.0.903, then first you will need to upgrade to at least 0.0.922:\n\njx upgrade cli\njx upgrade platform\n\nInstall addon\n\nYou can install the\nAnchore engine addon\nwhen you are in your Jenkins X team home environment.\n\njx env dev\njx create addon anchore\n\nThis will install the engine in a seperate anchore namespace\nand create a service link in the current team home environment\nso our pipeline builds can add docker images to Anchore for analysis.\n\nCreate an application\n\nYou can now create a new quickstart:\n\njx create quickstart\n\nList any CVEs\n\nOnce the build has run you will be able to check for CVEs in any environment incluing previews created for pull requests.\n\njx get cve --environment staging\n\nDemo\n\nHere’s a 4 minute video that demonstrates the steps above:\n\nUpgrading existing pipelines\n\nIf you have an existing application pipeline and and want enable image analysis you can update your Jenkinsfile,\nin the preview stage after the skaffold step add the line\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:$PREVIEW_VERSION\"\n\nIn the master stage the add this line after the skaffold step\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:\\$(cat VERSION)\"\n\nFor any questions please find us - we mainly hang out on Slack at\n#jenkins-x-dev - or see\njenkins-x.io/community for other channels.","title":"Jenkins X: Announcing CVE docker image analysis with Anchore","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings","twitter":"jdrawlings"}]}}]}},"pageContext":{"limit":8,"skip":224,"numPages":100,"currentPage":29}},
    "staticQueryHashes": ["3649515864"]}