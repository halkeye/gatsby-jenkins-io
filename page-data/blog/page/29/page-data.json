{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/29",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-05-17T00:00:00.000Z","id":"ae3ff15b-6a37-56b0-89c0-ca24db87819d","slug":"/blog/2018/05/17/tracymiranda-intro/","strippedHtml":"I’m Tracy Miranda, and I’m really excited to have joined CloudBees this month leading the open source program. CloudBees’ contributions to Jenkins include developing Pipeline and Blue Ocean, staffing the infrastructure team, advocacy and events work, as well as security efforts. My focus is on making sure there is a great relationship between the Jenkins community and CloudBees, which means strong communication, help get traction on things the community wants, and generally working to make Jenkins and the community thrive and stay awesome in an ever-changing tech landscape.\n\nHere’s a little background on me: I come from an electronics/EDA background but switched to software early in my career when I first got involved with open source software. I’ve been part of the Eclipse community for around 15 years, definitely from before git was even a thing. I love being involved with all levels: project committer, conference chair, steering committee for working groups and more recently board of directors.\n\nOn a personal note, I …\n\nLive in the UK with my husband and 2 young kids\n\nGrew up in Kenya\n\nEnjoy playing badminton, love good food & am always first at any buffets\n\nI am looking forward to getting to know the Jenkins community well, and really getting a feel for your Jenkins stories, good and bad. Please feel free to let me know:\n\nWhat you love about the Jenkins community & how you are using Jenkins\n\nWhat you’re working on doing with Jenkins\n\nWhat you don’t like and want improved\n\nYou can find me on the mailing lists or via:\n\nTwitter @tracymiranda\n\nEmail: tmiranda@cloudbees.com\n\nIRC: tracymiranda\n\nAlso I’ll be at the upcoming events: DevOps World - Jenkins World in San Francisco, California and Nice, France so if you plan to attend do come and say hi. The Jenkins community is the real force behind Jenkins. And in turn Jenkins powers so much of the software out there. It is an honour to be joining this wonderful community.","title":"Introducing Tracy Miranda as the CloudBees Open Source Program Lead","tags":["community"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"blog/author/tracymiranda","twitter":"tracymiranda"}]}},{"node":{"date":"2018-05-16T00:00:00.000Z","id":"33bc69d0-dfa9-5c28-bfe5-208f3373b7f9","slug":"/blog/2018/05/16/pipelines-with-git-tags/","strippedHtml":"One common pattern for automated releases I have seen and used relies on Git\ntags as the catalyst for a release process. The immutable nature of releases\nand the immutable nature of tags can definitely go hand in hand, but up until\nfew months ago Jenkins Pipeline was not able to trigger effectively off of Git\ntags.\n\nIn this post I want to briefly share how to use tags to drive behaviors in\nJenkins Pipeline. Consider the following contrived Jenkinsfile, which\ncontains the three basic stages of Build, Test, and Deploy:\n\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make package'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'make check'\n            }\n        }\n        stage('Deploy') {\n            when { tag \"release-*\" }\n            steps {\n                echo 'Deploying only because this commit is tagged...'\n                sh 'make deploy'\n            }\n        }\n    }\n}\n\nOf particular note is the\nwhen\ncondition on the \"Deploy\" stage which is applying the tag criteria. This\nmeans the stage would only execute when the Pipeline has been triggered from a\ntag in Git matching the release-* Ant-style wildcard.\n\nIn practice, this means that all pull requests, and branch-based Pipeline Runs\nresult in the stage being skipped:\n\nWhen I push a release-1.0 tag, the Pipeline will then be triggerd and run the\n\"Deploy\" stage:\n\nOut of the box, Pipelines won’t trigger off of the presence of tags, which\nmeans that a Multibranch Pipeline must have a configuration update to know that\nit must Discover Tags.\n\nConfiguring\n\nFrom the configuration screen of a Multibranch Pipeline (or GitHub Organization\nFolder), Discovering tags can be enabled by adding the appropriate \"Behavior\"\nto the Branch Source configuration:\n\nWith these changes, the Jenkinsfile in the tagged versions of my source\nrepository can now drive distinct deployment behavior which is not otherwise\nenabled in the Pipeline.","title":"When using tags in Jenkins Pipeline","tags":["pipeline","git"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-05-15T00:00:00.000Z","id":"85458a0f-8ad5-53fb-a455-a4b6ae133fb4","slug":"/blog/2018/05/15/incremental-deployment/","strippedHtml":"A couple of weeks ago, Tyler mentioned some\ndeveloper improvements in Essentials\nthat had been recently introduced:\nthe ability for\nci.jenkins.io\nbuilds to get deployed automatically to an “Incrementals” Maven repository,\nas described in\nJEP-305.\nFor a plugin maintainer, you just need to\nturn on this support\nand you are ready to both deploy individual Git commits from your repository\nwithout the need to run heavyweight traditional Maven releases,\nand to depend directly on similar commits of Jenkins core or other plugins.\nThis is a stepping stone toward continuous delivery, and ultimately deployment, of Jenkins itself.\n\nHere I would like to peek behind the curtain a bit at how we did this,\nsince the solution turns out to be very interesting for people thinking about security in Jenkins.\nI will gloss over the Maven arcana required to get the project version to look like 1.40-rc301.87ce0dd8909b\n(a real example from the\nCopy Artifact plugin)\nrather than the usual 1.40-SNAPSHOT, and why this format is even useful.\nSuffice it to say that if you had enough permissions, you could run\n\nmvn -Dset.changelist -DskipTests clean deploy\n\nfrom your laptop to publish your latest commit.\nIndeed as\nmentioned in the JEP,\nthe most straightforward server setup would be to run more or less that command\nfrom the buildPlugin function called from a typical Jenkinsfile,\nwith some predefined credentials adequate to upload to the Maven repository.\n\nUnfortunately, that simple solution did not look very secure.\nIf you offer deployment credentials to a Jenkins job,\nyou need to trust anyone who might configure that job (here, its Jenkinsfile)\nto use those credentials appropriately.\n(The withCredentials step will mask the password from the log file, to prevent accidental disclosures.\nIt in no way blocks deliberate misuse or theft.)\nIf your Jenkins service runs inside a protected network and works with private repositories,\nthat is probably good enough.\n\nFor this project, we wanted to permit incremental deployments from any pull request.\nJenkins will refuse to run Jenkinsfile modifications from people\nwho would not normally be able to merge the pull request or push directly,\nand those people would be more or less trustworthy Jenkins developers,\nbut that is of no help if a pull request changes pom.xml\nor other source files used by the build itself.\nIf the server administrator exposes a secret to a job,\nand it is bound to an environment variable while running some open-ended command like a Maven build,\nthere is no practical way to control what might happen.\n\nThe lesson here is that the unit of access control in Jenkins is the job.\nYou can control who can configure a job, or who can edit files it uses,\nbut you have no control over what the job does or how it might use any credentials.\nFor JEP-305, therefore, we wanted a way to perform deployments from builds considered as black boxes.\nThis means a division of responsibility:\nthe build produces some artifacts, however it sees fit;\nand another process picks up those artifacts and deploys them.\n\nThis worked was tracked in\nINFRA-1571.\nThe idea was to create a “serverless function” in Azure\nthat would retrieve artifacts from Jenkins at the end of a build,\nperform a set of validations to ensure that the artifacts follow an expected repository path pattern,\nand finally deploy them to Artifactory using a trusted token.\nI prototyped this in Java, Tyler\nrewrote it in JavaScript,\nand together we brought it into production.\n\nThe crucial bit here is what information (or misinformation!) the Jenkins build can send to the function.\nAll we actually need to know is the build URL, so the\ncall site from Jenkins\nis quite simple.\nWhen the function is called with this URL,\nit starts off by performing input validation:\nit knows what the Jenkins base URL is,\nand what a build URL from inside an organization folder is supposed to look like:\nhttps://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/ , for example.\n\nThe next step is to call back to Jenkins and ask it for some metadata about that build.\nWhile we do not trust the build, we trust the server that ran it to be properly configured.\nAn obstacle here was that the ci.jenkins.io server had been configured to disable the Jenkins REST API;\nwith Tyler’s guidance I was able to amend this policy to permit API requests from registered users\n(or, in the case of the Incrementals publisher, a bot).\n\nIf you want to try this at home, get an\nAPI token,\npick a build of an “incrementalified” plugin or Jenkins core,\nand run something like\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/api/json?pretty&tree=actions[revision[hash,pullHash]]'\n\nYou will see a hash or pullHash corresponding to the main commit of that build.\n(This information was added to the Jenkins REST API to support this use case in\nJENKINS-50777.)\nThe main commit is selected when the build starts\nand always corresponds to the version of Jenkinsfile in the repository for which the job is named.\nWhile a build might checkout any number of repositories,\ncheckout scm always picks “this” repository in “this” version.\nTherefore the deployment function knows for sure which commit the sources came from,\nand will refuse to deploy artifacts named for some other commit.\n\nNext it looks up information about the Git repository at the folder level (again from JENKINS-50777):\n\ncurl -igu : 'https://ci.jenkins.io/job/Plugins/job/git-plugin/api/json?pretty&tree=sources[source[repoOwner,repository]]'\n\nThe Git repository now needs to be correlated to a list of Maven artifact paths that this component is expected to produce.\nThe\nrepository-permissions-updater\n(RPU) tool already had a list of artifact paths used to perform permission checks on regular release deployments to Artifactory; in\nINFRA-1598\nI extended it to also record the GitHub repository name, as can be seen\nhere.\nNow the function knows that the CI build in this example may legitimately create artifacts in the org/jenkins-ci/plugins/git/ namespace\nincluding 38c569094828 in their versions.\nThe build is expected to have produced artifacts in the same structure as mvn install sends to the local repository,\nso the function downloads everything associated with that commit hash:\n\ncurl -sg 'https://ci.jenkins.io/job/Plugins/job/git-plugin/job/PR-582/17/artifact/**/*-rc*.38c569094828/*-rc*.38c569094828*/*zip*/archive.zip' | jar t\n\nWhen all the artifacts are indeed inside the expected path(s),\nand at least one POM file is included (here org/jenkins-ci/plugins/git/3.9.0-rc1671.38c569094828/git-3.9.0-rc1671.38c569094828.pom),\nthen the ZIP file looks good—ready to send to Artifactory.\n\nOne last check is whether the commit has already been deployed (perhaps this is a rebuild).\nIf it has not, the function uses the Artifactory REST API to atomically upload the ZIP file\nand uses the GitHub Status API to associate a message with the commit\nso that you can see right in your pull request that it got deployed:\n\nOne more bit of caution was required.\nJust because we successfully published some bits from some PR does not mean they should be used!\nWe also needed a tool which lets you select the newest published version of some artifact\nwithin a particular branch, usually master.\nThis was tracked in\nJENKINS-50953\nand is available to start with as a Maven command operating on a pom.xml :\n\nmvn incrementals:update\n\nThis will check Artifactory for updates to relevant components.\nWhen each one is found, it will use the GitHub API to check whether the commit has been merged to the selected branch.\nOnly matches are offered for update.\n\nPutting all this together, we have a system for continuously delivering components\nfrom any of the hundreds of Jenkins Git repositories\ntriggered by the simple act of filing a pull request.\nSecuring that system was a lot of work\nbut highlights how boundaries of trust interact with CI/CD.","title":"Automatic deployment of “incremental” commits to Jenkins core and plugins","tags":["evergreen","developer"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"blog/author/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-05-09T00:00:00.000Z","id":"60f8a17b-1600-571d-a45d-9012801aa2b7","slug":"/blog/2018/05/09/security-advisory/","strippedHtml":"We just released security updates to Jenkins, versions 2.121 and 2.107.3, that fix multiple security vulnerabilities.\n\nAdditionally, we announce previously published security issues and corresponding fixes in these plugins:\n\nBlack Duck Hub\n\nGroovy Postbuild\n\nGitlab Hook (fix unreleased)\n\nFor an overview of what was fixed, see the security advisory.\nFor an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core and plugins","tags":["core","plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"blog/author/daniel-beck","twitter":null}]}},{"node":{"date":"2018-05-08T00:00:00.000Z","id":"29ad061f-dba2-536d-91b4-878d290af36d","slug":"/blog/2018/05/08/jenkins-x-anchore/","strippedHtml":"Anchore provides docker image analysis for user defined acceptance policies to allow automated image validation and acceptance.\n\nAs developers we would like to know if a change we are proposing introduces a\nCommon Vulnerability and Exposure (CVE).\nAs operators we would like to know what running applications are affected if a new CVE is discovered.\n\nNow in Jenkins X pipelines, if we find an\nAnchore engine service running we will add the preview and release images to be analyzed.\nThis means we can look at any environment including previews (created from Pull Requests)\nto see if your application contains a CVE.\n\nUpgrade\n\nStart by checking your current Jenkins X version:\n\njx version\n\nIf your Jenkins X platform is older than 0.0.903, then first you will need to upgrade to at least 0.0.922:\n\njx upgrade cli\njx upgrade platform\n\nInstall addon\n\nYou can install the\nAnchore engine addon\nwhen you are in your Jenkins X team home environment.\n\njx env dev\njx create addon anchore\n\nThis will install the engine in a seperate anchore namespace\nand create a service link in the current team home environment\nso our pipeline builds can add docker images to Anchore for analysis.\n\nCreate an application\n\nYou can now create a new quickstart:\n\njx create quickstart\n\nList any CVEs\n\nOnce the build has run you will be able to check for CVEs in any environment incluing previews created for pull requests.\n\njx get cve --environment staging\n\nDemo\n\nHere’s a 4 minute video that demonstrates the steps above:\n\nUpgrading existing pipelines\n\nIf you have an existing application pipeline and and want enable image analysis you can update your Jenkinsfile,\nin the preview stage after the skaffold step add the line\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:$PREVIEW_VERSION\"\n\nIn the master stage the add this line after the skaffold step\n\nsh \"jx step validate --min-jx-version 1.2.36\"\nsh \"jx step post build --image \\$JENKINS_X_DOCKER_REGISTRY_SERVICE_HOST:\\$JENKINS_X_DOCKER_REGISTRY_SERVICE_PORT/$ORG/$APP_NAME:\\$(cat VERSION)\"\n\nFor any questions please find us - we mainly hang out on Slack at\n#jenkins-x-dev - or see\njenkins-x.io/community for other channels.","title":"Jenkins X: Announcing CVE docker image analysis with Anchore","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"blog/author/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-05-01T00:00:00.000Z","id":"29e7f29f-403c-5601-b053-b8a3c4a7dcee","slug":"/blog/2018/05/01/gsoc2018-projects-announcement/","strippedHtml":"On behalf of the Jenkins GSoC team and mentors,\nI would like to welcome\nShenyu Zheng,\nUdara De Silva,\nPham Vu Tuan and\nAbhishek Gautam.\nThey will be working on Google Summer of Code projects in the Jenkins organization,\nand they have already done some contributions.\n\nThis year we have the following projects:\n\nCode Coverage API Plugin -\ncreate a new API Plugin to unify existing Code Coverage plugins and provide new features.\n\nStudent: Shenyu Zheng from Henan University, Kaifeng, China\n\nMentors: Steven Christou and Supun Wanniarachchi\n\nElectronic Design Automation Plugins -\ncreate plugins for open-source Electronic Design Automation tools for synthesis, simulation and coverage analysis (iVerilog, covered, Yosys).\n\nStudent: Udara De Silva from University of Akron, Ohio, USA\n\nMentors: Martin d’Anjou and Oleg Nenashev\n\nJenkins Remoting over Message Bus/Queue -\nadd support of a popular message queue/bus technology (RabbitMQ or Kafka) as a fault-tolerant communication layer in Jenkins.\n\nStudent: Pham Vu Tuan from Nanyang Technological University, Singapore\n\nMentors: Oleg Nenashev and Supun Wanniarachchi\n\nSimple Pull-Request Job Plugin -\nadd ability to define Jenkins jobs as YAML files stored in SCM, integrate it with existing plugin ecosystem.\n\nStudent: Abhishek Gautam from Visvesvaraya National Institute of Technology, Nagpur, India\n\nMentors: Jeff Knurek, Kristin Whetstone and\nWilly Aguirre\n\nDuring next 4 weeks project teams will be reaching out to potential stakeholders in order to establish connections and\nto get comments regarding their project designs.\nIf you are interested in the projects, please join discussions in the\nDeveloper mailing lists and project meetings once they get scheduled.\nPlease also expect expect more detailed blogposts about the projects soon.\n\nIf you are interested to know more about GSoC in Jenkins, you can find information, timeline and communication channels\nhere.","title":"Welcome Google Summer of Code 2018 students!","tags":["gsoc","gsoc2018","events","community"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"blog/author/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2018-04-30T00:00:00.000Z","id":"b56ab05f-d077-5b8d-ab93-27f00b4c8c1e","slug":"/blog/2018/04/30/using-the-beta-annotation/","strippedHtml":"This sort of slid under the radar in the middle of some bigger changes\nfor the JEP-202\nreference implementation, so I wanted to call it out now. Arguably this could\ndeserve a retroactive JEP, though I would rather fold it into a JEP for\nJENKINS-49651 (see below).\n\nAs of Jenkins 2.118, or plugin parent POM 3.7, you can mark any Java member\n( class, method, constructor, field, or I suppose also interface,\nenum, or annotation) with API visibility ( protected or public) with an\nannotation :\n\n@Restricted(Beta.class)\n\nThe idea is to announce to potential users of the member that the API\nmay still be in flux and only code prepared to keep up should be using\nit. For an example, 2.118 added a VirtualFile.toExternalURL() method\nthat is being implemented in artifact-manager-s3 and (pending some\nPR merges) called in copyartifact and workflow-basic-steps. We do\nnot necessarily want this to be called yet by unknown parties out\nthere in the Jenkins ecosystem. To enforce that, any attempt to call\nor implement toExternalURL will produce a build failure, unless you\nadd this property to your plugin POM, as these plugins have done:\n\ntrue\n\nWhy? Because there is a chance the design is wrong and it might need\nto be changed—perhaps some upcoming bug fix would demand a boolean\nparameter be added, for example.\n\nUnder the conventional notion of Jenkins API deprecation and compatibility\npolicy, once an API like this makes it into a release version, that is it—we\nmight mark it @Deprecated but we need to maintain compatibility indefinitely,\nand find some way to migrate existing implementations / call sites.\n\nWith the @Beta annotation, that promise is not being made. If it needs\na boolean parameter for some reason, that will be added and those\nthree plugins updated to match; we are not going to bother retaining\nthe original overload and somehow delegating to the new one. This\nsimplification of the developer workflow is important to the use cases\nof Essentials (JEP-3xx), and I would expect the useBeta mark to\nbecome widespread among plugins included in Essentials. Such as the situation\nwhere one team needs to feel\ncomfortable refactoring code under its aegis freely, and the refactored result\nshould be deliverable as a unit to production via the Evergreen distribution\nsystem.\n\nSo that leaves two important questions:\n\nFirst, is the annotation\npermanent, and if not, when should it be removed? I do not think there\nis any hard policy, but the intention is that it should be removed\nonce the API is in more or less widespread use and has held up. For\nthis example, if people start using S3 artifacts, and especially if\nsomeone successfully writes an implementation of artifact storage in\nAzure that uses the API, the concept will have been reasonably proven.\nAt that point we want the API to be used wherever it would make sense,\nand if there is some very belated realization that the design is not\nquite right, we accept the burden of deprecating the original and\nmigrating callers compatibly.\n\nSecond, it is fine and well to say that someone changing the signature\nof a beta toExternalURL is on the hook to update the three plugins\nusing it, but what if a Jenkins admin ( not running Essentials, for\nshame) upgrades to (say) Jenkins 2.125 with the new signature but\ndeclines to accept the updates to those plugins (say,\nworkflow-basic-steps 2.9) which adapt to the change? It is not\nenough to say that it is their fault for holding back on the updates\narbitrarily; the plugin manager offers you updates but does nothing\nto tell you when they are required, so suddenly throwing\nNoSuchMethodError is not a helpful response.\n\nThe solution needs to be ironed out, but my expectation is to use\nJENKINS-49651\nfor this. For example, workflow-basic-steps 2.8,\nusing toExternalURL(), would have declared itself compatible with\nJenkins-Version: 2.118, and thus implicitly anything newer. The\ndeveloper doing the refactoring would also amend some 2.125 (and\nnewer) core metadata to say that it conflicts with anything older than\nthe 2.9 release of the plugin. The plugin manager would therefore\nblock the 2.8 plugin from even being loaded on the 2.125 core; the\nadmin would need to update before using it. In the case of an\nincompatible change made to a plugin API, rather than a core API, the\nUX is a little smoother since the plugin manager could just refuse to\nlet you update one without the other.\n\nIf you’re a plugin or core developer who is interested in using the @Beta\nannotations, or have questions about our motiviations, please join the\ndiscussion on\nthis mailing list thread.","title":"Using new core APIs with the Beta annotation","tags":["core","developer","plugin"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"blog/author/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-04-27T00:00:00.000Z","id":"3e9f5209-666c-54d9-9dcf-8fcbc3620a51","slug":"/blog/2018/04/27/essentials-versions-are-numbered/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nA couple weeks ago, I\nwrote about the Jenkins Essentials\neffort, on which we’ve been making steady progress. Personally, the most\nexciting challenge of this project is defining the machinery to drive\nautomatic updates\nof Jenkins Essentials, which viewed from a high level, are classic continuous\ndelivery challenges.\n\nIn this post, I wanted to dive into a bit of the gritty details of how we’re\ngoing to be delivering Jenkins Essentials with automatic updates, which has\nsome really interesting requirements for the development of Jenkins itself.\n\nThe traditional Jenkins core and plugin development workflow involves a\ndeveloper working on changes for some amount of time, then when they’re ready,\nthey \"create a release\" which typically involves publishing artifacts to our\nArtifactory, and then on a timer (typically every 15 minutes) the Update Center will\nre-generate a file called update-center.json. Once the new Update Center has\nbeen generated, it is published and consumed by Jenkins installations within\n24 hours. Of course, only after Jenkins administrators recognize that there is\nan update available, can they install it. All in all, it can take quite a long\ntime from when a developer publishes a release, to when it is successfully used\nby an end-user.\n\nWith our desire to make Jenkins Essentials updates seamless and automatic, the\nstatus quo clearly was not going to work. Our shift in thinking has required a\ncouple simultaneous efforts to make this more continuously delivered approach\nviable.\n\nDeveloper Improvements\n\nStarting from the developer’s workflow,\nJesse Glick\nhas been working on publishing \"incremental builds\" of artifacts into a\nspecial Maven repository\nin Artifactory. Much of his work is described in the very thorough\nJenkins Enhancement Proposal 305.\nThis support, which is now live on\nci.jenkins.io\nallows plugin developers to publish versioned changes from pull requests and\nbranches to the incrementals repository. Not only does this make it much\neasier for Jenkins Essentials to deliver changes closer to the HEAD of\nmaster branches, it also unlocks lots of flexibility for Jenkins developers\nwho coordinate changes across matrices of plugins and core, as occasionally is\nnecessary for Jenkins Pipeline, Credentials, Blue Ocean, and a number of other\nfoundational components of a modern Jenkins install.\n\nIn a follow-up blog post, Jesse is going to go into much more detail on some of\nthe access control and tooling changes he had to solve to make this\nincrementals machinery work.\n\nOf course, incremental builds are only a piece of the puzzle, with those\nartifacts, Jenkins Essentials has to be able to do something useful with them!\n\nUpdate Improvements\n\nThe number one requirement, from my perspective, for the automatically updated\ndistribution is that it is safe. \"Safe\" means that a user doesn’t need to\nbe involved in the update process, and if something goes wrong, the\ninstance recovers without the user needing to do anything to remediate a\n\"bad code deploy.\"\n\nIn my previous post on the subject, I mentioned Baptiste’s work on\nJenkins Enhancement\nProposal 302 which describes the \"data safety\" system for safely applying\nupdates, and in case of failure, rolling back.\n\nThe next obvious question is \"what’s failure?\" which Baptiste spent some time\nexploring and implementing in two more designs:\n\nJEP-304: Essentials Client Error Telemetry Logging\n\nJEP-306: Essentials Instance Client Health Checking\n\nOn the server side, of which there is substantial work for Jenkins Essentials,\nthese concepts integrate with the concept of an\nUpdate Lifecycle\nbetween the server and client. In essence, the server side must be able to\ndeliver the right updates to the right clients, and avoid delivering tainted\nupdates (those with known problems) to clients. While this part of the work is\nstill on-going, tremendous progress has been made over the past couple weeks\nin ensuring that updates can be safely, securely, and automatically delivered.\n\nWith the ability to identify \"bad code deploys\", and having a mechanism for\nsafely rolling back, not only does Jenkins Essentials allow seamless\nupdates, but it enables Jenkins developers to deliver features and bugfixes\nmuch more quickly than our current distribution model allows.\n\nWhile Jenkins Essentials does not have a package ready for broad consumption\nyet, we’re rapidly closing in on the completion of our first milestone which\nties all of these automatic update components together and builds the\nfoundation for continuous delivery of all subsequent improvements.\n\nYou can follow our progress in the\njenkins-infra/evergreen\nrepository, or join us in our\nGitter chat!","title":"Jenkins Essentials: The days of versions are numbered","tags":["evergreen"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}}]}},"pageContext":{"limit":8,"skip":224,"numPages":100,"currentPage":29}},
    "staticQueryHashes": ["3649515864"]}