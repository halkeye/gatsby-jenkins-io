{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/36",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-08-08T00:00:00.000Z","id":"2e385886-1033-5881-ab06-b060d5568108","slug":"/blog/2017/08/08/introducing-jenkins-minute/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nThere are less than three weeks left until\nJenkins World 2017.\nLike last year, I’ll be at the\n\" Ask the Experts\"\nbooth to answer questions about all things Jenkins.\nIn preparation, I’ve started a continuing series of quick tutorial videos that answer\nsome of the most common questions I’ve seen asked in the community forums.\nThese  are by no means exhaustive - they’re basic answers, which we can build upon.\nEach video give a takes a simple example, shows how to create a working solution,\nand includes links in the description to related Jenkins documentation pages.\n\nI hope you find them useful.  Look for more of them coming soon!\n\nLiam will be at the\n\" Ask the Experts\"\nbooth at\nJenkins World in August.\nRegister with the code JWFOSS for a 30% discount off your pass.\n\nCreating Your First Pipeline in Blue Ocean\n\nUsing a Dockerfile with Jenkins Pipeline\n\nAdding Parameters to Jenkins Pipeline\n\nRecording Test Results and Archiving Artifacts","title":"Introducing the Jenkins Minute video series","tags":["blueocean","docker","jenkins-minute","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/lnewman.jpeg"},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman/","twitter":"bitwiseman"}]}},{"node":{"date":"2017-08-07T00:00:00.000Z","id":"30508a44-0d3c-579b-8b31-b92e43b9e1f2","slug":"/blog/2017/08/07/intro-to-plugin-development/","strippedHtml":"This is a guest post by Mark Waite, who maintains\nthe git plugin,\nthe git client plugin,\nand is a technical evangelist for CloudBees, Inc.\n\nWhile developing the \" Intro to Plugin Development\"\nworkshop for Jenkins World 2017, I was impressed by the many Jenkins plugin development videos, tutorials, and guides.\nHere are some of my favorite plugin development topics and links.\n\nPlugin tutorial videos\n\nJenkins Online Meetup Plugin Development Part 1 - Basics - Steven Christou and Jesse Glick\n\nJenkins Online Meetup Plugin Development Part 2 - Web UI - Daniel Beck and Tom Fennelly\n\nWriting your third plugin - Justin Ryan\n\nJenkins Hackathon session at TNG Technology Consulting - Kohsuke Kawaguchi\n\nPlugin tutorial pages\n\nTutorial on jenkins.io\n\nInstall a Java Development kit, for example AdoptOpenJDK 8 or 11\n\nInstall the latest maven release\n\nInstall your IDE (I like Netbeans, has the Jenkins/Stapler plugin to make plugin creation as easy as menu:File[New Project > Maven > Jenkins Plugin])\n\nMore details\n\nMany of the Jenkins plugin development topics have dedicated pages of their own, including user interface, plugin testing, and javadoc.\n\nUser interface\n\nUI samples plugin (bars, boxes, buttons, lists, notification, and syntax highlighting)\n\nUnderstanding Jelly Tags from the Jenkins wiki\n\nForm Validation from the Jenkins wiki\n\nJelly Form Controls from the Jenkins wiki\n\nJelly Tag Library Reference from jenkins.io\n\nDataBoundConstructor in Basic Guide to Jelly usage\n\nDataBoundSetter in google groups\n\nTesting a plugin\n\nUnit test from the Jenkins wiki\n\nJenkins test objects like JenkinsRule and the WithoutJenkins annotation\n\nDataBoundConstructor in Basic Guide to Jelly usage\n\nDataBoundSetter in google groups\n\nJava unit testing tools like Hamcrest and AssertJ (and JenkinsMatchers)\n\nJava unit testing rules like TemporaryFolder, Timeout, and DisableOnDebug\n\nJava unit testing classes like Assume and Parameterized\n\nJava unit testing mock frameworks like mockito and powermock\n\nJavadoc\n\nJenkins core javadoc\n\nJenkins plugins javadoc\n\nExtension Points\n\nList of Jenkins core extension points and all Jenkins extension points\n\nCustom build steps\n\nAdding a custom build step\n\nActions\n\nJenkins Action and its subtypes\n\nMark will be presenting\nIntro to Plugin Development\nat\nJenkins World in August.\nRegister with the code JWFOSS for a 30% discount off your pass.","title":"Plugin Development Tutorials, Videos, and More","tags":["plugins"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#786888","images":{"fallback":{"src":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/60e20/markewaite.jpg","srcSet":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/f4523/markewaite.jpg 32w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/6859a/markewaite.jpg 64w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/60e20/markewaite.jpg 128w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/57001/markewaite.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/1fd06/markewaite.webp 32w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/a7803/markewaite.webp 64w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/1a87d/markewaite.webp 128w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/27a57/markewaite.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":140}},"publicURL":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/markewaite.jpg"},"blog":null,"github":"markewaite","html":"<div class=\"paragraph\">\n<p>Mark is the <a href=\"/project/team-leads/#documentation\">Jenkins Documentation Officer</a>, a long-time Jenkins user and contributor, and maintains the <a href=\"https://plugins.jenkins.io/git\">git plugin</a> and the <a href=\"https://plugins.jenkins.io/git-client\">git client plugin</a>.\nHe is active in <a href=\"/sigs/\">Jenkins special interest groups</a> including the <a href=\"/sigs/docs/\">Docs SIG</a>, <a href=\"/sigs/platform\">Platform SIG</a>, and <a href=\"/sigs/advocacy-and-outreach\">Advocacy SIG</a>.</p>\n</div>","id":"markewaite","irc":"markewaite","linkedin":"markwaite","name":"Mark Waite","slug":"/blog/authors/markewaite/","twitter":"MarkEWaite"}]}},{"node":{"date":"2017-08-07T00:00:00.000Z","id":"7ba8b0b9-e907-55d4-a2a2-ca447df4c528","slug":"/blog/2017/08/07/security-advisory/","strippedHtml":"Multiple Jenkins plugins received updates today that fix several security vulnerabilities, including multiple high severity ones.\n\nWe strongly recommend updating the following plugins as soon as possible:\n\nBlue Ocean\n\nPipeline: Groovy Plugin\n\nScript Security Plugin\n\nLess severe security updates have been released for these plugins:\n\nConfig File Provider Plugin\n\nDatadog Plugin\n\nDeploy to container Plugin\n\nDRY Plugin\n\nPipeline: Input Step Plugin\n\nStatic Analysis Utilities Plugin\n\nAdditionally, the OWASP Dependency-Check Plugin recently also received a security update.\n\nFor an overview of what was fixed, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important future notifications related to Jenkins security.","title":"Important security updates for multiple Jenkins plugins","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck/","twitter":null}]}},{"node":{"date":"2017-08-03T00:00:00.000Z","id":"1ddf93ad-21ef-5f16-9fd5-7a69d3fb97d3","slug":"/blog/2017/08/03/jenkinsworld-ask-the-experts/","strippedHtml":"This is a guest post by Alyssa Tong, who runs\nthe Jenkins Area Meetup program and is also responsible for\nMarketing & Community Programs at CloudBees, Inc.\n\nThere are less than four weeks left until Jenkins World 2017. As usual, Jenkins\nWorld would not be complete without the Jenkins projects' \"Ask the Experts\". If\nyou are new to Jenkins World, the Jenkins project booth will be located on the\nexpo floor where contributors to the project hang out, share demos, and\nhelp users via the \"Ask the Experts\" program. I hope you will be pleasantly\nsurprised at the amount of 1-on-1 learning to be had in the booth!\n\nWe have a great list of experts who have volunteered to help staff the booth,\nincluding many frequent contributors, JAM organizers, and board members:\n\nDaniel Beck - Core, security, Jenkins supporting infra and developer supporting infra, project processes and governance\n\nSteven Christou - Plugins\n\nR. Tyler Croy - Pipeline, Docker,  governance\n\nNicolas De Loof - Docker\n\nJames Dumay - Blue Ocean, Pipeline, Jenkins future\n\nDamien Duportal - Docker, Infra/Virtualization, Provisioning Systems (ansible,chef, etc.), Pipeline\n\nTom Fennelly - Blue Ocean, general frontend stuff, general Jenkins stuff\n\nJesse Glick - Core, Pipeline, security, Jenkins dev infra, Mercurial, …\n\nMichael Hutterman - DevOps\n\nBaptiste Mathus - Governance, infra, Pipeline, HOSTING\n\nMichael Neale - Docker, Blue Ocean\n\nOleg Nenashev - Jenkins core, Jenkins administration, remoting\n\nLiam Newman - Pipeline, Jenkins 2\n\nJames Nord - Maven, plugins\n\nSam Van Oort - Pipeline, performance/scalability, Linux, Docker\n\nChris Orr -  Android development, Jenkins dev infra\n\nCarlos Sanchez - Docker, Mesos, Kubernetes\n\nBobby Sandell - Gerrit, Declarative Pipeline, core\n\nThorsten Scherler - Blue Ocean, front-end\n\nEric Smalling - Docker, config management (Puppet, some Ansible), VMware solutions, running Jenkins at large scale and general enterprise SDLC\n\nOlivier Vernin - Infra, Docker\n\nMark Waite - Git, Git plugin, Git client plugin\n\nOwen Mehegan - GitLab plugin\n\nDon’t have questions? Stop by anyways to say ‘hello’ and pick up some stickers.\n\nIf you are an active member of the Jenkins community and/or a contributor,\nconsider taking part in the \"Ask the Experts\" program. It’s a great opportunity\nto bond with other contributors and talk with fellow Jenkins users.\n\nJoin the Jenkins project at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Ask the Experts at Jenkins World 2017","tags":["event","jenkinsworld"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg","srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/8d248/alyssat.jpg 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/c004c/alyssat.jpg 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/9e67b/alyssat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/22924/alyssat.webp 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/89767/alyssat.webp 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/40d97/alyssat.webp 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/5028e/alyssat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":166}},"publicURL":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/alyssat.jpg"},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"/blog/authors/alyssat/","twitter":null}]}},{"node":{"date":"2017-07-27T00:00:00.000Z","id":"92796c2d-9e8b-530e-82dd-441263269c06","slug":"/blog/2017/07/27/standardizing-builds-with-shared-libraries/","strippedHtml":"This is a guest post by Alvin Huang, DevOps Engineer at\nFireEye.\n\nAs a security company, FireEye relentlessly protects our customers from cyber attacks. To act\nquickly on intelligence and expertise learned, the feedback loop from the front lines to features\nand capabilities in software must be small. Jenkins helps us achieve this by allowing us to build,\ntest, and deploy to our hardware and software platforms faster, so we can stop the bad guys\nbefore they reach our customers.\n\nMore capabilities and functionalities in our product offerings means more applications and\nsystems, which means more software builds and jobs in Jenkins. Within the FaaS (FireEye as a\nService) organization, the tens of Jenkins jobs that were manageable manually in the web GUI\nquickly grew to hundreds of jobs that required more automation. Along the way, we outgrew\nour old legacy datacenter and were tasked with migrating 150+ Freestyle jobs on an old 1.x\nJenkins instance to a newer 2.x instance in the new datacenter in 60 days.\n\nCopying Freestyle job XML configuration files to the new server would leave\ntechnical debt.  Using Freestyle job templates would be better but for\ncomplicated jobs that require multiple templates, this would still create large\ndependency chains that would be hard to trace in the log output. Finally,\ndevelopers were not excited about having to replicate global changes, such as\nadd an email recipient when a new member joins the team, across tens of jobs\nmanually or using the\nConfiguration\nSlicer. We needed a way to migrate the jobs in a timely fashion while getting\nrid of as much technical debt as possible.\n\nJenkins Pipeline to the rescue! In 2.0, Jenkins added the capability to create pipelines as first-\nclass entities. At FireEye, we leveraged many of the features available in pipeline to aid in the\nmigration process including the ability to:\n\ncreate Pipeline as Code in a Jenkinsfile stored in SCM\n\ncreate Jenkins projects automatically when new branches or repos get added with a Jenkinsfile\n\ncontinue jobs after the Jenkins controller or build agent crashes\n\nand most importantly, build a Pipeline\nShared Library that keeps projects\nDRY and\nallows new applications to be on boarded into Jenkins within seconds\n\nHowever, Jenkins Pipeline came with a DSL that our users would have to learn to translate their\nFreestyle jobs to pipeline jobs. This would be a significant undertaking across multiple teams\njust to create Jenkins jobs. Instead, the DevOps team identified similarities across all the\nFreestyle jobs that we were migrating, learned the Jenkins DSL to become SMEs for the\norganization, and built a shared library of functions and wrappers that saved each Dev/QA\nengineer hours of time.\n\nBelow is an example function we created to promote builds in Artifactory:\n\nvars/promoteBuild.groovy\n\ndef call(source_repo, target_repo, build_name, build_number) {\n    stage('Promote to Production repo') {\n        milestone label: 'promote to production'\n        input 'Promote this build to Production?'\n\n        node {\n            Artifactory.server(getArtifactoryServerID()).promote([\n                'buildName'   : build_name,\n                'buildNumber' : build_number,\n                'targetRepo'  : target_repo,\n                'sourceRepo'  : source_repo,\n                'copy'        : true,\n            ])\n    }\n}\n\ndef call(source_repo, target_repo) {\n    buildInfo = getBuildInfo()\n\n    call(source_repo, target_repo, buildInfo.name, buildInfo.number)\n}\n\nRather than learning the Jenkins DSL and looking up how the Artifactory Plugin worked in\nPipeline, users could easily call this function and pass it parameters to do the promotion work\nfor them. In the Shared Library, we can also create build wrappers of opinionated workflows,\nthat encompasses multiple functions, based on a set of parameters defined in the Jenkinsfile.\nIn addition to migrating the jobs, we also had to migrate the build agents. No one knew the\nexact list of packages, versions, and build tools installed on each build server, so rebuilding\nthem would be extremely difficult. Rather than copying the VMs or trying to figure out what\npackages were on the build agents, we opted to use Docker to build containers with all\ndependencies needed for an application.\n\nI hope you will join me at my Jenkins World session:\nCodifying the Build and Release Process with a Jenkins\nPipeline Shared Library, as I deep dive into the inner workings of our Shared\nPipeline Library and explore how we integrated Docker into our CI/CD pipeline.\nCome see how we can turn a Jenkinsfile with just a set of parameters like this:\n\nJenkinsfile\n\nstandardBuild {\n    machine          = 'docker'\n    dev_branch       = 'develop'\n    release_branch   = 'master'\n    artifact_apttern = '*.rpm'\n    html_pattern     = [keepAll: true, reportDir: '.', reportFiles: 'output.html', reportName: 'OutputReport']\n    dev_repo         = 'pipeline-examples-dev'\n    prod_repo        = 'pipeline-examples-prod'\n    pr_script        = 'make prs'\n    dev_script       = 'make dev'\n    release_script   = 'make release'\n}\n\nand a Dockerfile like this:\n\nDockerfile\n\nFROM faas/el7-python:base\n\nRUN yum install -y python-virtualenv \\\n        rpm-build && \\\n        yum clean all\n\nInto a full Jenkins Pipeline like this:\n\nAs we look ahead at FireEye, I will explore how the Shared Library sets us up for easier future\nmigrations of other tools such as Puppet, JIRA, and Artifactory, and easier integration with new\ntools like Openshift. I will also cover our strategies for deployments and plans to move to\nDeclarative Pipeline.\n\nAlvin will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Codifying the Build and Release Process with a Pipeline Shared Library","tags":["event","JenkinsWorld"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/rtyler.jpeg"},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler/","twitter":"agentdero"}]}},{"node":{"date":"2017-07-26T00:00:00.000Z","id":"a5452093-8b55-5ee4-8314-15bc7e02cd41","slug":"/blog/2017/07/26/powershell-pipeline/","strippedHtml":"I am pleased to announce Microsoft PowerShell support for Jenkins Pipeline!\nAs of Durable Task 1.14 and\nPipeline Nodes and Processes Plugin 2.12, you will now be able to run Microsoft PowerShell scripts\ndirectly in your Jenkins Pipeline projects.  This blog post covers the basics\nof getting started with Microsoft PowerShell in Pipeline and provides some\nbasic examples.\n\nIntroduction to Microsoft PowerShell\n\nPowerShell is Microsoft’s open source and cross platform command line shell, as\nwell as an automation and configuration tool/framework which has a broad user\nbase. PowerShell can be used to perform common system administration tasks in\nWindows, macOS, and Linux environments. It can also be used as a general\npurpose scripting language. Now that Jenkins Pipeline supports PowerShell, you\ncan enjoy the rich set of features in PowerShell for your daily DevOps work.\n\nBefore diving into using PowerShell in your Pipeline, I recommend reading the\nWindows\nPowerShell Reference as well as the\nPowerShell Team Blog for an\nintroduction to PowerShell features, utilities, and as a quick look into the\nPowerShell language.  Microsoft also has an active\nPowerShell community on GitHub,\nwhich I highly recommend visiting to submit feature requests and bug\nreports as you see fit. Jenkins Pipeline currently supports Microsoft\nPowerShell 3.0 or higher, so also be sure to check which version of PowerShell\nis installed on your system in order to take advantage of PowerShell in your\nPipeline.  Please note that we recommend that you upgrade to the latest stable\nversion of PowerShell available, which as of this writing is version 5.1.14393.\n\nThe powershell step\n\nnode {\n    powershell 'Write-Output \"Hello, World!\"'\n}\n\nUsing Microsoft PowerShell in Pipeline\n\nWriting PowerShell code as part of your pipeline is incredibly simple. The step that you will use is\nsimply powershell, and it includes the same optional parameters as the\nWindows Batch ( bat) step, including:\n\nreturnStdout: Returns the standard output stream with a default encoding of UTF-8 (alternative encoding is optional)\n\nreturnStatus: Returns the exit status (integer) of the PowerShell script\n\nExamples\n\nCapture exit status of a PowerShell script\n\nnode {\n    def status = powershell(returnStatus: true, script: 'ipconfig')\n    if (status == 0) {\n        // Success!\n    }\n}\n\nCapture and print the output of a PowerShell script\n\nnode {\n    def msg = powershell(returnStdout: true, script: 'Write-Output \"PowerShell is mighty!\"')\n    println msg\n}\n\nWhich streams get returned when I use returnStdout?\n\nUntil the release of PowerShell 5, there were five distinct output streams. PowerShell 5 introduced a sixth stream for pushing \"informational\" content,\nwith the added benefit of being able to capture messages sent to Write-Host. Each row of the following table describes a PowerShell stream along with\nthe corresponding Cmdlet used for writing to the stream for that particular row. Please keep in mind that stream 6 and associated cmdlets either\ndo not exist or exhibit alternate behavior in versions of PowerShell earlier than version 5.\n\nStream\nDescription\nCmdlet\n\n1\nOutput stream (e.g. stdOut)\nWrite-Output\n\n2\nError stream (e.g. stdErr)\nWrite-Error\n\n3\nWarning stream\nWrite-Warning\n\n4\nVerbose stream\nWrite-Verbose\n\n5\nDebug stream\nWrite-Debug\n\n6\nInformation stream\nWrite-Information (or Write-Host with caveats)\n\nIf you are using the returnStdout option of the powershell Pipeline step\nthen only stream 1 will be returned, while streams 2-6 will be redirected to\nthe console output. For example:\n\nWrite to all available streams and return the standard output\n\nnode {\n    def stdout = powershell(returnStdout: true, script: '''\n        # Enable streams 3-6\n        $WarningPreference = 'Continue'\n        $VerbosePreference = 'Continue'\n        $DebugPreference = 'Continue'\n        $InformationPreference = 'Continue'\n\n        Write-Output 'Hello, World!'\n        Write-Error 'Something terrible has happened!'\n        Write-Warning 'Warning! There is nothing wrong with your television set'\n        Write-Verbose 'Do not attempt to adjust the picture'\n        Write-Debug 'We will control the horizontal.  We will control the vertical'\n        Write-Information 'We can change the focus to a soft blur or sharpen it to crystal clarity.'\n    ''')\n    println stdout\n}\n\nConsole output:\n\n[Pipeline] {\n[Pipeline] powershell\n[TestStreams] Running PowerShell script\n\\workspace\\TestStreams@tmp\\durable-4d924c2d\\powershellScript.ps1 : Something terrible has\nhappened!\nAt \\workspace\\TestStreams@tmp\\durable-4d924c2d\\powershellMain.ps1:2 char:1\n+ & ' \\workspace\\TestStreams@tmp\\durable-4d924c ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : NotSpecified: (:) [Write-Error], WriteErrorException\n    + FullyQualifiedErrorId : Microsoft.PowerShell.Commands.WriteErrorException,powershellScript.ps1\n\nWarning! There is nothing wrong with your television set\nDo not attempt to adjust the picture\nWe will control the horizontal.  We will control the vertical\nWe can change the focus to a soft blur or sharpen it to crystal clarity.\nHello, World!\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] End of Pipeline\nERROR: script returned exit code 1\nFinished: FAILURE\n\nNote that \"Hello, World!\" gets printed last even though it is the first output\nstatement in my script.  Another interesting aspect of this example is that the\npowershell step failed, which ultimately caused the job to fail. The failure\nin this example is due to the PowerShell error stream being non-empty, which\ntherefore caused the step to result in a non-zero exit status. However, as you\nwill soon discover, there are a variety of causes for a failing powershell\nstep.\n\nWhat causes a failing exit status?\n\nWhen you execute a powershell step, it may produce a non-zero exit code and\nfail your pipeline build.  This is very similar to other shell steps with some\ninteresting caveats. Your powershell step may produce a failing exit status\nin the following instances:\n\nSomething in your PowerShell script has thrown an exception\n\nYour PowerShell script explicitly calls exit with a non-zero exit code\n\nYour PowerShell script calls a native application that produces a non-zero $LastExitCode\n\n$LastExitCode is an automatic variable that is set after executing a native application\n\nYour PowerShell script results in a non-empty error stream (with or without throwing an exception)\n\nOverriding the exit status behavior of your powershell step can be achieved\nby explicitly exiting from your script as long as the failure was not caused by\nan unhandled exception. For example:\n\nUnavoidable failure caused by an unhandled exception\n\nnode {\n    powershell '''\n        throw 'Error! Problem Exists Between Keyboard And Chair'\n        exit 0  # Unreachable code\n    '''\n}\n\nFailed step caused by a non-empty error stream\n\nnode {\n    powershell '''\n        Write-Error 'Error! Problem Exists Between Keyboard And Chair'\n    '''\n}\n\nFailure prevented by an explicit exit\n\nnode {\n    powershell '''\n        Write-Error 'Error! Problem Exists Between Keyboard And Chair'\n        exit 0\n    '''\n}\n\nScripts vs. Cmdlets\n\nA Cmdlet is a small lightweight utility written in either C#, and compiled, or\nwritten in PowerShell directly. Depending on what your goal is in your pipeline\nyou can make use of Cmdlets directly in your pipeline code, call a self\ncontained PowerShell script, or some mixture of the two. If your strategy is to\nkeep each powershell step as short and succinct as possible then it may make\nsense for you to write a library of Cmdlets, but if you have monolithic scripts\nthen it may make sense for you to call those scripts directly from your\npipeline. The choice is entirely up to you, as both scenarios are supported.\n\nThanks for reading, and have fun!\n\nI sincerely hope that this post has encouraged you to try using PowerShell in\nyour Jenkins Pipeline. Please do not hesitate to file an issue against the\ndurable-task\nplugin on\nJIRA\nif you have discovered any problem that you suspect is related to the\npowershell step.  For general PowerShell related issues or inquiries\nplease route your questions to the\nPowerShell community.","title":"Microsoft PowerShell Support for Pipeline","tags":["durable-task","powershell"],"authors":[{"avatar":null,"blog":null,"github":"gabloe","html":"","id":"gabloe","irc":null,"linkedin":null,"name":"Gabriel Loewen","slug":"/blog/authors/gabloe/","twitter":null}]}},{"node":{"date":"2017-07-21T00:00:00.000Z","id":"215b578b-be74-5ce1-b9f3-38b9bfc35f5c","slug":"/blog/2017/07/21/scaling-jenkins-with-kubernetes-on-google-container-engine/","strippedHtml":"This is a guest post by Guillaume Laforge,\nDeveloper Advocate for Google Cloud\n\nLast week, I had the pleasure to speak at the\nJenkins Community Day conference, in Paris,\norganized by my friends from JFrog,\nprovider of awesome tools for software management and distribution.\nI covered how to scale Jenkins with Kubernetes on\nGoogle Container Engine.\n\nFor the impatient, here are the slides of the presentation I’ve given:\n\nBut let’s step back a little. In this article, I’d like to share with you why you would want to run Jenkins in the cloud,\nas well as give you some pointers to interesting resources on the topic.\n\nWhy running Jenkins in the cloud?\n\nSo why running Jenkins in the cloud? First of all, imagine your small team, working on a single project.\nYou have your own little server, running under a desk somewhere, happily building your application on each commit,\na few times a day. So far so good, your build machine running Jenkins isn’t too busy, and stays idle most of the day.\n\nLet’s do some bottom of the napkin calculations. Let’s say you have a team of 3 developers,\ncommitting roughly 4 times a day, on one single project, and the build takes roughly 10 minutes to go.\n\n3 developers * 4 commits / day / developer * 10 minutes build time * 1 project = 1 hour 20 minutes\n\nSo far so good, your server indeed stays idle most of the day. Usually, at most,\nyour developers will wait just 10 minutes to see the result of their work.\n\nBut your team is growing to 10 persons, the team is still as productive, but the project becoming bigger,\nthe build time goes up to 15 minutes:\n\n10 developers * 4 commits / day / developer * 15 minutes build time * 1 project = 10 hours\n\nYou’re already at 10 hours build time, so your server is busy the whole day, and at times,\nyou might have several build going on at the same time, using several CPU cores in parallel.\nAnd instead of building in 15 minutes, sometimes, the build might take longer, or your build might be queued.\nSo in theory, it might be 15 minutes, but in practice, it could be half an hour because of the length of the queue\nor the longer time to build parallel projects.\n\nNow, the company is successful, and has two projects instead of one (think a backend and a mobile app).\nYour teams grow further up to 20 developers per project. The developers are a little less productive\nbecause of the size of the codebase and project, so they only commit 3 times a day.\nThe build takes more time too, at 20 minutes (in ideal time). Let’s do some math again:\n\n20 developers * 3 commits / day / developer * 20 minutes build time * 2 projects = 40 hours\n\nWoh, that’s already 40 hours of total build time, if all the builds are run serially.\nFortunately, our server is multi-core, but still, there are certainly already many builds that are enqueued,\nand many of them, perhaps up to 2-3 or perhaps even 4 could be run in parallel.\nBut as we said, the build queue increases further, the real effective time of build is certainly longer than 30 minutes.\nPerhaps at times, developers won’t see the result of their developments before at least an hour, if not more.\n\nOne last calculation? With team sizes of 30 developers, decreased productivity of 2 commits, 25 build time,\nand 3 projects? And you’ll get 75 hours total build time. You may start creating a little build farm,\nwith a controller and several build agents. But you also increase the burden of server management.\nAlso, if you move towards a full Continuous Delivery or Continuous Deployment approach,\nyou may further increase your build times to go up to deployment, make more but smaller commits, etc.\nYou could think of running builds less often, or even on a nightly basis, to cope with the demand, but then,\nyour company is less agile, and the time-to-market for fixes of new features might increase,\nand your developers may also become more frustrated because they are developing in the blind,\nnot knowing before the next day if their work was successful or not.\n\nWith my calculations, you might think that it makes more sense for big companies, with tons of projects and developers.\nThis is quite true, but when you’re a startup, you also want to avoid taking care of local server management,\nprovisioning, etc. You want to be agile, and use only compute resources you need for the time you need them.\nSo even if you’re a small startup, a small team, it might still make sense to take advantage of the cloud.\nYou pay only for the actual time taken by your builds as the build agent containers are automatically provisioned\nand decommissioned. The builds can scale up via Kubernetes, as you need more (or less) CPU time for building everything.\n\nAnd this is why I was happy to dive into scaling Jenkins in the cloud. For that purpose,\nI decided to go with building with containers, with Kubernetes, as my app was also containerized as well.\nGoogle Cloud offers Container Engine, which is basically just Kubernetes in the cloud.\n\nUseful pointers\n\nI based my presentation and demo on some great solutions that are published on the Google Cloud documentation portal.\nLet me give you some pointers.\n\nOverview of Jenkins on Container Engine\n\nSetting up Jenkins on Container Engine\n\nConfiguring Jenkins for Container Engine\n\nContinuous Deployment to Container Engine using Jenkins\n\nLab: Build a Continuous Deployment Pipeline with Jenkins and Kubernetes\n\nThe latter one is the tutorial I actually followed for the demo that I presented during the conference.\nIt’s a simple Go application, with a frontend and backend.\nIt’s continuously build, on each commit (well, every minute to check if there’s a new commit),\nand deployed automatically in different environments: dev, canary, production.\nThe sources of the project are stored in Cloud Source Repository (it can be mirrored from Github, for example).\nThe containers are stored in Cloud Container Registry.\nAnd both the Jenkins controller and agents, as well as the application are running inside Kubernetes clusters in Container Engine.\n\nSummary and perspective\n\nDon’t bother with managing servers! Quickly, you’ll run out of CPU cycles,\nand you’ll have happier developers with builds that are super snappy!\n\nAnd for the record, at Google, dev teams are also running Jenkins!\nThere was a presentation ( video and\nslides\navailable) given last year by David Hoover at Jenkins World\ntalking about how developers inside Google are running hundreds of build agents to build projects on various platforms.","title":"Scaling Jenkins with Kubernetes on Google Container Engine","tags":["jenkins","kubernetes","jenkins-community-day-paris"],"authors":[{"avatar":null,"blog":"https://glaforge.appspot.com/","github":"glaforge","html":"","id":"glaforge","irc":null,"linkedin":null,"name":"Guillaume Laforge","slug":"/blog/authors/glaforge/","twitter":"glaforge"}]}},{"node":{"date":"2017-07-17T00:00:00.000Z","id":"0116e3f0-03af-5f1b-b064-5d44aaf60398","slug":"/blog/2017/07/17/speaker-blog-care/","strippedHtml":"This is a guest post by Mandy Hubbard, Software Engineer/QA Architect at\nCare.com.\n\nImagine this: It’s 4:30pm on a Friday,\nyou have a major release on Monday, and your Jenkins server goes down.\nIt doesn’t matter if it experienced a hardware failure,\nfell victim to a catastrophic\nfat-finger error,\nor just got hit by a meteor - your Jenkins server is toast.\nHow long did it take to perfect your Pipeline,\nall your Continuous Delivery jobs, plugins, and credentials?\nHopefully you at least have a recent backup of your Jenkins home directory,\nbut you’re still going have to work over the weekend with IT to procure a new server,\ninstall it, and do full regression testing to be up and running by Monday morning.\nGo ahead and take a moment, go to your car and just scream.\nIt will help …​ a little.\n\nBut what if you could have a Jenkins environment that is completely disposable,\none that could be easily rebuilt at any time?\nUsing Docker and Joyent’s\nContainerPilot, the team at\nCare.com HomePay\nhas created a production Jenkins environment that is completely software-defined.\nEverything required to set up a new Jenkins environment is stored in source control,\nversioned, and released just like any other software.\nAt Jenkins World, I’ll do a developer deep-dive into this approach during my technical session,\nIndispensable, Disposable Jenkins,\nincluding a demo of bringing up a fully configured Jenkins server in a Docker container.\nFor now, let me give you a basic outline of what we’ve done.\n\nMandy will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.\n\nFirst, we add ContainerPilot to our Jenkins image by including it in the Dockerfile.\n\nDockerfile\n\n## ContainerPilot\n\nENV CONTAINERPILOT_VERSION 2.7.0\nENV CONTAINERPILOT_SHA256 3cf91aabd3d3651613942d65359be9af0f6a25a1df9ec9bd9ea94d980724ee13\nENV CONTAINERPILOT file:///etc/containerpilot/containerpilot.json\n\nRUN curl -Lso /tmp/containerpilot.tar.gz https://github.com/joyent/containerpilot/releases/download/${CONTAINERPILOT_VERSION}/containerpilot-${CONTAINERPILOT_VERSION}.tar.gz && \\\n    echo \"${CONTAINERPILOT_SHA256}  /tmp/containerpilot.tar.gz\" | sha256sum -c && \\\n    tar zxf /tmp/containerpilot.tar.gz -C /bin && \\\nrm /tmp/containerpilot.tar.gz\n\nThen we specify containerpilot as the Docker command in the docker-compose.yml\nand pass the Jenkins startup script as an argument.\nThis allows ContainerPilot to perform our preStart business before starting the Jenkins server.\n\ndocker-compose.yml\n\njenkins:\n    image: devmandy/auto-jenkins:latest\n    restart: always\n    mem_limit: 8g\n    ports:\n      - 80\n      - 22\n    dns:\n      - 8.8.8.8\n      - 127.0.0.1\n    env_file: _env\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - CONSUL=consul\n    links:\n      - consul:consul\n    ports:\n      - \"8080:80\"\n      - \"2222:22\"\n    command: >\n      containerpilot\n      /usr/local/bin/jenkins.sh\n\nConfiguration data is read from a Docker Compose _env file,\nas specified in the docker-compose.yml file,\nand stored in environment variables inside the container.\nThis is an example of our _env file:\n\n_env\n\nGITHUB_TOKEN=\nGITHUB_USERNAME=DevMandy\nGITHUB_ORGANIZATION=DevMandy\nDOCKERHUB_ORGANIZATION=DevMandy\nDOCKERHUB_USERNAME=DevMandy\nDOCKERHUB_PASSWORD=\nDOCKER_HOST=\nSLACK_TEAM_DOMAIN=DevMandy\nSLACK_CHANNEL=jenkinsbuilds\nSLACK_TOKEN=\nBASIC_AUTH=\nAD_NAME=\nAD_SERVER=\nPRIVATE_KEY=\n\nJenkins stores its credentials and plugin information in various xml files.\nThe preStart script modifies the relevant files,\nsubstituting the environment variables as appropriate,\nusing a set of command line utilities called xmlstarlet.\nHere is an example method from our preStart script that configures Github credentials:\n\ngithub_credentials_setup() {\n    ## Setting Up Github username in credentials.xml file\n    echo\n    echo -e \"Adding Github username to credentials.xml file for SSH key\"\n    xmlstarlet \\\n        ed \\\n        --inplace \\\n        -u '//com.cloudbees.jenkins.plugins.sshcredentials.impl.BasicSSHUserPrivateKey[id=\"github\"]/username' \\\n        -v ${GITHUB_USERNAME} \\\n        ${JENKINS_HOME}/credentials.xml\n\n    echo -e \"Adding Github username to credentials.xml file for Github token\"\n    xmlstarlet \\\n        ed \\\n         --inplace \\\n        -u '//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=\"github_token\"]/username' \\\n        -v ${GITHUB_USERNAME} \\\n        ${JENKINS_HOME}/credentials.xml\n\n    PASSWORD=${GITHUB_TOKEN}\n    echo -e \"Adding Github token to credentials.xml\"\n    xmlstarlet \\\n        ed \\\n        --inplace \\\n        -u '//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=\"github_token\"]/password' \\\n        -v ${PASSWORD} \\\n        ${JENKINS_HOME}/credentials.xml\n}\n\nThis approach can be used to automate all things Jenkins.\nThese are just a few of the things I’ll show you in my Jenkins World session,\nwhich you can build on to automate anything else your Jenkins environment needs.\n\nCreation of credentials sets for interacting with third party services\nlike Github, Docker Hub and Slack\n\nConfiguration of the Active Directory plugin\nand setup of matrix-based security\n\nConfiguration of the Github Organization plugin,\nwhich results in the automatic creation of all Jenkins pipeline jobs\nby scanning the organization for all repositories containing a Jenkinsfile\n\nConfiguration of the\nDocker Pipeline plugin, including creating templates for all custom build agents\n\nConfiguration of the Global Pipeline Libraries plugin\n\nConfiguration of the Slack Notifier plugin\n\nWith software-defined Jenkins, pipeline infrastructure\ngains the same flexibility and resiliency as the rest of the development pipeline.\nIf we decide to change our Jenkins configuration in any way –\nfor example installing a new plugin or upgrading an existing one,\nadding a new global library, or adding new Docker images for build agents –\nwe simply edit our preStart script to include these changes, build a new Docker image,\nand the Jenkins environment is automatically reconfigured when we start a new container.\nBecause the entire configuration specification lives in a Github repository,\nchanges are merged to the \"master\" branch using pull requests,\nand our Jenkins Docker image is tagged using\nsemantic versioning just like any other component.\nJenkins can be both indispensable and completely disposable at the same time.","title":"Indispensable, Disposable Jenkins","tags":["event","JenkinsWorld"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"","id":"hinman","irc":null,"linkedin":null,"name":"Hannah Inman","slug":"/blog/authors/hinman/","twitter":null}]}}]}},"pageContext":{"limit":8,"skip":280,"numPages":100,"currentPage":36}},
    "staticQueryHashes": ["3649515864"]}