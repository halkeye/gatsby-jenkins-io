{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/25",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-08-23T00:00:00.000Z","id":"409d4d90-3aa4-5eba-ac07-97d9486bc294","slug":"/blog/2018/08/23/speaker-blog-casc-part-1/","strippedHtml":"This blog post is part 1 of a Configuration-as-Code series\n\nJenkins is highly flexible and is today the de facto standard for implementing CI/CD, with an active community to maintain plugins for almost any combination of tools and use-cases.\nBut flexibility has a cost: in addition to Jenkins core, many plugins require some system-level configuration to be set so they can do their job.\n\nIn some circumstances, \"Jenkins Administrator\" is a full time position.\nOne person is responsible for both maintaining the infrastructure, and also pampering a huge Jenkins controller with hundred installed plugins and thousands hosted jobs.\nMaintaining up-to-date plugin versions is a challenge and failover is a nightmare.\n\nThis is like years ago when system administrators had to manage dedicated machines per service.\nIn 2018, everything is managed as code using infrastructure automation tools and virtualization.\nNeed a fresh new application server as staging environment for your application? Just deploy a Docker container.\nInfrastructure is missing resources? Apply a Terraform recipe to allocate more on your favourite Cloud.\n\nWhat about the Jenkins administrator role in this context? Should they still spend hours in the web UI, clicking checkboxes on web forms? Maybe they already adopted some automation, relying on Groovy script voodoo, or some home-made XML templating?\n\nEarly this year we announced the first alpha release of “Jenkins Configuration-as-Code” (JCasC), a fresh new approach to Jenkins configuration management, based on YAML configuration files and automatic model discovery.\n“JCasC” has been promoted as a\ntop-level Jenkins project, and the corresponding\nJenkins Enhancement Proposal has been accepted.\n\nWhat can JCasC do for our Jenkins Administrator?\n\nJCasC allows us to apply a set of YAML files on our Jenkins controller at startup or on-demand via the web UI.\nThose configuration files are very concise and human readable compared to verbose XML files the Jenkins uses to actually store configuration.\nThe files also have user-friendly naming conventions making it easy for administrators to configure all Jenkins components.\n\nHere’s an example:\n\njenkins:\n systemMessage: \"Jenkins managed by Configuration as Code\"\n\n securityRealm:\n   ldap:\n     configurations:\n       - server: ldap.acme.com\n         rootDN: dc=acme,dc=fr\n         managerPasswordSecret: ${LDAP_PASSWORD}\n     cache:\n       size: 100\n       ttl: 10\n     userIdStrategy: CaseInsensitive\n     groupIdStrategy: CaseSensitive\n\nAs you can see, you don’t need long explanation to understand how this YAML file will setup your Jenkins controller.\n\nBenefits\n\nThe most immediate benefit of JCasC is reproducibility.\nAn administrator can now bootstrap a new Jenkins controller with the exact same configuration with a trivial setup.\nThis allows them to create a test instance and check the impact of plugin upgrades in a sandboxed environment.\nThis also lets them be more confident with failover and disaster recovery scenarios.\n\nFurther benefits come when administrators start managing their Jenkins’ YAML configuration files in source control, like they do with Terraform configuration.\nDoing so gives them auditing and reversibility of their Jenkins controller configuration.\nTheycan establish a sane configuration change workflow that runs a test Jenkins instance and ensures configuration is healthy before actually applying any change to their production Jenkins controller.\n\nLast but not least, with ability to quickly setup Jenkins controllers and control them from a set of shared YAML configuration files, administrators can now offer per-team Jenkins instances, with more flexibility on installed plugins.\nA controller becomes more or less a transient piece of infrastructure for your team, as long as they also manage build definition with Jenkinsfiles.\n\nWith Configuration-as-Code we can stop having to treat our Jenkins controller like a pet we need to pamper, and start managing Jenkins controllers as cattle you can replace without effort nor impacts.\nWelcome in the “as-code” world.\n\nFigure 1. They are still cute though, right?\n\nOk, so what’s next?\n\nYou can read more about the Jenkins Configuration-as-Code plugin on the project’s\ngithub repository.\nTo chat with the community and contributors join our\ngitter channel,\nor come see us in person at\nlink: Jenkins World to discuss the JCasC project and its future!\n\nAlso don’t miss next post from the Configuration-as-Code series, where we’ll look at how JCasC works with sensitive data like passwords and other credentials.\n\nCome meet the Configuration as Code contributors, Nicolas de Loof and Ewelina Wilkosz at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins Configuration-as-Code: Look ma, no hands","tags":["configuration-as-code","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":null,"blog":null,"github":"ndeloof","html":"","id":"ndeloof","irc":null,"linkedin":null,"name":"Nicolas De Loof","slug":"/blog/author/ndeloof","twitter":null}]}},{"node":{"date":"2018-08-21T00:00:00.000Z","id":"814e4630-7e61-5840-9cbd-22628b628bfe","slug":"/blog/2018/08/21/contributor-summit-nice/","strippedHtml":"The Jenkins Contributor summit is where the current and future contributors of the Jenkins project get together.\nThis summit will be on Tuesday, October 23rd 2018 in Nice, France just before Jenkins World.\nThe summit brings together community members to learn, meet and help shape the future of Jenkins.\nIn the Jenkins commmunity we value all types and sizes of contributions and love to welcome new participants.\nIt is free to join, just register here.\n\nTopics\n\nThere are plenty of exciting developments happening in the Jenkins community.\nThe summit will feature a 'State of the Project' update including updates from the Jenkins officers.\nWe will also have updates on the 'Big 5' projects in active development:\n\nJenkins Evergreen\n\nJenkins X\n\nConfiguration as Code\n\nJenkins Pipeline\n\nCloud Native Jenkins\n\nPlus we will feature a Google Summer of Code update, Special Interest Group updates and more!\n\nAgenda\n\nThe agenda is shaping up well and here is the outline so far.\n\n9:00am Kickoff & Welcome with coffee/pastries\n\n10:00am Project Updates\n\n12:00pm Lunch\n\n1.00pm BoF/Unconference\n\n3.00pm Break\n\n3.30pm Ignite Talks\n\n5.00pm Wrap-up\n\n6.00pm Contributor Dinner\n\nThe BoF (birds-of-a-feather) session will be an opportunity for in depth discussions, hacking or learning more about any of the big 5.\nBring your laptop, come prepared with questions and ideas, and be ready for some hacking too if you want.\nJoin in, hear the latest and get involved in any project during the BoF sessions.\nIf you want to share anything there will be an opportunity to do a 5-min ignite talk at the end.\nAttending is free, and no DevOps World | Jenkins World ticket is needed, but RSVP if you are going to attend to help us plan.\nSee you there!","title":"Join us at the Jenkins Contributor Summit Nice, Tuesday 23 October 2018","tags":["community","events","jenkins-world"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg","srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/6105b/tracymiranda.jpg 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/9d80c/tracymiranda.jpg 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a5e1e/tracymiranda.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a4758/tracymiranda.webp 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fec68/tracymiranda.webp 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fe590/tracymiranda.webp 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/c2c8e/tracymiranda.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":116}}},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"/blog/author/tracymiranda","twitter":"tracymiranda"}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"003e40e9-a1b3-5859-a18a-60017d86c651","slug":"/blog/2018/08/17/speaker-blog-brent-laster/","strippedHtml":"More and more today, continuous delivery (CD) pipelines are making use of containers.\nIn many implementations, the primary workflow/orchestration tool for CD pipelines is Jenkins.\nAnd the primary container orchestration tool is Docker.\nTogether these two applications provide a powerful, yet simple to understand and use, model for leveraging containers in your CD pipeline.\n\nWhen creating a pipeline script in Jenkins, there are multiple ways to incorporate Docker into your CD pipeline.\nThey include:\n\nManually running a predefined Docker image as a separate Jenkins agent\n\nAutomatically provisioning a Docker image, when needed, as a part of a “cloud” configuration\n\nReferencing a “docker” global variable that can be invoked via the Jenkins DSL\n\nCalling the Docker executable directly via a shell call in the Jenkins DSL\n\nFor this article, we’ll focus on the third item in this list given that it provides the most flexibility and convenience for Docker use in the pipeline.\nMore details on the other three can be found in the upcoming “Continuous Delivery and Containerization” workshop at Jenkins World/DevOps World 2018.\n\nFirst, we’ll provide some background on a couple of terms for those who may not be familiar with Jenkins 2.\nIf you already are familiar with it, feel free to skip ahead to the Global Variables section.\n\nBackground\n\nWhen we talk about Jenkins here, we’re referring to “Jenkins 2” - a name we use to generally refer to the 2.0 and beyond versions of Jenkins.\nJenkins 2 offers a powerful evolution of Jenkins over prior versions.\nIn particular, it provides full integration for “pipeline-as-code” (PAC).\nPAC refers to being able to write your pipeline in a scripting language, much like source code for any program.\nThe code you write becomes the program that defines your pipeline.\nIt is also the code that gets executed when your pipeline is initiated.\nListing 1 shows a simple example pipeline.\nNotice that this is very different from the classic way of creating pipelines in Jenkins.\nHere you are writing code - rather than the more traditional approaches, such as filling in web forms to configure a Freestyle job.\n\n// Scripted Pipeline //\nnode('worker') {\n    stage('Source') { // Get code\n        // Get code from our git repository\n        git 'git@diyvb2:/home/git/repositories/workshop.git'\n    }\n    stage('Compile') { // Compile and do unit testing\n        // Run gradle to execute compile and unit testing\n        sh \"gradle clean compileJava test\"\n    }\n}\n// Declarative //\n\nListing 1: Example Jenkins 2 pipeline\n\nThe language that we write the Jenkins pipeline code in is a Domain-Specific Language (DSL).\nYou can think of it as the “programming language” for Jenkins pipelines.\nThere are two variants of it.\nThe style we saw in figure 1 is called “scripted syntax”.\nIt is a mixture of elements from the Groovy programming language and special Jenkins “steps”.\nThe Jenkins steps are provided by the plugins that are installed in the current system.\nA built-in tool called the Snippet Generator provides a wizard interface to allow users to pick the step and options they want.\nThen, the user can click on a button to have Jenkins automatically generate the correct DSL code in the large text box (figure 1).\nThe DSL code can be copied from there and pasted into the pipeline script.\n\nFigure 1. The Snippet Generator\n\nA second type of syntax is called “declarative syntax.”  We won’t go into detail on it here.\nBut it is a much more structured syntax that focuses on having users declare what they want in a pipeline, rather than writing the logic to make it happen.\n\nGlobal Variables\n\nIn addition to the steps that are provided by plugins, additional functionality for pipelines can be provided by global variables.\nThe simplest way to think of a global variable is as an object with methods that can be invoked on it.\nSeveral of these are built in to Jenkins, such as the Docker global variable.\nOthers can be created by users as part of the structure of a shared source code repository called a “shared pipeline library.”\n\nTo get a list of the global variables that are currently available to your Jenkins instance, you can go to the Snippet Generator screen.\nImmediately below the box for the generated pipeline script is a section titled Global Variables.\nThere, within the small print, is a link to get to the actual section (figure 2).\n\nFigure 2. Link to Global Variables Reference section.\n\nClicking on that link takes us to a list of currently available Global Variables.\nIf you have the Docker Pipeline Plugin installed, you will see one at the top for Docker. (Figure 3).\n\nFigure 3. Docker global variable specifics.\n\nBroadly, the docker global variable includes methods that can be applied to the Docker application, Docker images, and Docker containers.\n\nWe’ll focus first on a couple of the Docker image methods as shown in figure 4.\n\nFigure 4. Key methods for getting a Docker image.\n\nThere are multiple ways you can use these methods to create a new image.\nListing 2 shows a basic example of assigning and pulling an image using the image method.\n\nmyImage = docker.image(\"bclaster/jenkins-node:1.0\")\nmyImage.pull()\n\nListing 2: Assigning a image to a variable and pulling it down.\n\nThis can also be done in a single statement as shown in listing 3.\n\ndocker.image(\"bclaster/jenkins-node:1.0\").pull()\n\nListing 3: Shorthand version of previous call.\n\nYou can also download a Dockerfile and build an image based on it.(See listing 4.)\n\nnode() {\n    def myImg\n    stage (\"Build image\") {\n        // download the dockerfile to build from\n        git 'git@diyvb:repos/dockerResources.git'\n\n        // build our docker image\n        myImg = docker.build 'my-image:snapshot'\n    }\n}\n\nListing 4: Pipeline code to download a Dockerfile and build an image from it.\n\nFigure 5 shows the actual output from running that “Build image” stage.\nNote that the docker.build step was translated into an actual Docker build command.\n\nFigure 5. Actual Docker output from running the download and build\n\nThe Inside Command\n\nAnother powerful method available for the Docker global variable is the inside method.\nWhen executed, this method will do the following:\n\nGet an agent and a workspace to execute on\n\nIf the Docker image is not already present, pull it down\n\nStart the container with that image\n\nMount the workspace from Jenkins\n\nExecute the build steps\n\nMounting the workspace means that the Jenkins workspace will appear as a volume inside the container.\nAnd it will have the same file path.\nSo, things running in the container will have direct access to the same location.\nHowever, this can only be done if the container is running on the same underlying system - such that it can directly access the path.\n\nIn terms of executing the build steps, the inside method acts as a scoping method.\nThis means that the environment it sets up is in effect for any statement that happens within its scope (within the block under it bounded by {}).\nThe practical application here is that any pipeline “sh” steps (a call to the shell to execute something) are automatically run in the container.\nBehind the scenes, this is done by wrapping the calls with “docker exec”.\n\nWhen executed, the calls with the global variable are translated (by Jenkins) into actual Docker call invocations.\nListing 5 shows an example of using this in a script, along with the output from the first invocation of the “inside” method.\nYou can see in the output the docker commands that are generated from the inside method call.\n\nstage (\"Get Source\") {\n        // run a command to get the source code download\n        myImg.inside('-v /home/git/repos:/home/git/repos') {\n            sh \"rm -rf gradle-greetings\"\n            sh \"git clone --branch test /home/git/repos/gradle-greetings.git\"\n        }\n    }\n    stage (\"Run Build\") {\n        myImg.inside() {\n            sh \"cd gradle-greetings && gradle -g /tmp clean build -x test\"\n        }\n    }\n\nListing 5: Example inside method usage.\n\nFigure 6. Example inside method Docker command output.\n\nOnce completed, the inside step will stop the container,\nget rid of the storage, and create a record that this image was used for the build.\nThat record facilitates image traceability, updates, etc.\n\nAs you can see, the combination of using the Docker “global variable” and its “inside” method provide a simple and powerful way to spin up and work with containers in your pipeline.\nIn addition, since you are not having to make the direct Docker calls, you can invoke steps like sh within the scope of the inside method, and have them executed by Docker transparently.\n\nAs we mentioned, this is only one of several ways you can interact with Docker in your pipeline code.\nTo learn about the other methods and get hands-on practice, join me at DevOps World/Jenkins World in San Francisco or Nice for the workshop\n\" Creating a Deployment Pipeline with Jenkins 2\".\nHope to see you there!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Using the Docker Global Variable in Your Jenkins Pipeline","tags":["event","jenkinsworld","jenkinsworld2018","pipeline","docker"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg","srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/77b35/brentlaster.jpg 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/d4a57/brentlaster.jpg 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/68974/brentlaster.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/ef6ff/brentlaster.webp 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/8257c/brentlaster.webp 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/6766a/brentlaster.webp 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/22bfc/brentlaster.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"brentlaster","html":"<div class=\"paragraph\">\n<p>Brent Laster is a Senior Manager in the Research and Development division at SAS in Cary, North Carolina. He manages several groups involved with release engineering processes, best practices, and tooling. He also serves as a resource for the use of open-source technologies and conducts internal training classes in technologies such as Git, Gerrit, Gradle, and Jenkins, both in the U.S. and abroad.</p>\n</div>\n<div class=\"paragraph\">\n<p>Brent Laster is the author of \"Professional Git\"\n(a comprehensive guide to Git for users ranging from beginners to advanced)\nand \"Jenkins 2 – Up and Running:  Evolve Your Pipeline for Next-Generation Automation\".</p>\n</div>","id":"brentlaster","irc":null,"linkedin":null,"name":"Brent Laster","slug":"/blog/author/brentlaster","twitter":"brentclaster"}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"e4121dfc-f5a5-57b7-b1e0-733189f8140a","slug":"/blog/2018/08/17/code-coverage-api-plugin-1.0-release/","strippedHtml":"I am happy to announce availability of Code Coverage API. These plugins have been recently released as 1.0, and they are now available in the Jenkins Update Center. In this blogpost I will introduce the features and project structure of Code Coverage API plugin.\n\nMy name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.\n\nOverview\n\nCode Coverage API plugin is one of GSoC 2018 Jenkins projects.\n\nThere are a lot of plugins which currently implement code coverage; however, they all use similar config, charts, and content. So it would be much better if we could have an API plugin which does the most repeated work for those plugins and offers a unified API which can be consumed by other plugins and external tools.\n\nMy mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.\n\nSupported Coverage Formats\n\nEmbedded\n\nJaCoCo\n\nOther plugins as an Extension of Code Coverage API plugin\n\nCobertura ( Cobertura Plugin)\n\nllvm-cov ( llvm-cov Plugin)\n\nFeatures\n\nModernized coverage chart\n\nCoverage trend\n\nSource code navigation\n\nParallel pipeline support\n\nReports combining\n\nREST API\n\nFailed conditions and flexible threshold setting\n\nOther small features\n\nModernized Coverage Chart\n\nIn the summary chart we can see the coverage summary of current coverage metric.\n\nIn the child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size. If we want to see coverage details of the child, we can click the child name to see more information.\n\nCoverage Trend\n\nWe also support coverage trend to show coverage metrics changing between builds.\n\nSource Code Navigation\n\nYou can enable source code navigation by specifying Source File Storing Level to save last build source files (enable source files navigation in current and last build) or save all build source files (enable source files navigation in all builds).\n\nYou can see source file with coverage information on File level coverage page.\n\nParallel Pipeline Support\n\nWe support parallel pipeline. You can call the Code Coverage API plugin in different branches like this:\n\nnode {\n    parallel firstBranch: {\n        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')]\n}, secondBranch: {\n        publishCoverage adapters: [jacocoAdapter('jacoco.xml')]\n    }\n}\n\nReports Combining\n\nYou can add tag on publishCoverage and Code Coverage API plugin will combine reports have same tag\n\nnode {\n    parallel firstBranch: {\n        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')], tag: ‘t’\n}, secondBranch: {\n        publishCoverage adapters: [jacocoAdapter('jacoco.xml')], tag: ‘t’\n    }\n}\n\nREST API\n\nWe provide a REST API to retrieve coverage data:\n\nCoverage result:…​/{buildNumber}/coverage/…​/result/api/\\{json|xml\\}\n\nTrend result:…​/{buildNumber}/coverage/…​/trend/api/\\{json|xml\\}\n\nCoverage result of last build:…​/{buildNumber}/coverage/…​/last/result/api/\\{json|xml\\}\n\nTrend result of last build:…​/{buildNumber}/coverage/…​/last/trend/api/\\{json|xml\\}\n\nFailed Conditions and Flexible Threshold Setting\n\nYou can set different failed conditions and threholds to control build result.\n\nIf the thresholds satisfy the failed conditions, it will fail the build.\n\nOther Small Features\n\nWe also have other small features like auto detecting reports, coverage filters, etc. You can find more information about these features in the plugin documentation.\n\nArchitecture\n\nThis API plugin will mainly do these things:\n\nFind coverage reports according to the user’s config.\n\nUse adapters to convert reports into the our standard format.\n\nParse standard format reports, and aggregate them.\n\nShow parsed result in a chart.\n\nSo, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing - convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.\n\nThe below diagram show the architecture of Code Coverage API plugin\n\nImplementing a New Coverage Plugin\n\nWe can implement a coverage plugin by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement JaCoCo simple like this:\n\npublic final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {\n\n    @DataBoundConstructor\n    public JacocoReportAdapter(String path) {\n        super(path);\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getXSL() {\n        return \"jacoco-to-standard.xsl\";\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getXSD() {\n        return null;\n    }\n\n    @Symbol(\"jacoco\")\n    @Extension\n    public static final class JacocoReportAdapterDescriptor extends JavaCoverageReportAdapterDescriptor {\n\n        public JacocoReportAdapterDescriptor() {\n            super(JacocoReportAdapter.class);\n        }\n\n        @NonNull\n        @Override\n        public String getDisplayName() {\n            return Messages.JacocoReportAdapter_displayName();\n        }\n    }\n}\n\nAll we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our standard format. There are also other extension points which are under development.\n\nIf you want implement a new coverage format that we did not provide abstract layer, you need to register `CoverageElement`s and implement an simple parser. See llvm-cov Plugin to get more details.\n\nFuture Tasks\n\nSupport more coverage tools ( JENKINS-52467, JENKINS-52469 and etc.)\n\nMake the UI extensible ( JENKINS-51738)\n\nImprove performance ( JENKINS-52982)\n\nPhase 3 Presentation Slides\n\nPhase 3 Presentation Video\n\nLinks\n\nJIRA Component\n\nProject Page\n\nProject Repository","title":"Code Coverage API plugin: 1.0 Release","tags":["plugins","gsoc","gsoc2018"],"authors":[{"avatar":null,"blog":null,"github":"cizezsy","html":"<div class=\"paragraph\">\n<p>Shenyu comes from China. He is a third year student now, and his major is\nComputer Science and technology. He has participated in GSoC 2018 for\n<a href=\"https://jenkins.io/projects/gsoc/2018/code-coverage-api-plugin/\">Code Coverage API Plugin</a></p>\n</div>","id":"shenyu_zheng","irc":"cizezsy","linkedin":null,"name":"Shenyu Zheng","slug":"/blog/author/shenyu_zheng","twitter":null}]}},{"node":{"date":"2018-08-16T00:00:00.000Z","id":"8a951bf4-62b1-5a68-b1e8-22376e509229","slug":"/blog/2018/08/16/dwjw-2018-is-almost-here/","strippedHtml":"DevOps World | Jenkins World 2018 in San Francisco is only a month away.\nIt is shaping up to be a great event including the Contributor Summit,\nthe \"Ask the Experts\" desk at the Jenkin booth, several days of training and certifications,\nand tons of informative presentation and demos.\n\nTo give you a taste of what you’ll see this year at DevOps World | Jenkins World 2018,\nwe’ve lined up a series of guest blog posts by a number of this years speakers,\nstarting in the next week with posts from Tracy Miranda, Brent Laster, and Nicholas De Loof.\nFor now, let’s take a look at last year’s keynote from Kohsuke Kawaguchi.\n\nStay tuned!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"DevOps World | Jenkins World 2018 is Almost Here","tags":["event","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/author/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2018-08-15T00:00:00.000Z","id":"09b0e766-f69d-5d93-bda5-3729f028d501","slug":"/blog/2018/08/15/security-updates/","strippedHtml":"We just released security updates to Jenkins, versions 2.138 and 2.121.3, that fix multiple security vulnerabilities.\n\nFor an overview of what was fixed, see the security advisory.\nFor an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Jenkins 2.121.3 and 2.138 security updates","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/author/daniel-beck","twitter":null}]}},{"node":{"date":"2018-08-14T00:00:00.000Z","id":"2fa297fb-b9d2-5c87-846c-6ac7d68adea3","slug":"/blog/2018/08/14/simple-pull-request-plugin-final-evaluation/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of reports at conventional locations,\nand publish them automatically. If the reports are not present at their respective conventional\nlocation, the location of the report can be configured in the YAML file.\n\nMy mentors are\nOleg Nenashev (Org Admin),\nMartin d’Anjou,\nKristin Whetstone,\nJeff Knurek\n\nProject Repository\n\nProject repository\n\nCode changes\n\nAll the pull requests made can be found here\n\nList of major pull requests.\n\nPhase 1\n\nPR-5 : Git wrappers like clone, pull, checkout,\npullChangesOfPullrequest, merge, deleteBranch and merge added.\n\nPR-6 : Yaml to Declarative Pipeline code generation.\n\nPlease see Phase 1 blog post\n\nPhase 2\n\nPR-11 : Implemented StepConfigurator\nusing Jenkins configuration as code plugin.\n\nPR-19 : Unit tests created for agent and yaml to pipeline generation.\n\nPlease see Phase 2 blog post\n\nPhase 3\n\nPR-25 : Declarative pipeline code generator code\nexported to extensions for extensibility and support of custom sections\n\nJenkinsfile.yaml example\n\nDocumentation of Jenkinsfile.yaml and yaml format can be found here\n\nTasks completed in Coding Phase 3\n\nAdd unit tests, JenkinsRule tests JENKINS-52495\n\nRefactor snippet generator to extensions ( JENKINS-52491)\n\nPlugin overview (Present in README.md)\n\nFuture tasks\n\nPhase 3 Jira Epic\n\nRelease 1.0 ( JENKINS-52519)\n\nSupport the “when” Declarative Pipeline directive ( JENKINS-52520)\n\nNice2have: Support hierarchical report types ( JENKINS-52521)\n\nAcceptance Test Harness tests JENKINS-52496\n\nAutomatic Workspace Cleanup when PR is closed ( JENKINS-51897)\n\nTest Multi-Branch Pipeline features support:\n\nSupport for webhooks ( JENKINS-51941)\n\nCheck if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)\n\nFinalize documentation ( JENKINS-52518)\n\nTest the integration with various platforms Bitbucket, Gitlab, Github.\n\nPhase 3 evaluation presentation video\n\nVideo: Link to video evaluation\n\nPhase 3 evaluation presentation slides\n\nLink to presentation slides\n\nMy GSoC experience\n\nStudent applications started on March 12 16:00 UTC and ended on March 27 16:00 UTC. Application period allowed me to explore\nmany new technology and platforms that are making peoples life easy.\n\nBefore starting of the application\nperiod I did not know anything about Jenkins. I found Jenkins organisation on the GSoC organisations page\nand came to know that I is a CI/CD platform that is used automate various things related to software development. I studied\nabout Jenkins online and went through the problem statements provided by some mentors.\n\nI decided that to work on Simple Pull-Request Job Plugin project.\nThen I wrote a draft proposal for this project and received many comments to refactor the proposal and enhance its quality from the mentors,\nthen finally I submitted my final proposal to Google.\n\nI was able to complete most of the tasks decided in Phase 1 and 2. After Phase 2 I was not able to give time to the project because\nof the placement season in the my college. I modified the code so that other plugin developers can contribute to it by Jenkins extensions.\n\nAll the mentors made themselves available for most of the weekly calls and provided many valuable suggestions during the\nentire period of GSoC. Sometimes I was not able to communicate effectively. As communication is the key while working remotely, mentors\nsuggested to communicate more thorough gitter chat.\n\nMy overall experience of GSoC was good and all the mentors helped me as they can all times. This project allowed me to explore\nJenkins and the services offered by it. I am allowed to work on the project after GSoC ends (This is a good thing).\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository","title":"alpha-3 release Pipeline as YAML (Simple pull request plugin)","tags":["gsoc2018","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/author/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-08-06T00:00:00.000Z","id":"e7cd7824-744d-512b-9ee1-51257e0c567a","slug":"/blog/2018/08/06/serverless-cicd-jenkins/","strippedHtml":"Everyone is talking about serverless.\n\nAs with any new hyped-technology the term 'serverless' is often overloaded with different meanings.\nSometimes serverless is oversimplified to mean function-as-a-service(faas).\nBut there is more to it than that.\nAlso, not many people are talking about doing CI/CD with serverless,\neven though where there is code there still in need of continuous integration and continuous delivery.\nSo I was excited to hear about this talk by\nAnubhav Mishra on\nBuilding a CI/CD Pipeline for Serverless Applications.\n\nIn the talk Anubhav proposes a new definition for serverless:\n\n\"\"\nServerless is a technology pattern that provides services and concepts to minimize operational overhead that comes with managing servers.\nIt is a powerful abstraction when used can result in an increased focus on business value.\n\"\"\n\nThe talk then goes on to demo Jenkins on AWS Fargate (a platform for running containers without managing servers or clusters).\nThe main focus is on increased elasticity/scaling.\n\nThe advantages of this approach are:\n\nNo nodes/servers to manage\n\nLaunch 10,000+ builds/containers in seconds\n\nNo cost for idle time\n\nThe real headline is the cost saving, which is 2 orders of magnitude better with serverless.\nA cost comparison is done based on 1 vCPU & 2GB memory:\n\nWith Jenkins on Fargate: 100 builds * 5 mins = $0.633/month\n\nWith Jenkins on EC2 Instances: ~50/month\n\nThis huge potential cost saving is one of the things that makes serverless incredibly compelling.\nNot to mention you don’t have to think much upfront about scaling the system.\n\nBut there are drawbacks with this approach, noted as:\n\nCold starts - slower boot times for clients\n\nLarge container images (~1G)\n\nNo root access\n\nEphemeral storage (default)\n\nThis is an area where Jenkins can continue to evolve to make the most of serverless architectures.\nI highly recommend you check out the\nslides for yourself.\nThe best part is that, in the true spirit of open source, Anubvha shared the code\nhere.\nSo you can give it a try yourself and build your own serverless CI/CD pipeline with Jenkins.","title":"Building a Serverless CI/CD Pipeline with Jenkins","tags":["serverless","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg","srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/6105b/tracymiranda.jpg 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/9d80c/tracymiranda.jpg 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a5e1e/tracymiranda.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a4758/tracymiranda.webp 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fec68/tracymiranda.webp 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fe590/tracymiranda.webp 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/c2c8e/tracymiranda.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":116}}},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"/blog/author/tracymiranda","twitter":"tracymiranda"}]}}]}},"pageContext":{"limit":8,"skip":192,"numPages":100,"currentPage":25}},
    "staticQueryHashes": ["3649515864"]}