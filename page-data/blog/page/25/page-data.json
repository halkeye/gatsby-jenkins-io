{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/25",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-08-31T00:00:00.000Z","id":"0d561c02-de0c-5799-a5a4-74b3cc361577","slug":"/blog/2018/08/31/shifting-gears/","strippedHtml":"Kohsuke here. This is a message for my fellow Jenkins developers.\n\nJenkins has been on an amazing run, but I believe we are trapped in a local optimum, and losing appeal to people who fall outside of our traditional sweet spot.\nWe need to take on new efforts to solve this. One is “cloud native Jenkins” that creates a flavor of Jenkins that runs well on Kubernetes.\nThe other is “gear shift”, where we take an evolutionary line from the current Jenkins 2, but with breaking changes in order to gain higher development speed.\n\nI say it’s time we tackle these problems head on. I’ve been talking to various folks, and I think we need to take on two initiatives.\nOne is what I call \"Cloud Native Jenkins,\" and the other is to insert a jolt in Jenkins.\n\nSome of you have already seen the presentation I posted on the Jenkins YouTube channel.  In this post, I’ll expand on that with some additional details.\n\nJenkins: Shifting Gears Presentation ( Slides)\n\nCome hear more in Kohsuke’s keynote at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.\n\nOur Amazing Success\n\nOur project has been an amazing success over the past 10+ years, thanks to you all. What started as my hobby project became a huge community that boasts thousands of contributors and millions of users.\nWhen I think about what enabled this amazing journey, I can think of several magic sauces:\n\nExtensible:\nthe ability to take the system, or a portion of the system, then build on top of it to achieve what you need, without anyone else’s permission.\nHere, I’m not talking about the specific technical mechanism of Guice, extension point, etc, but rather I’m talking more broadly about the governance, culture, distribution mechanism, and so on.\n\nGeneral purpose:\nAt the base level, Jenkins can be used for any kind of automation around the area of software development.\nThis matched the reality of the software engineering world well.\nCombined with extensibility, this general purpose system that is Jenkins can specialize into any domain, much like Linux and JetBrains IDEs.\n\nCommunity:\nTogether we created a community where different people push envelopes in different directions and share the fruits with others.\nThis meant everyone can benefit from somebody else’s work, and great ideas and best practices spread more quickly.\n\nOur Challenges\n\nThe way we set up our community meant that collectively we were able to work toward solving certain kinds of problems locally and organically, such as Android application development, new UX, more expressive pipeline description language, …​\n\nBut at the same time, the incremental, autonomous nature of our community made us demonstrably unable to solve certain kinds of problems.\nAnd after 10+ years, these unsolved problems are getting more pronounced, and they are taking a toll — segments of users correctly feel that the community doesn’t get them, because we have shown an inability to address some of their greatest difficulties in using Jenkins.\nAnd I know some of those problems, such as service instability, matter to all of us.\n\nIn a way, we are stuck in a local optimum, and that is a dangerous place to be when there is growing competition from all sides.\nSo we must solve these problems to ensure our continued relevance and popularity in the space.\n\nSolving those problems starts with correctly understanding them, so let’s look at those.\n\nService Instability\n\nCI/CD service was once a novelty and a nice-to-have.\nToday, it is very much a mission critical service, in no small part because of us!\nIncreasingly, people are running bigger and bigger workloads, loading up more and more plugins, and expect higher and higher availability.\n\nAdmins today are unable to meet that heightened expectation using Jenkins easily enough.\nA Jenkins instance, especially a large one, requires too much overhead just to keep it running.\nIt’s not unheard of that somebody restarts Jenkins every day.\n\nAdmins expect errors to be contained and not impact the entire service.\nThey expect Jenkins to defend itself better from issues such as pipeline execution problems, run-away processes, over resource consumption so that they don’t have to constantly babysit the service.\n\nEvery restart implies degraded service for the software delivery teams where they have to wait longer for their builds to start or complete.\n\nBrittle Configuration\n\nEvery Jenkins admin must have been burnt at least once in the past by making changes that have caused unintended side effects.\nBy “changes,” I’m talking about installing/upgrading plugins, tweaking job settings, etc.\n\nAs a result, too many admins today aren’t confident that they can make changes safely.\nThey fear that their changes might cause issues for their software delivery teams, that those teams will notice regressions before they do, and that they may not be able to back out somes changes easily.\nIt feels like touching a Jenga tower for them, even when a change is small.\n\nUpgrading Jenkins and plugins is an important sub case of this, where admins often do not have understanding of the impact.\nThis decreases the willingness to upgrade, which in turn makes it difficult for the project to move forward more rapidly, and instead we get trapped with the long tail of compatibility burden.\n\nAssembly Required\n\nI’ve often described Jenkins as a bucket full of LEGO blocks — you can build any car you want, but everyone first has to assemble their own car in order to drive one.\n\nAs CI/CD has gone mainstream, this is no longer OK.\nPeople want something that works out of the box, something that gets people to productivity within 5 clicks in 5 minutes.\nToo many choices are confusing users, and we are not helping them toward “the lit path.”\nEveryone feels uncertain if they are doing the right thing, contributors are spread thin, and the whole thing feels a bit like a Frankenstein.\n\nThis is yet another problem we can’t solve by “writing more plugins.”\n\nReduced Development Velocity\n\nThis one is a little different from others that our users face, but nonetheless a very important one, because it impacts our ability to expand and sustain the developer community, and influences how fast we can solve challenges that our users face.\n\nSome of these problems are not structural and rather just a matter of doing it (for example, Java 11 upgrade), but there are some problems here that are structural.\n\nI think the following ones are the key ones:\n\nAs a contributor, a change that spans across multiple plugins is difficult.\nTooling gets in the way, users might not always upgrade a group of changes together, reviewing changes is hard.\n\nAs a contributor, the tests that we have do not give me enough confidence to ship code.\nNot enough of them run automatically, coverage is shallow, and there just isn’t anything like production workload of real users/customers.\n\nThese core problems create other downstream problems, for example:\n\nAs a non-regular contributor, what I think of as a small and reasonable change takes forever and a 100 comments going back & forth to get in. I get discouraged from ever doing it again.\n\nAs a regular contributor, I feel people are throwing crap over the wall, and if they cause problems after a release, I’m on the hook to clean up that mess.\n\nAs a user, I get a half-baked change that wreaks havoc, which results in loss of their confidence to Jenkins, an even slower pace of change, etc. This is a vicious cycle as it makes us even more conservative, and slow down the development velocity.\n\nPath Forward\n\nIn the past, my frustration and regret is that we couldn’t take on an effort of this magnitude.\nBut that is NO MORE!\nAs CTO of CloudBees, I’m excited that these challenges are important enough for CloudBees now that we want to solve these efforts within the Jenkins project.\n\nI’ve been talking to many of you, and there are a number of existing efforts going on that touch this space already.\nFrom there, the vision emerged is that we organize around two key efforts:\n\nCloud Native Jenkins: a general purpose CI/CD engine that runs on Kubernetes, and embraces a fundamentally different architecture and extensibility mechanism.\n\nJolt in Jenkins: continue the incremental trajectory of Jenkins 2 today, but with renegotiated “contract” with users to gain what we really need, such as faster pace of development and better stability.\n\nCloud Native Jenkins\n\nIn order to solve these problems that we can’t solve incrementally,\nI’m proposing the “Cloud Native Jenkins” sub-project in the context of the\nCloud Native SIG\nwith Carlos, who is the leader of this SIG.\n\nWe don’t have all the answers, that’s something we’ll discuss and figure out collectively, but based on numerous conversations with various folks, I think there are many clear pieces of puzzles.\n\nKubernetes as the Runtime\n\nJust like Java was the winning server application platform in the early 2000s, today, Kubernetes is the dominant, winning platform.\nCloud Native Jenkins should embrace the paradigm this new platform encourages. For example,\n\nServerless / function-as-a-service build execution (ala\nJenkinsfile runner)\nthat are isolated.\n\nVarious pieces of functionalities deployed as separate microservices.\n\nServices interacting through\nKubernetes CRDs\nin order to promote better reuse and composability.\n\nThese are the design principles that enable highly desirable properties like infinite scalability, pay-as-you-go cost model, immutability, zero down time operability, etc.\n\nNew Extensibility Mechanism\n\nWe need to introduce a new mechanism of extensibility in order to retain the magic sauces, and continue our incredible ecosystem.\n\nFor example, microservice or container-based extensibility avoids the service instability problem (ala\nKnative builder\nand the\nuserspace-scm work.)\nPipeline shared libraries is another example that concretely shows how extensibility mechanism can go beyond plugin, though it hasn’t fully flourished as one just yet.\n\nData on Cloud Managed Data Services\n\nThe long-term data storage must be moved from the file system to data services backed by cloud managed services, in order to achieve high availability and horizontal scalability, without burdening admins with additional operational responsibilities.\n\nConfiguration as Code\n\nJenkins Configuration as Code\nhas been incredibly well received, in part because it helps to solve some of the brittle configuration problems.\nIn Cloud Native Jenkins, JCasC must play a more central role, which in turn also helps us reduce the surface area for Blue Ocean to cover by eliminating many configuration screens.\n\nEvergreen\n\nJenkins Evergreen\nis another well received effort that’s already underway, which aims to solve the brittleness problem and developer velocity problem. This is a key piece of the puzzle that allows us to move faster without throwing users under the bus.\n\nSecure by Default Design\n\nOver the past years, we’ve learned that several different areas of Jenkins codebase, such as Remoting, are inherently prone to security vulnerabilities because of their design. Cloud Native Jenkins must address those problems by flipping those to “secure by design.”\n\nFollowing Footsteps of Jenkins X\n\nJenkins X\nhas been pioneering the use of Jenkins on Kubernetes for a while now, and it has been very well received, too.\nSo naturally, part of the aim of Cloud Native Jenkins is to grow and morph Jenkins into a shape that really works well for Jenkins X.\nCloud Native Jenkins will be the general purpose CI/CD engine that runs on Kubernetes, which Jenkins X uses to create an opinionated CD experience for developing cloud native apps.\n\nAll The Same Good Things, with New Foundation\n\nAnd then on top of these foundations, we need to rebuild or transplant all the good things that people love about Jenkins today, and all the good things people expect, such as:\n\nGreat “batteries included” onboarding experience for new users, where we are present in all the marketplaces, 5 clicks to get going and easy integration with key services.\n\nModern lovable UX in the direction of front-end web apps that Blue Ocean pioneered.\n\nGeneral purpose software that is useful for all sorts of software development.\n\nCloud Native Jenkins MVP\n\nAs I wrote, a number of good efforts are already ongoing today. Thus in order to get this effort off the ground, I believe the first MVP that we aim toward is pretty clear, which is to build a function-as-a-service style Jenkins build engine  that can be used underneath Jenkins X.\n\nCloud Native Jenkins MVP combines the spirits of Jenkins Pipeline, Jenkins Evergreen, Jenkinsfile Runner, and Jenkins Configuration as Code.\nIt consists of:\n\nWebhook receiver:\na service that receives webhooks from GitHub and triggers a build engine.\n\nBuild Engine:\ntake Jenkinsfile Runner and evolve it so that it can run as a “function” that carries out a pipeline execution, with some CasC sprinkled together in order to control Jenkins configuration and plugins  used.\nThis way, Jenkinsfile works as-is for the most part.\n\nContinuously delivered through Evergreen:\nIt allows us to solve the combinatorial version explosion problem, allow us to develop changes that span multiple plugins faster, and develop changes more confidently.\nOf all the projects out there, ours should be the community that believes in the value of Continuous Delivery and Evergreen is how we bring continuous delivery to the development of Cloud Native Jenkins itself.\n\nThis solves some of the key challenges listed above that are really hard to achieve today, so it’s already incredibly useful.\n\nThe catch is that this MVP has no GUI. There’s no Blue Ocean UI to look at. No parsing of test reports, no build history. It uses no persistent volumes, it keeps no record of builds. The only thing permanent at the end of a build is whatever data is pushed out from Jenkins Pipeline, such as images pushed to a Docker registry, email notifications, and GitHub commit status updates.  Load of other features in Jenkins will not be available here.\n\nThis is not that far from how some sophisticated users are deploying Jenkins today. All in all, I think this is the right trade off for the first MVP. As you can see, we have most of the pieces already.\n\nFrom here, the build engine will get continuously more polished and more cloud native, other services will get added to regain features that were  lost, new extensibility will get introduced to reduce the role of current in-VM plugins, and so on.\n\nJolt in Jenkins\n\nCloud Native Jenkins is a major effort and in particular initially it’s not usable for everyone; it only targets a subset of Jenkins functionalities, and it requires a platform whose adoption is still limited today.\nSo in parallel, we need to continue the incremental evolution of Jenkins 2, but in an accelerated speed. Said differently, we need to continue to serve the majority of production workload on Jenkins 2 today, but we are willing to break some stuff to gain what we really need, such as faster pace of development and better stability, in ways that were previously not possible. This requires us injecting a jolt in Jenkins.\n\nRelease Model Change\n\nThe kind of jolts that we need will almost certainly means we need to renegotiate the expectation around new releases with our users.\nMy inspiration source is what happened to the development of Java SE. It changed the release model and started moving faster, by shedding off more pieces faster, in ways that they haven’t done before.\nAgain, Jenkins Evergreen is the key piece that achieves this without throwing users under a bus, for the reasons I described in the Cloud Native MVP above.\n\nCompatibility\n\nThis jolt is aimed to put us on a different footing, one where our current “forever compatibility” expectation does not hold. If that requires us to use a new major version number, such as Jenkins 3, or new major version number every N months, I’m open to that.\n\nOf course, whatever move we do has to make sense to users. The accelerated pace of value delivery needs to justify any inconvenience we put on users, such as migration, breaking changes, and so on.\n\nIn practice, what that means is that we need to be largely compatible. We have to protect users’ investment into their existing job definitions as much as possible. We continue to run freestyle jobs, etc…​\n\nIngredients\n\nOther proposals CloudBees is putting forward with the intent to staff the effort are:\n\nConfiguration as Code: accelerate that and make it a more central  part of Jenkins.\n\nDeveloper experience improvements through buildpack style auto-detection of project types.\n\nContinued evolution of Jenkins Pipeline\n\nThere’s an effort going on to remove CPS execution of Pipeline and isolate any failures during pipeline execution.\n\nContinue to evolve Jenkins Pipeline toward the sweet spot that works well with the Cloud Native Jenkins effort.\n\nContinued tactical bug-by-bug improvements of Pipeline.\n\nEvergreen: I already talked about this above.\n\nPlugin spring cleaning: let’s actively guide users more toward the sweet spot of Jenkins and reduce our feature surface area, so that we can focus our contributors’ effort to important parts of Jenkins. I expect this to be a combination of governance and technical efforts.\n\nTable stakes service integration: let’s look at what kind of tablestake tool/service integrations today’s user need, and\nsee if we are meeting/exceeding the competition.\nWhere we fall short, let’s add/reimplement what are needed.\n\nUI Effort\n\nThe Web UI will be likely done differently in Cloud Native Jenkins, as its own app and not a plugin in Jenkins. JCasC will also play a bigger role in Cloud Native Jenkins, reducing UI surface area from Jenkins.\n\nGiven that, CloudBees will reconsider where to spend its effort in Blue Ocean. The current work where parts of Blue Ocean are made reusable as NPM modules is one example that aligns well with this new vision.\n\nConclusion\n\nThis document lays out the key directions and approaches in a broad stroke, which I discussed with a number of you in the past. Hopefully, this gives you the big picture of how I envision where to move Jenkins forward, not just as the creator of Jenkins but as the CTO of CloudBees, who employs a number of key contributors to the Jenkins project.\n\nCome meet Kohsuke and chat with him about the direction of Jenkins at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins: Shifting Gears","tags":["development","core"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg","srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/f81fe/kohsuke.jpg 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/01b1b/kohsuke.jpg 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/035c3/kohsuke.webp 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/273f8/kohsuke.webp 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/e3840/kohsuke.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":148}}},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"/blog/authors/kohsuke","twitter":"kohsukekawa"}]}},{"node":{"date":"2018-08-30T00:00:00.000Z","id":"76fe30c4-d5ca-529d-af0c-044c46a5a864","slug":"/blog/2018/08/30/speaker-blog-kubernetes-plugin/","strippedHtml":"This is a guest blog by Niklas Tanskanen, consultant at\nEficode.\n\nKubernetes, the container orchestration platform is rapidly becoming popular. There are more and more workloads that you can run on top of Kubernetes. It’s becoming an enabling layer of your Hyper-convergenced infrastructure.\n\nIf you set up Kubernetes as a Cloud provider in Jenkins, you’ll get a very powerful couple for running your workloads.\nTo do that, you can simply install\nKubernetes plugin.\nKubernetes is able to run your Jenkins workloads as long as they are run in container.\nAnd containers are an awesome way if your workload is a build, because you can pack all your application and OS dependencies in a container and then run it anywhere!\n\nLet’s imagine that you have been running a Kubernetes cluster setup in your organisation for a while now.\nFirst it was all about proof of concept but now its becoming more popular within your developers and you have to think about scaling and orchestration.\nResource quotas are a part of that and every responsible operator should set those up both in both development and production clusters.\nOtherwise people will be lazy and just reserve all the resources of your cluster without actually using those resources for anything.\nBy introducing quotas into your cluster, you can control how many resources should each namespace have.\n\nQuotas are a mature feature of Kubernetes already.\nYou have the possibility to create very fine grained quotas for different hardware resources, whenever it’s fast disk, GPUs or CPU time.\nYou can also specify multiple scopes of quota per one namespace.\nFor example, you can have a quota for workloads that are to be run to the infinity like web servers or databases.\nOr have quota for workloads that are short lived like builds or test automation runs.\n\nTable 1. Scopes\n\nScope\nDescription\n\nTerminating\nMatch pods where.spec.activeDeadlineSeconds >= 0\n\nNotTerminating\nMatch pods where.spec.activeDeadlineSeconds is nil\n\nBestEffort\nMatch pods that have best effort quality of service.\n\nNotBestEffort\nMatch pods that do not have best effort quality of service.\n\nDifferent scopes of Kubernetes quota\n\nSince Jenkins is all about running short workloads, you should aim for the Terminating scope of quota.\nBut how do you specify workloads in Jenkins so that correct scope is used?\n\nIf you were to do this in Kubernetes, you have to specify.spec.activeDeadlineSeconds.\nThe same field can also be specified by the Kubernetes plugin when you are specifying a Pod Template.\n\nFigure 1. Specifying.spec.activeDeadlineSeconds in the Kubernetes plugin\n\nSame configuration is available in the Jenkinsfile as well if you don’t like static configurations.\n\npodTemplate(label: 'maven', activeDeadlineSeconds: 180, containers: [\n    containerTemplate(name: 'maven', image: 'maven:3.5.4-jdk-10-slim')\n  ]) {\n  // maven magic\n}\n\nThis was just a small sample of features of the Kubernetes plugin in Jenkins. For more, be sure to check out our\ntalk where we share more of how you can utilise Kubernetes with Jenkins!\n\nCome see Niklas Tanskanen and many other Jenkins experts and contributors at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Effectively using Kubernetes plugin with Jenkins","tags":["kubernetes","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":null,"blog":null,"github":"tanskann","html":"","id":"tanskann","irc":null,"linkedin":null,"name":"Niklas Tanskanen","slug":"/blog/authors/tanskann","twitter":null}]}},{"node":{"date":"2018-08-29T00:00:00.000Z","id":"edd1abcd-b413-5696-b610-a81a6a7fdd9f","slug":"/blog/2018/08/29/day-of-jenkins-and-other-chances-to-meet-jcasc/","strippedHtml":"The Jenkins Configuration as Code plugin is reaching a stage when it is almost ready to be used in a production environment.\nAs a matter of fact, I know some living-on-the-edge users are already doing that.\nThe first release candidates are out and the official 1.0 is just around the corner.\n\nI’d like to use this chance to invite you to meet us and contribute to the plugin.\nThere will be plenty of opportunities this autumn.\n\nJenkins Configuration as Code (also called \"JCasC\") is a Jenkins plugin that allows you to store and maintain all your Jenkins configuration in yaml file.\nIt’s like Pipeline or Job DSL but for managing Jenkins.\n\nIn one of my blogposts,\nJenkins Configuration as Code - Automating an automation server,\nI provide a longer explanation of the plugin, and answer questions like\n“why did we decided to develop it?” and “why you may want to use it?”.\nI recommend you to read that one if you’re not familiar with the project yet.\n\nThe plugin has been presented at a number of meetups - by me but also other contributors.\nThis is the first open source project that I’ve actively participated in and I’m quite shocked - positively - to see how many people decided to join the effort and actively develop the plugin with us.\nNow it’s time to take it to the bigger stage and broader audience.\nSo together with Nicolas de Loof I’m gonna present the plugin at DevOps World | Jenkins World in San Francisco (19th of September)  and in Nice (24th of October) - yes, Jenkins World is coming to Europe.\n\nBut that’s not all!\nPraqma - the company I work for -\nhas organised a number of “Day of Jenkins” events around Scandinavia in past years.\nThis October they have decided to bring the events back with a theme: Day of Jenkins 2018 is\nDay of Jenkins [as code] .\nIt’s a two track one day event with presentations and hands-on sessions for users and a hackathon for contributors - in that specific case Configuration as Code Plugin’s contributors.\n\nDetailed agenda is available on the\nevent page -\nJenkins X, Jenkins Evergreen, Jenkins Configuration as Code and more waiting for you!\n\nI really can’t wait to hear what Kohsuke has to say and to introduce you to the plugin during the hands-on session I’ll run.\n\nHope to see you at least at one of those events!\n\nCome meet the Configuration as Code contributors, Nicolas de Loof and Ewelina Wilkosz at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Day of Jenkins, and other chances to meet JCasC","tags":["jenkins","jcasc","configuration as code"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/19e71/ewelinawilkosz.jpg","srcSet":"/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/77b35/ewelinawilkosz.jpg 32w,\n/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/d4a57/ewelinawilkosz.jpg 64w,\n/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/19e71/ewelinawilkosz.jpg 128w,\n/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/68974/ewelinawilkosz.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/ef6ff/ewelinawilkosz.webp 32w,\n/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/8257c/ewelinawilkosz.webp 64w,\n/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/6766a/ewelinawilkosz.webp 128w,\n/gatsby-jenkins-io/static/62cac5d7353c59176523b1ca3cb1166c/22bfc/ewelinawilkosz.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"ewelinawilkosz","html":"<div class=\"paragraph\">\n<p>Jenkins Contributor since 2017, when she got involved in Jenkins Configuration as Code Plugin development.\nVoted Most Valuable Contributor in 2018.\nShe has 14 years of experience in IT, currently working as a CI/CD consultant at Verifa.\nIn that role she’s trying to solve numerous issues Jenkins users are facing daily - as developers, administrators, maintainers.\nJenkins Governance Board member.</p>\n</div>","id":"ewelinawilkosz","irc":null,"linkedin":null,"name":"Ewelina Wilkosz","slug":"/blog/authors/ewelinawilkosz","twitter":"WilkoszEwelina"}]}},{"node":{"date":"2018-08-23T00:00:00.000Z","id":"409d4d90-3aa4-5eba-ac07-97d9486bc294","slug":"/blog/2018/08/23/speaker-blog-casc-part-1/","strippedHtml":"This blog post is part 1 of a Configuration-as-Code series\n\nJenkins is highly flexible and is today the de facto standard for implementing CI/CD, with an active community to maintain plugins for almost any combination of tools and use-cases.\nBut flexibility has a cost: in addition to Jenkins core, many plugins require some system-level configuration to be set so they can do their job.\n\nIn some circumstances, \"Jenkins Administrator\" is a full time position.\nOne person is responsible for both maintaining the infrastructure, and also pampering a huge Jenkins controller with hundred installed plugins and thousands hosted jobs.\nMaintaining up-to-date plugin versions is a challenge and failover is a nightmare.\n\nThis is like years ago when system administrators had to manage dedicated machines per service.\nIn 2018, everything is managed as code using infrastructure automation tools and virtualization.\nNeed a fresh new application server as staging environment for your application? Just deploy a Docker container.\nInfrastructure is missing resources? Apply a Terraform recipe to allocate more on your favourite Cloud.\n\nWhat about the Jenkins administrator role in this context? Should they still spend hours in the web UI, clicking checkboxes on web forms? Maybe they already adopted some automation, relying on Groovy script voodoo, or some home-made XML templating?\n\nEarly this year we announced the first alpha release of “Jenkins Configuration-as-Code” (JCasC), a fresh new approach to Jenkins configuration management, based on YAML configuration files and automatic model discovery.\n“JCasC” has been promoted as a\ntop-level Jenkins project, and the corresponding\nJenkins Enhancement Proposal has been accepted.\n\nWhat can JCasC do for our Jenkins Administrator?\n\nJCasC allows us to apply a set of YAML files on our Jenkins controller at startup or on-demand via the web UI.\nThose configuration files are very concise and human readable compared to verbose XML files the Jenkins uses to actually store configuration.\nThe files also have user-friendly naming conventions making it easy for administrators to configure all Jenkins components.\n\nHere’s an example:\n\njenkins:\n systemMessage: \"Jenkins managed by Configuration as Code\"\n\n securityRealm:\n   ldap:\n     configurations:\n       - server: ldap.acme.com\n         rootDN: dc=acme,dc=fr\n         managerPasswordSecret: ${LDAP_PASSWORD}\n     cache:\n       size: 100\n       ttl: 10\n     userIdStrategy: CaseInsensitive\n     groupIdStrategy: CaseSensitive\n\nAs you can see, you don’t need long explanation to understand how this YAML file will setup your Jenkins controller.\n\nBenefits\n\nThe most immediate benefit of JCasC is reproducibility.\nAn administrator can now bootstrap a new Jenkins controller with the exact same configuration with a trivial setup.\nThis allows them to create a test instance and check the impact of plugin upgrades in a sandboxed environment.\nThis also lets them be more confident with failover and disaster recovery scenarios.\n\nFurther benefits come when administrators start managing their Jenkins’ YAML configuration files in source control, like they do with Terraform configuration.\nDoing so gives them auditing and reversibility of their Jenkins controller configuration.\nTheycan establish a sane configuration change workflow that runs a test Jenkins instance and ensures configuration is healthy before actually applying any change to their production Jenkins controller.\n\nLast but not least, with ability to quickly setup Jenkins controllers and control them from a set of shared YAML configuration files, administrators can now offer per-team Jenkins instances, with more flexibility on installed plugins.\nA controller becomes more or less a transient piece of infrastructure for your team, as long as they also manage build definition with Jenkinsfiles.\n\nWith Configuration-as-Code we can stop having to treat our Jenkins controller like a pet we need to pamper, and start managing Jenkins controllers as cattle you can replace without effort nor impacts.\nWelcome in the “as-code” world.\n\nFigure 1. They are still cute though, right?\n\nOk, so what’s next?\n\nYou can read more about the Jenkins Configuration-as-Code plugin on the project’s\ngithub repository.\nTo chat with the community and contributors join our\ngitter channel,\nor come see us in person at\nlink: Jenkins World to discuss the JCasC project and its future!\n\nAlso don’t miss next post from the Configuration-as-Code series, where we’ll look at how JCasC works with sensitive data like passwords and other credentials.\n\nCome meet the Configuration as Code contributors, Nicolas de Loof and Ewelina Wilkosz at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Jenkins Configuration-as-Code: Look ma, no hands","tags":["configuration-as-code","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":null,"blog":null,"github":"ndeloof","html":"","id":"ndeloof","irc":null,"linkedin":null,"name":"Nicolas De Loof","slug":"/blog/authors/ndeloof","twitter":null}]}},{"node":{"date":"2018-08-21T00:00:00.000Z","id":"814e4630-7e61-5840-9cbd-22628b628bfe","slug":"/blog/2018/08/21/contributor-summit-nice/","strippedHtml":"The Jenkins Contributor summit is where the current and future contributors of the Jenkins project get together.\nThis summit will be on Tuesday, October 23rd 2018 in Nice, France just before Jenkins World.\nThe summit brings together community members to learn, meet and help shape the future of Jenkins.\nIn the Jenkins commmunity we value all types and sizes of contributions and love to welcome new participants.\nIt is free to join, just register here.\n\nTopics\n\nThere are plenty of exciting developments happening in the Jenkins community.\nThe summit will feature a 'State of the Project' update including updates from the Jenkins officers.\nWe will also have updates on the 'Big 5' projects in active development:\n\nJenkins Evergreen\n\nJenkins X\n\nConfiguration as Code\n\nJenkins Pipeline\n\nCloud Native Jenkins\n\nPlus we will feature a Google Summer of Code update, Special Interest Group updates and more!\n\nAgenda\n\nThe agenda is shaping up well and here is the outline so far.\n\n9:00am Kickoff & Welcome with coffee/pastries\n\n10:00am Project Updates\n\n12:00pm Lunch\n\n1.00pm BoF/Unconference\n\n3.00pm Break\n\n3.30pm Ignite Talks\n\n5.00pm Wrap-up\n\n6.00pm Contributor Dinner\n\nThe BoF (birds-of-a-feather) session will be an opportunity for in depth discussions, hacking or learning more about any of the big 5.\nBring your laptop, come prepared with questions and ideas, and be ready for some hacking too if you want.\nJoin in, hear the latest and get involved in any project during the BoF sessions.\nIf you want to share anything there will be an opportunity to do a 5-min ignite talk at the end.\nAttending is free, and no DevOps World | Jenkins World ticket is needed, but RSVP if you are going to attend to help us plan.\nSee you there!","title":"Join us at the Jenkins Contributor Summit Nice, Tuesday 23 October 2018","tags":["community","events","jenkins-world"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg","srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/6105b/tracymiranda.jpg 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/9d80c/tracymiranda.jpg 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a5e1e/tracymiranda.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a4758/tracymiranda.webp 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fec68/tracymiranda.webp 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fe590/tracymiranda.webp 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/c2c8e/tracymiranda.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":116}}},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"/blog/authors/tracymiranda","twitter":"tracymiranda"}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"e4121dfc-f5a5-57b7-b1e0-733189f8140a","slug":"/blog/2018/08/17/code-coverage-api-plugin-1.0-release/","strippedHtml":"I am happy to announce availability of Code Coverage API. These plugins have been recently released as 1.0, and they are now available in the Jenkins Update Center. In this blogpost I will introduce the features and project structure of Code Coverage API plugin.\n\nMy name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.\n\nOverview\n\nCode Coverage API plugin is one of GSoC 2018 Jenkins projects.\n\nThere are a lot of plugins which currently implement code coverage; however, they all use similar config, charts, and content. So it would be much better if we could have an API plugin which does the most repeated work for those plugins and offers a unified API which can be consumed by other plugins and external tools.\n\nMy mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.\n\nSupported Coverage Formats\n\nEmbedded\n\nJaCoCo\n\nOther plugins as an Extension of Code Coverage API plugin\n\nCobertura ( Cobertura Plugin)\n\nllvm-cov ( llvm-cov Plugin)\n\nFeatures\n\nModernized coverage chart\n\nCoverage trend\n\nSource code navigation\n\nParallel pipeline support\n\nReports combining\n\nREST API\n\nFailed conditions and flexible threshold setting\n\nOther small features\n\nModernized Coverage Chart\n\nIn the summary chart we can see the coverage summary of current coverage metric.\n\nIn the child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size. If we want to see coverage details of the child, we can click the child name to see more information.\n\nCoverage Trend\n\nWe also support coverage trend to show coverage metrics changing between builds.\n\nSource Code Navigation\n\nYou can enable source code navigation by specifying Source File Storing Level to save last build source files (enable source files navigation in current and last build) or save all build source files (enable source files navigation in all builds).\n\nYou can see source file with coverage information on File level coverage page.\n\nParallel Pipeline Support\n\nWe support parallel pipeline. You can call the Code Coverage API plugin in different branches like this:\n\nnode {\n    parallel firstBranch: {\n        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')]\n}, secondBranch: {\n        publishCoverage adapters: [jacocoAdapter('jacoco.xml')]\n    }\n}\n\nReports Combining\n\nYou can add tag on publishCoverage and Code Coverage API plugin will combine reports have same tag\n\nnode {\n    parallel firstBranch: {\n        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')], tag: ‘t’\n}, secondBranch: {\n        publishCoverage adapters: [jacocoAdapter('jacoco.xml')], tag: ‘t’\n    }\n}\n\nREST API\n\nWe provide a REST API to retrieve coverage data:\n\nCoverage result:…​/{buildNumber}/coverage/…​/result/api/\\{json|xml\\}\n\nTrend result:…​/{buildNumber}/coverage/…​/trend/api/\\{json|xml\\}\n\nCoverage result of last build:…​/{buildNumber}/coverage/…​/last/result/api/\\{json|xml\\}\n\nTrend result of last build:…​/{buildNumber}/coverage/…​/last/trend/api/\\{json|xml\\}\n\nFailed Conditions and Flexible Threshold Setting\n\nYou can set different failed conditions and threholds to control build result.\n\nIf the thresholds satisfy the failed conditions, it will fail the build.\n\nOther Small Features\n\nWe also have other small features like auto detecting reports, coverage filters, etc. You can find more information about these features in the plugin documentation.\n\nArchitecture\n\nThis API plugin will mainly do these things:\n\nFind coverage reports according to the user’s config.\n\nUse adapters to convert reports into the our standard format.\n\nParse standard format reports, and aggregate them.\n\nShow parsed result in a chart.\n\nSo, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing - convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.\n\nThe below diagram show the architecture of Code Coverage API plugin\n\nImplementing a New Coverage Plugin\n\nWe can implement a coverage plugin by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement JaCoCo simple like this:\n\npublic final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {\n\n    @DataBoundConstructor\n    public JacocoReportAdapter(String path) {\n        super(path);\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getXSL() {\n        return \"jacoco-to-standard.xsl\";\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getXSD() {\n        return null;\n    }\n\n    @Symbol(\"jacoco\")\n    @Extension\n    public static final class JacocoReportAdapterDescriptor extends JavaCoverageReportAdapterDescriptor {\n\n        public JacocoReportAdapterDescriptor() {\n            super(JacocoReportAdapter.class);\n        }\n\n        @NonNull\n        @Override\n        public String getDisplayName() {\n            return Messages.JacocoReportAdapter_displayName();\n        }\n    }\n}\n\nAll we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our standard format. There are also other extension points which are under development.\n\nIf you want implement a new coverage format that we did not provide abstract layer, you need to register `CoverageElement`s and implement an simple parser. See llvm-cov Plugin to get more details.\n\nFuture Tasks\n\nSupport more coverage tools ( JENKINS-52467, JENKINS-52469 and etc.)\n\nMake the UI extensible ( JENKINS-51738)\n\nImprove performance ( JENKINS-52982)\n\nPhase 3 Presentation Slides\n\nPhase 3 Presentation Video\n\nLinks\n\nJIRA Component\n\nProject Page\n\nProject Repository","title":"Code Coverage API plugin: 1.0 Release","tags":["plugins","gsoc","gsoc2018"],"authors":[{"avatar":null,"blog":null,"github":"cizezsy","html":"<div class=\"paragraph\">\n<p>Shenyu comes from China. He is a third year student now, and his major is\nComputer Science and technology. He has participated in GSoC 2018 for\n<a href=\"https://jenkins.io/projects/gsoc/2018/code-coverage-api-plugin/\">Code Coverage API Plugin</a></p>\n</div>","id":"shenyu_zheng","irc":"cizezsy","linkedin":null,"name":"Shenyu Zheng","slug":"/blog/authors/shenyu_zheng","twitter":null}]}},{"node":{"date":"2018-08-17T00:00:00.000Z","id":"003e40e9-a1b3-5859-a18a-60017d86c651","slug":"/blog/2018/08/17/speaker-blog-brent-laster/","strippedHtml":"More and more today, continuous delivery (CD) pipelines are making use of containers.\nIn many implementations, the primary workflow/orchestration tool for CD pipelines is Jenkins.\nAnd the primary container orchestration tool is Docker.\nTogether these two applications provide a powerful, yet simple to understand and use, model for leveraging containers in your CD pipeline.\n\nWhen creating a pipeline script in Jenkins, there are multiple ways to incorporate Docker into your CD pipeline.\nThey include:\n\nManually running a predefined Docker image as a separate Jenkins agent\n\nAutomatically provisioning a Docker image, when needed, as a part of a “cloud” configuration\n\nReferencing a “docker” global variable that can be invoked via the Jenkins DSL\n\nCalling the Docker executable directly via a shell call in the Jenkins DSL\n\nFor this article, we’ll focus on the third item in this list given that it provides the most flexibility and convenience for Docker use in the pipeline.\nMore details on the other three can be found in the upcoming “Continuous Delivery and Containerization” workshop at Jenkins World/DevOps World 2018.\n\nFirst, we’ll provide some background on a couple of terms for those who may not be familiar with Jenkins 2.\nIf you already are familiar with it, feel free to skip ahead to the Global Variables section.\n\nBackground\n\nWhen we talk about Jenkins here, we’re referring to “Jenkins 2” - a name we use to generally refer to the 2.0 and beyond versions of Jenkins.\nJenkins 2 offers a powerful evolution of Jenkins over prior versions.\nIn particular, it provides full integration for “pipeline-as-code” (PAC).\nPAC refers to being able to write your pipeline in a scripting language, much like source code for any program.\nThe code you write becomes the program that defines your pipeline.\nIt is also the code that gets executed when your pipeline is initiated.\nListing 1 shows a simple example pipeline.\nNotice that this is very different from the classic way of creating pipelines in Jenkins.\nHere you are writing code - rather than the more traditional approaches, such as filling in web forms to configure a Freestyle job.\n\n// Scripted Pipeline //\nnode('worker') {\n    stage('Source') { // Get code\n        // Get code from our git repository\n        git 'git@diyvb2:/home/git/repositories/workshop.git'\n    }\n    stage('Compile') { // Compile and do unit testing\n        // Run gradle to execute compile and unit testing\n        sh \"gradle clean compileJava test\"\n    }\n}\n// Declarative //\n\nListing 1: Example Jenkins 2 pipeline\n\nThe language that we write the Jenkins pipeline code in is a Domain-Specific Language (DSL).\nYou can think of it as the “programming language” for Jenkins pipelines.\nThere are two variants of it.\nThe style we saw in figure 1 is called “scripted syntax”.\nIt is a mixture of elements from the Groovy programming language and special Jenkins “steps”.\nThe Jenkins steps are provided by the plugins that are installed in the current system.\nA built-in tool called the Snippet Generator provides a wizard interface to allow users to pick the step and options they want.\nThen, the user can click on a button to have Jenkins automatically generate the correct DSL code in the large text box (figure 1).\nThe DSL code can be copied from there and pasted into the pipeline script.\n\nFigure 1. The Snippet Generator\n\nA second type of syntax is called “declarative syntax.”  We won’t go into detail on it here.\nBut it is a much more structured syntax that focuses on having users declare what they want in a pipeline, rather than writing the logic to make it happen.\n\nGlobal Variables\n\nIn addition to the steps that are provided by plugins, additional functionality for pipelines can be provided by global variables.\nThe simplest way to think of a global variable is as an object with methods that can be invoked on it.\nSeveral of these are built in to Jenkins, such as the Docker global variable.\nOthers can be created by users as part of the structure of a shared source code repository called a “shared pipeline library.”\n\nTo get a list of the global variables that are currently available to your Jenkins instance, you can go to the Snippet Generator screen.\nImmediately below the box for the generated pipeline script is a section titled Global Variables.\nThere, within the small print, is a link to get to the actual section (figure 2).\n\nFigure 2. Link to Global Variables Reference section.\n\nClicking on that link takes us to a list of currently available Global Variables.\nIf you have the Docker Pipeline Plugin installed, you will see one at the top for Docker. (Figure 3).\n\nFigure 3. Docker global variable specifics.\n\nBroadly, the docker global variable includes methods that can be applied to the Docker application, Docker images, and Docker containers.\n\nWe’ll focus first on a couple of the Docker image methods as shown in figure 4.\n\nFigure 4. Key methods for getting a Docker image.\n\nThere are multiple ways you can use these methods to create a new image.\nListing 2 shows a basic example of assigning and pulling an image using the image method.\n\nmyImage = docker.image(\"bclaster/jenkins-node:1.0\")\nmyImage.pull()\n\nListing 2: Assigning a image to a variable and pulling it down.\n\nThis can also be done in a single statement as shown in listing 3.\n\ndocker.image(\"bclaster/jenkins-node:1.0\").pull()\n\nListing 3: Shorthand version of previous call.\n\nYou can also download a Dockerfile and build an image based on it.(See listing 4.)\n\nnode() {\n    def myImg\n    stage (\"Build image\") {\n        // download the dockerfile to build from\n        git 'git@diyvb:repos/dockerResources.git'\n\n        // build our docker image\n        myImg = docker.build 'my-image:snapshot'\n    }\n}\n\nListing 4: Pipeline code to download a Dockerfile and build an image from it.\n\nFigure 5 shows the actual output from running that “Build image” stage.\nNote that the docker.build step was translated into an actual Docker build command.\n\nFigure 5. Actual Docker output from running the download and build\n\nThe Inside Command\n\nAnother powerful method available for the Docker global variable is the inside method.\nWhen executed, this method will do the following:\n\nGet an agent and a workspace to execute on\n\nIf the Docker image is not already present, pull it down\n\nStart the container with that image\n\nMount the workspace from Jenkins\n\nExecute the build steps\n\nMounting the workspace means that the Jenkins workspace will appear as a volume inside the container.\nAnd it will have the same file path.\nSo, things running in the container will have direct access to the same location.\nHowever, this can only be done if the container is running on the same underlying system - such that it can directly access the path.\n\nIn terms of executing the build steps, the inside method acts as a scoping method.\nThis means that the environment it sets up is in effect for any statement that happens within its scope (within the block under it bounded by {}).\nThe practical application here is that any pipeline “sh” steps (a call to the shell to execute something) are automatically run in the container.\nBehind the scenes, this is done by wrapping the calls with “docker exec”.\n\nWhen executed, the calls with the global variable are translated (by Jenkins) into actual Docker call invocations.\nListing 5 shows an example of using this in a script, along with the output from the first invocation of the “inside” method.\nYou can see in the output the docker commands that are generated from the inside method call.\n\nstage (\"Get Source\") {\n        // run a command to get the source code download\n        myImg.inside('-v /home/git/repos:/home/git/repos') {\n            sh \"rm -rf gradle-greetings\"\n            sh \"git clone --branch test /home/git/repos/gradle-greetings.git\"\n        }\n    }\n    stage (\"Run Build\") {\n        myImg.inside() {\n            sh \"cd gradle-greetings && gradle -g /tmp clean build -x test\"\n        }\n    }\n\nListing 5: Example inside method usage.\n\nFigure 6. Example inside method Docker command output.\n\nOnce completed, the inside step will stop the container,\nget rid of the storage, and create a record that this image was used for the build.\nThat record facilitates image traceability, updates, etc.\n\nAs you can see, the combination of using the Docker “global variable” and its “inside” method provide a simple and powerful way to spin up and work with containers in your pipeline.\nIn addition, since you are not having to make the direct Docker calls, you can invoke steps like sh within the scope of the inside method, and have them executed by Docker transparently.\n\nAs we mentioned, this is only one of several ways you can interact with Docker in your pipeline code.\nTo learn about the other methods and get hands-on practice, join me at DevOps World/Jenkins World in San Francisco or Nice for the workshop\n\" Creating a Deployment Pipeline with Jenkins 2\".\nHope to see you there!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Using the Docker Global Variable in Your Jenkins Pipeline","tags":["event","jenkinsworld","jenkinsworld2018","pipeline","docker"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg","srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/77b35/brentlaster.jpg 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/d4a57/brentlaster.jpg 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/19e71/brentlaster.jpg 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/68974/brentlaster.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/ef6ff/brentlaster.webp 32w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/8257c/brentlaster.webp 64w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/6766a/brentlaster.webp 128w,\n/gatsby-jenkins-io/static/04c1d7e712c641c082c7193fa99be1e5/22bfc/brentlaster.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"brentlaster","html":"<div class=\"paragraph\">\n<p>Brent Laster is a Senior Manager in the Research and Development division at SAS in Cary, North Carolina. He manages several groups involved with release engineering processes, best practices, and tooling. He also serves as a resource for the use of open-source technologies and conducts internal training classes in technologies such as Git, Gerrit, Gradle, and Jenkins, both in the U.S. and abroad.</p>\n</div>\n<div class=\"paragraph\">\n<p>Brent Laster is the author of \"Professional Git\"\n(a comprehensive guide to Git for users ranging from beginners to advanced)\nand \"Jenkins 2 – Up and Running:  Evolve Your Pipeline for Next-Generation Automation\".</p>\n</div>","id":"brentlaster","irc":null,"linkedin":null,"name":"Brent Laster","slug":"/blog/authors/brentlaster","twitter":"brentclaster"}]}},{"node":{"date":"2018-08-16T00:00:00.000Z","id":"8a951bf4-62b1-5a68-b1e8-22376e509229","slug":"/blog/2018/08/16/dwjw-2018-is-almost-here/","strippedHtml":"DevOps World | Jenkins World 2018 in San Francisco is only a month away.\nIt is shaping up to be a great event including the Contributor Summit,\nthe \"Ask the Experts\" desk at the Jenkin booth, several days of training and certifications,\nand tons of informative presentation and demos.\n\nTo give you a taste of what you’ll see this year at DevOps World | Jenkins World 2018,\nwe’ve lined up a series of guest blog posts by a number of this years speakers,\nstarting in the next week with posts from Tracy Miranda, Brent Laster, and Nicholas De Loof.\nFor now, let’s take a look at last year’s keynote from Kohsuke Kawaguchi.\n\nStay tuned!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"DevOps World | Jenkins World 2018 is Almost Here","tags":["event","jenkinsworld","jenkinsworld2018"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"limit":8,"skip":192,"numPages":100,"currentPage":25}},
    "staticQueryHashes": ["3649515864"]}