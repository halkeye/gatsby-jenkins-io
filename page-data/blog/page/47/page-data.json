{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/47",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-09-20T00:00:00.000Z","id":"2af55d7f-59c7-5a3f-b9bb-07c4e85c5df6","slug":"/blog/2016/09/20/jom-plugin-development/","strippedHtml":"On September 6th we had a Jenkins Online Meetup.\nThis meetup was the second event in the series of Plugin Development meet ups.\nAt this meetup we were talking about Jenkins Web UI development.\n\nTalks\n\n1) Classic Jenkins UI framework -\nDaniel Beck\n\nIn the first part of his talk, Daniel presented how Stapler, the web framework used in Jenkins, works, and how you can add to the set of URLs handled by Jenkins.\nIn the second part he was talking about creating new views using Jelly and Groovy, and how to add new content to existing views.\n\nKeywords:\nStapler,\nJelly,\nGroovy-defined UIs\n\n2) Developing modern Jenkins UIs with Javascript -\nTom Fennelly\n\nFeel that Jenkins UI is a bit old? You are not alone.\nIn addition to the old stack Jenkins offers a framework for writing UI components in Javascript with help of Node.js.\nTom presented this new engine, which is being used in new Jenkins Web UI components like Jenkins installation wizard.\nHe also provided several examples from the BlueOcean project he is working on.\n\nKeywords:\nNode.js,\nReactJS,\nJenkins JS Builder,\nJenkins Design Language,\nBlue Ocean\n\nLinks\n\nMeetup page\n\nEvent page: Plugin Development. Web UI\n\nWebinar recording\n\nWant to conduct a meetup?\n\nWe are looking for speakers, who would be interested to share their experience about Jenkins best-practices, war stories and plugin development.\n\nIf you are interested to conduct a presentation,\nplease contact meetup organizers using meetup.com “contact organizers” feature\nor via the events@lists.jenkins-ci.org mailing list.","title":"Jenkins Online Meetup report. Plugin Development - WebUI","tags":["meetup","event"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png","srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/914ee/oleg_nenashev.png 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/1c9ce/oleg_nenashev.png 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/acb7c/oleg_nenashev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/ef6ff/oleg_nenashev.webp 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/8257c/oleg_nenashev.webp 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/6766a/oleg_nenashev.webp 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/22bfc/oleg_nenashev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/authors/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2016-09-19T00:00:00.000Z","id":"9f1352d7-4bb9-5af7-a7b7-3dab3d29a690","slug":"/blog/2016/09/19/blueocean-beta-declarative-pipeline-pipeline-editor/","strippedHtml":"At Jenkins World on Wednesday 14th of September, the Jenkins project was happy to\nintroduce the beta release of Blue Ocean. Blue Ocean is the new user experience\nfor Jenkins, built from the ground up to take advantage of Jenkins Pipeline.\nIt is an entire rethink of the the way that modern developers will use Jenkins.\n\nBlue Ocean is available today via the Jenkins Update Center for Jenkins users\nrunning 2.7.1 and above.\n\nGet the beta\n\nJust search for BlueOcean beta in the Update Center, install it,\nbrowse to the dashboard, and then click the Try BlueOcean UI button on the dashboard.\n\nWhats included?\n\nBack in April we open sourced Blue Ocean\nand shared our vision with the community. We’re very happy that all the things we showed you then have\nshipped in the beta (software projects run on time?!).\n\nFor a refresher on Blue Ocean, watch this short video:\n\nDeclarative Pipeline\n\nWe have heard from the community about the usability of Jenkins\nPipeline. Much of the feedback we received was to a desire to\nconfigure Pipelines rather than script them, and to make it easy for beginners\nto get started with their first Pipeline.\n\nThis is how Declarative Pipeline was born. We’ve introduced a new method whereby\nyou declare how you want your Pipeline to look rather than using Pipeline Script\n - it’s configuration rather than code.\n\nHere’s a small example of a Declarative Pipeline for nodejs that runs the whole\nPipeline inside a Docker container:\n\n// Declarative //\npipeline {\n  agent docker:'node:6.3'\n  stages {\n    stage('build') {\n      sh 'npm --version'\n      sh 'npm install'\n    }\n    stage ('test') {\n      sh 'npm test'\n    }\n  }\n}\n\n// Script //\nnode('docker') {\n  docker.image('node:6.3').inside {\n    stage('build') {\n      sh 'npm --version'\n      sh 'npm install'\n    }\n\n    stage('test') {\n      sh 'npm test'\n    }\n  }\n}\n\nDocker support in Declarative Pipeline allows you to version your application code,\nJenkins Pipeline configuration, and the environment where your pipeline will run,\nall in a single repository. It’s a crazy powerful combination.\n\nDeclarative Pipeline introduces the postBuild section that makes it\neasy to run things conditionally at the end of your Pipeline without the\ncomplexity of the try…​ catch of Pipeline script.\n\n// Declarative //\npostBuild {\n  always {\n    sh 'echo \"This will always run\"'\n  }\n  success {\n    sh 'echo \"This will run only if successful\"'\n  }\n  failure {\n    sh 'echo \"This will run only if failed\"'\n  }\n  unstable {\n    sh 'echo \"This will run only if the run was marked as unstable\"'\n  }\n  changed {\n    sh 'echo \"This will run only if the state of the Pipeline has changed\"'\n    sh 'echo \"For example, the Pipeline was previously failing but is now successful\"'\n    sh 'echo \"... or the other way around :)\"'\n  }\n}\n\n\n// Script //\nnode('docker') {\n  try {\n    stage('build') {\n      /* .. snip .. */\n    }\n    stage('test') {\n      /* .. snip .. */\n    }\n\n    sh 'echo \"This will run only if successful\"'\n  }\n  catch (exc) {\n    if (currentBuild.result == 'UNSTABLE') {\n      sh 'echo \"This will run only if the run was marked as unstable\"'\n    }\n    if (currentBuild.result == 'FAILURE') {\n      sh 'echo \"This will run only if failed\"'\n    }\n  }\n  finally {\n    sh 'echo \"This will always run\"'\n  }\n}\n\nAnd there is so much more!\n\nIf you have the Blue Ocean beta installed you already have Declarative Pipeline.\nWhile Declarative Pipeline is still alpha at the moment, we do encourage you to\nfollow our getting started guide,\n give us feedback on the Jenkins Users mailing list\nor file bugs against the 'pipeline-model-definition' component in JIRA.\n\nIntroducing the Pipeline Editor\n\nThe Pipeline Editor is a graphical user interface that gives Jenkins users the\nsimplest way yet to get started with creating Pipelines in Jenkins. It will also\nsave a lot of time for intermediate and advanced Jenkins users as a way to author\nPipelines.\n\nWhen you build your Pipeline in the Editor and click the save button, the editor\nwill commit a new Jenkinsfile back to your repository in the form of the new\nDeclarative Pipeline. When you want to edit again, Jenkins will read it from\nyour repository exactly how you saw it previously.\n\nThe Pipeline Editor is a work in progress and should arrive in a beta release soon.\n\nThank you\n\nThanks for reading our news from Jenkins World and be sure to check the blog\nfor regular updates!\n\nI’d also like to thank our amazing community for their feedback and support\nas we change the way software teams around the world use Jenkins. We couldn’t\ndo this without you.","title":"Announcing the Blue Ocean beta, Declarative Pipeline and Pipeline Editor","tags":["blueocean","ux","pipeline","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":null,"blog":null,"github":"i386","html":"","id":"i386","irc":null,"linkedin":null,"name":"James Dumay","slug":"/blog/authors/i386","twitter":"i386"}]}},{"node":{"date":"2016-09-09T00:00:00.000Z","id":"ebc932b1-1d9b-5ee9-80be-9c7081c78a03","slug":"/blog/2016/09/09/take-the-2016-jenkins-survey-blog/","strippedHtml":"This is a guest post by Brian\nDawson on behalf of CloudBees, where he works as a DevOps Evangelist\nresponsible for developing and sharing continuous delivery and DevOps best\npractices. He also serves as the CloudBees Product Marketing Manager for\nJenkins.\n\nOnce again it’s that time of year when CloudBees sponsors the\nJenkins Community Survey to\nassist the community with gathering objective insights into how jenkins is\nbeing used and what users would like to see in the Jenkins project.\n\nYour personal information (name, email address and company) will NOT be used by CloudBees for\nsales or marketing.\n\nAs an added incentive to take the survey, CloudBees will enter participants\ninto a drawing for a free pass to Jenkins World 2017 (1st prize) and a $100\nAmazon Gift Card (2nd prize). The survey will close at the end of September, so\nclick the link at the end of the blog post to get started!\n\nAll participants will be able to access reports summarizing survey results. If\nyou’re curious about what insights your input will provide, see the results of\nlast year’s 2015 survey:\n\n2015 Community Survey Results (PDF)\n\nState of Jenkins Infographic (PDF)\n\nYour feedback helps capture a bigger picture of\ncommunity trends and needs. There are laws that govern prize giveaways and\neligibility; CloudBees has compiled all those fancy\nterms and conditions here.\n\nPlease take the survey and let your voice be heard - it will take less than 10\nminutes.\n\nTake me to the survey","title":"Take the 2016 Jenkins Survey!","tags":["jenkins"],"authors":[{"avatar":null,"blog":null,"github":"bvdawson","html":"<div class=\"paragraph\">\n<p>DevOps dude at CloudBees.\nJenkins Marketing Manager.\nTools geek.</p>\n</div>","id":"bvdawson","irc":null,"linkedin":null,"name":"Brian Dawson","slug":"/blog/authors/bvdawson","twitter":"brianvdawson"}]}},{"node":{"date":"2016-09-08T00:00:00.000Z","id":"51fd82b2-e6d8-562f-a3a7-329013385e5a","slug":"/blog/2016/09/08/continuous-delivery-of-infra/","strippedHtml":"This is a guest post by Jenkins World speaker\nR Tyler Croy, infrastructure maintainer for the\nJenkins project.\n\nI don’t think I have ever met a tools, infrastructure, or operations team that\ndid not have a ton of work to do. The Jenkins project’s\ninfrastructure\"team\" is no different; too much work, not enough time. In lieu of hiring more\npeople, which isn’t always an option, I have found heavy automation and\ncontinuous delivery pipelines to be two solutions within reach of the\nover-worked infrastructure team.\n\nAs a big believer in the concept of \"Infrastructure as Code\", I have been,\nslowly but surely, moving the project’s infrastructure from manual tasks to\ncode, whether implemented in our\nPuppet code-base,\nDocker containers,\nor even as\nmachine specifications\nwith\nPacker.\nThe more of our infrastructure that is code, the more we can apply continuous\ndelivery practices to consistently and reliably build, test and deliver our\ninfrastructure.\n\nThis approach integrates nicely with\nJenkins Pipeline,\nallowing us to also define our continuous delivery pipelines themselves as\ncode. For example, by sanity-checking our BIND zone files:\n\nJenkinsfile\n\nnode('docker') {\n    def dockerImage = 'rtyler/jenkins-infra-builder'\n\n    checkout scm\n    docker.image(dockerImage).inside {\n        sh \"/usr/sbin/named-checkzone jenkins-ci.org dist/profile/files/bind/jenkins-ci.org.zone\"\n        sh \"/usr/sbin/named-checkzone jenkins.io dist/profile/files/bind/jenkins.io.zone\"\n    }\n}\n\nOr delivering our Docker containers automatically to\nDocker Hub, with a Jenkinsfile such as:\n\nJenkinsfile\n\nnode('docker') {\n    checkout scm\n\n    /* Get our abbreviated SHA-1 to uniquely identify this build */\n    def shortCommit = sh(script: 'git rev-parse HEAD', returnStdout: true).take(6)\n\n    stage 'Build ircbot' {\n        withEnv([\"JAVA_HOME=${tool 'jdk8'}\", \"PATH+MVN=${tool 'mvn'}/bin\"]) }\n            sh 'make bot'\n        }\n    }\n\n    def whale\n    stage 'Build container' {\n        whale = docker.build(\"jenkinsciinfra/ircbot:build${shortCommit}\")\n    }\n\n    stage 'Deploy container' {\n        /* Push to Docker Hub */\n        whale.push()\n    }\n}\n\nIn\nmy talk at Jenkins World\n(September 14th, 3:00 - 3:45pm in Exhibit Hall A-1) I will discuss these\nJenkinsfiles along with some of the strategies, patterns and code used with the\nJenkins project’s\nopen source\ninfrastructure to get the most out of the team’s limited time.\n\nR Tyler will be\npresenting\nmore about continous delivery of infrastructure at\nJenkins World\nin September.  Register with the code JWFOSS for 20% off your full conference\npass.","title":"Continuous Delivery of Infrastructure with Jenkins","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-09-07T00:00:00.000Z","id":"a11e3798-132b-51c1-b4f2-5be067a487f4","slug":"/blog/2016/09/07/pipeline-at-jenkins-world/","strippedHtml":"This is a guest post by R. Tyler Croy, who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\nCloudBees, Inc.\n\nI have been heavily using Jenkins Pipeline for just about\nevery Jenkins-related project I have contributed to over the past year. Whether I am\nbuilding and publishing Docker\ncontainers, testing\ninfrastructure code or\npublishing this very web\nsite, I have been adding a Jenkinsfile to nearly every Git repository I\ntouch.\n\nImplementing Pipeline has been rewarding, but has not been without its own\nchallenges. That’s why I’m excited to see lots of different Jenkins Pipeline\nrelated content in the agenda at\nJenkins World.\n\nI don’t think it’s possible for a single person to attend all of the Pipeline\ntalks, or the Pipeline-related demos\nin the \"Open Source Hub\", but fortunately CloudBees\nwill be recording the sessions. If you have Pipeline-related questions unanswered by\nall these presentations, feel free to join us at the \"Open Source Hub\" in the\nexpo hall and Ask the\nExperts.\n\nOn the first day of Jenkins World (September 13th), Isaac Cohen is hosting a\nworkshop titled\nLet’s\nBuild a Jenkins Pipeline which may be interesting to you if you haven’t yet\nworked with Pipeline.\n\nPipelining\nDevOps with Jenkins and AWS\n\nSeptember 14th 2:00 PM - 2:45 PM, Exhibit Hall A-1\n\nAutomated workflow is a proven method for removing process variability. DevOps\npipelines are the next step in the evolution of CI/CD/DevOps. This talk covers\nJenkins pipelines, both with and without AWS integration, and explains how\nJenkins can be used to create, execute and manage pipelines.\n\n— Jimmy Ray of nextSource\n\nPerfecting\nYour Development Tools: Updates to the Helix Plugin for Jenkins\n\nSeptember 14th 5:00 PM - 6:00 PM, Exhibit Hall C\n\nConsidering a mono repo that can manage all your source code, binary and other\nassets? Join us at the Perforce Birds of a Feather Session for updates and\ndiscussions around the Helix Plugin for Jenkins (or ‘P4 plugin’).\n\nThis session will look at the latest DSL PipeLine support in the ‘P4 plugin’\nfor Jenkins and will include a live demo. We will show you how to map your\nBranches and Streams into a Jenkins Workspace, publish assets back into\nHelix, and more. You may even get a sneak preview at the latest ‘P4 plugin’\nfor Jenkins that allows you the freedom to query and run commands from\nwithin Jenkins directly against your Helix connection.\n\n— Paul Allen of Perforce\n\nContinuously\nDeploying Containers with Jenkins Pipeline to Docker Swarm Cluster\n\nSeptember 14th 3:00 PM - 3:45 PM, Exhibit Hall A-3\n\nMany of us have already experimented with Docker - for example, by running one\nof the pre-built images from Docker Hub. It is possible that your team might\nhave recognized the benefits that Docker provides in building microservices and\nthe advantages the technology could bring to development, testing, integration\nand, ultimately, production. However, you must create a comprehensive build\npipeline before deploying any containers into a live environment. Integrating\ncontainers into a CD pipeline is far from easy. Along with the benefits Docker\nbrings, there are challenges both technically and process-related. This\npresentation attempts to outline the steps you need to take for a\nfully-automated Jenkins pipeline that continuously builds, tests and deploys\nmicroservices into a Docker Swarm cluster.\n\n— Viktor Farcic\n\nNo,\nYou Shouldn’t Do That! Lessons from Using Pipeline\n\nSeptember 15th 10:30 AM - 11:15 AM, Exhibit Hall A-1\n\nPipeline is as powerful as a loaded gun, but with skill can be as delicate as a\nsurgeon’s knife. This talk will give an overview of health and safety so that\nyou can avoid shooting yourself in the head and walk the path to medical\nschool. It will cover not only what not to do, but also why, and share some\nsolutions so you are not left high and dry. Both James and Bobby have bullet\nwounds from “Champagning” pipeline to automate the test and release of several\nof the CloudBees products and can occasionally still be seen walking with a\nlimp from shooting for the moon and hitting their feet.\n\n— Bobby Sandell and James T. Nord of CloudBees\n\nDocker\nImage Lifecycle Implemented with Jenkins Pipeline\n\nSeptember 15th 11:30 AM - 12:15 PM, Exhibit Hall A-2\n\nWhile Docker has enabled an unprecedented velocity of software production, it\nis all too easy to spin out of control. A promotion-based model is required to\ncontrol and track the flow of Docker images as much as it is required for a\ntraditional software development lifecycle. We will demonstrate how to go from\ndevelopment to containerization to distribution utilizing binary management\npromotion in a framework implemented on Jenkins, using the Pipeline\nfunctionality.\n\n— Mark Galpin\n\nDirections for Pipeline\n\nSeptember 15th 11:30 AM - 12:15 PM, Exhibit Hall A-1\n\nThe Pipeline feature has matured and is now included in Jenkins 2.0. During the\ntime since its release, copious user feedback has been received about missing\nfeatures and pain points. Come hear about some things we know should be worked\non - or are already in progress - and bring your suggestions.\n\n— Jesse Glick of CloudBees\n\nHow\nto Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes\n\nSeptember 15th 2:30 PM - 3:15 PM, Great America J\n\nIn this talk, we’ll show how to use Jenkins Pipeline together with Docker and\nKubernetes to implement a complete end-to-end continuous delivery and\ncontinuous improvement system for microservices and monolithic applications\nusing open source software. We’ll demonstrate how to easily create new\nmicroservices projects or import existing projects, have them automatically\nbuilt, system and integration tested, staged and then deployed. Once deployed,\nwe will also see how to manage and update applications using continuous\ndelivery practices along with integrated ChatOps - all completely automated!\n\n— James Strachan of Red Hat\n\nIntroducing\na New Way to Define Jenkins Pipelines\n\nSeptember 15th 3:45 PM - 4:30 PM, Great America J\n\nPipeline is quickly establishing itself as the direction that Jenkins jobs are\ngoing, enabling the definition of a complete CD pipeline in a single job;\nPipeline as Code via the “Jenkinsfile”; job durability across controller restarts;\nand more. I’ll be talking here about the next evolution for Pipeline: a simple,\ndeclarative model to define your Pipelines with no need to write scripts. This\nconfiguration syntax for Pipeline allows you to automatically configure all\nstages of your pipeline, the complete build environment, post-build actions,\nnotifications and more. All while providing syntactic and semantic validation\nbefore the build actually gets going.\n\n— Andrew Bayer of CloudBees\n\nThe\nNeed For Speed: Building Pipelines To Be Faster\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall A-1\n\nResponse time is paramount for a CI/CD system. In this session, you will see\nhow a few best practices in constructing pipelines can yield faster turnaround\ntimes and reduced resource use. We’ll also run through plugins and tools to\nanalyze and visualize performance, including the Pipeline Stage View plugin. If\ntime permits, we may briefly discuss some of the computer science theory behind\ndifferent aspects of performance.\n\n— Sam Van Oort of CloudBees\n\nContinuously Delivering\nContinuous Delivery Pipelines\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall J\n\nOur 600-person IT organization has committed to implementing continuous\ndelivery practices enterprise-wide. This isn’t a single momentous event put in\nplace overnight. Rather, it’s a strategic journey towards a common goal, and\nthrough which each application will take its own unique path. A seminal\ncomponent of our CD journey is the Pipeline plugin and it has become our\nstandard for CD pipeline orchestration. We will discuss a few of the diverse\npaths taken by the application teams at our company and show how the use of the\nPipeline plugin has uniquely enabled continuous delivery for us in a way that\nno competing tool can.\n\n— Neil Hunt of Aquilent\n\nCD Pipelines as Code with\nGithub and Bitbucket\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall J\n\nPipeline Multibranch projects come as a natural evolution of pipeline as code:\ndefine your CD pipeline in your source code repository and Jenkins will create\nisolated branch and pull requests jobs for it. This talk is about the\nintegration of the Pipeline Multibranch plugin with Github and Bitbucket as\nbranch sources.\n\n— Antonio Muñiz of CloudBees\n\nRegister for Jenkins World in\nSeptember with the code JWFOSS for a 20% discount off your pass.","title":"Pipeline at Jenkins World 2016","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-09-06T00:00:00.000Z","id":"8ad9f6bc-3bc6-5882-82e5-d2a281d96faa","slug":"/blog/2016/09/06/jenkins-world-speaker-blog-pipeline-model-definition/","strippedHtml":"This is a guest post by Jenkins World speaker Andrew Bayer, Jenkins\ndeveloper at CloudBees.\n\nOver the last couple years, Pipeline as code has very much become the future of\nJenkins - in fact, at this point, I’d say it’s pretty well established as the\npresent of Jenkins. But that doesn’t mean it’s done, let alone that it’s\nperfect. While many developers enjoy the power and control that they get from\nwriting Pipelines using scripting, not everyone feels the same way. A lot of\ndevelopers want to specify their build as configuration and get on with building\nsoftware.\n\nPipeline scripts haven’t been a good way to do that…​until now.\n\nWith new changes to Jenkins Pipeline, you are now able to define your Pipeline\nfrom configuration in your Jenkinsfile by installing the new\nPipeline Model Definition\nplugin. It’s available today for you to try via the update center.\nBe sure to check the documentation for examples on how to get started for a\nvariety of languages and platforms.\n\nHere’s a quick example based on the plugin’s own Jenkinsfile :\n\npipeline {\n    // Make sure that the tools we need are installed and on the path.\n    tools {\n        maven \"Maven 3.3.9\"\n        jdk \"Oracle JDK 8u40\"\n    }\n\n    // Run on any executor.\n    agent label:\"\"\n\n    // The order that sections are specified doesn't matter - this will still be run\n    // after the stages, even though it's specified before the stages.\n    postBuild {\n        // No matter what the build status is, run these steps. There are other conditions\n        // available as well, such as \"success\", \"failed\", \"unstable\", and \"changed\".\n        always {\n            archive \"target/**/*\"\n            junit 'target/surefire-reports/*.xml'\n        }\n    }\n\n    stages {\n        // While there's only one stage here, you can specify as many stages as you like!\n        stage(\"build\") {\n            sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n        }\n    }\n\n}\n\nIt’s still early days for this feature, with a lot of further functionality\nplanned to make it easier and more intuitive to define your Pipelines. All of\nthat functionality lives on top of Pipeline scripting, so we’ll also keep\nimproving Pipeline steps and syntax outside of the model! And perhaps most\nexciting, the Pipeline model will be used by an in-the-works visual editor\nthat will be part of the Blue Ocean project - while the editor isn’t ready yet,\nthe Pipeline Model Definition plugin will be bundled with the Blue Ocean beta\nfor you to try out.\n\nI’ll be going into all of this and more at my talk on Thursday, September 15th, at\n3:45pm at Jenkins World, and showing off the same day at the lunchtime demo\ntheater. I can’t wait to see you all there and hear what you think of all this!\n\nAndrew will be\npresenting\nmore of this concept at\nJenkins World in September.\nRegister with the code JWFOSS for 20% off your full conference pass.","title":"Introducing a New Way to Define Jenkins Pipelines","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2016-09-01T00:00:00.000Z","id":"029c2b9c-b402-58ba-b094-5060a9fa4c30","slug":"/blog/2016/09/01/jenkins-world-contributor-summit/","strippedHtml":"At previous Jenkins User Conferences we have hosted \"Contributor Summits\" to\ngather developers and power-users in one room to discuss specific areas of\nJenkins, such as Scalability, Pipeline, etc. As part of this year’s\nJenkins World we’re hosting\nanother Contributor\nSummit, to discuss: Blue Ocean ,\nPipeline and Storage Pluggability.\n\nContributors to these three areas of the Jenkins ecosystem will be in\nattendance to present details of their design, requirements, and tentative\nroadmaps. After the presentations, the afternoon will be \"unconference style\" which\nis much more fluid to allow discussions, feedback, and brain-storming around\nthe three focus areas.\n\nThe program for the\nJenkins World\nContributor Summit includes:\n\nUpdates from the various project\nofficers.\n\nA discussion of the Blue Ocean technology stack,\noverall architecture, and how to develop plugins that integrate with Blue\nOcean. Led by Keith Zantow.\n\nPresentation on the current status of Pipeline, lessons\nlearned, new changes and the future. Led by\nJesse Glick.\n\nOverview of \"Storage Pluggability\", a new scalability-oriented project to\nrevamp the underlying storage mechanisms in Jenkins. Led by\nKohsuke Kawaguchi.\n\nI cannot recommend participating in the Contributor Summit enough. I have found\nprevious Summits to be immensely useful for sharing my own thoughts, as well as\nfor hearing new perspectives from the others in attendance.\n\nOur space is limited however! I encourage you to join us, so please\nRSVP soon!\n\nRegister for Jenkins World in\nSeptember with the code JWFOSS for a 20% discount off your pass.","title":"Jenkins World Contributor Summit","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-08-31T00:00:00.000Z","id":"b54df086-f29e-5e1b-ba30-0dde098bb3d0","slug":"/blog/2016/08/31/scaling-jenkins-at-jenkins-world/","strippedHtml":"This is a guest post by R. Tyler Croy, who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\nCloudBees, Inc.\n\nI find the topic of \"scaling Jenkins\" to be incredibly interesting because,\nmore often than not, scaling Jenkins isn’t just about scaling a single instance\nbut rather scaling an organization and its continuous delivery processes. In\nmany cases when people talk about \"scaling Jenkins\" they’re talking about\n\"Jenkins as a Service\" or \"Continuous Delivery as a Service\" which introduces a\nmuch broader scope, and also more organization-specific requirements, to the\nproblem.\n\nOne of my favorite parts of a big conference like\nJenkins World is getting to\nsee how other people are solving similar problems at different organizations,\nin essence:\n\" how\nthe sausage is made.\" This year’s Jenkins World will be no different, with a number\nof sessions by developers and engineers from the companies leading the way,\nscaling continuous delivery and Jenkins.\n\nRegister for Jenkins World in\nSeptember with the code JWFOSS for a 20% discount off your pass.\n\nIn the realm of \"scaling Jenkins\" the following sessions stand-out to me as\n\"must-attend\" for those interested in the space:\n\nJenkinsOps:\nAn Initiative to Streamline and Automate Jenkins\n\nSeptember 14th 4:15 PM - 5:00 PM, Exhibit Hall A-1\n\nNPR’s Digital Media team uses Jenkins to build, test and deploy code to various\nstaging and production environments. As the complexity of the software\ncomponents, environments and tests have grown - both generally and due to our\nquest to achieve continuous deployment - management of Jenkins has become a\nchallenge. In this talk, we share information about our “JenkinsOps” effort\nwhich has allowed us to automate many of the administrative tasks necessary to\nmanage feature code branches, handle deployments, run tests and configure our\nenvironments properly.\n\n— Paul Miles and Grant Dickie of NPR\n\nThinking\nInside the Container: A Continuous Delivery Story\n\nSeptember 15th 1:30 PM - 2:15 PM, Exhibit Hall C\n\nAt Riot Games, we build a lot of software. Come learn how we built an\nintegrated Docker solution using Jenkins that accepts Docker images submitted\nas build environments by engineers around the company. Our containerized farm\nnow creates over 10,000 containers per week and handles nearly 1,000 jobs at a\nrate of about 100 jobs per hour. All this is done with readily available, open\nsource Jenkins plugins. We’ll explore lessons learned, best practices and how\nto scale and build your own system, as well as why we chose to solve the\nproblem this way…and whether or not we succeeded!\n\n— Maxfield F Stewart of Riot Games\n\nHow\nto Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes\n\nSeptember 15th 2:30 PM - 3:15 PM, Great America J\n\nIn this talk, we’ll show how to use Jenkins Pipeline together with Docker and\nKubernetes to implement a complete end-to-end continuous delivery and\ncontinuous improvement system for microservices and monolithic applications\nusing open source software. We’ll demonstrate how to easily create new\nmicroservices projects or import existing projects, have them automatically\nbuilt, system and integration tested, staged and then deployed. Once deployed,\nwe will also see how to manage and update applications using continuous\ndelivery practices along with integrated ChatOps - all completely automated!\n\n— James Strachan of Red Hat\n\nScaling\nJenkins with Docker: Swarm, Kubernetes or Mesos?\n\nSeptember 15th 2:30 PM - 3:15 PM, Exhibit Hall C\n\nThe Jenkins platform can be dynamically scaled by using several Docker cluster\nand orchestration platforms, using containers to run agents and jobs and also\nisolating job execution. But which cluster technology should be used? Docker\nSwarm? Apache Mesos? Kubernetes? How do they compare? All of them can be used\nto dynamically run jobs inside containers. This talk will cover these main\ncontainer clusters, outlining the pros and cons of each, the current state of\nthe art of the technologies and Jenkins support. I believe people will be very\ninterested in learning about the multiple options available.\n\n— Carlos Sanchez of CloudBees\n\nSo,\nYou Want to Build the World’s Biggest Jenkins Cluster?\n\nSeptember 15th 3:45 PM - 4:30 PM, Exhibit Hall C\n\nHow can we do it? We start with some real world results realized by Jenkins\nusers who have built large clusters and review how they got there. Next, we\nwill do experiments scaling some individual sub-components of Jenkins in\nisolation and see what challenges we will face when integrated. The famous\nlarge, distributed systems undoubtedly faced problems scaling - and we can\nlearn from them, too. The result will be recipes for building Jenkins\nclusters with different scaling capabilities. After all of this, you can\nbuild the biggest Jenkins cluster in the world…or maybe just make your own\nJenkins cluster more efficient.\n\n— Stephen Connolly of CloudBees\n\nJenkins at\nSplunk and Splunking Jenkins\n\nSeptember 15th 3:45 PM - 4:30 PM, Exhibit Hall A-1\n\nThis session will highlight how Splunk uses Jenkins to provide an end-to-end\nsolution in the development CI system. Attendees will see how test results are\ndelivered to a Splunk indexer, where they can be analyzed and presented in a\nvariety of ways. This session will also include a live demonstration.\n\n— Bill Houston of Splunk\n\nJenkins inside Google\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall C\n\nLast year, we presented our initial investigations and stress testing as we\nprepared to deploy a large-scale Jenkins installation at Google. Now, with a\nyear of real-world use under our belts, we’ll discuss how our expectations held\nup, what new issues we encountered and how we have addressed them.\n\n— David Hoover of Google\n\nIn addition to these, we will also be hosting a\nJenkins World\nContributor Summit where \"scaling\" relevant topics such as \"Storage\nPluggability\" will be discussed.\n\nThe Jenkins World agenda is packed\nwith even more sessions, so it should be a very informational event for\neverybody; hope to see you there!","title":"Scaling Jenkins at Jenkins World 2016","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}}]}},"pageContext":{"limit":8,"skip":368,"numPages":100,"currentPage":47}},
    "staticQueryHashes": ["3649515864"]}