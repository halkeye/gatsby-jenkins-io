{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/46",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-10-31T00:00:00.000Z","id":"dcf580a2-8de4-526e-8237-399ee53b3b39","slug":"/blog/2016/10/31/xunit-reporting/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nThe\nJUnit plugin\nis the go-to test result reporter for many Jenkins projects,\nbut the it is not the only one available.  The\nxUnit plugin\nis a viable alternative that supports JUnit and many other test result file formats.\n\nIntroduction\n\nNo matter the project, you need to gather and report test results.\nJUnit is one of the most widely supported formats for recording test results.\nFor a scenarios where your tests are stable and your framework can produce JUnit output,\nthis makes the JUnit plugin ideal for reporting results in Jenkins.\nIt will consume results from a specified file or path, create a report,\nand if it finds test failures it will set the the job state to \"unstable\" or \"failed\".\n\nThere are also plenty of scenarios where the JUnit plugin is not enough.\nIf your project has some failing tests that will take some time to fix,\nor if there are some flaky tests,\nthe JUnit plugin’s simplistic view of test failures may be difficult to work with.\n\nNo problem, the Jenkins plugin model lets us replace the JUnit\nplugin functionality with similar\nfunctionality from another plugin and Jenkins Pipeline lets us do this in safe\nstepwise fashion where we can test and debug each of our changes.\n\nIn this article, I will show you how to replace the JUnit plugin with the\nxUnit plugin in Pipeline code to address a few common test reporting scenarios.\n\nInitial Setup\n\nI’m going to use the \"JS-Nightwatch.js\" sample project from my\nprevious post to demonstrate a couple\ncommon scenarios that the xUnit handles better.\nI already have the latest\nJUnit plugin\nand\nxUnit plugin\ninstalled on my Jenkins server.\n\nI’ll be keeping my changes in\nlink: my fork\nof the \"JS-Nightwatch.js\" sample project on GitHub, under the\n\" blog/xunit\" branch.\n\nHere’s what the Jenkinsfile looked like at the end of that previous post and what\nthe report page looks like after a few runs:\n\nJenkinsfile\n\nnode {\n    stage \"Build\"\n    checkout scm\n\n    // Install dependencies\n    sh 'npm install'\n\n    stage \"Test\"\n    // Add sauce credentials\n    sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n        // Start sauce connect\n        sauceconnect(options: '', useGeneratedTunnelIdentifier: false, verboseLogging: false) {\n\n            // List of browser configs we'll be testing against.\n            def platform_configs = [\n                'chrome',\n                'firefox',\n                'ie',\n                'edge'\n            ].join(',')\n\n            // Nightwatch.js supports color ouput, so wrap this step for ansi color\n            wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm']) {\n                // Run selenium tests using Nightwatch.js\n                // Ignore error codes. The junit publisher will cover setting build status.\n                sh \"./node_modules/.bin/nightwatch -e ${platform_configs} || true\"\n            }\n\n            junit 'reports/**'\n\n            step([$class: 'SauceOnDemandTestPublisher'])\n        }\n    }\n}\n\nSwitching from JUnit to xUnit\n\nI’ll start by replacing JUnit with xUnit in my pipeline.\nI use the Snippet Generator to create the step with the right parameters.\nThe main downside of using the xUnit plugin is that while it is Pipeline compatible,\nit still uses the more verbose step() syntax and has some very rough edges around that, too.\nI’ve filed\nJENKINS-37611\nbut in the meanwhile, we’ll work with what we have.\n\n// Original JUnit step\njunit 'reports/**'\n\n// Equivalent xUnit step - generated (reformatted)\nstep([$class: 'XUnitBuilder', testTimeMargin: '3000', thresholdMode: 1,\n    thresholds: [\n        [$class: 'FailedThreshold', failureNewThreshold: '', failureThreshold: '', unstableNewThreshold: '', unstableThreshold: '1'],\n        [$class: 'SkippedThreshold', failureNewThreshold: '', failureThreshold: '', unstableNewThreshold: '', unstableThreshold: '']],\n    tools: [\n        [$class: 'JUnitType', deleteOutputFiles: false, failIfNotNew: false, pattern: 'reports/**', skipNoTestFiles: false, stopProcessingIfError: true]]\n    ])\n\n// Equivalent xUnit step - cleaned\nstep([$class: 'XUnitBuilder',\n    thresholds: [[$class: 'FailedThreshold', unstableThreshold: '1']],\n    tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\nIf I replace the junit step in my Jenkinsfile with that last step above,\nit produces a report and job result identical to the JUnit plugin but using the xUnit plugin.  Easy!\n\nnode {\n    stage \"Build\"\n    // ... snip ...\n\n    stage \"Test\"\n    // Add sauce credentials\n    sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n        // Start sauce connect\n        sauceconnect(options: '', useGeneratedTunnelIdentifier: false, verboseLogging: false) {\n\n            // ... snip ...\n\n            // junit 'reports/**'\n            step([$class: 'XUnitBuilder',\n                thresholds: [[$class: 'FailedThreshold', unstableThreshold: '1']],\n                tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n            // ... snip ...\n        }\n    }\n}\n\nAccept a Baseline\n\nMost projects don’t start off with automated tests passing or even running.\nThey start with a people hacking and prototyping, and eventually they start to write tests.\nAs new tests are written, having tests checked-in, running, and failing can be valuable information.\nWith the xUnit plugin we can accept a baseline of failed cases and drive that number down over time.\n\nI’ll start by changing the Jenkinsfile to fail jobs only if the number of failures is greater than an expected baseline,\nin this case four failures. When I run the job with this change, the reported numbers remain the same, but the job passes.\n\nJenkinsfile\n\n// The rest of the Jenkinsfile is unchanged.\n// Only the xUnit step() call is modified.\nstep([$class: 'XUnitBuilder',\n    thresholds: [[$class: 'FailedThreshold', failureThreshold: '4']],\n    tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\nNext, I can also check that the plugin reports the job as failed if more failures occur.\nSince this is sample code, I’ll do this by adding another failing test and checking the job\nreports as failed.\n\ntests/guineaPig.js\n\n// ... snip ...\n\n    'Guinea Pig Assert Title 0 - D': function(client) { /* ... */ },\n\n    'Guinea Pig Assert Title 0 - E': function(client) {\n        client\n            .url('https://saucelabs.com/test/guinea-pig')\n            .waitForElementVisible('body', 1000)\n            //.assert.title('I am a page title - Sauce Labs');\n            .assert.title('I am a page title - Sauce Labs - Cause a Failure');\n    },\n\n    afterEach: function(client, done) { /* ... */ }\n\n// ... snip ...\n\nIn a real project, we’d make fixes over a number of commits bringing the number of failures down and adjusting our baseline.\nSince this is a sample, I’ll just make all tests pass and set the job failure threshold for failed and skipped cases to zero.\n\nJenkinsfile\n\n// The rest of the Jenkinsfile is unchanged.\n// Only the xUnit step() call is modified.\nstep([$class: 'XUnitBuilder',\n    thresholds: [\n        [$class: 'SkippedThreshold', failureThreshold: '0'],\n        [$class: 'FailedThreshold', failureThreshold: '0']],\n    tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\ntests/guineaPig.js\n\n// ... snip ...\n\n    'Guinea Pig Assert Title 0 - D': function(client) { /* ... */ },\n\n    'Guinea Pig Assert Title 0 - E': function(client) {\n        client\n            .url('https://saucelabs.com/test/guinea-pig')\n            .waitForElementVisible('body', 1000)\n            .assert.title('I am a page title - Sauce Labs');\n    },\n\n    afterEach: function(client, done) { /* ... */ }\n\n// ... snip ...\n\ntests/guineaPig_1.js\n\n// ... snip ...\n\n    'Guinea Pig Assert Title 1 - A': function(client) {\n        client\n            .url('https://saucelabs.com/test/guinea-pig')\n            .waitForElementVisible('body', 1000)\n            .assert.title('I am a page title - Sauce Labs');\n    },\n\n// ... snip ...\n\nAllow for Flakiness\n\nWe’ve all known the frustration of having one flaky test that fails once every ten jobs.\nYou want to keep it active so you can working isolating the source of the problem,\nbut you also don’t want to destablize your CI pipeline or reject commits that are actually okay.\nYou could move the test to a separate job that runs the \"flaky\" tests,\nbut in my experience that just leads to a job that is always in a failed state\nand a pile of flaky tests no one looks at.\n\nWith the xUnit plugin, we can keep the this flaky test in main test suite but allow\nthe our job to still pass.\n\nI’ll start by adding a sample flaky test.  After a few runs, we can see the test\nfails intermittently and causes the job to fail too.\n\ntests/guineaPigFlaky.js\n\n// New test file: tests/guineaPigFlaky.js\nvar https = require('https');\nvar SauceLabs = require(\"saucelabs\");\n\nmodule.exports = {\n\n    '@tags': ['guineaPig'],\n\n    'Guinea Pig Flaky Assert Title 0': function(client) {\n        var expectedTitle = 'I am a page title - Sauce Labs';\n        // Fail every fifth minute\n        if (Math.floor(Date.now() / (1000 * 60)) % 5 === 0) {\n            expectedTitle += \" - Cause failure\";\n        }\n\n        client\n            .url('https://saucelabs.com/test/guinea-pig')\n            .waitForElementVisible('body', 1000)\n            .assert.title(expectedTitle);\n    }\n\n    afterEach: function(client, done) {\n        client.customSauceEnd();\n\n        setTimeout(function() {\n            done();\n        }, 1000);\n\n    }\n\n};\n\nI can almost hear my teammates screaming in frustration just looking at this report.\nTo allow specific tests to be unstable but not others,\nI’m going to add a guard \"suite completed\" test to the suites that should be stable,\nand keep flaky test on it’s own.\nThen I’ll tell xUnit to allow for a number of failed tests, but no skipped ones.\nIf any test fails other than the ones I allow to be flaky,\nit will also result in one or more skipped tests and will fail the build.\n\n// The rest of the Jenkinsfile is unchanged.\n// Only the xUnit step() call is modified.\nstep([$class: 'XUnitBuilder',\n    thresholds: [\n        [$class: 'SkippedThreshold', failureThreshold: '0'],\n        // Allow for a significant number of failures\n        // Keeping this threshold so that overwhelming failures are guaranteed\n        //     to still fail the build\n        [$class: 'FailedThreshold', failureThreshold: '10']],\n    tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\ntests/guineaPig.js\n\n// ... snip ...\n\n    'Guinea Pig Assert Title 0 - E': function(client) { /* ... */ },\n\n    'Guinea Pig Assert Title 0 - Suite Completed': function(client) {\n      // No assertion needed\n    },\n\n    afterEach: function(client, done) { /* ... */ }\n\n// ... snip ...\n\ntests/guineaPig_1.js\n\n// ... snip ...\n\n    'Guinea Pig Assert Title 1 - E': function(client) { /* ... */ },\n\n    'Guinea Pig Assert Title 1 - Suite Completed': function(client) {\n      // No assertion needed\n    },\n\n    afterEach: function(client, done) { /* ... */ }\n\n// ... snip ...\n\nAfter a few more runs, you can see the flaky test is still being flaky,\nbut it is no longer failing the build.  Meanwhile, if another test fails,\nit will cause the \"suite completed\" test to be skipped, failing the job.\nIf this were a real project, the test owner could instrument and eventually fix\nthe test.  When they were confident they had stabilized the test the could add\na \"suite completed\" test after it to enforce it passing without changes to other\ntests or framework.\n\nConclusion\n\nThis post has shown how to migrate from the JUnit plugin to the\nxUnit plugin on an existing project in Jenkins pipeline.  It also covered how to\nuse the features of xUnit plugin to get more meaningful and effective Jenkins\nreporting behavior.\n\nWhat I didn’t show was how many other formats xUnit supports - from CCPUnit to MSTest.  You can\nalso write your own XSL for result formats not on the known/supported list.\n\nLinks\n\nxUnit plugin\n\nbitwiseman/JS-Nightwatch.js\n\nsaucelabs-sample-test-frameworks","title":"xUnit and Pipeline","tags":["pipeline","plugins","xunit","nightwatch"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-10-18T00:00:00.000Z","id":"225fd884-7b63-5638-9d0e-c7a57c82002b","slug":"/blog/2016/10/18/jenkins-world-2016-videos/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nThe videos of the sessions from\nJenkins World 2016 are up!\n\nI’ve updated the wrap-up posts with links to each of the sessions mentioned:\n\nJenkins Pipeline\n\nScaling Jenkins\n\nAsk the Experts & Demos\n\nYou can also find video from all the sessions\nhere.  Enjoy!","title":"Jenkins World 2016 Session Videos","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-10-16T00:00:00.000Z","id":"1b6c5cc3-a7d6-56f2-91fc-f717ed4f85fc","slug":"/blog/2016/10/16/stage-lock-milestone/","strippedHtml":"This is a guest post by Patrick Wolf,\nDirector of Product Management at CloudBees.\n\nRecently the Pipeline team began making several changes to improve the stage step and increase control of concurrent builds in Pipeline. Until now the stage step has been the catch-all for functionality related to the flow of builds through the Pipeline: grouping build steps into visualized stages, limiting concurrent builds, and discarding stale builds.\n\nIn order to improve upon each of these areas independently we decided to break this functionality into discrete steps rather than push more and more features into an already packed stage step.\n\nstage - the stage step remains but is now focused on grouping steps and providing boundaries for Pipeline segments.\n\nlock - the lock step throttles the number of concurrent builds in a defined section of the Pipeline.\n\nmilestone - the milestone step automatically discards builds that will finish out of order and become stale.\n\nSeparating these concerns into explicit, independent steps allows for much greater control of Pipelines and broadens the set of possible use cases.\n\nStage\n\nThe stage step is a primary building block in Pipeline, dividing the steps of a Pipeline into explicit units and helping to visualize the progress using the \"Stage View\" plugin or\"Blue Ocean\". Beginning with version 2.2 of \"Pipeline Stage Step\" plugin, the stage step now requires a block argument, wrapping all steps within the defined stage. This makes the boundaries of where each stage begins and ends obvious and predictable. In addition, the concurrency argument of stage has now been removed to make this step more concise; responsibility for concurrency control has been delegated to the lock step.\n\nstage('Build') {\n  doSomething()\n  sh \"echo $PATH\"\n}\n\nOmitting the block from stage and using the concurrency argument are now deprecated in Pipeline. Pipelines using this syntax will continue to function but will produce a warning in the console log:\n\nUsing the 'stage' step without a block argument is deprecated\n\nThis message is only a reminder to update your Pipeline scripts; none of your Pipelines will stop working. If we reach a point where the old syntax is to be removed we will make an announcement prior to the change. We do, however, recommend that you update your existing Pipelines to utilize the new syntax.\n\nnote: Stage View and Blue Ocean will both work with either the old stage syntax or the new.\n\nLock\n\nRather than attempt to limit the number of concurrent builds of a job using the stage, we now rely on the \"Lockable Resources\" plugin and the lock step to control this. The lock step limits concurrency to a single build and it provides much greater flexibility in designating where the concurrency is limited.\n\nlock can be used to constrain an entire stage or just a segment:\n\nstage('Build') {\n  doSomething()\n  lock('myResource') {\n    echo \"locked build\"\n  }\n}\n\nlock can be also used to wrap multiple stages into a single concurrency unit:\n\nlock('myResource') {\n  stage('Build') {\n    echo \"Building\"\n  }\n  stage('Test') {\n    echo \"Testing\"\n  }\n}\n\nMilestone\n\nThe milestone step is the last piece of the puzzle to replace functionality originally intended for stage and adds even more control for handling concurrent builds of a job. The lock step limits the number of builds running concurrently in a section of your Pipeline while the milestone step ensures that older builds of a job will not overwrite a newer build.\n\nConcurrent builds of the same job do not always run at the same rate. Depending on the network, the node used, compilation times, test times, etc. it is always possible for a newer build to complete faster than an older build. For example:\n\nBuild 1 is triggered\n\nBuild 2 is triggered\n\nBuild 2 builds faster than Build 1 and enters the Test stage sooner.\n\nRather than allowing Build 1 to continue and possibly overwrite the newer artifact produced in Build 2, you can use the milestone step to abort Build 1:\n\nstage('Build') {\n  milestone()\n  echo \"Building\"\n}\nstage('Test') {\n  milestone()\n  echo \"Testing\"\n}\n\nWhen using the input step or the lock step a backlog of concurrent builds can easily stack up, either waiting for user input or waiting for a resource to become free. The milestone step will automatically prune all older jobs that are waiting at these junctions.\n\nmilestone()\ninput message: \"Proceed?\"\nmilestone()\n\nBookending an input step like this allows you to select a specific build to proceed and automatically abort all antecedent builds.\n\nmilestone()\nlock(resource: 'myResource', inversePrecedence: true) {\n  echo \"locked step\"\n  milestone()\n}\n\nSimilarly a pair of milestone steps used with a lock will discard all old builds waiting for a shared resource. In this example, inversePrecedence: true instructs the lock to begin most recent waiting build first, ensuring that the most recent code takes precedence.\n\nPutting it all together\n\nEach of these steps can be used independently of the others to control one aspect of a Pipeline or they can be combined to provide powerful, fine-grained control of every aspect of multiple concurrent builds flowing through a Pipeline. Here is a very simple example utilizing all three:\n\nstage('Build') {\n  // The first milestone step starts tracking concurrent build order\n  milestone()\n  node {\n    echo \"Building\"\n  }\n}\n\n// This locked resource contains both Test stages as a single concurrency Unit.\n// Only 1 concurrent build is allowed to utilize the test resources at a time.\n// Newer builds are pulled off the queue first. When a build reaches the\n// milestone at the end of the lock, all jobs started prior to the current\n// build that are still waiting for the lock will be aborted\nlock(resource: 'myResource', inversePrecedence: true){\n  node('test') {\n    stage('Unit Tests') {\n      echo \"Unit Tests\"\n    }\n    stage('System Tests') {\n      echo \"System Tests\"\n    }\n  }\n  milestone()\n}\n\n// The Deploy stage does not limit concurrency but requires manual input\n// from a user. Several builds might reach this step waiting for input.\n// When a user promotes a specific build all preceding builds are aborted,\n// ensuring that the latest code is always deployed.\nstage('Deploy') {\n  input \"Deploy?\"\n  milestone()\n  node {\n    echo \"Deploying\"\n  }\n}\n\nFor a more complete and complex example utilizing all these steps in a Pipeline check out the Jenkinsfile provided with the Docker image for demonstrating Pipeline. This is a working demo that can be quickly set up and run.","title":"Controlling the Flow with Stage, Lock, and Milestone","tags":["pipeline","newfeatures"],"authors":[{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"/blog/authors/hrmpw","twitter":"hrmpw"}]}},{"node":{"date":"2016-09-30T00:00:00.000Z","id":"868e7958-3c45-5b27-8d18-435c005e0771","slug":"/blog/2016/09/30/jenkins-world-2016-wrap-up-complete/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nThis year’s Jenkins World conference\nwas a huge milestone for the Jenkins project - the first global event for the Jenkins community.\nIt brought users and contributors together to exchange ideas on the current state\nof the project, celebrate accomplishments of the past year, and look ahead at all the exiting enhancements\ncoming down the pipe(line).\n\nContributor Summit\n\nTo kick off Jenkins World, we had a full day \"Contributor Summit\".\nJenkins is a distributed project with contributors from all over the globe.\nConferences like this are perfect time to get contributors together face-to-face,\nto talk through current issues and upcoming plans for the the project.\nSome key topics discussed during this summit were:\n\nInfrastructure - In the past year, the Jenkins project has moved new domain name,\na statically generated website, and has entered a\npartnership with Microsoft\nto host to host infrastructure on Azure.\n\nEvents - A year ago, there were five\nJenkins Area Meetups, today there are 37 around the\nworld, with ~7000 members.\n\nSecurity - Daniel Beck has done a great job a \"Security Officer\" for the project over the last year.\nJenkins 2 includes tighter security out of the box, 9 security alerts have been addressed, and the\nSecurity Team is continuing to evaluate threats as they are reported.\n\nPipeline - Pipeline has been a success and there many improvements on the way, including better\nPipeline Library support, a UI-based Pipeline Editor, and Declarative Pipeline syntax.\n\nBlue Ocean - Blue Ocean announced their \"1.0 Beta\" release and discussed their roadmap.\n\nStorage Pluggability - One of the big upcoming goals is reducing Jenkins'\ndependence on local file system storage on the server system\n(job configuration, build logs, etc.).  There was extensive\ndiscussion of how to accomplish this goal.\n\nKeynote: The State of Jenkins 2016\n\nThe next day,\nKohsuke gave a great\nkeynote,\nshowing how far the project as come this year and where it is headed.\nYou can get the slides\nhere\nor see the full video below.\n\nWhat’s Next?\n\nOverall, Jenkins World was a very enjoyable event. I’m sure everyone came away having\nlearned a lot and made many new connections.  I know I’m excited to see\nwhat the coming year brings for Jenkins and the Jenkins community.\n\nDon’t forget that there are many ways to continue\nto build connections to the rest of the Jenkins community throughout the year, such as the\nJenkins Online Meetup which\nhosts online events year-round.  Or, see if there is a\nJenkins Area Meetup (JAM) near you.  If\nthere isn’t, take a look at the\nJenkins Area Meetup page to see about starting one.\n\nThanks, and I hope to see you all and Jenkins World 2017!","title":"Jenkins World 2016, That's a Wrap!","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-09-29T00:00:00.000Z","id":"e21157bd-374b-5814-a345-a0163473ab62","slug":"/blog/2016/09/29/jenkins-world-2016-wrap-up-experts-demos/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nAs I mentioned in my\nprevious post,\nJenkins World brought together\nJenkins users from organizations of all sizes.  It also brought together Jenkins\nusers of all skill levels; from beginners to experts (including to JAM\norganizers, board members, and long time contributors).  A number\nof those experts also volunteered to staff the Open Source Hub’s\n\"Ask the Experts\" desk throughout the conference to answer Jenkins questions.\nThis included, but was not limited to:\nPaul Allen,\nR Tyler Croy,\nJames Dumay,\nJesse Glick,\nEddú Meléndez Gonzales,\nJon Hermansen,\nOwen Mehegan,\nOleg Nenashev,\nLiam Newman,\nChristopher Orr,\nCasey Vega,\nMark Waite,\nDean Yu,\nand\nKeith Zantow.\n\nI actually chose to spend the majority of my time at the booth. It was\nfantastic to hear all the different ways people are using\nJenkins and wanting use Jenkins to do even more. I answered dozens of questions\non both days of the conference, often learning new things in the process of answering them.\nAnd for questions that were beyond any one person’s knowledge, there was such a\nbreadth of expertise, very few questions were beyond our combined abilities.\n\nWhile \"Ask the Experts\" saw a lot traffic, the Open Source Hub’s lunch-time demos drew\nreally big crowds. They covered wide range of subjects in a quick succession and offered people\na chance to be introduced to new areas of in Jenkins without spending a whole session on them.\nSome demos were only presented at lunch while others were abbreviated versions of\nlonger talks presented at other times during the conference.  Here’s the full list with related links:\n\nKeith Zantow gave a live demo of\nBlue Ocean in Action on their\nlive Jenkins instance.\n\nChristopher Orr presented a lightning version of his talk\nPipelines for building and deploying Android apps\n( Slides)\n( video).\n\nOleg Nenashev showed a different way to\nmanage security with the\nOwnership plugin for Jenkins\n( Slides).\n\nAlex Somai presented his\nGoogle Summer of Code (GSoC) 2016 project, the\nExternal Workspace Manager plugin for Jenkins Pipeline ( GSOC Video).\n\nMark Waite discussed\nGit plugin - large repos, submodule authentication and more\n( Slides).\n\nLiam Newman gave a live demo of\nNotifications with Jenkins Pipeline\n(based on this blog post).\n\nJesse Glick talked about\nExtending Pipeline with Libraries using the\nPipeline Shared Groovy Libraries Plugin\n\nJon Hermansen demonstrated some cool ways to use\nMultibranch Pipelines + Git symbolic-ref to optimize build times.\n\nR Tyler Croy showed the power of\nDocker and Pipeline\n( Slides)\n\nR Tyler Croy also showed how easy it can be to migrate from\nFreestyle to Pipeline\n( Slides)\n\nCasey Vega gave a live demo,\npackage.json and Jenkins, on using package.json to control all aspects of Jenkins builds.\n\nAndrew Bayer presented at lightning version of his talk,\nA simpler way to define Jenkins Pipelines\n( Slides)\n( Video).\n\nThank you to everyone who staffed the booth and gave demos.\n\nAlso, thanks to everyone who attended the demos and came by to ask questions.\nIf you have more questions, you don’t have to wait until next year’s Jenkins World.\nJoin the\njenkinsci-users mailing list or the\n#jenkins IRC channel to\nget help from experts around the world.\n\nAnd finally, a special thanks to the Jenkins Events officer, Alyssa Tong,\nfor getting the entire booth designed, prepared, and keeping everything\non track before, during, and after the conference.","title":"Jenkins World 2016 Wrap-up - Ask the Experts & Demos","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-09-27T00:00:00.000Z","id":"e7da6d48-fbaf-5549-9581-1b1cb3ddf4f6","slug":"/blog/2016/09/27/jenkins-world-2016-wrap-up-scaling/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nOne of the great features of Jenkins is how far it\ncan scale, not only from a software perspective, but also from an\norganizational one.  From a single Jenkins controller with one or two agents to a\nmultiple controller with thousands of agents, from a team of only a few people\nto a whole company with multiple disparate departments and organizations,\nyou’ll find space where Jenkins is used.\n\nLike any software or organization,\nthere are common challenges for increasing scale with Jenkins and some common best practices, but\nthere are also some unique solutions.  A big conference like\nJenkins World brings users\nfrom all scales together to see how people in other organizations at similar or\ngreater scale are solving similar problems.\n\nHere’s a recap of the some of the sessions on scaling Jenkins,\nwith links to slides and videos shared by CloudBees :\n\nPaul Miles and\nGrant Dickie of\nNPR talked about\nJenkinsOps: An Initiative to Streamline and Automate Jenkins .\nThey shared ways their team has used Jenkins to automate many of the\nadministrative tasks related to managing feature code branches,\nhandling deployments, running tests, and properly configuring their environments.\nThey also showed code samples and talked about future challenges in their quest\nto achieve\ncontinuous deployment.\n\nDownload Presentation\n\nStream Presentation\n\nMaxfield F Stewart of\nRiot Games showed how they built an\nintegrated Docker solution using Jenkins in\nThinking Inside the Container: A Continuous Delivery Story\nHe showed how their system allows engineers around the company to\nsubmit Docker images as build environments.\nThis has let their containerized farm now create over 10,000 containers per week\nand handles nearly 1,000 jobs at a rate of about 100 jobs per hour.\nAnd they have done this using readily available, open\nsource Jenkins plugins. He also talked about how they settled on this design,\nlessons learned, best practices, and how to build and scale other similar system.\n\nDownload Presentation\n\nStream Presentation\n\nHow to Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes ,\npresented by\nJames Strachan of\nRed Hat, showed how to use Jenkins Pipeline with\nDocker and Kubernetes to implement a complete end-to-end continuous delivery and\ncontinuous improvement system using open source software for both microservices\nand monolithic applications. He demonstrated how to\ncreate or import projects, and have them automatically build, run\nsystem and integration tests, stage, and finally deploy. He also showed to\nmanage and update those deployed applications using continuous\ndelivery practices.\n\nDownload Presentation\n\nWatch the Video Demo from the Presentation\n\nCarlos Sanchez of\nCloudBees discussed\nScaling Jenkins with Docker: Swarm, Kubernetes or Mesos?\nHe compared various Docker Swarm, Apache Mesos, and Kubernetes in terms of their\nability to dynamically scale in Jenkins by running jobs inside containers.\nHe also discussed the pros and cons, best practices, level of Jenkins support for each\nof these technologies.\n\nDownload Presentation\n\nStream Presentation\n\nStephen Connolly of\nCloudBees asked\n\" So, You Want to Build the World’s Biggest Jenkins Cluster? \"\nand explained how to do so.  He started with\nreal world results realized by Jenkins users who have built large clusters.\nNext, he showed experiments around scaling some individual sub-components of Jenkins in\nisolation to see what challenges have been faced when integrated. Finally,\nhe arrived at recipes for building Jenkins clusters with different scaling capabilities and\nmaking existing Jenkins clusters more efficient.\n\nDownload Presentation\n\nStream Presentation\n\nBill Houston and\nAli Raza of\nSplunk\ngave a talk in two parts,\nJenkins at Splunk and Splunking Jenkins\nIn the first part, Bill showed how Splunk uses Jenkins to implement their end-to-end CI system.\nThey discussed features and design goals, challenges they encountered, and how they addressed\nthese challenges.\nIn the second part, Ali showed how to use the Jenkins Splunk plugin.  Using plugin, he gathered\ntest results and Jenkins environment data, and delivered it to a Splunk indexer for analysis and presentation.\n\nDownload Presentation\n\nStream Presentation\n\nDavid Hoover of\nGoogle talked about\nJenkins inside Google .\nLast year, they\npresented\ntheir initial investigations and stress testing as they\nprepared to deploy a large-scale Jenkins installation at Google. Now, with a\nyear of real-world use under their belts, they returned to present on how their\nexpectations held up, what new issues they encountered, how they have addressed those issues, and\nthe challenges and opportunities they see ahead.\n\nDownload Presentation\n\nStream Presentation","title":"Jenkins World 2016 Wrap-up - Scaling","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-09-24T00:00:00.000Z","id":"1f3da69f-0fed-5d62-bb32-d769047f8abb","slug":"/blog/2016/09/24/jenkins-world-2016-wrap-up-pipeline/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nAs someone who has managed Jenkins for years and manually managed jobs, I think\npipeline is fantastic. I spent much of the conference manning the\nAsk the Experts desk of the\n\"Open Source Hub\" and was glad to find I was not alone in that sentiment.\nThe questions were not \"Why should I use Pipeline?\", but \"How do I do this in Pipeline?\"\n\nEveryone was interested in showing what they have been able to accomplish,\nlearning about best practices, and seeing what new features were on the horizon.\nThe sessions and demos on Pipeline that\nI saw were all well attended, but no one could have seen all of them.\n\nHere’s a recap of the some of the sessions on Jenkins Pipeline,\nwith links to slides and videos shared by CloudBees :\n\nJesse Glick discussed the past, present, and future of Jenkins Pipeline in\nDirections for Pipeline .\nHe reviewed a broad range of improvements made to Pipeline over the last year, including\nsyntax, documentation, plugin support, and stability.  He reviewed the changes\ncurrently underway.  He also pointed out that many of the improvements have been\ndriven by user feedback and invited everyone to continue to participate in making\npipeline even better.\n\nDownload Presentation\n\nStream Presentation\n\nIn\nPipelining DevOps with Jenkins and AWS ,\nJimmy Ray\nof\nnextSource showed how Pipeline can be used to automate CI/CD build processes,\nand how to integrate Jenkins and Pipeline with AWS.\nHe also discussed some admin-level considerations,\nsuch as how to install Jenkins on EC2\nand the merits of \"LTS\" and \"latest build\".\n\nDownload Presentation\n\nStream Presentation\n\nChristopher Orr examined how to create\n\" Continuous Build and Delivery Pipelines for Android \"\napplications.\nHe showed how to set up Android-capable build agents, ensure traceable application releases,\nreporting warnings, run various types of tests, and deploy and app to Google Play.\nThis included live demonstrations and discussion of best practices.\n\nDownload Presentation\n\nStream Presentation\n\nAndrew Bayer presented\nA New Way to Define Jenkins Pipelines .\nHe showed the next evolution for Pipeline, based on a simpler declarative model.\nThis declarative syntax for Pipeline still supports the creation of complex pipelines,\nincluding complete build environments, post-build actions, and notifications, while\nalso being easier to understand. This declarative syntax also makes in it easier to\nimplement other interesting scenarios such as early validation of pipelines and\na visual pipeline editor.\n\nDownload Presentation\n\nStream Presentation\n\nIn\nPerfecting Your Development Tools: Updates to the Helix Plugin for Jenkins ,\nPaul Allen of\nPerforce walked through using Perforce’s \"Monorepo\" model with Jenkins Pipeline.\nHe explained in detail how to work with the Perforce\"P4\" plugin in Jenkins,\nincluding credential passing and workspace management.\nOf particular interest was his side-by-side comparison the various actions done with the Jenkins UI vs Pipeline.\n\nDownload Presentation\n\nSam Van Oort\ndemonstrated strategies for faster pipelines in\nThe Need For Speed: Building Pipelines To Be Faster .\nHe discussed various elements that contribute to making pipelines faster or slower,\nsuch a number of resources and latency.  He then showed several best practices\nfor constructing pipelines that have lower turnaround times and reduced resource use.\nHe also reviewed plugins and tools that can help analyze and visualize pipeline\nperformance, including the Pipeline Stage View plugin and Blue Ocean.\n\nDownload Presentation\n\nStream Presentation\n\nBobby Sandell and\nJames T. Nord talked about what not to do with Pipeline in\nNo, You Shouldn’t Do That! Lessons from Using Pipeline .\nThey told the story of their own experiences as early adopters of\nJenkins Pipeline at CloudBees. They described a number of key scenarios they attempted\nto address, detailed various mistakes and false starts, and finally share what\nthey learned in each case.\n\nDownload Presentation\n\nStream Presentation\n\nAlexandru Somai gave a\nlightning talk on his\nGoogle Summer of Code (GSoC) 2016 project,\n\" External Workspace Manager Plugin for Jenkins Pipeline\".\nThe build workspace for Jenkins projects may become very large.\nAlex showed how the External Workspace Manager plugin addresses this issue,\nadding support for managing and reusing the same workspace between multiple pipeline builds.\n\nA recording of his presentation for GSOC is available\nhere.\n\nHow to Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes ,\npresented by\nJames Strachan of\nRed Hat, showed how to use Jenkins Pipeline with\nDocker and Kubernetes to implement a complete end-to-end continuous delivery and\ncontinuous improvement system using open source software for both microservices\nand monolithic applications. He demonstrated how to\ncreate or import projects, and have them automatically build, run\nsystem and integration tests, stage, and finally deploy. He also showed to\nmanage and update those deployed applications using continuous\ndelivery practices.\n\nDownload Presentation\n\nStream Demo Video","title":"Jenkins World 2016 Wrap-up - Pipeline","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-09-21T00:00:00.000Z","id":"00f2fadc-e637-58e5-9db3-eb9874add2cf","slug":"/blog/2016/09/21/jenkins-world-2016-wrap-up/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nThat’s a Wrap!\n\nAny way you look at it, last week’s Jenkins World Conference 2016 was a huge success.\n\nIn 2011, a few hundred users gathered in San Francisco for the first \"Jenkins User Conference\".\nOver successive years, this grew into several yearly regional Jenkins user conferences.\nThis year, over 1,300 people came from around the world to \"Jenkins World 2016\",\nthe first global event for the Jenkins community.\n\nThis year’s Jenkins World conference included:\n\nKeynote presentation by Jenkins creator, Kohsuke Kawaguchi, announcing a number of great new Jenkins project features, such as \"Blue Ocean\".\n\nMore than 50 sessions on everything from the new \"Blue Ocean\" UI, to \"Continuous Security\" to \"Dockerizing Jenkins\".\n\nJenkins Open-source Hub, with \"Ask the Experts\" and demos by 20+ Jenkins contributors.\n\nBooths from 30+ sponsors.\n\nStickers!\n\nOver the next week, I’ll be posting highlights from the event,\nincluding slides, videos, and links to other useful resources.  Stay tuned!","title":"Jenkins World 2016 Wrap-up - Introduction","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"limit":8,"skip":360,"numPages":100,"currentPage":46}},
    "staticQueryHashes": ["3649515864"]}