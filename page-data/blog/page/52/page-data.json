{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/52",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-05-25T00:00:00.000Z","id":"3bdee89e-566b-52d9-a3cc-f41507becadc","slug":"/blog/2016/05/25/update-plugin-for-pipeline/","strippedHtml":"This is a guest post by Chris Price.\nChris is a software engineer at Puppet, and has been\nspending some time lately on automating performance testing using the latest\nJenkins features.\n\nIn this blog post, I’m going to attempt to provide some step-by-step notes on\nhow to refactor an existing Jenkins plugin to make it compatible with the new\nJenkins Pipeline jobs.  Before we get to the fun stuff, though, a little\nbackground.\n\nHow’d I end up here?\n\nRecently, I started working on a project to automate some performance tests for\nmy company’s products.  We use the awesome Gatling load\ntesting tool for these tests, but we’ve largely been handling the testing very\nmanually to date, due to a lack of bandwidth to get them automated in a clean,\nmaintainable, extensible way.  We have a years-old Jenkins server where we use\nthe gatling jenkins\nplugin to track the\nhistory of certain tests over time, but the setup of the Jenkins instance was\nvery delicate and not easy to reproduce, so it had fallen into a state of\ndisrepair.\n\nOver the last few days I’ve been putting some effort into getting things more\nautomated and repeatable so that we can really maximize the value that we’re\ngetting out of the performance tests.  With some encouragement from the fine\nfolks in the #jenkins IRC channel, I ended up exploring\nthe JobDSL\nplugin and the new Pipeline jobs.  Combining those two\nthings with some Puppet code to provision a Jenkins server via the\njenkins puppet module gave me\na really nice way to completely automate my Jenkins setup and get a seed job in\nplace that would create my perf testing jobs.  And the Pipeline job format is\njust an awesome fit for what I wanted to do in terms of being able to easily\nmonitor the stages of my performance tests, and to make the job definitions\nmodular so that it would be really easy to create new performance testing jobs\nwith slight variations.\n\nSo everything’s going GREAT up to this point.  I’m really happy with how it’s\nall shaping up.  But then…​ (you knew there was a \"but\" coming, right?) I\nstarted trying to figure out how to add the\nGatling Jenkins\nplugin to the Pipeline jobs, and kind of ran into a wall.\n\nAs best as I could tell from my Googling, the plugin was probably going to\nrequire some modifications in order to be able to be used with Pipeline jobs.\nHowever, I wasn’t able to find any really cohesive documentation that\ndefinitively confirmed that or explained how everything fits together.\n\nEventually, I got it all sorted out.  So, in hopes of saving the next person a\nlittle time, and encouraging plugin authors to invest the time to get their\nplugins working with Pipeline, here are some notes about what I learned.\n\nSpoiler: if you’re just interested in looking at the individual git commits that\nI made on may way to getting the plugin working with Pipeline, have a look at\nthis github\nbranch.\n\nCreating a pipeline step\n\nThe main task that the Gatling plugin performs is to archive Gatling reports\nafter a run.  I figured that the end game for this exercise was that I was going\nto end up with a Pipeline \"step\" that I could include in my Pipeline scripts, to\ntrigger the archiving of the reports.  So my first thought was to look for an\nexisting plugin / Pipeline \"step\" that was doing something roughly similar, so\nthat I could use it as a model.  The Pipeline \"Snippet Generator\" feature\n(create a pipeline job, scroll down to the \"Definition\" section of its\nconfiguration, and check the \"Snippet Generator\" checkbox) is really helpful for\nfiguring out stuff like this; it is automatically populated with all of the\nsteps that are valid on your server (based on which plugins you have installed),\nso you can use it to verify whether or not your custom \"step\" is recognized, and\nalso to look at examples of existing steps.\n\nLooking through the list of existing steps, I figured that the archive step\nwas pretty likely to be similar to what I needed for the gatling plugin:\n\nSo, I started poking around to see what magic it was that made that archive\nstep show up there.  There are some mentions of this in the\npipeline-plugin\nDEVGUIDE.md and the\nworkflow-step-api-plugin\nREADME.md, but the real breakthrough for me was finding the definition of the\narchive step in the workflow-basic-steps-plugin source\ncode.\n\nWith that as an example, I was able to start poking at getting a\ngatlingArchive step to show up in the Snippet Generator.  The first thing that\nI needed to do was to update the gatling-plugin project’s pom.xml to depend\non a recent enough version of Jenkins, as well as specify dependencies on the\nappropriate pipeline\nplugins\n\nOnce that was out of the way, I noticed that the archive step had some tests\nwritten for it, using what looks to be a pretty awesome test API for pipeline\njobs and plugins.  Based on those archive\ntests,\nI added\na\nskeleton for a test for the gatlingArchive step that I was about to write.\n\nThen, I moved on to\nactually\ncreating the step.  The meat of the code was this:\n\npublic class GatlingArchiverStep extends AbstractStepImpl {\n    @DataBoundConstructor\n    public GatlingArchiverStep() {}\n\n    @Extension\n    public static class DescriptorImpl extends AbstractStepDescriptorImpl {\n        public DescriptorImpl() { super(GatlingArchiverStepExecution.class); }\n\n        @Override\n        public String getFunctionName() {\n            return \"gatlingArchive\";\n        }\n\n        @NonNull\n        @Override\n        public String getDisplayName() {\n            return \"Archive Gatling reports\";\n        }\n    }\n}\n\nNote that in that commit I also added a config.jelly file.  This is how you\ndefine the UI for your step, which will show up in the Snippet Generator.  In\nthe case of this Gatling step there’s really not much to configure, so my\nconfig.jelly is basically empty.\n\nWith that (and the rest of the code from that commit) in place, I was able to\nfire up the development Jenkins server (via mvn hpi:run, and note that you\nneed to go into the \"Manage Plugins\" screen on your development server and\ninstall the Pipeline plugin once before any of this will work) and visit the\nSnippet Generator to see if my step showed up in the dropdown:\n\nGREAT SUCCESS!\n\nThis step doesn’t actually do anything yet, but it’s recognized by Jenkins and\ncan be included in your pipeline scripts at that point, so, we’re on our way!\n\nThe step metastep\n\nThe step that we created above is a first-class DSL addition that can be used in\nPipeline scripts.  There’s another way to make your plugin work usable from a\nPipeline job, without making it a first-class build step.  This is by use of the\nstep\"metastep\", mentioned in the pipeline-plugin\nDEVGUIDE.\nWhen using this approach, you simply refactor your Builder or Publisher to\nextend SimpleBuildStep, and then you can reference the build step from the\nPipeline DSL using the step method.\n\nIn the Jenkins GUI, go to the config screen for a Pipeline job and click on the\nSnippet Generator checkbox.  Select 'step: General Build Step' from the\ndropdown, and then have a look at the options that appear in the 'Build Step'\ndropdown.  To compare with our previous work, let’s see what \"Archive the\nartifacts\" looks like:\n\nFrom the snippet generator we can see that it’s possible to trigger an Archive\naction with syntax like:\n\nstep([$class: 'ArtifactArchiver', artifacts: 'foo*', excludes: null])\n\nThis is the \"metastep\".  It’s a way to trigger any build action that implements\nSimpleBuildStep, without having to actually implement a real \"step\" that\nextends the Pipeline DSL like we did above.  In many cases, it might only make\nsense to do one or the other in your plugin; you probably don’t really need\nboth.\n\nFor the purposes of this tutorial, we’re going to do both.  For a couple of reasons:\n\nWhy the heck not?  :)  It’s a good demonstration of how the metastep stuff\nworks.\n\nBecause implementing the \"for realz\" step will be a lot easier if the Gatling\naction that we’re trying to call from our gatlingArchive() syntax is using the\nnewer Jenkins APIs that are required for subclasses of SimpleBuildStep.\n\nGatlingPublisher is the main build action that we’re interested in using in\nPipeline jobs.  So, with all of that in mind, here’s our next goal: get\nstep([$class: 'GatlingPublisher', …​) showing up in the Snippet Generator.\n\nThe javadocs for the SimpleBuildStep\nclass\nhave some notes on what you need to do when porting an existing Builder or\nPublisher over to implement the SimpleBuildStep interface.  In all\nlikelihood, most of what you’re going to end up doing is to replace occurrences\nof AbstractBuild with references to the Run class, and replace occurrences\nof AbstractProject with references to the Job class.  The APIs are pretty\nsimilar, so it’s not too hard to do once you understand that that’s the game.\nThere is some discussion of this in the pipeline-plugin\nDEVGUIDE.\n\nFor the Gatling plugin, my\ninitial\nefforts to port the GatlingPublisher over to implement SimpleBuildStep only\nrequired the AbstractBuild → Run refactor.\n\nAfter making these changes, I fired up the development Jenkins server, and, voila!\n\nSo, now, we can add a line like this to a Pipeline build script:\n\nstep([$class: 'GatlingPublisher', enabled: true])\n\nAnd it’ll effectively be the same as if we’d added the Gatling \"Post-Build\nAction\" to an old-school Freestyle project.\n\nWell…​ mostly.\n\nBuild Actions vs. Project Actions\n\nAt this point our modified Gatling plugin should work the same way as it always\ndid in a Freestyle build, but in a Pipeline build, it only partially works.\nSpecifically, the Gatling plugin implements two different \"Actions\" to surface\nthings in the Jenkins GUI: a \"Build\" action, which adds the Gatling icon to the\nleft sidebar in the GUI when you’re viewing an individual build in the build\nhistory of a job, and a \"Project\" action, which adds that same icon to the left\nsidebar of the GUI of the main page for a job.  The \"Project\" action also adds a\n\"floating panel\" on the main job page, which shows a graph of the historical\ndata for the Gatling runs.\n\nIn a Pipeline job, though, assuming we’ve added a call to the metastep, we’re\nonly seeing the \"Build\" actions.  Part of this is because, in the last round of\nchanges that I linked, we only modified the \"Build\" action, and not the\n\"Project\" action.  Running the metastep in a Pipeline job has no visible effect\nat all on the project/job page at this point.  So that’s what we’ll tackle next.\n\nThe key thing to know about getting \"Project\" actions working in a Pipeline job\nis that, with a Pipeline job, there is no way for Jenkins to know up front what\nsteps or actions are going to be involved in a job.  It’s only after the job\nruns once that Jenkins has a chance to introspect what all the steps were.  As\nsuch, there’s no list of Builders or Publishers that it knows about up front to\ncall getProjectAction on, like it would with a Freestyle job.\n\nThis is where\nSimpleBuildStep.LastBuildAction\ncomes into play.  This is an interface that you can add to your Build actions,\nwhich give them their own getProjectActions method that Jenkins recognizes and\nwill call when rendering the project page after the job has been run at least\nonce.\n\nSo, effectively, what we need to do is to\nget\nrid of the getProjectAction method on our Publisher class, modify the Build\naction to implement SimpleBuildStep.LastBuildAction, and encapsulate our\nProject action instances in the Build action.\n\nThe build action class now constructs an instance of the Project action and\nmakes it accessible via getProjectActions (which comes from the\nLastBuildAction interface):\n\npublic class GatlingBuildAction implements Action, SimpleBuildStep.LastBuildAction {\n    public GatlingBuildAction(Run build, List sims) {\n        this.build = build;\n        this.simulations = sims;\n\n        List projectActions = new ArrayList<>();\n        projectActions.add(new GatlingProjectAction(build.getParent()));\n        this.projectActions = projectActions;\n    }\n\n    @Override\n    public Collection getProjectActions() {\n        return this.projectActions;\n    }\n}\n\nAfter making these changes, if we run the development Jenkins server, we can see\nthat after the first successful run of the Pipeline job that calls the\nGatlingPublisher metastep, the Gatling icon indeed shows up in the sidebar on\nthe main project page, and the floating box with the graph shows up as well:\n\nMaking our DSL step do something\n\nSo at this point we’ve got the metastep syntax working from end-to-end, and\nwe’ve got a valid Pipeline DSL step ( gatlingArchive()) that we can use in our\nPipeline scripts without breaking anything…​ but our custom step doesn’t\nactually do anything.  Here’s the part where we tie it all together…​ and it’s\npretty easy!  All we need to do is to make our step \"Execution\" class\ninstantiate a Publisher and call perform on\nit.\n\nAs per the\nnotes\nin the pipeline-plugin DEVGUIDE, we can use the @StepContextParameter\nannotation to inject in the objects that we need to pass to the Publisher’s\nperform method:\n\npublic class GatlingArchiverStepExecution extends AbstractSynchronousNonBlockingStepExecution {\n\n    @StepContextParameter\n    private transient TaskListener listener;\n\n    @StepContextParameter\n    private transient FilePath ws;\n\n    @StepContextParameter\n    private transient Run build;\n\n    @StepContextParameter\n    private transient Launcher launcher;\n\n    @Override\n    protected Void run() throws Exception {\n        listener.getLogger().println(\"Running Gatling archiver step.\");\n\n        GatlingPublisher publisher = new GatlingPublisher(true);\n        publisher.perform(build, ws, launcher, listener);\n\n        return null;\n    }\n}\n\nAfter these changes, we can fire up the development Jenkins server, and hack up\nour Pipeline script to call gatlingArchive() instead of the metastep\nstep([$class: 'GatlingPublisher', enabled: true]) syntax.  One of these is\nnicer to type and read than the other, but I’ll leave that as an exercise for\nthe reader.\n\nFin\n\nWith that, our plugin now works just as well in the brave new Pipeline world as\nit did in the olden days of Freestyle builds.  I hope these notes save someone\nelse a little bit of time and googling on your way to writing (or porting) an\nawesome plugin for Jenkins Pipeline jobs!\n\nLinks\n\nJenkins Pipeline Overview\n\nPipeline Plugin Developer Guide\n\nJenkins Source Code\n\nWorkflow Step API Plugin\n\nWorkflow Basic Steps Plugin","title":"Refactoring a Jenkins plugin for compatibility with Pipeline jobs","tags":["core","pipeline","plugins"],"authors":[{"avatar":null,"blog":null,"github":"cprice404","html":"<div class=\"paragraph\">\n<p>Chris is a software engineer at Puppet, who mostly works on backend services\nfor Puppet itself, but occasionally gets to spend some time improving CI\nand automation using Jenkins.</p>\n</div>","id":"cprice404","irc":null,"linkedin":null,"name":"Chris Price","slug":"/blog/authors/cprice404","twitter":"cprice404"}]}},{"node":{"date":"2016-05-23T00:00:00.000Z","id":"85257451-d116-575c-b893-3c51d7386caa","slug":"/blog/2016/05/23/external-workspace-manager-plugin/","strippedHtml":"About myself\n\nMy name is Alexandru Somai.\nI’m following a major in Software Engineering at the Babes-Bolyai University of Cluj-Napoca, Romania.\nI have more than two years hands-on experience working in Software Development.\n\nI enjoy writing code in Java, Groovy and JavaScript.\nThe technologies and frameworks that I’m most familiar with are: Spring Framework, Spring Security, Hibernate,\nJMS, Web Services, JUnit, TestNG, Mockito.\nAs build tools and continuous integration, I’m using Maven and Jenkins.\nI’m a passionate software developer who is always learning, always looking for new challenges.\nI want to start contributing to the open source community and Google Summer of Code is a starting point for me.\n\nProject summary\n\nCurrently, Jenkins’ build workspace may become very large in size due to the fact that some compilers generate\nvery large volumes of data.\nThe existing plugins that share the workspace across builds are able to do this by copying the files from\none workspace to another, process which is inefficient.\nA solution is to have a Jenkins plugin that is able to manage and reuse the same workspace between multiple builds.\n\nAs part of the Google Summer of Code 2016 I will be working on\nthe External Workspace Manager plugin.\nMy mentors for this project are Oleg Nenashev\nand Martin d’Anjou.\nThis plugin aims to provide an external workspace management system.\nIt should facilitate workspace share and reuse across multiple Jenkins jobs.\nIt should eliminate the need to copy, archive or move files.\nThe plugin will be written for Pipeline jobs.\n\nUsage\n\nPrerequisites\n\nMultiple physical disks accessible from controller.\n\nThe same physical disks must be accessible from Jenkins Nodes (renamed to Agents in Jenkins 2.0).\n\nIn the Jenkins global configuration, define a disk pool (or many) that will contain the physical disks.\n\nIn each Node configuration, define the mounting point from the current node to each physical disk.\n\nThe following diagram gives you an overview of how an External Workspace Manager configuration may look like:\n\nExample one\n\nLet’s assume that we have one Jenkins job. In this job, we want to use the same workspace on multiple Jenkins nodes.\nOur pipeline code may look like this:\n\nstage ('Stage 1. Allocate workspace')\ndef extWorkspace = exwsAllocate id: 'diskpool1'\n\nnode ('linux') {\n    exws (extWorkspace) {\n        stage('Stage 2. Build on the build server')\n        git url: '...'\n        sh 'mvn clean install'\n    }\n}\n\nnode ('test') {\n    exws (extWorkspace) {\n        stage('Stage 3. Run tests on a test machine')\n        sh 'mvn test'\n    }\n}\n\nNote: The stage() steps are optional from the External Workspace Manager plugin perspective.\n\nStage 1. Allocate workspace\n\nThe exwsAllocate step selects a disk from diskpool1\n(default behavior: the disk with the most available size).\nOn that disk, let’s say disk1, it allocates a directory.\nThe computed directory path is: /physicalPathOnDisk/$JOB_NAME/$BUILD_NUMBER.\n\nFor example, Let’s assume that the $JOB_NAME is integration and the $BUILD_NUMBER is 14.\nThen, the resulting path is: /jenkins-project/disk1/integration/14.\n\nStage 2. Build on the build server\n\nAll the nodes labeled linux must have access to the disks defined in the disk pool.\nIn the Jenkins Node configurations we have defined the local paths that are the mounting points to each disk.\n\nThe exws step concatenates the node’s local path with the path returned by the exwsAllocate step.\nIn our case, the node labeled linux has its local path to disk1 defined as: /linux-node/disk1/.\nSo, the complete workspace path is: /linux-node/disk1/jenkins-project/disk1/integration/14.\n\nStage 3. Run tests on a test machine\n\nFurther, we want to run our tests on a different node, but we want to reuse the previously created workspace.\n\nIn the node labeled test we have defined the local path to disk1 as: /test-node/disk1/.\nBy applying the exws step, our tests will be able to run in the same workspace as the build.\nTherefore, the path is: /test-node/disk1/jenkins-project/disk1/integration/14.\n\nExample two\n\nLet’s assume that we have two Jenkins jobs, one called upstream and the other one called downstream.\nIn the upstream job, we clone the repository and build the project, and in the downstream job we run the tests.\nIn the downstream job we don’t want to clone and re-build the project, we need to use the same\nworkspace created in the upstream job.\nWe have to be able to do so without copying the workspace content from one location to another.\n\nThe pipeline code in the upstream job is the following:\n\nstage ('Stage 1. Allocate workspace in the upstream job')\ndef extWorkspace = exwsAllocate id: 'diskpool1'\n\nnode ('linux') {\n    exws (extWorkspace) {\n        stage('Stage 2. Build in the upstream job')\n           git url: '...'\n           sh 'mvn clean install'\n    }\n}\n\nAnd the downstream 's pipeline code is:\n\nstage ('Stage 3. Allocate workspace in the downstream job')\ndef extWorkspace = exwsAllocate id: 'diskpool1', upstream: 'upstream'\n\nnode ('test') {\n    exws (extWorkspace) {\n        stage('Stage 4. Run tests in the downstream job')\n        sh 'mvn test'\n    }\n}\n\nStage 1. Allocate workspace in the upstream job\n\nThe functionality is the same as in example one - stage 1.\nIn our case, the allocated directory on the physical disk is: /jenkins-project/disk1/upstream/14.\n\nStage 2. Build in the upstream job\n\nSame functionality as example one - stage 2.\nThe final workspace path is: /linux-node/disk1/jenkins-project/disk1/upstream/14.\n\nStage 3. Allocate workspace in the downstream job\n\nBy passing the upstream parameter to the exwsAllocate step,\nit selects the most recent stable upstream workspace (default behavior).\nThe workspace path pattern is like this: /physicalPathOnDisk/$UPSTREAM_NAME/$MOST_RECENT_STABLE_BUILD.\nLet’s assume that the last stable build number is 12, then the resulting path is:\n/jenkins-project/disk1/upstream/12.\n\nStage 4. Run tests in the downstream job\n\nThe exws step concatenates the node’s local path with the path returned by the exwsAllocate step in stage 3.\nIn this scenario, the complete path for running tests is: /test-node/disk1/jenkins-project/disk1/upstream/12.\nIt will reuse the workspace defined in the upstream job.\n\nAdditional details\n\nYou may find the complete project proposal, along with the design details, features, more examples and use cases,\nimplementation ideas and milestones in the design document.\nThe plugin repository will be available on GitHub.\n\nA prototype version of the plugin should be available in late June and the releasable version in late August.\nI will be holding plugin functionality demos within the community.\n\nI do appreciate any feedback.\nYou may add comments in the design document.\nIf you are interested to have a verbal conversation, feel free to join our regular meetings on Mondays at\n12:00 PM UTC\non the Jenkins hangout.\nI will be posting updates from time to time about the plugin status on the\nJenkins developers mailing list.\n\nLinks\n\nDesign document\n\nGSoC program\n\nJenkins GSoC Page\n\nProject repository","title":"GSoC Project Intro: External Workspace Manager Plugin","tags":["pipeline","plugins","gsoc"],"authors":[{"avatar":null,"blog":null,"github":"alexsomai","html":"","id":"alexsomai","irc":null,"linkedin":null,"name":"Alexandru Somai","slug":"/blog/authors/alexsomai","twitter":"alex_somai"}]}},{"node":{"date":"2016-05-18T00:00:00.000Z","id":"3098cab4-cd65-52ec-a4a9-2b36e2ac20d7","slug":"/blog/2016/05/18/announcing-azure-partnership/","strippedHtml":"I am pleased to announce that we have partnered with Microsoft to migrate and\npower the Jenkins project’s infrastructure with\nMicrosoft Azure. The partnership comes\nat an important time, after the recent launch of Jenkins 2.0,\nJenkins users are more readily adopting Pipeline as\nCode and many other plugins at an increasing rate, elevating the importance of\nJenkins infrastructure to the overall success of the project. That strong and\ncontinued growth has brought new demands to our infrastructure’s design and\nimplementation, requiring the next step in its evolution. This partnership helps\nus grow with the rest of the project by unifying our existing infrastructure\nunder one comprehensive, modern and scalable platform.\n\nIn March we\ndiscussed\nthe potential partnership in our regularly scheduled\nproject\nmeeting,\nhighlighting some of the infrastructure challenges that we face:\n\nCurrently we have infrastructure in four different locations, with four\ndifferent infrastructure providers, each with their own APIs and tools for\nmanaging resources, each with varying capabilities and capacities.\n\nProject infrastructure is managed by a team of volunteers, operating\nmore than 15 different services and managing a number of additional external\nservices.\n\nOur current download/mirror network, while geographically distributed, is\nrelatively primitive and its implementation prevents us from using more modern\ndistribution best practices.\n\nIn essence, five years of tremendous growth for Jenkins has outpaced our\norganically grown, unnecessarily complex, project infrastructure. Migrating to\nAzure simplifies and improves our infrastructure in a dramatic way that would\nnot be possible without a comprehensive platform consisting of: compute, CDN,\nstorage and data-store services. Our partnership covers, at minimum, the next\nthree years of the project’s infrastructure needs, giving us a great home for\nthe future.\n\nAzure also enables a couple of projects that I\nhave long been dreaming of providing to Jenkins users and contributors:\n\nEnd-to-end TLS encrypted distribution of Jenkins packages, plugins and\nmetadata via the Azure CDN.\n\nMore complete build/test/release support and capacity on\nci.jenkins.io for plugin developers using\nAzure\nContainer Service and generic VMs.\n\nThe Jenkins infrastructure is all open\nsource which means  all of our Docker containers, Puppet code and many of our\ntools are all available on GitHub. Not\nonly can you watch the migration process to Azure as it happens, but I also\ninvite you to participate in making our project’s infrastructure better (join\nus in the #jenkins-infra channel on Freenode or our\nmailing list).\n\nSuffice it to say, I’m very excited about the bright [blue] future for the\nJenkins project and the infrastructure that powers it!","title":"Partnering with Microsoft to run Jenkins infrastructure on Azure","tags":["azure","infra","infrastructure"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-05-17T00:00:00.000Z","id":"f5d8714c-54dc-5d02-9311-d7a814cce01e","slug":"/blog/2016/05/17/state-of-jam/","strippedHtml":"Recently, the Jenkins project announced the release of\nJenkins 2.0, a first major release\nafter 10 years and 655 weekly releases. This has been a major milestone for\nJenkins and its growing community of developers, testers, designers and other\nusers in the software delivery process.\n\nWith its rising popularity and wide adoption, the Jenkins community continues to\ngrow and evolve into the millions. Jenkins community meetup activity has risen\nto an all time high since the first Jenkins meetup which was established on\nAugust 23 2010, in San Francisco.\n\nOver the last six months the number of\nJenkins Area Meetup (JAM) Groups has\ngrown from 5 to 30, with coverage in Asia, North America, South America and\nEurope.  That’s an average growth of 4 new JAMs per month.\n\nAs of today, there are over 4,100 Jenkins fans within the Jenkins meetup\ncommunity.  This is the result of contributions from community JAM leaders who\nhave volunteered their time to provide a platform for learning, sharing and\nnetworking all things Jenkins within their local communities.\n\nFor anyone who has not organized a meetup before, there are many moving parts\nthat have to come together at a specific location, date and time. This process\ntakes significant effort to methodically plan out. From planning the food and\nbeverages to securing speaker(s), a venue, audio/visual setup, technical\nlogistics and of course promoting the meetup. It does takes a level of passion\nand effort to make it all happen.\n\nMany THANKS to the 55 JAM leaders, who share this passion - they have\nsuccessfully organized over 41 meetups within the past six months in North\nAmerica, South America and Europe. That’s about 6 meetups a month!\n\nThere are still plenty of opportunities to be a JAM organizer. If there is not a\nJAM near you, we’d love to hear from\nyou! Here’s\nhow you can get\nstarted.","title":"The State of Jenkins Area Meetups (JAM)","tags":["meetup","JAM","event"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg","srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/8d248/alyssat.jpg 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/c004c/alyssat.jpg 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/9e67b/alyssat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/22924/alyssat.webp 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/89767/alyssat.webp 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/40d97/alyssat.webp 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/5028e/alyssat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":166}}},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"/blog/authors/alyssat","twitter":null}]}},{"node":{"date":"2016-05-12T00:00:00.000Z","id":"16aeac16-1357-5d74-85da-84ef71ddbaa2","slug":"/blog/2016/05/12/sf-jam-jenkins-and-azure/","strippedHtml":"A few weeks ago, my colleague Brian Dawson\nand I were invited to present on\nScaling Jenkins for\nContinuous Delivery with Microsoft Azure in Microsoft’s\nReactor space. Azure is Microsoft’s\npublic cloud offering and one of the many tools available to Jenkins users for\nadding elastic compute capacity, among other things, to their build/test/deploy\ninfrastructure. While our presentations are applicable to practically\nany cloud-based Jenkins environment, Thiago Almeida and Oguz Pastirmaci from\nMicrosoft were also on-hand and presented some interesting Azure-specific\nofferings like\nAzure\nContainer Service with Jenkins.\n\nWhile we do not have video from the meetup, Brian and I did record\na\nsession with Thiago and Oguz for Channel9\nwhich covers much of the same content:\n\nTo kick-off the meetup we asked attendees a few polling questions and\nreceived very telling responses:\n\nHow big is your Development/IT organization?\n\nWhat is your role?\n\nBy show of hands do you practice CI/CD/DevOps/etc?\n\nAt what scale (tooling and practice)?\n\nThe responses indicated that the majority of attendees were from small to medium\norganizations where they practiced Continuous Delivery across multiple teams. A\nnotable 25% or greater attendees considered themselves \"fullstack\" or\nparticipating in all of the roles of Developer, QA, and Operations. Interesting\nwhen paired with the high number (~80%) of those who practice CD.  This is\nlikely because modern teams, with mature CD practices, tend to blur the\ntraditional lines of Developer, QA and Operations. However, In my experience,\nwhile this is often the case for small to medium companies in large\norganizations team members tend to fall into the traditional roles, with CD\nproviding the practice and platform to unify teams across roles.\n\n— Brian Dawson\n\nAfter gauging the audience, Thiago and Brian reviewed Continuous Delivery (CD)\nand implementing it at scale. They highlighted the fact that CD is being rapidly\nadopted across teams and organizations, providing the ability: to deliver a demonstrably\nhigher quality product, shipping more rapidly than before, and to keep team members happier.\n\nHowever, when organizations fail to properly support CD as they scale, they run\ninto issues such as: developers acting as administrators at the cost of\nproductivity, potential lack of security and/or exposure of IP and difficulty in\nsharing best practices across teams.\n\nThiago then highlighted that properly scaling CD practices in the organization\nalong with the infrastructure itself can alleviate these issues, and discussed\nthe benefits of scaling CD to on cloud platforms to provide \"CD-as-a-Service.\"\n\nOverall I found the \"theory\" discussion to be on point, continuous delivery is\nnot just a technology nor a people problem. Successful organizations scale their\nprocesses and tooling together.\n\nThe slides from our respective presentations are linked below:\n\n(Brian) Scaling Jenkins for Continuous Delivery (.pdf)\n\n(Tyler) Scaling Jenkins with Azure (.pdf)\n\nI hope you join us at future\nSan Francisco\nJAM s!","title":"SF JAM Report: Scaling Jenkins for Continuous Delivery with Azure","tags":["jam","azure","meetup"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-05-11T00:00:00.000Z","id":"31e502bf-b2a2-58e7-aec8-26b504df7584","slug":"/blog/2016/05/11/security-update/","strippedHtml":"We just released security updates to Jenkins that fix a number of low and medium severity issues. For an overview of what was fixed, see the security advisory.\n\nOne of the fixes may well break some of your use cases in Jenkins, at least until plugins have been adapted: SECURITY-170. This change removes parameters that are not defined on a job from the build environment. So, right now, a job could even be unparameterized, and plugins were able to pass parameters anyway. Since build parameters are added to the environment variables of scripts run during a build, parameters such as PATH or DYLD_LIBRARY_PATH can be defined — on jobs which don’t even expect those as build parameters — to change the behavior of builds.\n\nA number of plugins define additional parameters for builds. For example, GitHub Pull Request Builder passes a number of additional parameters describing the pull request. Release Plugin also allows adding several additional parameters to a build that are not considered to be defined in the job as part of this security fix.\n\nPlease see this wiki page for a list of plugins known to be affected by this change.\n\nUntil these plugins have been adapted to work with the new restriction (and advice on that is available further down), you can define the following system properties to work around this limitation, at least for a time:\n\nSet hudson.model.ParametersAction.keepUndefinedParameters to true, e.g. java -Dhudson.model.ParametersAction.keepUndefinedParameters=true -jar jenkins.war to revert to the old behavior of allowing any build parameters. Depending on your environment, this may be unsafe, as it opens you up to attacks as described above.\n\nSet hudson.model.ParametersAction.safeParameters to a comma-separated list of safe parameter names, e.g. java -Dhudson.model.ParametersAction.safeParameters=FOO,BAR_baz,quX -jar jenkins.war.\n\nI realize this change, among a few others that improve the security of Jenkins, may be difficult to adapt for some, but given the valuable secrets typically stored in Jenkins, I’m certain that this is the correct approach. We made sure to release this fix with the options described above, so that this change doesn’t block updating those that rely on this behavior.\n\nDevelopers have several options to adapt to this change:\n\nParametersAction actually stores all parameters, but getParameters() only returns those that are defined on the job. The new method getAllParameters() returns all of them. This can be used, for example by EnvironmentContributor extensions, to add known safe parameters to build environments.\n\nDon’t pass extra arguments, but define a QueueAction for your metadata instead. Those can still be made available to the build environment as needed.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2016-05-10T00:00:00.000Z","id":"e79a5ee4-9a52-50ad-875a-d0e23f888bab","slug":"/blog/2016/05/10/jenkins-20-vjam/","strippedHtml":"Last week we hosted our first ever\nOnline JAM with the debut\ntopic of: Jenkins 2.0. Alyssa, our\nEvents officer, and I pulled together a\nseries of\nsessions focusing on some of the most notable aspects of Jenkins 2 with:\n\nA Jenkins 2.0 keynote from project founder\nKohsuke Kawaguchi\n\nAn overview of \"Pipeline as Code\" from Patrick\nWolf\n\nA deep-dive into Pipeline and related plugins like Multibranch, etc from\nJesse Glick and\nKishore Bhatia\n\nAn overview of new user experience changes in 2.0 from\nKeith Zantow\n\nA quick lightning talk about documentation by yours truly\n\nWrapping up the sessions, was Kohsuke again, talking about the road beyond\nJenkins 2.0 and what big projects he sees on the horizon.\n\nThe event was really interesting for me, and I hope informative for those who\nparticipated in the live stream and Q&A session. I look forward to hosting more\nVirtual JAM events in the future, and I hope you will\njoin us!\n\nQuestions and Answers\n\nBelow are a collection of questions and answers, that were posed during the\nVirtual JAM. Many of these were answered during the course of the sessions, but\nfor posterity all are included below.\n\nPipeline\n\nWhat kind of DSL is used behind pipeline as code? Groovy or allow freely use\ndifferent languages as a user prefer?\n\nPipeline uses a Groovy-based domain specific language.\n\nHow do you test your very own pipeline DSL?\n\nReplay helps in testing/debugging while creating pipelines and at the branch\nlevel. There are some ideas which Jesse Glick\nhas proposed for testing Jenkinsfile and Pipeline libraries captured in\nJENKINS-33925.\n\nIsn’t \"Survive Jenkins restart\" exclusive to [CloudBees] Jenkins Enterprise?\n\nNo, this feature does not need\nCloudBees\nJenkins Enterprise. All features shown\nduring the virtual JAM are free and open source. CloudBees' Jenkins Enterprise\nproduct does support restarting from a specified stage however, and that is not\nopen source.\n\nHow well is jenkins 2.0 integrate with github for tracking job definitions?\n\nUsing the\nGitHub\nOrganization Folder plugin, Jenkins can automatically detect a Jenkinsfile in\nsource repositories to create Pipeline projects.\n\nPlease make the ability for re-run failed stages Open Source too :)\n\nThis has been passed on to our friends at CloudBees for consideration :)\n\nIf Jenkinsfile is in the repo, co-located with code, does this mean Jenkins can\nauto-detect new jobs for different branches?\n\nThis is possible using the\nPipeline Multibranch plugin.\n\nWhat documentation sources are there for Pipeline?\n\nOur documentation section contains a number of pagesaround Pipeline.\nThere is also additional documentation and examples in the plugin’s\ngit repository and the\njenkinsci/pipeline-examples\nrepository. (contributions welcome!)\n\nWhere we can find the DSL method documentation?\n\nThere is generated documentation on jenkins.io which\nincldues steps from all public plugins. Inside of a running Jenkins instance,\nyou can also navigate to\nJENKINS_URL/workflow-cps-snippetizer/dslReference\nto see the documentation for the plugins which are installed in that instance.\n\nIf Pipeline is not support some plugins (there is a lot actually), I needed\nSonarQube Runner but unfortunately it’s not supported yet, in Job DSL plugin i\ncan use \"Configure Block\" and cover any plugin via XML, how i can achieve the\nsame with a Pipeline?\n\nNot at this time\n\nIs there a possibility to create custom tooltips i.e. with a quick reference or\na link to internal project documentation? Might be useful i.e. for junior team\nmembers who need to refer to external docs.\n\nNot generally. Though in the case of Pipeline global libraries, you can create\ndescriptions of vars/functions like standardBuild in the demo, and these will\nappear in Snippet Generator under Global Variables.\n\nOh pipeline supports joining jobs? It’s really good, but I cannot find document\nat https://jenkins.io/doc/ could you tell me where is it?\n\nThere is a build step, but the Pipeline system is optimized for single-job\npipelines\n\nWe have multiple projects that we would like to follow the same pipeline.  How\nwould I write a common pipeline that can be shared across multiple projects.\n\nYou may want to look at implementing some additional steps using the\nPipeline Global\nLibrary feature. This would allow you to define\norganization-specific extensions to the Pipeline DSL to abstract away common\npatterns between projects.\n\nHow much flexibility is there with creating context / setting environment\nvariables or changing / modifying build tool options when calling a web hook /\napi to parameterize pipelines for example to target deployments to different env\nusing same pipeline\n\nVarious environment variables are exposed under the env variable in the Groovy\nDSL which would allow you to construct logic as simple or as complex as\nnecessary to achieve your goal.\n\nWhen you set up the job for the first time, does it build every branch in git,\nor is there a way to stop it from building old branches?\n\nNot at this time, the best way to prevent older branches from being built is to\nremove the Jenkinsfile in those branches. Alternatively, you could use the\n\"include\" or \"exclude\" patterns when setting up the SCM configuration of your\nmultibranch Pipeline. See also\nJENKINS-32396.\n\nSimilar to GitHub organizations, will BitBucket \"projects\" (ways of organizing\ncollections of repos) be supported?\n\nYes, these are supported via the\nBitbucket\nBranch Source plugin.\n\nHow do you handle build secrets with the pipeline plugin? Using unique\ncredentials stored in the credentials plugin per project and/or branch?\n\nThis can be accomplished by using the\nCredentials\nBinding plugin.\n\nSimilar to GitHub Orgs, are Gitlab projects supported in the same way?\n\nGitLab projects are not explicitly supported at this time, but the extension\npoints which the GitHub Organization Folder plugin uses could be extended in a\nsimilar manner for GitLab. See also JENKINS-34396\n\nIs Perforce scm supported by the Pipeline plugin?\n\nAs a SCM source for discovering a Jenkinsfile, not at this time. The\nP4\nplugin does provide some p4 steps which can be used in a Pipeline script\nhowever, see here for documentation.\n\nIs Mercurial supported with multibranch?\n\nYes, it is.\n\nCan Jenkinsfile detect when it’s running against a pull request vs an approved commit, so that it can perform a different type of build?\n\nYes, via the env variables provided in the DSL scope. Using an if statement,\none could guard specific behaviors with:\n\nif (env.CHANGE_ID != null) {\n    /* do things! */\n}\n\nLet’s say I’m building RPMs with Jenkins and use build number as an RPM\nversion/release number. Is there a way to maintain build numbers and leverage\nversioning of Jenkinsfile?\n\nThrough the env variable, it’s possible to utilize env.BUILD_NUMBER or the\nSCM commit ID, etc.\n\nLove the snippet generator! Any chance of separating it out from the pipeline\ninto a separate page on its own, available in the left nav?\n\nYes, this is tracked in\nJENKINS-31831\n\nAny tips on pre-creating the admin user credential and selecting plugins to\nautomate the Jenkins install?\n\nThere are various configuration\nmanagement modules which provide parts of this functionality.\n\nI’m looking at the pipeline syntax (in Jenkins 2.0) how do I detect a\nstep([…​]) has failed and create a notification inside the Jenkinsfile?\n\nThis can be done by wrapping a step invocation with a Groovy try/catch block.\nSee also JENKINS-28119\n\nUser Interface/Experience\n\nIs the user experience same as before when we replace the Jenkins.war(1.x to\n2.x) in an existing (with security in place) installation?\n\nYou will get the new UI features like redesigned configuration forms, but the\ninitial setup wizard will be skipped. In its stead, Jenkins will offer to\ninstall Pipeline-related functionality.\n\nIs it possible to use custom defined syntax highlighting ?\n\nWithin the Pipeline script editor itself, no. It is using the\nACE editor system,\nso it may be possible for a plugin to change the color scheme used.\n\nCan you elaborate on what the Blue Ocean UI is? Is there a link or more\ninformation on it?\n\nBlue Ocean is the name of user experience an design project, unfortunately at\nthis point in time there is not more information available on it.\n\nGeneral\n\nHow well this integrate with cloud environment?\n\nThe Jenkins controller and agents can run easily in any public cloud environment\nthat supports running Java applications. Through the\nEC2,\nJClouds,\nAzure, or\nany other plugins which extend the cloud\nextension\npoint, it is possible to dynamically provision new build agents on a configured\ncloud provider.\n\nAre help texts and other labels and messages updated for other localizations /\nlanguages as well?\n\nPractically every string in Jenkins core is localizable. The extent to which those\nstrings have been translated depends on contributors by speakers of those\nlanguages to the project. If you want to contribute translations, this\nwiki\npage should get you started.\n\nAny additional WinRM/Windows remoting functionality in 2.0?\n\nNo\n\nIs there a CLI to find all the jobs created by a specific user?\n\nNo, out-of-the-box Jenkins does not keep track of which user created which jobs.\nThe functionality provided by the\nOwnership\nplugin may be of interest though.\n\nPlease consider replacing terms like \"master\" and \"slave\" with \"primary\" and\n\"secondary\".\n\n\"slave\" has been replaced with \"agent\" in Jenkins 2.0.\n\nUpdated 2020-09-18 : The term \"master\" is being replaced with \"controller\".\n\nWe’ve been making tutorial videos on Jenkins for awhile (mostly geared toward\npassing the upcoming CCJPE). Because of that we’re using 1.625.2 (since that is\nwhat is listed on the exam), but should we instead base the videos on 2.0?\n\nAs of right now all of the\nJenkins Certification work done by CloudBees is\nfocused around the Jenkins LTS 1.625.x.","title":"Jenkins 2.0 Online JAM Wrap-up","tags":["jenkins2","jam","meetup"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-26T00:00:00.000Z","id":"8d1a1951-ad97-5021-a398-24ee5d471516","slug":"/blog/2016/04/26/jenkins-20-is-here/","strippedHtml":"Over the past 10 years, Jenkins has really\ngrown to a\nde-facto standard tool that millions of people use to handle automation in\nsoftware development and beyond.  It is quite remarkable for a project that\noriginally started as a hobby project under a different name. I’m very proud.\n\nAround this time last year,\nwe’ve\ncelebrated 10 years, 1000 plugins, and 100K installations. That was a good time\nto retrospect, and we started thinking about the next 10 years of Jenkins and\nwhat’s necessary to meet that challenge.  This project has long been on a\nweekly \"train\" release model, so it was useful to step back and think about a\nbig picture.\n\nThat is where three pillars of Jenkins 2.0 have emerged from.\n\nFirst, one of the challenges our users are facing today is that the automation\nthat happens between a commit and a production has significantly grown in its\nscope. Because of this, the clothing that used to fit (aka \"freestyle project\",\nwhich was the workhorse of Jenkins) no longer fits. We now need something that\nbetter fits today’s use cases like \"continuous delivery pipeline.\" This is why\nin 2.0 we’ve added the pipeline capability. This 2 year old effort allows you\nto describe your chain of automation in a textual form. This allows you to\nversion control it, put it alongside your source tree, etc. It is also actually\na domain specific language (DSL) of Groovy, so when your pipeline grows in\ncomplexity/sophistication, you can manage its complexity and keep it\nunderstandable far more easily.\n\nSecond, over time, Jenkins has developed the \"assembly required before initial\nuse\" feeling. As the project has grown, the frontier of interesting development\nhas shifted to plugins, which is how it should be, but we have left it up to\nusers to discover & use them. As a result, the default installation became very\nthin and minimal, and every user has to find several plugins before Jenkins\nbecomes really functional. This created a paradox of choice and unnecessarily\nhurt the user experience. In 2.0, we reset this thinking and tried to create\nmore sensible out of the box experience that solves 80% use cases for 80% of\npeople. You get something useful out of the box, and you can get some\nconsiderable mileage out of it before you start feeling the need of plugins.\nThis allows us to focus our development & QA effort around this base\nfunctionality, too. By the way, the focus on the out of the box experience\ndoesn’t stop at functionality, either. The initial security setup of Jenkins is\nimproved, too, to prevent unprotected Jenkins instances from getting abused by\nbotnets and attacks.\n\nThird, we were fortunate to have a number of developers with UX background\nspend some quality time on Jenkins, and they have made a big dent in improving\nvarious parts of Jenkins web UI. The setup wizard that implements the out of\nthe box experience improvement is one of them, and it also includes other parts\nof Jenkins that you use all the time, such as job configuration pages and new\nitem pages. This brings much needed attention to the web UI.\n\nAs you can see, 2.0 brings a lot of exciting features on the table, but this is\nan evolutionary release, built on top of the same foundation, so that your\nexisting installations can upgrade smoothly. After this initial release, we’ll\nget back to our usual weekly release march.  Improvements will be made\nto those pillars and others in coming months and years continuously. If you’d\nlike to get a more in-depth look at Jenkins 2.0, please join us in our virtual\nJenkins meetup 2.0 launch event.\n\nThank you very much for everyone who made Jenkins 2.0 possible. There are\ntoo many of you\nto thank individually, but you know who you are. I wanted to thank CloudBees in\nparticular for sponsoring the time of many of those people. Ten years ago, all I\ncould utilize was my own night & weekend time. Now I’ve got a team of smart\npeople working with me to carry this torch forward, and a big effort like 2.0\nwouldn’t have been possible without such organized effort.","title":"Jenkins 2.0 is here!","tags":["jenkins2"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg","srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/f81fe/kohsuke.jpg 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/01b1b/kohsuke.jpg 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/edb43/kohsuke.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/035c3/kohsuke.webp 32w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/273f8/kohsuke.webp 64w,\n/gatsby-jenkins-io/static/dd191cfa3b1158515bff16d455e6117b/e3840/kohsuke.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":148}}},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"/blog/authors/kohsuke","twitter":"kohsukekawa"}]}}]}},"pageContext":{"limit":8,"skip":408,"numPages":100,"currentPage":52}},
    "staticQueryHashes": ["3649515864"]}