{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/52",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-05-11T00:00:00.000Z","id":"31e502bf-b2a2-58e7-aec8-26b504df7584","slug":"/blog/2016/05/11/security-update/","strippedHtml":"We just released security updates to Jenkins that fix a number of low and medium severity issues. For an overview of what was fixed, see the security advisory.\n\nOne of the fixes may well break some of your use cases in Jenkins, at least until plugins have been adapted: SECURITY-170. This change removes parameters that are not defined on a job from the build environment. So, right now, a job could even be unparameterized, and plugins were able to pass parameters anyway. Since build parameters are added to the environment variables of scripts run during a build, parameters such as PATH or DYLD_LIBRARY_PATH can be defined — on jobs which don’t even expect those as build parameters — to change the behavior of builds.\n\nA number of plugins define additional parameters for builds. For example, GitHub Pull Request Builder passes a number of additional parameters describing the pull request. Release Plugin also allows adding several additional parameters to a build that are not considered to be defined in the job as part of this security fix.\n\nPlease see this wiki page for a list of plugins known to be affected by this change.\n\nUntil these plugins have been adapted to work with the new restriction (and advice on that is available further down), you can define the following system properties to work around this limitation, at least for a time:\n\nSet hudson.model.ParametersAction.keepUndefinedParameters to true, e.g. java -Dhudson.model.ParametersAction.keepUndefinedParameters=true -jar jenkins.war to revert to the old behavior of allowing any build parameters. Depending on your environment, this may be unsafe, as it opens you up to attacks as described above.\n\nSet hudson.model.ParametersAction.safeParameters to a comma-separated list of safe parameter names, e.g. java -Dhudson.model.ParametersAction.safeParameters=FOO,BAR_baz,quX -jar jenkins.war.\n\nI realize this change, among a few others that improve the security of Jenkins, may be difficult to adapt for some, but given the valuable secrets typically stored in Jenkins, I’m certain that this is the correct approach. We made sure to release this fix with the options described above, so that this change doesn’t block updating those that rely on this behavior.\n\nDevelopers have several options to adapt to this change:\n\nParametersAction actually stores all parameters, but getParameters() only returns those that are defined on the job. The new method getAllParameters() returns all of them. This can be used, for example by EnvironmentContributor extensions, to add known safe parameters to build environments.\n\nDon’t pass extra arguments, but define a QueueAction for your metadata instead. Those can still be made available to the build environment as needed.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"blog/author/daniel-beck","twitter":null}]}},{"node":{"date":"2016-05-10T00:00:00.000Z","id":"e79a5ee4-9a52-50ad-875a-d0e23f888bab","slug":"/blog/2016/05/10/jenkins-20-vjam/","strippedHtml":"Last week we hosted our first ever\nOnline JAM with the debut\ntopic of: Jenkins 2.0. Alyssa, our\nEvents officer, and I pulled together a\nseries of\nsessions focusing on some of the most notable aspects of Jenkins 2 with:\n\nA Jenkins 2.0 keynote from project founder\nKohsuke Kawaguchi\n\nAn overview of \"Pipeline as Code\" from Patrick\nWolf\n\nA deep-dive into Pipeline and related plugins like Multibranch, etc from\nJesse Glick and\nKishore Bhatia\n\nAn overview of new user experience changes in 2.0 from\nKeith Zantow\n\nA quick lightning talk about documentation by yours truly\n\nWrapping up the sessions, was Kohsuke again, talking about the road beyond\nJenkins 2.0 and what big projects he sees on the horizon.\n\nThe event was really interesting for me, and I hope informative for those who\nparticipated in the live stream and Q&A session. I look forward to hosting more\nVirtual JAM events in the future, and I hope you will\njoin us!\n\nQuestions and Answers\n\nBelow are a collection of questions and answers, that were posed during the\nVirtual JAM. Many of these were answered during the course of the sessions, but\nfor posterity all are included below.\n\nPipeline\n\nWhat kind of DSL is used behind pipeline as code? Groovy or allow freely use\ndifferent languages as a user prefer?\n\nPipeline uses a Groovy-based domain specific language.\n\nHow do you test your very own pipeline DSL?\n\nReplay helps in testing/debugging while creating pipelines and at the branch\nlevel. There are some ideas which Jesse Glick\nhas proposed for testing Jenkinsfile and Pipeline libraries captured in\nJENKINS-33925.\n\nIsn’t \"Survive Jenkins restart\" exclusive to [CloudBees] Jenkins Enterprise?\n\nNo, this feature does not need\nCloudBees\nJenkins Enterprise. All features shown\nduring the virtual JAM are free and open source. CloudBees' Jenkins Enterprise\nproduct does support restarting from a specified stage however, and that is not\nopen source.\n\nHow well is jenkins 2.0 integrate with github for tracking job definitions?\n\nUsing the\nGitHub\nOrganization Folder plugin, Jenkins can automatically detect a Jenkinsfile in\nsource repositories to create Pipeline projects.\n\nPlease make the ability for re-run failed stages Open Source too :)\n\nThis has been passed on to our friends at CloudBees for consideration :)\n\nIf Jenkinsfile is in the repo, co-located with code, does this mean Jenkins can\nauto-detect new jobs for different branches?\n\nThis is possible using the\nPipeline Multibranch plugin.\n\nWhat documentation sources are there for Pipeline?\n\nOur documentation section contains a number of pagesaround Pipeline.\nThere is also additional documentation and examples in the plugin’s\ngit repository and the\njenkinsci/pipeline-examples\nrepository. (contributions welcome!)\n\nWhere we can find the DSL method documentation?\n\nThere is generated documentation on jenkins.io which\nincldues steps from all public plugins. Inside of a running Jenkins instance,\nyou can also navigate to\nJENKINS_URL/workflow-cps-snippetizer/dslReference\nto see the documentation for the plugins which are installed in that instance.\n\nIf Pipeline is not support some plugins (there is a lot actually), I needed\nSonarQube Runner but unfortunately it’s not supported yet, in Job DSL plugin i\ncan use \"Configure Block\" and cover any plugin via XML, how i can achieve the\nsame with a Pipeline?\n\nNot at this time\n\nIs there a possibility to create custom tooltips i.e. with a quick reference or\na link to internal project documentation? Might be useful i.e. for junior team\nmembers who need to refer to external docs.\n\nNot generally. Though in the case of Pipeline global libraries, you can create\ndescriptions of vars/functions like standardBuild in the demo, and these will\nappear in Snippet Generator under Global Variables.\n\nOh pipeline supports joining jobs? It’s really good, but I cannot find document\nat https://jenkins.io/doc/ could you tell me where is it?\n\nThere is a build step, but the Pipeline system is optimized for single-job\npipelines\n\nWe have multiple projects that we would like to follow the same pipeline.  How\nwould I write a common pipeline that can be shared across multiple projects.\n\nYou may want to look at implementing some additional steps using the\nPipeline Global\nLibrary feature. This would allow you to define\norganization-specific extensions to the Pipeline DSL to abstract away common\npatterns between projects.\n\nHow much flexibility is there with creating context / setting environment\nvariables or changing / modifying build tool options when calling a web hook /\napi to parameterize pipelines for example to target deployments to different env\nusing same pipeline\n\nVarious environment variables are exposed under the env variable in the Groovy\nDSL which would allow you to construct logic as simple or as complex as\nnecessary to achieve your goal.\n\nWhen you set up the job for the first time, does it build every branch in git,\nor is there a way to stop it from building old branches?\n\nNot at this time, the best way to prevent older branches from being built is to\nremove the Jenkinsfile in those branches. Alternatively, you could use the\n\"include\" or \"exclude\" patterns when setting up the SCM configuration of your\nmultibranch Pipeline. See also\nJENKINS-32396.\n\nSimilar to GitHub organizations, will BitBucket \"projects\" (ways of organizing\ncollections of repos) be supported?\n\nYes, these are supported via the\nBitbucket\nBranch Source plugin.\n\nHow do you handle build secrets with the pipeline plugin? Using unique\ncredentials stored in the credentials plugin per project and/or branch?\n\nThis can be accomplished by using the\nCredentials\nBinding plugin.\n\nSimilar to GitHub Orgs, are Gitlab projects supported in the same way?\n\nGitLab projects are not explicitly supported at this time, but the extension\npoints which the GitHub Organization Folder plugin uses could be extended in a\nsimilar manner for GitLab. See also JENKINS-34396\n\nIs Perforce scm supported by the Pipeline plugin?\n\nAs a SCM source for discovering a Jenkinsfile, not at this time. The\nP4\nplugin does provide some p4 steps which can be used in a Pipeline script\nhowever, see here for documentation.\n\nIs Mercurial supported with multibranch?\n\nYes, it is.\n\nCan Jenkinsfile detect when it’s running against a pull request vs an approved commit, so that it can perform a different type of build?\n\nYes, via the env variables provided in the DSL scope. Using an if statement,\none could guard specific behaviors with:\n\nif (env.CHANGE_ID != null) {\n    /* do things! */\n}\n\nLet’s say I’m building RPMs with Jenkins and use build number as an RPM\nversion/release number. Is there a way to maintain build numbers and leverage\nversioning of Jenkinsfile?\n\nThrough the env variable, it’s possible to utilize env.BUILD_NUMBER or the\nSCM commit ID, etc.\n\nLove the snippet generator! Any chance of separating it out from the pipeline\ninto a separate page on its own, available in the left nav?\n\nYes, this is tracked in\nJENKINS-31831\n\nAny tips on pre-creating the admin user credential and selecting plugins to\nautomate the Jenkins install?\n\nThere are various configuration\nmanagement modules which provide parts of this functionality.\n\nI’m looking at the pipeline syntax (in Jenkins 2.0) how do I detect a\nstep([…​]) has failed and create a notification inside the Jenkinsfile?\n\nThis can be done by wrapping a step invocation with a Groovy try/catch block.\nSee also JENKINS-28119\n\nUser Interface/Experience\n\nIs the user experience same as before when we replace the Jenkins.war(1.x to\n2.x) in an existing (with security in place) installation?\n\nYou will get the new UI features like redesigned configuration forms, but the\ninitial setup wizard will be skipped. In its stead, Jenkins will offer to\ninstall Pipeline-related functionality.\n\nIs it possible to use custom defined syntax highlighting ?\n\nWithin the Pipeline script editor itself, no. It is using the\nACE editor system,\nso it may be possible for a plugin to change the color scheme used.\n\nCan you elaborate on what the Blue Ocean UI is? Is there a link or more\ninformation on it?\n\nBlue Ocean is the name of user experience an design project, unfortunately at\nthis point in time there is not more information available on it.\n\nGeneral\n\nHow well this integrate with cloud environment?\n\nThe Jenkins controller and agents can run easily in any public cloud environment\nthat supports running Java applications. Through the\nEC2,\nJClouds,\nAzure, or\nany other plugins which extend the cloud\nextension\npoint, it is possible to dynamically provision new build agents on a configured\ncloud provider.\n\nAre help texts and other labels and messages updated for other localizations /\nlanguages as well?\n\nPractically every string in Jenkins core is localizable. The extent to which those\nstrings have been translated depends on contributors by speakers of those\nlanguages to the project. If you want to contribute translations, this\nwiki\npage should get you started.\n\nAny additional WinRM/Windows remoting functionality in 2.0?\n\nNo\n\nIs there a CLI to find all the jobs created by a specific user?\n\nNo, out-of-the-box Jenkins does not keep track of which user created which jobs.\nThe functionality provided by the\nOwnership\nplugin may be of interest though.\n\nPlease consider replacing terms like \"master\" and \"slave\" with \"primary\" and\n\"secondary\".\n\n\"slave\" has been replaced with \"agent\" in Jenkins 2.0.\n\nUpdated 2020-09-18 : The term \"master\" is being replaced with \"controller\".\n\nWe’ve been making tutorial videos on Jenkins for awhile (mostly geared toward\npassing the upcoming CCJPE). Because of that we’re using 1.625.2 (since that is\nwhat is listed on the exam), but should we instead base the videos on 2.0?\n\nAs of right now all of the\nJenkins Certification work done by CloudBees is\nfocused around the Jenkins LTS 1.625.x.","title":"Jenkins 2.0 Online JAM Wrap-up","tags":["jenkins2","jam","meetup"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-26T00:00:00.000Z","id":"8d1a1951-ad97-5021-a398-24ee5d471516","slug":"/blog/2016/04/26/jenkins-20-is-here/","strippedHtml":"Over the past 10 years, Jenkins has really\ngrown to a\nde-facto standard tool that millions of people use to handle automation in\nsoftware development and beyond.  It is quite remarkable for a project that\noriginally started as a hobby project under a different name. I’m very proud.\n\nAround this time last year,\nwe’ve\ncelebrated 10 years, 1000 plugins, and 100K installations. That was a good time\nto retrospect, and we started thinking about the next 10 years of Jenkins and\nwhat’s necessary to meet that challenge.  This project has long been on a\nweekly \"train\" release model, so it was useful to step back and think about a\nbig picture.\n\nThat is where three pillars of Jenkins 2.0 have emerged from.\n\nFirst, one of the challenges our users are facing today is that the automation\nthat happens between a commit and a production has significantly grown in its\nscope. Because of this, the clothing that used to fit (aka \"freestyle project\",\nwhich was the workhorse of Jenkins) no longer fits. We now need something that\nbetter fits today’s use cases like \"continuous delivery pipeline.\" This is why\nin 2.0 we’ve added the pipeline capability. This 2 year old effort allows you\nto describe your chain of automation in a textual form. This allows you to\nversion control it, put it alongside your source tree, etc. It is also actually\na domain specific language (DSL) of Groovy, so when your pipeline grows in\ncomplexity/sophistication, you can manage its complexity and keep it\nunderstandable far more easily.\n\nSecond, over time, Jenkins has developed the \"assembly required before initial\nuse\" feeling. As the project has grown, the frontier of interesting development\nhas shifted to plugins, which is how it should be, but we have left it up to\nusers to discover & use them. As a result, the default installation became very\nthin and minimal, and every user has to find several plugins before Jenkins\nbecomes really functional. This created a paradox of choice and unnecessarily\nhurt the user experience. In 2.0, we reset this thinking and tried to create\nmore sensible out of the box experience that solves 80% use cases for 80% of\npeople. You get something useful out of the box, and you can get some\nconsiderable mileage out of it before you start feeling the need of plugins.\nThis allows us to focus our development & QA effort around this base\nfunctionality, too. By the way, the focus on the out of the box experience\ndoesn’t stop at functionality, either. The initial security setup of Jenkins is\nimproved, too, to prevent unprotected Jenkins instances from getting abused by\nbotnets and attacks.\n\nThird, we were fortunate to have a number of developers with UX background\nspend some quality time on Jenkins, and they have made a big dent in improving\nvarious parts of Jenkins web UI. The setup wizard that implements the out of\nthe box experience improvement is one of them, and it also includes other parts\nof Jenkins that you use all the time, such as job configuration pages and new\nitem pages. This brings much needed attention to the web UI.\n\nAs you can see, 2.0 brings a lot of exciting features on the table, but this is\nan evolutionary release, built on top of the same foundation, so that your\nexisting installations can upgrade smoothly. After this initial release, we’ll\nget back to our usual weekly release march.  Improvements will be made\nto those pillars and others in coming months and years continuously. If you’d\nlike to get a more in-depth look at Jenkins 2.0, please join us in our virtual\nJenkins meetup 2.0 launch event.\n\nThank you very much for everyone who made Jenkins 2.0 possible. There are\ntoo many of you\nto thank individually, but you know who you are. I wanted to thank CloudBees in\nparticular for sponsoring the time of many of those people. Ten years ago, all I\ncould utilize was my own night & weekend time. Now I’ve got a team of smart\npeople working with me to carry this torch forward, and a big effort like 2.0\nwouldn’t have been possible without such organized effort.","title":"Jenkins 2.0 is here!","tags":["jenkins2"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"kohsuke","html":"<div class=\"paragraph\">\n<p>Kohsuke is the creator of Jenkins.</p>\n</div>","id":"kohsuke","irc":null,"linkedin":null,"name":"Kohsuke Kawaguchi","slug":"blog/author/kohsuke","twitter":"kohsukekawa"}]}},{"node":{"date":"2016-04-22T00:00:00.000Z","id":"4e17de3e-4be0-59e9-b38e-1f1bbf9188e4","slug":"/blog/2016/04/22/pipeline-2.x/","strippedHtml":"Those of you who routinely apply all plugin updates may already have noticed that the version numbers of the plugins in the Pipeline suite have switched to a 2.x scheme. Besides aligning better with the upcoming Jenkins 2.0 core release, the plugins are now being released with independent lifecycles.\n\n“Pipeline 1.15” (the last in the 1.x line) included simultaneous releases of a dozen or so plugins with the 1.15 version number (and 1.15+ dependencies on each other). All these plugins were built out of a single workflow-plugin repository. While that was convenient in the early days for prototyping wide-ranging changes, it has become an encumbrance now that the Pipeline code is fairly mature, and more people are experimenting with additions and patches.\n\nAs of 2.0, all the plugins in the system live in their own repositories on GitHub—named to match the plugin code name, which in most cases uses the historical workflow term, so for example workflow-job-plugin. Some complex steps were moved into their own plugins, such as pipeline-build-step-plugin. The 1.x changelog is closed; now each plugin keeps a changelog in its own wiki, for example here for the Pipeline Job plugin.\n\nAmong other benefits, this change makes it easier to cut new plugin releases for even minor bug fixes or enhancements, or for developers to experiment with patches to certain plugins. It also opens the door for the “aggregator” plugin (called simply Pipeline) to pull in dependencies on other plugins that seem broadly valuable, like the stage view.\n\nThe original repository has been renamed pipeline-plugin and for now still holds some documentation, which might later be moved to jenkins.io.\n\nYou need not do anything special to “move” to the 2.x line; 1.642.x and later users can just accept all Pipeline-related plugin updates. Note that if you update Pipeline Supporting APIs you must update Pipeline, or at least install/update some related plugins as noted in the wiki.","title":"Pipeline 2.x plugins","tags":["pipeline","jenkins2"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"blog/author/jglick","twitter":"tyvole"}]}},{"node":{"date":"2016-04-22T00:00:00.000Z","id":"be010022-b98d-5767-afad-a1578cc4e23f","slug":"/blog/2016/04/22/possible-infra-compromise/","strippedHtml":"Last week, the infrastructure team identified the potential compromise of a key\ninfrastructure machine. This compromise could have taken advantage of, what\ncould be categorized as, an attempt to target contributors with elevated\naccess. Unfortunately, when facing the uncertainty of a potential compromise,\nthe safest option is to treat it as if it were an actual incident, and react\naccordingly. The machine in question had access to binaries published to our\nprimary and secondary mirrors, and to contributor account information.\n\nSince this machine is not the source of truth for Jenkins binaries, we verified\nthat the files distributed to Jenkins users: plugins, packages, etc, were not\ntampered with. We cannot, however, verify that contributor account information\nwas not accessed or tampered with and, as a proactive measure, we are issuing a\npassword reset for all contributor accounts. We have also spent significant effort\nmigrating all key services off of the potentially compromised machine to\n(virtual) hardware so the machine can be re-imaged or decommissioned entirely.\n\nWhat you should do now\n\nIf you have ever filed an issue in JIRA,\nedited a wiki page, released a plugin or\notherwise created an account via the Jenkins\nwebsite, you have a Jenkins community account. You should be receiving a\npassword reset email shortly, but if you have re-used your Jenkins account\npassword with other services we strongly encourage you to update your passwords\nwith those other services.  If you’re not already using one, we also encourage\nthe use of a password manager for generating and managing service-specific\npasswords.\n\nThe generated password sent out is temporary and will expire if you do not\nuse it to update your account. Once it expires you will need recover your\naccount with the password reset\nin the accounts app.\n\nThis does not apply to your own Jenkins installation, or any account that you\nmay use to log into it. If you do not have a Jenkins community account, there is\nno action you need to take.\n\nWhat we’re doing to prevent events like this in the future\n\nAs stated above, the potentially compromised machine is being removed from our\ninfrastructure. That helps address the immediate problem but doesn’t put\nguarantees in place for the future. To help prevent potential issues in the\nfuture we’re taking the following actions:\n\nIncorporating more security policy enforcement into our\nPuppet-driven infrastructure. Without a\nconfiguration management tool enforcing a given state for some legacy services,\nuser error and manual mis-configurations can adversely affect project security.\nAs of right now, all key services are managed by Puppet.\n\nBalkanizing our machine and permissions model more. The machine affected was\nliterally the first independent (outside of Sun) piece of project\ninfrastructure and like many legacy systems, it grew to host a multitude of\nservices. We are rapidly evolving away from that model with increasing levels\nof user and host separation for project services.\n\nIn a similar vein, we have also introduced a trusted zone in our\ninfrastructure which is not routable on the public internet, where sensitive\noperations, such as generating update center information, can be managed and\nsecured more effectively.\n\nWe are performing an infrastructure permissions audit. Some portions of our\ninfrastructure are 6+ years old and have had contributors come and go. Any\ninactive users with unnecessarily elevated permissions in the project\ninfrastructure will have those permissions revoked.\n\nI would like to extend thanks, on behalf of the Jenkins project, to\nCloudBees for their help in funding and\nmigrating this infrastructure.\n\nIf you have further questions about the Jenkins project infrastructure, you can\njoin us in the #jenkins-infra channel on Freenode\nor in an Infrastructure Q&A session I’ve scheduled for next Wednesday (April\n27) at 20:00 UTC (12:00 PST).","title":"Possible Jenkins Project Infrastructure Compromise","tags":["infra","security"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-21T00:00:00.000Z","id":"d9ce8340-eedf-5dba-874d-c9eba3f8e717","slug":"/blog/2016/04/21/dsl-plugins/","strippedHtml":"In this post I will show how you can make your own DSL extensions and distribute\nthem as a plugin, using Pipeline Script.\n\nA quick refresher\n\nPipeline has a well kept secret: the ability to add your own DSL\nelements. Pipeline is itself a DSL, but you can extend it.\n\nThere are 2 main reasons I can think you may want to do this:\n\nYou want to reduce boilerplate by encapsulating common snippets/things you do\nin one DSL statement.\n\nYou want to provide a DSL that provides a prescriptive way that your builds\nwork - uniform across your organisations Jenkinsfiles.\n\nA DSL could look as simple as\n\nacmeBuild {\n    script = \"./bin/ci\"\n    environment = \"nginx\"\n    team = \"evil-devs\"\n    deployBranch = \"production\"\n}\n\nThis could be the entirety of your Jenkinsfile!\n\nIn this \"simple\" example, it could actually be doing a multi stage build with\nretries, in a specified docker container, that deploys only from the production\nbranch.  Detailed notifications are sent to the right team on important events\n(as defined by your org).\n\nTraditionally this is done via the\nglobal\nlibrary.  You take a snippet of DSL you want to want to make into a DSL, and\ndrop it in the git repo that is baked into Jenkins.\n\nA great trivial\nexample\nis this:\n\njenkinsPlugin {\n    name = 'git'\n}\n\nWhich is enabled by git pushing the following into vars/jenkinsPlugin.groovy\n\nThe name of the file is the name of the DSL expression you use in the Jenkinsfile\n\ndef call(body) {\n    def config = [:]\n    body.resolveStrategy = Closure.DELEGATE_FIRST\n    body.delegate = config\n    body()\n\n    // This is where the magic happens - put your pipeline snippets in here, get variables from config.\n    node {\n        git url: \"https://github.com/jenkinsci/${config.name}-plugin.git\"\n        sh \"mvn install\"\n        mail to: \"...\", subject: \"${config.name} plugin build\", body: \"...\"\n    }\n}\n\nYou can imagine many more pipelines, or even archetypes/templates of pipelines\nyou could do in this way, providing a really easy Jenkinsfile syntax for your\nusers.\n\nMaking it a plugin\n\nUsing the global DSL library is a handy thing if you have a single Jenkins, or\nwant to keep the DSLs local to a Jenkins instance.  But what if you want to\ndistribute it around your org, or, perhaps it is general purpose enough you want\nto share it with the world?\n\nWell this is possible, by wrapping it in a plugin. You use the same pipeline\nsnippet tricks you use in the global lib, but put it in the dsl directory of a\nplugin.\n\nMy simple\nbuild plugin shows how it is done.  To make your own plugin:\n\nCreate a new plugin project, either fork the simple build one, or add a\ndependency to it in your pom.xml / build.gradle file\n\nPut your dsl in the resources directory in a similar fashion to\nthis\n(note the \"package dsl\" declaration at the top)\n\nCreate the equivalent extension that just points to the DSL by name like\nthis\nThis is mostly \"boiler plate\" but it tells Jenkins there is a GlobalVariable extension available when Pipelines run.\n\nDeploy it to an Jenkins Update Center to share with your org, or everyone!\n\nThe advantage of delivering this DSL as a plugin is that it has a version (you\ncan also put tests in there), and distributable just like any other plugin.\n\nFor the more advanced, Andrew Bayer has a Simple\nTravis Runner plugin that\ninterprets and runs\ntravis.yml files which is also implemented in pipeline.\n\nSo, approximately, you can build plugins for pipeline that extend pipeline, in\npipeline script (with a teeny bit of boiler plate).\n\nEnjoy!","title":"Making your own DSL with plugins, written in Pipeline script","tags":["jenkins","dsl","pipeline","plugins"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"blog/author/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2016-04-15T00:00:00.000Z","id":"fa2f2d1b-91d5-5e2e-9783-72c7059face6","slug":"/blog/2016/04/15/the-need-for-pipeline/","strippedHtml":"This is a cross-post of\nan article authored\nby Viktor Farcic on the\nCloudBees blog. Viktor is also the author\nof The DevOps 2.0 Toolkit, which\nexplores Jenkins, the Pipeline plugin, and the ecosystem\naround it in much more detail.\n\nOver the years, Jenkins has become the undisputed ruler among continuous\nintegration (CI), delivery and deployment (CD) tools. It, in a way, defined the\nCI/CD processes we use today. As a result of its leadership, many other products\nhave tried to overthrow it from its position. Among others, we got Bamboo and\nTeam City attempting to get a piece of the market. At the same time, new\nproducts emerged with a service approach (as opposed to on-premises). Some of\nthem are Travis, CircleCI and Shippable. Be that as it may, none managed to get\neven close to Jenkins' adoption. Today, depending on the source we use, Jenkins\nholds between 50-70% of the whole CI/CD tools market. The reason behind such a\nhigh percentage is its dedication to open source principles set from the very\nbeginning by Kohsuke Kawaguchi. Those same principles were the reason he forked\nJenkins from Hudson. The community behind the project, as well as commercial\nentities behind enterprise versions, are continuously improving the way it works\nand adding new features and capabilities. They are redefining not only the way\nJenkins behaves but also the CI/CD practices in a much broader sense. One of\nthose new features is the Jenkins Pipeline plugin. Before we\ndive into it, let us take a step back and discuss the reasons that led us to\ninitiate the move away from Freestyle jobs and towards the Pipeline.\n\nThe Need for Change\n\nOver time, Jenkins, like most other self-hosted CI/CD tools, tends to accumulate\na vast number of jobs. Having a lot of them causes quite an increase in\nmaintenance cost. Maintaining ten jobs is easy. It becomes a bit harder (but\nstill bearable) to manage a hundred. When the number of jobs increases to\nhundreds or even thousands, managing them becomes very tedious and time\ndemanding.\n\nIf you are not proficient with Jenkins (or other CI/CD tools) or you do not work\nfor a big project, you might think that hundreds of jobs is excessive. The truth\nis that such a number is reached over a relatively short period when teams\nare practicing continuous delivery or deployment. Let’s say that an average\nCD flow has the following set of tasks that should be run on each commit:\nbuilding, pre-deployment testing, deployment to a staging environment,\npost-deployment testing and deployment to production. That’s five groups of\ntasks that are often divided into, at least, five separate Jenkins jobs. In\nreality, there are often more than five jobs for a single CD flow, but let\nus keep it an optimistic estimate. How many different CD flows does a medium\nsized company have? With twenty, we are already reaching a three digits\nnumber. That’s quite a lot of  jobs to cope with even though the estimates\nwe used are too optimistic for all but the smallest entities.\n\nNow, imagine that we need to change all those jobs from, let’s say, Maven to\nGradle. We can choose to start modifying them through the Jenkins UI, but that\ntakes too much time. We can apply changes directly to Jenkins XML files that\nrepresent those jobs but that is too complicated and error prone. Besides,\nunless we write a script that will do the modifications for us, we would\nprobably not save much time with this approach. There are quite a few plugins\nthat can help us to apply changes to multiple jobs at once, but none of them is\ntruly successful (at least among free plugins). They all suffer from one\ndeficiency or another. The problem is not whether we have the tools to perform\nmassive changes to our jobs, but whether jobs are defined in a way that they can\nbe easily maintained.\n\nBesides the sheer number of Jenkins jobs, another critical Jenkins' pain point\nis centralization. While having everything in one location provides a lot of\nbenefits (visibility, reporting and so on), it also poses quite a few\ndifficulties. Since the emergence of agile methodologies, there’s been a huge\nmovement towards self-sufficient teams. Instead of horizontal organization with\nseparate development, testing, infrastructure, operations and other groups, more\nand more companies are moving (or already moved) towards self-sufficient teams\norganized vertically. As a result, having one centralized place that defines all\nthe CD flows becomes a liability and often impedes us from splitting teams\nvertically based on projects. Members of a team should be able to collaborate\neffectively without too much reliance on other teams or departments. Translated\nto CD needs, that means that each team should be able to define the deployment\nflow of the application they are developing.\n\nFinally, Jenkins, like many other tools, relies heavily on its UI. While that is\nwelcome and needed as a way to get a visual overview through dashboards and\nreports, it is suboptimal as a way to define the delivery and deployment flows.\nJenkins originated in an era when it was fashionable to use UIs for everything.\nIf you worked in this industry long enough you probably saw the swarm of tools\nthat rely completely on UIs, drag & drop operations and a lot of forms that\nshould be filled. As a result, we got tools that produce artifacts that cannot\nbe easily stored in a code repository and are hard to reason with when anything\nbut simple operations are to be performed. Things changed since then, and now we\nknow that many things (deployment flow being one of them) are much easier to\nexpress through code. That can be observed when, for example, we try to define a\ncomplex flow through many Jenkins jobs. When deployment complexity requires\nconditional executions and some kind of a simple intelligence that depends on\nresults of different steps, chained jobs are truly complicated and often\nimpossible to create.\n\nAll things considered, the major pain points Jenkins had until recently are as\nfollows.\n\nTendency to create a vast number of jobs\n\nRelatively hard and costly maintenance\n\nCentralization of everything\n\nLack of powerful and easy ways to specify deployment flow through code\n\nThis list is, by no means, unique to Jenkins. Other CI/CD tools have at least\none of the same problems or suffer from deficiencies that Jenkins solved a long\ntime ago. Since the focus of this article is Jenkins, I won’t dive into a\ncomparison between the CI/CD tools.\n\nLuckily, all those, and many other deficiencies are now a thing of the past.\nWith the emergence of the\nPipeline\nplugin and many others that were created on\ntop of it, Jenkins entered a new era and proved itself as a dominant player in\nthe CI/CD market. A whole new ecosystem was born, and the door was opened for\nvery exciting possibilities in the future.\n\nBefore we dive into the Jenkins Pipeline and the toolset that surrounds it, let\nus quickly go through the needs of a modern CD flow.\n\nContinuous Delivery or Deployment Flow with Jenkins\n\nWhen embarking on the CD journey for the first time, newcomers tend to think\nthat the tasks that constitute the flow are straightforward and linear. While\nthat might be true with small projects, in most cases things are much more\ncomplicated than that. You might think that the flow consists of building,\ntesting and deployment, and that the approach is linear and follows the\nall-or-nothing rule. Build invokes testing and testing invokes deployment. If\none of them fails, the developer gets a notification, fixes the problem and\ncommits the code that will initiate the repetition of the process.\n\nIn most instances, the process is far more complex. There are many tasks to run,\nand each of them might produce a failure. In some cases, a failure should only\nstop the process. However, more often than not, some additional logic should be\nexecuted as part of the after-failure cleanup. For example, what happens if\npost-deployment tests fail after a new release was deployed to production? We\ncannot just stop the flow and declare the build a failure. We might need to\nrevert to the previous release, rollback the proxy, de-register the service and\nso on. I won’t go into many examples of situations that require complex flow\nwith many tasks, conditionals that depend on results, parallel execution and so\non. Instead, I’ll share a diagram of one of the flows I worked on.\n\nSome tasks are run in one of the testing servers (yellow) while others are run\non the production cluster (blue). While any task might produce an error, in some\ncases such an outcome triggers a separate set of tasks. Some parts of the flow\nare not linear and depend on task results. Some tasks should be executed in\nparallel to improve the overall time required to run them. The list goes on and\non. Please note that this discussion is not about the best way to execute the\ndeployment flow but only a demonstration that the complexity can be, often, very\nhigh and cannot be solved by a simple chaining of Freestyle jobs. Even in cases\nwhen such chaining is possible, the maintenance cost tends to be very high.\n\nOne of the CD objectives we are unable to solve through chained jobs, or is\nproved to be difficult to implement, is conditional logic. In many cases, it is\nnot enough to simply chain jobs in a linear fashion. Often, we do not want only\nto create a job A that, once it’s finished running, executes job B, which, in\nturn, invokes job C. In real-world situations, things are more complicated than\nthat. We want to run some tasks (let’s call them job A), and, depending on the\nresult, invoke jobs B1 or B2, then run in parallel C1, C2 and C3, and, finally,\nexecute job D only when all C jobs are finished successfully. If this were a\nprogram or a script, we would have no problem accomplishing something like that,\nsince all modern programming languages allow us to employ conditional logic in a\nsimple and efficient way. Chained Jenkins jobs, created through its UI, pose\ndifficulties to create even a simple conditional logic. Truth be told, some\nplugins can help us with conditional logic. We have Conditional Build Steps,\nParameterised Trigger, Promotions and others. However, one of the major issues\nwith these plugins is configuration. It tends to be scattered across multiple\nlocations, hard to maintain and with little visibility.\n\nResource allocation needs a careful thought and is, often, more complicated than\na simple decision to run a job on a predefined agent. There are cases when agent\nshould be decided dynamically, workspace should be defined during runtime and\ncleanup depends on a result of some action.\n\nWhile a continuous deployment process means that the whole pipeline ends with\ndeployment to production, many businesses are not ready for such a goal or have\nuse-cases when it is not appropriate. Any other process with a smaller scope, be\nit continuous delivery or continuous integration, often requires some human\ninteraction. A step in the pipeline might need someone’s confirmation, a failed\nprocess might require a manual input about reasons for the failure, and so on.\nThe requirement for human interaction should be an integral part of the pipeline\nand should allow us to pause, inspect and resume the flow. At least, until we\nreach the true continuous deployment stage.\n\nThe industry is, slowly, moving towards microservices architectures. However,\nthe transformation process might take a long time to be adopted, and even more\nto be implemented. Until then, we are stuck with monolithic applications that\noften require a long time for deployment pipelines to be fully executed. It is\nnot uncommon for them to run for a couple of hours, or even days. In such cases,\nfailure of the process, or the whole node the process is running on, should not\nmean that everything needs to be repeated. We should have a mechanism to\ncontinue the flow from defined checkpoints, thus avoiding costly repetition,\npotential delays and additional costs. That is not to say that long-running\ndeployment flows are appropriate or recommended. A well-designed CD process\nshould run within minutes, if not seconds. However, such a process requires not\nonly the flow to be designed well, but also the architecture of our applications\nto be changed. Since, in many cases, that does not seem to be a viable option,\nresumable points of the flow are a time saver.\n\nAll those needs, and many others, needed to be addressed in Jenkins if it was to\ncontinue being a dominant CI/CD tool. Fortunately, developers behind the project\nunderstood those needs and, as a result, we got the Jenkins Pipeline plugin. The\nfuture of Jenkins lies in a transition from Freestyle chained jobs to a single\npipeline expressed as code. Modern delivery flows cannot be expressed and easily\nmaintained through UI drag 'n drop features, nor through chained jobs. They can\nneither be defined through YAML (Yet Another Markup Language) definitions\nproposed by some of the newer tools (which I’m not going to name). We need to go\nback to code as a primary way to define not only the applications and services\nwe are developing but almost everything else. Many other types of tools adopted\nthat approach, and it was time for us to get that option for CI/CD processes as\nwell.","title":"The Need For Jenkins Pipeline","tags":["jenkins2","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-04-14T00:00:00.000Z","id":"c98c0308-267c-58ea-bd87-6999a646f331","slug":"/blog/2016/04/14/jenkins-world-registration-is-open/","strippedHtml":"This is a guest post by Alyssa Tong.\nAlyssa works for CloudBees, helping to organize\nJenkins community events around the\nworld.\n\nJenkins World 2016 will be the largest gathering of Jenkins users in the world. This event will bring together Jenkins experts, continuous delivery thought leaders and the ecosystem offering complementary technologies for Jenkins. Join us September 13-15, 2016 in Santa Clara, California to learn and explore, network face-to-face and help shape the next evolution of Jenkins development and solutions for DevOps.\n\nRegistration for Jenkins World 2016 is now live. Take advantage of the Super Early Bird rate of $399 (available until July 1st).\n\nAnd don’t forget, the Call for Papers will be ending on May 1st. That’s 2.5 short weeks left to get your proposal(s) in.  We anxiously await your amazing stories.","title":"Registration is Open for Jenkins World 2016!","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"blog/author/alyssat","twitter":null}]}}]}},"pageContext":{"limit":8,"skip":408,"numPages":100,"currentPage":52}},
    "staticQueryHashes": ["3649515864"]}