{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/37",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-07-27T00:00:00.000Z","id":"92796c2d-9e8b-530e-82dd-441263269c06","slug":"/blog/2017/07/27/standardizing-builds-with-shared-libraries/","strippedHtml":"This is a guest post by Alvin Huang, DevOps Engineer at\nFireEye.\n\nAs a security company, FireEye relentlessly protects our customers from cyber attacks. To act\nquickly on intelligence and expertise learned, the feedback loop from the front lines to features\nand capabilities in software must be small. Jenkins helps us achieve this by allowing us to build,\ntest, and deploy to our hardware and software platforms faster, so we can stop the bad guys\nbefore they reach our customers.\n\nMore capabilities and functionalities in our product offerings means more applications and\nsystems, which means more software builds and jobs in Jenkins. Within the FaaS (FireEye as a\nService) organization, the tens of Jenkins jobs that were manageable manually in the web GUI\nquickly grew to hundreds of jobs that required more automation. Along the way, we outgrew\nour old legacy datacenter and were tasked with migrating 150+ Freestyle jobs on an old 1.x\nJenkins instance to a newer 2.x instance in the new datacenter in 60 days.\n\nCopying Freestyle job XML configuration files to the new server would leave\ntechnical debt.  Using Freestyle job templates would be better but for\ncomplicated jobs that require multiple templates, this would still create large\ndependency chains that would be hard to trace in the log output. Finally,\ndevelopers were not excited about having to replicate global changes, such as\nadd an email recipient when a new member joins the team, across tens of jobs\nmanually or using the\nConfiguration\nSlicer. We needed a way to migrate the jobs in a timely fashion while getting\nrid of as much technical debt as possible.\n\nJenkins Pipeline to the rescue! In 2.0, Jenkins added the capability to create pipelines as first-\nclass entities. At FireEye, we leveraged many of the features available in pipeline to aid in the\nmigration process including the ability to:\n\ncreate Pipeline as Code in a Jenkinsfile stored in SCM\n\ncreate Jenkins projects automatically when new branches or repos get added with a Jenkinsfile\n\ncontinue jobs after the Jenkins controller or build agent crashes\n\nand most importantly, build a Pipeline\nShared Library that keeps projects\nDRY and\nallows new applications to be on boarded into Jenkins within seconds\n\nHowever, Jenkins Pipeline came with a DSL that our users would have to learn to translate their\nFreestyle jobs to pipeline jobs. This would be a significant undertaking across multiple teams\njust to create Jenkins jobs. Instead, the DevOps team identified similarities across all the\nFreestyle jobs that we were migrating, learned the Jenkins DSL to become SMEs for the\norganization, and built a shared library of functions and wrappers that saved each Dev/QA\nengineer hours of time.\n\nBelow is an example function we created to promote builds in Artifactory:\n\nvars/promoteBuild.groovy\n\ndef call(source_repo, target_repo, build_name, build_number) {\n    stage('Promote to Production repo') {\n        milestone label: 'promote to production'\n        input 'Promote this build to Production?'\n\n        node {\n            Artifactory.server(getArtifactoryServerID()).promote([\n                'buildName'   : build_name,\n                'buildNumber' : build_number,\n                'targetRepo'  : target_repo,\n                'sourceRepo'  : source_repo,\n                'copy'        : true,\n            ])\n    }\n}\n\ndef call(source_repo, target_repo) {\n    buildInfo = getBuildInfo()\n\n    call(source_repo, target_repo, buildInfo.name, buildInfo.number)\n}\n\nRather than learning the Jenkins DSL and looking up how the Artifactory Plugin worked in\nPipeline, users could easily call this function and pass it parameters to do the promotion work\nfor them. In the Shared Library, we can also create build wrappers of opinionated workflows,\nthat encompasses multiple functions, based on a set of parameters defined in the Jenkinsfile.\nIn addition to migrating the jobs, we also had to migrate the build agents. No one knew the\nexact list of packages, versions, and build tools installed on each build server, so rebuilding\nthem would be extremely difficult. Rather than copying the VMs or trying to figure out what\npackages were on the build agents, we opted to use Docker to build containers with all\ndependencies needed for an application.\n\nI hope you will join me at my Jenkins World session:\nCodifying the Build and Release Process with a Jenkins\nPipeline Shared Library, as I deep dive into the inner workings of our Shared\nPipeline Library and explore how we integrated Docker into our CI/CD pipeline.\nCome see how we can turn a Jenkinsfile with just a set of parameters like this:\n\nJenkinsfile\n\nstandardBuild {\n    machine          = 'docker'\n    dev_branch       = 'develop'\n    release_branch   = 'master'\n    artifact_apttern = '*.rpm'\n    html_pattern     = [keepAll: true, reportDir: '.', reportFiles: 'output.html', reportName: 'OutputReport']\n    dev_repo         = 'pipeline-examples-dev'\n    prod_repo        = 'pipeline-examples-prod'\n    pr_script        = 'make prs'\n    dev_script       = 'make dev'\n    release_script   = 'make release'\n}\n\nand a Dockerfile like this:\n\nDockerfile\n\nFROM faas/el7-python:base\n\nRUN yum install -y python-virtualenv \\\n        rpm-build && \\\n        yum clean all\n\nInto a full Jenkins Pipeline like this:\n\nAs we look ahead at FireEye, I will explore how the Shared Library sets us up for easier future\nmigrations of other tools such as Puppet, JIRA, and Artifactory, and easier integration with new\ntools like Openshift. I will also cover our strategies for deployments and plans to move to\nDeclarative Pipeline.\n\nAlvin will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Codifying the Build and Release Process with a Pipeline Shared Library","tags":["event","JenkinsWorld"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2017-07-26T00:00:00.000Z","id":"a5452093-8b55-5ee4-8314-15bc7e02cd41","slug":"/blog/2017/07/26/powershell-pipeline/","strippedHtml":"I am pleased to announce Microsoft PowerShell support for Jenkins Pipeline!\nAs of Durable Task 1.14 and\nPipeline Nodes and Processes Plugin 2.12, you will now be able to run Microsoft PowerShell scripts\ndirectly in your Jenkins Pipeline projects.  This blog post covers the basics\nof getting started with Microsoft PowerShell in Pipeline and provides some\nbasic examples.\n\nIntroduction to Microsoft PowerShell\n\nPowerShell is Microsoft’s open source and cross platform command line shell, as\nwell as an automation and configuration tool/framework which has a broad user\nbase. PowerShell can be used to perform common system administration tasks in\nWindows, macOS, and Linux environments. It can also be used as a general\npurpose scripting language. Now that Jenkins Pipeline supports PowerShell, you\ncan enjoy the rich set of features in PowerShell for your daily DevOps work.\n\nBefore diving into using PowerShell in your Pipeline, I recommend reading the\nWindows\nPowerShell Reference as well as the\nPowerShell Team Blog for an\nintroduction to PowerShell features, utilities, and as a quick look into the\nPowerShell language.  Microsoft also has an active\nPowerShell community on GitHub,\nwhich I highly recommend visiting to submit feature requests and bug\nreports as you see fit. Jenkins Pipeline currently supports Microsoft\nPowerShell 3.0 or higher, so also be sure to check which version of PowerShell\nis installed on your system in order to take advantage of PowerShell in your\nPipeline.  Please note that we recommend that you upgrade to the latest stable\nversion of PowerShell available, which as of this writing is version 5.1.14393.\n\nThe powershell step\n\nnode {\n    powershell 'Write-Output \"Hello, World!\"'\n}\n\nUsing Microsoft PowerShell in Pipeline\n\nWriting PowerShell code as part of your pipeline is incredibly simple. The step that you will use is\nsimply powershell, and it includes the same optional parameters as the\nWindows Batch ( bat) step, including:\n\nreturnStdout: Returns the standard output stream with a default encoding of UTF-8 (alternative encoding is optional)\n\nreturnStatus: Returns the exit status (integer) of the PowerShell script\n\nExamples\n\nCapture exit status of a PowerShell script\n\nnode {\n    def status = powershell(returnStatus: true, script: 'ipconfig')\n    if (status == 0) {\n        // Success!\n    }\n}\n\nCapture and print the output of a PowerShell script\n\nnode {\n    def msg = powershell(returnStdout: true, script: 'Write-Output \"PowerShell is mighty!\"')\n    println msg\n}\n\nWhich streams get returned when I use returnStdout?\n\nUntil the release of PowerShell 5, there were five distinct output streams. PowerShell 5 introduced a sixth stream for pushing \"informational\" content,\nwith the added benefit of being able to capture messages sent to Write-Host. Each row of the following table describes a PowerShell stream along with\nthe corresponding Cmdlet used for writing to the stream for that particular row. Please keep in mind that stream 6 and associated cmdlets either\ndo not exist or exhibit alternate behavior in versions of PowerShell earlier than version 5.\n\nStream\nDescription\nCmdlet\n\n1\nOutput stream (e.g. stdOut)\nWrite-Output\n\n2\nError stream (e.g. stdErr)\nWrite-Error\n\n3\nWarning stream\nWrite-Warning\n\n4\nVerbose stream\nWrite-Verbose\n\n5\nDebug stream\nWrite-Debug\n\n6\nInformation stream\nWrite-Information (or Write-Host with caveats)\n\nIf you are using the returnStdout option of the powershell Pipeline step\nthen only stream 1 will be returned, while streams 2-6 will be redirected to\nthe console output. For example:\n\nWrite to all available streams and return the standard output\n\nnode {\n    def stdout = powershell(returnStdout: true, script: '''\n        # Enable streams 3-6\n        $WarningPreference = 'Continue'\n        $VerbosePreference = 'Continue'\n        $DebugPreference = 'Continue'\n        $InformationPreference = 'Continue'\n\n        Write-Output 'Hello, World!'\n        Write-Error 'Something terrible has happened!'\n        Write-Warning 'Warning! There is nothing wrong with your television set'\n        Write-Verbose 'Do not attempt to adjust the picture'\n        Write-Debug 'We will control the horizontal.  We will control the vertical'\n        Write-Information 'We can change the focus to a soft blur or sharpen it to crystal clarity.'\n    ''')\n    println stdout\n}\n\nConsole output:\n\n[Pipeline] {\n[Pipeline] powershell\n[TestStreams] Running PowerShell script\n\\workspace\\TestStreams@tmp\\durable-4d924c2d\\powershellScript.ps1 : Something terrible has\nhappened!\nAt \\workspace\\TestStreams@tmp\\durable-4d924c2d\\powershellMain.ps1:2 char:1\n+ & ' \\workspace\\TestStreams@tmp\\durable-4d924c ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : NotSpecified: (:) [Write-Error], WriteErrorException\n    + FullyQualifiedErrorId : Microsoft.PowerShell.Commands.WriteErrorException,powershellScript.ps1\n\nWarning! There is nothing wrong with your television set\nDo not attempt to adjust the picture\nWe will control the horizontal.  We will control the vertical\nWe can change the focus to a soft blur or sharpen it to crystal clarity.\nHello, World!\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] End of Pipeline\nERROR: script returned exit code 1\nFinished: FAILURE\n\nNote that \"Hello, World!\" gets printed last even though it is the first output\nstatement in my script.  Another interesting aspect of this example is that the\npowershell step failed, which ultimately caused the job to fail. The failure\nin this example is due to the PowerShell error stream being non-empty, which\ntherefore caused the step to result in a non-zero exit status. However, as you\nwill soon discover, there are a variety of causes for a failing powershell\nstep.\n\nWhat causes a failing exit status?\n\nWhen you execute a powershell step, it may produce a non-zero exit code and\nfail your pipeline build.  This is very similar to other shell steps with some\ninteresting caveats. Your powershell step may produce a failing exit status\nin the following instances:\n\nSomething in your PowerShell script has thrown an exception\n\nYour PowerShell script explicitly calls exit with a non-zero exit code\n\nYour PowerShell script calls a native application that produces a non-zero $LastExitCode\n\n$LastExitCode is an automatic variable that is set after executing a native application\n\nYour PowerShell script results in a non-empty error stream (with or without throwing an exception)\n\nOverriding the exit status behavior of your powershell step can be achieved\nby explicitly exiting from your script as long as the failure was not caused by\nan unhandled exception. For example:\n\nUnavoidable failure caused by an unhandled exception\n\nnode {\n    powershell '''\n        throw 'Error! Problem Exists Between Keyboard And Chair'\n        exit 0  # Unreachable code\n    '''\n}\n\nFailed step caused by a non-empty error stream\n\nnode {\n    powershell '''\n        Write-Error 'Error! Problem Exists Between Keyboard And Chair'\n    '''\n}\n\nFailure prevented by an explicit exit\n\nnode {\n    powershell '''\n        Write-Error 'Error! Problem Exists Between Keyboard And Chair'\n        exit 0\n    '''\n}\n\nScripts vs. Cmdlets\n\nA Cmdlet is a small lightweight utility written in either C#, and compiled, or\nwritten in PowerShell directly. Depending on what your goal is in your pipeline\nyou can make use of Cmdlets directly in your pipeline code, call a self\ncontained PowerShell script, or some mixture of the two. If your strategy is to\nkeep each powershell step as short and succinct as possible then it may make\nsense for you to write a library of Cmdlets, but if you have monolithic scripts\nthen it may make sense for you to call those scripts directly from your\npipeline. The choice is entirely up to you, as both scenarios are supported.\n\nThanks for reading, and have fun!\n\nI sincerely hope that this post has encouraged you to try using PowerShell in\nyour Jenkins Pipeline. Please do not hesitate to file an issue against the\ndurable-task\nplugin on\nJIRA\nif you have discovered any problem that you suspect is related to the\npowershell step.  For general PowerShell related issues or inquiries\nplease route your questions to the\nPowerShell community.","title":"Microsoft PowerShell Support for Pipeline","tags":["durable-task","powershell"],"authors":[{"avatar":null,"blog":null,"github":"gabloe","html":"","id":"gabloe","irc":null,"linkedin":null,"name":"Gabriel Loewen","slug":"/blog/authors/gabloe","twitter":null}]}},{"node":{"date":"2017-07-21T00:00:00.000Z","id":"215b578b-be74-5ce1-b9f3-38b9bfc35f5c","slug":"/blog/2017/07/21/scaling-jenkins-with-kubernetes-on-google-container-engine/","strippedHtml":"This is a guest post by Guillaume Laforge,\nDeveloper Advocate for Google Cloud\n\nLast week, I had the pleasure to speak at the\nJenkins Community Day conference, in Paris,\norganized by my friends from JFrog,\nprovider of awesome tools for software management and distribution.\nI covered how to scale Jenkins with Kubernetes on\nGoogle Container Engine.\n\nFor the impatient, here are the slides of the presentation I’ve given:\n\nBut let’s step back a little. In this article, I’d like to share with you why you would want to run Jenkins in the cloud,\nas well as give you some pointers to interesting resources on the topic.\n\nWhy running Jenkins in the cloud?\n\nSo why running Jenkins in the cloud? First of all, imagine your small team, working on a single project.\nYou have your own little server, running under a desk somewhere, happily building your application on each commit,\na few times a day. So far so good, your build machine running Jenkins isn’t too busy, and stays idle most of the day.\n\nLet’s do some bottom of the napkin calculations. Let’s say you have a team of 3 developers,\ncommitting roughly 4 times a day, on one single project, and the build takes roughly 10 minutes to go.\n\n3 developers * 4 commits / day / developer * 10 minutes build time * 1 project = 1 hour 20 minutes\n\nSo far so good, your server indeed stays idle most of the day. Usually, at most,\nyour developers will wait just 10 minutes to see the result of their work.\n\nBut your team is growing to 10 persons, the team is still as productive, but the project becoming bigger,\nthe build time goes up to 15 minutes:\n\n10 developers * 4 commits / day / developer * 15 minutes build time * 1 project = 10 hours\n\nYou’re already at 10 hours build time, so your server is busy the whole day, and at times,\nyou might have several build going on at the same time, using several CPU cores in parallel.\nAnd instead of building in 15 minutes, sometimes, the build might take longer, or your build might be queued.\nSo in theory, it might be 15 minutes, but in practice, it could be half an hour because of the length of the queue\nor the longer time to build parallel projects.\n\nNow, the company is successful, and has two projects instead of one (think a backend and a mobile app).\nYour teams grow further up to 20 developers per project. The developers are a little less productive\nbecause of the size of the codebase and project, so they only commit 3 times a day.\nThe build takes more time too, at 20 minutes (in ideal time). Let’s do some math again:\n\n20 developers * 3 commits / day / developer * 20 minutes build time * 2 projects = 40 hours\n\nWoh, that’s already 40 hours of total build time, if all the builds are run serially.\nFortunately, our server is multi-core, but still, there are certainly already many builds that are enqueued,\nand many of them, perhaps up to 2-3 or perhaps even 4 could be run in parallel.\nBut as we said, the build queue increases further, the real effective time of build is certainly longer than 30 minutes.\nPerhaps at times, developers won’t see the result of their developments before at least an hour, if not more.\n\nOne last calculation? With team sizes of 30 developers, decreased productivity of 2 commits, 25 build time,\nand 3 projects? And you’ll get 75 hours total build time. You may start creating a little build farm,\nwith a controller and several build agents. But you also increase the burden of server management.\nAlso, if you move towards a full Continuous Delivery or Continuous Deployment approach,\nyou may further increase your build times to go up to deployment, make more but smaller commits, etc.\nYou could think of running builds less often, or even on a nightly basis, to cope with the demand, but then,\nyour company is less agile, and the time-to-market for fixes of new features might increase,\nand your developers may also become more frustrated because they are developing in the blind,\nnot knowing before the next day if their work was successful or not.\n\nWith my calculations, you might think that it makes more sense for big companies, with tons of projects and developers.\nThis is quite true, but when you’re a startup, you also want to avoid taking care of local server management,\nprovisioning, etc. You want to be agile, and use only compute resources you need for the time you need them.\nSo even if you’re a small startup, a small team, it might still make sense to take advantage of the cloud.\nYou pay only for the actual time taken by your builds as the build agent containers are automatically provisioned\nand decommissioned. The builds can scale up via Kubernetes, as you need more (or less) CPU time for building everything.\n\nAnd this is why I was happy to dive into scaling Jenkins in the cloud. For that purpose,\nI decided to go with building with containers, with Kubernetes, as my app was also containerized as well.\nGoogle Cloud offers Container Engine, which is basically just Kubernetes in the cloud.\n\nUseful pointers\n\nI based my presentation and demo on some great solutions that are published on the Google Cloud documentation portal.\nLet me give you some pointers.\n\nOverview of Jenkins on Container Engine\n\nSetting up Jenkins on Container Engine\n\nConfiguring Jenkins for Container Engine\n\nContinuous Deployment to Container Engine using Jenkins\n\nLab: Build a Continuous Deployment Pipeline with Jenkins and Kubernetes\n\nThe latter one is the tutorial I actually followed for the demo that I presented during the conference.\nIt’s a simple Go application, with a frontend and backend.\nIt’s continuously build, on each commit (well, every minute to check if there’s a new commit),\nand deployed automatically in different environments: dev, canary, production.\nThe sources of the project are stored in Cloud Source Repository (it can be mirrored from Github, for example).\nThe containers are stored in Cloud Container Registry.\nAnd both the Jenkins controller and agents, as well as the application are running inside Kubernetes clusters in Container Engine.\n\nSummary and perspective\n\nDon’t bother with managing servers! Quickly, you’ll run out of CPU cycles,\nand you’ll have happier developers with builds that are super snappy!\n\nAnd for the record, at Google, dev teams are also running Jenkins!\nThere was a presentation ( video and\nslides\navailable) given last year by David Hoover at Jenkins World\ntalking about how developers inside Google are running hundreds of build agents to build projects on various platforms.","title":"Scaling Jenkins with Kubernetes on Google Container Engine","tags":["jenkins","kubernetes","jenkins-community-day-paris"],"authors":[{"avatar":null,"blog":"https://glaforge.appspot.com/","github":"glaforge","html":"","id":"glaforge","irc":null,"linkedin":null,"name":"Guillaume Laforge","slug":"/blog/authors/glaforge","twitter":"glaforge"}]}},{"node":{"date":"2017-07-17T00:00:00.000Z","id":"0116e3f0-03af-5f1b-b064-5d44aaf60398","slug":"/blog/2017/07/17/speaker-blog-care/","strippedHtml":"This is a guest post by Mandy Hubbard, Software Engineer/QA Architect at\nCare.com.\n\nImagine this: It’s 4:30pm on a Friday,\nyou have a major release on Monday, and your Jenkins server goes down.\nIt doesn’t matter if it experienced a hardware failure,\nfell victim to a catastrophic\nfat-finger error,\nor just got hit by a meteor - your Jenkins server is toast.\nHow long did it take to perfect your Pipeline,\nall your Continuous Delivery jobs, plugins, and credentials?\nHopefully you at least have a recent backup of your Jenkins home directory,\nbut you’re still going have to work over the weekend with IT to procure a new server,\ninstall it, and do full regression testing to be up and running by Monday morning.\nGo ahead and take a moment, go to your car and just scream.\nIt will help …​ a little.\n\nBut what if you could have a Jenkins environment that is completely disposable,\none that could be easily rebuilt at any time?\nUsing Docker and Joyent’s\nContainerPilot, the team at\nCare.com HomePay\nhas created a production Jenkins environment that is completely software-defined.\nEverything required to set up a new Jenkins environment is stored in source control,\nversioned, and released just like any other software.\nAt Jenkins World, I’ll do a developer deep-dive into this approach during my technical session,\nIndispensable, Disposable Jenkins,\nincluding a demo of bringing up a fully configured Jenkins server in a Docker container.\nFor now, let me give you a basic outline of what we’ve done.\n\nMandy will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.\n\nFirst, we add ContainerPilot to our Jenkins image by including it in the Dockerfile.\n\nDockerfile\n\n## ContainerPilot\n\nENV CONTAINERPILOT_VERSION 2.7.0\nENV CONTAINERPILOT_SHA256 3cf91aabd3d3651613942d65359be9af0f6a25a1df9ec9bd9ea94d980724ee13\nENV CONTAINERPILOT file:///etc/containerpilot/containerpilot.json\n\nRUN curl -Lso /tmp/containerpilot.tar.gz https://github.com/joyent/containerpilot/releases/download/${CONTAINERPILOT_VERSION}/containerpilot-${CONTAINERPILOT_VERSION}.tar.gz && \\\n    echo \"${CONTAINERPILOT_SHA256}  /tmp/containerpilot.tar.gz\" | sha256sum -c && \\\n    tar zxf /tmp/containerpilot.tar.gz -C /bin && \\\nrm /tmp/containerpilot.tar.gz\n\nThen we specify containerpilot as the Docker command in the docker-compose.yml\nand pass the Jenkins startup script as an argument.\nThis allows ContainerPilot to perform our preStart business before starting the Jenkins server.\n\ndocker-compose.yml\n\njenkins:\n    image: devmandy/auto-jenkins:latest\n    restart: always\n    mem_limit: 8g\n    ports:\n      - 80\n      - 22\n    dns:\n      - 8.8.8.8\n      - 127.0.0.1\n    env_file: _env\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - CONSUL=consul\n    links:\n      - consul:consul\n    ports:\n      - \"8080:80\"\n      - \"2222:22\"\n    command: >\n      containerpilot\n      /usr/local/bin/jenkins.sh\n\nConfiguration data is read from a Docker Compose _env file,\nas specified in the docker-compose.yml file,\nand stored in environment variables inside the container.\nThis is an example of our _env file:\n\n_env\n\nGITHUB_TOKEN=\nGITHUB_USERNAME=DevMandy\nGITHUB_ORGANIZATION=DevMandy\nDOCKERHUB_ORGANIZATION=DevMandy\nDOCKERHUB_USERNAME=DevMandy\nDOCKERHUB_PASSWORD=\nDOCKER_HOST=\nSLACK_TEAM_DOMAIN=DevMandy\nSLACK_CHANNEL=jenkinsbuilds\nSLACK_TOKEN=\nBASIC_AUTH=\nAD_NAME=\nAD_SERVER=\nPRIVATE_KEY=\n\nJenkins stores its credentials and plugin information in various xml files.\nThe preStart script modifies the relevant files,\nsubstituting the environment variables as appropriate,\nusing a set of command line utilities called xmlstarlet.\nHere is an example method from our preStart script that configures Github credentials:\n\ngithub_credentials_setup() {\n    ## Setting Up Github username in credentials.xml file\n    echo\n    echo -e \"Adding Github username to credentials.xml file for SSH key\"\n    xmlstarlet \\\n        ed \\\n        --inplace \\\n        -u '//com.cloudbees.jenkins.plugins.sshcredentials.impl.BasicSSHUserPrivateKey[id=\"github\"]/username' \\\n        -v ${GITHUB_USERNAME} \\\n        ${JENKINS_HOME}/credentials.xml\n\n    echo -e \"Adding Github username to credentials.xml file for Github token\"\n    xmlstarlet \\\n        ed \\\n         --inplace \\\n        -u '//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=\"github_token\"]/username' \\\n        -v ${GITHUB_USERNAME} \\\n        ${JENKINS_HOME}/credentials.xml\n\n    PASSWORD=${GITHUB_TOKEN}\n    echo -e \"Adding Github token to credentials.xml\"\n    xmlstarlet \\\n        ed \\\n        --inplace \\\n        -u '//com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl[id=\"github_token\"]/password' \\\n        -v ${PASSWORD} \\\n        ${JENKINS_HOME}/credentials.xml\n}\n\nThis approach can be used to automate all things Jenkins.\nThese are just a few of the things I’ll show you in my Jenkins World session,\nwhich you can build on to automate anything else your Jenkins environment needs.\n\nCreation of credentials sets for interacting with third party services\nlike Github, Docker Hub and Slack\n\nConfiguration of the Active Directory plugin\nand setup of matrix-based security\n\nConfiguration of the Github Organization plugin,\nwhich results in the automatic creation of all Jenkins pipeline jobs\nby scanning the organization for all repositories containing a Jenkinsfile\n\nConfiguration of the\nDocker Pipeline plugin, including creating templates for all custom build agents\n\nConfiguration of the Global Pipeline Libraries plugin\n\nConfiguration of the Slack Notifier plugin\n\nWith software-defined Jenkins, pipeline infrastructure\ngains the same flexibility and resiliency as the rest of the development pipeline.\nIf we decide to change our Jenkins configuration in any way –\nfor example installing a new plugin or upgrading an existing one,\nadding a new global library, or adding new Docker images for build agents –\nwe simply edit our preStart script to include these changes, build a new Docker image,\nand the Jenkins environment is automatically reconfigured when we start a new container.\nBecause the entire configuration specification lives in a Github repository,\nchanges are merged to the \"master\" branch using pull requests,\nand our Jenkins Docker image is tagged using\nsemantic versioning just like any other component.\nJenkins can be both indispensable and completely disposable at the same time.","title":"Indispensable, Disposable Jenkins","tags":["event","JenkinsWorld"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"","id":"hinman","irc":null,"linkedin":null,"name":"Hannah Inman","slug":"/blog/authors/hinman","twitter":null}]}},{"node":{"date":"2017-07-13T00:00:00.000Z","id":"00ad337a-5c86-5032-be3e-f6f4934de80d","slug":"/blog/2017/07/13/speaker-blog-rosetta-stone/","strippedHtml":"This is a guest post by Kevin Burnett, DevOps Lead at\nRosetta Stone.\n\nHave you experienced that thing where you make a change in an app, and when you\ngo to check on the results of the build, you find an error that really doesn’t\nseem relevant to your change? And then you notice that your build is the first\nin over a year. And then you realize that you have accidentally become the\nsubject matter expert in this app.\n\nYou have no clue what change caused this failure or when that change occurred.\nDid one Jenkins agent become a\nsnowflake server,\naccruing cruft on the file system that is not cleaned up before each build?\nDid some unpinned external dependency upgrade in a backwards-incompatible fashion?\nDid the credentials the build plan was using to connect to source control get rotated?\nDid a dependent system go offline?\nOr - and I realize that this is unthinkable - did you legitimately break a test?\n\nNot only is this type of archaeological expedition often a bad time for the\nperson who happened to commit to this app (\"No good deed goes unpunished\"), but\nit’s also unnecessary. There’s a simple way to reduce the cognitive load it\ntakes to connect cause and effect: build more frequently.\n\nOne way we achieve this is by writing scripts to maintain our apps. When we\nbuild, the goal is that an equivalent artifact should be produced unless there\nwas a change to the app in source control. As such, we pin all of our\ndependencies to specific versions. But we also don’t want to languish on old\nversions of dependencies, whether internal or external. So we also have an\nauto-maintain script that bumps all of these versions and commits the result.\n\nI’ll give an example. We use docker to build and deploy our apps, and each app\ndepends on a base image that we host in a docker registry. So a Dockerfile in\none of our apps would have a line like this:\n\nFROM our.registry.example.com/rosettastone/sweet-repo:jenkins-awesome-project-sweet-repo-5\n\nWe build our base images in Jenkins and tag them with the Jenkins $BUILD_TAG,\nso this app is using build 5 of the rosettastone/sweet-repo base image.\nLet’s say we updated our sweet-repo base image to use ubuntu 16.04 instead of 14.04\nand this resulted in build 6 of the base image. Our auto-maintain script takes\ncare of upgrading an app that uses this base image to the most recent version.\nThe steps in the auto-maintain script look like this:\n\nFigure out what base image tag you’re using.\n\nFind the newest version of that base image tag by querying the docker registry.\n\nIf necessary, update the FROM line in the app’s Dockerfile to pull in the most recent version.\n\nWe do the same thing with library dependencies.\nIf our Gemfile.lock is referencing an old library, running auto-maintain will update things.\nThe same applies to the Jenkinsfile for each app. If we decide to implement a new policy where we\ndiscard old builds, we update auto-maintain so that it will bring each app into\ncompliance with the policy, by changing, for example, this Jenkinsfile :\n\nJenkinsfile (Before)\n\npipeline {\n  agent { label 'docker' }\n  stages {\n    stage('commit_stage') {\n      steps {\n        sh('./bin/ci')\n      }\n    }\n  }\n}\n\nto this:\n\nJenkinsfile (After)\n\npipeline {\n  agent { label 'docker' }\n  options {\n    buildDiscarder(logRotator(numToKeepStr: '100'))\n  }\n  stages {\n    stage('commit_stage') {\n      steps {\n        sh('./bin/ci')\n      }\n    }\n  }\n}\n\nWe try to account for these sorts of things (everything that we can) in our\nauto-maintain script rather than updating apps manually, since this reduces the\nfriction in keeping apps standardized.\n\nOnce you create an auto-maintain script (start small), you just have to run it.\nWe run ours based on both \"actions\" and \"non-actions.\" When an internal library\nchanges, we kick off app builds, so a library’s Jenkinsfile might look like\nthis:\n\nJenkinsfile\n\npipeline {\n  agent { label 'docker' }\n  stages {\n    stage('commit_stage') {\n      steps {\n        sh('./bin/ci')\n      }\n    }\n    stage('auto_maintain_things_that_might_be_using_me') {\n      steps {\n        build('hot-project/auto-maintain-all-apps/master')\n      }\n    }\n  }\n}\n\nWhen auto-maintain updates something in an app, we have it commit the change\nback to the app, which in turn triggers a build of that app, and—​if all is\nwell—​a production deployment.\n\nThe only missing link then for avoiding one-year build droughts is to get around\nthe problem where auto-maintain isn’t actually updating anything in a certain app.\nIf no dependencies are changing, or if the technology in question is not\nreceiving much attention, auto-maintain might not do anything for an\nextended period of time, even if the script is run on a schedule using\ncron . For those cases, putting\na cron trigger in the Pipeline for each app will ensure that builds still happen periodically:\n\nJenkinsfile\n\npipeline {\n  agent { label 'docker' }\n  triggers {\n    cron('@weekly')\n  }\n  stages {\n    stage('commit_stage') {\n      steps {\n        sh('./bin/ci')\n      }\n    }\n  }\n}\n\nIn most cases, these periodic builds won’t do anything different from the last\nbuild, but when something does break, this strategy will allow you to decide\nwhen you find out about it (by making your cron @weekly, @daily, etc)\ninstead of letting some poor developer find out about it when they do\nsomething silly like commit code to an infrequently-modified app.\n\nKevin will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Automated Software Maintenance","tags":["event","jenkinsworld","jenkinsworld2017"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"","id":"hinman","irc":null,"linkedin":null,"name":"Hannah Inman","slug":"/blog/authors/hinman","twitter":null}]}},{"node":{"date":"2017-07-10T00:00:00.000Z","id":"8686ea9f-8c07-53fb-867e-e9ea74741ecf","slug":"/blog/2017/07/10/security-advisory/","strippedHtml":"Multiple Jenkins plugins received updates today that fix several security vulnerabilities, including high severity ones:\n\nDocker Commons Plugin\n\nGit Plugin\n\nGitHub Branch Source Plugin\n\nParameterized Trigger Plugin\n\nPeriodic Backup Plugin\n\nPipeline: Build Step Plugin\n\nPipeline: Groovy Plugin\n\nPoll SCM Plugin\n\nRole-based Authorization Strategy Plugin\n\nScript Security Plugin\n\nSidebar Link Plugin\n\nSubversion Plugin\n\nAdditionally, the SSH Plugin received a security update a few days ago.\n\nFor an overview of what was fixed, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for multiple Jenkins plugins","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2017-07-07T00:00:00.000Z","id":"7541af12-10e1-5d79-bcc7-41f0ae0d3010","slug":"/blog/2017/07/07/jenkins-conan/","strippedHtml":"This is a guest post by Luis Martínez de Bartolomé,\nConan Co-Founder\n\nC and C++ are present in very important industries today, including Operating Systems, embedded systems, finances, research, automotive, robotics, gaming, and many more. The main reason for this is performance, which is critical to many of these industries, and cannot be compared to any other technology.\nAs a counterpart, the C/C++ ecosystem has a few important challenges to face:\n\nHuge projects - With millions of lines of code, it’s very hard to manage your projects without using modern tools.\n\nApplication Binary Interface (ABI) incompatibility - To guarantee the compatibility of a library with other libraries and your application,  different configurations (such as the operating system, architecture, and compiler) need to be under control.\n\nSlow compilation times - Due to header inclusion and pre-processor bloat, together with the challenges mentioned above, it requires special attention to optimize the process and rebuild only the libraries that need to be rebuilt.\n\nCode linkage and inlining - A static C/C++ library can embed headers from a dependent library. Also, a shared library can embed a static library. In both cases, you need to manage the rebuild of your library when any of its dependencies change.\n\nVaried ecosystem - There are many different compilers and build systems, for different platforms, targets and purposes.\n\nThis post will show how to implement DevOps best practices for C/C++ development, using Jenkins CI, Conan C/C++ package manager, and JFrog Artifactory the universal artifact repository.\n\nConan, The C/C++ Package Manager\n\nConan was born to mitigate these pains.\n\nConan uses python recipes, describing how to build a library by explicitly calling any build system, and also describing the needed information for the consumers (include directories, library names etc.).\nTo manage the different configurations and the ABI compatibility, Conan uses \"settings\" (os, architecture, compiler…). When a setting is changed, Conan generates a different binary version for the same library:\n\nThe built binaries can be uploaded to JFrog Artifactory or Bintray, to be shared with your team or the whole community. The developers in your team won’t need to rebuild the libraries again, Conan will fetch only the needed Binary packages matching the user’s configuration from the configured remotes (distributed model).\nBut there are still some more challenges to solve:\n\nHow to manage the development and release process of your C/C++ projects?\n\nHow to distribute your C/C++ libraries?\n\nHow to test your C/C++ project?\n\nHow to generate multiple packages for different configurations?\n*How to manage the rebuild of the libraries when one of them changes?\n\nConan Ecosystem\n\nThe Conan ecosystem is growing fast, and DevOps with C/C++ is now a reality:\n\nJFrog Artifactory manages the full development and releasing cycles.\n\nJFrog Bintray is the universal distribution hub.\n\nJenkins automates the project testing, generates different binary configurations of your Conan packages, and automates the rebuilt libraries.\n\nJenkins Artifactory plugin\n\nProvides a Conan DSL, a very generic but powerful way to call Conan from a Jenkins Pipeline script.\n\nManages the remote configuration with your Artifactory instance, hiding the authentication details.\n\nCollects from any Conan operation (installing/uploading packages) all the involved artifacts to generate and publish the buildInfo to Artifactory. The buildInfo object is very useful, for example, to promote the created Conan packages to a different repository and to have full traceability of the Jenkins build:\n\nHere’s an example of the Conan DSL with the Artifactory plugin.  First we configure the Artifactory repository, then retrieve the dependencies and finally build it:\n\ndef artifactory_name = \"artifactory\"\ndef artifactory_repo = \"conan-local\"\ndef repo_url = 'https://github.com/memsharded/example-boost-poco.git'\ndef repo_branch = 'master'\n\nnode {\n   def server\n   def client\n   def serverName\n\nstage(\"Get project\"){\n    git branch: repo_branch, url: repo_url\n}\n\nstage(\"Configure Artifactory/Conan\"){\n    server = Artifactory.server artifactory_name\n    client = Artifactory.newConanClient()\n    serverName = client.remote.add server: server, repo: artifactory_repo\n}\n\nstage(\"Get dependencies and publish build info\"){\n    sh \"mkdir -p build\"\n    dir ('build') {\n      def b = client.run(command: \"install ..\")\n      server.publishBuildInfo b\n    }\n}\n\nstage(\"Build/Test project\"){\n        dir ('build') {\n          sh \"cmake ../ && cmake --build .\"\n        }\n    }\n}\n\nYou can see in the above example that the Conan DSL is very explicit. It helps a lot with common operations, but also allows powerful and custom integrations. This is very important for C/C++ projects, because every company has a very specific project structure, custom integrations etc.\n\nComplex Jenkins Pipeline operations: Managed and parallelized libraries building\n\nAs we saw at the beginning of this blog post, it’s crucial to save time when building a C/C++ project. Here are several ways to optimize the process:\n\nOnly re-build the libraries that need to be rebuilt. These are the libraries that  have been affected by a dependant library that has changed.\n\nBuild in parallel, if possible. When there is no relation between two or more libraries in the project graph, you can build them in parallel.\n\nBuild different configurations (os, compiler, etc) in parallel. Use different agents if needed.\n\nLet’s see an example using Jenkins Pipeline feature\n\nThe above graph represents our project P and its dependencies (A-G). We want to distribute the project for two different architectures, x86 and x86_64.\n\nWhat happens if we change library A?\n\nIf we bump the version to A(v1) there is no problem, we can update the B requirement and also bump its version to B(v1) and so on. The complete flow would be as follows:\n\nPush A(v1) version to Git, Jenkins will build the x86 and x86_64 binaries. Jenkins will upload all the packages to Artifactory.\n\nManually change B to v1, now depending on A1, push to Git, Jenkins will build the B(v1) for x86 and x86_64 using the retrieved new A1 from Artifactory.\n\nRepeat the same process for C, D, F, G and finally our project.\n\nBut if we are developing our libraries in a development repository, we probably depend on the latest A version or will override A (v0) packages on every git push, and we want to automatically rebuild the affected libraries in this case B, D, F, G and P.\n\nHow we can do this with Jenkins Pipelines?\n\nFirst we need to know which libraries need to be rebuilt. The \"conan info --build_order\" command identifies the libraries that were changed in our project, and also tells us which can be rebuilt in parallel.\n\nSo, we created two Jenkins pipelines tasks:\n\nThe\"SimpleBuild\" task which builds every single library. Similar to the first example using Conan DSL with the Jenkins Artifactory plugin. It’s a parameterized task that receives the libraries that need to built.\n\nThe\"MultiBuild\" task which coordinates and launches the \" SimpleBuild\" tasks, in parallel when possible.\n\nWe also have a repository with a configuration yml. The Jenkins tasks will use it to know where the recipe of each library is, and the different profiles to be used. In this case they are x86 and x86_64.\n\nleaves:\n  PROJECT:\n    profiles:\n       - ./profiles/osx_64\n       - ./profiles/osx_32\n\nartifactory:\n  name: artifactory\n  repo: conan-local\n\nrepos:\n LIB_A/1.0:\n   url: https://github.com/lasote/skynet_example.git\n   branch: master\n   dir: ./recipes/A\n\nLIB_B/1.0:\n url: https://github.com/lasote/skynet_example.git\n branch: master\n dir: ./recipes/b\n\n…\n\nPROJECT:\n url: https://github.com/lasote/skynet_example.git\n branch: master\n dir: ./recipes/PROJECT\n\nIf we change and push library A to the repository, the \" MultiBuild\" task will be triggered. It will start by checking which libraries need to be rebuilt, using the \"conan info\" command.\nConan will return something like this:\n[B, [D, F], G]\n\nThis means that we need to start building B, then we can build D and F in parallel, and finally build G. Note that library C does not need to be rebuilt, because it’s not affected by a change in library A.\n\nThe \" MultiBuild\" Jenkins pipeline script will create closures with the parallelized calls to the \" SimpleBuild\" task, and finally launch the groups in parallel.\n\n//for each group\n      tasks = [:]\n      // for each dep in group\n         tasks[label] = { -> build(job: \"SimpleBuild\",\n                            parameters: [\n                               string(name: \"build_label\", value: label),\n                               string(name: \"channel\", value: a_build[\"channel\"]),\n                               string(name: \"name_version\", value: a_build[\"name_version\"]),\n                               string(name: \"conf_repo_url\", value: conf_repo_url),\n                               string(name: \"conf_repo_branch\", value: conf_repo_branch),\n                               string(name: \"profile\", value: a_build[\"profile\"])\n                            ]\n                     )\n          }\n     parallel(tasks)\n\nEventually, this is what will happen:\n\nTwo SimpleBuild tasks will be  triggered, both for building library B, one for x86 and another for x86_64 architectures\n\nOnce \"A\" and \"B\" are built, \"F\" and \"D\" will be triggered, 4 workers will run the \"SimpleBuild\" task in parallel, (x86, x86_64)\n\nFinally \"G\" will be built. So 2 workers will run in parallel.\n\nThe Jenkins Stage View for the will looks similar to the figures below:\n\nMultiBuild\n\nSimpleBuild\n\nWe can configure the \" SimpleBuild\" task within different nodes (Windows, OSX, Linux…), and control the number of executors available in our Jenkins configuration.\n\nConclusions\n\nEmbracing DevOps for C/C++ is still marked as a to-do for many companies. It requires a big investment of time but can save huge amounts of time in the development and releasing life cycle for the long run. Moreover it increases the quality and the reliability of the C/C++ products. Very soon, adoption of DevOps for C/C++ companies will be a must!\n\nThe Jenkins example shown above that demonstrating how to control the library building in parallel is just Groovy code and a custom convenient yml file. The great thing about it is not the example or the code itself. The great thing is the possibility of defining your own pipeline scripts to adapt to your specific workflows, thanks to Jenkins Pipeline, Conan and JFrog Artifactory.\n\nMore on this topic will be presented at Jenkins Community Day Paris on\nJuly 11, and Jenkins User Conference Israel on July 13.","title":"Continuous Integration for C/C++ Projects with Jenkins and Conan","tags":["event","jenkins-user-conference","jenkins-community-day-paris"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg","srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/8d248/alyssat.jpg 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/c004c/alyssat.jpg 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/9e67b/alyssat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/22924/alyssat.webp 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/89767/alyssat.webp 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/40d97/alyssat.webp 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/5028e/alyssat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":166}}},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"/blog/authors/alyssat","twitter":null}]}},{"node":{"date":"2017-07-05T00:00:00.000Z","id":"fd2d8b89-b05f-5caf-a6b1-923d33960065","slug":"/blog/2017/07/05/continuousdelivery-devops-artifactory/","strippedHtml":"This is a guest post by Michael Hüttermann. Michael is an expert\nin Continuous Delivery, DevOps and SCM/ALM. More information about him at huettermann.net, or\nfollow him on Twitter: @huettermann.\n\nIn a past blog post Delivery Pipelines,\nwith Jenkins 2, SonarQube, and Artifactory, we talked about pipelines which result in binaries for development versions. Now, in this blog post, I zoom in to different parts of the\nholistic pipeline and cover the handling of possible downstream steps once you have the binaries of development versions, in our example a Java EE WAR and a Docker image (which contains the WAR).\nWe discuss basic concept of staging software, including further information about quality gates, and show example toolchains. This contribution particularly examines the staging from binaries from\ndev versions to release candidate versions and from release candidate versions to final releases from the perspective of the automation server Jenkins, integrating with the binary\nrepository manager JFrog Artifactory and the distribution management platform JFrog Bintray, and ecosystem.\n\nStaging software\n\nStaging (also often called promoting) software is the process of completely and consistently transferring a release with all its configuration items\nfrom one environment to another. This is even more true with DevOps, where you want to accelerate the cycle time (see Michael Hüttermann, DevOps for Developers (Apress, 2012), 38ff).\nFor accelerating the cycle time, meaning to bring software to production, fast and in good quality, it is crucial to have fine processes and integrated tools to streamline the\ndelivery of software. The process of staging releases consists of deploying software to different staging levels, especially different test environments.\nStaging also involves configuring the software for various environments without needing to recompile or rebuild the software. Staging is necessary\nto transport the software to production systems in high quality. Many Agile projects make great experience with implementing a staging ladder in\norder to optimize the cycle time between development software and the point when the end user is able to use the software in production.\n\nCommonly, the staging ladder is illustrated on its side, with the higher rungs being the boxes further to the right. It’s good practice not to skip any rungs during staging.\nThe central development environment packages and integrates all respective configuration items and is the base for releasing. Software is staged over different environments by\nconfiguration, without rebuilding. All changes go through the entire staging process, although defined exception routines may be in place,\nfor details see Michael Hüttermann, Agile ALM (Manning, 2012).\n\nTo make concepts clearer, this blog post covers sample tools. Please note, that there are also alternative tools available. As one example: Sonatype Nexus is also able to host the covered binaries and also offers scripting functionality.\n\nWe nowadays often talk about delivery pipelines. A pipeline is just a set of stages and transition rules between those stages. From a DevOps perspective, a pipeline bridges multiple\nfunctions in organizations, above all development and operations. A pipeline is a staging ladder. A change enters the pipeline at the beginning and leaves it at the end. The processing\ncan be triggered automatically (typical for delivery pipelines) or by a human actor (typical for special steps at overall pipelines, e.g. pulling and thus cherry-picking specific\nversions to promote them to be release candidates are final releases).\n\nPipelines often look different, because they strongly depend on requirements and basic conditions, and can contain further sub pipelines. In our scenario, we have two sub pipelines to\nmanage the promotion of continuous dev versions to release candidates and the promotion of release candidates to final release. A change typically waits at a stage for further processing\naccording to the transition rules, aligned with defined requirements to meet, which are the Quality Gates, explored next.\n\nQuality Gates\n\nQuality gates allow the software to pass through stages only if it meets their defined requirements. The next illustration shows a staging ladder with quality gates injected. You and\nother engaged developers commit code to the version control system (please, use VCS as an abbreviation, not SCM, because the latter is much more) in order to update the central test\nenvironment only if the code satisfies the defined quality requirements; for instance, the local build may need to run successfully and have all tests pass locally. Build, test, and\nmetrics should pass out of the central development environment, and then automated and manual acceptance tests are needed to pass the system test. In our case, the last quality gate\nto pass is the one from the  production mirror to production. Here, for example, specific production tests are done or relevant documents must be filled in and signed.\n\nIt’s mandatory to define the quality requirements in advance and to resist customizing them after the fact, when the software has failed. Quality gates are different at lower and\nhigher stages; the latter normally consist of a more severe or broader set of quality requirements, and they often include the requirements of the lower gates. The binary repository\nmanager must underpin corresponding quality gates, while managing the binaries, what we cover next.\n\nThis blog post illustrates typical concepts and sample toolchains. For more information, please consult the respective documentation, good books or attend top notch conferences, e.g.\nJenkins World, powered by CloudBees.\n\nBinary repository manager\n\nA central backbone of the staging ladder is the binary repository manager, e.g. JFrog Artifactory. The binary repository manager manages all binaries including the self-produced\nones (producing view) and the 3rd party ones (consuming view), across all artifact types, in our case a Java EE WAR file and a Docker image. Basic idea here is that the repo manager serves\nas a proxy, thus all developers access the repo manager, and not remote binary pools directly, e.g. Maven Central. The binary repository manager offers cross-cutting services,\ne.g. role-based access control on specific logical repositories, which may correspond to specific stages of the staging ladder.\n\nLogical repositories can be generic ones (meaning they are agnostic regarding any tools and platforms, thus you can also just upload the menu of your local canteen) or repos\nspecific to tools and platforms. In our case, we need a repository for managing the Java EE WAR files and for the Docker images. This can be achieved by\n\na generic repository (preferred for higher stages) or a repo which is aligned with the layout of the Maven build tool, and\n\na repository for managing Docker images, which serves as a Docker registry.\n\nIn our scenario, preparing the staging of artifacts includes the following ramp-up activities\n\nCreating two sets of logical repositories, inside JFrog Artifactory, where each set has a repo for the WAR file and a repo for the Docker image, and one set is for managing dev\nversions and one set is for release candidate versions.\n\nDefining and implementing processes to promote the binaries from the one set of repositories (which is for dev versions) to the other set of repositories (which is for RC versions).\nPart of the process is defining roles, and JFrog Artifactory helps you to implement role-based access control.\n\nSetting up procedures or scripts to bring binaries from one set of repositories to the other set of repositories, reproducibly. Adding meta data to binaries is important if the degree of maturity\nof the binary cannot be easily derived from the context.\n\nThe following illustration shows a JFrog Artifactory instance with the involved logical repos in place. In our simplified example, the repo promotions are supposed to go from\ndocker-local to docker-prod-local, and from libs-release-local to libs-releases-staging-local. In our use case, we promote the software in version 1.0.0.\n\nAnother type of binary repository manager is JFrog Bintray, which serves as a universal distribution platform for many technologies. JFrog Bintray can be an interesting choice\nif you have strong requirements for scalability and worldwide coverage including IP restrictions and handy features around statistics. Most of the concepts and ramp up activities\n are similar compared to JFrog Artifactory, thus I do not want to repeat them here. Bintray is used by lot of projects e.g. by Groovy, to host their deliverables in the public.\n But keep in mind that you can of course also host your release binaries in JFrog Artifactory.\n In this blog post, I’d like to introduce different options, thus we promote our release candidates to JFrog Artifactory and our releases to JFrog Bintray.\n Bintray has the concept of products, packages and versions. A product can have multiple packages and has different versions. In our example, the product has two packages, namely the Java EE WAR and\n the Docker image, and the concrete version that will be processed is 1.0.0.\n\nSome tool features covered in this blog post are available as part of commercial offerings of tool vendors. Examples include the Docker support of JFrog Artifactory or the Firehose Event API of JFrog Bintray.\nPlease consult the respective documentation for more information.\n\nNow it is time to have a deeper look at the pipelines.\n\nImplementing Pipelines\n\nOur example pipelines are implemented with Jenkins, including its Blue Ocean and declarative pipelines facilities, JFrog Artifactory and JFrog Bintray. To derive your personal\npipelines, please check your individual requirements and basic conditions to come up with the best solution for your target architecture, and consult the respective documentation for\n more information, e.g. about scripting the tools.\n\nIn case your development versions are built with Maven, and have SNAPSHOT character, you need to either rebuild the software after setting the release version, as part of\nyour pipeline, or you solely use Maven releases from the very beginning. Many projects make great experience with morphing Maven snapshot versions into\nrelease versions, as part of the pipeline, by using a dedicated Maven plugin, and externalizing it into a Jenkins shared library. This can look like the following:\n\nsl.groovy (excerpt): A Jenkins shared library, to include in Jenkins pipelines.\n\n#!/usr/bin/groovy\n    def call(args) { (1)\necho \"Calling shared library, with ${args}.\"\n       sh \"mvn com.huettermann:versionfetcher:1.0.0:release versions:set -DgenerateBackupPoms=false -f ${args}\" (2)\n}\n\n1\nWe provide a global variable/function to include it in our pipelines.\n\n2\nThe library calls a Maven plugin, which dynamically morphs the snapshot version of a Maven project to a release version.\n\nAnd including it into the pipeline is then also very straight forward:\n\npipeline.groovy (excerpt): A stage calling a Jenkins shared library.\n\nstage('Produce RC') { (1)\nreleaseVersion 'all/pom.xml' (2)\n}\n\n1\nThis stage is part of a scripted pipeline and is dedicated to morphing a Maven snapshot version into a release version, dynamically.\n\n2\nWe call the Jenkins shared library, with a parameter pointing to the Maven POM file, which can be a parent POM.\n\nYou can find the code of the underlying Maven plugin here.\n\nLet’s now discuss how to proceed for the release candidates.\n\nRelease Candidate (RC)\n\nThe pipeline to promote a dev version to a RC version does contain a couple of different stages, including stages to certify the binaries (meaning labeling it or adding context information) and stages to process the concrete promotion.\nThe following illustration shows the successful run of the promotion, for software version 1.0.0.\n\nWe utilize Jenkins Blue Ocean that is a new user experience for Jenkins based on a personalizable, modern design that allows users to graphically create, visualize and diagnose\ndelivery pipelines. Besides the new approach in general, single Blue Ocean features help to boost productivity dramatically, e.g. to provide log information at your fingertips\nand the ability to search pipelines. The stages to perform the promote are as follows starting with the  Jenkins pipeline stage for promoting the WAR file. Keep in mind that all\nscripts are parameterized, including variables for versions and Artifactory domain names, which are either injected to the pipeline run by user input or set system wide in the Jenkins admin panel,\nand the underlying call is using the JFrog command line interface, CLI in short. JFrog Artifactory\nas well as JFrog Bintray can be used and managed by scripts, based on a REST API. The JFrog CLI\nis an abstraction on top of the JFrog REST API, and we show sample usages of both.\n\npipeline.groovy (excerpt): Staging WAR file to different logical repository\n\nstage('Promote WAR') { (1)\nsteps { (2)\nsh 'jfrog rt cp --url=https://$ARTI3 --apikey=$artifactory_key --flat=true libs-release-local/com/huettermann/web/$version/ ' + (3)\n'libs-releases-staging-local/com/huettermann/web/$version/'\n       }\n    }\n\n1\nThe dedicated stage for running the promotion of the WAR file.\n\n2\nHere we have the steps which make up the stage, based on Jenkins declarative pipeline syntax.\n\n3\nCopying the WAR file, with JFrog CLI, using variables, e.g. the domain name of the Artifactory installation. Many options available, check the docs.\n\nThe second stage to explore more is the promotion of the Docker image. Here, I want to show you a different way how to achieve the goal, thus in this use case we utilize the JFrog REST API.\n\npipeline.grovvy (excerpt): Promote Docker image\n\nstage('Promote Docker Image') {\n          sh '''curl -H \"X-JFrog-Art-Api:$artifactory_key\" -X POST https://$ARTI3/api/docker/docker-local/v2/promote ''' + (1)\n'''-H \"Content-Type:application/json\" ''' + (2)\n'''-d \\'{\"targetRepo\" : \"docker-prod-local\", \"dockerRepository\" : \"michaelhuettermann/tomcat7\", \"tag\": \"\\'$version\\'\", \"copy\": true }\\' (3)\n'''\n    }\n\n1\nThe shell script to perform the staging of Docker image is based on JFrog REST API.\n\n2\nPart of parameters are sent in JSON format.\n\n3\nThe payload tells the REST API endpoint what to to, i.e. gives information about target repo and tag.\n\nOnce the binaries are promoted (and hopefully deployed and tested on respective environments before), we can promote them to become final releases, which I like to call GA.\n\nGeneral Availability (GA)\n\nIn our scenario, JFrog Bintray serves as the distribution platform to manage and provide binaries for further usage. Bintray can also serve as a Docker registry, or can just\nprovide binaries for scripted or manual download. There are again different ways how to promote binaries, in this case from the RC repos inside JFrog Artifactory to the GA storage in JFrog Bintray, and I summarize one of those possible ways. First, let’s look at the Jenkins pipeline, showed in the next illustration. The processing is on its way, currently, and we again have a list of linked stages.\n\nZooming in now to the key stages, we see that promoting the WAR file is a set of steps that utilize JFrog REST API. We download the binary from JFrog Artifactory, parameterized,\nand upload it to JFrog Bintray.\n\npipeline.groovy (excerpt): Promote WAR to Bintray\n\nstage('Promote WAR to Bintray') {\n       steps {\n          sh '''\n             curl -u michaelhuettermann:${bintray_key} -X DELETE https://api.bintray.com/packages/huettermann/meow/cat/versions/$version (1)\ncurl -u michaelhuettermann:${bintray_key} -H \"Content-Type: application/json\" -X POST https://api.bintray.com/packages/huettermann/meow/cat/$version --data \"\"\"{ \"name\": \"$version\", \"desc\": \"desc\" }\"\"\" (2)\ncurl -T \"$WORKSPACE/all-$version-GA.war\" -u michaelhuettermann:${bintray_key} -H \"X-Bintray-Package:cat\" -H \"X-Bintray-Version:$version\" https://api.bintray.com/content/huettermann/meow/ (3)\ncurl -u michaelhuettermann:${bintray_key} -H \"Content-Type: application/json\" -X POST https://api.bintray.com/content/huettermann/meow/cat/$version/publish --data '{ \"discard\": \"false\" }' (4)\n'''\n       }\n    }\n\n1\nFor testing and demo purposes, we remove the existing release version.\n\n2\nNext we create the version in Bintray, in our case the created version is 1.0.0. The value was insert by user while triggering the pipeline.\n\n3\nThe upload of the WAR file.\n\n4\nBintray needs a dedicated publish step to make the binary publicly available.\n\nProcessing the Docker image is as easy as processing the WAR. In this case, we just push the Docker image to the Docker registry, which is served by JFrog Bintray.\n\npipeline.groovy (excerpt): Promote Docker image to Bintray\n\nstage('Promote Docker Image to Bintray') { (1)\nsteps {\n          sh 'docker push $BINTRAYREGISTRY/michaelhuettermann/tomcat7:$version' (2)\n}\n    }\n\n1\nThe stage for promoting the Docker image. Please note, depending on your setup, you may add further stages, e.g. to login to your Docker registry.\n\n2\nThe Docker push of the specific version. Note, that also here all variables are parameterized.\n\nWe now have promoted the binaries and uploaded them to JFrog Bintray. The overview page of our product lists two packages: the WAR file and the Docker image. Both can be downloaded\nnow and used, the Docker image can be pulled from the JFrog Bintray Docker registry with native Docker commands.\n\nAs part of its graphical visualization capabilitites, Bintray is able to show the single layers of the uploaded Docker images.\n\nBintray can also display usage statistics, e.g. download details. Now guess where I’m sitting right now while downloading the binary?\n\nBesides providing own statistics, Bintray provides the JFrog Firehose Event API. This API streams live usage data, which in turn can be integrated or aggregated with your ecosystem.\nIn our case, we visualize the data, particularly download, upload, and delete statistics, with the ELK stack, as part of a functional monitoring initiative.\n\nCrisp, isn’t it?\n\nSummary\n\nThis closes are quick ride through the world of staging binaries, based on Jenkins. We’ve discussed concepts and example DevOps enabler tools, which can help to implement\n the concepts. Along the way, we discussed some more options how to integrate with ecosystem, e.g. releasing Maven snapshots and functional monitoring with dedicated tools.\n After this appetizer you may want to now consider to double-check your staging processes and toolchains, and maybe you find some room for further adjustments.\n\nReferences\n\n'Agile ALM', Manning, 2011\n\nBinary Repository Manager Feature Matrix\n\n'DevOps for Developers', Apress, 2012\n\nDocker\n\nELK\n\nJFrog Artifactory\n\nJFrog Bintray\n\nJFrog CLI\n\nJFrog REST API\n\nSonatype Nexus","title":"Delivery pipelines, with Jenkins 2: how to promote Java EE and Docker binaries toward production.","tags":["devops","jenkins","artifactory","bintray"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/c09ea/michaelhuettermann.jpg","srcSet":"/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/534e5/michaelhuettermann.jpg 32w,\n/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/99887/michaelhuettermann.jpg 64w,\n/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/c09ea/michaelhuettermann.jpg 128w,\n/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/76fd4/michaelhuettermann.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/59a6b/michaelhuettermann.webp 32w,\n/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/cbb78/michaelhuettermann.webp 64w,\n/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/96250/michaelhuettermann.webp 128w,\n/gatsby-jenkins-io/static/f049e8f2aa656a7f976c387e735fa4a3/50511/michaelhuettermann.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":171}}},"blog":"http://huettermann.net","github":"michaelhuettermann","html":"<div class=\"paragraph\">\n<p>Michael is expert in Continuous Delivery, DevOps and SCM/ALM supporting enterprises in implementing DevOps.\nMichael is Jenkins Ambassador.</p>\n</div>","id":"michaelhuettermann","irc":null,"linkedin":null,"name":"Michael Hüttermann","slug":"/blog/authors/michaelhuettermann","twitter":"huettermann"}]}}]}},"pageContext":{"limit":8,"skip":288,"numPages":100,"currentPage":37}},
    "staticQueryHashes": ["3649515864"]}