{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/50",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-06-16T00:00:00.000Z","id":"9d5b4fb7-1151-5470-985c-045b0dd79455","slug":"/blog/2016/06/16/parallel-test-executor-plugin/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nIn this blog post, I’ll show you how to speed up your pipeline by using the\nParallel Test Executor Plugin.\n\nSo much to do, so little time…​\n\nIn my career, I’ve helped many teams move to continuous integration and delivery. One problem\nwe always encounter is how to run all the tests needed to ensure high-quality\nchanges while still keeping pipeline times reasonable and changes flowing\nsmoothly. More tests mean greater confidence, but also longer wait times.\nBuild systems may or may not support running tests in parallel, but they still only use one\nmachine even while other lab machines sit idle. In these cases, parallelizing\ntest execution across multiple machines is a great way to speed up pipelines.\nThe Parallel Test Executor plugin lets us leverage Jenkins do just that with no\ndisruption to the rest of the build system.\n\nSerial Test Execution\n\nFor this post, I’ll be running a pipeline based on the\nJenkins Git Plugin. I’ve modified\nthe Jenkinsfile from that project to allow us to compare execution times to our\nlater changes, and I’ve truncated the \"mvn\" utility method since it remains\nunchanged.  You can find the original file\nhere.\n\nnode {\n  stage 'Checkout'\n  checkout scm\n\n  stage 'Build'\n\n  /* Call the Maven build without tests. */\n  mvn \"clean install -DskipTests\"\n\n  stage 'Test'\n  runTests()\n\n  /* Save Results. */\n  stage 'Results'\n\n  /* Archive the build artifacts */\n  archive includes: 'target/*.hpi,target/*.jpi'\n}\n\nvoid runTests(def args) {\n  /* Call the Maven build with tests. */\n  mvn \"install -Dmaven.test.failure.ignore=true\"\n\n  /* Archive the test results */\n  junit '**/target/surefire-reports/TEST-*.xml'\n}\n\n/* Run Maven */\nvoid mvn(def args) { /* ... */ }\n\nThis pipeline expects to be run from a Jenkinsfile in SCM.\nTo copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with\ngit 'https://github.com/jenkinsci/git-plugin.git'.\n\nThis is a Maven project, so the Jenkinsfile is pretty simple.\nI’ve split the Maven build into separate “Build” and “Test”\nstages. Maven doesn’t support this split very well, it wants to run all\nthe steps of the lifecycle in order every time. So, I have to call Maven twice:\nfirst using the “skipTests” property to do only build steps in the first call,\nand then a second time with out that property to run tests.\n\nOn my quad-core machine, executing this pipeline takes about 13 minutes and 30\nseconds.  Of that time, it takes 13 minutes to run about 2.7 thousand tests in\nserial.\n\nParallel Test Execution\n\nThis looks like an ideal project for parallel test execution: a short build\nfollowed by a large number of serially executed tests that consume the most of\nthe pipeline time. There are a number of things I could try to speed this up.\nFor example, I could modify test harness to look for ways to parallelize\nthe test execution on this single machine. Or I could try speed up the tests\nthemselves. Both of those can be time-consuming and both risk destabilizing the\ntests. I’d need to know more about the project to do it well.\n\nI’ll avoid that risk by using Jenkins and the\nParallel Test Executor Plugin to\nparallelize the tests across multiple nodes instead. This will isolate the tests\nfrom each other, while still giving us speed gains from parallel execution.\n\nThe plugin reads the list of tests from the results archived in the previous execution of this\njob and splits that list into a specified number of sublists. I can then use\nthose sublists to execute the tests in parallel, passing a different sublist to\neach node.\n\nLet’s look at how this changes the pipeline:\n\nnode { /* ...unchanged... */ }\n\nvoid runTests(def args) {\n  /* Request the test groupings.  Based on previous test results. */\n  /* see https://wiki.jenkins.io/display/JENKINS/Parallel+Test+Executor+Plugin and demo on github\n  /* Using arbitrary parallelism of 4 and \"generateInclusions\" feature added in v1.8. */\n  def splits = splitTests parallelism: [$class: 'CountDrivenParallelism', size: 4], generateInclusions: true\n\n  /* Create dictionary to hold set of parallel test executions. */\n  def testGroups = [:]\n\n  for (int i = 0; i }. */\n    /*     includes = whether list specifies tests to include (true) or tests to exclude (false). */\n    /*     list = list of tests for inclusion or exclusion. */\n    /* The list of inclusions is constructed based on results gathered from */\n    /* the previous successfully completed job. One additional record will exclude */\n    /* all known tests to run any tests not seen during the previous run.  */\n    testGroups[\"split-${i}\"] = {  // example, \"split3\"\n      node {\n        checkout scm\n\n        /* Clean each test node to start. */\n        mvn 'clean'\n\n        def mavenInstall = 'install -DMaven.test.failure.ignore=true'\n\n        /* Write includesFile or excludesFile for tests.  Split record provided by splitTests. */\n        /* Tell Maven to read the appropriate file. */\n        if (split.includes) {\n          writeFile file: \"target/parallel-test-includes-${i}.txt\", text: split.list.join(\"\\n\")\n          mavenInstall += \" -Dsurefire.includesFile=target/parallel-test-includes-${i}.txt\"\n        } else {\n          writeFile file: \"target/parallel-test-excludes-${i}.txt\", text: split.list.join(\"\\n\")\n          mavenInstall += \" -Dsurefire.excludesFile=target/parallel-test-excludes-${i}.txt\"\n        }\n\n        /* Call the Maven build with tests. */\n        mvn mavenInstall\n\n        /* Archive the test results */\n        junit '**/target/surefire-reports/TEST-*.xml'\n      }\n    }\n  }\n  parallel testGroups\n}\n\n/* Run Maven */\nvoid mvn(def args) { /* ... */ }\n\nThat’s it!  The change is significant but it is all encapsulated in this one\nmethod in the Jenkinsfile.\n\nGreat (ish) Success!\n\nHere’s the results for the new pipeline with parallel test execution:\n\nThe tests ran almost twice as fast, without changes outside pipeline.  Great!\n\nHowever, I used 4 test executors, so why am I not seeing a 4x? improvement.\nA quick review of the logs shows the problem: A small number of tests are taking up\nto 5 minutes each to complete! This is actually good news. It means that I\nshould be able to see further improvement in pipeline throughput just by refactoring\nthose few long running tests into smaller parts.\n\nConclusion\n\nWhile I would like to have seen closer to a 4x improvement to match to number\nof executors, 2x is still perfectly respectable. If I were working on a group of projects\nwith similar pipelines, I’d be completely comfortable reusing these same changes\non my other project and I’d expect to similar improvement without any disruption to\nother tools or processes.\n\nLinks\n\nhttps://wiki.jenkins.io/display/JENKINS/Parallel+Test+Executor+Plugin","title":"Faster Pipelines with the Parallel Test Executor Plugin","tags":["tutorial","pipeline","plugins"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"blog/author/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2016-06-15T00:00:00.000Z","id":"92e6efae-588c-5a80-886a-8fe7822dcea3","slug":"/blog/2016/06/15/jenkins-pipeline-scalability/","strippedHtml":"This is a guest post by Damien\nCoraboeuf, Jenkins project contributor and Continuous Delivery consultant.\n\nImplementing a CI/CD solution based on Jenkins has become very easy. Dealing\nwith hundreds of jobs? Not so much. Having to scale to thousands of jobs?\nNow this is a real challenge.\n\nThis is the story of a journey to get out of the jungle of jobs…​\n\nStart of the journey\n\nAt the beginning of the journey there were several projects using roughly the same\ntechnologies. Those projects had several\nbranches, for maintenance of releases, for new features.\n\nIn turn, each of those branches had to be carefully built, deployed on different\nplatforms and versions, promoted so they could be tested for functionalities,\nperformances and security, and then promoted again for actual delivery.\n\nAdditionally, we had to offer the test teams the means to deploy any version of\ntheir choice on any supported platform in order to carry out some manual tests.\n\nThis represented, for each branch, around 20 jobs. Multiply this by the number of\nbranches and projects, and there you are: more than two years after the start\nof the story, we had more than 3500 jobs.\n\n3500 jobs. Half a dozen people to manage them all…​\n\nPreparing the journey\n\nHow did we deal with this load?\n\nWe were lucky enough to have several assets:\n\ntime - we had time to design a solution before the scaling went really out of\ncontrol\n\nforecast - we knew that the scaling would occur and we were not taken by\nsurprise\n\ntooling - the Jenkins Job DSL\nwas available, efficient and well documented\n\nWe also knew that, in order to scale, we’d have to provide a solution with the\nfollowing characteristics:\n\nself-service - we could not have a team of 6 people become a bottleneck for\nenabling CI/CD in projects\n\nsecurity - the solution had to be secure enough in order for it to be used by\nremote developers we never met and didn’t know\n\nsimplicity - enabling CI/CD had to be simple so that people having\nnever heard of it could still use it\n\nextensibility - no solution is a one-size-fits-all and must be flexible\nenough to allow for corner cases\n\nAll the mechanisms described in this article are available through the\nJenkins Seed plugin.\n\nCreating pipelines using the Job DSL and embedding the scripts in the code was\nsimple enough. But what about branching? We needed a mechanism to allow the\ncreation of pipelines per branch, by downloading the associated DSL and to\nrun it in a dedicated folder.\n\nBut then, all those projects, all those branches, they were mostly using the\nsame pipelines, give or take a few configurable items. Going this way would\nhave lead to a terrible duplication of code, transforming a job maintenance\nnightmare into a code maintenance nightmare.\n\nPipeline as configuration\n\nOur trick was to transform this vision of \"pipeline as code\" into a \"pipeline\nas configuration\":\n\nby maintaining well documented and tested \"pipeline libraries\"\n\nby asking projects to describe their pipeline not as code, but as property\nfiles which would:\n\ndefine the name and version of the DSL pipeline library to use\n\nuse the rest of the property file to configure the pipeline library, using\nas many sensible default values as possible\n\nPiloting the pipeline from the SCM\n\nOnce this was done, the only remaining trick was to automate the creation,\nupdate, start and deletion of the pipelines using SCM events. By enabling SCM\nhooks (in GitHub, BitBucket or even in Subversion), we could:\n\nautomatically create a pipeline for a new branch\n\nregenerate a pipeline when the branch’s pipeline description was modified\n\nstart the pipeline on any other commit on the branch\n\nremove the pipeline when the branch was deleted\n\nOnce a project wants to go in our ecosystem, the Jenkins team \"seeds\" the\nproject into Jenkins, by running a job and giving a few parameters.\n\nIt will create a folder for the project and grant proper authorisations, using\nActive Directory group names based on the project name.\n\nThe hook for the project must be registered into the SCM and you’re up and\nrunning.\n\nConfiguration and code\n\nMixing the use of strong pipeline libraries configured by properties and the\ndirect use of the Jenkins Job DSL is still possible. The Seed plugin\nsupports all kinds of combinations:\n\nuse of pipeline libraries only - this can even be enforced\n\nuse a DSL script which can in turn use some classes and methods defined in\na pipeline library\n\nuse of a Job DSL script only\n\nUsually, we tried to have a maximum reuse, through only pipeline libraries, for\nmost of our projects, but in other circumstances, we were less strict and\nallowed some teams to develop their own pipeline script.\n\nEnd of the journey\n\nIn the end, what did we achieve?\n\nSelf service ✔︎\n\nPipeline automation from SCM - no intervention from the Jenkins team but for\nthe initial bootstrapping\n\nGetting a project on board of this system can be done in a few minutes only\n\nSecurity ✔︎\n\nProject level authorisations\n\nNo code execution on the controller\n\nSimplicity ✔︎\n\nProperty files\n\nExtensibility ✔︎\n\nPipeline libraries\n\nDirect job DSL still possible\n\nSeed and Pipeline plugin\n\nNow, what about the Pipeline plugin? Both\nthis plugin and the Seed plugin have common functionalities:\n\nWhat we have found in our journey is that having a \"pipeline as configuration\"\nwas the easiest and most secure way to get a lot of projects on board, with\ndevelopers not knowing Jenkins and even less the DSL.\n\nThe outcome of the two plugins is different:\n\none pipeline job for the Pipeline plugin\n\na list of orchestrated jobs for the Seed plugin\n\nIf time allows, it would be probably a good idea to find a way to integrate the\nfunctionalities of the Seed plugin into the pipeline framework, and to keep\nwhat makes the strength of the Seed plugin:\n\npipeline as configuration\n\nreuseable pipeline libraries, versioned and tested\n\nLinks\n\nYou can find additional information about the Seed plugin and its usage at the\nfollowing links:\n\nthe Seed plugin itself\n\nJUC London, June 2015\n\nBruJUG Brussels, March 2016","title":"Jenkins Pipeline Scalability in the Enterprise","tags":["jenkins","scalability","dsl"],"authors":[{"avatar":null,"blog":null,"github":"dcoraboeuf","html":"<div class=\"paragraph\">\n<p>I&#8217;ve started many years ago in the Java development before switching\nprogressively toward continuous delivery aspects.  I&#8217;m now a consultant\nimplementing CD solutions based on Jenkins. Implementation of the Pipeline\nas Code principles have allowed one of my clients to be able to manage more\nthan 3000 jobs, using a self service approach based on the Seed plugin.</p>\n</div>\n<div class=\"paragraph\">\n<p>I&#8217;m also a contributor for some Jenkins plugins and the author of the\nOntrack application, which allows the monitoring of continuous delivery\npipelines.</p>\n</div>","id":"dcoraboeuf","irc":null,"linkedin":null,"name":"Damien Coraboeuf","slug":"blog/author/dcoraboeuf","twitter":"DamienCoraboeuf"}]}},{"node":{"date":"2016-06-14T00:00:00.000Z","id":"0e5d650b-c2ea-591f-9965-564c0e2df2c3","slug":"/blog/2016/06/14/gsoc-jenkins-support-core-plugin-improvements/","strippedHtml":"About me\n\nI am Minudika Malshan, an undergraduate student in Computer Science and Engineering from University of Moratuwa, Sri Lanka.\n\nAs a person who is passionate in open source software development and seeking for new knowledge and experience, I am willing to give my contribution for this project.\n\nLinkedIn | Twitter\n\nAbstract\n\nThe Support-Core Plugin provides the basic infrastructure for generating \"bundles\" of support information with Jenkins.\nThere are two kinds of bundles.\n\nAutomatic bundles: Bundles which are generated and get saved in $JENKINS_HOME/support once per hour starting 15 seconds after Jenkins starts the plugin.\nThe automatic bundles are retained using an exponential aging strategy. Therefore it’s possible to have a bunch of them over the entire lifetime after the plugin installing the plugin.\n\nOn demand bundles: These bundles are generated from the root \"Support\" action.\n\nHowever current support-core plugin is not much user friendly. The object of this project is to make it more user friendly by adding some features which make a sophisticated environment for the user who use support plugin.\n\nIn this project scope, there are three features and improvements we are going to consider.\n\nEase the bundles management by the administrator ( JENKINS-33090)\n\nAdding an option to anonymize customer labels (strings created by the user such as name of a job, folder, view, agent, and template etc). ( JENKINS-33091)\n\nAllowing user to create an issue and submit a bundle into the OSS tracker using the support-core plugin. ( JENKINS-21670)\n\nArnaud Héritier and Steven Christou are guiding me through the project as my mentors.\n\nTasks and Deliverables\n\nEase the bundles management by the administrator.\n\nUnder this task, the following functions are going to be implemented.\n\nListing bundles stored on the jenkins instance with their details.\n\nAllowing user to download each bundle.\n\nAllowing user to delete each bundle or all bundles.\n\nAllowing user to browse the content of each bundle.\n\nAutomatically purging old bundles.\n\nEnabling user to create an issue and submit a bundle into the OSS tracker\n\nWhen a Jenkins user sees an issue, he/she commonly contacts his support contacts (Jenkins instance admins) and then Jenkins admins troubleshoot the issue.\nThe objective of this task is to implement a feature which enables the user to report an issue to a admin through support core plugin.\n\nWhen creating bundles to attach with the ticket, it is important to protect the privacy of the user who creates the ticket. When considering doing that, anonymizing user created labels (texts) comes to the front.\n\nAdding  an option to anonymize customer labels\n\nThe following functions will be implemented under this taks.\n\nCreating randomized tokens for labels created by users.\n\nProducing a mapping for those labels.\n\nSubstituting encoded labels into all the files included in the support bundle.\n\nWhen creating randomized tokens, it would be much useful and effective if we can create those tokens in a way they make sense to humans. (i.e. readable to humans). For that, I am hoping to use a suitable java library to create human friendly random tokens. One of such libraries is wordnet-random-name.\n\nHowever in order to substitute randomized tokens, all files included in the bundle should be read. This can become inefficient when bundle consists of large number of files.  Therefore it’s important to follow an optimized method for this task.\n\nReferences\n\nInitial proposal of the project\n\nProject repository","title":"GSoC Project Intro: Support Core Plugin Improvements","tags":["core","gsoc","plugin","support-core"],"authors":[{"avatar":null,"blog":null,"github":"minudika","html":"","id":"minudika","irc":null,"linkedin":null,"name":"Minudika Malshan","slug":"blog/author/minudika","twitter":"minudika"}]}},{"node":{"date":"2016-06-14T00:00:00.000Z","id":"06cd0ff0-b842-5785-b6b9-ec7c24f8ea95","slug":"/blog/2016/06/14/jenkins-world-agenda/","strippedHtml":"Join us in Santa Clara, California on September 13-15, 2016!\n\nWe are excited to announce the Jenkins\nWorld agenda is now live. There will be 50+ sessions, keynotes, training,\ncertifications and workshops. Here are a few highlights of what you can expect:\n\nHigh level topics\n\nContinuous delivery\n\nDevOps\n\nMicroservices architectures\n\nTesting\n\nAutomation tools\n\nPlugin development\n\nPipeline\n\nBest practices\n\nAnd much more\n\nAdditionally, Jenkins World offers great opportunities for hands-on learning,\nexploring and networking:\n\nPlugin Development Workshop\n\nDue to its popularity in previous years, we are bringing back the plugin\ndevelopment workshop. This workshop will introduce developers to the Jenkins\nplugin ecosystem and terminology. The goal is to provide a cursory overview of\nthe resources available to Jenkins plugin developers. Armed with this\ninformation, Jenkins developers can learn how to navigate the project and\ncodebase to find answers to their questions.\n\nBirds of a Feather Sessions\n\nBoFs, as they are usually known, will be a new addition to Jenkins World this\nyear. Sessions will be curated on various technical topics from DevOps to how\nenterprises are integrating Jenkins in their environment. Discussions will be\nlead by the industry’s brightest minds who have an influence in shaping the\nfuture of Jenkins.\n\nAsk the Experts\n\nGot a Jenkins question that’s been keeping you up at night? Need to bounce ideas\noff somebody? Or you just need someone to fix your Jenkins issue? This is your chance\nto get connected with the Jenkins Experts. Experts will be on hand to help with\nall your Jenkins needs on Sept 14th & 15th.\n\nPrepare for Jenkins Certification\n\nThe objective of this session is to help you assess your level of readiness for\nthe certification exam - either the Certified Jenkins Engineer (CJE/open source)\ncertification or the Certified CloudBees Jenkins Platform Engineer\n(CCJPE/CloudBees-specific) certification. After an overview about the\ncertification program, a Jenkins expert from CloudBees will walk you through the\nvarious sections of the exam, highlighting the important things to controller ahead\nof time, not only from a pure knowledge perspective but also in terms of\npractical experience. This will be an interactive session.\n\nHope to see you at Jenkins World 2016!\n\nDon’t miss out on\nSuper\nEarly Bird Rate $399. Price goes up after July 1.\n\nLinks\n\nStart a JAM in your city if there isn’t one already.\n\nBecome a JAM member.\n\nBecome an online JAM member\n\nBe a JAM speaker or sponsor. Let us know jenkinsci-jam@googlegroups.com\n\nBecome a Jenkins project contributor","title":"Jenkins World Agenda is Live!","tags":["event"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"blog/author/alyssat","twitter":null}]}},{"node":{"date":"2016-06-13T00:00:00.000Z","id":"169b8859-fdce-5c99-a2ba-d10df55f6894","slug":"/blog/2016/06/13/gsoc-usage-stats-analysis/","strippedHtml":"About myself\n\nHello, my name is Payal Priyadarshini.  I am pursing my major in Computer\nScience & Engineering at the Indian Institute of Technology Kharagpur, India.  I\nam very proficient in writing code in Python, C++, Java and currently getting\nfamiliar and hopefully good in Groovy too.\n\nI have internship experiences in renowned institutions like Google and VMware\nwhere I worked with some exciting technologies for example Knowledge Graphs,\nBigTable, SPARQL, RDF in Google. I am a passionate computer science student who\nis always interested in learning and looking for new challenges and\ntechnologies.That’s how I came across to Google Summer of Code where I am\nworking on some exciting data mining problems which you are going to encounter\nbelow in this blog.\n\nProject Overview\n\nJenkins has collected anonymous usage information of more than 100,000\ninstallations which includes set of plugins and their versions etc and also\nrelease history information of the upgrades. This data collection can be used\nfor various data mining experiments. The main goal of this project is to perform\nvarious analysis and studies over the available dataset to discover trends\nin data usage. This project will help us to learn more about the Jenkins\nusage by solving various problems, such as:\n\nPlugin versions installation trends, will let us know about the versions installation behaviour of a given plugin.\n\nSpotting downgrades, which will warn us that something is wrong with the version from which downgrading was performed.\n\nCorrelating what users are saying (community rating) with what users are doing (upgrades/downgrades).\n\nDistribution of cluster size, where clusters represents jobs, nodes count which approximates the size of installation.\n\nFinding set of plugins which are likely to be used together, will setup pillar for plugin recommendation system.\n\nAs a part of the Google Summer of Code 2016, I will be working on the above\nmentioned problems. My mentors for the project are Kohsuke Kawaguchi and Daniel Beck. Some analyses has already been done over this\ndata but those are outdated as charts can be more clearer and interactive. This project aims to improvise existing\nstatistics and generating new ones discussed above.\n\nUse Cases\n\nThis project covers wide-range of the use-cases that has been derived from the\nproblems mentioned above.\n\nUse Case 1: Upgrade/Downgrade Analysis\n\nUnderstanding the trend in upgrades and downgrades have lots of utilities, some\nof them have already been explained earlier which includes measuring the\npopularity, spotting downgrades, giving warning about the wrong versions quickly\netc.\n\nUse Case 1.1: Plugin versions installation trends\n\nHere we are analysing the trend in the different version installations for a\ngiven plugin. This use-case will help us to know about:\n\nTrend in the upgrade to the latest version released for a given plugin.\n\nTrend in the popularity decrement of the previous versions after new version release.\n\nFind the most popular plugin version at any given point of time.\n\nUse Case 1.2: Spotting dowgrades\n\nHere we are interested to know, how many installations are downgraded from any\ngiven version to previously used version. Far fetched goal of this analysis is\nto give warning when something goes wrong with the new version release, which\ncan be sensed using downgrades performed by users. This analysis can be\naccomplished by studying the monotonic property of the version number vs.\ntimestamp graph for a given plugin.\n\nUse Case 1.3: Correlation with the perceived quality of Jenkins release\n\nTo correlate what users are saying to what users are doing, we have community\nratings which tells us about the ratings and reviews of the releases and has\nfollowing parameters:\n\nUsed the release on production site w/o major issues.\n\nDon’t recommend to other.\n\nTried but rolled it back to the previous version.\n\nFirst parameters can be calculated from the Jenkins usage data and third\nparameter is basically spotting downgrades(use case 1.2). But the second\nparameter is basically an expression which is not possible to calculate. This\nanalysis is just to get a subjective idea about the correlation.\n\nUse Case 2: Plugin Recommendation System\n\nThis section involves setting up ground work for the plugin recommendation\nsystem. The idea is to find out the set of plugins which are most likely to be\nused together. Here we will be following both content based filtering as well as\ncollaborative filtering approach.\n\nCollaborative Filtering\n\nThis approach is based upon analysing large amount of information on\ninstallation’s behaviours and activities. We have implicit form of the data\nabout the plugins, that is for every install ids, we know the set of plugins\ninstalled. We can use this information to construct plugin usage graph where\nnodes are the plugins and the edges between them is the number of installations\nin which both plugins are installed together.\n\nContent-based Filtering\n\nThis method is based on a properties or the content of the item for example\nrecommending items that are similar to the those that a user liked in the past\nor examining in the present based upon some properties. Here, we are utilizing\nJenkins\nplugin dependency graph to learn about the properties of a plugin. This graph\ntells us about dependent plugins on a given plugin as well as its dependencies\non others. Here is an example to show, how this graph is use for content based\nfiletring, suppose if a user is using “CloudBees Cloud Connector”, then we can\nrecommend them for “CloudBees Registration Plugin” as both plugins are dependent\non “CloudBees Credentials Plugin”.\n\nAdditional Details\n\nYou may find the complete project proposal along with the detailed design of the\nuse-cases with their implementation details here in the\ndesign\ndocument.\n\nA complete version of the use-case 1: Upgrade & Downgrade Analysis should be\navailable in late June and basic version of plugin recommendation system will be\navailable in late July.\n\nI do appreciate any kind of feedback and suggestions.  You may add comments in\nthe\ndesign\ndoc.  I will be posting updates about the statistics generation status on the\njenkins-dev mailing\nlist and jenkins-infra mailing list.\n\nLinks:\n\nDesign Doc\n\nGoogle Summer of Code\n\nGithub infra-stats\n\nJenkins statistics\n\nJenkins Plugin Dependency Graph\n\nGithub GSoC Jenkins Usage Statistics Analysis","title":"GSoC Project Intro: Usage Statistics Analysis","tags":["usage-statistics","gsoc"],"authors":[{"avatar":null,"blog":null,"github":"payal94","html":"","id":"payal94","irc":null,"linkedin":null,"name":"Payal Priyadarshini","slug":"blog/author/payal94","twitter":null}]}},{"node":{"date":"2016-06-13T00:00:00.000Z","id":"29d1cef2-5ba3-567a-b9dc-18a27c3802aa","slug":"/blog/2016/06/13/june-jenkins-events/","strippedHtml":"It is hard to believe that the first half of 2016 is almost over and summer is\njust around the corner.  As usual, there are plenty of educational Jenkins\nevents planned for this month. Below lists what’s happening in your neck of the\nwoods:\n\nOnline JAM\n\nJune 14: Plugin Development - Basics\n\nNorth America JAMs\n\nJune 14: Pipeline in a Windows Environment - Boston, Massachusetts\n\nJune 15: Open Source Jenkins 2.0, What’s New? - Washington, DC\n\nJune 22: Continuously Deploying Containers with Jenkins Pipeline to a Docker Swarm Cluster - Seattle, Washington\n\nEurope JAM\n\nJune 14: Jenkins 2.0 - London, United Kingdom\n\nJune 22: Pipeline As Code - Toulouse, France\n\nLinks\n\nStart a JAM in your city if there isn’t one already.\n\nBecome a JAM member\n\nBecome an online JAM member\n\nSpeak or sponsor at a JAM. Contact us at jenkinsci-jam@googlegroups.com\n\nTake advantage of the super-early-bird price to Jenkins World 2016\n\nBecome a Jenkins project contributor","title":"Upcoming June Jenkins Events","tags":["events","jam"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"blog/author/alyssat","twitter":null}]}},{"node":{"date":"2016-06-10T00:00:00.000Z","id":"14ea0208-9b66-5e17-a4c1-d9b43525e9f4","slug":"/blog/2016/06/10/save-costs-with-ec2-spot-fleet/","strippedHtml":"This is a guest post by Aleksei Besogonov, Senior Software Developer at\nAmazon Web Services.\n\nEarlier this year, we published a case study on how\nLyft has used Amazon EC2 Spot instances to save 75% on their continuous delivery\ninfrastructure costs by simply changing four lines of code. Several other EC2 customers like Mozilla have\nalso reduced costs of their\ncontinuous integration, deployment and testing pipelines by up to 90% on Spot instances. You can view\nthe current savings on Spot instances over EC2 On-demand instances using the\nSpot Bid Advisor :\n\nAWS Spot instances are spare EC2 instances that you can bid on. While your Spot instances may be\nterminated when EC2’s spare capacity declines, you can automatically replenish these instances and\nmaintain your target capacity using\nEC2 Spot fleets. As each\ninstance type and Availability Zone provides an alternative capacity pool, you can select multiple\nsuch pools to launch the lowest priced instances currently available by launching a Spot\nfleet on the Amazon EC2 Spot Requests console\nor using the AWS CLI/SDK tools.\n\nIn this walkthrough, we’ll show you how to configure Jenkins to automatically scale a fleet of Spot\ninstances up or down depending on the number jobs to be completed.\n\nRequest an Amazon EC2 Spot fleet\n\nTo get started, login to Amazon EC2 console, and click on Spot Requests\nin the left hand navigation pane. Alternatively, you can directly login to\nAmazon EC2 Spot Requests console. Then click on the\nRequest Spot Instances button at the top of the dashboard.\n\nIn the Spot instance launch wizard, select the Request & Maintain option to request a Spot fleet that automatically\nprovisions the most cost-effective EC2 Spot instances, and replenishes them if interrupted. Enter an initial\ntarget capacity, choose an AMI, and select multiple instance types to automatically provision the lowest priced\ninstances available.\n\nOn the next page, ensure that you have selected a key pair, complete the launch wizard, and note the Spot\nfleet request ID.\n\nAmazon EC2 Spot fleet automates finding the lowest priced instances for you, and enables your Jenkins cluster\nto maintain the required capacity; so, you don’t need any bidding algorithms to provision the optimal Spot\ninstances over time.\n\nConfigure Jenkins\n\nInstall the Plugin\n\nFrom the Jenkins dashboard, select Manage Jenkins, and then click Manage Plugins. On the Available tab,\nsearch for and select the EC2 Fleet Jenkins Plugin. Then click the Install button.\n\nAfter the plugin installation is completed, select Manage Jenkins from the Jenkins dashboard, and\nclick Configure System. In the Cloud section, select Amazon Spot Fleet to add a new Cloud.\n\nConfigure AWS Credentials\n\nNext, we will configure the AWS and agent node credentials. Click the Add button next to AWS Credentials,\nselect Jenkins, and enter your AWS Access Key, secret, and ID.\n\nNext, click the Add button in the Spot fleet launcher to configure your agents with an SSH key.\nSelect Jenkins, and enter the username and private key (from the key pair you configured in your Spot fleet request)\nas shown below.\n\nConfirm that the AWS and SSH credentials you just added are selected. Then choose the region, and the Spot fleet\nrequest ID from the drop-down. You can also enter the maximum idle time before your cluster automatically scales\ndown, and the maximum cluster size that it can scale up to.\n\nSubmit Jobs and View Status\n\nAfter you have finished the previous step, you can view the EC2 Fleet Status in the left hand navigation pane on\nthe Jenkins dashboard. Now, as you submit more jobs, Jenkins will automatically scale your Spot fleet to add more\nnodes. You can view these new nodes executing jobs under the Build Executor Status.\nAfter the jobs are done, if the nodes remain free for the specified idle time (configured in the previous step),\nthen Jenkins releases the nodes, automatically scaling down your Spot fleet nodes.\n\nBuild faster and cheaper\n\nIf you have a story to share about your team or product, or have a question to ask, do leave a comment\nfor us; we’d love to connect with you!","title":"Save up to 90% of CI cost on AWS with Jenkins and EC2 Spot Fleet","tags":["aws","plugins","ec2"],"authors":[{"avatar":null,"blog":null,"github":"Cyberax","html":"","id":"cyberax","irc":null,"linkedin":null,"name":"Aleksei Besogonov","slug":"blog/author/cyberax","twitter":null}]}},{"node":{"date":"2016-06-01T00:00:00.000Z","id":"2ec37d75-53e9-562c-9bbb-de2a06ecbafd","slug":"/blog/2016/06/01/gsoc-automatic-plugin-documentation/","strippedHtml":"About me\n\nI am Cynthia Anyango from Nairobi, Kenya. I am a second year student at Maseno\nUniversity. I am currently specializing on Ruby on Rails and trying to learn\nPython. I recently started contributing to Open source projects.My major\ncontribution was at Mozilla, where I worked with the QA for Cloud services. I did\nmanual and automated tests for various cloud services. I wrote documentation\ntoo. Above that, I am competent and I am always passionate about what I get my\nhands on.\n\nProject summary\n\nCurrently Jenkins plugin documentation is being stored in Confluence. Sometimes\nthe documentation is scattered and outdated. In order to improve the situation we\nwould like to follow the documentation-as-code approach and to put docs to\nplugin repositories and then publish them on the project website using the\nawestruct engine. The project aims an implementation of a documentation\ncontinuous deployment flow powered by Jenkins and Pipeline Plugin.\n\nThe idea is to automatically pull in the README and other docs from GitHub, show\nchangelogs with versions and releases dates. I will be designing file templates\nthat will contain most of the  docs information that will be required from\nplugin developers. Initially the files will be written in\nAsciiDoc. Plugin developers will get a chance to\nreview the templates. The templates will be prototyped by various plugin\ndevelopers.\n\nThe docs that will be automatically pulled from github and will be published on\nJenkins.io under the Documentation section.\n\nMy mentors are R.Tyler and\nBaptiste Mathus\n\nI hope to achieve this by 25th June when we will be having our mid-term\nevaluations.\n\nI will update more on the progress.\n\nLinks\n\nGsoc Page\n\nJenkins Gsoc Page\n\nMailing List discussion on Jenkins-Developers\n\nMy blog on Medium","title":"GSOC Project Intro: Automatic Plugin Documentation","tags":["gsoc","plugins"],"authors":[{"avatar":null,"blog":null,"github":"anyangocynthia","html":"","id":"cynthia","irc":null,"linkedin":null,"name":"Cynthia Anyango","slug":"blog/author/cynthia","twitter":"annyanngo"}]}}]}},"pageContext":{"limit":8,"skip":392,"numPages":100,"currentPage":50}},
    "staticQueryHashes": ["3649515864"]}