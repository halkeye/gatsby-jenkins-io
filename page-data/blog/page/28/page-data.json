{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/28",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-07-18T00:00:00.000Z","id":"4f74ad43-7236-5f3c-bf1f-5c49dd133357","slug":"/blog/2018/07/18/security-updates/","strippedHtml":"We just released security updates to Jenkins, versions 2.133 and 2.121.2, that fix multiple security vulnerabilities.\n\nFor an overview of what was fixed, see the security advisory.\nFor an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2018-07-17T00:00:00.000Z","id":"2629d18c-2a10-59b8-8b11-b24bb8b2b87d","slug":"/blog/2018/07/17/simple-pull-request-plugin/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of reports at conventional locations,\nand publish them automatically. If the reports are not present at their respective conventional\nlocation, the location of the report can be configured in the YAML file.\n\nMy mentors are\nOleg Nenashev (Org Admin),\nMartin d’Anjou,\nKristin Whetstone,\nJeff Knurek\n\nBenefits to the community\n\nProject administrators will be able to handle pull request builds more easily.\n\nBuild specifications for pull requests can be written in a concise declarative format.\n\nBuild reports will be automatically published to Github, Bitbucket, etc.\n\nBuild status updates will be sent to git servers automatically.\n\nUsers will not have to deal with pipeline code.\n\nIf there will be no merge conflicts or build failures, the PR can be merged into target branch.\n\nPhase 1 blog post\n\nPlease see Phase 1 blog post\n\nImplementations till now\n\nAlpha version of the plugin is released. It supports all features of Multi-Branch Pipeline and offers the following features.\n\nBuild description is defined via YAML file stored within the SCM repo. This plugin\nwill depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be\nusing respective platforms for their repositories.\n\nConversion of YAML to Declarative Pipeline: A class YamlToPipeline\nis written which will load the \"Jenkinsfile.yaml\" and make use of PipelineSnippetGenerator class\nto generate Declarative pipeline code.\n\nReporting of results, only xml report types is supported for now.\n\nUse of Yaml file (Jenkinsfile.yaml) from target branch.\n\nGit Push step: To push the changes of pull request to the target branch. This is implemented\nusing git-plugin, PushCommand is used for this from git-plugin. credentialId,\nbranch name and repository url for interacting with Github, Bitbucket, etc\nwill be taken automatically from \"Branch-Source\" (Users have to fill this\ndetails of branch source in job configuration UI). (You can see\nHow to run the demo)\n\nStepConfigurator: To generate pipeline code for all supported steps in Jenkins. This is using\nJenkins configuration-as-code plugin (JCasC plugin) to configure a particular step object and\nthen that step object is passed to Snippetizer.object2Groovy() method to generate the script of that step.\n\nJenkinsfile.yaml example\n\nFor the phase 1 prototype demonstration, the following yaml file was used.\nNote that this format is subject to change in the next phases of the project,\nas we formalise the yaml format definition.\n\n#  Docker image agent example\nagent:\n label: my_label\n customWorkspace: path_to_workspace\n dockerImage: maven:3-alpine\n args: -v /tmp:/tmp\n\n  tools:\n    maven : maven_3.0.1\n    jdk : jdk8\n\nconfiguration:\n  # Push PR changes to the target branch if the build succeeds.\n  # default value is false\n  pushPrOnSuccess: false\n\n  # Trusted user to approve pull requests\n  prApprovers:\n    - username1\n    - username2\n    - username3\n\nenvironment:\n  variables:\n    variable_1: value_1\n    variable_2: value_2\n\n  # Credentials contains only two fields. credentialId must be present in the Jenkins Credentials\n  credentials:\n    - credentialId : fileCredentialId\n      variable : FILE\n\n      # In user scripts Username and Password can be accessed by LOGIN_USR and LOGIN_PSW\n      # respectively as environment variales\n    - credentialId : dummyGitRepo\n      variable : LOGIN\n\nstages:\n  - name: stage1\n    agent: any\n    steps:\n      - sh: \"scripts/hello\"\n      - sleep:\n          time: 2\n          unit: SECONDS\n      - sleep: 2\n      - junit:\n          testResults: \"target/**.xml\"\n          allowEmptyResults: true\n          testDataPublishers:\n            - AutomateTestDataPublisher\n            - JunitResultPublisher:\n                urlOverride: \"urlOverride\"\n    # Post section for \"stage1\". All Conditions which are available in Jenkins\n    # declarative pipeline are supported\n    post:\n      failure:\n        - sh: \"scripts/hello\"\n\n# Outer post section. Just like declarative pipeline.\npost:\n  always:\n    - sh: \"scripts/hello\"\n\nCoding Phase 2 plans (Completed)\n\nDecide a proper YAML format to use for Jenkinsfile.yaml\n\nCreate Step Configurator for SPRP plugin. JENKINS-51637.\nThis will enable users to use Pipeline steps in Jenkinsfile.yaml.\n\nAutomatic indentation generation in the generated PipelineSnippetGenerator class.\n\nWrite tests for the plugin.\n\nCoding Phase 3 plans\n\nTest Multi-Branch Pipeline features support:\n\nSupport for webhooks ( JENKINS-51941)\n\nCheck if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)\n\nFinalize documentation ( JENKINS-52518)\n\nRelease 1.0 ( JENKINS-52519)\n\nPlugin overview blog post\n\nCoding Phase 3 plans after release\n\nSupport the “when” Declarative Pipeline directive ( JENKINS-52520)\n\nNice2have: Support hierarchical report types ( JENKINS-52521)\n\nAdd unit tests, JenkinsRule tests, and ATH tests ( JENKINS-52495, JENKINS-52496)\n\nAutomatic Workspace Cleanup when PR is closed ( JENKINS-51897)\n\nRefactor snippet generator to extensions ( JENKINS-52491)\n\nPhase 3 Jira Epic\n\nPhase 2 evaluation presentation video\n\nVideo:\n\nPhase 2 evaluation presentation slides\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository\n\nPhase 2 Presentation video (July 12, 2018)\n\nPhase 2 Presentation Slides (July 12, 2018)","title":"Pipeline as YAML: Alpha release","tags":["gsoc2018","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/authors/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-07-13T00:00:00.000Z","id":"970120e2-6f31-5ddd-9fed-9bfcc306c79a","slug":"/blog/2018/07/13/jenkins-user-conference-china.adoc/","strippedHtml":"On June 30, 2018 in sunny Beijing, the capital of China, we welcomed over 200 attendees to Jenkins User Conference China (JUCC). This is the first JUCC in Beijing and we are overwhelmed by the interest and love for Jenkins. The conference had sessions in DevOps, Continuous Delivery, Jenkins X, Pipeline, and Container. The GreatOps community, event host, invited John Willis, a thought leader of DevOps to deliver the keynote speech. John’s topic was \"DevOps: Almost 10 years - What A  Strange Long Trip It’s Been.\" It was very insightful to learn of the history of DevOps and John’s point of view on the practice.\n\nLily Lin from Micro Focus presented, \"How to practice CI/CD for large-scale micro service based on Jenkins Pipeline.\"\n\nJames Rawlings, one of the core Jenkins X contributors traveled from the United Kingdom to present, \"Jenkins X for the future, Easy CI/CD for Kubernetes.\"\n\nAfter James’ presentation, there were many questions about Jenkins X, Jenkins users in China are very interested in Jenkins X. We all posed Jenkins \"X\" gesture.\n\nWe also invite Shuwei Hao from Alibaba, Michael Hüttermann who is the author of DevOps for Developers, Xiang Lu from CPI.\n\nMr Huaqiang Li and Xiaojie Zhao ran a workshop for help attendees master Jenkins Pipeline and Jenkins X in the cloud environment.\n\nHere are additional pictures from our event\n\nSpecial THANKS to BC who is the co-organizer of JUCC to host the main track and Alyssa and Maxwell for your help with our event.\n\nNext up, Jenkins User Conference China Shenzhen in November.\nLet’s Jenkins X and DevOps!","title":"Jenkins User Conference China Beijing Recap","tags":["event","juc"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"<div class=\"paragraph\">\n<p>Forest runs\nthe <a href=\"https://www.meetup.com/Shanghai-Jenkins-Area-Meetup/\">Shanghai Jenkins Area Meetup</a> and <a href=\"https://www.bagevent.com/event/jenkins-user-conference\">Jenkins User Conference China</a>.</p>\n</div>","id":"fjing","irc":null,"linkedin":null,"name":"Forest Jing","slug":"/blog/authors/fjing","twitter":null}]}},{"node":{"date":"2018-07-10T00:00:00.000Z","id":"b0312033-b8b4-5dbc-b5a3-6c06dd49dcb5","slug":"/blog/2018/07/10/jenkins-essentials-on-aws/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nJenkins Essentials is about providing a distribution of Jenkins in less than five minutes and five clicks.\nOne of the main ideas to make this a reality is that Jenkins will be autoconfigured with sane defaults for the environment it is running in.\n\nWe are happy to report we recently merged the change that provides this feature for AWS.\nWe use an AWS CloudFormation template to provision a working version of Jenkins Essentials, automatically configured to:\n\ndynamically provision EC2 agents, using the EC2 plugin;\n\nuse the Artifact Manager on S3 plugin, so that artifacts are not stored anymore on the controller’s file system, but directly in an S3 bucket.\n\nI recorded a short demo video last week showing the basics of this:\n\nWhile there are still many items to complete to provide a usable version for end-users, we are making steady progress towards it.\n\nYou can learn more about Jenkins Essentials from the\nGitHub repository, or join us\non our\nGitter channel.","title":"Jenkins Essentials flavor for AWS","tags":["jenkinsevergreen","evergreen"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8e8d8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/f1e03/batmat.jpg","srcSet":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/ede19/batmat.jpg 32w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/bc20c/batmat.jpg 64w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/f1e03/batmat.jpg 128w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/b691b/batmat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/8ba60/batmat.webp 32w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/a9ea7/batmat.webp 64w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/51559/batmat.webp 128w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/28f98/batmat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":130}}},"blog":"http://batmat.net","github":"batmat","html":"<div class=\"paragraph\">\n<p>Baptiste has been using and contributing to Jenkins since it was called differently, and is a huge proponent of the Agile, Devops &amp; Continuous Delivery movements.\nHe loves to discuss not only the technical aspects, but also the even more essential cultural aspects of this all, working together to improve the value provided to customers in a great inclusive and blameless environment.</p>\n</div>","id":"batmat","irc":null,"linkedin":null,"name":"Baptiste Mathus","slug":"/blog/authors/batmat","twitter":"bmathus"}]}},{"node":{"date":"2018-07-05T00:00:00.000Z","id":"b1c89781-ce73-5eec-8d31-bf7f51174f63","slug":"/blog/2018/07/05/remoting-over-message-bus-alpha-release/","strippedHtml":"I am happy to announce that we have recently released an alpha version of Remoting Kafka Plugin to the Experimental Update Center. You can check the CHANGELOG to see the features included in this initial release.\n\nOverview\n\nCurrent versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.\n\nRemoting Kafka Plugin is a plugin developed under Jenkins Google Summer of Code 2018. The plugin is developed to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins. A quick introduction of the project can be found in this introduction blogpost.\n\nHow to use the plugin?\n\nThe instructions to run the plugin in alpha version are written here. Feel free to have a try and let us know your feedback on Gitter or the mailing list.\n\nLinks\n\nAlpha Changelog\n\nIntroduction Blogpost\n\nGitHub Repository\n\nProject Page\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Update: Alpha release of Remoting Kafka Plugin","tags":["plugins","gsoc","gsoc2018","remoting","alpha-release"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg","srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/77b35/pvtuan10.jpg 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/d4a57/pvtuan10.jpg 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/ef6ff/pvtuan10.webp 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/8257c/pvtuan10.webp 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/6766a/pvtuan10.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"pvtuan10","html":"<div class=\"paragraph\">\n<p>Pham Vu Tuan is a developer from Singapore.\nHe starts contributing to Jenkins from Google Summer of Code 2018 for <a href=\"https://jenkins.io/projects/gsoc/2018/remoting-over-message-bus/\">Jenkins Remoting over Message Bus/Queue</a></p>\n</div>","id":"pvtuan10","irc":"pvtuan10","linkedin":null,"name":"Pham Vu Tuan","slug":"/blog/authors/pvtuan10","twitter":null}]}},{"node":{"date":"2018-07-02T00:00:00.000Z","id":"0c991121-dfec-5b10-a945-33a402cf3ddd","slug":"/blog/2018/07/02/new-api-token-system/","strippedHtml":"About API tokens\n\nJenkins API tokens are an authentication mechanism that allows a tool (script, application, etc.) to impersonate a user\nwithout providing the actual password for use with the Jenkins API or CLI.\nThis is especially useful when your security realm is based on a central directory, like Active Directory or LDAP,\nand you don’t want to store your password in scripts.\nRecent versions of Jenkins also make it easier to use the remote API when using API tokens to authenticate,\nas no CSRF tokens need to be provided even with CSRF protection enabled.\nAPI tokens are not meant to — and cannot — replace the regular password for the Jenkins UI.\n\nPrevious problems\n\nWe addressed two major problems with the existing API token system in Jenkins 2.129:\n\nFirst, reported in JENKINS-32442,\nuser accounts in Jenkins have an automatically generated API token by default.\nAs these tokens can be used to authenticate as a given user, they increase the attack surface of Jenkins.\n\nThe second problem was reported in JENKINS-32776 :\nThe tokens were previously stored on disk in an encrypted form.\nThis meant that they could be decrypted by unauthorized users by leveraging another security vulnerability,\nor obtained, for example, from improperly secured backups, and used to impersonate other users.\n\nNew approach\n\nThe main objective of this new system is to provide API tokens that are stored in a unidirectional way on the disk,\ni.e. using a hashing algorithm (in this particular case SHA-256).\n\nWhile this means that you will not be able to see the actual API tokens anymore after you’ve created them,\nseveral features were added to mitigate this potential problem:\n\nYou can have multiple active API tokens at the same time.\nIf you don’t remember an API token’s value anymore, just revoke it.\n\nYou can name your tokens to know where they are used (and rename them after creation if desired).\nWe recommend that tokens use a name that indicates where (for example the application, script, or host) where it will be used.\n\nYou can track the usage of your tokens.\nEvery token keeps a record of the number of uses and the date of the last use.\nThis will allow you to better know which tokens are really used and which are no longer actively required.\nJenkins also encourages users to rotate old API tokens by highlighting their creation date in orange after six months, and in red after twelve months.\nThe goal is to remind the user that tokens are more secure when you regenerate them often:\nThe longer a token is around, perhaps passed around in script files and stored on shared drives,\nthe greater the chance it’s going to be accessed by someone not authorized to use it.\n\nFigure 1. Token usage tracking\n\nYou can revoke API tokens.\nWhen you know that you are not using a given token anymore, you can revoke it to reduce the risk of it getting used by unauthorized users.\nSince you can have multiple API tokens, this allows fine-grained control over which scripts, hosts, or applications are allowed to use Jenkins as a given user.\n\nMigrating to new API tokens\n\nTo help administrators migrate their instances progressively, the legacy behavior is still available, while new system is also usable.\n\nOn the user configuration page, the legacy token is highlighted with a warning sign,\nexplaining that users should revoke it and generate a new one (if needed) to increase security.\n\nFigure 2. Legacy token renewal still possible\n\nNew options for administrators\n\nIn order to let administrators control the pace of migration to the new API token system,\nwe added two global configuration options in the \"Configure Global Security\" page in the brand new \"API Token\" section:\n\nAn option to disable the creation of legacy API tokens on user creation.\n\nAn option to disable the recreation of legacy API tokens by users, forcing them to only use the new, unrecoverable API tokens.\n\nBoth options are disabled by default for new installations (the safe default), while they’re enabled when Jenkins is upgraded from before 2.129.\n\nFigure 3. Security Configuration options\n\nFigure 4. Remove legacy token and disable the re-creation\n\nNew administrator warnings\n\nWhen upgrading to Jenkins 2.129, an administrative monitor informs admins about the new options described above, and recommend disabling them.\n\nAnother administrative warnings shows up if at least one user still has a legacy API token.\nIt provides central control over legacy tokens still configured in the Jenkins instance, and allows revoking them all.\n\nFigure 5. Legacy token monitoring page\n\nSummary\n\nJenkins API tokens are now much more flexible: They allow and even encourage better security practices.\nWe recommend you revoke legacy API tokens as soon as you can, and only use the newly introduced API tokens.","title":"Security Hardening: New API token system in Jenkins 2.129+","tags":["community","core","security","upgrade"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/c09ea/wadeck.jpg","srcSet":"/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/534e5/wadeck.jpg 32w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/99887/wadeck.jpg 64w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/c09ea/wadeck.jpg 128w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/5f0ee/wadeck.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/59a6b/wadeck.webp 32w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/cbb78/wadeck.webp 64w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/96250/wadeck.webp 128w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/890ef/wadeck.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":171}}},"blog":null,"github":"wadeck","html":"<div class=\"paragraph\">\n<p>Wadeck is the Jenkins security officer, leading the <a href=\"/security/#team\">security team</a> in improving Jenkins security.\nHe likes to provide solutions that are both useful and easy to use.</p>\n</div>","id":"wadeck","irc":null,"linkedin":null,"name":"Wadeck Follonier","slug":"/blog/authors/wadeck","twitter":null}]}},{"node":{"date":"2018-07-02T00:00:00.000Z","id":"44cd4bd6-4c8f-5fdd-8f54-c99da078882e","slug":"/blog/2018/07/02/whats-new-declarative-piepline-13x-sequential-stages/","strippedHtml":"We recently released version 1.3 of Declarative Pipelines, which includes a couple significant new features. We’re\ngoing to cover these features in separate blog posts. The next post will show the new ability to restart a completed\nPipeline run starting from a stage partway through the Pipeline, but first, let’s look at the new sequential stages\nfeature.\n\nSequential Stages\n\nIn Declarative 1.2, we added the ability to define stages to run in parallel\nas part of the Declarative syntax. Now in Declarative 1.3, we’ve added another way to specify stages nested within other\nstages, which we’re calling \"sequential stages\".\n\nRunning Multiple Stages in a Parallel Branch\n\nOne common use case is running build and tests on multiple platforms. You could already do that with parallel stages,\nbut now you can run multiple stages in each parallel branch giving you more visibility into the progress of your\nPipeline without having to check the logs to see exactly which step is currently running where, etc.\n\nYou can also\nuse stage directives, including post, when, agent, and all the others covered in the\nPipeline Syntax reference\nin your sequential stages, letting you control behavior for different parts of each parallel branch.\n\nIn the example below, we are running builds on both Windows and Linux, but only want to deploy if we’re on the master branch.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and deploy on Windows and Linux\") {\n            parallel {\n                stage(\"windows\") {\n                    agent {\n                        label \"windows\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                bat \"run-build.bat\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                            when {\n                                branch \"master\"\n                            }\n                            steps {\n                                bat \"run-deploy.bat\"\n                            }\n                        }\n                    }\n                }\n\n                stage(\"linux\") {\n                    agent {\n                        label \"linux\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                sh \"./run-build.sh\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                             when {\n                                 branch \"master\"\n                             }\n                             steps {\n                                sh \"./run-deploy.sh\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nRunning Multiple Stages with the Same agent, or environment, or options\n\nWhile the sequential stages feature was originally driven by users wanting to have multiple stages in parallel branches,\nwe’ve found that being able to group multiple stages together with the same agent, environment, when, etc has a lot\nof other uses. For example, if you are using multiple agents in your Pipeline, but would like to be sure that stages using\nthe same agent use the same workspace, you can use a parent stage with an agent directive on it, and then all the stages\ninside its stages directive will run on the same executor, in the same workspace. Another example is that until now, you\ncould only set a timeout for the entire Pipeline or an individual stage. But by using a parent stage with nested stages,\nyou can define a timeout in the parent’s options directive, and that timeout will be applied for the execution of the\nparent, including its nested stages. You may also want to conditionally control the execution of multiple stages. For example,\nyour deployment process may be spread across multiple stages, and you don’t want to run any of those stages unless you’re on\na certain branch or some other criteria is satisified. Now you can group all those related stages together in a parent\nstage, within its stages directive, and have a single when condition on that parent, rather than having to copy an\nidentical when condition to each of the relevant stages.\n\nOne of my favorite use cases is shown in the example below. In Declarative 1.2.6, we added the input directive for stages.\nThis will pause the execution of the Pipeline until a user confirms that the Pipeline should continue, using the Scripted\nPipeline input step. The input directive is evaluated before the stage enters its agent, if it has one specified, and\nbefore the stage’s when condition, if specified, is evaluated. But if you’re using a top-level agent for most of your\nstages, you’re still going to be using that agent’s executor while waiting for input, which can be a waste of resources.\nWith sequential stages, you can instead use agent none at the top-level of the Pipeline, and group the stages using a common\nagent and running before the stage with the input directive together under a parent stage with the required agent\nspecified. Then, when your Pipeline reaches the stage with input, it will no longer be using an agent’s executor.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and test the project\") {\n            agent {\n                docker \"our-build-tools-image\"\n            }\n            stages {\n               stage(\"build\") {\n                   steps {\n                       sh \"./build.sh\"\n                   }\n               }\n               stage(\"test\") {\n                   steps {\n                       sh \"./test.sh\"\n                   }\n               }\n            }\n            post {\n                success {\n                    stash name: \"artifacts\", includes: \"artifacts/**/*\"\n                }\n            }\n        }\n\n        stage(\"deploy the artifacts if a user confirms\") {\n            input {\n                message \"Should we deploy the project?\"\n            }\n            agent {\n                docker \"our-deploy-tools-image\"\n            }\n            steps {\n                sh \"./deploy.sh\"\n            }\n        }\n    }\n}\n\nThese are just a few example of the power of the new sequential stages feature in Declarative 1.3.\nThis new feature adds another set of significant use cases that can be handled smoothly using Declarative Pipeline.\nIn my next post, I’ll show the another highly requested feature - the new ability to restart a Pipeline run from any stage in that Pipeline.","title":"What's New in Declarative Pipeline 1.3: Sequential Stages","tags":["pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2018-06-27T00:00:00.000Z","id":"fdf34f60-9243-5d28-b9d3-ea140833ede2","slug":"/blog/2018/06/27/lessons-java10-hackathon/","strippedHtml":"Last week I participated in the\nJenkins & Java 10 Online Hackathon.\nIt was my first Jenkins hackathon and I roped in\nJonah Graham to do some pair-programming.\nThe hackathon featured JDK Project Jigsaw committers Mandy Chung and Paul Sandoz,\nas well as Jenkins creator Kohsuke Kawaguchi.\nIt was a great opportunity for me to learn a lot about Jenkins and Java 10.\n\nWhy Java 10?\n\nWith the\nJava 8 EoL data looming,\nthe focus was on the current available version of Java, Java 10.\nJava 10 offers some nice new features and APIs, not least\nimproved docker container integration.\nWe learned from Paul of a number of projects with Java 10 migration success stories including Elasticsearch, Kafka & Netty.\n\nAt the beginning of the hackathon week, the Jenkins Pipeline feature would crash out when using Java 10.\nThis was resolved with a number of fixes including the upgrade of the\nASM library.\nThen it was nice to see things\nup and running with Java 10.\n\nGetting up & running\n\nThe first steps were to do some exploratory testing using\nJenkins with Java 10 via Docker, thanks to\nOleg for providing clear instructions.\nThis was boringly straightforward as most things worked and we only found one\nissue to report.\nNext to try to get some patches in, we needed to set-up a dev environment.\nThe live session gave us what we needed to set up a\nplugin or\ncore dev environment.\nOne open question we had was whether Jenkins has semantic versioning and\nAPI tools\nto help identify when you might be breaking backwards compatibility.\nOverall it was straightforward to get a dev environment up and running.\n\nJava 10 New APIs\n\nThe next step was to find an issue which we could help resolve.\nMany of the Java 10 issues were related to 'Illegal reflective access' from various plugins or third-party libraries.\nHowever after investigating a couple, removing these warnings required a good architectural knowledge of the plugin or core code itself.\nIn the end we decided that messing around with classloaders or attempting to upgrade version of jdom was not one for the newbies.\n\nInstead we looked at\nremoving reflection\nin cases of isAccessible calls.\nWe found the\nProcessHandle\napi very useful and a good replacement for some misuse of reflection, and even better it made the code work on Windows too.\nMandy also pointed us to look at the\nLookup api\nas possible alternate to findClass calls.\n\nMulti-Release JAR Builds\n\nUsing new APIs is all well and good but presents a problem when you want to maintain backwards compatibility with Java 8.\nHence the need for some sort of multi-jar solution -\nNicolas De loof proposed one such solution for\nmulti-release jars with Maven for this case.\n\nsun.misc.Signal\n\nThe Java Signal API is being deprecated, but so far no replacement APIs\nare available for signal handling.\nJenkins makes use of the Signal APIs so a big question for the Jigsaw team was whether this would be replaced going forward.\nKohsuke pointed out how it is important for Java to maintain this UNIX like behaviour as it shouldn’t matter to end users that Jenkins is written in Java.\nIt seems these APIs will be replaced in due course, they just\naren’t there right now.\n\nCollaboration, Collaboration, Collaboration\n\nIt was great to have the discussions with the Jigsaw team.\nThey reminded us how they need to know the Java use cases out there and how their team uses these to feed into their development process.\nIn turn, the hackathon had Jenkins community members participate, for instance\neasy-jenkins was up and running with Java 10 by the end of the week.\nThe hackathon had a great feeling of community spirit and was a reminder why collaborations with communities and also between different communities can be powerful and fun for all involved.\n\nAt the end of the week Jonah and I were both happy that we made our first Jenkins contributions (which were reviewed and merged quickly).\nThanks to all who participated and made it highly enjoyable, especially Oleg for great organization.\nI look forward to the next one!","title":"What I learned from the Jenkins & Java 10+ Hackathon","tags":["events","community","developer","java10","java11"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8c8c8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg","srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/6105b/tracymiranda.jpg 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/9d80c/tracymiranda.jpg 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/f84eb/tracymiranda.jpg 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a5e1e/tracymiranda.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/a4758/tracymiranda.webp 32w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fec68/tracymiranda.webp 64w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/fe590/tracymiranda.webp 128w,\n/gatsby-jenkins-io/static/36f2862463dddd3649a3901f5cb4f6ed/c2c8e/tracymiranda.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":116}}},"blog":"https://tracymiranda.com/","github":"tracymiranda","html":"<div class=\"paragraph\">\n<p>Tracy is the Director of Open Source Community at CloudBees, long time open source contributor and evangelist.</p>\n</div>","id":"tracymiranda","irc":"tracymiranda","linkedin":null,"name":"Tracy Miranda","slug":"/blog/authors/tracymiranda","twitter":"tracymiranda"}]}}]}},"pageContext":{"limit":8,"skip":216,"numPages":101,"currentPage":28}},
    "staticQueryHashes": ["3649515864"]}