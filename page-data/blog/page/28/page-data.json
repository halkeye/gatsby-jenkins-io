{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/28",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-06-21T00:00:00.000Z","id":"f197eae4-55a6-578b-aa6b-0f8809ef8608","slug":"/blog/2018/06/21/jenkins-x-devpods/","strippedHtml":"I use macOS day to day, and often struggle to keep my devtools up to date.\nThis isn’t any fault of packaging or tools, more just that I get tired of seeing the beachball:\n\nThe demands on dev machines grow, developers are now working across a more diverse\nset of technologies than just a JVM or a single scripting language these days.\n\nThis keeping up to date is a drag on time (and thus money).\nThere are lots of costs involved with development, and I\nhave written about\nabout the machine cost for development (how using something like GKE can be much\ncheaper than buying a new machine) but there is also the cost of a developer’s time.\nThankfully, there are ways to apply the same smarts here to save time as well as money.\n And time is money, or money is time?\n\nGiven all the work done in automating the detection and installation of required\ntools, environments, and libraries that goes on when you run ‘jx import’ in\nJenkins X,\nit makes sense to also make those available for development time,\nand the concept of “DevPods” was born.\n\nThe pod part of the name comes from the Kubernetes concept of pods (but you don’t have to know about Kubernetes or pods to use Jenkins X. There is a lot to Kubernetes but Jenkins X aims to provide a developer experience that doesn’t require you to understand it).\n\nWhy not use Jenkins X from code editing all the way to production,\nbefore you even commit the code or open a pull request?\nAll the tools are there, all the environments are there, ready to use (as they are used at CI time!).\n\nThis rounds out the picture: Jenkins X aims to deal with the whole lifecycle for you,\nfrom ideas/issues, change requests, testing, CI/CD, security and compliance verification,\nrollout and monitoring. So it totally makes sense to include the actual dev time tools.\n\nIf you have an existing project, you can create a DevPod by running (with the jx command):\n\njx create devpod\n\nThis will detect what type of project is (using build packs) and create a DevPod\nfor you with all the tools pre-installed and ready to go.\n\nObviously, at this point you want to be able to make changes to your app and try it out.\nEither run unit tests in the DevPod, or perhaps see some dev version of the app running in your browser (if it is a web app).\nWeb-based code editors have been a holy grail for some time, but never have quite taken off in the mainstream of developers (despite there being excellent ones out there, most developers prefer to develop on their desktop).\nIronically, the current crop of popular editors are based around\n“electron” which is actually a web technology stack,\nbut it runs locally (Visual Studio Code is my personal favourite at the moment),\nin fact Visual Studio Code has a Jenkins X extension (but you don’t have to use it):\n\nTo get your changes up to the Dev Pod, in a fresh shell run (and leave it running):\n\njx sync\n\nThis will watch for any changes locally (say you want to edit files locally on your desktop)\nand sync them to the Dev Pod.\n\nFinally, you can have the Dev Pod automatically deploy an “edit” version of the\napp on every single change you make in your editor:\n\njx create devpod --sync --reuse\n./watch.sh\n\nThe first command will create or reuse an existing Dev Pod and open a shell to it,\nthen the watch command will pick up any changes, and deploy them to your “edit” app.\nYou can keep this open in your browser, make a change, and just refresh it.\nYou don’t need to run any dev tools locally, or any manual commands in the Dev Pod to do this, it takes care of that.\n\nYou can have many DevPods running (jx get devpods), and you could stop them at the end of the day (jx delete devpod), start them at the beginning, if you like (or as I say: keep them running in the hours between coffee and beer). A pod uses resources on your cluster, and as the Jenkins X project fleshes out its support for dev tools (via things like VS Code extensions) you can expect even these few steps to be automated away in the near future, so many of the above instructions will not be needed!\n\nEnd-to-end experience\n\nSo bringing it all together, let me show a very wide (you may need to zoom out) screen shot of this workflow:\n\nFrom Left to Right :\n\nI have my editor (if you look closely, you can see the Jenkins X extension showing the state of apps,\npipelines and the environments it is deployed to).\n\nIn the middle I have jx sync running, pushing changes up to the cloud from the editor,\nand also the ‘watch’ script running in the DevPod. This means every change I make in my editor,\na temporary version of the app (and its dependencies are deployed).\n\nOn the right is my browser open to the “edit” version of the app.\nJenkins X automatically creates an “edit” environment for live changes,\nso if I make a change to my source on the left, the code is synced,\nbuild/tested and updated so I can see the change on the right\n(but I didn’t build anything locally, it all happens in the DevPod on Jenkins X).\n\nOn visual studio code: The Jenkins X extension for visual studio code can automate the creation of devpods and syncing for you. Expect richer support soon for this editor and others.\n\nExplaining things with pictures\n\nTo give a big picture of how this hangs together:\n\nIn my example, GitHub is still involved, but I don’t push any changes back to it until I am happy with the state of my “edit app” and changes.\nI run the editor on my local workstation and jx takes care of the rest.\nThis gives a tight feedback loop for changes. Of course, you can use any editor you like,\nand build and test changes locally (there is no requirement to use DevPods to make use of Jenkins X).\n\nJenkins X comes with some ready to go environments: development, staging and production (you can add more if you like).\nThese are implemented as Kubernetes namespaces to avoid the wrong app things talking to the wrong place.\nThe development environment is where the dev tools live: and this is also where the DevPods can live!\nThis makes sense as all the tools are available, and saves the hassle of you having slightly different\nversions of tools on your local workstation than what you are using in your pipeline.\n\nDevPods are an interesting idea, and at the very least a cool name!\nThere will be many more improvements/enhancements in this area, so keep an eye out for them.\nThey are a work in progress, so do check the documentation page for better ways to use them.\n\nSome more reading:\n\nDocs on DevPods on jenkins-x.io\n\nThe Visual Studio Code extension\nfor Jenkins X (what a different world: an open source editor by Microsoft!)\n\nJames Strachan’s great intro\nto Jenkins X talk at Devoxx-UK also   includes a DevPod demo","title":"Using Jenkins X DevPods for development","tags":["jenkinsx","developer"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/author/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2018-06-20T00:00:00.000Z","id":"c6c81158-09c3-5db5-9f8e-8e8ad25bd805","slug":"/blog/2018/06/20/anchore-image-scanning/","strippedHtml":"(adapted from this blog post by Daniel Nurmi)\n\nAs more and more Jenkins users ship docker containers, it is worth thinking about the security implications of this model, where the variance in software being included by developers has increased dramatically from previous models. Security implications in this context include what makes up the image, but also the components of the app that get bundled into your image. Docker images are increasingly becoming a “unit of deployment”, and if you look at a typical app (especially if it is a microservice), much of the components, libraries, and system are someone else’s code.\n\nAnchore exists to provide technology to act as a last line of defense, verifying the contents of these new deployable units against user specified policies to enforce security and compliance requirements. In this blog you will get a quick tour of this capability, and how to add the open-source Anchore Engine API service into your pipeline to validate that the flow of images you are shipping comply with your specific requirements, from a security point of view.\n\nKey among the fundamental tenets of agile development is the notion of “fail fast, fail often”, which is where CI/CD comes in: A developer commits code into the source code repository, such as git, that automatically triggers Jenkins to perform a build of the application that is then run through automated tests. If these tests fail the developer is notified immediately and can quickly correct the code. This level of automation increases the overall quality of code and speeds development.\n\nWhile some may feel that “fail fast” sounds rather negative (especially regarding security), you could better describe this process as “learn fast” as mistakes are found earlier in the development cycle and can be easily corrected. The increased use of CI/CD platforms such as Jenkins has helped to improve the efficiency of development teams and streamlined the testing process. We can leverage the same CI/CD infrastructure to improve the security of our container deployments.\n\nFor many organizations the last step before deploying an application is for the security team to perform an audit. This may entail scanning the image for vulnerable software components (like outdated packages that contain known security vulnerabilities) and verifying that the applications and OS are correctly configured. They may also check that the organization’s best practices and compliance policies have been correctly implemented.\n\nIn this post we walk through adding security and compliance checking into the CI/CD process so you can “learn fast” and correct any security or compliance issues early in the development cycle. This document will outline the steps to deploy Anchore’s open source security and compliance scanning engine with Jenkins to add analytics, compliance and governance to your CI/CD pipeline.\n\nAnchore has been designed to plug seamlessly into the CI/CD workflow, where a developer commits code into the source code management system, which then triggers Jenkins to start a build that creates a container image. In the typical workflow this container image is then run through automated testing. If an image does not meet your organization’s requirements for security or compliance then it makes little sense to invest the time required to perform automated tests on the image, it would be better to “learn fast” by failing the build and returning the appropriate reports back to the developer to allow the issue to be addressed.\n\nAnchore has published a plugin for Jenkins which, along with Anchore’s open source engine or Enterprise offering, allows container analysis and governance to be added quickly into the CI/CD process.\n\nRequirements\n\nThis guide presumes the following prerequisites have been met:\n\nJenkins 2.x installed and running on a virtual machine or physical server.\n\nAnchore-Engine installed and running, with accessible engine API URL (later referred to as) and credentials (later referred to as and) available - see Anchore Engine overview and installation.\n\nAnchore’s Jenkins plugin can work with single node installations or installations with multiple worker nodes.\n\nStep 1: Install the Anchore plugin\n\nThe Anchore plugin has been published in the Jenkins plugin registry and is available for installation on any Jenkins server. From the main Jenkins menu select Manage Jenkins, then Manage Plugins, select the Available tab, select and install Anchore Container Image Scanner.\n\nStep 2: Configure Anchore Plugin.\n\nOnce the Anchore Container Image Scanner plugin is installed - select Manage Jenkins menu click Configure System, and locate the Anchore Configuration section.  Select and enter the following parameters in this section:\n\nClick Enable Anchore Scanning\n\nSelect Engine Mode\n\nEnter your in the Engine URL text box - for example: http://your-anchore-engine.com:8228/v1\n\nEnter your and in the Engine Username and Engine Password fields, respectively\n\nClick Save\n\nAn example of a filled out configuration section is below, where we’ve used “http://192.168.1.3:8228/v1” as, “admin” as and “foobar” as :\n\nAt this point the Anchore plugin is configured on Jenkins, and is available to be accessed by any project to perform Anchore security and policy checks as part of your container image build pipeline.\n\nStep 3: Add Anchore image scanning to a pipeline build.\n\nIn the Pipeline model the entire build process is defined as code. This code can be created, edited and managed in the same way as any other artifact of your software project, or input via the Jenkins UI.\n\nPipeline builds can be more complex including forks/joins and parallelism. The pipeline is more resilient and can survive the controller node failure and restarts. To add an Anchore scan you need to add a simple code snippet to any existing pipeline code that first builds an image and pushes it to a docker registry. Once the image is available in a registry accessible by your installed Anchore Engine, a pipeline script will instruct the Anchore plugin to:\n\nSend an API call to the Anchore Engine to add the image for analysis\n\nWait for analysis of the image to complete by polling the engine\n\nSend an API call to the Anchore Engine service to perform a policy evaluation\n\nRetrieve the evaluation result and potentially fail the build if the plugin is configured to fail the build on policy evaluation STOP result (by default it will)\n\nProvide a report of the policy evaluation for review\n\nBelow is an example end-to-end script that will make a Dockerfile, use the docker plugin to build and push the a docker container image to dockerhub, perform an Anchore image analysis on the image and the result, and cleanup the built container.  In this example, we’re using a pre-configured docker-exampleuser named dockerhub credential for dockerhub access, and exampleuser/examplerepo:latest as the image to build and push.  These values would need to be changed to reflect your own local settings, or you can use the below example to extract the analyze stage to integrate an anchore scan into any pre-existing pipeline script, any time after a container image is built and is available in a docker registry that your anchore-engine service can access.\n\npipeline {\n    agent any\n    stages {\n        stage('build') {\n            steps {\n                sh'''\n                    echo 'FROM debian:latest’ > Dockerfile\n                    echo ‘CMD [\"/bin/echo\", \"HELLO WORLD....\"]' >> Dockerfile\n                '''\n                script {\n                    docker.withRegistry('https://index.docker.io/v1/', 'docker-exampleuser') {\n                        def image = docker.build('exampleuser/examplerepo:latest')\n                        image.push()\n                    }\n                }\n            }\n        }\n        stage('analyze') {\n            steps {\n                sh 'echo \"docker.io/exampleuser/examplerepo:latest `pwd`/Dockerfile\" > anchore_images'\n                anchore name: 'anchore_images'\n            }\n        }\n        stage('teardown') {\n            steps {\n                sh'''\n                    for i in `cat anchore_images | awk '{print $1}'`;do docker rmi $i; done\n                '''\n            }\n        }\n    }\n}\n\nThis code snippet writes out the anchore_images file that is read by the plugin to determine which image is to be added to Anchore Engine for scanning.\n\nThis code snippet can be crafted by hand or built using the Jenkins UI, for any Pipeline project. In the project configuration, select Pipeline Syntax from the Project.\n\nThis will launch the Snippet Generator where you can enter the available plugin parameters and press the Generate Pipeline Script button which will produce a snippet that you can use as a starting point.\n\nUsing our example from above, next we save the project:\n\nNote that once you are happy with your script, you could also check it into a Jenkinsfile, alongside the source code.\n\nStep 4: Run the build and review the results.\n\nFinally, we run the build, which will generate a report.  In the below screenshots, we’ve scanned the image docker.io/library/debian:latest to demonstrate some example results.  Once the build completes, the final build report will have some links that will take you to a page that describes the result of the Anchore Engine policy evaluation and security scan:\n\nIn this case, since we left the Fail build on policy STOP result as its default (True), the build has failed due to anchore-engine reporting a policy violation.  In order to see the results, click the Anchore Report (STOP) link:\n\nHere, we can see that there is a single policy check that has generated a ‘STOP’ action, which triggered due to a high severity vulnerability being found against a package installed in the image.  If there were only ‘WARN’ or ‘GO‘ check results here, they would also be displayed, but the build would have succeeded.\n\nWith the combination of Jenkins pipeline project capabilities, plus the Anchore scanner plugin, it’s quick and easy to add container image security scanning and policy checking to your Jenkins project.  In this example, we provide the mechanism for adding scanning to a Jenkins pipeline project using a simple policy that is doing an OS package vulnerability scan, but there are many more policy options that can be configured and loaded into Anchore Engine ranging from security checks to your own site-specific best practice checks (software licenses, package whitelist/blacklist, dockerfile checks, and many more).  For more information about the breadth of Anchore policies, you can find information about Anchore Engine configuration and usage here.\n\nFor more information on Jenkins Pipelines and Anchore Engine, check out the following information sources:\n\nhttps://anchore.com/\n\nhttps://anchore.com/opensource/\n\nhttps://github.com/anchore/anchore-engine\n\nhttps://anchore.freshdesk.com/support/home\n\nChat on Anchore open source slack","title":"Securing your Jenkins CI/CD Container Pipeline with Anchore (in under 10 minutes)","tags":["community","developer","security"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/author/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2018-06-19T00:00:00.000Z","id":"4e634674-53af-534b-ad3d-0fb231791ac9","slug":"/blog/2018/06/19/jenkins-java10-hackathon-day2/","strippedHtml":"This week we have a\nJenkins & Java 10 Online Hackathon.\nThis is an open online event, where we work together on Jenkins core and plugins in order\nto find and fix compatibility issues, share experiences and have some fun.\nEverybody is welcome to join, independently of their Jenkins experience and amount of time they have available.\n\nAfter the kick off on Monday\nJenkins contributors have been working on Java 10 and Java 11 support in Jenkins.\nWe have already received contributions from 12 hackathon participants, and the number keeps growing.\nThere are still 3 days ahead, but we have already achieved some important results we want to share.\n\nJenkins Pipeline\n\nOne of our major efforts over last 2 days was to get Jenkins Pipeline working on\nJava 10+.\nWhen the hackathon started Jenkins Pipeline was not working at all,\nand it was a major blocker for Java support and for exploratory testing in particular.\nWe’ve been working together with Sam van Oort and Devin Nusbaum to fix the libraries in\nthe Jenkins core, Pipeline: Support plugin and Docker packaging.\n\nJust to summarize the result of two days in one screenshot…​\n\nYes, we have got it running!\nOver two days we have got from the \"Pipeline Crashes Immediately\"\nstate to the situation when the most of key Pipeline features are operational,\nincluding Scripted and Declarative Pipeline, Blue Ocean, shared libraries and\ndozens of plugins being used in the Jenkins plugin build flow.\n\nThere is still a lot of work to do to get the changes finalized,\nbut Jenkins Pipeline is available for testing on Java 10 and 11 now.\nIf you want to try it out, you can use a new jenkins/jenkins-experimental:blueocean-jdk10\nimage we have created.\nIt bundles all the required patches, so you can just run the following command to get started:\n\ndocker run -p 8080:8080 -p 50000:50000 jenkins/jenkins-experimental:blueocean-jdk10\n\nIf you want to try more complex scenarions, see the\nRunning Jenkins with Java 10 and 11 blogpost\nand List of Required patches.\n\nWhat else?\n\nAlthough Pipeline is the most visible change,\nthere are other ongoing activities:\n\nDevin Nusbaum explored plugin startup issues we had with JDK 11ea+17\nand confirmed that we need to upgrade our images to JDK 11ea+18\n\nGianpaolo Macario is working on adopting the Java 10 experimental images in his\neasy-jenkins project\n\nSam van Oort and Devin Nusbaum are working on getting plugin build and test flows\nwhen using JDK 10 with Maven\n\nNicolas de Loof is working on cleaning up Illegal reflective access warnings in Jenkins components,\nusing the new Fields micro-library\n\nOlivier Lamy and Nicolas de Loof are updating the\nAnimal Sniffer plugin for Maven\nto make it compatible with Java 9 and above\n\nKohsuke Kawaguchi has released a repackaged version of ASM 6.2 we use in the project\n\nLast but not least, Liam Newman and Tracy Miranda helped us a lot to run the meetings\nand to get this hackathon organized\n\nThere are also other contributors working on exploratory testing and reporting\ndefects they discover.\nSee our status doc\nfor the full list.\n\nWhat’s next?\n\nTomorrow we will have 2 sessions:\n\nAt 8AM UTC we will have a sync-up.\nAccording to the requests from hackathon paticipants, we will have an intro session to Jenkins development for newcomers\n\nYouTube link\n\nAt 4PM UTC we will have a meeting with key JDK Project Jigsaw committers\n\nMark Reinhold, Mandy Chung and Paul Sandoz will join us to talk about\nJava 10/11 adoption\n\nYouTube link\n\nWe will also post participant links in our Gitter channel\n15 minutes before the meetings.\nIf you have any questions, please join the meetings or raise questions in the chat during the call.\n\nCan I still join the hackathon?\n\nYes, you can!\nIt is possible to hop in and hop off at any time.\nJust respond to the registration form,\njoin our Gitter channel and start hacking/testing.\n\nWe also have a number of\nnewbie-friendly issues\nyou can start from.\nSee our Kick-off session and\nslides for quick start guidelines.\n\nLinks\n\nDeveloper mailing list\n\nHackathon sync-up document\n\nRunning Jenkins with Java 10 and 11\n\nJenkins Online Meetup page","title":"Jenkins & Java 10+ Online Hackathon. Day 2 Update","tags":["events","community","developer","java10","java11"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/author/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2018-06-18T00:00:00.000Z","id":"88647b04-059d-549e-a712-a9dfe1d2427e","slug":"/blog/2018/06/18/remoting-over-message-bus/","strippedHtml":"About me\n\nMy name is Pham Vu Tuan, I am a final year undergraduate student from Singapore. This is the first time I participate in Google Summer of Code and contribute to an open-source organization. I am very excited to contribute this summer.\n\nMentors\n\nI have GSoC mentors who help me in this project Oleg Nenashev and Supun Wanniarachchi. Besides that, I also receive great support from developers in remoting project Devin Nusbaum and Jeff Thompson.\n\nOverview\n\nCurrent versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.\n\nThis project aims to develop a plugin in order to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins.\n\nWhy Kafka?\n\nWhen planning for this project, we want to use traditional message queue system such as ActiveMQ or RabbitMQ. However, after some discussion, we decided to have a try with Kafka with more suitable features with this project:\n\nKafka itself is not a queue like ActiveMQ or RabbitMQ, it is a distributed, replicated commit log. This helps to remove message delivery complexity we have in traditional queue system.\n\nWe need to support data streaming as a requirement, and Kafka is good at this aspect, which RabbitMQ is lack of.\n\nKafka is said to have a better scalability and good support from the development community.\n\nCurrent State\n\nThe project is reaching the end of the first phase and here are things we have achieved so far:\n\nSetup project as a set of Docker Compose components: Kafka cluster, Jenkins controller (with plugin) and a custom agent (JAR).\n\nCreate a PoC with new command transport implementation to support Kafka, which involves of command invocation, RMI, classloading and data streaming.\n\nMake neccessary changes in Remoting and Jenkins core to make them extensible for the use of this project.\n\nDecide to use Kafka as a suitable final implementation.\n\nWe planned to release an alpha version of this plugin by the end of this phase, but decided to move this release to the second phase because we need to wait for remoting and core patches to be released.\n\nArchitecture Overview\n\nThe project consists of multiple components:\n\nKafka Client Library - new command transport implementation, producer and consumer client logic.\n\nRemoting Kafka Plugin - plugin implementation with KafkaGlobalConfiguration and KafkaComputerLauncher.\n\nRemoting Kafka Agent - A custom JAR agent with remoting JAR packaged together with a custom Engine implementation to setup a communication channel with Kafka.\n\nAll the components are packaged together with Docker Compose.\n\nThe below diagram is the overview of the current architecture:\n\nWith this design, controller is not communicating with agent using direct TCP communication anymore, all the communication commands are transfered with Kafka.\n\nFeatures\n\n1. Kafka Global Configuration\n\n2. Custom agent start up as a JAR\n\nUser can start running an agent with the following command:\n\n3. Launch agents with Kafka\n\n4. Commands transferred between controller and agent over Kafka\n\nRemoting operations are being executed over Kafka. In the log you may see:\n\nClassloading (Classloader.fetch())\n\nLog streaming (Pipe.chunk())\n\n5. Run jobs with remoting Kafka\n\nIt is possible to run jobs on Agents connected over Kafka\n\nNext Phase Plan\n\nHere are the tasks planned for the next phase:\n\nSupport security for controller-agent connection:\n\nKafka authentication/authorization ( JENKINS-51472, JENKINS-51473).\n\nAgent secrets ( JENKINS-51470).\n\nImprove Kafka producer-consumer model to ensure reliability ( JENKINS-51942).\n\nBug fixing.\n\nRelease alpha version and address feedback ( JENKINS-51713).\n\nHow to run demo\n\nYou can try to run a demo of the plugin by following the instruction.\n\nLinks\n\nGitHub Repository\n\nProject Page\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Intro: Jenkins Remoting over Message Bus/Queue","tags":["plugins","gsoc","gsoc2018","remoting"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"pvtuan10","html":"<div class=\"paragraph\">\n<p>Pham Vu Tuan is a developer from Singapore.\nHe starts contributing to Jenkins from Google Summer of Code 2018 for <a href=\"https://jenkins.io/projects/gsoc/2018/remoting-over-message-bus/\">Jenkins Remoting over Message Bus/Queue</a></p>\n</div>","id":"pvtuan10","irc":"pvtuan10","linkedin":null,"name":"Pham Vu Tuan","slug":"/blog/author/pvtuan10","twitter":null}]}},{"node":{"date":"2018-06-17T00:00:00.000Z","id":"2a47e8d0-b919-50d2-9fe2-b9937f8d85bc","slug":"/blog/2018/06/17/running-jenkins-with-java10-11/","strippedHtml":"Please refer to Running Jenkins on Java 11 documentation to have the up-to-date details on how to run Jenkins on Java 11.\n\nGuidelines in this blogpost are rendered obsolete by the Java 11 Support Preview Availability\nannouncement on Dec 13, 2018 and by the Java 11 GA release on Sep 25, 2018.\nSee the Java support page\nfor up-to-date information about running Jenkins with Java 11.\nThe Jenkins project also no longer ships preview versions for Java 10.\n\nAs you probably know, we will have a\nJenkins and Java 10+ online hackathon this week.\nIn order to enable early adopters to try out Jenkins with new Java versions,\nwe have updated Jenkins core and Docker packages.\nStarting from Jenkins 2.127,\nweekly releases can be launched with Java 10 and Java 11 (preview).\nAlthough there are some known compatibility issues,\nthe packages are ready for evaluation and exploratory testing.\n\nThis article explains how to run Jenkins with Java 10 and 11 using Docker images and WAR files.\nIt also lists known issues and provides contributor guidelines.\n\nRunning in Docker\n\nIn order to simplify testing, we have created a new\njenkins/jenkins-experimental\nrepository on DockerHub.\nThis repository includes various Jenkins Core images, including Java 10 and Java 11 images.\nWe have also set up development branches and continuous delivery flows for Jenkins core,\nso now we can deliver patches for these images without waiting for weekly releases.\n\nYou can run the image simply as:\n\ndocker run -p 8080:8080 -p 50000:50000 jenkins/jenkins-experimental:latest-jdk11\n\nThe following tags are available:\n\n2.127-jdk10, 2.128-jdk10 - Weekly releases packaged with Java 10\n\n2.127-jdk11, 2.128-jdk11 - Weekly releases packaged with Java 11\n\nlatest-jdk10 - Jenkins core build from the java10-support branch\n\nlatest-jdk11 - Automatic build from the core’s java11-support branch.\n\nblueocean-jdk10, blueocean-jdk11 - Experimental build, which bundles all Jenkins Pipeline and\nBlue Ocean patches required to run on Java 11.\nIf you want to try Pipeline, use this image\n\nJava 10/11 images are fully compatible with the official\njenkins/jenkins\nDocker image documentation,\ne.g. you can use plugins.txt to install plugins, mount volumes and pass extra options via environment variables.\n\nRunning Jenkins without Docker\n\nJava 10\n\nDownload Jenkins WAR for 2.127 or above\n(or build the experimental branch)\n\nRun WAR with the following command:\n\n${JAVA10_HOME}/bin/java --add-modules java.xml.bind -jar jenkins.war \\\n    --enable-future-java --httpPort=8080 --prefix=/jenkins\n\nJava 11\n\nDownload Jenkins WAR for 2.127 or above\n(or build the experimental branch)\n\nDownload the following libraries to the same directory as jenkins.war\n\njaxb-api-2.3.0.jar (save as jaxb-api.jar)\n\njaxb-core-2.3.0.1.jar (save as jaxb-core.jar)\n\njaxb-impl-2.3.0.1.jar (save as jaxb-impl.jar)\n\njavax.activation v.1.2.0 (save as javax.activation.jar)\n\nRun the following command:\n\nRun Jenkins with ${JAVA11_HOME}/bin/java \\\n    -p jaxb-api.jar:javax.activation.jar --add-modules java.xml.bind,java.activation \\\n    -cp jaxb-core.jar:jaxb-impl.jar \\\n    -jar jenkins.war --enable-future-java --httpPort=8080 --prefix=/jenkins\n\nCurrent state\n\nAs of June 17, we have achieved the following state:\n\nJenkins 2.127+ starts up successfully with\nOpenJDK 10.0.1 and\nOpenJDK 11+17-Debian-2 (preview)\n\nIt is possible to configure and run simple Freestyle jobs\n\nJenkins agents are able to start on Java 10, to connect to the controller and to execute Freestyle jobs\n\nAgents can be connected using Docker Plugin and Yet Another Docker Plugin\n\nJob DSL plugin works well on demo projects\n\nMaven Integration plugin can build\nplugin-pom -based\nJenkins plugins when running on agents with JDK 8\n\nIt is possible to create Folders and manage items in them\n\nIt is possible to configure Jenkins using Configuration-as-Code plugin\n\nJenkins is able to execute Groovy scripts in Script Console and\nGroovy Hooks\n\nKnown issues\n\nSo far we know about the following issues:\n\nPipeline crashes immediately on Java 10 and 11 ( JENKINS-46602)\n\nWorkaround: Pipeline: Support plugin should be updated to version 3.0-java11-alpha-1-rc684.d802f5d9aeed from the Incrementals repo\n( download)\n\nFIXED - Git Client plugin 2.7.2 cannot be installed when running with Java 11 build 18ea\n\nThere are many warnings about Illegal reflective access during execution\n(linked in JENKINS-40689).\n\nIn current Java 10 and 11 releases it does not lead to failures,\nbut we want to cleanup these warnings anyway\n\nFIXED - Configuration-as-Code plugin fails to export configurations on Java 10\n( JENKINS-51991)\n\nWe anticipate to discover and report more issues during the hackathon this week.\n\nContributing\n\nIf you discover incompatibilities in plugins, please\nreport issues in our bugtracker.\nWe have java10 and java11 labels for such issues.\n\nIf you are interested to try out Jenkins with Java 10 and 11 before June 22nd,\nyou may be interested to sign-up to the Jenkins and Java 10+ online hackathon.\nEverybody is welcome to join, independently of their Jenkins experience and amount of time they have available.\nExploratory testing is also within the hackathon’s scope.\nDuring this event, please also use the java10_hackathon label.\nIt will help us to track contributions and send folks some small \"thank you\" gifts for participating (details will be figured out during the hackathon).\n\nIf you want to contribute patches to the core,\nplease submit pull requests to java10-support or\njava11-support branches.\nIf the patches are compatible with Java 8, we will try to upstream them to weekly releases.\nFor plugin patches please create pull requests against main branches and then follow guidelines from plugin maintainers.\nIf you need additional reviews and you are a member of the jenkinsci organization,\nfeel free to mention the @jenkinsci/java10-support team in your PRs.\n\nLinks:\n\nDocker: jenkins/jenkins-experimental images\n\nJIRA: Java 10 compatibility\n\nJIRA: Java 11 compatibility\n\nJenkins and Java 10+ online hackathon","title":"Running Jenkins with Java 10 and 11 (experimental support)","tags":["core","developer","java10","java11"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/author/oleg_nenashev","twitter":"oleg_nenashev"}]}},{"node":{"date":"2018-06-15T00:00:00.000Z","id":"099fdcfb-2f30-562a-9c7c-67ed48398003","slug":"/blog/2018/06/15/simple-pull-request-plugin/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nMentors\n\nOleg Nenashev (Org Admin)\n\nMartin d’Anjou\n\nKristin Whetstone\n\nJeff Knurek\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of the report at conventional locations,\nand publish them automatically. If the reports are not present at conventional location,\ncan specify the location using the YAML file.\n\nBenefits to the community\n\nProject administrators will be able to handle builds for pull requests more easily.\n\nBuild specifications for pull request can be written in a concise declarative format.\n\nBuild reports will be automatically published to Github, Bitbucket, etc.\n\nBuild status updates will be sent to git servers automatically.\n\nUsers will not have to deal with pipeline code.\n\nIf there will be no merge conflicts or build failures, the PR can be merged into target branch.\n\nPrior work\n\nTravis YML Plugin :\nDesigned to run .travis.yml as Jenkins pipeline job.\nTravis-CI does not support external pull requests. Jenkins environment\nis different than Travis and does not always make sense to use configurations\ndefined for other environment in Jenkins. Also maintenance of this is slowed\ndown and last commit for this plugin was on 14 Nov 2016.\nClick here to check.\n\nCodeShip Plugin :\nThis plugin is designed to convert codeship \"steps.yaml\" and\n\"services.yaml\" to scripted pipeline code. This plugin has never been released.\n\nJenkins pipeline builder :\nThis is a external non-Java-based tool, which cannot be easily converted to a Jenkins plugin.\n\nDesign\n\nThis plugin will be developed on the top of the MultiBranch Pipeline plugin.\n\nFor now the plugin is bulding branches and Pull request both using Jenkinsfile.yaml,\nbut this plugin is inclined to use for pull requests. This will be fixed in next coding phase.\n\nThis plugin is following below steps for now:\n\nclone target repo\n\ncheckout to target branch\n\nfetch the source branch\n\nmerge source-branch\n\ncall user call user script to build the repo.\n\npush changes of pull request to target branch\n\npublish test reports\n\nPlugin will start above steps if and only if the pull request is\nmergeable, to avoid merge conflicts while merging the source branch to target\nbranch. Pull request’s payload contains information if the pull request changes\nare mergeable or not hence, the pull request is mergebale or not can also be\ndecided by the payload of webhook also.\n\nHow to run the Plugin\n\nSee How to run the demo\nand set credentials, owner and repository on your own and you will be good to go.\n\nExample branch-source configuration.\n\nPhase 1 features\n\nUsers are able to select the Jenkinsfile.yaml file as the source for the Pipeline configuration.\n\nGit Push step\n\nharvest results and reports (and post in the pull request)\n\njunit()\n\nfindbugs()\n\narchiveArtifacts()\n\nBasic interface to parse and get build specifications from YAML file.\n\nThings decided\n\nTo build the plugin on the top of multibranch pipeline plugin. As that plugin has implementation of\n\nNice interface to show different branch and pull requests build separately with use of suitable plugins like Github, Bitbucket.\n\nDetect trusted revisions in a repository.\n\nPublishing of build status to the repository.\n\nConvert the YAML configuration to declarative pipeline.\n\nUser will provide path to the script relative to the root directory of the repository\nwithout extension (.sh or .bat) in the YAML file. The plugin will generate pipeline script to detect the\nplatform and call .sh or .bat script.\n\nExample:\n  Path provided: ./scripts/hello\n  a. On UNIX machine “./scripts/hello.sh” will be called\n  b. On non-UNIX machine “./scripts/hello.bat” will be called.\n\nImplementations till now\n\nA first prototype of the plugin is ready. It supports all features of Multi-Branch Pipeline and offers the following features.\n\nBuild description is defined via YAML file stored within the SCM repo. This plugin\nwill depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be\nusing respective paltfroms for their repositories.\n\nBasic conversion of YAML to Declarative Pipeline: A class YamlToPipeline\nis written which will load the \"Jenkinsfile.yaml\" and make use of PipelineSnippetGenerator class\nto generate Declarative pipeline code.\n\nReporting of results.\n\nPlugin is using Yaml from target branch right now. (Maybe this needs some discussion, example:\nwhat if pull request contains changes in Jenkinsfile.yaml)\n\nGit Push step: To push the changes of pull request to the target branch. This is implemented\nusing git-plugin, PushCommand is used for this from git-plugin. credentialId,\nbranch name and repository url for intracting with Github, Bitbucket, etc\nwill be taken automatically from \"Branch-Source\" (Users have to fill thes\ndetails of branch source in job configuration UI). (You can see\nHow to run the demo)\n\nJenkinsfile.yaml example\n\nFor the phase 1 prototype demonstration, the following yaml file was used.\nNote that this format is subject to change in the next phases of the project,\nas we formalise the yaml format definition.\n\nagent:\n    dockerImage: maven:3.5.3-jdk-8\n    args: -v /tmp:/tmp\n\ntestResultPaths:\n    - target/surefire-reports/*.xml\n\nfindBugs: target/*.xml\n\nstages:\n    - name: First\n      scripts:\n        -   ./scripts/hello\n    - name: Build\n      scripts:\n        -   ./scripts/build\n    - name: Tests\n      scripts:\n        -   ./scripts/test\n\narchiveArtifacts:\n    - Jenkinsfile.yaml\n    - scripts/hello.sh\n\nFrom the yaml file shown above, the plugin generates the following pipeline code:\n\npipeline {\n  agent {\n    docker {\n      image 'maven:3.5.3-jdk-8'\n      args '-v /tmp:/tmp'\n      alwaysPull false\n      reuseNode false\n    }\n  }\n  stages {\n    stage('First') {\n      steps {\n        script {\n          if (isUnix()) {\n            sh './scripts/hello.sh'\n          } else {\n            bat './scripts/hello.bat'\n          }\n        }\n      }\n    }\n    stage('Build') {\n      steps {\n        script {\n          if (isUnix()) {\n            sh './scripts/build.sh'\n          } else {\n            bat './scripts/build.bat'\n          }\n        }pipeline\n      }\n      post {\n        success {\n          archiveArtifacts artifacts: '**/target/*.jar'\n          archiveArtifacts artifacts: 'Jenkinsfile.yaml'\n          archiveArtifacts artifacts: 'scripts/hello.sh'\n        }\n      }\n    }\n    stage('Tests') {\n      steps {\n        script {\n          if (isUnix()) {\n            sh './scripts/test.sh'\n          } else {\n            bat './scripts/test.bat'\n          }\n        }\n      }\n      post {\n        success {\n          junit 'target/surefire-reports/*.xml'\n        }\n        always {\n          findbugs pattern: 'target/*.xml'\n        }\n      }\n    }\n  }\n}\n\nPipeline view in Jenkins instance\n\nCoding Phase 2 plans\n\nDecide a proper YAML format to use for Jenkinsfile.yaml\n\nCreate Step Configurator for SPRP plugin. Jenkins-51637.\nThis will enable users to use Pipeline steps in Jenkinsfile.yaml.\n\nAutomatic indentation generation in the generated Pipeline SnipperGenerator class.\n\nWrite tests for the plugin.\n\nJira Epic\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nInitial proposal of the project\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository\n\nPhase 1 Presentation video (June 14, 2018)\n\nPhase 1 Presentation Slides (June 14, 2018)","title":"GSoC Project Intro: Pipeline as YAML","tags":["gsoc2018","gsoc","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/author/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-06-13T00:00:00.000Z","id":"a1c90a56-ed3d-57e4-bd0b-1397798cc5ea","slug":"/blog/2018/06/13/code-coverage-api-plugin/","strippedHtml":"About me\n\nMy name is Shenyu Zheng, and I am an undergraduate student in Computer Science and Technology at Henan University from China.\n\nI am very excited that I can participate in GSoC to work on Code Coverage API plugin with the Jenkins community and to contribute to the open source world. It is my greatest pleasure to write a plugin that many developers will use.\n\nMy mentors are Steven Christou, Supun Wanniarachchi, Jeff Pearce and Oleg Nenashev.\n\nAbstract\n\nThere are a lot of plugins which currently implement code coverage, however, they all use similar config, charts, and content. So it will be much better if we can have an API plugin which does the most repeated work for those plugins and offers a unified APIs which can be consumed by other plugins and external tools.\n\nThis API plugin will mainly do these things:\n\nFind coverage reports according to the user’s config.\n\nUse adapters to convert reports into the our standard format.\n\nParse standard format reports, and aggregate them.\n\nShow parsed result in a chart.\n\nSo, we can implement code coverage publishing by simply writing an adapter, and such adapter only needs to do one thing — convert a coverage report into the standard format. The implementation is based on extension points, so new adapters can be created in separate plugins. In order to simplify conversion for XML reports, there is also an abstraction layer which allows creating XSLT-based converters.\n\nCurrent Progress - Alpha Version\n\nI have developed an alpha version for this plugin. It currently integrates two different coverage tools - Cobertura and Jacoco. Also, it implements many basic functionalities like threshold, auto-detect, trend chart and so on.\n\nConfiguration Page\n\nconfig plugin\n\nWe can input the path pattern for auto detect, so that plugin will automatically find reports and group them using a corresponding converter. That makes config simpler and the user doesn’t need to fully specify the report name. Also, if we want, we can manually specify each coverage report.\n\nWe also have global and per-report threshold configurations, which makes the plugin more flexible than existing plugins (e.g. global threshold for a multi-language project that has several reports).\n\nPipeline Support\n\nIn addition to configuring the Code Coverage API plugin from the UI page, we also have pipeline support.\n\nnode {\n   publishCoverage(autoDetectPath: '**/*.xml', adapters: [jacoco(path: 'jacoco.xml')], globalThresholds: [[thresholdTarget: 'GROUPS', unhealthyThreshold: 20.0, unstableThreshold: 0.0]])\n}\n\nReport Defects\n\nAs we can see in Configuration page, we can set healthy threshold and stable threshold for each metric. The Code Coverage API plugin will report healthy score according to the healthy threshold we set.\n\nthreshold config\n\nresult\n\nAlso, we have a group of options which can fail the build if coverage falls below a particular threshold.\n\nCoverage Result Page\n\nThe coverage result page now has a modernized UI which shows coverage results more clearly.\nThe result page includes three parts - Trend chart, Summary chart, Child Summary chart.\n\nTrend Chart\n\nIn the Trend chart, we can see the coverage trend of the selected coverage metrics.\n\nSummary Chart\n\nIn the summary chart we can see the coverage summary of current coverage metric.\n\nChild Summary Chart\n\nIn the Child summary chart, we can see the coverage summary of each child, also, we can use the range handler to filter item we want to see to reduce the chart size.\n\nBy using those more modernized chart components, we can easily focus on the information we want to know.\n\nExtensibility\n\nWe provide several extension points to make our plugin more extensible and flexible. Also, we have a series of abstract layers to help us implementing these extension points much easier.\n\nCoverageReportAdapter\n\nWe can implement a coverage tool by implementing CoverageReportAdapter extension point. For example, by using the provided abstract layer, we can implement Jacoco simple like this:\n\npublic final class JacocoReportAdapter extends JavaXMLCoverageReportAdapter {\n\n    @DataBoundConstructor\n    public JacocoReportAdapter(String path) {\n        super(path);\n    }\n\n    @Override\n    public String getXSL() {\n        return \"jacoco-to-standard.xsl\";\n    }\n\n    @Override\n    public String getXSD() {\n        return null;\n    }\n\n    @Symbol(\"jacoco\")\n    @Extension\n    public static final class JacocoReportAdapterDescriptor extends CoverageReportAdapterDescriptor {\n\n        public JacocoReportAdapterDescriptor() {\n            super(JacocoReportAdapter.class, \"jacoco\");\n        }\n    }\n}\n\nAll we need is to extend an abstract layer for XML-based Java report and provide an XSL file to convert the report to our Java standard format. There are also other extension points which are under development.\n\nOther Extension points\n\nWe also plan to provide extension points for coverage threshold and report detector. Once it completed, we can have more control over our coverage report process.\n\nNext Phase Plan\n\nThe Alpha version now has many parts which still need to be implemented before the final release. So in next phase, I will mainly do those things.\n\nAPIs which can be used by others\n\nIntegrate Cobertura Plugin with Code Coverage API (JENKINS-51424).\n\nProvide API for getting coverage information. E.g. summary information about coverage (percentages, trends) (JENKINS-51422), (JENKINS-51423).\n\nImplementing abstract layer for other report formats like JSON. (JENKINS-51732).\n\nSupporting converters for non-Java languages. (JENKINS-51924).\n\nSupporting combining reports within a build(e.g. after parallel() execution in Pipeline) (JENKINS-51926).\n\nAdding source code navigation in Coverage Result Page (JENKINS-51988).\n\nRefactoring the configuration page to make it more user-friendly (JENKINS-51927).\n\nHow to Try It Out\n\nAlso, I have released the Alpha version in the Experimental Update Center. If you can give me some of your valuable advice about it, I will very appreciate.\n\nLinks\n\nJIRA Component\n\nProject Page\n\nProject Repository\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Intro: Code Coverage API Plugin","tags":["plugins","gsoc","gsoc2018"],"authors":[{"avatar":null,"blog":null,"github":"cizezsy","html":"<div class=\"paragraph\">\n<p>Shenyu comes from China. He is a third year student now, and his major is\nComputer Science and technology. He has participated in GSoC 2018 for\n<a href=\"https://jenkins.io/projects/gsoc/2018/code-coverage-api-plugin/\">Code Coverage API Plugin</a></p>\n</div>","id":"shenyu_zheng","irc":"cizezsy","linkedin":null,"name":"Shenyu Zheng","slug":"/blog/author/shenyu_zheng","twitter":null}]}},{"node":{"date":"2018-06-08T00:00:00.000Z","id":"f46b46ad-a0ad-590a-a614-37ad7eaf1e7d","slug":"/blog/2018/06/08/jenkins-java10-hackathon/","strippedHtml":"On behalf of the Jenkins Events Team,\nI would like to invite you to the “Jenkins & Java 10 Online Hackathon” which will take place from June 18th to 22nd.\nWe will be working together on Jenkins core and plugins in order\nto find and fix compatibility issues, share experiences and have some fun.\nEverybody is welcome to join, independently of their Jenkins experience and amount of time they have available.\n\nIf you are interested in participating in the hackathon, please sign-up in\nthis form.\n\nBackground\n\nJava 9 has recently been end-of-lifed, Java 10 is in GA, and Java 11 is in early beta.\nJenkins project currently requires Java 8 to run reliably,\nand there are some known compatibility issues with higher Java versions.\n\nDuring the Jenkins World 2017 Hackathon,\nMark Waite and\nBaptiste Mathus spent some time exploring Java 9 compatibility in Jenkins.\nWe are currently tracking compatibility issues in the\nJENKINS-40689 EPIC,\nbut there are likely many unknown issues in Jenkins core, plugins and in libraries we use in the project.\nWe would like to continue their effort and work on Java 10+ support.\n\nObjectives and Scope\n\nAs I have said above,\nthe goals are to explore/fix compatibility issues, share experiences and have fun.\nWe DO NOT plan to make Jenkins fully compatible with Java 10+\nduring the hackathon,\nbut we will try to integrate fixes and make them available.\n\nSince the announcement of the Hackathon in the mailing list,\nwe have got a number of registrations from contributors working on several project areas.\nWe will split our work to several areas:\n\nJenkins core and Remoting\n\nPipeline Engine\n\nPlugins (e.g. Git plugin or any plugin you want to work on)\n\nExploratory testing for Java 10 and beyond\n\nIn order to organize the effort, we have created a\njava10_hackathon label\nin Jenkins JIRA.\nIf you are interested in particular tasks,\nplease assign them to yourself and add the label.\n\nOrganization\n\nCurrently the event is in the planning stage.\nWe will be using the Developer mailing list\nfor synchronization before the event.\n\nWhat will we have?\n\nCommunications in #jenkins-hackhouse IRC and in the\nJenkins Gitter channel\n\nDaily recorded sync-up calls in Hangouts\n\nKnowledge transfer sessions during the event\n\nWe also want to prepare some special swag for active participants.\nIf you have reached this part of the blogpost,\nyou have probably seen the logo ;)\n\nLinks\n\nRegistration\n\nDeveloper mailing list\n\nHackathon sync-up document\n\nRunning Jenkins with Java 10 and 11\n\nJIRA: Java 10 compatibility\n\nJIRA: Java 11 compatibility\n\nJIRA: Hackathon tasks","title":"Jenkins & Java 10+ Online Hackathon (Jun 18-22)","tags":["events","community","developer","java10","java11"],"authors":[{"avatar":{"childImageSharp":null},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/author/oleg_nenashev","twitter":"oleg_nenashev"}]}}]}},"pageContext":{"limit":8,"skip":216,"numPages":100,"currentPage":28}},
    "staticQueryHashes": ["3649515864"]}