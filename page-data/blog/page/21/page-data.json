{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/21",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2019-02-17T00:00:00.000Z","id":"a79ea93c-0082-5a4a-a338-9fde01ae88b1","slug":"/blog/2019/02/17/remoting-cli-removed/","strippedHtml":"Close to two years ago, we announced in\nNew, safer CLI in 2.54\nthat the traditional “Remoting” operation mode of the Jenkins command-line interface\nwas being deprecated for a variety of reasons, especially its very poor security record.\nToday in Jenkins 2.165 support for this mode is finally being removed altogether,\nin both the server and bundled jenkins-cli.jar client.\nThe projected June 5th LTS release will reflect this removal,\nat which point the Jenkins project will no longer maintain this feature\nnor investigate security vulnerabilities in it.\n\nThis change makes the code in Jenkins core related to the CLI considerably simpler and more maintainable.\n(There are still two transports —HTTP(S) and SSH—but they have similar capabilities and behavior.)\nIt also reduces the “attack surface” the Jenkins security team must consider.\nAmong other issues, a compromised server could freely attack a developer’s laptop if -remoting were used.\n\nThe\n2.46.x upgrade guide\nalready urged administrators to disable Remoting mode on the server.\nThose Jenkins users who rely on the CLI for remote scripting (as opposed to the HTTP(S) REST APIs)\nwould be affected only if they were still using the -remoting CLI flag,\nsince the default has long been to use HTTP(S) mode.\n\nMost CLI features have long worked fine without -remoting,\nin some cases using slightly different syntax such as requiring shell redirects to access local files.\nAs part of this change, some CLI commands, options, and option types in Jenkins core have been removed, other than -remoting itself:\n\nThe login and logout commands, and the --username and --password options.\n\nThe -p option to select a proxy. (The CLI in default -http mode accesses Jenkins no differently than any other HTTP client.)\n\nThe install-tool, set-build-parameter, and set-build-result commands relied on a fundamentally insecure idiom that is no longer supportable.\n\nCommand options or arguments which took either a local file or = for standard input/output (e.g., install-plugin, build -p, support) now only accept the latter.\n\nSome features of relatively little-used plugins will no longer work, such as:\n\nDistFork\n\nRemote Terminal Access\n\nBuild Env Propagator","title":"Remoting-based CLI removed from Jenkins","tags":["core","security","remoting"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}},{"node":{"date":"2019-02-06T00:00:00.000Z","id":"ed5dfb33-f5e6-565b-a671-f4ae47d2c691","slug":"/blog/2019/02/06/ssh-steps-for-jenkins-pipeline/","strippedHtml":"Pipeline-as-code or defining the deployment pipeline through code rather than manual job creation through UI, provides tremendous benefits for teams automating builds and deployment infrastructure across their environments.\n\nSource of image: https://jenkins.io/doc/book/pipeline/\n\nJenkins Pipelines\n\nJenkins is a well-known open source continuous integration and continuous deployment automation tool. With the latest 2.0 release, Jenkins introduced the Pipeline plugin that implements Pipeline-as-code. This plugin lets you define delivery pipelines using concise scripts which deal elegantly with jobs involving persistence and asynchrony.\n\nThe Pipeline-as-code’s script is also known as a Jenkinsfile.\n\nJenkinsfiles uses a domain specific language syntax based on the Groovy programming language. They are persistent files which can be checked in and version-controlled along with the rest of their project source code. This file can contain the complete set of encoded steps (steps, nodes, and stages) necessary to define the entire application life-cycle, becoming the intersecting point between development and operations.\n\nMissing piece of the puzzle\n\nOne of the most common steps defined in a basic pipeline job is the Deploy step. The deployment stage encompasses everything from publishing build artifacts to pushing code into pre-production and production environments. This deployment stage usually involves both development and operations teams logging onto various remote nodes to run commands and/or scripts to deploy code and configuration. While there are a couple of existing ssh plugins for Jenkins, they currently don’t support the functionality such as logging into nodes for pipelines. Thus, there was a need for a plugin that supports these steps.\n\nIntroducing SSH Steps\n\nRecently, our team at Cerner started working on a project to automate deployments through Jenkins pipelines to help facilitate running commands on over one thousand nodes. We looked at several options including existing plugins, internal shared Jenkins libraries, and others. In the end, we felt it was best to create and open source a plugin to fill this gap so that it can be used across Cerner and beyond.\n\nThe initial version of this new plugin SSH Steps supports the following:\n\nsshCommand : Executes the given command on a remote node.\n\nsshScript : Executes the given shell script on a remote node.\n\nsshGet : Gets a file/directory from the remote node to current workspace.\n\nsshPut : Puts a file/directory from the current workspace to remote node.\n\nsshRemove : Removes a file/directory from the remote node.\n\nUsage\n\nBelow is a simple demonstration on how to use above steps. More documentation can be found on GitHub.\n\ndef remote = [:]\nremote.name = \"node\"\nremote.host = \"node.abc.com\"\nremote.allowAnyHosts = true\n\nnode {\n    withCredentials([usernamePassword(credentialsId: 'sshUserAcct', passwordVariable: 'password', usernameVariable: 'userName')]) {\n        remote.user = userName\n        remote.password = password\n\n        stage(\"SSH Steps Rocks!\") {\n            writeFile file: 'test.sh', text: 'ls'\n            sshCommand remote: remote, command: 'for i in {1..5}; do echo -n \\\"Loop \\$i \\\"; date ; sleep 1; done'\n            sshScript remote: remote, script: 'test.sh'\n            sshPut remote: remote, from: 'test.sh', into: '.'\n            sshGet remote: remote, from: 'test.sh', into: 'test_new.sh', override: true\n            sshRemove remote: remote, path: 'test.sh'\n        }\n    }\n}\n\nConfiguring via YAML\n\nAt Cerner, we always strive to have simple configuration files for CI/CD pipelines whenever possible. With that in mind, my team built a wrapper on top of these steps from this plugin. After some design and analysis, we came up with the following YAML structure to run commands across various remote groups:\n\nconfig:\n  credentials_id: sshUserAcct\n\nremote_groups:\n  r_group_1:\n    - name: node01\n      host: node01.abc.net\n    - name: node02\n      host: node02.abc.net\n  r_group_2:\n    - name: node03\n      host: node03.abc.net\n\ncommand_groups:\n  c_group_1:\n    - commands:\n        - 'ls -lrt'\n        - 'whoami'\n    - scripts:\n        - 'test.sh'\n  c_group_2:\n    - gets:\n        - from: 'test.sh'\n          to: 'test_new.sh'\n    - puts:\n        - from: 'test.sh'\n          to: '.'\n    - removes:\n        - 'test.sh'\n\nsteps:\n  deploy:\n    - remote_groups:\n        - r_group_1\n      command_groups:\n        - c_group_1\n    - remote_groups:\n        - r_group_2\n      command_groups:\n        - c_group_2\n\nThe above example runs commands from c_group_1 on remote nodes within r_group_1 in parallel before it moves on to the next group using sshUserAcct (from the Jenkins Credentials store) to logon to nodes.\n\nShared Pipeline Library\n\nWe have created a shared pipeline library that contains a sshDeploy step to support the above mentioned YAML syntax. Below is the code snippet for the sshDeploy step from the library. The full version can be found here on Github.\n\n#!/usr/bin/groovy\ndef call(String yamlName) {\n    def yaml = readYaml file: yamlName\n    withCredentials([usernamePassword(credentialsId: yaml.config.credentials_id, passwordVariable: 'password', usernameVariable: 'userName')]) {\n        yaml.steps.each { stageName, step ->\n            step.each {\n                def remoteGroups = [:]\n                def allRemotes = []\n                it.remote_groups.each {\n                    remoteGroups[it] = yaml.remotes.\"$it\"\n                }\n\n                def commandGroups = [:]\n                it.command_groups.each {\n                    commandGroups[it] = yaml.commands.\"$it\"\n                }\n                def isSudo = false\n                remoteGroups.each { remoteGroupName, remotes ->\n                    allRemotes += remotes.collect { remote ->\n                        if(!remote.name)\n                            remote.name = remote.host\n                        remote.user = userName\n                        remote.password = password\n                        remote.allowAnyHosts = true\n                        remote.groupName = remoteGroupName\n                        remote\n                    }\n                }\n                if(allRemotes) {\n                    if(allRemotes.size() > 1) {\n                        def stepsForParallel = allRemotes.collectEntries { remote ->\n                            [\"${remote.groupName}-${remote.name}\" : transformIntoStep(stageName, remote.groupName, remote, commandGroups)]\n                        }\n                        stage(stageName) {\n                            parallel stepsForParallel\n                        }\n                    } else {\n                        def remote = allRemotes.first()\n                        stage(stageName + \"\\n\" + remote.groupName + \"-\" + remote.name) {\n                            transformIntoStep(stageName, remote.groupName, remote, commandGroups).call()\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nBy using the step (as described in the snippet above) from this shared pipeline library, a Jenkinsfile can be reduced to:\n\n@Library('ssh_deploy') _\n\nnode {\n  checkout scm\n  sshDeploy('dev/deploy.yml');\n}\n\nAn example execution of the above pipeline code in Blue Ocean looks like this:\n\nWrapping up\n\nSteps from the SSH Steps Plugin are deliberately generic enough that they can be used for various other use-cases as well, not just for deploying code. Using SSH Steps has significantly reduced the time we spend on deployments and has given us the possibility of easily scaling our deployment workflows to various environments.\n\nHelp us make this plugin better by contributing. Whether it is adding or suggesting a new feature, bug fixes, or simply improving documentation, contributions are always welcome.","title":"SSH Steps for Jenkins Pipeline","tags":["pipeline","plugins","ssh","steps"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg","srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/77b35/nrayapati.jpg 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/d4a57/nrayapati.jpg 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/19e71/nrayapati.jpg 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/68974/nrayapati.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/ef6ff/nrayapati.webp 32w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/8257c/nrayapati.webp 64w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/6766a/nrayapati.webp 128w,\n/gatsby-jenkins-io/static/4aea26279158324c14a34104f2df9d81/22bfc/nrayapati.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"nrayapati","html":"<div class=\"paragraph\">\n<p>Software Architect at <a href=\"https://www.cerner.com/\">Cerner Corporation</a>. Passionate about Agile, DevOps &amp; Continuous Delivery, and all things Automation.\nOSS Contributor, he is maintaining couple of Jenkins plugins since past several years. <a href=\"https://plugins.jenkins.io/ssh-steps\">SSH Steps</a> - <a href=\"https://plugins.jenkins.io/jira-steps\">JIRA Steps</a> - <a href=\"https://plugins.jenkins.io/hubot-steps\">Hubot Steps</a></p>\n</div>","id":"nrayapati","irc":null,"linkedin":null,"name":"Naresh Rayapati","slug":"/blog/authors/nrayapati","twitter":"nrayapati"}]}},{"node":{"date":"2019-02-05T00:00:00.000Z","id":"9488675b-0d5a-5055-8c7d-1ab61e7ad642","slug":"/blog/2019/02/05/jenkins-new-year-in-china/","strippedHtml":"At the time of the Spring Festival. I want to make a summary of some activities in the last year.\nYou might already notice that more and more Chinese contributors emerge in the Jenkins community.\nWe have a GSoC champion who is Shenyu Zheng.\nHe is a great example for other students. With the effort of three skilled engineers,\nmany Jenkins users could learn the edge technologies and useful use cases.\nThey co-organized several Jenkins Meetups in a couple of cities in China.\n\nThere are two workshops about Jenkins and Jenkins X in the DevOps International Summit. James Rawlings gave us a wonderful view of the Jenkins X. Many people start to know this project. The Chinese website of jx would be helpful to those people.\n\nOn November 3rd, 2018 the Jenkins User Conference China(JUCC) was hosted in Shenzhen. More than 200 attendees gathered at JUCC to share and discuss Jenkins, DevOps, Continuous Delivery, Pipeline, and Agile.\n\nThere was a Jenkins workshop to teach users to develop a plugin in October. It was during the Hacktoberfest 2018. So some people got a beautiful T-shirt at this meetup. We’ll keep this event in 2019. I hope more users and developers could join us.\n\nThank you all folks. And other friendly contributors.\n\nChinese is our main communication language. A large number of the Jenkins users are not a proficient English speaker.\nSo letting most of Chinese Jenkins users could easily use Jenkins as their CI/CD platform is the final mission of Chinese Localization SIG.\nYou can find three participants on the page. But that’s not the full list.\nMore exciting thing is that Alauda giving a big support which as a startup company.\n\nWeChat is the greatest social media channel in China. WeChat has one billion users.\nAlmost everyone in China has a WeChat account. It must be a perfect place to publish articles and events.\nThere are over 1k people subscribed the Jenkins official WeChat Subscription Account in the last three months.\n\nIn the new year, I’m looking forward to growing up with you all!","title":"Jenkins new year in China","tags":["core","community","chinese"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#989898","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/19e71/linuxsuren.jpg","srcSet":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/77b35/linuxsuren.jpg 32w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/d4a57/linuxsuren.jpg 64w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/19e71/linuxsuren.jpg 128w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/68974/linuxsuren.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/ef6ff/linuxsuren.webp 32w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/8257c/linuxsuren.webp 64w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/6766a/linuxsuren.webp 128w,\n/gatsby-jenkins-io/static/e862ae9393b3993a9bb02d848cf1c9ab/22bfc/linuxsuren.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"LinuxSuRen","html":"<div class=\"paragraph\">\n<p>Rick is a big fan of Jenkins, also as a contributor leading the Jenkins China community.</p>\n</div>","id":"linuxsuren","irc":null,"linkedin":"linuxsuren","name":"赵晓杰(Rick)","slug":"/blog/authors/linuxsuren","twitter":"LinuxSuRen"}]}},{"node":{"date":"2019-02-01T00:00:00.000Z","id":"16256d3b-178f-556d-93f1-d366b7ff53cb","slug":"/blog/2019/02/01/windows-installers/","strippedHtml":"The Windows Installer for Jenkins has been around for many years as a way for users to install a Jenkins controller on Windows as a service.\nSince it’s initial development, it has not received a lot of updates or features, but that is about to change.\n\nFirst, let’s take a look at the current installer experience.\n\nStep 1\n\nThis is the default look and feel for a Windows Installer using the WiX Toolset, not very pretty and doesn’t give\nmuch branding information as to what the installer is for.\n\nStep 2\n\nAgain, not much branding information.\n\nStep 3\n\nThe installer in general does not give many options for installing Jenkins, other than selecting the installation location.\n\nIssues\n\nThe current installer has a few issues that the Platform SIG wanted to fix in a new install experience for users.\n\nThe installer only supports 32-bit installations.\n\nThe user could not select ports or user accounts to run the service on.\n\nThe installer bundled a 32-bit version of the Java runtime instead of using a pre-existing JRE\n\nThe installer did not support the experimental support in Jenkins for Java 11\n\nThe JENKINS_HOME directory was not placed in a good spot for modern Windows\n\nThere is no branding in the installer.\n\nRoad Forward\n\nWith the experimental Jenkins Windows Installer, most of these issues have been resolved!\n\nThe installer will only support 64-bit systems going forward. This is the vast majority of Windows systems these days,\nso this will help more users install Jenkins using the installer package.\n\nThe user is now able to enter user information for the service and select the port that Jenkins will use and verify that the port is available.\n\nThe installer no longer bundles a JRE, but will search for a compatible JRE on the system. If the user wants to use a different JRE, they can specify during install.\n\nThe installer has support for running with a Java 11 JRE, including the components listed on the Java 11 Preview Page.\n\nthe JENKINS_HOME directory is placed in the LocalAppData directory for the user that the service will run as, this aligns with modern Windows file system layouts.\n\nThe installer has been updated with branding to make it look nicer and provide a better user experience.\n\nScreenshots\n\nBelow are screenshots of the new installer sequence:\n\nStep 1\n\nThe Jenkins logo is now a prominent part of the UI for the installer.\n\nStep 2\n\nThe Jenkins logo and name are now in the header during all phases of the installer.\n\nStep 3\n\nThe installer now allows you to specify the username/password for the account to run as and checks that the account has LogonAsService rights.\n\nStep 4\n\nThe installer also allows you to specify the port that Jenkins should run on and will not continue until a valid port is entered and tested.\n\nStep 5\n\nInstead of bundling a JRE, the installer now searches for a compatible JRE on the system (JRE 8 is the current search). If you want to use a different\nJRE on the system than the one found by the installer, you can browse and specify it. Only JRE 8 and JRE 11 runtimes are supported. The installer will\nautomatically add the necessary arguments and additional jar files for running under Java 11 if the selected JRE is found to be version 11.\n\nStep 6\n\nAll of the items that users can enter in the installer should be overridable on the command line for automated deployment as well. The full list of properties that\ncan be overridden will be available soon.\n\nNext Steps\n\nThe new installer is under review by the members of the Platform SIG, but we need people to test the installer and give feedback. If you are interested in testing\nthe new installer, please join the Platform SIG gitter room for more information.\n\nThere are still some things that are being researched and implemented in the new installer (e.g., keeping port and other selections when doing an upgrade), but it is\ngetting close to release.\n\nIn addition to updates to the MSI based Windows installer, the Platform SIG is working on taking over the Chocolatey Jenkins package and\nreleasing a version for each update.","title":"Windows Installer Updates","tags":["windows","platform-sig","installers"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#988878","images":{"fallback":{"src":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/19e71/slide_o_mix.jpg","srcSet":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/77b35/slide_o_mix.jpg 32w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/d4a57/slide_o_mix.jpg 64w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/19e71/slide_o_mix.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/ef6ff/slide_o_mix.webp 32w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/8257c/slide_o_mix.webp 64w,\n/gatsby-jenkins-io/static/aad9316d8598468ffde48a1a515f07ed/6766a/slide_o_mix.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"slide","html":"<div class=\"paragraph\">\n<p>Alex comes from a .NET background but likes to get his hands dirty in many different languages and frameworks. He currently\ndoes embedded development in a silicon validation group. He is an internal evangelist for Jenkins at his company. Alex\nis a community contributor to Jenkins, working on plugin hosting and maintaining several plugins. He is also involved in\na few SIGS. Alex enjoys working on open source software in his \"free\" time as well as spending time with his family.</p>\n</div>","id":"slide_o_mix","irc":null,"linkedin":null,"name":"Alex Earl","slug":"/blog/authors/slide_o_mix","twitter":"alexcearl"}]}},{"node":{"date":"2019-01-21T00:00:00.000Z","id":"a737d1ad-0575-5b79-8f34-0dd038cbbc0f","slug":"/blog/2019/01/21/fosdem-2019/","strippedHtml":"FOSDEM 2019 (February 2 & 3) is a free event for software developers to meet, share ideas and collaborate.\nIt is an annual event that brings open source contributors from around the world for two days of presentations, discussions, and learning.\nWhile the Jenkins project won’t have a table at FOSDEM 2019, we will be well represented before, during, and after the event.\n\nFriday Day - Workshops and Jenkins Office Hours\n\nOn Friday, February 1, we’ll start off with a couple workshops:\n\nJenkins Pipeline Fundamentals\n(9:00 AM – 5:00 PM)\nLearn to create and run Declarative Pipelines!\nYou’ll learn the structure of Declarative Pipeline, how to control the flow of execution, how to save artifacts of the build, and get practice using some of the features that give fit and finish to your Pipeline.\nRegistration required - see the\nevent page\nfor details\n\nJenkins X, Kubernetes, and Friends\nTwo sessions: (9:00 AM – 12:00 PM) and (1:00pm to 4:00pm)\nBy combining the power of Jenkins, its community and the power of Kubernetes, the Jenkins X project provides a path to the future of continuous delivery for microservices and cloud-native applications.\nCome explore some of the features of Jenkins X through this hands-on workshop.\nRegistration required - see the\nevent page\nfor details\n\nAside from the workshops, from 9am to 5pm a bunch of people will be working out of Hilton Brussels Grand Place, hanging out as travelers come in.\nIt’ll be a casual, unstructured day. Sign up on this meetup page to be notified what meeting room we’re in.\n\nFriday Evening - Happy Hour\n\nAfter the office hours and workshops, we’ll have a happy hour Friday evening before FOSDEM at Cafe Le Roy d’Espagne.\nSee the meetup page for details.\n\nPresentations at FOSDEM\n\nHackers gotta eat: Building a Company Around an Open Source Project\nby Kohsuke Kawaguchi\n\nSetting up an HPC lab from scratch with Mr-Provisioner, Jenkins and Ansible\nby Renato Golin\n\nMulticloud CI/CD with OpenStack and Kubernetes by Maxime Guyot\n\nJenkins Hackfest after FOSDEM\n\nFinally, a Jenkins Hackfest will be held the day after FOSDEM 2019 on Monday (February 4).\nThose who would like to join us for the hackfest should register for the meetup.\n\nMeals, snacks, and beverages will be provided for the hackfest.  Come join us, and let’s write some code!\n\nQuestions? feel free to contact\nAlyssa Tong or\nBaptiste Mathus or join us on the\nadvocacy-and-outreach gitter channel.","title":"FOSDEM 2019!","tags":["community","events"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2019-01-09T00:00:00.000Z","id":"2bba9081-9075-5138-b4bd-6bcf248a769e","slug":"/blog/2019/01/09/jenkins-user-conference-china-shenzhen-update/","strippedHtml":"On November 3rd, 2018 the Jenkins User Conference China (JUCC) met Jenkins users in Shenzhen which is the most burgeoning city in China.\nIt was the first time to hold JUCC in Shenzhen.\nWe held JUCC along with DevOps International Summit, which is the biggest DevOps event in China.\nMore than 200 attendees gathered at JUCC Shenzhen to share and discuss Jenkins, DevOps, Continuous Delivery, Pipeline, and Agile.\n\nBelow, I am sharing pictures and some of the topics discussed at the event:\n\nYu Gu from Accenture presented New challenges for DevOps in Cloud Native.\n\nPeng Wang from Meituan which is the biggest group-buying website in China much like Groupon presented\nThe continuous delivery toolchains based on Jenkins for ten thousand times build per day.\n\nGuangming Zhou from Ctrip who is a Jenkins expert in China presented CD system in Ctrip.\n\nJiaqi Guo Jiaqi Guo from Kingston presented DevOps practices in large manufacturing industry.\n\nYaxing Li from Tencent presented How to support the CI CD requirements for thousands of products in Tencent based on Jenkins.\n\nMei Xiao from ZTE presented Fast integration practice for Android.\n\nJohn Willis presented Next Generation Infrastructure which included Kubernetes and  Istio practices.\n\nBC Shi from JD.com who is also a Jenkins Ambassador and the co-organizer of JUCC presented Pipeline 3.0  for DevOps toolchains.\nHe introduced the practices based on Jenkins and Jenkins X to build an end to end pipeline for DevOps from requirement to online service.\n\nWe’ve also released a DevOps tool map to recommend an excellent tool to the community.\n\nLastly, myself, Forest Jing co-organizer of JUCC and also am a Jenkins Ambassador interacted with the attendees.\n\nWe also organized the Jenkins workshop and Open space for the attendees.\nRuddy Li ,Yunhua Li , Yu Gu and Dingan Liang have worked together to run an open space to lead the attendees to discuss problems they met in DevOps and CD.\n\nHuaqiang Li who is a Certified Jenkins Engineer and CCJE has led the attendees to practice Jenkins functions for a whole afternoon.\n\nHere are more photos from our event, it was a fantastic JUCC in Shenzhen.\nThere were so much interest and appetite to learn about Jenkins and DevOps.\nWe are looking forward to doing this again next year.\n\nSlides from the event can be downloaded at PPT Download Address, password: sepe (the website is in Chinese).\n\nThank you to Alyssa and Maxwell’s help to organize this event.\nJenkins User Conference China continues and we hope to see many of you next year in China for our next JUCC.\nLet’s be Kung fu Jenkins!","title":"Jenkins User Conference China - Shenzhen Update","tags":["jenkins","jenkinsuserconference","chinese"],"authors":[{"avatar":null,"blog":null,"github":"ijyun","html":"","id":"ijyun","irc":null,"linkedin":null,"name":"Forest Jing（景韵）","slug":"/blog/authors/ijyun","twitter":null}]}},{"node":{"date":"2019-01-08T00:00:00.000Z","id":"058588ed-0d18-5d03-bd6b-e2e62be7093b","slug":"/blog/2019/01/08/mpl-modular-pipeline-library/","strippedHtml":"Despite speeding up development with deployment automation, one of our clients\nwas experiencing slow time-to-market due to a lack of collaboration in DevOps.\nWhile they had invested in DevOps, every production pipeline was set up\nindividually, forcing teams to remake the wheel for each project. Making matters\nworse, there was no cross-team collaboration, so any bug in the platform was\npresent in each new pipeline. Many of our clients have similar issues, so we\ndecided that we should develop a common tool which would both help current\nclients, and be adaptable for use in the future. While the most obvious option\nwas standardizing the CI/CD platform with a common framework, this led to a\nmonolithic structure, which was inflexible and ultimately unworkable. Since each\nteam needed to work on their own pipelines, we developed a solution that would\nstore each reusable part of the DevOps pipeline for later use: a Jenkins-powered\nmodular pipeline library.\n\nSolution: a modular pipeline library\n\nThe modular pipeline library ( MPL) we\ncreated is a highly-flexible shared library for a Jenkins Pipeline that enables\neasy sharing of best practices across the entire company. It has a clear modular\nstructure, an advanced testing framework, multi-level nesting, a pipeline\nconfiguration system, improved error handling, and many other useful components.\n\nWe will take a look under the hood and explain how our solution works in several\nparts:\n\nExplore the technologies and tools we used to build the MPL\n\nReview the MPL, and illustrate why it’s effective\n\nFollow a step-by-step guide to operate the MPL on a sample pipeline\n\nDive into some of the more important components of the solution, such as the test framework and nested libraries\n\nSo now let’s jump right into an explanation of the crucial features we used to\nbuild our solution.\n\nBuilding the MPL with shared libraries and Jenkins pipelines\n\nJenkins, our main automation platform, recently received some updates to\nJenkins Pipeline. These updates allow us to\ncreate one Jenkinsfile that\ndescribes the entire pipeline, and the steps that need to be executed with a\nseries of self-explanatory scripts. This increases the visibility of CI/CD\nautomation processes for end users, and improves supportability by DevOps teams.\n\nHowever, there’s a large issue with Pipeline: it’s hard to support multiple\nJenkinsfiles (and therefore multiple projects) with unique pipelines. We need to\nstore the common logic somewhere, which is where\nJenkins Shared Libraries\ncome in. They are included in the Jenkinsfile, and allow the use of prepared\ninterfaces to simplify automation and store common pieces.\n\nWhile shared libraries allow you to store logic and manipulate Jenkins, they\ndon’t provide a good way to utilize all the common information. Therefore, the\nMPL optimizes the pipeline and shared libraries by allowing users to create\neasy-to-follow descriptions for processes, which are then stored for later use\nby other teams.\n\nThe MPL works to create collaborative DevOps processes across teams\n\nWith the MPL, we are now able to collaborate and share our DevOps practices\nacross teams, easily adopt existing pipelines for specific projects, and debug\nand test features before we actually integrate them into the library. Each team\ncan create a nested library, add a number of pipelines and modules inside, and\nuse it with pipeline automation to create great visibility of the processes for\nthe end user. The MPL can also work on any project to prepare a Jenkinsfile, and\nmanage it as flexibly as the project team wants.\n\nAt its core, the MPL provides a simple way to:\n\nSeparate pipelines and steps by introducing modules\n\nDescribe steps in the modules with an easy configuration interface\n\nTest the described modules and share the results with other pipelines and projects\n\nThere are a lot of other features in the MPL, but it’s essentially a platform to\nsolve general DevOps collaboration issues. To simplify development and manual\ntesting, the MPL provides modules overriding and an inheritance model, allowing\nusers to test specific fixes in the project without affecting anything else. In\nJenkins, a module is a file with scripted steps and logic to reach a simple goal\n(build an artifact, run tests, create an image, etc.). These modules are\ncombined in the pipeline stages, and are easily readable for anyone who knows\nthe Jenkins Pipeline syntax.\n\nThe MPL allows users to use the core features of the library (structure,\nmodules, pipelines) and create nested libraries for specific DevOps team needs.\nA DevOps team can prepare complete pipelines with any custom logic and use it\nfor their projects. They can also override and inherit the core MPL modules in a\nnumber of ways, or prepare custom modules which are easy to share with other\nteams. Check out the infographic below to see how modules fit in:\n\nYou can also specify certain pipeline required poststeps in a module. For\nexample, a dynamic deployment module creates the test environment, which needs\nto be destroyed when the pipeline ends. To take a closer look at the MPL calling\nprocess, check out the infographic below:\n\nThis infographic shows how calls are executed in the MPL. First, you need a job\non your Jenkins, which will call a Jenkinsfile (for example, when the source\ncode is changed), after which the Jenkinsfile will call a pipeline. The pipeline\ncould be described on the MPL side, in the pipeline script in the job, in the\nnested library, or in the project Jenkinsfile. Finally, the stages of the\npipeline will call the modules, and these modules will use features, which could\nbe groovy logic, pipeline steps, or steps in the shared libraries.\n\nNow that we’ve done an overview of the solution, let’s take a look at a simple\npipeline execution to see how the MPL works in action.\n\nAn example of a pipeline execution in the MPL\n\nFor example, let’s say you have a common Java Maven project. You are creating a\nJenkinsfile in the repo, and want to use the default pipeline prepared by your\nDevOps team. The MPL already has a simple pipeline: the core MPLPipeline. It’s\na really simple pipeline, but it’s a good start for anyone who wants to try the\nMPL. Let’s look at a simple Jenkinsfile:\n\n@Library('mpl') _\nMPLPipeline {}\n\nThis Jenkinsfile contains a single line to load the MPL, and another line to run\nthe pipeline. Most of the shared libraries implement an interface like this,\ncalling one step and providing some parameters. MPLPipeline is merely a custom\nPipeline step, as it lies in the vars directory, and its structure is very\nsimple, following these steps:\n\nInitialize the MPL\nThe MPL uses the MPLManager singleton object to control the pipeline\n\nMerge configuration with default and store it\nA default configuration needed to specify stages and predefine some useful configs\n\nDefine a declarative pipeline with 4 stages and poststeps:\n\nCheckout - Getting the project sources\n\nBuild - Compiling, validation of static, unit tests\n\nDeploy - Uploading artifacts to the dynamic environment and running the app\n\nTest - Checking integration with other components\n\nPoststeps - Cleaning dynamic environment, sending notifications, etc.\n\nRunning the defined pipeline\nThis is where the MPL starts to work its magic and actually runs\n\nStages of the main MPL usually have just one step, the MPLModule .\nThis step contains the core functionality of the MPL: executing the modules\nwhich contain the pipeline logic. You can find default modules in the MPL\nrepository, which are placed in resources/com/griddynamics/devops/mpl/modules.\nSome of the folders include: Checkout, Build, Deploy, and Test, and in each of\nthem we can find Groovy files with the actual logic for the stages. This\ninfographic is a good example of a simplified MPL repository\nstructure:\n\nWhen the Checkout stage starts, MPLModule loads the module by name (by default\na stage name), and runs the Checkout/Checkout.groovy\nlogic:\n\nif( CFG.'git.url' )\n  MPLModule('Git Checkout', CFG)\nelse\n  MPLModule('Default Checkout', CFG)\n\nIf the configuration contains the git.url option, it will load a Git Checkout\nmodule; otherwise, it will run the Default Checkout module. All the called\nmodules use the same configuration as the parent module, which is why CFG was\npassed to the MPLModule call. In this case, we have no specific configuration,\nso it will run the\nCheckout/DefaultCheckout.groovy\nlogic. The space in the name is a separator to place the module into a specific\nfolder.\n\nIn the Default Checkout module, there is just one line with checkout scm\nexecution, which clones the repository specified in the Jenkins job. That’s all\nthe Checkout stage does, as the MPL functionality is excessive for such a small\nstage, and we only need to talk about it here to show how the MPL works in\nmodules.\n\nThe same process applies to the Build stage, as the pipeline runs the\nMaven Build\nmodule:\n\nwithEnv([\"PATH+MAVEN=${tool(CFG.'maven.tool_version' ?: 'Maven 3')}/bin\"]) {\n  def settings = CFG.'maven.settings_path' ? \"-s '${CFG.'maven.settings_path'}'\" : ''\n  sh \"\"\"mvn -B ${settings} -DargLine='-Xmx1024m -XX:MaxPermSize=1024m' clean install\"\"\"\n}\n\nThis stage is a little bit more complicated, but the action is simple: we take\nthe tool with the default name Maven 3, and use it to run mvn clean install.\nThe modules are scripted pipelines, so you can do the same steps usually\navailable in the Jenkins Pipeline. The files don’t need any specific and\ncomplicated syntax, just a plain file with steps and CFG as a predefined\nvariable with a stage configuration. The MPL modules inherited the sandbox from\nthe parent, so your scripts will be safe and survive the Jenkins restart, just\nlike a plain Jenkins pipeline.\n\nIn the Deploy folder, we find the sample structure of the Openshift Deploy\nmodule. Its main purpose here is to show how to use poststep definitions in the\nmodules:\n\nMPLPostStep('always') {\n  echo \"OpenShift Deploy Decommission poststep\"\n}\necho 'Executing Openshift Deploy process'\n\nFirst, we define the always poststep. It is stored in the MPLManager, and is\ncalled when poststeps are executed. We can call MPLPostStep with always as\nmany times as we want: all the poststeps will be stored and executed in FILO\norder. Therefore, we can store poststep logic for actions that need to be done,\nand then undone, in the same module, such as the decommission of the dynamic\nenvironment. This ensures that the actions will be executed when the pipeline\nis complete.\n\nAfter the deploy stage, the pipeline executes the Test stage, but nothing too\ninteresting happens there. However, there is an aspect of testing which is very\nimportant, and that’s the testing framework of the MPL itself.\n\nTesting of the MPL\n\nThe testing framework of the MPL is based on the\nJenkinsPipelineUnit\nfrom LesFurets, with the one small difference being its ability to test the MPL\nmodules. Testing the whole pipeline doesn’t work, as pipelines can be really\ncomplicated, and writing tests for such monsters is a Sisyphean task. It is much\neasier to test a black box with a small amount of steps, ensuring that this\nparticular task is working correctly.\n\nIn the MPL, you can find Build module testing examples: all the tests are\nstored in the\ntest/groovy/com/griddynamics/devops/mpl/modules\ndirectory, and you can find the\nBuild/BuildTest.groovy\nfile with a number of test cases there. Tests are executed during the MPL build\nprocess, allowing users to see traces like this:\n\nLoading shared library mpl with version snapshot\n  MPLModule.call(Build, {maven={tool_version=Maven 2}})\n    Build.run()\n      Build.MPLModule(Maven Build, {maven.tool_version=Maven 2})\n        MavenBuild.run()\n          MavenBuild.tool(Maven 2)\n          MavenBuild.withEnv([PATH+MAVEN=Maven 2_HOME/bin], groovy.lang.Closure)\n            MavenBuild.sh(mvn -B  -DargLine='-Xmx1024m -XX:MaxPermSize=1024m' clean install)\n      Build.fileExists(openshift)\n\nThe test runs the MPLModule with custom configuration and mocked steps to\ncheck that, during execution, the tool was changed to Maven 2 according to the\nprovided configuration. We cover all test cases with such tests, ensuring that\nthe modules are working as expected, and that the pipeline will work properly.\nYou can test the whole pipeline if you want, but testing by modules is just an\nadditional way to simplify the testing process.\n\nNow that we’ve looked at how to test the MPL modules, it’s time to look at one\nof the key features of the MPL, which is nested libraries.\n\nThe benefits of nested libraries\n\nWhen working with a large company, supporting one big library makes no sense.\nEach department requires multiple configuration options and tuning for a\nsomewhat standard pipeline, which creates extra work. The MPL solves such\nproblems by introducing nested libraries. This infographic displays how a nested\nlibrary compares to just using the main library:\n\nA nested library is the same as a shared library that imports the MPL and uses\nits functionality, modules, and pipelines. Also, it allows the separation of\nsome team-related logic from the company common logic. Here is the structure of\nthe MPL with nested libraries:\n\nYou can import the MPL in the overridden pipeline, specify the path of some\nadditional modules, override module logic, and use Jenkins power moves: there\nare no limitations. When another team needs your unique module, you can just\ncreate a change request to the basic company MPL repo, and share your functional\nmodule with the others.\n\nWith nested libraries, it’s possible to debug and modify MPL-provided steps\n( MPLModule for example) and pipelines. This is because nested libraries can\noverride low-level functionalities of the MPL or the Jenkins Pipeline. There are\nno limitations to what you can or can’t change, as these overrides only affect\nyour own pipeline. This enables experimentation to be done, and then discussed\nwith other teams to see if it will work in other nested libraries as well.\n\nThere are also no limits to the number of nesting levels created, but we\nrecommend using just two (MPL and nested), because additional levels make\nconfiguration and testing of the nested libraries on lower levels very\ncomplicated.\n\nThe power of module overriding\n\nFurther into the nested libraries or project-side modules, it’s possible to\nstore a module with the same name as one in the upper-level library. This is a\ngood way to override the logic - you can just replace Build/Build.groovy with\nyour own - as the functional module will be executed instead of the upper-level\nmodule. For example, this infographic shows module overriding:\n\nEven better, one of the strengths of the MPL is that you still can use the\nupper-level module! The MPL has mechanisms to prevent loops, so the same module\ncan’t be executed in the same executing branch again. However, you can easily\ncall the original module a name from another module to use the upper-level\nlogic.\n\nThe Petclinic-Selenium example above uses the default MPLPipeline (you can\nfind it on the MPL Wiki-page), and\ncontains project-side modules in a.jenkins directory. These modules will be\ncalled before the library modules. For example, the Checkout module is not\nplaced on the project side, so it will be called from the MPL, but the Build\nmodule exists in a.jenkins directory on the project side, and it will be\ncalled:\n\nMPLPostStep('always') {\n  junit 'target/surefire-reports/*.xml'\n}\n\nMPLModule('Build', CFG)\n\nif( fileExists('Dockerfile') ) {\n  MPLModule('Docker Build', CFG)\n}\n\nAs you can see, the Build module from the project registers the poststep,\ncalls the original Build module from the MPL, and then calls the additional\nDocker Build module. The following stages of the pipeline are more\ncomplicated, but all module overriding essentially works like this. Some\nprojects can be tricky, and need some small tunings for the existing modules.\nHowever, you can easily implement those changes on the project level, and think\nabout how to move the functionality to the nested library or MPL later.\n\nConclusion: what the MPL brings to DevOps\n\nMany DevOps teams and companies work with bloated, restrictive, and buggy CI/CD\nautomation platforms. These increase the learning curve for users, cause teams\nto work slower, and raise production costs. DevOps teams frequently run into\nsimilar issues on different projects, but a lack of collaboration means that\nthey have to be individually fixed each time.\n\nHowever, with the MPL, DevOps teams have a shared, simple, and flexible CI/CD\nplatform to improve user support, collaboration, and overall project source code\nto the production process. By utilizing the MPL, your company can find an\nautomation consensus, reach cross-company collaboration goals, and reuse the\nbest practices from a large community, all with open source tools. If you’re\ninterested in building an MPL, please contact us to learn more!\n\nAdditional resources\n\nJenkins Pipeline Engine\n\nJenkins Shared Libraries\n\nMPL GitHub repository\n\nOverview & demo videos:\n\nIntroduction\n\nOverview\n\nDemo of the MPL Build\n\nDemo of the Nested Library\n\nDemo of the Petclinic Pipeline","title":"MPL - Modular Pipeline Library","tags":["jenkinsfile","pipeline","sharedlibrary"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#d8d8d8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/bf8e1/sparshev.png","srcSet":"/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/914ee/sparshev.png 32w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/1c9ce/sparshev.png 64w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/bf8e1/sparshev.png 128w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/acb7c/sparshev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/ef6ff/sparshev.webp 32w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/8257c/sparshev.webp 64w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/6766a/sparshev.webp 128w,\n/gatsby-jenkins-io/static/47da77b67c60ffe2efee543d5593025e/22bfc/sparshev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"https://www.state-of-the-art.io/","github":"sparshev","html":"<div class=\"paragraph\">\n<p>Sergei is a DevOps engineer and using Jenkins as a main automation tool since 2011.\nWants to automate everything to make sure that there no more room for boring tasks.</p>\n</div>","id":"sparshev","irc":null,"linkedin":null,"name":"Sergei Parshev","slug":"/blog/authors/sparshev","twitter":null}]}},{"node":{"date":"2019-01-07T00:00:00.000Z","id":"4187a71c-adb8-54ce-90c9-c412101f2f56","slug":"/blog/2019/01/07/webhook-firewalls/","strippedHtml":"In this post I wanted to show how you can run Jenkins behind a firewall (which could be a corporate firewall, a NAT’ed network like you have at home) but still receive webhooks in real time from GitHub.com. You can generalise this to other services too - such as BitBucket or DockerHub, or anything really that emits webhooks, but the instructions will be for GitHub projects hosted on github.com.\n\nWhat are webhooks\n\nJust a very quick refresher on what webhooks are: Messages (often JSON, but not always) typically posted by HTTP(S) from a server to a client that is listening for events.\n\nThe events flow left to right, Jenkins sits there happily listing on paths like /github-webhook/ or /dockerhub-webhook/ etc for some HTTP request to tell it to wake up and do some work.\n\nGitHub/BitBucket may be reporting a new commit or PR, or DockerHub reporting an upstream image has changed. What all these things have in common is that they push to Jenkins, and expect to be able to push to it (ie that Jenkins is visible to them). This works great when the network is open - say GitHub Enterprise, or Jenkins is listening on the web.\n\nNot on the web\n\nThe trick is when something gets in the middle, say a firewall:\n\n( As is industry standard, all firewalls have to be a wall on fire. Please don’t somehow set bricks on fire in your organisation)\n\nThis is just the same when you fire up Jenkins on your laptop, and want to receive webhooks from github.com (a legitimate thing, perhaps to test out your setup, perhaps to run builds for iOS on a mac, or some corner of a network that is not exposed to the web). Unless your laptop is addressable to the whole web that is (not likely), or your network is configured just right, the webhooks won’t be able to flow.\n\nThis is fine - we can fall back to polling for changes. Except this is terrible. You burn through API quotas, and you don’t get changes in real time, and really no one is happy.\n\nSome problems are opportunities\n\nWe can both solve this problem, but also, view this is an opportunity. Having things not addressable on the web, or locked down in some default way is a feature, not a bug. You massively reduce your attack surface, and can have defence in depth:\n\nA Webhook forwarding service\n\nEnter the memorably named Smee. This is an OSS project provided by GitHub and also helpfully hosted as a service by GitHub. This can capture and forward webhooks for you. I’ll try to explain it with a diagram:\n\nGitHub pushes an event (via HTTPS/json in this case) to Smee.io (the funny thing with circles, which is on the public web and accessible from GitHub.com) - and Jenkins in turn subscribes to Smee with an outgoing connection from a client. Note the direction of the arrows: Jenkins only makes an outbound connection.\n\nThis is the important point: this will work as long as the firewall is one way (like a NAT typically is, and many networks). If the Jenkins side can’t connect to anything on the outside world - well, this won’t help with that of course (but that is not often the case).\n\nSetting it up\n\nStep 1: Firstly - go to https://smee.io/ and click “Start a new channel”:\n\nThis will give you a unique URL (which you should copy for later use):\n\nNext you should install the smee client next to where you have the Jenkins server running:\n\nnpm install --global smee-client\n\n(This will make the smee client/command available to receive and forward webhooks).\n\nNow start the smee client and point it to your Jenkins server. In this case I have it running on port 8080 (the default if you fire it up on your laptop, change both the port and the smee URL as needed):\n\nsmee --url https://smee.io/GSm1B40sRfBvSjYS --path /github-webhook/ --port 8080\n\nThis says to connect to the smee service, and forward webhooks to /github-webhook/ (that trailing slash is important, don’t miss it). Once this is running, you will see it log that it is connected and forwarding webhooks. Leave this command running for as long as you want to receive webhooks.\n\nNext, you need to configure a pipeline that makes use of github. In this case I set up one from scratch. You can skip this if you already have a pipeline setup:\n\nI then chose “GitHub” as the where the code is:\n\nThen choose your repository. This will set things up ready to receive webhooks from GitHub. (also if you have an existing pipeline setup, and it is using GitHub as the SCM source, that is also fine).\n\nThe final step is to tell GitHub to post webhook events for that repository (or organization, you can do that too) to Smee (which ultimately means Jenkins will receive them).\n\nGo to the settings tab for your GitHub repository, and then click “add webhook”:\n\nNext, configure the webhook:\n\nPaste in the “smee” URL you copied from the step above.\n\nChoose application/json as the content type\n\nTell it to send everything (you can pick and choose what events, but I just did that as simpler).\n\nPress Add Webhook (or update)\n\nIt should look something like this:\n\nOK - webhooks should be flowing now. You can make a change to your repository, and check that a build starts soon after:\n\nGood luck!","title":"Triggering builds with webhooks behind a secure firewall","tags":["jenkins","webhooks","security"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg","srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/77b35/michaelneale.jpg 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/d4a57/michaelneale.jpg 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/ef6ff/michaelneale.webp 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/8257c/michaelneale.webp 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/6766a/michaelneale.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/authors/michaelneale","twitter":"michaelneale"}]}}]}},"pageContext":{"limit":8,"skip":160,"numPages":100,"currentPage":21}},
    "staticQueryHashes": ["3649515864"]}