{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/41",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-02-24T00:00:00.000Z","id":"d8607b43-cae5-5e9a-9907-dc6c1b7dd752","slug":"/blog/2017/02/24/blueocean-devlog-feb4/","strippedHtml":"We’re counting down the weeks until Blue Ocean 1.0.\nIn all the excitement I forgot to post\na dev log last week, so I will make up for it this week.\n\nIn the last 10 days, 2 betas went out: b22 and b23, and a preview release of\nthe editor. We expect the next release will be named a release candidate (we\nknow there is still more to go in, but want to signal that things are getting\ninto the final stages!). The\nGitter chat room is\ngetting busier, so join in!\n\nAlso last week, the Blue Ocean Pipeline Editor was presented at the\nJenkins Online Meetup,\nembedded below.\n\nFeature Highlights\n\nYou can now create Pipelines from GitHub in Blue Ocean. Either one\nPipeline at a time, or let it discover all your Pipelines for a GitHub Organization.\n\nWhen you press the \"Create\" button, it will open the new creation flow\nby default now; the feature was previously hidden behind a feature switch.\n\nYou can filter the activity screen by branch! That way you can see a\nhistory of Pipeline runs for just one branch.\n\nIf you like long names for stages - it now won’t pollute the screen\nwhen space is at a premium (truncated names on screen).\n\nBlue Ocean events ( SSE) should now work on Microsoft Edge again\n\nYou can see durations when you hover the mouse over indicators\n\nUp next:\n\nA release candidate is expected soon\n\nIntegration work with the Editor to save to branches\n\nSome updates to the design around tables\n\nBundling of the Editor with Blue Ocean\n\nDon’t forget, there is also a Blue Ocean Docker image published weekly with\nusually the latest released version. If you have Docker installed, this can\nbe as simple as:\n\ndocker run -p 8080:8080 jenkinsci/blueocean*\n\nThen browse to localhost:8080/blue - possibly\nthe quickest way to try things.\n\nEnjoy!\n\nIf you’re interested in helping to make Blue Ocean a great user experience for\nJenkins, please join the Blue Ocean development team on\nGitter!","title":"Blue Ocean Dev Log: February Week #4","tags":["blueocean"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/author/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2017-02-23T00:00:00.000Z","id":"4617d4e9-51f3-58b1-8cf1-558aa14ce01d","slug":"/blog/2017/02/23/declarative-saucelabs-xunit/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the fourth post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe integrated several notification services into a Declarative Pipeline.\nWe kept our Pipeline clean and easy to understand\nby using a shared library to make a custom step called sendNotifications\nthat we called at the start and end of our Pipeline.\n\nIn this blog post, we’ll start by translating the Scripted Pipeline in the sample project I worked with\nin\n\" Browser-testing with Sauce OnDemand and Pipeline\"\nand\n\" xUnit and Pipeline\"\nto Declarative.\nWe’ll make our Pipeline clearer by adding an environment directive\nto define some environment variables, and then moving some code to a shared library.\nFinally, we’ll look at using the when directive to add simple conditional behavior to our Pipeline.\n\nSetup\n\nThe setup for this post uses the same repository as the two posts above,\nmy fork\nof the\nJS-Nightwatch.js sample project.\nI’ve once again created a branch specifically for this blog post,\nthis time called\nblog/declarative/sauce .\n\nLike the two posts above, this Pipeline will use the\nxUnit and\nSauce OnDemand plugins.\nThe xUnit plugin only needs to be installed, the Sauce OnDemand needs additional configuration.\nFollow\nSauce Labs' configuration instructions\nto create an account with Sauce Labs and add your Sauce Labs credentials to Jenkins.\nThe Sauce OnDemand plugin will automatically install\nSauce Connect\nfor us when we call it from our Pipeline.\n\nBe sure to you have the latest version of the\nSauce OnDemand plugin (1.160 or newer).\nIt has several fixes required for this post.\n\nFor a shared library, I’ve still got the one from the\nprevious post.\nTo set up this \"Global Pipeline Library,\" navigate to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", add a new library.\nThen set the name to bitwiseman-shared, point it at my repository,\nand set the default branch for the library to master.\n\nReducing Complexity with Declarative\n\nIf you’ve been following along through this series,\nthis first step will be quite familiar by now.\nWe’ll start from the Pipeline we had at the end of the xUnit post\nand translate it to Declarative.\n\n// Declarative //\npipeline {\n    agent any\n    options {\n        // Nightwatch.js supports color ouput, so wrap add his option\n        ansiColor colorMapName: 'XTerm'\n    }\n    stages {\n        stage (\"Build\") {\n            steps {\n                // Install dependencies\n                sh 'npm install'\n            }\n        }\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e chrome,firefox,ie,edge --test tests/guineaPig.js || true\"\n                    }\n                }\n            }\n            post {\n                always {\n                    step([$class: 'XUnitBuilder',\n                        thresholds: [\n                            [$class: 'SkippedThreshold', failureThreshold: '0'],\n                            // Allow for a significant number of failures\n                            // Keeping this threshold so that overwhelming failures are guaranteed\n                            //     to still fail the build\n                            [$class: 'FailedThreshold', failureThreshold: '10']],\n                        tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n                    saucePublisher()\n                }\n            }\n        }\n    }\n// Scripted //\nnode {\n    stage \"Build\"\n    checkout scm\n\n    // Install dependencies\n    sh 'npm install'\n\n    stage \"Test\"\n    // Add sauce credentials\n    sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n        // Start sauce connect\n        sauceconnect() {\n\n            // List of browser configs we'll be testing against.\n            def platform_configs = [\n                'chrome',\n                'firefox',\n                'ie',\n                'edge'\n            ].join(',')\n\n            // Nightwatch.js supports color ouput, so wrap this step for ansi color\n            wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm']) {\n                // Run selenium tests using Nightwatch.js\n                // Ignore error codes. The junit publisher will cover setting build status.\n                sh \"./node_modules/.bin/nightwatch -e ${platform_configs} --test tests/guineaPig.js || true\"\n            }\n\n            step([$class: 'XUnitBuilder',\n                thresholds: [\n                    [$class: 'SkippedThreshold', failureThreshold: '0'],\n                    // Allow for a significant number of failures\n                    // Keeping this threshold so that overwhelming failures are guaranteed\n                    //     to still fail the build\n                    [$class: 'FailedThreshold', failureThreshold: '10']],\n                tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n            saucePublisher()\n        }\n    }\n}\n\nBlue Ocean doesn’t support displaying SauceLabs test reports yet\n(see JENKINS-42242).\nTo view the report above, I had to switch back to the stage view of this run.\n\nElevating Settings using environment\n\nEach time we’ve moved a project from Scripted Pipeline to Declarative,\nwe’ve found the cleaner format of Declarative Pipeline highlights the less\nclear parts of the existing Pipeline.\nIn this case, the first thing that jumps out at me is that the parameters of the\nSaucelabs and Nightwatch execution are hardcoded and buried down in the middle of our Pipeline.\nThis is a relatively short Pipeline, so it isn’t terribly hard to find them,\nbut as this pipeline grows and changes it would be better if those values were kept separate.\nIn Scripted, we’d have defined some variables,\nbut Declarative doesn’t allow us to define variables in the usual Groovy sense.\n\nThe environment directive let’s us set some environment variables\nand use them later in our pipeline.\nAs you’d expect, the environment directive is just a set of name-value pairs.\nEnvironment variables are accessible in Pipeline via env.variableName (or just variableName)\nand in shell scripts as standard environment variables, typically $variableName.\n\nLet’s move the list of browsers, the test filter, and the sauce credential string to environment variables.\n\nJenkinsfile\n\nenvironment {\n        saucelabsCredentialId = 'f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a'\n        sauceTestFilter = 'tests/guineaPig.js'\n        platformConfigs = 'chrome,firefox,ie,edge'\n    }\n    stages {\n        /* ... unchanged ... */\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce(saucelabsCredentialId) {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e ${env.platformConfigs} --test ${env.sauceTestFilter} || true\" (1)\n}\n                }\n            }\n            post { /* ... unchanged ... */ }\n        }\n    }\n}\n\n1\nThis double-quoted string causes Groovy to replace the variables with their\nliteral values before passing to sh.\nThis could also be written using singe-quotes:\nsh './node_modules/.bin/nightwatch -e $platformConfigs --test $sauceTestFilter || true'.\nWith a single quoted string, the string is passed as written to the shell,\nand then the shell does the variable substitution.\n\nMoving Complex Code to Shared Libraries\n\nNow that we have settings separated from the code, we can do some code clean up.\nUnlike the previous post, we don’t have any repeating code,\nbut we do have some distractions.\nThe nesting of sauce, sauceconnect, and sh nightwatch seems excessive,\nand that xUnit step is a bit ugly as well.\nLet’s move those into our shared library as custom steps with parameters.\nWe’ll change the Jenkinsfile in our main project,\nand add the custom steps to a branch named\nblog/declarative/sauce in our library repository.\n\nJenkinsfile\n\n@Library('bitwiseman-shared@blog/declarative/sauce') _\n\n/* ... unchanged ... */\n\nstage (\"Test\") {\n    steps {\n        sauceNightwatch saucelabsCredentialId,\n            platformConfigs,\n            sauceTestFilter\n    }\n    post {\n        always {\n            xUnitPublishResults 'reports/**',\n                /* failWhenSkippedExceeds */ 0,\n                /* failWhenFailedExceeds */ 10\n\n            saucePublisher()\n        }\n    }\n}\n\nvars/sauceNightwatch.groovy\n\ndef call(String sauceCredential, String platforms = null, String testFilter = null) {\n    platforms = platforms ? \"-e '\" + platforms + \"'\" : ''\n    testFilter = testFilter ? \"--test '\" + testFilter + \"'\" : ''\n\n    // Add sauce credentials\n    sauce(sauceCredential) {\n        // Start sauce connect\n        sauceconnect() {\n            // Run selenium tests using Nightwatch.js\n            // Ignore error codes. The junit publisher will cover setting build status.\n            sh \"./node_modules/.bin/nightwatch ${platforms} ${testFilter} || true\" (1)\n}\n    }\n}\n\n1\nIn this form, this could not be written using a literal single-quoted string.\nHere, platforms and testFilter are groovy variables, not environment variables.\n\nvars/xUnitPublishResults.groovy\n\ndef call(String pattern, Integer failWhenSkippedExceeds,\n        Integer failWhenFailedExceeds) {\n    step([$class: 'XUnitBuilder',\n        thresholds: [\n            [$class: 'SkippedThreshold', failureThreshold: failWhenSkippedExceeds.toString()],\n            // Allow for a significant number of failures\n            // Keeping this threshold so that overwhelming failures are guaranteed\n            //     to still fail the build\n            [$class: 'FailedThreshold', failureThreshold: failWhenFailedExceeds.toString()]],\n        tools: [[$class: 'JUnitType', pattern: pattern]]])\n}\n\nRunning Conditional Stages using when\n\nThis is a sample web testing project.\nWe probably wouldn’t deploy it like we would production code,\nbut we might still want to deploy somewhere,\nby publishing it to an artifact repository, for example.\nThis project is hosted on GitHub and uses feature branches and pull requests to make changes.\nI’d like to use the same Pipeline for feature branches, pull requests, and the master branch,\nbut I only want to deploy from master.\n\nIn Scripted, we’d wrap a stage in an if-then and check if the branch for\nthe current run is named \"master\".\nDeclarative doesn’t support that kind of general conditional behavior.\nInstead, it provides a\nwhen directive\nthat can be added to stage sections.\nThe when directive supports several types of conditions, including a branch condition,\nwhere the stage will run when the branch name matches the specified pattern.\nThat is exactly what we need here.\n\nJenkinsfile\n\nstages {\n    /* ... unchanged ... */\n    stage ('Deploy') {\n        when {\n            branch 'master'\n        }\n        steps {\n             echo 'Placeholder for deploy steps.'\n        }\n    }\n}\n\nWhen we run our Pipeline with this new stage, we get the following outputs:\n\nLog output for 'feature/test' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\nStage 'Deploy' skipped due to when conditional\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nLog output for 'master' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\n[Pipeline] echo\nPlaceholder for deploy steps.\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nConclusion\n\nI have to say, our latest Declarative Pipeline turned out extremely well.\nI think someone coming from Freestyle jobs, with little to no experience with Pipeline or Groovy,\nwould still be able to look at this Declarative Pipeline and make sense of what it is doing.\nWe’ve added new functionality to our Pipeline while making it easier to understand\nand maintain.\n\nI hope you’ve learned as much as I have during this blog series.\nI’m excited to see that even in the the short time since Declarative 1.0 was released,\nteams are already using it in make improvements similar to what those we’ve covered in this series.\nThanks for reading!\n\nLinks\n\nxUnit\n\nSauce OnDemand\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Browser testing and conditional logic in Declarative Pipeline","tags":["pipeline","plugins","xunit","nightwatch","saucelabs","selenium","declarative"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/author/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-15T00:00:00.000Z","id":"76a4ff94-6194-5d56-a94c-3287ec832681","slug":"/blog/2017/02/15/declarative-notifications/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the third post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe converted a Scripted Pipeline to a Declarative Pipeline, adding descriptive stages\nand post sections.  In one of those post blocks, we included a placeholder for\nsending notifications.\n\nIn this blog post, we’ll repeat what I did in\n\" Sending Notifications in Pipeline\nbut this time in Declarative Pipeline.\nFirst we’ll integrate calls to notification services Slack, HipChat, and Email into our Pipeline.\nThen we’ll refactor those calls into a single Step in a Shared Library, which\nwe’ll reuse as needed, keeping our Jenkinsfile concise and understandable.\n\nSetup\n\nThe setup for this post is almost the same as\nmy previous Declarative Pipeline post.\nI’ve used a new branch in\nmy fork of the\nHermann project :\nblog/declarative/notifications .\nI’d already set up a Multibranch Pipeline and pointed it at my repository,\nso the new branch will be picked up and built automatically.\n\nI still have my notification targets (where we’ll send notifications) that I created for the\n\" Sending Notifications in Pipeline\" blog post.\nTake a look at that post to review how I setup the\nSlack,\nHipChat,\nand Email-ext\nplugins to use those channels.\n\nAdding Notifications\n\nWe’ll start from the same Pipeline we had at the end of the previous post.\n\nThis Pipeline works quite well, except it doesn’t print anything at the start of\nthe run, and that final always directive only prints a message to the console log.\nLet’s start by getting the notifications working like we did in the original post.\nWe’ll just copy-and-paste the three notification steps (with different parameters)\nto get the notifications working for started, success, and failure.\n\npipeline {\n  /* ... unchanged ... */\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        slackSend (color: '#FFFF00', message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n        // send to HipChat\n        hipchatSend (color: 'YELLOW', notify: true,\n            message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n          )\n\n        // send to email\n        emailext (\n            subject: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n            body: \"\"\" STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n            recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n          )\n      }\n    }\n    /* ... unchanged ... */\n  }\n  post {\n    success {\n      slackSend (color: '#00FF00', message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'GREEN', notify: true,\n          message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n\n    failure {\n      slackSend (color: '#FF0000', message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'RED', notify: true,\n          message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n  }\n}\n\nMoving Notifications to Shared Library\n\nThis new Pipeline works and our Declarative Pipeline sends notifications; however,\nit is extremely ugly. In the original post using Scripted Pipeline,\nI defined a single method that I called at both the start and end of the pipeline.\nI’d like to do that here as well, but Declarative doesn’t support creating methods\nthat are accessible to multiple stages.\nFor this, we’ll need to turn to\nShared Libraries.\n\nShared Libraries, as the name suggests,\nlet Jenkins Pipelines share code instead of copying it to each new project.\nShared Libraries are not specific to Declarative; they were released in their\ncurrent form several months ago and were useful in Scripted Pipeline.\nDue to Declarative Pipeline’s lack of support for defining methods,\nShared Libraries take on a vital role.  They are the only supported way within\nDeclarative Pipeline to define methods or classes that we want to use in more than one stage.\n\nThe lack of support for defining methods that are accessible in multiple stages,\nis a known issue, with at least two JIRA tickets:\nJENKINS-41335 and\nJENKINS-41396.\nFor this series, I chose to stick to using features that are fully supported\nin Declarative Pipeline at this time.\nThe internet has plenty of hacked together solutions that happen to work today,\nbut I wanted to highlight current best practices and dependable solutions.\n\nSetting up a Shared Library\n\nI’ve created a simple shared library repository for this series of posts, called\njenkins-pipeline-shared.\nThe shared library functionality has too many configuration options to cover in one post.\nI’ve chosen to configure this library as a \"Global Pipeline Library,\"\naccessible from any project on my Jenkins controller.\nTo setup a \"Global Pipeline Library,\" I navigated to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", I added a new library.\nI then set the name to bitwiseman-shared, pointed it at my repository,\nand set the default branch for the library to master,\nbut I’ll override that in my Jenkinsfile.\n\nMoving the Code to the Library\n\nAdding a Step to a library involves creating a file with the name of our Step,\nadding our code to a call() method inside that file,\nand replacing the appropriate code in our Jenkinsfile with the new Step calls.\nLibraries can be set to load \"implicitly,\"\nmaking their default branch automatically available to all Pipelines,\nor they can be loaded manually using a @Library annotation.\nThe branch for implicitly loaded libraries can also be overridden using the @Library annotation.\n\nThe minimal set of dependencies for sendNotifications means we can\nbasically copy-and-paste the code from the original blog post.\nWe’ll check this change into a branch in the library named\nblog/declarative/notifications, the same as my branch in the hermann repository.\nThis will let us make changes on the master branch later without breaking this example.\nWe’ll then use the @Library directive to tell Jenkins to use that branch’s version\nof the library with this Pipeline.\n\nJenkinsfile\n\n// Declarative //\n#!groovy\n@Library('bitwiseman-shared@blog/declarative/notifications') _ (1)\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        sendNotifications 'STARTED'\n      }\n    }\n    stage ('Install') {\n      steps {\n        // install required bundles\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      sendNotifications currentBuild.result\n    }\n  }\n}\n// Scripted //\n\n1\nThe _ here is intentional.\nJava/Groovy Annotations\nsuch as @Library must be applied to an element.\nThat is often a using statement, but that isn’t needed here so by convention we use an \\_.\n\nvars/sendNotifications.groovy\n\n#!/usr/bin/env groovy\n\n/**\n * Send notifications based on build status string\n */\ndef call(String buildStatus = 'STARTED') {\n  // build status of null means successful\n  buildStatus = buildStatus ?: 'SUCCESS'\n\n  // Default values\n  def colorName = 'RED'\n  def colorCode = '#FF0000'\n  def subject = \"${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\"\n  def summary = \"${subject} (${env.BUILD_URL})\"\n  def details = \"\"\" ${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\"\n\n  // Override default values based on build status\n  if (buildStatus == 'STARTED') {\n    color = 'YELLOW'\n    colorCode = '#FFFF00'\n  } else if (buildStatus == 'SUCCESS') {\n    color = 'GREEN'\n    colorCode = '#00FF00'\n  } else {\n    color = 'RED'\n    colorCode = '#FF0000'\n  }\n\n  // Send notifications\n  slackSend (color: colorCode, message: summary)\n\n  hipchatSend (color: color, notify: true, message: summary)\n\n  emailext (\n      to: 'bitwiseman@bitwiseman.com',\n      subject: subject,\n      body: details,\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nConclusion\n\nIn this post we added notifications to our Declarative Pipeline.\nWe wanted to move our repetitive notification code into a method;\nhowever, Declarative Pipeline prevented us from defining a method in our Jenkinsfile.\nInstead, with the help of the Shared Library feature,\nwe were able to define a sendNotifications Step that we could call from our Jenkinsfile.\nThis maintained the clarity of our Pipeline and will let us easily reuse this Step in other projects.\nI was pleased to see how little the resulting Pipeline differed from where we started.\nThe changes were restricted to the start and end of the file with no reformatting elsewhere.\n\nIn the next post, we’ll cover more about shared libraries and how to\nrun Sauce OnDemand with xUnit Reporting in Declarative Pipeline.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nShared Library reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Declarative Pipeline: Notifications and Shared Libraries","tags":["tutorial","pipeline","declarative","plugins","notifications","slack","hipchat","emailext"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/author/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-15T00:00:00.000Z","id":"65c5d55a-edbc-5f25-8301-7393341de88e","slug":"/blog/2017/02/15/pipeline-editor-preview/","strippedHtml":"Back in September 2016 we announced the availability of the Blue Ocean beta\nand the forthcoming Visual Pipeline Editor. We are happy to announce that you can try\nthe Pipeline Editor preview release today.\n\nWhat is it?\n\nThe Visual Pipeline Editor is the simplest way for anyone wanting to get started with\ncreating Pipelines in Jenkins. It’s also a great way for advanced Jenkins users\nto start adopting pipeline. It allows developers to break up their pipeline into different\n stages and parallelize tasks that can occur at the same time - graphically.\n The rest is up to you.\n\nA pipeline you create visually will produce a Declarative Pipeline Jenkinsfile for you and\n the Jenkinsfile is stored within a Git repository where it is versioned with your application code.\n\nIf you are not sure what a Jenkins Pipeline or a Jenkinsfile is, why not check out the new guided tour to learn more about it?\n\nWhat are we doing next?\n\nWe are working hard to provide feature parity between the Declarative Pipeline syntax and the visual editor. The next phase is to integrate the editor into Blue Ocean so that you don’t have to leave the UI and commit the Jenkinsfile to your repository to complete authoring your pipeline.\n\nIn Blue Ocean, you will be able to edit a Jenkinsfile\nfor a branch directly from within the user interface using the Visual Pipeline Editor. When you are done authoring your pipeline, the pipeline definition will be saved back to your repository as a Jenkinsfile. You can edit the Pipeline again using the Visual Editor or from your favorite text editor.\n\nWe are hoping to deliver this level of integration into Blue Ocean and the\nVisual Pipeline Editor over the next few months, so be sure to check regularly for updates in\nthe Jenkins plugin manager.\n\nGet the Preview\n\nThe Visual Pipeline Editor is available in preview today.\n\nTo try it out today:\n\nInstall the Blue Ocean beta and Blue Ocean Pipeline Editor from the Jenkins plugin manager\n\nClick on the Open Blue Ocean button and then the Pipeline Editor in the main navigation\n\nWe are looking forward to your feedback to help make the Visual Pipeline Editor\nthe easiest way to get started with Jenkins Pipeline. To report bugs or to\nrequest features please follow the instructions on the project page.\n\nAnd don’t forget to join us on our Gitter community chat\n- drop by and say hello!","title":"Say Hello to the Blue Ocean Pipeline Editor","tags":["blueocean","editor","declarative","pipeline"],"authors":[{"avatar":null,"blog":null,"github":"i386","html":"","id":"i386","irc":null,"linkedin":null,"name":"James Dumay","slug":"/blog/author/i386","twitter":"i386"}]}},{"node":{"date":"2017-02-10T00:00:00.000Z","id":"1055263e-a6f2-5108-b391-a1511ae33556","slug":"/blog/2017/02/10/blueocean-devlog-feb2/","strippedHtml":"We’re counting down the weeks until\nBlue Ocean\n1.0, which is planned for the end of March. If you hadn’t picked up on the hint\nin my\nprevious post,\nmost of the Blue Ocean development team is in Australia, where it is currently\nthe middle of summer. As I write this it is about 1000 degrees outside.\nEmergency measures such as air-conditioning and beer have been deployed in\norder to continue Blue Ocean development.\n\nThis week featured a new beta with the\nSCM API\nchanges; many bug fixes, and some version bumps went out in beta 22. We also\ngot some fresh new designs coming soon, though not in time for beta 22.\n\nSome development highlights:\n\nBeta 22 went out featuring the new\nSCM API\nwith better use of GitHub API rate limits.\n\nA fix for publishing of\nServer Side Events\nthat made one CPU spin up to 100% was fixed (not good unless you want to heat up\nyour room)\n\nSome new refinements to the design merged to the master branch (see images below).\n\nBeta 22 featured the 1.0 version of\nDeclarative Pipeline\n\nAn\nAustralian translation\nwas added; really critical stuff, I know..\n\nThe Acceptance Test Harness (ATH) was stabilised a bit and it now covers\ncreating Pipelines from Git, which we talked about in\nlate January.\n\nThe Visual Pipeline Editor was released to the main Update Center\nas a preview release, ready to play with!\n\nSome small performance improvements\n\nI’m looking forward to those fancy new designs making their way into an\nupcoming release too.\n\nLovely! Hopefully you see more green than I do…​\n\nAnyways, up next for Blue Ocean:\n\nCreation of Pipelines from GitHub, including auto-discovery of new Pipelines.\n\nCloser to a \"release candidate\"\n\nWorking on filtering the activity view for \"per branch\" views\n\nBetter reporting of durations of stages, steps, and runs\n\nEnjoy!\n\nIf you’re interested in helping to make Blue Ocean a great user experience for\nJenkins, please join the Blue Ocean development team on\nGitter!","title":"Blue Ocean Dev Log: February Week #2","tags":["blueocean"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/author/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2017-02-10T00:00:00.000Z","id":"06a04f0b-7823-5a11-8c3a-d385a336b68c","slug":"/blog/2017/02/10/declarative-html-publisher/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the second post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious blog post,\nwe created a simple Declarative Pipeline.\nIn this blog post, we’ll go back and look at the Scripted Pipeline for the\nPublishing HTML Reports in Pipeline blog post.\nWe’ll convert that Pipeline to Declarative syntax (including properties), go\ninto more detail on the post section, and then we’ll use the agent\ndirective to switch our Pipeline to run in Docker.\n\nSetup\n\nFor this post, I’m going to use the\nblog/add-declarative/html\nbranch of\nmy fork of the\nhermann project.\nI’ve set up a Multibranch Pipeline and pointed it at my repository\nthe same as did it previous post.\nAlso the same as before, I’ve set this Pipeline’s Git configuration to\nautomatically \"Clean after checkout\".\n\nThis time we already have a Pipeline checked in.\nI’ll run it a few times to get a baseline.\n\nConverting to Declarative\n\nLet’s start by converting the Scripted Pipeline straight to Declarative.\n\n// Declarative //\npipeline {\n  agent any // <1> (2)\noptions {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10')) (3)\n}\n  stages {\n    stage ('Build') { (4)\nsteps {\n        // install required gems\n        sh 'bundle install'\n\n        // build and run tests with coverage\n        sh 'bundle exec rake build spec'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\nproperties([[$class: 'BuildDiscarderProperty',\n                strategy: [$class: 'LogRotator', numToKeepStr: '10']]]) (3)\n\nnode { (1)\nstage ('Build') { (4)\n\n// Checkout\n    checkout scm (2)\n\n// install required gems\n    sh 'bundle install'\n\n    // build and run tests with coverage\n    sh 'bundle exec rake build spec'\n\n    // Archive the built artifacts\n    archive includes: 'pkg/*.gem'\n\n    // publish html\n    publishHTML [\n        allowMissing: false,\n        alwaysLinkToLastBuild: false,\n        keepAll: true,\n        reportDir: 'coverage',\n        reportFiles: 'index.html',\n        reportName: 'RCov Report'\n      ]\n\n  }\n}\n\n1\nSelect where to run this Pipeline, in this case \"any\" agent, regardless of label.\n\n2\nDeclarative automatically performs a checkout of source code on the agent,\nwhereas Scripted Pipeline users must explicitly call checkout scm.\n\n3\nSet the Pipeline option to preserve the ten most recent runs.\nThis overrides the default behavior from the Multibranch parent of this Pipeline.\n\n4\nRun the \"Build\" stage.\n\nNow that we have this Pipeline in Declarative form, let’s take a minute to do a\nlittle clean up.  We’ll split out the bundle actions a little more and move\nsteps into logically grouped stages.  Rather than having one monolithic \"Build\"\nstage, we’ll have details for each stage.  As long as we’re prettying things\nup, let’s switch to using Blue Ocean to view our\nbuilds, as well.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\n\nUsing post sections\n\nThis looks pretty good, but if we think about it\nthe archive and publishHTML steps are really post-stage actions.\nThey should only occur when the rest of their stage succeeds.\nAs our Pipeline gets more complex we might need to add actions that always happen\neven if a stage or the Pipeline as a whole fail.\n\nIn Scripted Pipeline, we would use try-catch-finally,\nbut we cannot do that in Declarative.\nOne of the defining features of the Declarative Pipeline\nis that it does not allow script-based control structures\nsuch as for loops, if-then-else blocks, or try-catch-finally blocks.\nOf course, internally Step implementations can still contain whatever conditional logic they want,\nbut the Declarative Pipeline cannot.\n\nInstead of free-form conditional logic,\nDeclarative Pipeline provides a set of Pipeline-specific controls:\nwhen directives, which we’ll look at in\na later blog post in this series, control whether to execute the steps in a stage,\nand\npost sections\ncontrol which actions to take based on result of a single stage\nor a whole Pipeline. post supports a number of\nrun conditions,\nincluding always (execute no matter what) and changed\n(execute when the result differs from previous run).\nWe’ll use success to run archive and publishHTML when their respective stages complete.\nWe’ll also use an always block with a placeholder for sending notifications,\nwhich I’ll implement in the next blog post.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      echo \"Send notifications for result: ${currentBuild.result}\"\n    }\n  }\n}\n// Scripted //\n\nSwitching agent to run in Docker\n\nagent can actually accept\nseveral other parameters instead of any.\nWe could filter on label \"some-label\", for example,\nwhich would be the equivalent of node ('some-label') in Scripted Pipeline.\nHowever, agent also lets us just as easily switch to using a Docker container,\nwhich replaces a more complicated set of changes in Scripted Pipeline:\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  /* ... unchanged ... */\n}\n\nIf I needed to, I could add a label filter under docker\nto select a node to host the Docker container.\nI already have Docker available on all my agents, so I don’t need label -\nthis works as is.\nAs you can see below, the Docker container spins up at the start of the run\nand the pipeline runs inside it.  Simple!\n\nConclusion\n\nAt first glance, the Declarative Pipeline’s removal of control structures seems\nlike it would be too constrictive.  However, it replaces those structures with\nfacilities like the post section, that give us reasonable control over the\nflow our our Pipeline while still improving readability and maintainability.\nIn the next blog post, we’ll add notifications to this pipeline\nand look at how to use Shared Libraries with Declarative\nPipeline to share code and keep Pipelines easy to understand.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post","title":"Declarative Pipeline: Publishing HTML Reports","tags":["tutorial","pipeline","declarative","plugins","ruby"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/author/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-08T00:00:00.000Z","id":"fe83f4ec-fd69-5daf-b26d-80c88853da21","slug":"/blog/2017/02/08/jenkins-datadog-plugin/","strippedHtml":"This is a guest post by Emily Chang, Technical Author at Datadog. A modified version of this article was originally posted on the\nDatadog blog.\n\nIf you’re using Jenkins to continuously integrate changes into your projects, it’s helpful to be able to quickly identify build failures and assess their impact on other components of your stack.\n\nDatadog’s plugin helps users monitor and alert on the performance of their Jenkins builds, right alongside the rest of their infrastructure and applications.\n\nAs shown in the out-of-the-box dashboard below, the Datadog plugin provides a bird’s-eye view of job history and trends. You can use Datadog to:\n\nSet alerts for important build failures\n\nIdentify trends in build durations\n\nCorrelate Jenkins events with performance metrics from other parts of your infrastructure in order to identify and resolve issues\n\nTrack Jenkins build status in real-time\n\nOnce you install the Datadog plugin, Jenkins activities (when a build starts, fails, or succeeds) will start appearing in your Datadog event stream. You will also see what percentage of builds failed within the same job, so that you can quickly spot which jobs are experiencing a higher rate of failure than others.\n\nRemember to blacklist any jobs you don’t want to track by indicating them in your plugin configuration.\n\nDatadog’s out-of-the-box Jenkins dashboard includes a status widget that displays the count of all jobs that have run in the past day, grouped by success or failure. To explore further, you can also click on the widget to view the individual jobs that have failed or succeeded in the past day.\n\nThe dashboard also displays the proportion of successful vs. failed builds, along with the total number of job runs completed over the past four hours.\n\nDatadog enables you to correlate Jenkins events with application performance metrics to investigate the root cause of an issue. For example, the screenshot below shows that average CPU on the app servers increased sharply after a Jenkins build was completed and deployed (indicated by the pink bar). Your team can use this information as a starting point to investigate if code changes in the corresponding release may be causing issues.\n\nVisualize job duration metrics\n\nEvery time a build is completed, the plugin collects the build duration as a metric that you can aggregate by job name or any other tag, and graph over time. In the screenshot below, we can view the average job durations in the past four hours, sorted in decreasing order:\n\nYou can also graph and visualize trends in build durations for each job by using Datadog’s robust_trend() linear regression function, as shown in the screenshot below. This graph indicates which jobs' durations are trending longer over time, so that you can investigate if there appears to be a problem. If you’re experimenting with changes to your CI pipeline, consulting this graph can help you track the effects of those changes over time.\n\nUse tags to monitor your Jenkins jobs\n\nTags add custom dimensions to your monitoring, so you can focus on what’s important to you right now.\n\nEvery Jenkins event, metric, and service check is auto-tagged with job, result, and branch (if applicable). You can also enable the optional node tag in the plugin settings.\n\nAs of version 0.5.0, the plugin supports custom tags. This update was developed by one of our open source contributors, Mads Nielsen. Many thanks to Mads for helping us implement this feature!\n\nYou can create custom tags for the name of the application you’re building, your particular team name (e.g. team=licorice), or any other info that matters to you. For example, if you have multiple jobs that perform nightly builds, you might want to create a descriptive tag that distinguishes them from other types of jobs.\n\nAs shown in the configuration settings above, you can add custom tags, formatted as key=value, in two ways:\n\nin a text file (saved in the workspace for the job)\n\nin a list of properties in the text box\n\nSet up the Datadog plugin\n\nThe Datadog plugin requires Jenkins 1.580.1 or newer.\n\nIn Jenkins, navigate to Manage Jenkins > Manage Plugins.\n\nSearch for Datadog Plugin and check the box to install it.\n\nIn Jenkins, go to Manage Jenkins > Configure System.\n\nScroll down to the Datadog Plugin section, and paste your API key in the text box. You can copy this from the API Keys page of your Datadog account. Click Test Key to confirm that the plugin recognizes your API key.\n\nSave your changes, and you’re all set!\n\nGet started\n\nIf you’re already using Datadog, you can start monitoring Jenkins jobs by following the instructions here to download the Datadog plugin. If you’re not using Datadog yet, here’s a 14-day free trial.","title":"Monitor Jenkins jobs with the Datadog plugin","tags":["plugins","monitoring"],"authors":[{"avatar":null,"blog":null,"github":"echang26","html":"","id":"echang26","irc":null,"linkedin":null,"name":"Emily Chang","slug":"/blog/author/echang26","twitter":null}]}},{"node":{"date":"2017-02-07T00:00:00.000Z","id":"df12ba62-13a1-5a1b-88f3-afc58f167e79","slug":"/blog/2017/02/07/declarative-maven-project/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is first in a series of blog posts that will show some of the cool features of\nDeclarative Pipeline.\nFor several of these posts, I’ll be revisiting some of my\nprevious posts\non using various plugins with (Scripted) Pipeline,\nand seeing how those are implemented in Declarative Pipeline.\n\nTo start though, let’s get familiar with the basic structure of a Declarative Pipeline\nby creating a simple Pipeline for a Maven-based Java project - the\nJenkins JUnit plugin.\nWe’ll create a minimal Declarative Pipeline,\nadd the settings needed to install Maven and the JDK,\nand finally we’ll actually run Maven to build the plugin.\n\nSet up\n\nWith Declarative, it is still possible to run Pipelines edited directly in the\nJenkins web UI, but one of the key features of \"Pipeline as Code\" is\nchecking-in and being able to track changes.  For this post, I’m going to use\nthe\nblog/add-declarative-pipeline\nbranch of\nmy fork of the JUnit plugin.\nI’m going to set up a Multi-branch Pipeline and point it at my repository.\n\nI’ve also set this Pipeline’s Git configuration to automatically \"clean after\ncheckout\" and to only keep the ten most recent runs.\n\nWriting a Minimal Pipeline\n\nAs has been said before, Declarative Pipeline provides a more structured,\n\"opinionated\" way to create Pipelines. I’m going to start by creating a minimal\nDeclarative Pipeline and adding it to my branch.  Below is a minimal Pipeline\n(with annotations) that just prints a message:\n\n// Declarative //\npipeline { (1)\nagent any // <2> (3)\nstages { (4)\nstage('Build') { (5)\nsteps { (6)\necho 'This is a minimal pipeline.' (7)\n}\n        }\n    }\n}\n// Scripted //\nnode { (2)\ncheckout scm (3)\nstage ('Build') { (5)\necho 'This is a minimal pipeline.' (6)\n}\n}\n\n1\nAll Declarative Pipelines start with a pipeline section.\n\n2\nSelect where to run this Pipeline, in this case \"any\" agent, regardless of label.\n\n3\nDeclarative automatically performs a checkout of source code on the agent,\nwhereas Scripted Pipeline users must explicitly call checkout scm,\n\n4\nA Declarative Pipeline is defined as a series of stages.\n\n5\nRun the \"Build\" stage.\n\n6\nEach stage in a Declarative Pipeline runs a series of steps.\n\n7\nRun the echo step to print a message in the Console Output.\n\nIf you are familiar with Scripted Pipeline, you can toggle the above\nDeclarative code sample to show the Scripted equivalent.\n\nOnce I add the Pipeline above to my Jenkinsfile and run \"Branch Indexing\", my\nJenkins will pick it up and run run it.  We see that the Declarative Pipeline\nhas added stage called \"Declarative: Checkout SCM\":\n\nThis a \"dynamic stage\", one of several the kinds that Declarative Pipeline adds\nas needed for clearer reporting.  In this case, it is a stage in which the\nDeclarative Pipeline automatically checkouts out source code on the agent.\n\nAs you can see above, we didn’t have to tell it do any of this,\n\nConsole Output\n\n[Pipeline] node\nRunning on osx_mbp in /Users/bitwiseman/jenkins/agents/osx_mbp/workspace/blog_add-declarative-pipeline\n[Pipeline] {\n[Pipeline] stage\n[Pipeline] { (Declarative: Checkout SCM)\n[Pipeline] checkout\nCloning the remote Git repository\n{ ... truncated 20 lines ... }\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Build)\n[Pipeline] echo\nThis is a minimal pipeline\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] End of Pipeline\nFinished: SUCCESS\n\nDeclarative Pipeline syntax is a little more verbose than the equivalent Scripted Pipeline,\nbut the added detail gives a clearer, more consistent view of what the Pipeline is supposed to do.\nIt also gives us a structure into which we can add more configuration details about this Pipeline.\n\nAdding Tools to Pipeline\n\nThe next thing we’ll add in this Pipeline is a tools section to let us use\nMaven.  The tools section is one of several sections we can add under\npipeline, which affect the configuration of the rest of the Pipeline.  (We’ll\nlook at the others, including agent, in later posts.) Each tool entry will\nmake whatever settings changes, such as updating PATH or other environment\nvariables, to make the named tool available in the current pipeline.  It will\nalso automatically install the named tool if that tool is configured to do so\nunder \"Managing Jenkins\" → \"Global Tool Configuration\".\n\n// Declarative //\npipeline {\n    agent any\n    tools { (1)\nmaven 'Maven 3.3.9' (2)\njdk 'jdk8' (3)\n}\n    stages {\n        stage ('Initialize') {\n            steps {\n                sh '''\n                    echo \"PATH = ${PATH}\"\n                    echo \"M2_HOME = ${M2_HOME}\"\n                ''' (4)\n}\n        }\n\n        stage ('Build') {\n            steps {\n                echo 'This is a minimal pipeline.'\n            }\n        }\n    }\n}\n// Scripted Not Defined //\n\n1\ntools section for adding tool settings.\n\n2\nConfigure this Pipeline to use the Maven version matching \"Maven 3.3.9\"\n(configured in \"Managing Jenkins\" → \"Global Tool Configuration\").\n\n3\nConfigure this Pipeline to use the Maven version matching \"jdk8\"\n(configured in \"Managing Jenkins\" → \"Global Tool Configuration\").\n\n4\nThese will show the values of PATH and M2_HOME environment variables.\n\nWhen we run this updated Pipeline the same way we ran the first, we see that\nthe Declarative Pipeline has added another stage called \"Declarative: Tool\nInstall\": In the console output, we see that during this particular stage \"Maven 3.3.9\" gets installed,\nand the PATH and M2_HOME environment variables are set:\n\nConsole Output\n\n{ ... truncated lines ... }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Declarative: Tool Install)\n[Pipeline] tool\nUnpacking https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/3.3.9/apache-maven-3.3.9-bin.zip\nto /Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9\non osx_mbp\n[Pipeline] envVarsForTool\n[Pipeline] tool\n[Pipeline] envVarsForTool\n[Pipeline] }\n[Pipeline] // stage\n{ ... }\nPATH = /Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/bin:/Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9/bin:...\nM2_HOME = /Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9\n{ ... }\n\nRunning a Maven Build\n\nFinally, running a Maven build is trivial.  The tools section already added\nMaven and JDK8 to the PATH, all we need to do is call mvn install.  It\nwould be nice if I could split the build and the tests into separate stages,\nbut Maven is famous for not liking when people do that, so I’ll leave it alone\nfor now.\n\nInstead, let’s load up the results of the build using the JUnit plugin,\nhowever the version that was just built, sorry.\n\n// Declarative //\npipeline {\n    agent any\n    tools {\n        maven 'Maven 3.3.9'\n        jdk 'jdk8'\n    }\n    stages {\n        stage ('Initialize') {\n            steps {\n                sh '''\n                    echo \"PATH = ${PATH}\"\n                    echo \"M2_HOME = ${M2_HOME}\"\n                '''\n            }\n        }\n\n        stage ('Build') {\n            steps {\n                sh 'mvn -Dmaven.test.failure.ignore=true install' (1)\n}\n            post {\n                success {\n                    junit 'target/surefire-reports/**/*.xml' (2)\n}\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    checkout scm\n\n    String jdktool = tool name: \"jdk8\", type: 'hudson.model.JDK'\n    def mvnHome = tool name: 'mvn'\n\n    /* Set JAVA_HOME, and special PATH variables. */\n    List javaEnv = [\n        \"PATH+MVN=${jdktool}/bin:${mvnHome}/bin\",\n        \"M2_HOME=${mvnHome}\",\n        \"JAVA_HOME=${jdktool}\"\n    ]\n\n    withEnv(javaEnv) {\n    stage ('Initialize') {\n        sh '''\n            echo \"PATH = ${PATH}\"\n            echo \"M2_HOME = ${M2_HOME}\"\n        '''\n    }\n    stage ('Build') {\n        try {\n            sh 'mvn -Dmaven.test.failure.ignore=true install'\n        } catch (e) {\n            currentBuild.result = 'FAILURE'\n        }\n    }\n    stage ('Post') {\n        if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {\n            junit 'target/surefire-reports/**/*.xml' (2)\n}\n    }\n}\n\n1\nCall mvn, the version configured by the tools section will be first on the path.\n\n2\nIf the maven build succeeded, archive the JUnit test reports for display in the Jenkins web UI.\nWe’ll discuss the\npost section in detail in the next blog post.\n\nIf you are familiar with Scripted Pipeline, you can toggle the above\nDeclarative code sample to show the Scripted equivalent.\n\nBelow is the console output for this last revision:\n\nConsole Output\n\n{ ... truncated lines ... }\n+ mvn install\n[INFO] Scanning for projects...\n[WARNING] The POM for org.jenkins-ci.tools:maven-hpi-plugin:jar:1.119 is missing, no dependency information available\n[WARNING] Failed to build parent project for org.jenkins-ci.plugins:junit:hpi:1.20-SNAPSHOT\n[INFO]\n[INFO] ------------------------------------------------------------------------\n[INFO] Building JUnit Plugin 1.20-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO]\n[INFO] --- maven-hpi-plugin:1.119:validate (default-validate) @ junit ---\n[INFO]\n[INFO] --- maven-enforcer-plugin:1.3.1:display-info (display-info) @ junit ---\n[INFO] Maven Version: 3.3.9\n[INFO] JDK Version: 1.8.0_92 normalized as: 1.8.0-92\n[INFO] OS Info: Arch: x86_64 Family: mac Name: mac os x Version: 10.12.3\n[INFO]\n{ ... }\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 03:25 min\n[INFO] Finished at: 2017-02-06T22:43:41-08:00\n[INFO] Final Memory: 84M/1265M\n[INFO] ------------------------------------------------------------------------\n\nConclusion\n\nThe new Declarative syntax is a significant step forward for Jenkins Pipeline.\nIt trades some verbosity and constraints for much greater clarity and\nmaintainability.  In the coming weeks, I’ll be adding new blog posts\ndemonstrating various features of the Declarative syntax along with some recent\nJenkins Pipeline improvements.\n\nLinks\n\nDeclarative Pipeline\n\nDeclarative Pipeline Syntax Reference\n\nJenkins JUnit plugin","title":"Declarative Pipeline for Maven Projects","tags":["tutorial","pipeline","declarative","maven","java"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/author/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"limit":8,"skip":320,"numPages":100,"currentPage":41}},
    "staticQueryHashes": ["3649515864"]}