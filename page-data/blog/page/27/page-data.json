{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/27",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-07-19T00:00:00.000Z","id":"e791a263-9144-5400-9cc7-12e369131b87","slug":"/blog/2018/07/19/jenkins-x-accelerate/","strippedHtml":"Jenkins X uses Capabilities identified by the \"Accelerate:  The Science Behind Devops\"\n\nJenkins X is a reimagined CI/CD implementation for the Cloud which is heavily influence by the\nState of DevOps reports and more recently the book\n\"Accelerate: The Science Behind Devops\" by\nNicole Forsgren,\nJez Humble and\nGene Kim\n\nYears of gathering data from real world teams and organisations which has been analyzed by inspiring thought leaders and data\nscientists from the DevOps world, \"Accelerate\" recommends a number of capabilities that Jenkins X is implementing so\nusers gain the scientifically proven benefits, out of the box. We’ve started documenting the capabilities that are available\ntoday and will continue as more become available.\n\nCredit: thanks to tracymiranda for the image\n\nUse version control for all artifacts\n\nThe Weaveworks folks coined the term GitOps which we love.  Any change to an environment, whether it be a new application,\nversion upgrade, resource limit change or simple application configuration should be raised as a Pull Request to Git, have\nchecks run against it like a form of CI for environments and approved by a team that has control over what goes into the\nrelated environment.  We can now enable governance and have full traceability for any change to an environment.\n\nRelated Accelerate capability:  Use version control for all production artifacts\n\nAutomate your deployment process\n\nEnvironments\n\nJenkins X will automatically create Git backed environments during installation and makes it easy to add new ones using\njx create environment.  Additionally when creating new applications via a quickstart ( jx create quickstart), Java based\nSpringBoot ( jx create spring) or importing existing applications ( jx import), Jenkins X will both automatically add\nCI / CD pipelines and setup the jobs, git repos and webhooks to enable an automated deployment process.\n\nOut of the box Jenkins X creates Staging and Production (this is customisable) permanent environments as well as temporary\nenvironments for preview applications from Pull Requests.\n\nPreviews Environments\n\nWe are trying to move as much testing, security, validation and experimentation for a change before it’s merged to master.\nWith the use of temporary dynamically created Preview Environments any pull request can have a preview version built and\ndeployed, including libraries that feed into a downstream deployable application.  This means we can code review, test,\ncollaborate better with all teams that are involved in agreeing that change can go live.\n\nUltimately Jenkins X wants to provide a way that developers, testers, designers and product managers can be as sure as they\ncan that when a change is merged to master it works as expected.  We want to be confident the proposed change does not\nnegatively affect any service or feature as well as deliver the value it is intended to.\n\nWhere Preview Environments get really interesting is when we are able to progress a PR through various stages of maturity and\nconfidence where we begin to direct a percentage of real production traffic like beta users to it.  We can then analyse the\nvalue of the proposed change and possible run multiple automated experiments over time using Hypothesis Driven Development.\nThis helps give us better understanding of how the change will perform when released to all users.\n\nRelated Accelerate capability: Foster and enable team experimentation\n\nUsing preview environments is a great way to introduce better test automation.  While Jenkins X enables this we don’t yet\nhave examples of automated tests being run against a preview environment.  A simple test would be to ensure the application\nstarts ok and Kubernetes liveness check pass for an amount of time. This relates to\n\nRelated Accelerate capability: Implement Test Automation\nRelated Accelerate capability: Automate your deployment process\n\nPermanent Environments\n\nIn software development we’re used to working with multiple environments in the lead up to a change being promoted to a live\nproduction environment.  Whilst this seems business as usual it can cause significant delays to other changes if for any\nreason that it is deemed not fit via some process that didn’t happen pre merge to master.  Subsequent commits then become\nblocked and can cause delay of urgent changes being promoted to production.\n\nAs above Jenkins X wants any changes and experiments to be validated before it is merged to master.  We would like changes in\na staging environment to be held there for a short amount of time before being promoted, ideally in an automated fashion.\n\nThe default Jenkins X pipelines provide deployment automation via environments.  These are customisable to suite your own\nCI / CD pipeline requirements.\n\nJenkins X recommends Staging should act as a near as possible reflection on production, ideally with real production data\nshadowed to it using a service mesh to understand the behaviour.  This also helps when developing changes in preview where we\ncan link to non production services in staging.\n\nRelated Accelerate capability: Automate your deployment process\n\nUse trunk-based development\n\nThe Accelerate book found that teams which use trunk based development with short lived branches performed better.  This has\nalways worked for the Jenkins X core team members so this was an easy capability for Jenkins X to implement when setting up\nGit repositories and CI/CD jobs.\n\nImplement Continuous Integration\n\nJenkins X sees CI as the effort of validating a proposed change via pull requests before it is merged to controller.  Jenkins X\nwill automatically configure source code repositories, Jenkins and Kubernetes to provide Continuous Integration of the box.\n\nImplement Continuous Delivery\n\nJenkins X sees CD as the effort of taking that change after it’s been merged to controller through to running in a live\nenvironment.  Jenkins X automates many parts in a release pipeline:\n\nJenkins X advocates the use of semantic versioning.  We use git tags to calculate the next release version which means we\ndon’t need to store the latest release version in the controller branch.  Where release systems do store the last or next version\nin Git repos it means CD becomes hard, as a commit in a release pipeline back to controller triggers a new release.  This results\nin a recursive release trigger.  Using a Git tag helps avoid this situation which Jenkins X completely automates.\n\nJenkins X will automatically create a released version on every merge to master which can then potentially progress\nthrough to production.\n\nUse loosely coupled architecture\n\nBy targeting Kubernetes users of Jenkins X can take advantage of many of the cloud features that help design and develop\nloosely coupled solutions.  Service discovery, fault tolerance, scalability, health checks, rolling upgrades, container\nscheduling and orchestration to name just a few examples of where Kubernetes helps.\n\nArchitect for empowered teams\n\nJenkins X aims to help polyglot application developers.  Right now Jenkins X has quickstarts and automated CI/CD setup with\nlanguage detection for Golang, Java, NodeJS, .Net, React, Angular, Rust, Swift and more to come.  What this also does is\nprovide a consistent Way of Working so developers can concentrate on developing.\n\nJenkins X also provides many addons, for example Grafana and Prometheus for automated metrics collection and visualisation.\nIn this example centralised metrics help understand how your applications behave when built and deployed on Kubernetes.\n\nDevPods are another feature which enables developers to edit source code in their\nlocal IDE, behind the scenes it is then synced to the cloud and rapidly built and redeployed.\n\nJenkins X believes providing developers automation that helps them experiment in the cloud, with different technologies and\nfeedback empowers them to make the best decisions - faster.\n\nFancy a closer look?\n\nMyself, James Strachan and\nRob Davies are going to be presenting and running workshops at\nDevOps World  | Jenkins World.  We’ll also be hanging out at the Jenkins X demo\narea so come and say hello and see what’s the latest cool and exiting things to come out of Jenkins X.  Use JWFOSS for 30%\ndiscount off registration\n\nWant to get involved?\n\nJenkins X is open source, the community mainly hangs out in the\nJenkins X Kubernetes slack channels and for tips on being more involved with Jenkins X\ntake a look at our contributing docs.  We’ve been helping lots of folks get into open source, learn\nnew technoligies and languages like golang.  Why not get involved?\n\nDemo\n\nIf you’ve not already seen it here’s a video showing a spring boot quickstart with automatic CI/CD pipelines and preview environments.","title":"Accelerate with Jenkins X","tags":["jenkinsx","developer","kubernetes"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-07-18T00:00:00.000Z","id":"4f74ad43-7236-5f3c-bf1f-5c49dd133357","slug":"/blog/2018/07/18/security-updates/","strippedHtml":"We just released security updates to Jenkins, versions 2.133 and 2.121.2, that fix multiple security vulnerabilities.\n\nFor an overview of what was fixed, see the security advisory.\nFor an overview on the possible impact of these changes on upgrading Jenkins LTS, see our LTS upgrade guide.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2018-07-17T00:00:00.000Z","id":"2629d18c-2a10-59b8-8b11-b24bb8b2b87d","slug":"/blog/2018/07/17/simple-pull-request-plugin/","strippedHtml":"About me\n\nI am Abhishek Gautam, 3rd year student from Visvesvaraya National Institute of\ntechnology, India, Nagpur. I was a member of ACM Chapter and Google student developer club of my\ncollege. I am passionate about automation.\n\nProject Summary\n\nThis is a GSoC 2018 project.\n\nThis project aims to develop a pull request Job Plugin. Users should be able to\nconfigure job type using YAML file placed in root directory of the\nGit repository being the subject of the pull request. The plugin should interact with various\nplatforms like Bitbucket, Github, Gitlab, etc whenever a pull request is created or updated.\n\nPlugin detects the presence of certain types of reports at conventional locations,\nand publish them automatically. If the reports are not present at their respective conventional\nlocation, the location of the report can be configured in the YAML file.\n\nMy mentors are\nOleg Nenashev (Org Admin),\nMartin d’Anjou,\nKristin Whetstone,\nJeff Knurek\n\nBenefits to the community\n\nProject administrators will be able to handle pull request builds more easily.\n\nBuild specifications for pull requests can be written in a concise declarative format.\n\nBuild reports will be automatically published to Github, Bitbucket, etc.\n\nBuild status updates will be sent to git servers automatically.\n\nUsers will not have to deal with pipeline code.\n\nIf there will be no merge conflicts or build failures, the PR can be merged into target branch.\n\nPhase 1 blog post\n\nPlease see Phase 1 blog post\n\nImplementations till now\n\nAlpha version of the plugin is released. It supports all features of Multi-Branch Pipeline and offers the following features.\n\nBuild description is defined via YAML file stored within the SCM repo. This plugin\nwill depend on GitHub plugin, Bitbucket plugin, Gitlab plugin if users will be\nusing respective platforms for their repositories.\n\nConversion of YAML to Declarative Pipeline: A class YamlToPipeline\nis written which will load the \"Jenkinsfile.yaml\" and make use of PipelineSnippetGenerator class\nto generate Declarative pipeline code.\n\nReporting of results, only xml report types is supported for now.\n\nUse of Yaml file (Jenkinsfile.yaml) from target branch.\n\nGit Push step: To push the changes of pull request to the target branch. This is implemented\nusing git-plugin, PushCommand is used for this from git-plugin. credentialId,\nbranch name and repository url for interacting with Github, Bitbucket, etc\nwill be taken automatically from \"Branch-Source\" (Users have to fill this\ndetails of branch source in job configuration UI). (You can see\nHow to run the demo)\n\nStepConfigurator: To generate pipeline code for all supported steps in Jenkins. This is using\nJenkins configuration-as-code plugin (JCasC plugin) to configure a particular step object and\nthen that step object is passed to Snippetizer.object2Groovy() method to generate the script of that step.\n\nJenkinsfile.yaml example\n\nFor the phase 1 prototype demonstration, the following yaml file was used.\nNote that this format is subject to change in the next phases of the project,\nas we formalise the yaml format definition.\n\n#  Docker image agent example\nagent:\n label: my_label\n customWorkspace: path_to_workspace\n dockerImage: maven:3-alpine\n args: -v /tmp:/tmp\n\n  tools:\n    maven : maven_3.0.1\n    jdk : jdk8\n\nconfiguration:\n  # Push PR changes to the target branch if the build succeeds.\n  # default value is false\n  pushPrOnSuccess: false\n\n  # Trusted user to approve pull requests\n  prApprovers:\n    - username1\n    - username2\n    - username3\n\nenvironment:\n  variables:\n    variable_1: value_1\n    variable_2: value_2\n\n  # Credentials contains only two fields. credentialId must be present in the Jenkins Credentials\n  credentials:\n    - credentialId : fileCredentialId\n      variable : FILE\n\n      # In user scripts Username and Password can be accessed by LOGIN_USR and LOGIN_PSW\n      # respectively as environment variales\n    - credentialId : dummyGitRepo\n      variable : LOGIN\n\nstages:\n  - name: stage1\n    agent: any\n    steps:\n      - sh: \"scripts/hello\"\n      - sleep:\n          time: 2\n          unit: SECONDS\n      - sleep: 2\n      - junit:\n          testResults: \"target/**.xml\"\n          allowEmptyResults: true\n          testDataPublishers:\n            - AutomateTestDataPublisher\n            - JunitResultPublisher:\n                urlOverride: \"urlOverride\"\n    # Post section for \"stage1\". All Conditions which are available in Jenkins\n    # declarative pipeline are supported\n    post:\n      failure:\n        - sh: \"scripts/hello\"\n\n# Outer post section. Just like declarative pipeline.\npost:\n  always:\n    - sh: \"scripts/hello\"\n\nCoding Phase 2 plans (Completed)\n\nDecide a proper YAML format to use for Jenkinsfile.yaml\n\nCreate Step Configurator for SPRP plugin. JENKINS-51637.\nThis will enable users to use Pipeline steps in Jenkinsfile.yaml.\n\nAutomatic indentation generation in the generated PipelineSnippetGenerator class.\n\nWrite tests for the plugin.\n\nCoding Phase 3 plans\n\nTest Multi-Branch Pipeline features support:\n\nSupport for webhooks ( JENKINS-51941)\n\nCheck if trusted people have approved a pull request and start build accordingly ( JENKINS-52517)\n\nFinalize documentation ( JENKINS-52518)\n\nRelease 1.0 ( JENKINS-52519)\n\nPlugin overview blog post\n\nCoding Phase 3 plans after release\n\nSupport the “when” Declarative Pipeline directive ( JENKINS-52520)\n\nNice2have: Support hierarchical report types ( JENKINS-52521)\n\nAdd unit tests, JenkinsRule tests, and ATH tests ( JENKINS-52495, JENKINS-52496)\n\nAutomatic Workspace Cleanup when PR is closed ( JENKINS-51897)\n\nRefactor snippet generator to extensions ( JENKINS-52491)\n\nPhase 3 Jira Epic\n\nPhase 2 evaluation presentation video\n\nVideo:\n\nPhase 2 evaluation presentation slides\n\nHow to reach me\n\nEmail: gautamabhishek46@gmail.com\n\nGitter room: https://gitter.im/Jenkinsci/simple-pull-request-job-plugin\n\nReferences\n\nProject repository\n\nProject page\n\nGitter chat\n\nBug Tracker\n\nDemo Repository\n\nPhase 2 Presentation video (July 12, 2018)\n\nPhase 2 Presentation Slides (July 12, 2018)","title":"Pipeline as YAML: Alpha release","tags":["gsoc2018","plugin","pipeline","yaml"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg","srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/77b35/abhishek_gautam.jpg 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/d4a57/abhishek_gautam.jpg 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/19e71/abhishek_gautam.jpg 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/68974/abhishek_gautam.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/ef6ff/abhishek_gautam.webp 32w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/8257c/abhishek_gautam.webp 64w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/6766a/abhishek_gautam.webp 128w,\n/gatsby-jenkins-io/static/e91e42ab16b3d1ec82ed0c692425a50e/22bfc/abhishek_gautam.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"gautamabhishek46","html":"<div class=\"paragraph\">\n<p>Abhishek is a 3rd year Computer Science student from Visvesvaraya National\nInstitute of Technology, Nagpur, India. He has done some website projects for\nhis college technical festival. He is also a regular competitive programmer\n(abhishekg1128 at codechef). He has done two internships as a Game Programmer\nas well. He was a member of ACM Chapter and Google student developer club of his\ncollege. His interest in automation motivated his participation in the Jenkins\nGSOC 2018 program.</p>\n</div>","id":"abhishek_gautam","irc":"abhishekg","linkedin":null,"name":"Abhishek Gautam","slug":"/blog/authors/abhishek_gautam","twitter":null}]}},{"node":{"date":"2018-07-13T00:00:00.000Z","id":"970120e2-6f31-5ddd-9fed-9bfcc306c79a","slug":"/blog/2018/07/13/jenkins-user-conference-china.adoc/","strippedHtml":"On June 30, 2018 in sunny Beijing, the capital of China, we welcomed over 200 attendees to Jenkins User Conference China (JUCC). This is the first JUCC in Beijing and we are overwhelmed by the interest and love for Jenkins. The conference had sessions in DevOps, Continuous Delivery, Jenkins X, Pipeline, and Container. The GreatOps community, event host, invited John Willis, a thought leader of DevOps to deliver the keynote speech. John’s topic was \"DevOps: Almost 10 years - What A  Strange Long Trip It’s Been.\" It was very insightful to learn of the history of DevOps and John’s point of view on the practice.\n\nLily Lin from Micro Focus presented, \"How to practice CI/CD for large-scale micro service based on Jenkins Pipeline.\"\n\nJames Rawlings, one of the core Jenkins X contributors traveled from the United Kingdom to present, \"Jenkins X for the future, Easy CI/CD for Kubernetes.\"\n\nAfter James’ presentation, there were many questions about Jenkins X, Jenkins users in China are very interested in Jenkins X. We all posed Jenkins \"X\" gesture.\n\nWe also invite Shuwei Hao from Alibaba, Michael Hüttermann who is the author of DevOps for Developers, Xiang Lu from CPI.\n\nMr Huaqiang Li and Xiaojie Zhao ran a workshop for help attendees master Jenkins Pipeline and Jenkins X in the cloud environment.\n\nHere are additional pictures from our event\n\nSpecial THANKS to BC who is the co-organizer of JUCC to host the main track and Alyssa and Maxwell for your help with our event.\n\nNext up, Jenkins User Conference China Shenzhen in November.\nLet’s Jenkins X and DevOps!","title":"Jenkins User Conference China Beijing Recap","tags":["event","juc"],"authors":[{"avatar":null,"blog":null,"github":null,"html":"<div class=\"paragraph\">\n<p>Forest runs\nthe <a href=\"https://www.meetup.com/Shanghai-Jenkins-Area-Meetup/\">Shanghai Jenkins Area Meetup</a> and <a href=\"https://www.bagevent.com/event/jenkins-user-conference\">Jenkins User Conference China</a>.</p>\n</div>","id":"fjing","irc":null,"linkedin":null,"name":"Forest Jing","slug":"/blog/authors/fjing","twitter":null}]}},{"node":{"date":"2018-07-10T00:00:00.000Z","id":"b0312033-b8b4-5dbc-b5a3-6c06dd49dcb5","slug":"/blog/2018/07/10/jenkins-essentials-on-aws/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nJenkins Essentials is about providing a distribution of Jenkins in less than five minutes and five clicks.\nOne of the main ideas to make this a reality is that Jenkins will be autoconfigured with sane defaults for the environment it is running in.\n\nWe are happy to report we recently merged the change that provides this feature for AWS.\nWe use an AWS CloudFormation template to provision a working version of Jenkins Essentials, automatically configured to:\n\ndynamically provision EC2 agents, using the EC2 plugin;\n\nuse the Artifact Manager on S3 plugin, so that artifacts are not stored anymore on the controller’s file system, but directly in an S3 bucket.\n\nI recorded a short demo video last week showing the basics of this:\n\nWhile there are still many items to complete to provide a usable version for end-users, we are making steady progress towards it.\n\nYou can learn more about Jenkins Essentials from the\nGitHub repository, or join us\non our\nGitter channel.","title":"Jenkins Essentials flavor for AWS","tags":["jenkinsevergreen","evergreen"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8e8d8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/f1e03/batmat.jpg","srcSet":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/ede19/batmat.jpg 32w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/bc20c/batmat.jpg 64w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/f1e03/batmat.jpg 128w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/b691b/batmat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/8ba60/batmat.webp 32w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/a9ea7/batmat.webp 64w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/51559/batmat.webp 128w,\n/gatsby-jenkins-io/static/05e25bcf6699abfce74f0630971e7c78/28f98/batmat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":130}}},"blog":"http://batmat.net","github":"batmat","html":"<div class=\"paragraph\">\n<p>Baptiste has been using and contributing to Jenkins since it was called differently, and is a huge proponent of the Agile, Devops &amp; Continuous Delivery movements.\nHe loves to discuss not only the technical aspects, but also the even more essential cultural aspects of this all, working together to improve the value provided to customers in a great inclusive and blameless environment.</p>\n</div>","id":"batmat","irc":null,"linkedin":null,"name":"Baptiste Mathus","slug":"/blog/authors/batmat","twitter":"bmathus"}]}},{"node":{"date":"2018-07-05T00:00:00.000Z","id":"b1c89781-ce73-5eec-8d31-bf7f51174f63","slug":"/blog/2018/07/05/remoting-over-message-bus-alpha-release/","strippedHtml":"I am happy to announce that we have recently released an alpha version of Remoting Kafka Plugin to the Experimental Update Center. You can check the CHANGELOG to see the features included in this initial release.\n\nOverview\n\nCurrent versions of Jenkins Remoting are based on the TCP protocol. If it fails, the agent connection and the build fails as well. There are also issues with traffic prioritization and multi-agent communications, which impact Jenkins stability and scalability.\n\nRemoting Kafka Plugin is a plugin developed under Jenkins Google Summer of Code 2018. The plugin is developed to add support of a popular message queue/bus technology (Kafka) as a fault-tolerant communication layer in Jenkins. A quick introduction of the project can be found in this introduction blogpost.\n\nHow to use the plugin?\n\nThe instructions to run the plugin in alpha version are written here. Feel free to have a try and let us know your feedback on Gitter or the mailing list.\n\nLinks\n\nAlpha Changelog\n\nIntroduction Blogpost\n\nGitHub Repository\n\nProject Page\n\nPhase 1 Presentation Video\n\nPhase 1 Presentation Slides","title":"GSoC Project Update: Alpha release of Remoting Kafka Plugin","tags":["plugins","gsoc","gsoc2018","remoting","alpha-release"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg","srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/77b35/pvtuan10.jpg 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/d4a57/pvtuan10.jpg 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/19e71/pvtuan10.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/ef6ff/pvtuan10.webp 32w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/8257c/pvtuan10.webp 64w,\n/gatsby-jenkins-io/static/227c1aaf83f4dc4f3b44ed51b9e39c2b/6766a/pvtuan10.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"pvtuan10","html":"<div class=\"paragraph\">\n<p>Pham Vu Tuan is a developer from Singapore.\nHe starts contributing to Jenkins from Google Summer of Code 2018 for <a href=\"https://jenkins.io/projects/gsoc/2018/remoting-over-message-bus/\">Jenkins Remoting over Message Bus/Queue</a></p>\n</div>","id":"pvtuan10","irc":"pvtuan10","linkedin":null,"name":"Pham Vu Tuan","slug":"/blog/authors/pvtuan10","twitter":null}]}},{"node":{"date":"2018-07-02T00:00:00.000Z","id":"0c991121-dfec-5b10-a945-33a402cf3ddd","slug":"/blog/2018/07/02/new-api-token-system/","strippedHtml":"About API tokens\n\nJenkins API tokens are an authentication mechanism that allows a tool (script, application, etc.) to impersonate a user\nwithout providing the actual password for use with the Jenkins API or CLI.\nThis is especially useful when your security realm is based on a central directory, like Active Directory or LDAP,\nand you don’t want to store your password in scripts.\nRecent versions of Jenkins also make it easier to use the remote API when using API tokens to authenticate,\nas no CSRF tokens need to be provided even with CSRF protection enabled.\nAPI tokens are not meant to — and cannot — replace the regular password for the Jenkins UI.\n\nPrevious problems\n\nWe addressed two major problems with the existing API token system in Jenkins 2.129:\n\nFirst, reported in JENKINS-32442,\nuser accounts in Jenkins have an automatically generated API token by default.\nAs these tokens can be used to authenticate as a given user, they increase the attack surface of Jenkins.\n\nThe second problem was reported in JENKINS-32776 :\nThe tokens were previously stored on disk in an encrypted form.\nThis meant that they could be decrypted by unauthorized users by leveraging another security vulnerability,\nor obtained, for example, from improperly secured backups, and used to impersonate other users.\n\nNew approach\n\nThe main objective of this new system is to provide API tokens that are stored in a unidirectional way on the disk,\ni.e. using a hashing algorithm (in this particular case SHA-256).\n\nWhile this means that you will not be able to see the actual API tokens anymore after you’ve created them,\nseveral features were added to mitigate this potential problem:\n\nYou can have multiple active API tokens at the same time.\nIf you don’t remember an API token’s value anymore, just revoke it.\n\nYou can name your tokens to know where they are used (and rename them after creation if desired).\nWe recommend that tokens use a name that indicates where (for example the application, script, or host) where it will be used.\n\nYou can track the usage of your tokens.\nEvery token keeps a record of the number of uses and the date of the last use.\nThis will allow you to better know which tokens are really used and which are no longer actively required.\nJenkins also encourages users to rotate old API tokens by highlighting their creation date in orange after six months, and in red after twelve months.\nThe goal is to remind the user that tokens are more secure when you regenerate them often:\nThe longer a token is around, perhaps passed around in script files and stored on shared drives,\nthe greater the chance it’s going to be accessed by someone not authorized to use it.\n\nFigure 1. Token usage tracking\n\nYou can revoke API tokens.\nWhen you know that you are not using a given token anymore, you can revoke it to reduce the risk of it getting used by unauthorized users.\nSince you can have multiple API tokens, this allows fine-grained control over which scripts, hosts, or applications are allowed to use Jenkins as a given user.\n\nMigrating to new API tokens\n\nTo help administrators migrate their instances progressively, the legacy behavior is still available, while new system is also usable.\n\nOn the user configuration page, the legacy token is highlighted with a warning sign,\nexplaining that users should revoke it and generate a new one (if needed) to increase security.\n\nFigure 2. Legacy token renewal still possible\n\nNew options for administrators\n\nIn order to let administrators control the pace of migration to the new API token system,\nwe added two global configuration options in the \"Configure Global Security\" page in the brand new \"API Token\" section:\n\nAn option to disable the creation of legacy API tokens on user creation.\n\nAn option to disable the recreation of legacy API tokens by users, forcing them to only use the new, unrecoverable API tokens.\n\nBoth options are disabled by default for new installations (the safe default), while they’re enabled when Jenkins is upgraded from before 2.129.\n\nFigure 3. Security Configuration options\n\nFigure 4. Remove legacy token and disable the re-creation\n\nNew administrator warnings\n\nWhen upgrading to Jenkins 2.129, an administrative monitor informs admins about the new options described above, and recommend disabling them.\n\nAnother administrative warnings shows up if at least one user still has a legacy API token.\nIt provides central control over legacy tokens still configured in the Jenkins instance, and allows revoking them all.\n\nFigure 5. Legacy token monitoring page\n\nSummary\n\nJenkins API tokens are now much more flexible: They allow and even encourage better security practices.\nWe recommend you revoke legacy API tokens as soon as you can, and only use the newly introduced API tokens.","title":"Security Hardening: New API token system in Jenkins 2.129+","tags":["community","core","security","upgrade"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/c09ea/wadeck.jpg","srcSet":"/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/534e5/wadeck.jpg 32w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/99887/wadeck.jpg 64w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/c09ea/wadeck.jpg 128w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/5f0ee/wadeck.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/59a6b/wadeck.webp 32w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/cbb78/wadeck.webp 64w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/96250/wadeck.webp 128w,\n/gatsby-jenkins-io/static/608b05a5037fd519ec3cc8b218de672d/890ef/wadeck.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":171}}},"blog":null,"github":"wadeck","html":"<div class=\"paragraph\">\n<p>Wadeck is a member of the <a href=\"/security/#team\">Jenkins security team</a>, working on fixes and improvements to Jenkins security.\nHe likes to provide solutions that are both useful and easy to use.</p>\n</div>","id":"wadeck","irc":null,"linkedin":null,"name":"Wadeck Follonier","slug":"/blog/authors/wadeck","twitter":null}]}},{"node":{"date":"2018-07-02T00:00:00.000Z","id":"44cd4bd6-4c8f-5fdd-8f54-c99da078882e","slug":"/blog/2018/07/02/whats-new-declarative-piepline-13x-sequential-stages/","strippedHtml":"We recently released version 1.3 of Declarative Pipelines, which includes a couple significant new features. We’re\ngoing to cover these features in separate blog posts. The next post will show the new ability to restart a completed\nPipeline run starting from a stage partway through the Pipeline, but first, let’s look at the new sequential stages\nfeature.\n\nSequential Stages\n\nIn Declarative 1.2, we added the ability to define stages to run in parallel\nas part of the Declarative syntax. Now in Declarative 1.3, we’ve added another way to specify stages nested within other\nstages, which we’re calling \"sequential stages\".\n\nRunning Multiple Stages in a Parallel Branch\n\nOne common use case is running build and tests on multiple platforms. You could already do that with parallel stages,\nbut now you can run multiple stages in each parallel branch giving you more visibility into the progress of your\nPipeline without having to check the logs to see exactly which step is currently running where, etc.\n\nYou can also\nuse stage directives, including post, when, agent, and all the others covered in the\nPipeline Syntax reference\nin your sequential stages, letting you control behavior for different parts of each parallel branch.\n\nIn the example below, we are running builds on both Windows and Linux, but only want to deploy if we’re on the master branch.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and deploy on Windows and Linux\") {\n            parallel {\n                stage(\"windows\") {\n                    agent {\n                        label \"windows\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                bat \"run-build.bat\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                            when {\n                                branch \"master\"\n                            }\n                            steps {\n                                bat \"run-deploy.bat\"\n                            }\n                        }\n                    }\n                }\n\n                stage(\"linux\") {\n                    agent {\n                        label \"linux\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                sh \"./run-build.sh\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                             when {\n                                 branch \"master\"\n                             }\n                             steps {\n                                sh \"./run-deploy.sh\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nRunning Multiple Stages with the Same agent, or environment, or options\n\nWhile the sequential stages feature was originally driven by users wanting to have multiple stages in parallel branches,\nwe’ve found that being able to group multiple stages together with the same agent, environment, when, etc has a lot\nof other uses. For example, if you are using multiple agents in your Pipeline, but would like to be sure that stages using\nthe same agent use the same workspace, you can use a parent stage with an agent directive on it, and then all the stages\ninside its stages directive will run on the same executor, in the same workspace. Another example is that until now, you\ncould only set a timeout for the entire Pipeline or an individual stage. But by using a parent stage with nested stages,\nyou can define a timeout in the parent’s options directive, and that timeout will be applied for the execution of the\nparent, including its nested stages. You may also want to conditionally control the execution of multiple stages. For example,\nyour deployment process may be spread across multiple stages, and you don’t want to run any of those stages unless you’re on\na certain branch or some other criteria is satisified. Now you can group all those related stages together in a parent\nstage, within its stages directive, and have a single when condition on that parent, rather than having to copy an\nidentical when condition to each of the relevant stages.\n\nOne of my favorite use cases is shown in the example below. In Declarative 1.2.6, we added the input directive for stages.\nThis will pause the execution of the Pipeline until a user confirms that the Pipeline should continue, using the Scripted\nPipeline input step. The input directive is evaluated before the stage enters its agent, if it has one specified, and\nbefore the stage’s when condition, if specified, is evaluated. But if you’re using a top-level agent for most of your\nstages, you’re still going to be using that agent’s executor while waiting for input, which can be a waste of resources.\nWith sequential stages, you can instead use agent none at the top-level of the Pipeline, and group the stages using a common\nagent and running before the stage with the input directive together under a parent stage with the required agent\nspecified. Then, when your Pipeline reaches the stage with input, it will no longer be using an agent’s executor.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and test the project\") {\n            agent {\n                docker \"our-build-tools-image\"\n            }\n            stages {\n               stage(\"build\") {\n                   steps {\n                       sh \"./build.sh\"\n                   }\n               }\n               stage(\"test\") {\n                   steps {\n                       sh \"./test.sh\"\n                   }\n               }\n            }\n            post {\n                success {\n                    stash name: \"artifacts\", includes: \"artifacts/**/*\"\n                }\n            }\n        }\n\n        stage(\"deploy the artifacts if a user confirms\") {\n            input {\n                message \"Should we deploy the project?\"\n            }\n            agent {\n                docker \"our-deploy-tools-image\"\n            }\n            steps {\n                sh \"./deploy.sh\"\n            }\n        }\n    }\n}\n\nThese are just a few example of the power of the new sequential stages feature in Declarative 1.3.\nThis new feature adds another set of significant use cases that can be handled smoothly using Declarative Pipeline.\nIn my next post, I’ll show the another highly requested feature - the new ability to restart a Pipeline run from any stage in that Pipeline.","title":"What's New in Declarative Pipeline 1.3: Sequential Stages","tags":["pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}}]}},"pageContext":{"limit":8,"skip":208,"numPages":100,"currentPage":27}},
    "staticQueryHashes": ["3649515864"]}