{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/44",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2017-01-13T00:00:00.000Z","id":"3f353648-fd26-5fa2-874d-cbbc20b0fed6","slug":"/blog/2017/01/13/blueocean-dev-log-jan/","strippedHtml":"As we get closer to\nBlue Ocean\n1.0, which is planned for the end of March, I figured it would be great to\nhighlight some of the good stuff that has been going on. It’s been a\nbusy-as-usual week as everyone comes back from vacation.  A couple of new betas\nwent out this week. Of note:\n\ninput to Pipelines is now supported, a much asked for feature (see below)\n\nA new French translation\n\nSome optimisations (especially around reducing number of HTTP calls). We\nhave started using\ngtmetrix.com\nto measure changes on\"dogfood\"\nto get some numbers around optimisations on the web tier.\n\nAnd a grab bag of other great bug fixes.\n\nAlso a bunch of work has been done to support parametrized pipelines, as\nwell as creation of new multibranch pipelines (both are much asked for).\n\nThere is also now an \"official\" Docker image being published to\nDocker Hub. The Pipeline\nbuilding the container is run weekly and will be picking up newly tagged\nreleases of Blue Ocean.\n\nRunning the latest can be as simple as:\n\ndocker run -p 8888:8080 jenkinsci/blueocean:latest\n\nThis is built on the incredibly popular\nofficial \"jenkins\" image\n(10M pulls can’t all be wrong!). The container also has tags available (e.g.\njenkinsci/blueocean:1.0.0-b16) for grabbing a specific released version.\n\nUp next for Blue Ocean development as we march towards 1.0:\n\nSupport for parametrized jobs. For which a bunch of api work has already been\ndone.\n\nCreation of the new Pipeline GUI\n\nPreview release of the Visual Editor for\nDeclarative Pipeline.\n\nThe new header design will be applied\n\nEnjoy!\n\nIf you’re interested in helping to make Blue Ocean a great user experience for\nJenkins, please join the Blue Ocean development team on\nGitter!","title":"Blue Ocean Dev Log: January Week #2","tags":["blueocean"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg","srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/77b35/michaelneale.jpg 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/d4a57/michaelneale.jpg 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/ef6ff/michaelneale.webp 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/8257c/michaelneale.webp 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/6766a/michaelneale.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/authors/michaelneale","twitter":"michaelneale"}]}},{"node":{"date":"2017-01-12T00:00:00.000Z","id":"2ff4e12b-c7b0-5650-8366-ce14906b5f15","slug":"/blog/2017/01/12/declarative-pipeline-beta-2/","strippedHtml":"This week, we released the second beta of the new\nDeclarative Pipeline syntax,\navailable in the Update Center now as version 0.8.1 of Pipeline: Model Definition.\nYou can read more about Declarative Pipeline\nin the blog post introducing the first beta\nfrom December, but we wanted to update you all on the syntax changes in the\nsecond beta. These syntax changes are the last compatibility-breaking changes to\nthe syntax before the 1.0 release planned for February, so you can safely start\nusing the 0.8.1 syntax now without needing to change it when 1.0 is released.\n\nA full syntax reference is available on the wiki as well.\n\nSyntax Changes\n\nChanged \"agent\" configuration to block structure\n\nIn order to support more detailed and clear configuration of agents, as well as\nmaking agent syntax more consistent with the rest of the Declarative Pipeline\nsyntax, we’ve moved the agent configuration into blocks. The agent any and\nagent none configurations work the same as previously, but label, docker\nand dockerfile now look like the following:\n\nJust specifying a label is simple.\n\n// Declarative //\nagent {\n    label \"some-label\"\n}\n// Script //\n\nIf you’re just specifying a Docker image, you can use this simple syntax.\n\n// Declarative //\nagent {\n    docker \"ubuntu:16.04\"\n}\n// Script //\n\nWhen you are specifying a label or other arguments, docker looks like this:\n\n// Declarative //\nagent {\n    docker {\n        image \"ubuntu:16.04\"\n        label \"docker-label\"\n        args \"-v /tmp:/tmp -p 8000:8000\"\n    }\n}\n// Script //\n\nWhen you’re building an image from \"Dockerfile\" in your repository and\ndon’t care what node is used or have additional arguments, you can again\nuse a simple syntax.\n\n// Declarative //\nagent {\n    dockerfile true\n}\n// Script //\n\nWhen you’re building an image from a different file, or have a label or other\narguments, use the following syntax:\n\n// Declarative //\nagent {\n    dockerfile {\n        filename \"OtherDockerfile\"\n        label \"docker-label\"\n        args \"-v /tmp:/tmp -p 8000:8000\"\n    }\n}\n// Script //\n\nImproved \"when\" conditions\n\nWe introduced the when section a couple releases ago, but have made some\nchanges to its syntax here in 0.8.1. We wanted to add some simpler ways to\nspecify common conditions, and that required we re-work the syntax accordingly.\n\nBranch\n\nOne of the most common conditions is running a stage only if you’re on a\nspecific branch. You can also use wildcards like \"*/master\".\n\n// Declarative //\nwhen {\n    branch \"master\"\n}\n// Script //\n\nEnvironment\n\nAnother built-in condition is the environment condition, which checks to see\nif a given environment variable is set to a given value.\n\n// Declarative //\nwhen {\n    environment name: \"SOME_ENV_VAR\", value: \"SOME_VALUE\"\n}\n// Script //\n\nExpression\n\nLastly, there’s the expression condition, which resolves an arbitrary\nPipeline expression. If the return value of that expression isn’t false or\nnull, the stage will execute.\n\n// Declarative //\nwhen {\n    expression {\n        echo \"Should I run?\"\n        return \"foo\" == \"bar\"\n    }\n}\n// Script //\n\n\"options\" replaces \"properties\" and \"wrappers\"\n\nWe’ve renamed the properties section to options, due to needing to add new\nDeclarative-specific options and to cut down on confusion. The options section\nis now where you’ll put general Pipeline options like buildDiscarder,\nDeclarative-specific options like skipDefaultCheckout, and block-scoped steps\nthat should wrap the execution of the entire build, like timeout or\ntimestamps.\n\n// Declarative //\n\noptions {\n    buildDiscarder(logRotator(numToKeepStr:'1'))\n    skipDefaultCheckout()\n    timeout(time: 5, unit: 'MINUTES')\n}\n// Script //\n\nHeading towards 1.0!\n\nWhile we may still add more functionality to the Declarative Pipeline syntax,\nwe won’t be making any changes to existing syntax for the 1.0 release. This\nmeans that any pipelines you write against the 0.8.1 syntax will keep working\nfor the foreseeable future without any changes. So if you’re already using\nDeclarative Pipelines, make sure to update your `Jenkinsfile`s after upgrading\nto 0.8.1, and if you haven’t been using Declarative Pipelines yet, install the\nPipeline: Model Definition plugin and\ngive them a try!","title":"Declarative Pipeline Syntax Beta 2 release","tags":["plugins","pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"<div class=\"paragraph\">\n<p>Andrew was a core committer to Hudson and the author of numerous plugins.</p>\n</div>","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2017-01-11T00:00:00.000Z","id":"b6d5d789-c4f4-5f71-bda6-b5ab5196b7e9","slug":"/blog/2017/01/11/jenkins-world-2017-cfp/","strippedHtml":"The largest Jenkins event, Jenkins\nWorld is coming to San Francisco, California on August 28 - 31, 2017, at the\nMarriott Marquis.  This conference will feature two days of hands-on training,\nworkshops, and certification exams followed by two more days with five tracks\nof technical sessions from Jenkins and DevOps experts from around the world.\n\nInspire your peers and colleagues by sharing your expertise and experience as\none of the Jenkins World speakers.\nThe Call for Papers is open, last\nday for submitted a proposal is March 5th, 2017.\n\nCompared to Jenkins World 2016, what’s new for\n2017?  Two tracks are now dedicated to \"show and tell.\" These sessions are\ntechnically advanced with code sharing, heavy on demos, and only a few slides.\nIf you are like most of us - driven to learn, share, and collaborate…​we’d\nlike to hear from you!\n\nLooking forward to your amazing proposal(s)!\n\nSubmit your proposal here!","title":"Jenkins World 2017 Call for Papers is Open","tags":["event","jenkinsworld","jenkinsworld2017"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#281818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg","srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/8d248/alyssat.jpg 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/c004c/alyssat.jpg 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/a55dc/alyssat.jpg 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/9e67b/alyssat.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/22924/alyssat.webp 32w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/89767/alyssat.webp 64w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/40d97/alyssat.webp 128w,\n/gatsby-jenkins-io/static/fee8c4b53c42d9c396735bc2b737ff84/5028e/alyssat.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":166}}},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"/blog/authors/alyssat","twitter":null}]}},{"node":{"date":"2017-01-10T00:00:00.000Z","id":"ce9069d6-e9c4-5b3e-b147-2b3d3ac2f09d","slug":"/blog/2017/01/10/jenkins-lifx-notifier-plugin/","strippedHtml":"This is a\ncross\npost by Veaceslav Gaidarji, open source\ndeveloper and contributor to the Jenkins and Bitrise projects.\n\nSome time ago I encountered a LIFX smart bulbs.\nThese are the bulbs with a chip inside - 50% bulb, 50% chip. There are mobile\napplications for easy configuration and remote control of the bulb. Nothing\nspecial here, it simply works and is very convenient to have such bulbs in\ndormitory.\n\nBrilliant idea time\n\n99% of ideas which come to our minds either were already implemented by someone\nelse or they are useless.\n\n— Veaceslav Gaidarji\n\nAnd as it always happens, the developer inside me generated an idea which, as\nit always happens, was implemented by someone else already.\n\nThe idea was: to connect a LIFX bulb to Jenkins server and update the color\naccording to a job’s state.\n\nBefore starting to work on such Jenkins plugin, I searched for similar projects\non Google and the first links pointed me to existing\nLIFX notifier plugin\nand a\nblog post\nfrom\nMichael Neale\nwho created the plugin. Michael’s post describes exactly what I had in mind.\n\nAt this point I had 2 options:\n\nforget about building something new and just use the plugin\n\nimprove existing plugin\n\nFirst option is always easy and effortless, but second one is more challenging.\n\nImproving an existing plugin\n\nThe existing LIFX notifier plugin\ndid its job really well and I was able to connect my bulb to Jenkins and test\nit. But it wasn’t complete and had no configurable at all, therefore no\npossibility to change the colors.\n\nFirst, I read Jenkins contribution guidelines, which\nencourage\ndevelopers to improve existing plugins (if any) and not create other versions\nof plugins with similar functionality. Then I contacted the plugin author, Michael Neale,\nvia email and kindly asked for the contributor access in GitHub\nfor the existing plugin version. After a short discussion about my plans on this\nplugin, Michael added me as a contributor to GitHub\nrepo and wished me\ngood luck. Thanks Michael!\n\nI wanted to improve the LIFX notifier plugin to add the ability\ncustomize the colors ( in progress, build success and build failure). This\nis not a hard task actually.\nA 1000+ plugins were\ndeveloped for Jenkins by the hackers like me, which means that I should have no\nproblem to do it as well.\nFortunately for me, I have used some plugins already which had a UI similar to\nthat I had planned to add to the LIFX notifier, such as:\n\nHockeyApp plugin\n\nFabric Beta publisher plugin\n\nDifferent Build notifiers plugins\n\nReviewing the code for these plugins, plus Jenkins\nplugin\ndevelopment documentation, and of course looking over\nJelly components helped\nme to:\n\nBetter understand the Jenkins architecture.\n\nLearn how Jenkins plugins work in general.\n\nLearn how to create the UI components for a plugin.\n\nLearn how to subscribe to Jenkins job state changes using appropriate\nextension points.\n\nIn a few weeks I’ve finished my plugin modifications and added unit tests for\nits major parts.  As a result, the plugin now has a UI configuration section in\nPost-build Actions which is self descriptive:\n\nThe last step was to prepare new plugin version and publish it to the world!\nThe Jenkins\"Hosting\nplugins\" document describes step by step process of how to publish a plugin.\n\nThis includes many steps which should be respected very carefully.\n\nDemo\n\nWhat I’ve learned\n\nIt was my first experience in Jenkins plugins development. I should say that\nsteep learning curve is high enough, and sometimes is really hard to find\nanswers on appearing questions. But in general it’s all about Java, XML,\nMaven and it’s a lot of fun developing Jenkins plugins.\n\nCheck out the LIFX notifier page\nfor more information about the latest releases!\n\nBonus : bitrise.io users, I’ve developed step LIFX notifier for bitrise as well.","title":"Learning plugin development by improving the LIFX notifier plugin","tags":["plugins","lifx"],"authors":[{"avatar":null,"blog":"http://vgaidarji.me","github":"vgaidarji","html":"<div class=\"paragraph\">\n<p>Veaceslav is a software developer with the main focus on Android platform.\nIn his free time, he enjoys working on different open-source projects.</p>\n</div>","id":"vgaidarji","irc":null,"linkedin":null,"name":"Veaceslav Gaidarji","slug":"/blog/authors/vgaidarji","twitter":"v_gaidarji"}]}},{"node":{"date":"2017-01-10T00:00:00.000Z","id":"977904eb-252b-582f-a038-4682f4224260","slug":"/blog/2017/01/10/security-warnings/","strippedHtml":"Jenkins 2.40 was released earlier this week, and readers of the\nchangelog\nwill have noticed that it now includes the ability to show security warnings\npublished by the configured update site.  But what does that mean?\n\nIn the past, we’ve notified users about security issues in Jenkins and in\nplugins through various means: Emails to the\njenkinsci-advisories mailing list\n(which I recommend you subscribe to), blog posts, and, recently, emails to the\noss-security mailing list.  But I still wanted to increase the reach of our\nnotifications, to make sure Jenkins admins are informed quickly about possible\nsecurity problems on their instances.  The logical next step was to include\nthese notifications in Jenkins itself, and that feature has been added in\nJenkins 2.40.\n\nToday we enabled the publication of warnings on our update sites: Once Jenkins\n2.40 (or newer) refreshes its cache of update site metadata, it may now inform\nyou that you’re using a vulnerable plugin that should be updated or removed.\nRight now, these aren’t previously unknown warnings, but reference security\nadvisories for plugin vulnerabilies that have been published over the past few\nyears.\n\nWe will of course continue to publish security advisories using the mailing\nlist of the same name, as well other means.\n\nStay safe!","title":"Security warnings in Jenkins","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2016-12-31T00:00:00.000Z","id":"3267c8fe-f10e-530a-9caa-bae9eeb34fb0","slug":"/blog/2016/12/31/what-a-year/","strippedHtml":"I do not think it is an exaggeration to say: 2016 was the best year yet for the\nJenkins project. Since the first commit in 2006, the project has reached a\nnumber of significant milestones in its ten years but we have never experienced\nthe breadth of major milestones in such a short amount of time. From\nJenkins 2\nand\nBlue Ocean\nto the\nGoogle Summer of Code\nand\nJenkins World,\n\nI wanted to take a moment and celebrate the myriad of accomplishments which\ncouldn’t have happened without the help from everybody who participates in the\nJenkins project. The 1,300+ contributors to the\njenkinsci GitHub organization,\nthe 4,000+ members of the\ndevelopers mailing list,\nthe 8,000+ members of the\nusers mailing list,\nand countless others who have reported issues, submitted pull requests, and\npresented at meetups and conferences.\n\nJenkins 2\n\nThrough the course of 2016, the Jenkins project published 16\nLTS releases\nand 54\nWeekly releases.\nOf those 70 releases, the most notable may have been the\nJenkins 2.0 release\nwhich was published in April.\n\nJenkins 2 made Pipeline as Code front-and-center in the user experience,\nintroduced a new \"Getting Started\" experience, and included a number of other\nsmall UI improvements, all while maintaining backwards compatibility with\nexisting Jenkins environments.\n\nSince April, we have released a number of LTS\nreleases using Jenkins 2 as a baseline, meaning the Jenkins project no longer\nmaintains any 1.x release lines.\n\nThe\nPipeline\nefforts have continuted to gain steam since April, covered on this blog with a\nnumber of\nposts tagged \"pipeline\". Closing out 2016 with the\nannouncement of the beta for\nDeclarative Pipeline syntax\nwhich is expected in early 2017.\n\nBlue Ocean\n\nHot on the heels of Jenkins 2 announcement\"Blue Ocean, a new user experience for Jenkins\",\nwas\nopen sourced in May.\nBlue Ocean is a new project that rethinks the user experience of Jenkins.\nDesigned from the ground up for Jenkins Pipeline and compatible with Freestyle\njobs. The goal for the project is to reduce clutter and increase clarity for\nevery member of a team using Jenkins.\n\nThe Blue Ocean beta can be installed from the Update Center and can be run in\nproduction Jenkins environments alongside the existing UI. It adds the new user experience under\n/blue in the environment but does not disturb the existing UI.\n\nBlue Ocean is expected to reach \"1.0\" in the first half of 2017.\n\nAzure\n\nAlso in May of 2016, the Jenkins project announced an exciting\nPartnership with Microsoft\nto run our project infrastructure on\nAzure. While the migration of Jenkins project\ninfrastructure into Azure is still on-going, there have been some notable\nmilestones reached already:\n\nEnd-to-end TLS encrypted delivery for Debian/openSUSE/Red Hat repositories which are\nconfigured to use https://pkg.jenkins.io by the end-user.\n\nMajor capacity improvements to\nci.jenkins.io\nproviding on-demand Ubuntu and Windows build/test infrastructure.\n\nA full continuous delivery Pipeline for all Azure-based infrastructure using\nTerraform from Jenkins.\n\nThe migration to Azure is expected to complete in 2017.\n\nGoogle Summer of Code\n\nFor the first time in the history of the project, Jenkins was accepted into\nGoogle Summer of Code\n2016. Google Summer of Code (GSoC) is an annual, international, program\nwhich encourages college-aged students to participate with open source projects\nduring the summer break between classes. Students accepted into the program\nreceive a stipend, paid by Google, to work well-defined projects to improve or\nenhance the Jenkins project.\n\nIn exchange, numerous Jenkins community members volunteered as \"mentors\" for\nstudents to help integrate them into the open source community and succeed in\ncompleting their summer projects.\n\nA lot was learned during the summer which we look forward to applying to Google\nSummer of Code 2017\n\nJenkins World\n\nIn September, over one thousand people attended\nJenkins World,\nin Santa Clara, California.\n\nFollowing the event,\nLiam\nposted a series of blog posts which highlight some of the fantastic content\nshared by Jenkins users and contributors from around the world, such as:\n\nThe demos from the \"Experts\"\n\nSessions on Scaling Jenkins\n\nUsing Jenkins Pipeline\n\nThe Contributor Summit\n\nJenkins World was the first global event of its kind for Jenkins, it brought users\nand contributors together to exchange ideas on the current state of the\nproject, celebrate accomplishments of the past year, and look ahead at all the\nexiting enhancements coming down the pipe(line).\n\nIt was such a smashing success that\nJenkins World 2017\nis already scheduled for August 30-31st in San Francisco, California.\n\nJAM\n\nFinally, 2016 saw tremendous growth in the number of\nJenkins Area Meetups\n(JAMs) hosted around the world. JAMs are local meetups intended to bring\nJenkins users and contributors together for socializing and learning. JAMs are\norganized by local Jenkins community members who have a passion for sharing new\nJenkins concepts, patterns and tools.\n\nDriven by current Jenkins Events Officer,\nAlyssa Tong,\nand the dozens of passionate organizers, JAMs have become a great way to meet\nother Jenkins users near you.\n\nWhile we don’t yet have JAMs on each of the seven continents, you can always join the\nJenkins Online Meetup.\nThough we’re hoping more groups will be founded near you in 2017!\n\nI am personally grateful for the variety and volume of contributions made by\nthousands of people to the Jenkins project this year. I believe I can speak for\nproject founder,\nKohsuke Kawaguchi,\nin stating that the Jenkins community has grown beyond our anything we could\nhave imagined five years ago, let alone ten!\n\nThere are number of ways to\nparticipate\nin the Jenkins project, so if you didn’t have an opportunity to join in during\n2016, we hope to see you next year!","title":"Thank you for an amazing 2016","tags":["jam","jenkins2","pipeline","blueocean","azure","gsoc","new-year-blogpost"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-12-20T00:00:00.000Z","id":"07094990-1362-5018-bed6-12c7ddfa53ee","slug":"/blog/2016/12/20/jenkins-puppet-enterprise-plugin/","strippedHtml":"This is a guest post by Carl Caum,\nwho works at Puppet and created the\nPuppet Enterprise Pipeline plugin.\n\nDuring PuppetConf 2016, myself and Brian Dawson from CloudBees announced the\nplugin:puppet-enterprise-pipeline[Puppet Enterprise\nplugin for Jenkins Pipeline].\nLet’s take a look at how the plugin makes it trivial to use Puppet to perform\nsome or all of the deployment tasks in continuous delivery pipelines.\n\nJenkins Pipeline introduced an amazing world where the definition for a\npipeline is managed from the same version control repository as the code\ndelivered by the pipeline. This is a powerful idea, and one I felt complemented\nPuppet’s automation strengths. I wanted to make it trivial to control Puppet\nEnterprise’s orchestration and infrastructure code management capabilities, as\nwell as set hierarchical configuration data and use Puppet’s inventory data\nsystem as a source of truth – all from a Pipeline script. The result was the\nPuppet Enterprise plugin, which fully buys into the Pipeline ideals by\nproviding methods to control the different capabilities in Puppet Enterprise.\nThe methods provide ways to query\nPuppetDB, set\nHiera key/value pairs, deploy\nPuppet code environments with\nCode Management, and kick off orchestrated Puppet runs with the\nOrchestrator.\n\nThe Puppet Enterprise for Jenkins Pipeline plugin\n\nThe Puppet Enterprise for Jenkins Pipeline plugin itself has zero system\ndependencies. You need only to install the plugin from the update center. The\nplugin uses APIs available in Puppet Enterprise to do its work. Since the\nPuppetDB query, Code Management, and Orchestrator APIs are all\nbacked by Puppet Enterprise’s role-based access control (RBAC) system, it’s\neasy to restrict what pipelines are allowed to control in Puppet Enterprise. To\nlearn more about RBAC in Puppet Enterprise,\nread the docs here.\n\nConfiguring\n\nConfiguring the plugin is fairly straight forward. It takes three simple steps:\n\nSet the address of the Puppet server\n\nCreate a Jenkins credential with a Pupppet Enterprise RBAC authentication token\n\nConfigure the Hiera backend\n\nSet the Puppet Enterprise Server Address\n\nGo to Jenkins > Manage Jenkins > Puppet Enterprise page. Put the DNS address of\nthe Puppet server in the Puppet Master Address text field. Click the Test\nConnection button to verify the server is reachable, the Puppet CA certificate\nis retrievable, and HTTPS connections are successful. Once the test succeeds,\nClick Save.\n\nCreate a Jenkins Credentials Entry\n\nThe plugin uses the Jenkins built-in credentials system (the plain-credentials\nplugin) to store and refer RBAC tokens to Puppet Enterprise for authentication\nand authorization. First, generate an RBAC token in Puppet Enterprise by\nfollowing\nthe\ninstructions on the docs site. Next, create a new Jenkins Credentials item\nwith Kind Secret text and the Secret value the Puppet Enterprise RBAC\ntoken. It’s highly recommended to give the credential an ID value that’s\ndescriptive and identifiable. You’ll use it in your Pipeline scripts.\n\nIn your Jenkinsfile, use the puppet.credentials method to set all future Puppet\nmethods to use the RBAC token. For example:\n\npuppet.credentials 'pe-team-token'\n\nConfigure the Hiera Backend\n\nThe plugin exposes an HTTP API for performing Hiera data lookups for key/value\npairs managed by Pipeline jobs. To configure Hiera on the Puppet compile\nmaster(s) to query the Jenkins Hiera data store backend, use the\nhiera-http backend. On the\nPuppet Enterprise compile master(s), run the following commands:\n\n/opt/puppetlabs/puppet/bin/gem install hiera-http\n/opt/puppetlabs/bin/puppetserver gem install hiera-http\n\nNow you can configure the /etc/puppetlabs/puppet/hiera.yaml file. The following\nconfiguration instructs Hiera to first look to the Hiera yaml files in the\nPuppet code’s environment, then fall back to the http backend. The http backend\nwill first query the Hiera data store API looking for the key in the scope with\nthe same name as the node. If nothing’s found, look for the key in the node’s\nenvironments. You can use any Facter fact to match scope names.\n\n:backends:\n  - yaml\n  - http\n\n:http:\n  :host: jenkins.example.com\n  :port: 8080\n  :output: json\n  :use_auth: true\n  :auth_user:\n:auth_pass:\n:cache_timeout: 10\n  :failure: graceful\n  :paths:\n    - /hiera/lookup?path=%{clientcert}&key=%{key}\n    - /hiera/lookup?path=%{environment}&key=%{key}\n\nFinally, restart the pe-puppetserver process to pick up the new configs:\n\n/opt/puppetlabs/bin/puppet resource service pe-puppetserver ensure=stopped\n/opt/puppetlabs/bin/puppet resource service pe-puppetserver ensure=running\n\nHiera HTTP Authentication\n\nIf Jenkins' Global Security is configured to allow unauthenticated read-only\naccess, the 'use_auth', 'auth_pass', and 'auth_user' parameters are\nunnecessary. Otherwise, create a local Jenkins user that has permissions to\nview the Hiera Data Lookup page and use that user’s credentials for the\nhiera.yaml configuration.\n\nQuerying the infrastructure\n\nPuppetDB is an extensive data store that holds every bit of information Puppet\ngenerates and collects across every system Puppet is installed on. PuppetDB\nprovides a sweet query language called\nPQL. With PQL,\nyou can ask complex questions of your infrastructure such as \"How many\nproduction Red Hat systems are there with the openssl package installed?\" or\n\"What us-west-2c nodes with the MyApp role that were created in the last 24\nhours?\"\n\nThis can be a powerful tool for parts of your pipeline where you need to\nperform specific operations on subsets of the infrastructure like draining a\nloadbalancer.\n\nHere’s an example using the puppet.query method:\n\nresults = puppet.query '''\n  inventory[certname] {\n    facts.os.name = \"RedHat\" and\n    facts.ec2_metadata.placement.availability-zone = \"us-west-2c\" and\n    facts.uptime_hours < 24\n  }'''\n\nThe query returns an array of matching items. The results can be\niterated on, and even passed to a series of puppet.job calls. For example, the\nfollowing code will query all nodes in production that experienced a failure on\nthe last Puppet run.\n\nresults = puppet.query 'nodes { latest_report_status = \"failed\" and catalog_environment = \"production\"}'\n\nNote that once you can use closures in Pipeline scripts, doing the above\nexample will be much simpler.\n\nCreating an orchestrator job\n\nThe orchestration service in Puppet Enterprise is a tool to perform\norchestrated Puppet runs across as broad or as targeted an infrastructure as\nyou need at different parts of a pipeline. You can use the orchestrator to\nupdate applications in an environment, or update a specific list of nodes, or\nupdate nodes across a set of nodes that match certain criteria. In each\nscenario, Puppet will always push distributed changes in the correct order by\nrespecting the cross-node dependencies.\n\nTo create a job in the Puppet orchestrator from a Jenkins pipeline, use the\npuppet.job method. The puppet.job method will create a new orchestrator job,\nmonitor the job for completion, and determine if any Puppet runs failed. If\nthere were failures, the pipeline will fail.\n\nThe following are just some examples of how to run Puppet orchestration jobs against the infrastructure you need to target.\n\nTarget an entire environment:\n\npuppet.job 'production'\n\nTarget instances of an application in production:\n\npuppet.job 'production', application: 'Myapp'\n\nTarget a specific list of nodes:\n\npuppet.job 'production', nodes: ['db.example.com','appserver01.example.com','appserver02.example.com']\n\nTarget nodes matching a complex set if criteria:\n\npuppet.job 'production', query: 'inventory[certname] { facts.os.name = \"RedHat\" and facts.ec2_metadata.placement.availability-zone = \"us-west-2c\" and uptime_hours < 24 }'\n\nAs you can see, the puppet.job command means you can be as broad or as targeted\nas you need to be for different parts of your pipeline. There are many other\noptions you can add to the puppet.job method call, such as setting the Puppet\nruns to noop, or giving the orchestrator a maximum concurrency limit.\nLearn\nmore about the orchestrator here.\n\nUpdating Puppet code\n\nIf you’re using Code Management in Puppet Enterprise (and you should), you can\nensure that all the modules, site manifests, Hiera data, and roles and profiles\nare staged, synced, and ready across all your Puppet masters, direct from your\nJenkins pipeline.\n\nTo update Puppet code across all Puppet masters, use the puppet.codeDeploy method:\n\npuppet.codeDeploy 'staging'\n\nLearn more Code Management in Puppet Enterprise here.\n\nSetting Hiera values\n\nThe plugin includes an experimental feature to set Hiera key/value pairs. There\nare many cases where you need to promote information through a pipeline, such\nas a build version or artifact location. Doing so is very difficult in Puppet,\nsince data promotion almost always involves changing Hiera files and committing\nto version control.\n\nThe plugin exposes an HTTP API endpoint that Hiera can query using the\nhiera-http backend. With the backend configured on the Puppet master(s),\nkey/value pairs can be set to scopes. A scope is arbitrary and can be anything\nyou like, such as a Puppet environment, a node’s certname, or the name of a\nFacter fact like operatingsystem or domain.\n\nTo set a Hiera value from a pipeline, use the puppet.hiera method.\n\npuppet.hiera scope: 'staging', key: 'build-version', value: env.BUILD_ID\n\nNow you can set the same key with the same value to the production scope later\nin the pipeline, followed by a call to puppet.job to push the change out.\n\nExamples\n\nThe\nplugin’s\nGithub repository contains a set of example Pipeline scripts. Feel free to\nissue pull requests to add your own scripts!\n\nWhat’s next\n\nI’m pretty excited to see how this is going to help simplify continuous\ndelivery pipelines. I encourage everyone to get started with continuous\ndelivery today, even if it’s just a simple pipeline. As your practices evolve,\nyou can begin to add automated tests, automate away manual checkpoints, start\nto incorporate InfoSec tests, and include phases for practices like patch\nmanagement that require lots of manual approvals, verifications and rollouts.\nYou’ll be glad you did.","title":"Continuous Delivery with Jenkins and Puppet Enterprise","tags":["continuousdelivery","puppet","pipeline","puppetenterprise"],"authors":[{"avatar":null,"blog":null,"github":"ccaum","html":"","id":"ccaum","irc":null,"linkedin":null,"name":"Carl Caum","slug":"/blog/authors/ccaum","twitter":"ccaum"}]}},{"node":{"date":"2016-12-19T00:00:00.000Z","id":"584ac2c5-5d3d-5e1c-bcbe-5ef1ef71e42e","slug":"/blog/2016/12/19/declarative-pipeline-beta/","strippedHtml":"Last week we released version 0.7.1 of the\nPipeline-Model-Defintion\nplugin and wanted to crown it as the official Beta version of the Declarative\nPipeline syntax. Although it has been available in the update center\nsince August,\nwe continue to solidify the syntax. We feel this release is getting\nvery close to the final version and should not change much before 1.0. However,\nit is still a Beta so further tweaks are possible.\n\nA release (0.8.0) is planned for early January 2017 which will finalize the\nsyntax with the following changes:\nJENKINS-40524,\nJENKINS-40370,\nJENKINS-40462,\nJENKINS-40337\n\nWhat is Declarative Pipeline?\n\nAll the way back at Jenkins World in September, Andrew Bayer presented a\nsneak peak\nof a new syntax for constructing Pipelines. We are calling this new syntax\nDeclarative Pipeline to differentiate it from the existing Scripted Pipeline\nsyntax that has always been a part of Pipeline.\n\nAfter listening to many Jenkins users over the last year we felt that, while\nPipeline Script provides tremendous power, flexibility, and extensibility, the\nlearning curve for Scripted Pipeline was steep for users new to either Jenkins\nor Pipeline. Beginning users wanting to take advantage of all the features\nprovided by Pipeline and Jenkinsfiles were required to learn Scripted Pipeline\nor remain limited to the functionality provided by Freestyle jobs.\n\nDeclarative Pipeline does not replace Scripted Pipeline but extends Pipeline it\nwith a pre-defined structure to let users focus entirely on the steps\nrequired at each stage without needing to worry about scripting every aspect\nof the pipeline. Granular flow-control is extremely powerful and Scripted\nPipeline syntax will always be part of Pipeline but it’s not for everyone.\n\nDeclarative Pipeline enables all users to connect simple, declarative blocks\nthat define agents (including Docker), post actions, environment\nsettings, credentials and all stages that make up the pipeline. Best of all,\nbecause this Declarative syntax is part of Pipeline, all build steps and build\nwrappers available in Plugins or loaded from Shared Libraries are also\navailable as steps in Declarative.\n\nExample\n\nBelow is an example of a pipeline in Declarative syntax. You can also switch the view to show the same pipeline in Scripted syntax.\n The Declarative syntax has a more straightforward structure that is easier to grok by users not versed in Groovy.\n\n// Declarative //\npipeline {\n  agent  label:'has-docker', dockerfile: true\n  environment {\n    GIT_COMMITTER_NAME = \"jenkins\"\n    GIT_COMMITTER_EMAIL = \"jenkins@jenkins.io\"\n  }\n  stages {\n    stage(\"Build\") {\n      steps {\n        sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n      }\n    }\n    stage(\"Archive\"){\n      steps {\n        archive \"*/target/**/*\"\n        junit '*/target/surefire-reports/*.xml'\n      }\n    }\n  }\n  post {\n    always {\n      deleteDir()\n    }\n    success {\n      mail to:\"me@example.com\", subject:\"SUCCESS: ${currentBuild.fullDisplayName}\", body: \"Yay, we passed.\"\n    }\n    failure {\n      mail to:\"me@example.com\", subject:\"FAILURE: ${currentBuild.fullDisplayName}\", body: \"Boo, we failed.\"\n    }\n  }\n}\n\n// Script //\nwithEnv([\"GIT_COMMITTER_NAME = jenkins\",\"GIT_COMMITTER_EMAIL = jenkins@jenkins.io\"]) {\n  node('has-docker') {\n    try {\n      checkout scm // checks out Dockerfile and source code\n      def myImage = docker.build 'my-environment:snapshot'\n      myImage.inside {\n        stage('Build') {\n          sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n        }\n        stage('Archive') {\n          archive \"*/target/**/*\"\n          junit '*/target/surefire-reports/*.xml'\n        }\n      }\n      if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {\n        mail to:\"me@example.com\", subject:\"SUCCESS: ${currentBuild.fullDisplayName}\", body: \"Yay, we passed.\"\n      }\n    }\n    catch (exc) {\n      mail to:\"me@example.com\", subject:\"FAILURE: ${currentBuild.fullDisplayName}\", body: \"Boo, we failed.\"\n    }\n    finally {\n      deleteDir()\n    }\n  }\n}\n\nHow can you help?\n\nInstall the lastest version of the\nPipeline-Model-Defintion plugin.\n\nRead the documentation:\nGetting Started and\nSyntax overview.\n(These documents will be incorporated into the Jenkins.io documentation.)\n\nConvert some of your existing Pipeline scripts into Declarative\n\nLog any issues or enhancements you have\nhere\nfor the syntax, the execution, or the documentation.\n\nAsk questions. You can send questions to the\nusers mailing list\nor visit the #jenkins channel on IRC.\n\nHow will this work with Blue Ocean?\n\nBlue Ocean is all about Pipelines in Jenkins. Running, displaying, and soon,\ncreating Pipelines.  Blue Ocean will be able to run and display Pipelines\nwritten in this new syntax just like any other Pipeline works today. However,\nbecause Declarative Pipeline includes a pre-defined structure, or model, it is\nnow possible to create and edit pipelines with a GUI editor.\n\nAlthough we plan to launch 1.0 of Declarative Pipeline before Blue Ocean 1.0 is\nofficially available, we expect to have a working Beta of the Editor available\nto play with. The combination of a simple syntax and an intuitive editor\nshould make creating Jenkins Pipelines a breeze.\n\nHappy Holidays\n\nI hope everyone has a great end of the year and a Happy New Year. With\nDeclarative Pipeline and\nBlue Ocean\nwe expect great things for Jenkins in 2017!","title":"Announcing the beta of Declarative Pipeline Syntax","tags":["pipeline","blueocean"],"authors":[{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"/blog/authors/hrmpw","twitter":"hrmpw"}]}}]}},"pageContext":{"limit":8,"skip":344,"numPages":100,"currentPage":44}},
    "staticQueryHashes": ["3649515864"]}