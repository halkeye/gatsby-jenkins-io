{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/44",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-12-31T00:00:00.000Z","id":"3267c8fe-f10e-530a-9caa-bae9eeb34fb0","slug":"/blog/2016/12/31/what-a-year/","strippedHtml":"I do not think it is an exaggeration to say: 2016 was the best year yet for the\nJenkins project. Since the first commit in 2006, the project has reached a\nnumber of significant milestones in its ten years but we have never experienced\nthe breadth of major milestones in such a short amount of time. From\nJenkins 2\nand\nBlue Ocean\nto the\nGoogle Summer of Code\nand\nJenkins World,\n\nI wanted to take a moment and celebrate the myriad of accomplishments which\ncouldn’t have happened without the help from everybody who participates in the\nJenkins project. The 1,300+ contributors to the\njenkinsci GitHub organization,\nthe 4,000+ members of the\ndevelopers mailing list,\nthe 8,000+ members of the\nusers mailing list,\nand countless others who have reported issues, submitted pull requests, and\npresented at meetups and conferences.\n\nJenkins 2\n\nThrough the course of 2016, the Jenkins project published 16\nLTS releases\nand 54\nWeekly releases.\nOf those 70 releases, the most notable may have been the\nJenkins 2.0 release\nwhich was published in April.\n\nJenkins 2 made Pipeline as Code front-and-center in the user experience,\nintroduced a new \"Getting Started\" experience, and included a number of other\nsmall UI improvements, all while maintaining backwards compatibility with\nexisting Jenkins environments.\n\nSince April, we have released a number of LTS\nreleases using Jenkins 2 as a baseline, meaning the Jenkins project no longer\nmaintains any 1.x release lines.\n\nThe\nPipeline\nefforts have continuted to gain steam since April, covered on this blog with a\nnumber of\nposts tagged \"pipeline\". Closing out 2016 with the\nannouncement of the beta for\nDeclarative Pipeline syntax\nwhich is expected in early 2017.\n\nBlue Ocean\n\nHot on the heels of Jenkins 2 announcement\"Blue Ocean, a new user experience for Jenkins\",\nwas\nopen sourced in May.\nBlue Ocean is a new project that rethinks the user experience of Jenkins.\nDesigned from the ground up for Jenkins Pipeline and compatible with Freestyle\njobs. The goal for the project is to reduce clutter and increase clarity for\nevery member of a team using Jenkins.\n\nThe Blue Ocean beta can be installed from the Update Center and can be run in\nproduction Jenkins environments alongside the existing UI. It adds the new user experience under\n/blue in the environment but does not disturb the existing UI.\n\nBlue Ocean is expected to reach \"1.0\" in the first half of 2017.\n\nAzure\n\nAlso in May of 2016, the Jenkins project announced an exciting\nPartnership with Microsoft\nto run our project infrastructure on\nAzure. While the migration of Jenkins project\ninfrastructure into Azure is still on-going, there have been some notable\nmilestones reached already:\n\nEnd-to-end TLS encrypted delivery for Debian/openSUSE/Red Hat repositories which are\nconfigured to use https://pkg.jenkins.io by the end-user.\n\nMajor capacity improvements to\nci.jenkins.io\nproviding on-demand Ubuntu and Windows build/test infrastructure.\n\nA full continuous delivery Pipeline for all Azure-based infrastructure using\nTerraform from Jenkins.\n\nThe migration to Azure is expected to complete in 2017.\n\nGoogle Summer of Code\n\nFor the first time in the history of the project, Jenkins was accepted into\nGoogle Summer of Code\n2016. Google Summer of Code (GSoC) is an annual, international, program\nwhich encourages college-aged students to participate with open source projects\nduring the summer break between classes. Students accepted into the program\nreceive a stipend, paid by Google, to work well-defined projects to improve or\nenhance the Jenkins project.\n\nIn exchange, numerous Jenkins community members volunteered as \"mentors\" for\nstudents to help integrate them into the open source community and succeed in\ncompleting their summer projects.\n\nA lot was learned during the summer which we look forward to applying to Google\nSummer of Code 2017\n\nJenkins World\n\nIn September, over one thousand people attended\nJenkins World,\nin Santa Clara, California.\n\nFollowing the event,\nLiam\nposted a series of blog posts which highlight some of the fantastic content\nshared by Jenkins users and contributors from around the world, such as:\n\nThe demos from the \"Experts\"\n\nSessions on Scaling Jenkins\n\nUsing Jenkins Pipeline\n\nThe Contributor Summit\n\nJenkins World was the first global event of its kind for Jenkins, it brought users\nand contributors together to exchange ideas on the current state of the\nproject, celebrate accomplishments of the past year, and look ahead at all the\nexiting enhancements coming down the pipe(line).\n\nIt was such a smashing success that\nJenkins World 2017\nis already scheduled for August 30-31st in San Francisco, California.\n\nJAM\n\nFinally, 2016 saw tremendous growth in the number of\nJenkins Area Meetups\n(JAMs) hosted around the world. JAMs are local meetups intended to bring\nJenkins users and contributors together for socializing and learning. JAMs are\norganized by local Jenkins community members who have a passion for sharing new\nJenkins concepts, patterns and tools.\n\nDriven by current Jenkins Events Officer,\nAlyssa Tong,\nand the dozens of passionate organizers, JAMs have become a great way to meet\nother Jenkins users near you.\n\nWhile we don’t yet have JAMs on each of the seven continents, you can always join the\nJenkins Online Meetup.\nThough we’re hoping more groups will be founded near you in 2017!\n\nI am personally grateful for the variety and volume of contributions made by\nthousands of people to the Jenkins project this year. I believe I can speak for\nproject founder,\nKohsuke Kawaguchi,\nin stating that the Jenkins community has grown beyond our anything we could\nhave imagined five years ago, let alone ten!\n\nThere are number of ways to\nparticipate\nin the Jenkins project, so if you didn’t have an opportunity to join in during\n2016, we hope to see you next year!","title":"Thank you for an amazing 2016","tags":["jam","jenkins2","pipeline","blueocean","azure","gsoc","new-year-blogpost"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-12-20T00:00:00.000Z","id":"07094990-1362-5018-bed6-12c7ddfa53ee","slug":"/blog/2016/12/20/jenkins-puppet-enterprise-plugin/","strippedHtml":"This is a guest post by Carl Caum,\nwho works at Puppet and created the\nPuppet Enterprise Pipeline plugin.\n\nDuring PuppetConf 2016, myself and Brian Dawson from CloudBees announced the\nplugin:puppet-enterprise-pipeline[Puppet Enterprise\nplugin for Jenkins Pipeline].\nLet’s take a look at how the plugin makes it trivial to use Puppet to perform\nsome or all of the deployment tasks in continuous delivery pipelines.\n\nJenkins Pipeline introduced an amazing world where the definition for a\npipeline is managed from the same version control repository as the code\ndelivered by the pipeline. This is a powerful idea, and one I felt complemented\nPuppet’s automation strengths. I wanted to make it trivial to control Puppet\nEnterprise’s orchestration and infrastructure code management capabilities, as\nwell as set hierarchical configuration data and use Puppet’s inventory data\nsystem as a source of truth – all from a Pipeline script. The result was the\nPuppet Enterprise plugin, which fully buys into the Pipeline ideals by\nproviding methods to control the different capabilities in Puppet Enterprise.\nThe methods provide ways to query\nPuppetDB, set\nHiera key/value pairs, deploy\nPuppet code environments with\nCode Management, and kick off orchestrated Puppet runs with the\nOrchestrator.\n\nThe Puppet Enterprise for Jenkins Pipeline plugin\n\nThe Puppet Enterprise for Jenkins Pipeline plugin itself has zero system\ndependencies. You need only to install the plugin from the update center. The\nplugin uses APIs available in Puppet Enterprise to do its work. Since the\nPuppetDB query, Code Management, and Orchestrator APIs are all\nbacked by Puppet Enterprise’s role-based access control (RBAC) system, it’s\neasy to restrict what pipelines are allowed to control in Puppet Enterprise. To\nlearn more about RBAC in Puppet Enterprise,\nread the docs here.\n\nConfiguring\n\nConfiguring the plugin is fairly straight forward. It takes three simple steps:\n\nSet the address of the Puppet server\n\nCreate a Jenkins credential with a Pupppet Enterprise RBAC authentication token\n\nConfigure the Hiera backend\n\nSet the Puppet Enterprise Server Address\n\nGo to Jenkins > Manage Jenkins > Puppet Enterprise page. Put the DNS address of\nthe Puppet server in the Puppet Master Address text field. Click the Test\nConnection button to verify the server is reachable, the Puppet CA certificate\nis retrievable, and HTTPS connections are successful. Once the test succeeds,\nClick Save.\n\nCreate a Jenkins Credentials Entry\n\nThe plugin uses the Jenkins built-in credentials system (the plain-credentials\nplugin) to store and refer RBAC tokens to Puppet Enterprise for authentication\nand authorization. First, generate an RBAC token in Puppet Enterprise by\nfollowing\nthe\ninstructions on the docs site. Next, create a new Jenkins Credentials item\nwith Kind Secret text and the Secret value the Puppet Enterprise RBAC\ntoken. It’s highly recommended to give the credential an ID value that’s\ndescriptive and identifiable. You’ll use it in your Pipeline scripts.\n\nIn your Jenkinsfile, use the puppet.credentials method to set all future Puppet\nmethods to use the RBAC token. For example:\n\npuppet.credentials 'pe-team-token'\n\nConfigure the Hiera Backend\n\nThe plugin exposes an HTTP API for performing Hiera data lookups for key/value\npairs managed by Pipeline jobs. To configure Hiera on the Puppet compile\nmaster(s) to query the Jenkins Hiera data store backend, use the\nhiera-http backend. On the\nPuppet Enterprise compile master(s), run the following commands:\n\n/opt/puppetlabs/puppet/bin/gem install hiera-http\n/opt/puppetlabs/bin/puppetserver gem install hiera-http\n\nNow you can configure the /etc/puppetlabs/puppet/hiera.yaml file. The following\nconfiguration instructs Hiera to first look to the Hiera yaml files in the\nPuppet code’s environment, then fall back to the http backend. The http backend\nwill first query the Hiera data store API looking for the key in the scope with\nthe same name as the node. If nothing’s found, look for the key in the node’s\nenvironments. You can use any Facter fact to match scope names.\n\n:backends:\n  - yaml\n  - http\n\n:http:\n  :host: jenkins.example.com\n  :port: 8080\n  :output: json\n  :use_auth: true\n  :auth_user:\n:auth_pass:\n:cache_timeout: 10\n  :failure: graceful\n  :paths:\n    - /hiera/lookup?path=%{clientcert}&key=%{key}\n    - /hiera/lookup?path=%{environment}&key=%{key}\n\nFinally, restart the pe-puppetserver process to pick up the new configs:\n\n/opt/puppetlabs/bin/puppet resource service pe-puppetserver ensure=stopped\n/opt/puppetlabs/bin/puppet resource service pe-puppetserver ensure=running\n\nHiera HTTP Authentication\n\nIf Jenkins' Global Security is configured to allow unauthenticated read-only\naccess, the 'use_auth', 'auth_pass', and 'auth_user' parameters are\nunnecessary. Otherwise, create a local Jenkins user that has permissions to\nview the Hiera Data Lookup page and use that user’s credentials for the\nhiera.yaml configuration.\n\nQuerying the infrastructure\n\nPuppetDB is an extensive data store that holds every bit of information Puppet\ngenerates and collects across every system Puppet is installed on. PuppetDB\nprovides a sweet query language called\nPQL. With PQL,\nyou can ask complex questions of your infrastructure such as \"How many\nproduction Red Hat systems are there with the openssl package installed?\" or\n\"What us-west-2c nodes with the MyApp role that were created in the last 24\nhours?\"\n\nThis can be a powerful tool for parts of your pipeline where you need to\nperform specific operations on subsets of the infrastructure like draining a\nloadbalancer.\n\nHere’s an example using the puppet.query method:\n\nresults = puppet.query '''\n  inventory[certname] {\n    facts.os.name = \"RedHat\" and\n    facts.ec2_metadata.placement.availability-zone = \"us-west-2c\" and\n    facts.uptime_hours < 24\n  }'''\n\nThe query returns an array of matching items. The results can be\niterated on, and even passed to a series of puppet.job calls. For example, the\nfollowing code will query all nodes in production that experienced a failure on\nthe last Puppet run.\n\nresults = puppet.query 'nodes { latest_report_status = \"failed\" and catalog_environment = \"production\"}'\n\nNote that once you can use closures in Pipeline scripts, doing the above\nexample will be much simpler.\n\nCreating an orchestrator job\n\nThe orchestration service in Puppet Enterprise is a tool to perform\norchestrated Puppet runs across as broad or as targeted an infrastructure as\nyou need at different parts of a pipeline. You can use the orchestrator to\nupdate applications in an environment, or update a specific list of nodes, or\nupdate nodes across a set of nodes that match certain criteria. In each\nscenario, Puppet will always push distributed changes in the correct order by\nrespecting the cross-node dependencies.\n\nTo create a job in the Puppet orchestrator from a Jenkins pipeline, use the\npuppet.job method. The puppet.job method will create a new orchestrator job,\nmonitor the job for completion, and determine if any Puppet runs failed. If\nthere were failures, the pipeline will fail.\n\nThe following are just some examples of how to run Puppet orchestration jobs against the infrastructure you need to target.\n\nTarget an entire environment:\n\npuppet.job 'production'\n\nTarget instances of an application in production:\n\npuppet.job 'production', application: 'Myapp'\n\nTarget a specific list of nodes:\n\npuppet.job 'production', nodes: ['db.example.com','appserver01.example.com','appserver02.example.com']\n\nTarget nodes matching a complex set if criteria:\n\npuppet.job 'production', query: 'inventory[certname] { facts.os.name = \"RedHat\" and facts.ec2_metadata.placement.availability-zone = \"us-west-2c\" and uptime_hours < 24 }'\n\nAs you can see, the puppet.job command means you can be as broad or as targeted\nas you need to be for different parts of your pipeline. There are many other\noptions you can add to the puppet.job method call, such as setting the Puppet\nruns to noop, or giving the orchestrator a maximum concurrency limit.\nLearn\nmore about the orchestrator here.\n\nUpdating Puppet code\n\nIf you’re using Code Management in Puppet Enterprise (and you should), you can\nensure that all the modules, site manifests, Hiera data, and roles and profiles\nare staged, synced, and ready across all your Puppet masters, direct from your\nJenkins pipeline.\n\nTo update Puppet code across all Puppet masters, use the puppet.codeDeploy method:\n\npuppet.codeDeploy 'staging'\n\nLearn more Code Management in Puppet Enterprise here.\n\nSetting Hiera values\n\nThe plugin includes an experimental feature to set Hiera key/value pairs. There\nare many cases where you need to promote information through a pipeline, such\nas a build version or artifact location. Doing so is very difficult in Puppet,\nsince data promotion almost always involves changing Hiera files and committing\nto version control.\n\nThe plugin exposes an HTTP API endpoint that Hiera can query using the\nhiera-http backend. With the backend configured on the Puppet master(s),\nkey/value pairs can be set to scopes. A scope is arbitrary and can be anything\nyou like, such as a Puppet environment, a node’s certname, or the name of a\nFacter fact like operatingsystem or domain.\n\nTo set a Hiera value from a pipeline, use the puppet.hiera method.\n\npuppet.hiera scope: 'staging', key: 'build-version', value: env.BUILD_ID\n\nNow you can set the same key with the same value to the production scope later\nin the pipeline, followed by a call to puppet.job to push the change out.\n\nExamples\n\nThe\nplugin’s\nGithub repository contains a set of example Pipeline scripts. Feel free to\nissue pull requests to add your own scripts!\n\nWhat’s next\n\nI’m pretty excited to see how this is going to help simplify continuous\ndelivery pipelines. I encourage everyone to get started with continuous\ndelivery today, even if it’s just a simple pipeline. As your practices evolve,\nyou can begin to add automated tests, automate away manual checkpoints, start\nto incorporate InfoSec tests, and include phases for practices like patch\nmanagement that require lots of manual approvals, verifications and rollouts.\nYou’ll be glad you did.","title":"Continuous Delivery with Jenkins and Puppet Enterprise","tags":["continuousdelivery","puppet","pipeline","puppetenterprise"],"authors":[{"avatar":null,"blog":null,"github":"ccaum","html":"","id":"ccaum","irc":null,"linkedin":null,"name":"Carl Caum","slug":"blog/author/ccaum","twitter":"ccaum"}]}},{"node":{"date":"2016-12-19T00:00:00.000Z","id":"584ac2c5-5d3d-5e1c-bcbe-5ef1ef71e42e","slug":"/blog/2016/12/19/declarative-pipeline-beta/","strippedHtml":"Last week we released version 0.7.1 of the\nPipeline-Model-Defintion\nplugin and wanted to crown it as the official Beta version of the Declarative\nPipeline syntax. Although it has been available in the update center\nsince August,\nwe continue to solidify the syntax. We feel this release is getting\nvery close to the final version and should not change much before 1.0. However,\nit is still a Beta so further tweaks are possible.\n\nA release (0.8.0) is planned for early January 2017 which will finalize the\nsyntax with the following changes:\nJENKINS-40524,\nJENKINS-40370,\nJENKINS-40462,\nJENKINS-40337\n\nWhat is Declarative Pipeline?\n\nAll the way back at Jenkins World in September, Andrew Bayer presented a\nsneak peak\nof a new syntax for constructing Pipelines. We are calling this new syntax\nDeclarative Pipeline to differentiate it from the existing Scripted Pipeline\nsyntax that has always been a part of Pipeline.\n\nAfter listening to many Jenkins users over the last year we felt that, while\nPipeline Script provides tremendous power, flexibility, and extensibility, the\nlearning curve for Scripted Pipeline was steep for users new to either Jenkins\nor Pipeline. Beginning users wanting to take advantage of all the features\nprovided by Pipeline and Jenkinsfiles were required to learn Scripted Pipeline\nor remain limited to the functionality provided by Freestyle jobs.\n\nDeclarative Pipeline does not replace Scripted Pipeline but extends Pipeline it\nwith a pre-defined structure to let users focus entirely on the steps\nrequired at each stage without needing to worry about scripting every aspect\nof the pipeline. Granular flow-control is extremely powerful and Scripted\nPipeline syntax will always be part of Pipeline but it’s not for everyone.\n\nDeclarative Pipeline enables all users to connect simple, declarative blocks\nthat define agents (including Docker), post actions, environment\nsettings, credentials and all stages that make up the pipeline. Best of all,\nbecause this Declarative syntax is part of Pipeline, all build steps and build\nwrappers available in Plugins or loaded from Shared Libraries are also\navailable as steps in Declarative.\n\nExample\n\nBelow is an example of a pipeline in Declarative syntax. You can also switch the view to show the same pipeline in Scripted syntax.\n The Declarative syntax has a more straightforward structure that is easier to grok by users not versed in Groovy.\n\n// Declarative //\npipeline {\n  agent  label:'has-docker', dockerfile: true\n  environment {\n    GIT_COMMITTER_NAME = \"jenkins\"\n    GIT_COMMITTER_EMAIL = \"jenkins@jenkins.io\"\n  }\n  stages {\n    stage(\"Build\") {\n      steps {\n        sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n      }\n    }\n    stage(\"Archive\"){\n      steps {\n        archive \"*/target/**/*\"\n        junit '*/target/surefire-reports/*.xml'\n      }\n    }\n  }\n  post {\n    always {\n      deleteDir()\n    }\n    success {\n      mail to:\"me@example.com\", subject:\"SUCCESS: ${currentBuild.fullDisplayName}\", body: \"Yay, we passed.\"\n    }\n    failure {\n      mail to:\"me@example.com\", subject:\"FAILURE: ${currentBuild.fullDisplayName}\", body: \"Boo, we failed.\"\n    }\n  }\n}\n\n// Script //\nwithEnv([\"GIT_COMMITTER_NAME = jenkins\",\"GIT_COMMITTER_EMAIL = jenkins@jenkins.io\"]) {\n  node('has-docker') {\n    try {\n      checkout scm // checks out Dockerfile and source code\n      def myImage = docker.build 'my-environment:snapshot'\n      myImage.inside {\n        stage('Build') {\n          sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n        }\n        stage('Archive') {\n          archive \"*/target/**/*\"\n          junit '*/target/surefire-reports/*.xml'\n        }\n      }\n      if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {\n        mail to:\"me@example.com\", subject:\"SUCCESS: ${currentBuild.fullDisplayName}\", body: \"Yay, we passed.\"\n      }\n    }\n    catch (exc) {\n      mail to:\"me@example.com\", subject:\"FAILURE: ${currentBuild.fullDisplayName}\", body: \"Boo, we failed.\"\n    }\n    finally {\n      deleteDir()\n    }\n  }\n}\n\nHow can you help?\n\nInstall the lastest version of the\nPipeline-Model-Defintion plugin.\n\nRead the documentation:\nGetting Started and\nSyntax overview.\n(These documents will be incorporated into the Jenkins.io documentation.)\n\nConvert some of your existing Pipeline scripts into Declarative\n\nLog any issues or enhancements you have\nhere\nfor the syntax, the execution, or the documentation.\n\nAsk questions. You can send questions to the\nusers mailing list\nor visit the #jenkins channel on IRC.\n\nHow will this work with Blue Ocean?\n\nBlue Ocean is all about Pipelines in Jenkins. Running, displaying, and soon,\ncreating Pipelines.  Blue Ocean will be able to run and display Pipelines\nwritten in this new syntax just like any other Pipeline works today. However,\nbecause Declarative Pipeline includes a pre-defined structure, or model, it is\nnow possible to create and edit pipelines with a GUI editor.\n\nAlthough we plan to launch 1.0 of Declarative Pipeline before Blue Ocean 1.0 is\nofficially available, we expect to have a working Beta of the Editor available\nto play with. The combination of a simple syntax and an intuitive editor\nshould make creating Jenkins Pipelines a breeze.\n\nHappy Holidays\n\nI hope everyone has a great end of the year and a Happy New Year. With\nDeclarative Pipeline and\nBlue Ocean\nwe expect great things for Jenkins in 2017!","title":"Announcing the beta of Declarative Pipeline Syntax","tags":["pipeline","blueocean"],"authors":[{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"blog/author/hrmpw","twitter":"hrmpw"}]}},{"node":{"date":"2016-12-10T00:00:00.000Z","id":"f232c003-357c-5a76-9845-ebc3bcb77896","slug":"/blog/2016/12/10/monthly-jam-recap-november/","strippedHtml":"As we near the end of the year, the number of November JAMs show that the\nJenkins community isn’t slowing down for holiday season. We had a number of\nexcellent events hosted around the world this November with plenty of great\nstories and presentations shared by the various members of the world-wide\nJenkins community.\n\nMelbourne, Australia JAM\n\nMelbourne JAM leaders,\nRaisa\nand\nBhuva\nhosted Blue Ocean for the inaugural meeting. Attendees learned the values of\nBlue Ocean, a project that rethinks the user experience of Jenkins, modeling\nand presenting the process of software delivery by surfacing information that\nis important to development teams with as few clicks as possible, while still\nstaying true to the extensibility that Jenkins always has had as a core value.\nThank you James Dumay for stopping by to take part in\nthe inauguration.\n\nSingapore, Singapore JAM\n\nOne of the members  who had several years of experience using Jenkins (since\nHudson days in fact) to present some basics on Continuous Integration with\nGitHub. It was targeted at new members who are starting out with Jenkins. We\nunderstand that we cannot always serve advanced topics to cater to the\nexperienced users and neglect the newbies so this session was targeted to help\ngive new users an introduction to Jenkins. It went well with about 15-20\nattendees and we hope to run some hands-on workshops in 2017. Some members were\nlooking forward to freebies like stickers and T-shirts too!\n\nMoscow, Russia JAM\n\nMoscow JAM leaders,\nKirill Tolkachev\nand\nOleg Nenashev\nled the inaugural meeting with\na packed full agenda. Oleg began the meeting with an update on Jenkins 2 what improvements users can expect and what\nenhancements are in the works within the Jenkins project. Following Oleg, Kirill shared\nhow his team in Alfa Laboratory used Jenkins to improve CD/DevOps in their\nprojects (with Jenkins Pipeline, Job DSL and\nBlue Ocean), the problems they experienced and how they fixed them. Then Oleg talked\nabout Jenkins Pipeline internals, main features and recent changes in the\necosystem. It was followed up by a discussion of large-scale Jenkins instances\nat the after-party.\n\nThe recording of the event can be found\non YouTube.\n\nMilan, Italy JAM\n\nThe first meetup was a great opportunity to meet local Jenkins fans to learn\nand share Jenkins experiences at a local cafe.\n\nSan Francisco, California JAM\n\nR. Tyler Croy\nperformed a 30 minutes live Pipeline coding demo to a relatively novice\naudience (though all had used Jenkins). A good amount of questions from the\naudience  which conveyed an appetite for the content being presented.\nRyan Wallner,\npresenter from ClusterHQ, also gave a demo based around Pipeline talking about\nClusterHQ’s \"Fli\" integration with a delivery pipeline.\n\nWashington, DC JAM\n\nThere was a fantastic 90% showup rate at this month’s meetup - 58 RSVPs and 52\nin attendance was pretty impressive. All this may be due to Fannie Mae’s story\n- the success of how they used Jenkins for CI/CD as part of their DevOps\nadoption. Afterwards, there was a lot of interests and further discussions\ntaking place. Next month’s host will be Freddie Mac.\n\nSeattle, Washington JAM\n\nLong time Jenkins community member and Seattle JAM leader,\nKhai Do showed how OpenStack uses \"Jenkins Job\nBuilder\" to manage and run thousands of Jenkins jobs per day in their\nmulti-controller CI/CD system.  He also compared\nJenkins Job Builder\nwith other Jenkins \"Infrastructure-as-code\" technologies - Jenkins Pipeline and\nJenkins JobDSL. It was followed by an in-depth Q&A and discussion session.\n\nDallas/Forth Worth, Texas (DFW) JAM\n\nThe November DFW JAM was the most strongly attended of the year! DFW JAM leader,\nEric Smalling discussed the benefits of\ndynamic build agents and demonstrated various ways to implement them such as\nthe EC2 and Docker plugins. There was a lot of interest and discussion,\nespecially around Docker and the ability it provides to have ephemeral agents\nwith very little provisioning time.\n\nThe recording can be downloaded from\nGooel Drive.\n\nLinks\n\nStart a JAM in your city if there isn’t one already.\n\nBecome a JAM member.\n\nBecome an online JAM member\n\nBe a JAM speaker or sponsor. Let us know jenkinsci-jam@googlegroups.com\n\nBecome a Jenkins project contributor","title":"Monthly JAM Recap - November 2016","tags":["event","jam","meetup"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"blog/author/alyssat","twitter":null}]}},{"node":{"date":"2016-12-09T00:00:00.000Z","id":"08ea2c86-7b22-5481-88a2-4bdcb1cfe5be","slug":"/blog/2016/12/09/december-jenkins-events/","strippedHtml":"Happy Holidays! A special shout out to all JAM leaders who continue to keep\nlocal activities going in December.\n\nOnline JAM\n\nDecember 14 | Live Demos: Pipeline, Git, and Blue Ocean\n\nNorth America\n\nDecember 7 | Seattle JAM: Jenkins at Microsoft\n\nDecember 14 | Los Angeles JAM: Jenkins Days\n\nDecember 14 | Guadalajara JAM: Jenkins & Docker\n\nAustralia\n\nDecember 14 | Melbourne JAM: Meeting at AWS Office\n\nLinks\n\nStart a JAM in your city if there isn’t one already.\n\nBecome a JAM member\n\nBecome an online JAM member\n\nSpeak or sponsor at a JAM. Contact us at jenkinsci-jam@googlegroups.com\n\nBecome a Jenkins project contributor","title":"Upcoming December Jenkins Events","tags":["events","jam"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"alyssat","html":"<div class=\"paragraph\">\n<p>Member of the <a href=\"/sigs/advocacy-and-outreach/\">Jenkins Advocacy and Outreach SIG</a>.\nAlyssa drives and manages Jenkins participation in community events and conferences like <a href=\"https://fosdem.org/\">FOSDEM</a>, <a href=\"https://www.socallinuxexpo.org/\">SCaLE</a>, <a href=\"https://events.linuxfoundation.org/cdcon/\">cdCON</a>, and <a href=\"https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\">KubeCon</a>.\nShe is also responsible for Marketing &amp; Community Programs at <a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>","id":"alyssat","irc":null,"linkedin":null,"name":"Alyssa Tong","slug":"blog/author/alyssat","twitter":null}]}},{"node":{"date":"2016-11-22T00:00:00.000Z","id":"bf7f59a9-58e8-5509-a6f1-6515f7050a5b","slug":"/blog/2016/11/22/what-jvm-versions-are-running-jenkins-the-return/","strippedHtml":"Like for last year’s article about the same subject, yet another recent discussion about finally requiring Java 8 to run future versions Jenkins pushed me to gather some more factual data around it.\n\nWhat follows contains some opinions or statements which may not be seen as purely factual or neutral. Note that this represents by no mean the general position of the Jenkins governance board. This is solely my opinion as a contributor based on the data I gathered, and what I feel from the feedback of the community at large.\n\nJava 8 now the most used version, and growing\n\nIf we look at the global numbers, Java 8 runtimes now represent 52.8% of the Jenkins instances running, which have not opted out of anonymous usage statistics.\n\nAnd if you look at the trend, Java 8 is clearly growing fast.\n\nZooming into the Jenkins 2.x instances subset\n\nNow, if you look at that picture, though already interesting and showing a clear trend towards Java 8 runtime adoption, some might argue it’s being too nice to older JREs.\nThe reasoning could be: instances running (very) old Jenkins versions may not be the ones you want to look at when trying to plan the future of an opensource project:\nthose are indeed probably not going to upgrade in general anyway, or when they do, upgrading the JRE would be a small thing compared to the rest to be tested with such a gap.\n\nSo, if we only keep the instances running Jenkins 2.x, then the proportion of Java 8 goes to almost 70% compared to Java 7 (Jenkins 2.x requires Java 7)\n[ 1 ] :\n\nConclusion\n\nJava 8 adoption numbers are getting bigger, while every other JREs are going down.\n\nIf you are still using a JRE 7 to run Jenkins, it is seriously time to think\nabout upgrading to 8.  Knowing that it’s definitely not a bleeding-edge path\nmight help you go that way, especially if you generally do not like upgrades.\nAlso, as a reminder, the most used JDK,\nOracle JDK 7 now got end-of-lifed more than 18 months ago.\n\nContrary to the past attempts the previous years, the discussion on the Jenkins\ndevelopment mailing list did not trigger strong rebutals by many people.\n\nPerhaps it’s finally time for Mr. Jenkins to upgrade to Java 8!\n\nAll numbers shown below are derived from the new jvms.json file now generated automatically every month, after the two related pull-requests 1 and 2 got merged.\n[ 2 ]\n\n1. 69% for October, 67% in September\n\n2. You are more than welcome to review those Pull-Requests and shout if you see something wrong in the calculations.","title":"What JVM versions are running Jenkins? 2016 Update!","tags":["statistics"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://batmat.net","github":"batmat","html":"<div class=\"paragraph\">\n<p>Baptiste has been using and contributing to Jenkins since it was called differently, and is a huge proponent of the Agile, Devops &amp; Continuous Delivery movements.\nHe loves to discuss not only the technical aspects, but also the even more essential cultural aspects of this all, working together to improve the value provided to customers in a great inclusive and blameless environment.</p>\n</div>","id":"batmat","irc":null,"linkedin":null,"name":"Baptiste Mathus","slug":"blog/author/batmat","twitter":"bmathus"}]}},{"node":{"date":"2016-11-21T00:00:00.000Z","id":"bf6fcc51-7017-5159-91de-3d955a72998d","slug":"/blog/2016/11/21/gc-tuning/","strippedHtml":"This is a\ncross\npost by Sam Van Oort, Software Engineer at\nCloudBees and contributor to the Jenkins project.\n\nToday I’m going to show you how easy it is to tune Jenkins Java settings to\nmake your controllers more responsive and stable, especially with large heap sizes.\n\nThe Magic Settings:\n\nBasics: -server -XX:+AlwaysPreTouch\n\nGC Logging: -Xloggc:$JENKINS_HOME/gc-%t.log -XX:NumberOfGCLogFiles=5 -XX:+UseGCLogFileRotation -XX:GCLogFileSize=20m -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCCause -XX:+PrintTenuringDistribution -XX:+PrintReferenceGC -XX:+PrintAdaptiveSizePolicy\n\nG1 GC settings: -XX:+UseG1GC -XX:+ExplicitGCInvokesConcurrent -XX:+ParallelRefProcEnabled -XX:+UseStringDeduplication -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20 -XX:+UnlockDiagnosticVMOptions -XX:G1SummarizeRSetStatsPeriod=1\n\nHeap settings: set your minimum heap size ( -Xms) to at least 1/2 of your maximum size ( -Xmx).\n\nNow, let’s look at where those came from!  We’re going to focus on garbage\ncollection (GC) here and dig fast and deep to strike for gold; if you’re not\nfamiliar with GC fundamentals\ntake a look at this source.\n\nBecause performance tuning is data driven, I’m going to use real-world data\nselected three very large Jenkins instances that I help support.\n\nWhat we’re not going to do: Jenkins basics, or play with max heap.  See the\nsection \"what should I do before tuning.\"  This is for cases where we really\ndo need a big heap and can’t easily split our Jenkins controllers into smaller\nones.\n\nThe Problem: Hangups\n\nSymptom: Users report that the Jenkins instance periodically hangs, taking\nseveral seconds to handle normally fast requests.  We may even see lockups or\ntimeouts from systems communicating with the Jenkins controller (build agents,\netc).  In long periods of heavy load, users may report Jenkins running slowly.\nApplication monitoring shows that during lockups all or most of the CPU cores\nare fully loaded, but there’s not enough activity to justify it.  Process and\nJStack dumps will reveal that the most active Java threads are doing garbage\ncollection.\n\nWith Instance A, they had this problem.  Their Jenkins Java arguments are very\nclose to the default, aside from sizing the heap:\n\n24 GB max heap, 4 GB initial, default GC settings (ParallelGC)\n\nA few flags set (some coming in as defaults): -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:+ReduceSignalUsage -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation\n\nAfter enabling garbage collection (GC) logging we see the following rough stats:\n\n.\n\nDiving deeper, we get this chart of GC pause durations:\n\nKey stats:\n\nThroughput: 99.64%  (percent of time spent executing application code, not doing garbage collection)\n\nAverage GC time: 348 ms (ugh!)\n\nGC cycles over 2 seconds: 36 (2.7%)\n\nMinor/Full GC average time: 263 ms / 2.803 sec\n\nObject creation & promotion rate: 42.4 MB/s & 1.99 MB/s\n\nExplanations:\n\nAs you can see, young GC cycles very quickly clear away freshly-created\ngarbage, but the deeper old-gen GC cycles run very slowly: 2-4 seconds. This is\nwhere our problems happen.  The default Java garbage collection algorithm\n(ParallelGC) pauses everything when it has to collect garbage (often called a\n\"stop the world pause\"). During that period, Jenkins is fully halted: normally\n(with small heaps) these pauses are too brief to be an issue.  With heaps of 4\nGB or larger, the time required becomes long enough to be a problem: several\nseconds over short windows, and over a longer interval you occasionally see\nmuch longer pauses (tens of seconds, or minutes.)\n\nThis is where the user-visible hangs and lock-ups happen.  It also adds\nsignificant latency to those build/deploy tasks.  In periods of heavy load, the\nsystem was even experiencing hangs of 30+ seconds for a single full GC cycle.\nThis was long enough to trigger network timeouts (or internal Jenkins thread\ntimeouts) and cause even larger problems.\n\nFortunately there’s a solution: the concurrent low-pause garbage collection\nalgorithms, Concurrent Mark Sweep (CMS) and Garbage First (G1). These attempt\nto do much of the garbage collection concurrently with application threads,\nresulting in much shorter pauses (at a slight cost in extra CPU use).  We’re\ngoing to focus on G1, because it is slated to become the default in Java 9 and\nis the official recommendation for large heap sizes.\n\nLet’s see what happens when someone uses G1 on a similarly-sized Jenkins\ncontroller with Instance B (17 GB heap):\n\nTheir settings:\n\n16 GB max heap, 0.5 GB initial size\n\nJava flags (mostly defaults, except for G1): -XX:+UseG1GC -XX:+UseCompressedClassPointers -XX:+UseCompressedOops\n\nAnd the GC log analysis:\n\nKey stats:\n\nThroughput: 98.76%  (not great, but still only slowing things down a bit)\n\nAverage GC time: 128 ms\n\nGC cycles over 2 seconds: 11, 0.27%\n\nMinor/Full GC average time: 122 ms / 1 sec 232 ms\n\nObject creation & promotion rate: 132.53 MB/s & 522 KB/s\n\nOkay, much better : some improvement may be expected from a 30% smaller\nheap, but not as much as we’ve seen.  Most of the GC pauses are well\nunder 2 seconds, but we have 11 outliers - long Full GC pauses of 2-12 seconds.\nThose are troubling; we’ll take a deeper dive into their causes in a second.\nFirst, let’s look at the big picture and at how Jenkins behaves with G1 GC for\na second instance.\n\nG1 Garbage Collection with Instance C (24 GB heap):\n\nTheir settings:\n\n24 GB max heap, 24 GB initial heap, 2 GB max metaspace\n\nSome custom flags: `-XX:+UseG1GC -XX:+AlwaysPreTouch -XX:+UseStringDeduplication  -XX:+UseCompressedClassPointers -XX:+UseCompressedOops `\n\nClearly they’ve done some garbage collection tuning and optimization.  The\nAlwaysPreTouch pre-zeros allocated heap pages, rather than waiting until\nthey’re first used. This is suggested especially for large heap sizes, because\nit trades slightly slower startup times for improved runtime performance.  Note\nalso that they pre-allocated the whole heap.  This is a common optimization.\n\nThey also enabled StringDeduplication, a G1 option introduced in Java 8 Update\n20 that transparently replaces identical character arrays with pointers to the\noriginal, reducing memory use (and improving cache performance).  Think of it\nlike String.intern() but it silently happens during garbage collection.  This\nis a concurrent operation added on to normal GC cycles, so it doesn’t pause the\napplication.  We’ll look at its impacts later.\n\nLooking at the basics:\n\nSimilar picture to Instance B, but it’s hidden by the sheer number of points\n(this is a longer period here, 1 month).  Those same occasional Full GC\noutliers are present!\n\nKey stats:\n\nThroughput: 99.93%\n\nAverage GC time: 127 ms\n\nGC cycles over 2 seconds: 235 (1.56%)\n\nMinor/Full GC average time: 56 ms / 3.97 sec\n\nObject creation & promotion rate: 34.06 MB/s & 286 kb/s\n\nOverall fairly similar to Instance B: ~100 ms GC cycles, all the minor GC\ncycles are very fast.  Object promotion rates sound similar.\n\nRemember those random long pauses?\n\nLet’s find out what caused them and how to get rid of them.  Instance B had 11\nsuper-long pause outliers.  Let’s get some more detail, by opening GC Logs in\nGCViewer.\nThis tool gives a tremendous amount of information.  Too much, in fact —  I\nprefer to use\nGCEasy.io\nexcept where needed.  Since GC logs do not contain compromising information\n(unlike heap dumps or some stack traces), web apps are a great tool for\nanalysis.\n\nWhat we care about are at the Full GC times in the middle (highlighted).  See\nhow much longer they are vs. the young and concurrent GC cycles up top (2\nseconds or less)?\n\nNow, I lied a bit earlier - sorry!  For concurrent garbage collectors, there\nare actually 3 modes: young GC, concurrent GC, and full GC.  Concurrent GC\nreplaces the Full GC mode in Parallel GC with a faster concurrent operation\nthat runs in parallel with the application.  But in a few cases, we are\nforced to fall back to a non-concurrent Full GC operation, which will use the\nserial  (single-threaded) garbage collector.  That means that even if we have\n30+ CPU cores, only one is working. This is what is happening here, and on a\nlarge-heap, multicore system it is S  L  O  W.  How slow?  280 MB/s vs. 12487\nMB/s for Instance B (for instance C, the difference is also about 50:1).\n\nWhat triggers a full GC instead of concurrent:\n\nExplicit calls to System.gc() (most common culprit, often tricky to trace down)\n\nMetadata GC Threshold: Metaspace (used for Class data mostly) has hit the\ndefined size to force garbage collection or increase it.  Documentation is\nterrible for this,\nStack Overflow\nwill be your friend.\n\nConcurrent mode failure: concurrent GC can’t complete fast enough to keep up\nwith objects the application is creating (there are JVM arguments to trigger\nconcurrent GC earlier)\n\nHow do we fix this?\n\nFor explicit GC:\n\n-XX:+DisableExplicitGC will turn off Full GC triggered by System.gc().  Often set in production, but the below option is safer.\n\nWe can trigger a concurrent GC in place of a full one with -XX:+ExplicitGCInvokesConcurrent - this will take the explicit call as a hint to do deeper cleanup, but with less performance cost.\n\nGotcha for people who’ve used CMS: if you have used CMS in the past, you\nmay have used the option -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses — which does what it says.  This option will silently fail in G1, meaning you\nstill see the very long pauses from Full GC cycles as if it wasn’t set (no\nwarning is generated).  I have logged a JVM bug for this issue.\n\nFor the Metadata GC threshold:\n\nIncrease your initial metaspace to the final amount to avoid resizing. For example: -XX:MetaspaceSize=500M\n\nInstance C also suffered the same problem with explicit GC calls, with almost\nall our outliers accounted for (230 out of 235) by slow, nonconcurrent Full GC\ncycles (all from explicit System.gc() calls, since they tuned metaspace):\n\nHere’s what GC pause durations look like if we remove the log entries for the\nexplicit System.gc() calls, assuming that they’ll blend in with the other\nconcurrent GC pauses (not 100% accurate, but a good approximation):\n\nInstance B:\n\nThe few long Full GC cycles at the start are from metaspace expansion — they\ncan be removed by increasing initial Metaspace size, as noted above. The\nspikes?  That’s when we’re about to resize the Java heap, and memory pressure\nis high. You can avoid this by setting the minimum/initial heap to at least\nhalf of the maximum, to limit resizing.\n\nStats:\n\nThroughput: 98.93%\n\nAverage GC time: 111 ms\n\nGC cycles over 2 seconds: 3\n\nMinor & Full or concurrent GC average time: 122 ms / 25 ms (yes, faster than minor!)\n\nObject creation & promotion rate: 132.07 MB/s & 522 kB/s\n\nInstance C:\n\nStats:\n\nThroughput: 99.97%\n\nAverage GC time: 56 ms\n\nGC cycles over 2 seconds: 0 (!!!)\n\nMinor & Full or concurrent GC average time: 56 ms & 10 ms (yes, faster than minor!)\n\nObject creation & promotion rate: 33.31 MB/s & 286 kB/s\n\nSide point: GCViewer is claiming GC performance of 128 GB/s (not unreasonable, we clear ~10 GB of young generation in under 100 ms usually)\n\nOkay, so we’ve tamed the long worst-case pauses!\n\nBut What About Those Long Minor GC Pauses We Saw?\n\nOkay, now we’re in the home stretch!  We’ve tamed the old-generation GC pauses\nwith concurrent collection, but what about those longer young-generation\npauses?  Lets look at stats for the different phases and causes again in\nGCViewer.\n\nHighlighted in yellow we see the culprit: the remark phase of G1 garbage\ncollection. This stop-the-world phase ensures we’ve identified all live\nobjects, and process references (\nmore info).\n\nLet’s look at a sample execution to get more info:\n\n2016-09-07T15:28:33.104+0000: 26230.652: [GC remark 26230.652: [GC ref-proc, 1.7204585 secs], 1.7440552 secs]\n\n [Times: user=1.78 sys=0.03, real=1.75 secs]\n\nThis turns out to be typical for the GC log: the longest pauses are spent in\nreference processing. This is not surprising because Jenkins internally uses\nreferences heavily for caching, especially weak references, and the default\nreference processing algorithm is single-threaded.  Note that user (CPU) time\nmatches real time, and it would be higher if we were using multiple cores.\n\nSo, we add the GC flag -XX:+ParallelRefProcEnabled which enables us to use the multiple cores more effectively.\n\nTuning young-generation GC further based on Instance C:\n\nBack to GCViewer we go, to see what’s time consuming with the GC for Instance C.\n\nThat’s good, because most of the time is just sweeping out the trash\n(evacuation pause).  But the 1.8 second pause looks odd.  Let’s look at the raw\nGC log for the longest pause:\n\n2016-09-24T16:31:27.738-0700: 106414.347: [GC pause (G1 Evacuation Pause) (young), 1.8203527 secs]\n[Parallel Time: 1796.4 ms, GC Workers: 8]\n [GC Worker Start (ms): Min: 106414348.2, Avg: 106414348.3, Max: 106414348.6, Diff: 0.4]\n[Ext Root Scanning (ms): Min: 0.3, Avg: 1.7, Max: 5.7, Diff: 5.4, Sum: 14.0]\n  [Update RS (ms): Min: 0.0, Avg: 7.0, Max: 19.6, Diff: 19.6, Sum: 55.9]\n    [Processed Buffers: Min: 0, Avg: 45.1, Max: 146, Diff: 146, Sum: 361]\n [Scan RS (ms): Min: 0.2, Avg: 0.4, Max: 0.7, Diff: 0.6, Sum: 3.5]\n [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.2]\n [Object Copy (ms): Min: 1767.1, Avg: 1784.4, Max: 1792.6, Diff: 25.5, Sum: 14275.2]\n [Termination (ms): Min: 0.3, Avg: 2.4, Max: 3.5, Diff: 3.2, Sum: 19.3]\n    [Termination Attempts: Min: 11, Avg: 142.5, Max: 294, Diff: 283, Sum: 1140]\n [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.4, Diff: 0.3, Sum: 0.8]\n [GC Worker Total (ms): Min: 1795.9, Avg: 1796.1, Max: 1796.2, Diff: 0.3, Sum: 14368.9]\n [GC Worker End (ms): Min: 106416144.4, Avg: 106416144.5, Max: 106416144.5, Diff: 0.1]\n\n…​oh, well dang. Almost the entire time (1.792 s out of 1.820) is walking\nthrough the live objects and copying them.  And wait, what about this line,\nshowing the summary statistics:\n\nEden: 13.0G(13.0G)->0.0B(288.0M) Survivors: 1000.0M->936.0M Heap: 20.6G(24.0G)->7965.2M(24.0G)]\n\nGood grief, we flushed out 13 GB (!!!) of freshly-allocated garbage in one\nswoop and compacted the leftovers!  No wonder it was so slow.  I wonder how we\naccumulated so much…​\n\nOh, right…​ we set up for 24 GB of heap initially, and each minor GC clears\nmost of the young generation.  Okay, so we’ve set aside tons of space for trash\nto collect, which means longer but less frequent GC periods.  This also gets\nthe best performance from Jenkins memory caches which are using WeakReferences\n(survives until collected by GC) and SoftReferences (more long-lived). Those\ncaches boost performance a lot.\n\nWe could take actions to prevent those rare longer pauses. The best ways are to\nlimit total heap size or reduce the value of -XX:MaxGCPauseMillis=200 from\nits default (200).  A more advanced way (if those don’t help enough) is to\nexplicitly set the maximum size of the young generation smaller (say\n-XX:G1MaxNewSizePercent=45 instead of the default of 60).  We could also\nthrow more CPUs at the problem.\n\nBut if we look up, most pauses are around 100 ms (200 ms is the default value\nfor MaxGCPauseMillis).  For Jenkins on this hardware, this appears to work\njust fine and a rare longer pause is OK as long as they don’t get too\nbig.  Also remember, if this happens often, G1 GC will try to autotune for\nlower pauses and more predictable performance.\n\nA Few Final Settings\n\nWe mentioned StringDeduplication was on with Instance C, what is the impact?\nThis only triggers on Strings that have survived a few generations (most of our\ngarbage does not), has limits on the CPU time it can use, and replaces\nduplicate references to their immutable backing character arrays.\nFor more info, look here.\nSo, we should be trading a little CPU time for improved memory efficiently\n(similarly to string interning).\n\nAt the beginning, this has a huge impact:\n\n[GC concurrent-string-deduplication, 375.3K->222.5K(152.8K), avg 63.0%, 0.0     024966 secs]\n[GC concurrent-string-deduplication, 4178.8K->965.5K(3213.2K), avg 65.3%, 0     .0272168 secs]\n[GC concurrent-string-deduplication, 36.1M->9702.6K(26.6M), avg 70.3%, 0.09     65196 secs]\n[GC concurrent-string-deduplication, 4895.2K->394.9K(4500.3K), avg 71.9%, 0     .0114704 secs]\n\nThis peaks at an average of about ~90%:\n\nAfter running for a month, less of an impact - many of the strings that can be\ndeduplicated already are:\n\n[GC concurrent-string-deduplication, 138.7K->39.3K(99.4K), avg 68.2%, 0.0007080 secs]\n[GC concurrent-string-deduplication, 27.3M->21.5M(5945.1K), avg 68.1%, 0.0554714 secs]\n[GC concurrent-string-deduplication, 304.0K->48.5K(255.5K), avg 68.1%, 0.0021169 secs]\n[GC concurrent-string-deduplication, 748.9K->407.3K(341.7K), avg 68.1%, 0.0026401 secs]\n[GC concurrent-string-deduplication, 3756.7K->663.1K(3093.6K), avg 68.1%, 0.0270676 secs]\n[GC concurrent-string-deduplication, 974.3K->17.0K(957.3K), avg 68.1%, 0.0121952 secs]\n\nHowever it’s cheap to use: in average, each dedup cycle takes 8.8 ms and\nremoves 2.4 kB of duplicates.  The median takes 1.33 ms and removes 17.66 kB\nfrom the old generation.  A small change per cycle, but in aggregate it adds up\nquickly — in periods of heavy load, this can save hundreds of megabytes of\ndata. But that’s still small, relative to multi-GB heaps.\n\nConclusion: turn string deduplication on string deduplication is fairly\ncheap to use, and reduces the steady-state memory needed for Jenkins.  That\nfrees up more room for the young generation, and should overall reduce GC time\nby removing duplicate objects.  I think it’s worth turning on.\n\nSoft reference flushing: Jenkins uses soft references for caching build\nrecords and in pipeline FlowNodes.  The only guarantee for these is that they\nwill be removed instead of causing an OutOfMemoryError…​ however Java\napplications can slow to a crawl from memory pressure long before that happens.\nThere’s an option that provides a hint to the JVM based on time & free memory,\ncontrolled by -XX:SoftRefLRUPolicyMSPerMB (default 1000).  The SoftReferences\nbecome eligible for garbage collection after this many milliseconds have\nelapsed since last touch…​ per MB of unused heap (vs the maximum).  The\nreferenced objects don’t count towards that target.  So, with 10 GB of heap\nfree and the default 1000 ms setting, soft references stick around for ~2.8\nhours (!).\n\nIf the system is continuously allocating more soft references, it may trigger\nheavy GC activity, rather than clearing out soft references. See the open bug\nJDK-6912889\nfor more details.\n\nIf Jenkins consumes excessive old generation memory, it may help to make soft\nreferences easier to flush  by reducing -XX:SoftRefLRUPolicyMSPerMB from its\ndefault (1000) to something smaller (say 10-200).  The catch is that\nSoftReferences are often used for objects that are relatively expensive to\nload, such lazy-loaded build records and pipeline FlowNode data.\n\nCaveats\n\nG1 vs. CMS:\n\nG1 was available on later releases of JRE 7, but unstable and slow. If you\nuse it you absolutely must be using JRE 8, and the later the release the better\n(it’s gotten a lot of patches).  Googling around will show horrible G1 vs CMS\nbenchmarks from around 2014: these are probably best ignored, since the G1\nimplementation was still immature then. There’s probably a niche for CMS use\nstill, especially on midsized heaps (1-3 GB) or where settings are already\ntuned.  With appropriate tuning it can still perform generally well for\nJenkins (which mostly generates short-lived garbage), but CMS eventually suffer\nfrom heap fragmentation and need a slow, non-concurrent Full GC to clear this.\nIt also needs considerably more tuning than G1.\n\nGeneral GC tuning caveats :\n\nNo single setting is perfect for everybody.  We avoid tweaking settings that we\ndon’t have strong evidence for here, but there are of course many additional\nsettings to tweak.  One shouldn’t change them without evidence though, because\nit can cause unexpected side effects.  The GC logs we enabled earlier will\ncollect this evidence.  The only setting that jumps out as a likely candidate\nfor further tuning is G1 region size (too small and there are many humungous\nobject allocations, which hurt performance).  Running on smaller systems,\nI’ve seen evidence that regions shouldn’t be smaller than 4 MB because\nthere are 1-2 MB objects allocated somewhat regularly — but it’s not\nenough to make solid guidance without more data.\n\nWhat Should I Do Before Tuning Jenkins GC:\n\nIf you’ve seen\nStephen Connolly’s excellent Jenkins World talk,\nyou know that most Jenkins instances can and should get by with 4 GB or less of\nallocated heap, even up to very large sizes.  You will want to turn on GC\nlogging (suggested above) and look at stats over a few weeks (remember\nGCeasy.io).\nIf you’re not seeing periodic longer pause times, you’re probably okay.\n\nFor this post we assume we’ve already done the basic performance work for Jenkins:\n\nJenkins is running on fast, SSD-backed storage.\n\nWe’ve set up build rotation for your Jobs, to delete old builds so they don’t pile up.\n\nThe weather column is already disabled for folders.\n\nAll builds/deploys are running on build agents not on the controller. If the controller has executors allocated, they are exclusively used for backup tasks.\n\nWe’ve verified that Jenkins really does need the large heap size and can’t easily be split into separate controllers.\n\nIf not, we need to do that FIRST before looking at GC tuning, because those will have larger impacts.\n\nConclusions\n\nWe’ve gone from:\n\nAverage 350 ms pauses (bad user experience) including less frequent 2+ second generation pauses\n\nTo an average pause of ~50 ms, with almost all under 250 ms\n\nReduced total memory footprint from String deduplication\n\nHow:\n\nUse Garbage First (G1) garbage collection, which performs generally very well for Jenkins.  Usually there’s enough spare CPU time to enable concurrent running.\n\nEnsure explicit System.gc() and metaspace resizing do not trigger a Full GC because this can trigger a very long pause\n\nTurn on parallel reference processing for Jenkins to use all CPU cores fully.\n\nUse String deduplication, which generates a tidy win for Jenkins\n\nEnable GC logging, which can then be used for the next level of tuning and diagnostics, if needed.\n\nThere’s still a little unpredictability, but using appropriate settings gives a\nmuch more stable, responsive CI/CD server…​ even up to 20 GB heap sizes!\n\nFurther Reading:\n\nG1GC fundamentals\n\nMechanicalSympathy: Garbage Collection Distilled\n\nOracle Garbage First Garbage Collector Tuning\n\nOne additional thing\n\nI’ve added -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20 to our\noptions above.  This is covering a complex and usually infrequent case where G1\nself-tuning can trigger bad performance for Jenkins — but that’s material for\nanother post…​","title":"Tuning Jenkins GC For Responsiveness and Stability with Large Instances","tags":["performance","scalability","administration"],"authors":[{"avatar":null,"blog":null,"github":"svanoort","html":"","id":"svanoort","irc":null,"linkedin":null,"name":"Sam Van Oort","slug":"blog/author/svanoort","twitter":null}]}},{"node":{"date":"2016-11-16T00:00:00.000Z","id":"98cc175a-5e42-541a-a6b0-25f3c783cc80","slug":"/blog/2016/11/16/security-updates-addressing-zero-day/","strippedHtml":"A zero-day vulnerability in Jenkins was published on Friday, November 11.  Last\nweek\nwe provided an immediate mitigation\nand today we are releasing updates to Jenkins which fix the vulnerability. We\nstrongly recommend you update Jenkins to 2.32 (main line) or 2.19.3 (LTS) as\nsoon as possible.\n\nToday’s\nsecurity advisory\ncontains more information on the exploit, affected versions, and fixed\nversions, but in short:\n\nAn unauthenticated remote code execution vulnerability allowed attackers to\ntransfer a serialized Java object to the Jenkins CLI, making Jenkins connect to\nan attacker-controlled LDAP server, which in turn can send a serialized payload\nleading to code execution, bypassing existing protection mechanisms.\n\nMoving forward, the Jenkins security team is revisiting the design of the\nJenkins CLI over the coming weeks to prevent this class of vulnerability in the\nfuture. If you are interested in participating in that discussion, please join\nin on the\njenkinsci-dev@\nmailing list.\n\nThe Jenkins project encourages administrators to subscribe to the\njenkinsci-advisories@\nmailing list to receive future Jenkins security notifications.","title":"Security updates addressing zero day vulnerability","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"blog/author/daniel-beck","twitter":null}]}}]}},"pageContext":{"limit":8,"skip":344,"numPages":100,"currentPage":44}},
    "staticQueryHashes": ["3649515864"]}