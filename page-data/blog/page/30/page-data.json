{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/30",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-04-25T00:00:00.000Z","id":"e34fdb6b-09c7-5772-a251-10cec0ccef26","slug":"/blog/2018/04/25/configuring-jenkins-pipeline-with-yaml-file/","strippedHtml":"A few years ago our CTO wrote about building a\nContinuous Integration server for Ruby On Rails using Jenkins and docker.\nThe solution has been our CI pipeline for the past years until we recently decided to\nmake an upgrade. Why?\n\nJenkins version was way out of date and it was getting difficult to\nupgrade\n\nWolox has grown significantly over the past years\nand we’ve been experiencing scaling issues\n\nVery few people knew how to fix any issues with the server\n\nConfiguring jobs was not an easy task and that made our project\nkickoff process slower\n\nMaking changes to the commands that each job runs was not easy and not\nmany people had permissions to do so. Wolox has a wide range of\nprojects, with a wide variety of languages which made this problem even\nbigger.\n\nTaking into account these problems, we started digging into the newest\nversion of Jenkins to see how we could improve our CI. We needed to\nbuild a new CI that could, at least, address the following:\n\nProjects must be built using Docker. Our projects depend on one or\nmultiple docker images to run (app, database, redis, etc)\n\nEasy to configure and replicate if necessary\n\nEasy to add a new project\n\nEasy to change the building steps. Everyone working on the project\nshould be able to change if they want to run npm install or yarn\ninstall.\n\nInstalling Jenkins and Docker\n\nInstalling Jenkins is straightforward. You can visit\nJenkins Installation page and choose the\noption that best suits your needs.\n\nHere are the steps we followed to install Jenkins in AWS:\n\nsudo rpm — import https://pkg.jenkins.io/debian/jenkins.io.key\nsudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo\nsudo yum install java-1.8.0 -y\nsudo yum remove java-1.7.0-openjdk -y\nsudo yum install jenkins -y\nsudo yum update -y\nsudo yum install -y docker\n\nAutomatically adding projects from Github\n\nAdding projects automatically from Github can be achieved using the\nGitHub Branch Source Plugin.\nIt allows Jenkins to scan a GitHub organization\nfor projects that match certain rules and add them to Jenkins\nautomatically. The only constraint that all branches must meet in order\nto be added is that they contain a Jenkinsfile that explains how to\nbuild the project.\n\nEasy to change configuration\n\nNot so easy to change configuration\n\nOne of the biggest pains we had with our previous Jenkins was the\ndifficulty of changing the steps necessary to build the project. If you\nlooked at a project’s build steps, you would find something like this:\n\n#!/bin/bash +x\nset -e\n\n# Remove unnecessary files\necho -e \"\\033[34mRemoving unnecessary files...\\033[0m\"\nrm -f log/*.log &> /dev/null || true &> /dev/null\nrm -rf public/uploads/* &> /dev/null || true &> /dev/null\n\n# Build Project\necho -e \"\\033[34mBuilding Project...\\033[0m\"\ndocker-compose --project-name=${JOB_NAME} build\n\n# Prepare test database\nCOMMAND=\"bundle exec rake db:drop db:create db:migrate\"\necho -e \"\\033[34mRunning: $COMMAND\\033[0m\"\ndocker-compose --project-name=${JOB_NAME} run  \\\n\t-e RAILS_ENV=test web $COMMAND\n\n# Run tests\nCOMMAND=\"bundle exec rspec spec\"\necho -e \"\\033[34mRunning: $COMMAND\\033[0m\"\nunbuffer docker-compose --project-name=${JOB_NAME} run web $COMMAND\n\n# Run rubocop lint\nCOMMAND=\"bundle exec rubocop app spec -R --format simple\"\necho -e \"\\033[34mRunning: $COMMAND\\033[0m\"\nunbuffer docker-compose --project-name=${JOB_NAME} run -e RUBYOPT=\"-Ku\" web $COMMAND\n\nAnd some post build steps that cleaned up the docker:\n\n#!/bin/bash +x\ndocker-compose --project-name=${JOB_NAME} stop &> /dev/null || true &> /dev/null\ndocker-compose --project-name=${JOB_NAME} rm --force &> /dev/null || true &> /dev/null\ndocker stop `docker ps -a -q -f status=exited` &> /dev/null || true &> /dev/null\ndocker rm -v `docker ps -a -q -f status=exited` &> /dev/null || true &> /dev/null\ndocker rmi `docker images --filter 'dangling=true' -q --no-trunc` &> /dev/null || true &> /dev/null\n\nAlthough these commands are not complex, changing any of them required\nsomeone with permissions to modify the job and an understanding ofwhat\nneeded to be done.\n\nJenkinsfile to the rescue…​ or not\n\nWith the current Jenkins version, we can take advantage of\nJenkins Pipeline and model our build\nflow in a file. This file is checked into the repository and, therefore,\nanyone with access to it can change the build steps. Yay!\n\nJenkins Pipeline even has support for:\n\nDocker and\nmultiple\nimages can be used for a build!\n\nSetting environment variables with withEnv and many other built -in\nfunctions that can be found\nhere.\n\nThis makes a perfect case for Wolox. We can have\nour build configuration in a file that’s checked into the repository and\ncan be changed by anyone with write access to it. However, a Jenkinsfile\nfor a simple rails project would look something like this:\n\n# sample Jenkinsfile. Might not compile\nnode {\n    checkout scm\n    withEnv(['MYTOOL_HOME=/usr/local/mytool']) {\n        docker.image(\"postgres:9.2\").withRun() { db ->\n            withEnv(['DB_USERNAME=postgres', 'DB_PASSWORD=', \"DB_HOST=db\", \"DB_PORT=5432\"]) {\n                docker.image(\"redis:X\").withRun() { redis ->\n                    withEnv([\"REDIS_URL=redis://redis\"]) {\n                        docker.build(imageName, \"--file .woloxci/Dockerfile .\").inside(\"--link ${db.id}:postgres --link ${redis.id}:redis\") {\n                            sh \"rake db:create\"\n                            sh \"rake db:migrate\"\n                            sh \"bundle exec rspec spec\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nThis file is not only difficult to read, but also difficult to change.\nIt’s quite easy to break things if you’re not familiar with Groovy and\neven easier if you know nothing about how Jenkins’ pipeline works.\nChanging or adding a new Docker image isn’t straightforward and might\nlead to confusion.\n\nConfiguring Jenkins Pipeline via YAML\n\nPersonally, I’ve always envied simple configuration files for CIs and\nthis time it was our chance to build CI that could be configured using a\nYAML file. After some analysis we concluded that a YAML like this one\nwould suffice:\n\nconfig:\n  dockerfile: .woloxci/Dockerfile\n  project_name: some-project-name\n\nservices:\n  - postgresql\n  - redis\n\nsteps:\n  analysis:\n    - bundle exec rubocop -R app spec --format simple\n    - bundle exec rubycritic --path ./analysis --minimum-score 80 --no-browser\n  setup_db:\n    - bundle exec rails db:create\n    - bundle exec rails db:schema:load\n  test:\n    - bundle exec rspec\n  security:\n    - bundle exec brakeman --exit-on-error\n  audit:\n    - bundle audit check --update\n\n\nenvironment:\n  RAILS_ENV: test\n  GIT_COMMITTER_NAME: a\n  GIT_COMMITTER_EMAIL: b\n  LANG: C.UTF-8\n\nIt outlines some basic configuration for the project, environment\nvariables that need to be present during the run, dependentservices, and\nour build steps.\n\nJenkinsfile + Shared Libraries = WoloxCI\n\nAfter investigating for a while about Jenkins and the pipeline, we found\nthat we could extend it with\nshared libraries.\nShared libraries are written in groovy and can be imported\ninto the pipeline and executed when necessary.\n\nIf you look carefully at this Jenkinsfile,\nwe see that the code is a chain of methods calls that receive a\nclosure, where we execute another method passing a new closure to it.\n\n# sample Jenkinsfile. Might not compile\nnode {\n    checkout scm\n    withEnv(['MYTOOL_HOME=/usr/local/mytool']) {\n        docker.image(\"postgres:9.2\").withRun() { db ->\n            withEnv(['DB_USERNAME=postgres', 'DB_PASSWORD=', \"DB_HOST=db\", \"DB_PORT=5432\"]) {\n                docker.image(\"redis:X\").withRun() { redis ->\n                    withEnv([\"REDIS_URL=redis://redis\"]) {\n                        docker.build(imageName, \"--file .woloxci/Dockerfile .\").inside(\"--link ${db.id}:postgres --link ${redis.id}:redis\") {\n                            sh \"rake db:create\"\n                            sh \"rake db:migrate\"\n                            sh \"bundle exec rspec spec\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nGroovy is flexible enough to allow this same declarative code to be\ncreated at runtime, making our dream of using a YAML to configure our\njob come true!\n\nIntroducing Wolox-CI\n\nThat’s how wolox-ci was born- our\nshared library for Jenkins!\n\nWith wolox-ci, our Jenkinsfile is now\nreduced to:\n\n@Library('wolox-ci') _\n\nnode {\n\n  checkout scm\n\n  woloxCi('.woloxci/config.yml');\n}\n\nNow it simply checks out the code and then calls wolox-ci. The library\nreads yaml file like this one\n\nconfig:\n  dockerfile: .woloxci/Dockerfile\n  project_name: some-project-name\n\nservices:\n  - postgresql\n  - redis\n\nsteps:\n  analysis:\n    - bundle exec rubocop -R app spec --format simple\n    - bundle exec rubycritic --path ./analysis --minimum-score 80 --no-browser\n  setup_db:\n    - bundle exec rails db:create\n    - bundle exec rails db:schema:load\n  test:\n    - bundle exec rspec\n  security:\n    - bundle exec brakeman --exit-on-error\n  audit:\n    - bundle audit check --update\n\n\nenvironment:\n  RAILS_ENV: test\n  GIT_COMMITTER_NAME: a\n  GIT_COMMITTER_EMAIL: b\n  LANG: C.UTF-8\n\nand builds the Jenkinsfile to get your job running on the fly.\n\nThe nice part about having a shared library is that we can extend and\nfix our library in a centralized way. Once we add new code, the library\nis automatically updated in Jenkins which will notify all of our jobs\nwith the update.\n\nSince we have projects in different languages we use Docker to build the\ntesting environment. WoloxCI assumes there is a Dockerfile to build and\nwill run all the specified commands inside the container.\n\nWoloxci config.yml\n\nConfig\n\nThe first part of the config.yml file specifies some basic\nconfiguration: project’s name and Dockerfile location. The Dockerfile is\nused to build the image where the commands will be run.\n\nServices\n\nThis section describes which services will be exposed to the container.\nOut of the box, WoloxCI has support for postgresql, mssql and\nredis. You can also specify the docker image version you want! It is\nnot hard to add a new service. You just need to add the corresponding\nfile at\n\nhttps://github.com/Wolox/wolox-ci/tree/development/vars\n\nand modify how the services are parsed\n\nhttps://github.com/Wolox/wolox-ci/blob/development/src/com/wolox/parser/ConfigParser.groovy#L76\n\nSteps\n\nThe listed commands in this section will run inside the Docker\ncontainer. As a result, you’ll see each of the steps on the Jenkins UI.\n\nEnvironment\n\nIf you need some environment variables during your build, you can\nspecify them here. Whatever variable you set will be available inside\nthe Docker container when your commands listed in the steps section\ndescribed above.\n\nWrapping up\n\nWoloxCI is still being tested with a not-so-small sample of our\nprojects. The possibility of changing the build steps through a YAML\nfile makes it accessible for everyone and that is a great improvement in\nour CI workflow.\n\nDocker gives us the possibility of easily changing the programming\nlanguage without making any changes to our Jenkins installation and\nJenkins’ Github Organization feature automatically adds new projects\nwhen a new repository with a Jenkinsfile is detected.\n\nAll of these improvements have reduced the time we spend maintaining\nJenkins significantly and give us the possibility of easily scaling\nwithout any extra configuration.\n\nThis library is working in our CI but it still can be improved.\nIf you would like to add features, feel free to\ncontribute!","title":"Configuring a Jenkins Pipeline using a YAML file","tags":["jenkins","pipelines","yaml","sharedlibrary"],"authors":[{"avatar":null,"blog":null,"github":"mdesanti","html":"<div class=\"paragraph\">\n<p>Head of Infrastructure &amp; Cloud at <a href=\"https://www.wolox.com.ar\">Wolox</a></p>\n</div>","id":"mdesanti","irc":null,"linkedin":null,"name":"Matias De Santi","slug":"/blog/authors/mdesanti/","twitter":"mdsanti"}]}},{"node":{"date":"2018-04-18T00:00:00.000Z","id":"36cc7fb2-3a58-5fd5-82ce-aa9662b5820b","slug":"/blog/2018/04/18/blueocean-1-5-0/","strippedHtml":"Hello, I am Jenn, the new Product Manager for Blue Ocean and Jenkins\nPipeline at CloudBees. I am based out of the Seattle area and am excited to be\nworking on Jenkins. :D We released version 1.5.0 of the Blue Ocean plugin late last week. If you’re\nusing Blue Ocean, you’ll want to grab this update since it includes many\nimprovements and bug fixes!\n\nNew Features\n\nBlue Ocean now includes a user interface update to show the downstream jobs\nlaunched with the 'build' step\n(link: JENKINS-38339)\n\nWith Blue Ocean 1.5.0, users can now Reorder Steps in the Blue Ocean Pipeline\nEditor simply by dragging and dropping steps to reorder them in the list of\nsteps.\n( JENKINS-38323)\n\nThe \"Artifacts\" tab also now supports pagination, which allows developers to\npaginate through the Artifacts tab. Previously, this list\nwas cut off at 100 entries.\n( JENKINS-43588)\n\nImprovements\n\nWe were able to include two performance improvements in 1.5.0 which reduce the\nDashboard loading time in Blue Ocean:\n\nJENKINS-44995\n\nJENKINS-48868\n\nSupport for viewing output for failed runs with no stages is also included in\nthis release. For developers who have no stages/steps defined in their\npipelines, they can now see the full log output for failed runs. This update\nhelps with Pipeline debugging in Jenkins.\n( JENKINS-48074)\n\nFurther improving the log output for Pipeline Runs, 1.5.0 also improves viewing\nof long log output lines with wrapping.  Previously, a single, long line of\noutput in the log wouldn’t be fully visible in the log window.\n( JENKINS-49036)\n\nFixes\n\nOne notable bug fix we addressed in this release was that input steps in\npost directives would not properly prompt for input. By fixing\nJENKINS-49297\nusers of Declarative Pipeline with Blue Ocean can include input steps in\ntheir post directives.\n\nThe full detailed change log can be viewed on the\nBlue Ocean plugin page\n\nUpdate Your Plugin\n\nPlugin updates in Jenkins are available in the Plugin Manager Update Center. This page includes instructions for using the UI and CLI to update your plugins: https://jenkins.io/doc/book/managing/plugins/.\n\nIf you are using the Blue Ocean UI, click Administration in the page’s header to open Plugin Manager.\n\nInstalling the primary Blue Ocean plugin will update its dependencies as well.\n\nProviding Feedback\n\nChat with us at Gitter: https://gitter.im/jenkinsci/blueocean-plugin\n\nReport issues at https://issues.jenkins.io/","title":"Faster sailing on Blue Ocean 1.5.0","tags":["blueocean"],"authors":[{"avatar":null,"blog":null,"github":"jennbriden","html":"<div class=\"paragraph\">\n<p>Jenn Briden is located in the Seattle area and is the Product Manager for the Blue Ocean plugin and the Jenkins pipeline. She has previously worked at Microsoft and ExtraHop Networks. Jenn likes drinking coffee but hasn&#8217;t ever seen a bigfoot.</p>\n</div>","id":"jennbriden","irc":null,"linkedin":null,"name":"Jenn Briden","slug":"/blog/authors/jennbriden/","twitter":"jennbriden"}]}},{"node":{"date":"2018-04-16T00:00:00.000Z","id":"5bccde5f-c4ec-5989-8dc2-3f6097a019eb","slug":"/blog/2018/04/16/jenkins-x-explained-part1/","strippedHtml":"Jenkins X is an opinionated platform for providing CI / CD on top of\nKubernetes.\nWe’ve chosen a set of core applications that we install and wire together so things work out-of-the-box, providing a\nturn key experience. This blog aims to build on previous introductions to Jenkins X and provide a deeper\ninsight to what you get when you install Jenkins X.\n\nSo what happens? After downloading the jx CLI you will now be able to create clusters with public cloud providers\nor install onto an existing Kubernetes cluster.\n\nThis command will create a cluster on your cloud provider of choice.\n\njx create cluster\n\nAlternatively you can bring your own Kubernetes cluster and install Jenkins X on it:\n\njx install\n\nThat said, we’ve found that creating a new cluster on a public cloud such as GKE\nis a lot way easier to start as we can be sure of the state of the cluster.\nFor example we know that storage, networking and loadbalancers will be working as expected.\nCreating a cluster on GKE takes only a few minutes so it’s a great way to try things out as well as run your\nenterprise workloads.\n\nFor now lets assume we are using GKE. When jx create cluster has finished you will see some output in the\nterminal that also includes the default admin password to use when logging into the core applications below.\nThere is a flag --default-admin-password you can use to set this password yourself.\n\nAccessing applications\n\nWe automatically install an Nginx ingress controller running with an external loadbalancer pointing at it’s\nKubernetes service. We also generate all the Kubernetes Ingress rules using a golang library called\n\" exposecontroller\".\nThis runs as a Kubernetes Job triggered by a\nHelm hook once any application is installed to the cluster.\n\nUsing \"exposecontroller\" means we can control all the ingress rules for an environment using a single set of\nconfigurations, rather than each application needing to know how to expose the kubernetes service to the outside world.\nThis also means we can easily switch between HTTP and HTTPS plus support intregration with projects like\ncert-manager for auto generation of signed TLS certificates.\n\nEnvironments\n\nOne important point to make is Jenkins X aims to use terminology that developers are familiar with. That’s not\nto say we are changing Kubernetes fundamentals, it’s more that if you don’t know Kubernetes concepts then we aim\nto help you still adopt the cloud technology and pull back the curtain as you gain confidence and experience.\nTo that point, a core part of Jenkins X are \"environments\". An environment can have one or more applications running\nin it. In Kubernetes term an \"environment\" maps to the concept of a \"namespace\" in code.\n\nThe installation by default created three environments, this is customisable but by default we have a \"dev\", a \"staging\"\nand a \"production environment\". To list, select, or switch between these environments run:\n\njx env\n\nJenkins X core applications\n\nIn the \"dev\" environment we have installed a number of core applications we believe are required at a minimum\nto start folks off with CI/CD on Kubernetes. We can easily add to these core apps using Jenkins X addons but\nfor now lets focus on the core apps. Jenkins X comes with configuration that wires these services together,\nmeaning everything works together straight away. This dramatically reduces the time to get started with Kubernetes\nas all the passwords, environment variables and config files are all setup up to work with each other.\n\nJenkins — provides both CI and CD automation. There is an effort to decompose Jenkins over time to\nbecome more cloud native and make use of Kubernetes concepts around CRDs, storage and scaling for example.\n\nNexus — acts as a dependency cache for Nodejs and Java applications to dramatically improve build\ntimes. After an initial build of a SpringBoot application the build time is reduced from 12 mins to 4. We\nhave not yet but intend to demonstrate swapping this with Artifactory soon.\n\nDocker Registry — an in cluster docker registry where our pipelines push application images, we will\nsoon switch to using native cloud provider registries such as Google Container Registry, Azure Container\nRegistry or Amazon Elastic Container Registry (ECR) for example.\n\nChartmuseum — a registry for publishing Helm charts\n\nMonocular — a UI used for discovering and running Helm charts\n\nHelm\n\nWe learned a lot in our early days with fabric8 on Kubernetes and there were some projects from the ecosystem\nthat either weren’t around or (at the time) didn’t work with OpenShift, therefore we were restricted when\nmaking some design decisions. A couple of years on and now with Jenkins X we were able to look at other OSS\nprojects that have been flourishing, so I was very happy to start looking at Helm.\nHelm is a package manager for Kubernetes and allows easy installation and upgrades of applications.\n\nIt was pretty clear that for Jenkins to evolve and include deployments to the cloud we should embrace Helm\nand provide an opinionated experience that helps teams and developers. The core applications mentioned above\nmeans Jenkins X provides an out of the box integrated CI/CD solution for Helm.\n\nWe know that helm has limitations but with the work on\nHelm 3, the focus of the Kubernetes\nsig-apps group, the Kubernetes community and investment we see from key organisations such as Microsoft, we feel Helm\nis currently the best way to install and upgrade applications on Kubernetes.\n\nGitOps\n\nWe mentioned earlier that we setup three environments by default. What this means is for the staging and production\nenvironments we created:\n\nKubernetes namespace\n\nAn environment resource ( CustomResourceDefinition)\nin the dev environment which includes details of how applications are promoted to it and includes various team\nsettings.\n\nA git repository that we store what applications and their versions should be present in that environment.\nThese are stored in a Helm requirements.yaml file\n\nA Jenkins Pipeline job: explained in more detail below\n\nCI/CD for Environments\n\nHaving a Jenkins Pipeline Job for each environment means that Pull Requests to the git repo trigger a CI\njob.  For now that job performs basic validation but in the future will include ‘gates’ to ensure a change to that\nenvironment has passed expected checks such as QA tasks, gain enough approvals from the correct people, etc -\nYES CI for environments!\n\nOnce CI checks have passed the new application or version change can be merged. Only users that have karma\ncan merge the Pull Request and therefore we get RBAC plus traceability for our environment deployments.\n\nThis means every application manifest, their version and configuration including storage requirements, resource\nneeds and secrets for your environments are stored in Git repositories. Given a disaster recovery scenario this\nis exactly what you want.\n\nDid I just say secrets in Git? Yes! We will be providing a nicer experience to helps folks get set up but we\nourselves encrypt our secrets and  store them in Git, then decrypt them when we come to install and upgrade.\n\nHere’s our Git repo https://github.com/jenkins-x/cloud-environments/blob/a1edcc6/env-jx-infra/secrets.yaml.\n\nWe do all this with the help of a Helm wrapper called helm secrets.\nI’m working on a followup blog post with examples, better explanations and how to guides + add better integration\nwith JX in the coming weeks.\n\nFancy getting involved?\n\nWe mainly hangout in the jenkins-x Kubernetes slack channels and for tips on\nbeing more involved with Jenkins X take a look at our contributing docs\n\nIf you’ve not already seen it here’s a video showing the create cluster explained in this blog.","title":"Jenkins X Explained Part 1 - an integrated CI/CD solution for Kubernetes","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/jrawlings.jpeg"},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings/","twitter":"jdrawlings"}]}},{"node":{"date":"2018-04-13T00:00:00.000Z","id":"31f8965a-bc62-54ab-a155-4d858e063b0e","slug":"/blog/2018/04/13/jenkins-x-23-days-later/","strippedHtml":"Its been 24 days since we\nannounced Jenkins X,\na CI/CD solution for modern cloud applications on Kubernetes.\nI’m truly blown away by the response and feedback from the community - thank you!\n\nWe’ve also had lots of folks report they’ve successfully used Jenkins X\non a number of clouds including GKE, AWS and AKS along with on-premises clusters which is great to hear!\n\nHere’s a brief overview of the changes in the last 24 days from the\nRoadmap :\n\nwe now fully support GitHub and GitHub enterprise. BitBucket cloud and gitea is almost there too.\nHopefully BitBucketServer and Gitlab are not too far away either. For more detail see\nsupporting different git servers\n\nFor issue tracking we support GitHub, GitHub Enterprise and JIRA. For more detail see\nsupporting issue trackers\n\nGradle support is now available from jx create spring\nor by importing gradle apps\n\nGo, Node and Rust build packs are now available with more planned\n\nNew addons for anchore and kubeless\n\nAlso we’ve made it a little bit easier to keep your jx binary up to date continuously. Just type one of the following:\n\njx version will prompt you if there is a new version available\nand if prompted, it will upgrade itself\n\njx upgrade cli will upgrade the jx binary if its available or\njx upgrade platform for the platform\n\nFor more detail on the changes over the last 24 days with metrics please see the\nchangelog generated by Jenkins X\n\nWe’d love to hear your feedback what you think of\nJenkins X and the\nRoadmap - please\njoin the community.\n\nLinks\n\nJenkins X website\n\nDemos\n\nJenkins X JEP proposal","title":"Jenkins X making awesome progress after 24 days","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/19e71/jstrachan.jpg","srcSet":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/77b35/jstrachan.jpg 32w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/d4a57/jstrachan.jpg 64w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/19e71/jstrachan.jpg 128w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/68974/jstrachan.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/ef6ff/jstrachan.webp 32w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/8257c/jstrachan.webp 64w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/6766a/jstrachan.webp 128w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/22bfc/jstrachan.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/jstrachan.jpeg"},"blog":null,"github":"jstrachan","html":"<div class=\"paragraph\">\n<p>James is a long time open source contributor, created the Groovy programming language and Apache Camel integration framework.\nFor the past few years he&#8217;s been working on CI/CD with Kubernetes.</p>\n</div>","id":"jstrachan","irc":null,"linkedin":null,"name":"James Strachan","slug":"/blog/authors/jstrachan/","twitter":"jstrachan"}]}},{"node":{"date":"2018-04-11T00:00:00.000Z","id":"ed222945-0b4b-5227-9e90-64450f40170f","slug":"/blog/2018/04/11/security-updates/","strippedHtml":"We just released security updates to Jenkins, versions 2.116 and 2.107.2, that fix two security vulnerabilities.\n\nFor an overview of what was fixed, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck/","twitter":null}]}},{"node":{"date":"2018-04-10T00:00:00.000Z","id":"de012828-154d-5d83-8b81-e1199eaa8685","slug":"/blog/2018/04/10/opinionated-cd-jenkins-x/","strippedHtml":"I\nrecently wrote\nabout how all the cloud platforms are all in Kubernetes and so are developers.\nIt is an exciting time, but the problem for many is that this is\na huge blank sheet of paper for how to build and deploy applications.\nA white space, a void, a limitless canvas of possibilities.\nInsert metaphors here.\n\nThe problem, as you may guess, is that few people really like or are able to start with a blank canvas.\nI know I prefer to start with something working and iterate towards a solution,\nor be given some rails to stay on (again with the metaphors).\n\nThat’s where the Jenkins X project comes in.\nJenkins X is a Kubernetes-native continuous integration and continuous delivery platform\nfor developing cloud native applications that was recently introduced as a\nJenkins Enhancement Proposal,\nsponsored by James Strachan.\n\nThere is a lot to take in but at it’s heart,\nthis is an open source opinionated way to do continuous delivery with Kubernetes,\nnatively, without necessarily having to learn all the things I talked about in my last blog post.\nI shall attempt to explain what this is all about and why it matters to developers.\nAs someone said on the jenkins-dev mailing list\n“We have the two glued together with baling wire and twine” -\nJenkins X aims to simplify how to work with continuous delivery and Kubernetes.\n\nFirst and most importantly, let’s see the logo:\n\nYou can see the nautical theme leaking through (and Kubernetes).\nWhilst it is called Jenkins X, it is about quite a lot more than Jenkins.\n\nJenkins X makes decisions for you\n\nJenkins X presents itself to you initially as a handy sleek command line\n(a native binary you can install called jx - the debate is on as to how pronounce it).\nLet’s take a tour (sail?):\n\njx import my-app\n\nIf you have an existing project, this will detect what type of project it is, build a pipeline for you (and a bunch of Kubernetes things, like Helm Charts), add it to your project and set it up in GitHub, WebHooks and all, build the project (run the pipeline) and deploy a version to a “staging” environment.\n\nIf it looks ok, you can promote it to production:\n\njx promote --env production --version 1.0.1 my-app\n\nIf something went wrong in production, you can roll back an app to any version (the version numbers are made for you):\n\njx promote --env production --version 1.0.0 my-app\n> jx get apps # list versions\n\nAn environment is a well-established concept for web developers using\ncontinuous delivery: out of the box Jenkins X makes three of them for you\n(dev, staging and production), but you can make as many as you like.\nEnvironments have rules around how things are promoted into them\n(and they also have their own extensible pipelines,\nbut you can just use them as-is to start).\n\nYou can also create a Spring Boot microservice app:\n\njx create spring\n\nAnswer a few questions and it will set everything up for you.\n\nAny changes you make to your app automatically are built,\nand if the build looks good, they go through to the staging environment.\nWebHooks are setup for you (if you are using GitHub) to smooth this over.\n\nFor those looking at starting from pre-made apps, there are \"quickstarts\":\n\njx create quickstart\n\nThey are based on a growing set of starter apps, in a variety of languages and tech stacks.\n\nReview apps for your changes: Each pull request is built/tested,\nand a “review app” is made available in a temporary environment.\nThat means each proposed change, before it goes to the default branch (master),\nhas an environment made (temporary) that it can be tried out in.\nIn GitHub, this shows up as a comment in the pull request:\n\nProject type detection\n\nAs you can see, so far there is no editing or manual creation of pipelines,\nor scripting or setup, just importing or creating your app and go.\nThis is powered by\nDraft “packs”\n(a handy project that came out of Azure).\n What you end up with is a Jenkinsfile in your project repository.\n You may want to edit it one day, or you may be happy with it as is!\n Jenkins is famous for being un-opinionated in what you do,\n but Jenkins X has strong opinions (but you can extend and customise).\n\nimage::/images/jenkins-x/draft-logo.png[Draft Logo, width=300]\n\nDeploying or promoting to environments\n\nDeploying happens via pipelines behind the scenes -\nwhen a change is pushed, or a version promoted.\nYou don’t need to directly interact with Kubernetes if you don’t need to.\nA tool called Helm does the heavy lifting:\nHelm is used to package and perform installations and upgrade for your apps.\n\nThere is a little more magic going on here with environments, which you don’t see at first.\nEach environment, for a team, is represented by a Git repository behind the scenes.\nConfiguration as code is a well-established best practice these days,\nso why not use it to track deployments and initiate deployments.\nI also mentioned in my previous post how declarative Kubernetes is:\nit is perfect for keeping all config in a repository, of the desired system state.\n\nEach promotion is actually a pull request to a per-environment repository.\nThis repository is made and managed for you (and kept outside of the\nmain application code repository), you don’t have to look at it,\nbut you can extend things there should you need to.\nSpecific environment repositories may have different access rules,\nor be controlled by a different team (perhaps even deploy to a different cluster).\nSome have coined the term for this as “GitOps.”\nI first came across this concept on a\nWeaveWorks blog.\n\nI’ll try and explain this one with a diagram:\n\nThe pipeline is actually split in the middle.\nOn the left is the more familiar continuous integration pipeline.\nThis works on pull requests, pre-release version of things\nand is all about testing(automated and manual review).\nThe source of truth for this is the configuration in the\napplications repository: branches, pull requests and so on.\n\nThe right-hand side is the continuous delivery pipeline.\nThis kicks in when the application is ready to be updated with a new release.\nThis is the “GitOps” repo behind the scenes that controls the state of things in Kubernetes.\nA promotion on this side is a pull request, and then a merge,\nfrom the staging repository to the production repository.\n\nInstalling Jenkins X\n\nThe jx command line has a jx install command that installs it into a Kubernetes cluster.\n\nThe best experience initially is using Google’s excellent GKE service:\n\njx create cluster gke\n\nThis will ask a few questions, and go and set it all up for you in a\ncluster set aside for Jenkins X (recommended).\nJenkins X runs entirely as services on top of a Kubernetes cluster.\n\njx install\n\nIs designed to work with a Kubernetes cluster (if it already exists,\nrecommendation is to have a cluster put aside for Jenkins X if possible).\nAmazon EKS support is coming (mostly it is around testing),\nthat service is in beta/early access so it is still a work in progress,\nas is Microsoft Azures excellent AKS service.\n\nSo where is Jenkins?\n\nGood question, thanks for asking. Well, it is behind the scenes.\nAs you have seen, there was no direct interaction with Jenkins,\nbut it is there, running the pipelines for continuous integration and\ncontinuous delivery of the respective repositories, and orchestrating things with Kubernetes.\n\nIf you run jx get pipelines you can see URLs to the various pipelines\nthat have been setup for you are part of interacting with Jenkins X.\n\nBy the way,\nJames Strachan has written an extensive blog on jenkins.io\nthat really explores the Jenkins X project in-depth.\nOnce you finish reading this blog, take a stroll on over there and read James'.\nHe also provides several ways you can get involved in the project.\n\nWhat else can I do with the command line?\n\nLots, the jx command line has built in help:\n\njx open\n\nopen apps, services or pipelines in your browser\n\njx activity\n\nexplains how things got to where they are, a history\n\njx get environments\n\nlist environments\n\njx get apps\n\nshow the state of applications, what versions are in what environments.\n\nWhat’s next\n\nThere is a whole lot more to this, and lots more moving parts and services\nthat are set up for you that are very useful, but it is best to head over\nto jenkins-x.io and have a look.\n\nThis project is obviously in early stages (it is stll a Draft JEP after all) and there is lots happening.\nCheck out the Jenkins X community\nif you want to chat on slack, IRC, issues or email.\nAlso, read the\nJenkins Enhancement Proposal doc.","title":"Opinionated Kubernetes and Jenkins X","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg","srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/77b35/michaelneale.jpg 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/d4a57/michaelneale.jpg 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/ef6ff/michaelneale.webp 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/8257c/michaelneale.webp 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/6766a/michaelneale.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/michaelneale.jpg"},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/authors/michaelneale/","twitter":"michaelneale"}]}},{"node":{"date":"2018-04-09T00:00:00.000Z","id":"3494cf73-5468-5673-9163-ca20378f0110","slug":"/blog/2018/04/09/whats-in-declarative/","strippedHtml":"Last week we released the latest version of Declarative Pipelines, version\n1.2.8. With that out, we thought now would be a good time to introduce you to\nthe new features and options that have been added to Declarative since the\nbeginning of 2018. These are all available now in the Update Center, with\nversion 1.2.8.\n\nDeclarative Directive Generator\n\nThis is something we’re really happy about - if you go to the \"Pipeline Syntax\"\nlink from your Pipeline’s page in Jenkins, you’ll see a couple new links on the\nleft, including \"Declarative Directive Generator\". The Directive Generator is\nmuch like the Snippet Generator that’s been in Pipeline for a couple years now,\nbut where the Snippet Generator is just for filling out a form for a step and\ngenerating the Pipeline code that configuration maps to, the Directive\nGenerator is built to help you write your Declarative Pipeline directives, like\nagent, options, stage, and more!\n\nThis is the first release to include the Directive Generator, and it’s\ndefinitely going to see more polish going forward, but we think it should be\nquite helpful for you already. We’ll be putting up another blog post looking at\nthe Directive Generator in more detail in the near future.\n\nNew when conditions\n\nWe’ve added a number of new when conditions, providing you more control over\nwhether your stages get executed.\n\nequals - Compares two values - strings, variables, numbers, booleans - and\nreturns true if they’re equal. I’m honestly not sure how we missed adding\nthis earlier! You can do \"not equals\" comparisons using the not { equals …​\n} combination too.\n\nchangeRequest - In its simplest form, this will return true if this\nPipeline is building a change request, such as a GitHub pull request. You can\nalso do more detailed checks against the change request, allowing you to ask\n\"is this a change request against the master branch?\" and much more.\n\nbuildingTag - A simple condition that just checks if the Pipeline is\nrunning against a tag in SCM, rather than a branch or a specific commit\nreference.\n\ntag - A more detailed equivalent of buildingTag, allowing you to check\nagainst the tag name itself.\n\nIn addition, we’ve added a new option to when : beforeAgent. This allows you\nto specify that the when conditions should be evaluated before entering the\nagent for the stage, rather than the normal behavior of evaluating when\nconditions after entering the agent. When beforeAgent true is specified,\nyou will not have access to the agent’s workspace, but you can avoid\nunnecessary SCM checkouts and waiting for a valid `agent to be available. This\ncan speed up your Pipeline’s execution in some cases.\n\nNew post conditions\n\nThe changed condition has always been a bit confusing, and to be\nhonest, it wasn’t our best work. changed will fire any time the current run’s\nstatus is different than the previous run’s status - whether the current run is\nhealthier than the previous one, or the other way around. That’s…​not actually\nvery useful. So now we’ve added two new post conditions that should provide\nyou with a lot more value than changed has.\n\nfixed - This will check to see if the current run is successful, and if the\nprevious run was either failed or unstable.\n\nregression - This will check to see if the current run’s status is worse\nthan the previous run’s status. So if the previous run was successful, and\nthe current run is unstable, this will fire and its block of steps will\nexecute. It will also run if the previous run was unstable, and the current\nrun is a failure, etc.\n\nNew options\n\nThe options directive in Declarative can contain a number of different kinds\nof configuration: traditional Jenkins job properties, like buildDiscarder,\nwrapper steps to execute the entire Pipeline within, like timeout, and\nDeclarative-specific options that can switch from some default behaviors of\nDeclarative execution. We’ve added two new Declarative-specific options in the\nlast few releases.\n\ncheckoutToSubdirectory - Allows you to override the location that the\nautomatic SCM checkout will use. Using checkoutToSubdirectory(\"foo\"), your\nPipeline will checkout your repository to\"$WORKSPACE/foo\", rather than the\ndefault of\"$WORKSPACE\".\n\nnewContainerPerStage - If you’re using a top-level docker or dockerfile\nagent, and want to ensure that each of your stages run in a fresh container\nof the same image, you can use this option. Any stage without its own\nagent specified will run in a new container using the image you’ve\nspecified or built, on the same computer and with access to the same\nworkspace.\n\nStage options\n\nSometimes, you may only want to disable automatic checkout of your repository,\nusing the skipDefaultCheckout(true) option, for one specific stage in your\nPipeline. Or perhaps you want to have a timeout that covers an entire\nstage, including time spent waiting for a valid agent, post condition\nexecution, or the new input directive for stages (see further down for more\ndetails on that!). To make those things possible, we’ve added a new options\ndirection to stage. You can use a subset of the top-level options content\nin a stage’s `options - wrapper steps, and Declarative-specific options that\nare marked as legal in a stage.\n\nInput\n\nYou’ve always been able to run the input step inside a stage’s `steps\nblock, but we’ve found that approach can lose out on some of the value that the\ninput step provides.\n\nTo help with that, we’ve added a new input directive\nto stage, with the same parameters as the input step. When you use the\nstage input directive rather than using the step directly, any parameters\nyou’ve specified for the input will be made available in the stage’s\nenvironment, meaning you can reference parameters from the `input in when\nconditions, or in environment variables.\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Example') {\n            input {\n                message \"Should we continue?\"\n                ok \"Yes, we should.\"\n                submitter \"alice,bob\"\n                parameters {\n                    string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n                }\n            }\n            agent any\n            steps {\n                echo \"Hello, ${PERSON}, nice to meet you.\"\n            }\n        }\n    }\n}\n// Script //\n\nAlso, the input directive is evaluated before you enter any agent specified\non this stage, so if you are using a top-level agent none and each stage\nhas its own agent specified, you can avoid consuming an executor while\nwaiting for the input to be submitted.\n\nLastly, you can use timeout in the stage options, as\nmentioned above, to time-out the input if too much time has passed without a\nresponse.\n\nI hope you find these new features and options for Declarative Pipelines\nhelpful, and I look forward to the rest of 2018 as we continue to invest and\nimprove in Jenkins Pipeline!","title":"The new things arriving in Declarative Pipeline!","tags":["pipeline","declarative"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer/","twitter":"abayer"}]}},{"node":{"date":"2018-04-06T00:00:00.000Z","id":"f074f9a0-3eb3-5f51-9a32-4b65a80079ce","slug":"/blog/2018/04/06/jenkins-essentials/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nIn his presentation at the 2017 Jenkins World Contributor Summit,\nKohsuke\nchallenged us to continue the work started with Jenkins 2 of making Jenkins\neasier to install and easier to use. \"A user should be successful with Jenkins\nin under five minutes and five clicks.\" At that same Contributor Summit, a few\nof us discussed the idea of a distribution which had \"batteries\nincluded\", which\nAndrew\nproudly named \"Jenkins Essentials.\" At the time I was certainly not as excited\nabout the project as I am now, I thought to myself \"we built a Setup Wizard in\nJenkins 2, nobody needs a Setup Wizard++.\"\n\nAs Kohsuke and I continued to discuss the idea, more and more ideas came up.\nTowards the end of 2017 the picture became much clearer: Jenkins Essentials\nwould be a comprehensive, low-maintenance distribution to help new and\nexisting users be successful with Jenkins, without needing to be Jenkins\nexperts. This will of course not replace the existing distribution of Jenkins core and\nits plugins, which allow many of us large amounts of flexibility, but rather it\nwill make Jenkins easier for users who don’t want to \"build it themselves.\"\n\nThe more I thought about it, the more excited about the idea I became: Jenkins\nEssentials could open the door to new improvements and features in Jenkins\nwhich had been left in the \"idea and design\" phase going back almost two\nyears! Really, I checked, some of the concepts adopted into the design of\nJenkins Essentials were first conceived of in early 2016!\n\nKohsuke briefly discussed the project in\nhis previous blog post\nbut in post I wanted to expand on what Jenkins Essentials is, and our\nprogress has been in its development.\n\nWhat’s in Jenkins Essentials\n\nA few months ago I prepared\nthis presentation\nfor the\nFOSDEM 2018\nJenkins Contributor Summit, which outlines the following \"pillars\" or Jenkins\nEssentials, which are also described in\nJEP-300 :\n\nAutomatically Updated Distribution\n\nAutomatic Sane Defaults\n\nConnected\n\nObvious Path to User Success\n\nAutomatically Updated Distribution\n\nIn order to provide an easier-to-use and easier-to-manage Jenkins environment,\nJenkins Essentials will be distributed as an automatically self-updating\ndistribution, containing Jenkins core and a version-locked set of plugins\nconsidered \"essential.\" Rather than attempting to mirror the existing Weekly\nand LTS release lines for core, plus some plugin version matrix, Jenkins\nEssentials will update in a manner similar to Google Chrome.\n\nThis automatically updating distribution will mean that Jenkins Essentials will\nrequire significantly less overhead to manage, receiving improvements and bug\nfixes without any user involvement. From the user perspective, their Jenkins\nwill appear to automatically improve over time.\n\nThere is really interesting work being pioneered by\nBaptiste Mathus\nwith\nJEP-302\nto ensure that these automatic upgrades can be performed safely.\n\nAutomatic Sane Defaults\n\nProviding a core along with \"essential\" plugins is a good first step to helping\nJenkins users successfully automate their CI/CD workloads, but requires\nadditional \"smoothing\" over some of the numerous options and configurations\nplugins. Jenkins Essentials will perform some amount of \"automatic\nenvironment-based self-configuration.\"\n\nFor example, clicking a \"Launch Stack\" button from the Download\npage would launch an AWS-flavored Jenkins Essentials which, out of the box\nattempts to set up AWS-specific configuration with S3 and EC2 services.\n\nConnected\n\nIn order to provide a more seamless experience for end-users, and ensure that\nJenkins project developers receive useful error and usage telemetry to drive\nfurther improvements in Jenkins, Jenkins Essentials must necessarily be viewed\nas a \" Connected\" application. This means some yet-to-be-specified number of\nserver-side applications to coordinate updates, receive and process telemetry,\nbroker 3rd-party service authentications, relay webhooks, etc.\n\nObvious Path to User Success\n\nThe final pillar in Jenkins Essentials, is to ensure that Jenkins provides an\nobvious path for a user to configure and use it successfully. This largely\nentails in-application documentation, examples, and disabling legacy\nfunctionality within the application. All with the end goal of preventing users\nfrom inadvertently choosing legacy, or poorly supported, options when\nconfiguring their CI/CD workloads.\n\nProgress thus far\n\nSuffice it to say, Jenkins Essentials is a hugely ambitious project! We have\nbeen making steady progress however, as you can see in the\njenkins-infra/evergreen\nrepository on GitHub. We have been adamantly following the\nJenkins Enhancement Proposal\nprocess, and have been making sure our designs and implementations are clear as\nwe build them. Thus far we’ve written designs and implemented:\n\nJEP-300: Jenkins Essentials\n\nJEP-301: Evergreen packaging for Jenkins Essentials\n\nJEP-302: Evergreen snapshotting data safety system\n\nJEP-303: Evergreen Client Registration and Authentication\n\nJEP-304: Essentials Client Error Telemetry Logging\n\nUnfortunately we don’t yet have the first parts of the Automatically Updated Distribution working,\nwhich means you cannot download Jenkins Essentials today and get started with\nit. We’re still building the Jenkins-side and server-side components necessary\nto make the full feedback loop operate, without which we would not be able to\nsafely deliver new upgrades to Jenkins Essentials installations.\n\nIf you’re interested in getting involved, you can check out our\nGitter channel\nor our\nJira issues board.\n\nJenkins Essentials is just one major initiative going on in the Jenkins project\nthis year, so I hope you’re as excited as I am for the future of Jenkins!","title":"Jenkins Essentials: five minutes, five clicks","tags":["evergreen"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/rtyler.jpeg"},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler/","twitter":"agentdero"}]}}]}},"pageContext":{"limit":8,"skip":232,"numPages":100,"currentPage":30}},
    "staticQueryHashes": ["3649515864"]}