{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/31",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2018-04-30T00:00:00.000Z","id":"b56ab05f-d077-5b8d-ab93-27f00b4c8c1e","slug":"/blog/2018/04/30/using-the-beta-annotation/","strippedHtml":"This sort of slid under the radar in the middle of some bigger changes\nfor the JEP-202\nreference implementation, so I wanted to call it out now. Arguably this could\ndeserve a retroactive JEP, though I would rather fold it into a JEP for\nJENKINS-49651 (see below).\n\nAs of Jenkins 2.118, or plugin parent POM 3.7, you can mark any Java member\n( class, method, constructor, field, or I suppose also interface,\nenum, or annotation) with API visibility ( protected or public) with an\nannotation :\n\n@Restricted(Beta.class)\n\nThe idea is to announce to potential users of the member that the API\nmay still be in flux and only code prepared to keep up should be using\nit. For an example, 2.118 added a VirtualFile.toExternalURL() method\nthat is being implemented in artifact-manager-s3 and (pending some\nPR merges) called in copyartifact and workflow-basic-steps. We do\nnot necessarily want this to be called yet by unknown parties out\nthere in the Jenkins ecosystem. To enforce that, any attempt to call\nor implement toExternalURL will produce a build failure, unless you\nadd this property to your plugin POM, as these plugins have done:\n\ntrue\n\nWhy? Because there is a chance the design is wrong and it might need\nto be changed—perhaps some upcoming bug fix would demand a boolean\nparameter be added, for example.\n\nUnder the conventional notion of Jenkins API deprecation and compatibility\npolicy, once an API like this makes it into a release version, that is it—we\nmight mark it @Deprecated but we need to maintain compatibility indefinitely,\nand find some way to migrate existing implementations / call sites.\n\nWith the @Beta annotation, that promise is not being made. If it needs\na boolean parameter for some reason, that will be added and those\nthree plugins updated to match; we are not going to bother retaining\nthe original overload and somehow delegating to the new one. This\nsimplification of the developer workflow is important to the use cases\nof Essentials (JEP-3xx), and I would expect the useBeta mark to\nbecome widespread among plugins included in Essentials. Such as the situation\nwhere one team needs to feel\ncomfortable refactoring code under its aegis freely, and the refactored result\nshould be deliverable as a unit to production via the Evergreen distribution\nsystem.\n\nSo that leaves two important questions:\n\nFirst, is the annotation\npermanent, and if not, when should it be removed? I do not think there\nis any hard policy, but the intention is that it should be removed\nonce the API is in more or less widespread use and has held up. For\nthis example, if people start using S3 artifacts, and especially if\nsomeone successfully writes an implementation of artifact storage in\nAzure that uses the API, the concept will have been reasonably proven.\nAt that point we want the API to be used wherever it would make sense,\nand if there is some very belated realization that the design is not\nquite right, we accept the burden of deprecating the original and\nmigrating callers compatibly.\n\nSecond, it is fine and well to say that someone changing the signature\nof a beta toExternalURL is on the hook to update the three plugins\nusing it, but what if a Jenkins admin ( not running Essentials, for\nshame) upgrades to (say) Jenkins 2.125 with the new signature but\ndeclines to accept the updates to those plugins (say,\nworkflow-basic-steps 2.9) which adapt to the change? It is not\nenough to say that it is their fault for holding back on the updates\narbitrarily; the plugin manager offers you updates but does nothing\nto tell you when they are required, so suddenly throwing\nNoSuchMethodError is not a helpful response.\n\nThe solution needs to be ironed out, but my expectation is to use\nJENKINS-49651\nfor this. For example, workflow-basic-steps 2.8,\nusing toExternalURL(), would have declared itself compatible with\nJenkins-Version: 2.118, and thus implicitly anything newer. The\ndeveloper doing the refactoring would also amend some 2.125 (and\nnewer) core metadata to say that it conflicts with anything older than\nthe 2.9 release of the plugin. The plugin manager would therefore\nblock the 2.8 plugin from even being loaded on the 2.125 core; the\nadmin would need to update before using it. In the case of an\nincompatible change made to a plugin API, rather than a core API, the\nUX is a little smoother since the plugin manager could just refuse to\nlet you update one without the other.\n\nIf you’re a plugin or core developer who is interested in using the @Beta\nannotations, or have questions about our motiviations, please join the\ndiscussion on\nthis mailing list thread.","title":"Using new core APIs with the Beta annotation","tags":["core","developer","plugin"],"authors":[{"avatar":null,"blog":null,"github":"jglick","html":"<div class=\"paragraph\">\n<p>Jesse has been developing Jenkins core and plugins for years.\nHe is the coauthor with Kohsuke of the core infrastructure of the Pipeline system.</p>\n</div>","id":"jglick","irc":null,"linkedin":null,"name":"Jesse Glick","slug":"/blog/authors/jglick","twitter":"tyvole"}]}},{"node":{"date":"2018-04-27T00:00:00.000Z","id":"3e9f5209-666c-54d9-9dcf-8fcbc3620a51","slug":"/blog/2018/04/27/essentials-versions-are-numbered/","strippedHtml":"Jenkins Essentials has been renamed to Jenkins Evergreen since this was written.\n\nA couple weeks ago, I\nwrote about the Jenkins Essentials\neffort, on which we’ve been making steady progress. Personally, the most\nexciting challenge of this project is defining the machinery to drive\nautomatic updates\nof Jenkins Essentials, which viewed from a high level, are classic continuous\ndelivery challenges.\n\nIn this post, I wanted to dive into a bit of the gritty details of how we’re\ngoing to be delivering Jenkins Essentials with automatic updates, which has\nsome really interesting requirements for the development of Jenkins itself.\n\nThe traditional Jenkins core and plugin development workflow involves a\ndeveloper working on changes for some amount of time, then when they’re ready,\nthey \"create a release\" which typically involves publishing artifacts to our\nArtifactory, and then on a timer (typically every 15 minutes) the Update Center will\nre-generate a file called update-center.json. Once the new Update Center has\nbeen generated, it is published and consumed by Jenkins installations within\n24 hours. Of course, only after Jenkins administrators recognize that there is\nan update available, can they install it. All in all, it can take quite a long\ntime from when a developer publishes a release, to when it is successfully used\nby an end-user.\n\nWith our desire to make Jenkins Essentials updates seamless and automatic, the\nstatus quo clearly was not going to work. Our shift in thinking has required a\ncouple simultaneous efforts to make this more continuously delivered approach\nviable.\n\nDeveloper Improvements\n\nStarting from the developer’s workflow,\nJesse Glick\nhas been working on publishing \"incremental builds\" of artifacts into a\nspecial Maven repository\nin Artifactory. Much of his work is described in the very thorough\nJenkins Enhancement Proposal 305.\nThis support, which is now live on\nci.jenkins.io\nallows plugin developers to publish versioned changes from pull requests and\nbranches to the incrementals repository. Not only does this make it much\neasier for Jenkins Essentials to deliver changes closer to the HEAD of\nmaster branches, it also unlocks lots of flexibility for Jenkins developers\nwho coordinate changes across matrices of plugins and core, as occasionally is\nnecessary for Jenkins Pipeline, Credentials, Blue Ocean, and a number of other\nfoundational components of a modern Jenkins install.\n\nIn a follow-up blog post, Jesse is going to go into much more detail on some of\nthe access control and tooling changes he had to solve to make this\nincrementals machinery work.\n\nOf course, incremental builds are only a piece of the puzzle, with those\nartifacts, Jenkins Essentials has to be able to do something useful with them!\n\nUpdate Improvements\n\nThe number one requirement, from my perspective, for the automatically updated\ndistribution is that it is safe. \"Safe\" means that a user doesn’t need to\nbe involved in the update process, and if something goes wrong, the\ninstance recovers without the user needing to do anything to remediate a\n\"bad code deploy.\"\n\nIn my previous post on the subject, I mentioned Baptiste’s work on\nJenkins Enhancement\nProposal 302 which describes the \"data safety\" system for safely applying\nupdates, and in case of failure, rolling back.\n\nThe next obvious question is \"what’s failure?\" which Baptiste spent some time\nexploring and implementing in two more designs:\n\nJEP-304: Essentials Client Error Telemetry Logging\n\nJEP-306: Essentials Instance Client Health Checking\n\nOn the server side, of which there is substantial work for Jenkins Essentials,\nthese concepts integrate with the concept of an\nUpdate Lifecycle\nbetween the server and client. In essence, the server side must be able to\ndeliver the right updates to the right clients, and avoid delivering tainted\nupdates (those with known problems) to clients. While this part of the work is\nstill on-going, tremendous progress has been made over the past couple weeks\nin ensuring that updates can be safely, securely, and automatically delivered.\n\nWith the ability to identify \"bad code deploys\", and having a mechanism for\nsafely rolling back, not only does Jenkins Essentials allow seamless\nupdates, but it enables Jenkins developers to deliver features and bugfixes\nmuch more quickly than our current distribution model allows.\n\nWhile Jenkins Essentials does not have a package ready for broad consumption\nyet, we’re rapidly closing in on the completion of our first milestone which\nties all of these automatic update components together and builds the\nfoundation for continuous delivery of all subsequent improvements.\n\nYou can follow our progress in the\njenkins-infra/evergreen\nrepository, or join us in our\nGitter chat!","title":"Jenkins Essentials: The days of versions are numbered","tags":["evergreen"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2018-04-25T00:00:00.000Z","id":"e34fdb6b-09c7-5772-a251-10cec0ccef26","slug":"/blog/2018/04/25/configuring-jenkins-pipeline-with-yaml-file/","strippedHtml":"A few years ago our CTO wrote about building a\nContinuous Integration server for Ruby On Rails using Jenkins and docker.\nThe solution has been our CI pipeline for the past years until we recently decided to\nmake an upgrade. Why?\n\nJenkins version was way out of date and it was getting difficult to\nupgrade\n\nWolox has grown significantly over the past years\nand we’ve been experiencing scaling issues\n\nVery few people knew how to fix any issues with the server\n\nConfiguring jobs was not an easy task and that made our project\nkickoff process slower\n\nMaking changes to the commands that each job runs was not easy and not\nmany people had permissions to do so. Wolox has a wide range of\nprojects, with a wide variety of languages which made this problem even\nbigger.\n\nTaking into account these problems, we started digging into the newest\nversion of Jenkins to see how we could improve our CI. We needed to\nbuild a new CI that could, at least, address the following:\n\nProjects must be built using Docker. Our projects depend on one or\nmultiple docker images to run (app, database, redis, etc)\n\nEasy to configure and replicate if necessary\n\nEasy to add a new project\n\nEasy to change the building steps. Everyone working on the project\nshould be able to change if they want to run npm install or yarn\ninstall.\n\nInstalling Jenkins and Docker\n\nInstalling Jenkins is straightforward. You can visit\nJenkins Installation page and choose the\noption that best suits your needs.\n\nHere are the steps we followed to install Jenkins in AWS:\n\nsudo rpm — import https://pkg.jenkins.io/debian/jenkins.io.key\nsudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo\nsudo yum install java-1.8.0 -y\nsudo yum remove java-1.7.0-openjdk -y\nsudo yum install jenkins -y\nsudo yum update -y\nsudo yum install -y docker\n\nAutomatically adding projects from Github\n\nAdding projects automatically from Github can be achieved using the\nGitHub Branch Source Plugin.\nIt allows Jenkins to scan a GitHub organization\nfor projects that match certain rules and add them to Jenkins\nautomatically. The only constraint that all branches must meet in order\nto be added is that they contain a Jenkinsfile that explains how to\nbuild the project.\n\nEasy to change configuration\n\nNot so easy to change configuration\n\nOne of the biggest pains we had with our previous Jenkins was the\ndifficulty of changing the steps necessary to build the project. If you\nlooked at a project’s build steps, you would find something like this:\n\n#!/bin/bash +x\nset -e\n\n# Remove unnecessary files\necho -e \"\\033[34mRemoving unnecessary files...\\033[0m\"\nrm -f log/*.log &> /dev/null || true &> /dev/null\nrm -rf public/uploads/* &> /dev/null || true &> /dev/null\n\n# Build Project\necho -e \"\\033[34mBuilding Project...\\033[0m\"\ndocker-compose --project-name=${JOB_NAME} build\n\n# Prepare test database\nCOMMAND=\"bundle exec rake db:drop db:create db:migrate\"\necho -e \"\\033[34mRunning: $COMMAND\\033[0m\"\ndocker-compose --project-name=${JOB_NAME} run  \\\n\t-e RAILS_ENV=test web $COMMAND\n\n# Run tests\nCOMMAND=\"bundle exec rspec spec\"\necho -e \"\\033[34mRunning: $COMMAND\\033[0m\"\nunbuffer docker-compose --project-name=${JOB_NAME} run web $COMMAND\n\n# Run rubocop lint\nCOMMAND=\"bundle exec rubocop app spec -R --format simple\"\necho -e \"\\033[34mRunning: $COMMAND\\033[0m\"\nunbuffer docker-compose --project-name=${JOB_NAME} run -e RUBYOPT=\"-Ku\" web $COMMAND\n\nAnd some post build steps that cleaned up the docker:\n\n#!/bin/bash +x\ndocker-compose --project-name=${JOB_NAME} stop &> /dev/null || true &> /dev/null\ndocker-compose --project-name=${JOB_NAME} rm --force &> /dev/null || true &> /dev/null\ndocker stop `docker ps -a -q -f status=exited` &> /dev/null || true &> /dev/null\ndocker rm -v `docker ps -a -q -f status=exited` &> /dev/null || true &> /dev/null\ndocker rmi `docker images --filter 'dangling=true' -q --no-trunc` &> /dev/null || true &> /dev/null\n\nAlthough these commands are not complex, changing any of them required\nsomeone with permissions to modify the job and an understanding ofwhat\nneeded to be done.\n\nJenkinsfile to the rescue…​ or not\n\nWith the current Jenkins version, we can take advantage of\nJenkins Pipeline and model our build\nflow in a file. This file is checked into the repository and, therefore,\nanyone with access to it can change the build steps. Yay!\n\nJenkins Pipeline even has support for:\n\nDocker and\nmultiple\nimages can be used for a build!\n\nSetting environment variables with withEnv and many other built -in\nfunctions that can be found\nhere.\n\nThis makes a perfect case for Wolox. We can have\nour build configuration in a file that’s checked into the repository and\ncan be changed by anyone with write access to it. However, a Jenkinsfile\nfor a simple rails project would look something like this:\n\n# sample Jenkinsfile. Might not compile\nnode {\n    checkout scm\n    withEnv(['MYTOOL_HOME=/usr/local/mytool']) {\n        docker.image(\"postgres:9.2\").withRun() { db ->\n            withEnv(['DB_USERNAME=postgres', 'DB_PASSWORD=', \"DB_HOST=db\", \"DB_PORT=5432\"]) {\n                docker.image(\"redis:X\").withRun() { redis ->\n                    withEnv([\"REDIS_URL=redis://redis\"]) {\n                        docker.build(imageName, \"--file .woloxci/Dockerfile .\").inside(\"--link ${db.id}:postgres --link ${redis.id}:redis\") {\n                            sh \"rake db:create\"\n                            sh \"rake db:migrate\"\n                            sh \"bundle exec rspec spec\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nThis file is not only difficult to read, but also difficult to change.\nIt’s quite easy to break things if you’re not familiar with Groovy and\neven easier if you know nothing about how Jenkins’ pipeline works.\nChanging or adding a new Docker image isn’t straightforward and might\nlead to confusion.\n\nConfiguring Jenkins Pipeline via YAML\n\nPersonally, I’ve always envied simple configuration files for CIs and\nthis time it was our chance to build CI that could be configured using a\nYAML file. After some analysis we concluded that a YAML like this one\nwould suffice:\n\nconfig:\n  dockerfile: .woloxci/Dockerfile\n  project_name: some-project-name\n\nservices:\n  - postgresql\n  - redis\n\nsteps:\n  analysis:\n    - bundle exec rubocop -R app spec --format simple\n    - bundle exec rubycritic --path ./analysis --minimum-score 80 --no-browser\n  setup_db:\n    - bundle exec rails db:create\n    - bundle exec rails db:schema:load\n  test:\n    - bundle exec rspec\n  security:\n    - bundle exec brakeman --exit-on-error\n  audit:\n    - bundle audit check --update\n\n\nenvironment:\n  RAILS_ENV: test\n  GIT_COMMITTER_NAME: a\n  GIT_COMMITTER_EMAIL: b\n  LANG: C.UTF-8\n\nIt outlines some basic configuration for the project, environment\nvariables that need to be present during the run, dependentservices, and\nour build steps.\n\nJenkinsfile + Shared Libraries = WoloxCI\n\nAfter investigating for a while about Jenkins and the pipeline, we found\nthat we could extend it with\nshared libraries.\nShared libraries are written in groovy and can be imported\ninto the pipeline and executed when necessary.\n\nIf you look carefully at this Jenkinsfile,\nwe see that the code is a chain of methods calls that receive a\nclosure, where we execute another method passing a new closure to it.\n\n# sample Jenkinsfile. Might not compile\nnode {\n    checkout scm\n    withEnv(['MYTOOL_HOME=/usr/local/mytool']) {\n        docker.image(\"postgres:9.2\").withRun() { db ->\n            withEnv(['DB_USERNAME=postgres', 'DB_PASSWORD=', \"DB_HOST=db\", \"DB_PORT=5432\"]) {\n                docker.image(\"redis:X\").withRun() { redis ->\n                    withEnv([\"REDIS_URL=redis://redis\"]) {\n                        docker.build(imageName, \"--file .woloxci/Dockerfile .\").inside(\"--link ${db.id}:postgres --link ${redis.id}:redis\") {\n                            sh \"rake db:create\"\n                            sh \"rake db:migrate\"\n                            sh \"bundle exec rspec spec\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nGroovy is flexible enough to allow this same declarative code to be\ncreated at runtime, making our dream of using a YAML to configure our\njob come true!\n\nIntroducing Wolox-CI\n\nThat’s how wolox-ci was born- our\nshared library for Jenkins!\n\nWith wolox-ci, our Jenkinsfile is now\nreduced to:\n\n@Library('wolox-ci') _\n\nnode {\n\n  checkout scm\n\n  woloxCi('.woloxci/config.yml');\n}\n\nNow it simply checks out the code and then calls wolox-ci. The library\nreads yaml file like this one\n\nconfig:\n  dockerfile: .woloxci/Dockerfile\n  project_name: some-project-name\n\nservices:\n  - postgresql\n  - redis\n\nsteps:\n  analysis:\n    - bundle exec rubocop -R app spec --format simple\n    - bundle exec rubycritic --path ./analysis --minimum-score 80 --no-browser\n  setup_db:\n    - bundle exec rails db:create\n    - bundle exec rails db:schema:load\n  test:\n    - bundle exec rspec\n  security:\n    - bundle exec brakeman --exit-on-error\n  audit:\n    - bundle audit check --update\n\n\nenvironment:\n  RAILS_ENV: test\n  GIT_COMMITTER_NAME: a\n  GIT_COMMITTER_EMAIL: b\n  LANG: C.UTF-8\n\nand builds the Jenkinsfile to get your job running on the fly.\n\nThe nice part about having a shared library is that we can extend and\nfix our library in a centralized way. Once we add new code, the library\nis automatically updated in Jenkins which will notify all of our jobs\nwith the update.\n\nSince we have projects in different languages we use Docker to build the\ntesting environment. WoloxCI assumes there is a Dockerfile to build and\nwill run all the specified commands inside the container.\n\nWoloxci config.yml\n\nConfig\n\nThe first part of the config.yml file specifies some basic\nconfiguration: project’s name and Dockerfile location. The Dockerfile is\nused to build the image where the commands will be run.\n\nServices\n\nThis section describes which services will be exposed to the container.\nOut of the box, WoloxCI has support for postgresql, mssql and\nredis. You can also specify the docker image version you want! It is\nnot hard to add a new service. You just need to add the corresponding\nfile at\n\nhttps://github.com/Wolox/wolox-ci/tree/development/vars\n\nand modify how the services are parsed\n\nhttps://github.com/Wolox/wolox-ci/blob/development/src/com/wolox/parser/ConfigParser.groovy#L76\n\nSteps\n\nThe listed commands in this section will run inside the Docker\ncontainer. As a result, you’ll see each of the steps on the Jenkins UI.\n\nEnvironment\n\nIf you need some environment variables during your build, you can\nspecify them here. Whatever variable you set will be available inside\nthe Docker container when your commands listed in the steps section\ndescribed above.\n\nWrapping up\n\nWoloxCI is still being tested with a not-so-small sample of our\nprojects. The possibility of changing the build steps through a YAML\nfile makes it accessible for everyone and that is a great improvement in\nour CI workflow.\n\nDocker gives us the possibility of easily changing the programming\nlanguage without making any changes to our Jenkins installation and\nJenkins’ Github Organization feature automatically adds new projects\nwhen a new repository with a Jenkinsfile is detected.\n\nAll of these improvements have reduced the time we spend maintaining\nJenkins significantly and give us the possibility of easily scaling\nwithout any extra configuration.\n\nThis library is working in our CI but it still can be improved.\nIf you would like to add features, feel free to\ncontribute!","title":"Configuring a Jenkins Pipeline using a YAML file","tags":["jenkins","pipelines","yaml","sharedlibrary"],"authors":[{"avatar":null,"blog":null,"github":"mdesanti","html":"<div class=\"paragraph\">\n<p>Head of Infrastructure &amp; Cloud at <a href=\"https://www.wolox.com.ar\">Wolox</a></p>\n</div>","id":"mdesanti","irc":null,"linkedin":null,"name":"Matias De Santi","slug":"/blog/authors/mdesanti","twitter":"mdsanti"}]}},{"node":{"date":"2018-04-18T00:00:00.000Z","id":"36cc7fb2-3a58-5fd5-82ce-aa9662b5820b","slug":"/blog/2018/04/18/blueocean-1-5-0/","strippedHtml":"Hello, I am Jenn, the new Product Manager for Blue Ocean and Jenkins\nPipeline at CloudBees. I am based out of the Seattle area and am excited to be\nworking on Jenkins. :D We released version 1.5.0 of the Blue Ocean plugin late last week. If you’re\nusing Blue Ocean, you’ll want to grab this update since it includes many\nimprovements and bug fixes!\n\nNew Features\n\nBlue Ocean now includes a user interface update to show the downstream jobs\nlaunched with the 'build' step\n(link: JENKINS-38339)\n\nWith Blue Ocean 1.5.0, users can now Reorder Steps in the Blue Ocean Pipeline\nEditor simply by dragging and dropping steps to reorder them in the list of\nsteps.\n( JENKINS-38323)\n\nThe \"Artifacts\" tab also now supports pagination, which allows developers to\npaginate through the Artifacts tab. Previously, this list\nwas cut off at 100 entries.\n( JENKINS-43588)\n\nImprovements\n\nWe were able to include two performance improvements in 1.5.0 which reduce the\nDashboard loading time in Blue Ocean:\n\nJENKINS-44995\n\nJENKINS-48868\n\nSupport for viewing output for failed runs with no stages is also included in\nthis release. For developers who have no stages/steps defined in their\npipelines, they can now see the full log output for failed runs. This update\nhelps with Pipeline debugging in Jenkins.\n( JENKINS-48074)\n\nFurther improving the log output for Pipeline Runs, 1.5.0 also improves viewing\nof long log output lines with wrapping.  Previously, a single, long line of\noutput in the log wouldn’t be fully visible in the log window.\n( JENKINS-49036)\n\nFixes\n\nOne notable bug fix we addressed in this release was that input steps in\npost directives would not properly prompt for input. By fixing\nJENKINS-49297\nusers of Declarative Pipeline with Blue Ocean can include input steps in\ntheir post directives.\n\nThe full detailed change log can be viewed on the\nBlue Ocean plugin page\n\nUpdate Your Plugin\n\nPlugin updates in Jenkins are available in the Plugin Manager Update Center. This page includes instructions for using the UI and CLI to update your plugins: https://jenkins.io/doc/book/managing/plugins/.\n\nIf you are using the Blue Ocean UI, click Administration in the page’s header to open Plugin Manager.\n\nInstalling the primary Blue Ocean plugin will update its dependencies as well.\n\nProviding Feedback\n\nChat with us at Gitter: https://gitter.im/jenkinsci/blueocean-plugin\n\nReport issues at https://issues.jenkins.io/","title":"Faster sailing on Blue Ocean 1.5.0","tags":["blueocean"],"authors":[{"avatar":null,"blog":null,"github":"jennbriden","html":"<div class=\"paragraph\">\n<p>Jenn Briden is located in the Seattle area and is the Product Manager for the Blue Ocean plugin and the Jenkins pipeline. She has previously worked at Microsoft and ExtraHop Networks. Jenn likes drinking coffee but hasn&#8217;t ever seen a bigfoot.</p>\n</div>","id":"jennbriden","irc":null,"linkedin":null,"name":"Jenn Briden","slug":"/blog/authors/jennbriden","twitter":"jennbriden"}]}},{"node":{"date":"2018-04-16T00:00:00.000Z","id":"5bccde5f-c4ec-5989-8dc2-3f6097a019eb","slug":"/blog/2018/04/16/jenkins-x-explained-part1/","strippedHtml":"Jenkins X is an opinionated platform for providing CI / CD on top of\nKubernetes.\nWe’ve chosen a set of core applications that we install and wire together so things work out-of-the-box, providing a\nturn key experience. This blog aims to build on previous introductions to Jenkins X and provide a deeper\ninsight to what you get when you install Jenkins X.\n\nSo what happens? After downloading the jx CLI you will now be able to create clusters with public cloud providers\nor install onto an existing Kubernetes cluster.\n\nThis command will create a cluster on your cloud provider of choice.\n\njx create cluster\n\nAlternatively you can bring your own Kubernetes cluster and install Jenkins X on it:\n\njx install\n\nThat said, we’ve found that creating a new cluster on a public cloud such as GKE\nis a lot way easier to start as we can be sure of the state of the cluster.\nFor example we know that storage, networking and loadbalancers will be working as expected.\nCreating a cluster on GKE takes only a few minutes so it’s a great way to try things out as well as run your\nenterprise workloads.\n\nFor now lets assume we are using GKE. When jx create cluster has finished you will see some output in the\nterminal that also includes the default admin password to use when logging into the core applications below.\nThere is a flag --default-admin-password you can use to set this password yourself.\n\nAccessing applications\n\nWe automatically install an Nginx ingress controller running with an external loadbalancer pointing at it’s\nKubernetes service. We also generate all the Kubernetes Ingress rules using a golang library called\n\" exposecontroller\".\nThis runs as a Kubernetes Job triggered by a\nHelm hook once any application is installed to the cluster.\n\nUsing \"exposecontroller\" means we can control all the ingress rules for an environment using a single set of\nconfigurations, rather than each application needing to know how to expose the kubernetes service to the outside world.\nThis also means we can easily switch between HTTP and HTTPS plus support intregration with projects like\ncert-manager for auto generation of signed TLS certificates.\n\nEnvironments\n\nOne important point to make is Jenkins X aims to use terminology that developers are familiar with. That’s not\nto say we are changing Kubernetes fundamentals, it’s more that if you don’t know Kubernetes concepts then we aim\nto help you still adopt the cloud technology and pull back the curtain as you gain confidence and experience.\nTo that point, a core part of Jenkins X are \"environments\". An environment can have one or more applications running\nin it. In Kubernetes term an \"environment\" maps to the concept of a \"namespace\" in code.\n\nThe installation by default created three environments, this is customisable but by default we have a \"dev\", a \"staging\"\nand a \"production environment\". To list, select, or switch between these environments run:\n\njx env\n\nJenkins X core applications\n\nIn the \"dev\" environment we have installed a number of core applications we believe are required at a minimum\nto start folks off with CI/CD on Kubernetes. We can easily add to these core apps using Jenkins X addons but\nfor now lets focus on the core apps. Jenkins X comes with configuration that wires these services together,\nmeaning everything works together straight away. This dramatically reduces the time to get started with Kubernetes\nas all the passwords, environment variables and config files are all setup up to work with each other.\n\nJenkins — provides both CI and CD automation. There is an effort to decompose Jenkins over time to\nbecome more cloud native and make use of Kubernetes concepts around CRDs, storage and scaling for example.\n\nNexus — acts as a dependency cache for Nodejs and Java applications to dramatically improve build\ntimes. After an initial build of a SpringBoot application the build time is reduced from 12 mins to 4. We\nhave not yet but intend to demonstrate swapping this with Artifactory soon.\n\nDocker Registry — an in cluster docker registry where our pipelines push application images, we will\nsoon switch to using native cloud provider registries such as Google Container Registry, Azure Container\nRegistry or Amazon Elastic Container Registry (ECR) for example.\n\nChartmuseum — a registry for publishing Helm charts\n\nMonocular — a UI used for discovering and running Helm charts\n\nHelm\n\nWe learned a lot in our early days with fabric8 on Kubernetes and there were some projects from the ecosystem\nthat either weren’t around or (at the time) didn’t work with OpenShift, therefore we were restricted when\nmaking some design decisions. A couple of years on and now with Jenkins X we were able to look at other OSS\nprojects that have been flourishing, so I was very happy to start looking at Helm.\nHelm is a package manager for Kubernetes and allows easy installation and upgrades of applications.\n\nIt was pretty clear that for Jenkins to evolve and include deployments to the cloud we should embrace Helm\nand provide an opinionated experience that helps teams and developers. The core applications mentioned above\nmeans Jenkins X provides an out of the box integrated CI/CD solution for Helm.\n\nWe know that helm has limitations but with the work on\nHelm 3, the focus of the Kubernetes\nsig-apps group, the Kubernetes community and investment we see from key organisations such as Microsoft, we feel Helm\nis currently the best way to install and upgrade applications on Kubernetes.\n\nGitOps\n\nWe mentioned earlier that we setup three environments by default. What this means is for the staging and production\nenvironments we created:\n\nKubernetes namespace\n\nAn environment resource ( CustomResourceDefinition)\nin the dev environment which includes details of how applications are promoted to it and includes various team\nsettings.\n\nA git repository that we store what applications and their versions should be present in that environment.\nThese are stored in a Helm requirements.yaml file\n\nA Jenkins Pipeline job: explained in more detail below\n\nCI/CD for Environments\n\nHaving a Jenkins Pipeline Job for each environment means that Pull Requests to the git repo trigger a CI\njob.  For now that job performs basic validation but in the future will include ‘gates’ to ensure a change to that\nenvironment has passed expected checks such as QA tasks, gain enough approvals from the correct people, etc -\nYES CI for environments!\n\nOnce CI checks have passed the new application or version change can be merged. Only users that have karma\ncan merge the Pull Request and therefore we get RBAC plus traceability for our environment deployments.\n\nThis means every application manifest, their version and configuration including storage requirements, resource\nneeds and secrets for your environments are stored in Git repositories. Given a disaster recovery scenario this\nis exactly what you want.\n\nDid I just say secrets in Git? Yes! We will be providing a nicer experience to helps folks get set up but we\nourselves encrypt our secrets and  store them in Git, then decrypt them when we come to install and upgrade.\n\nHere’s our Git repo https://github.com/jenkins-x/cloud-environments/blob/a1edcc6/env-jx-infra/secrets.yaml.\n\nWe do all this with the help of a Helm wrapper called helm secrets.\nI’m working on a followup blog post with examples, better explanations and how to guides + add better integration\nwith JX in the coming weeks.\n\nFancy getting involved?\n\nWe mainly hangout in the jenkins-x Kubernetes slack channels and for tips on\nbeing more involved with Jenkins X take a look at our contributing docs\n\nIf you’ve not already seen it here’s a video showing the create cluster explained in this blog.","title":"Jenkins X Explained Part 1 - an integrated CI/CD solution for Kubernetes","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#c8e8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg","srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/77b35/jrawlings.jpg 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/d4a57/jrawlings.jpg 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/19e71/jrawlings.jpg 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/68974/jrawlings.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/ef6ff/jrawlings.webp 32w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/8257c/jrawlings.webp 64w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/6766a/jrawlings.webp 128w,\n/gatsby-jenkins-io/static/8f3e9e2f521cb211e3ccac77dc47d04f/22bfc/jrawlings.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"rawlingsj","html":"<div class=\"paragraph\">\n<p>James has a passion for continuous delivery and software automation in general.  Continually looking at\nways to help improve developers experience for the cloud.  James works on the OSS project <a href=\"https://jenkins-x.io/\">Jenkins X</a></p>\n</div>","id":"jrawlings","irc":null,"linkedin":null,"name":"James Rawlings","slug":"/blog/authors/jrawlings","twitter":"jdrawlings"}]}},{"node":{"date":"2018-04-13T00:00:00.000Z","id":"31f8965a-bc62-54ab-a155-4d858e063b0e","slug":"/blog/2018/04/13/jenkins-x-23-days-later/","strippedHtml":"Its been 24 days since we\nannounced Jenkins X,\na CI/CD solution for modern cloud applications on Kubernetes.\nI’m truly blown away by the response and feedback from the community - thank you!\n\nWe’ve also had lots of folks report they’ve successfully used Jenkins X\non a number of clouds including GKE, AWS and AKS along with on-premises clusters which is great to hear!\n\nHere’s a brief overview of the changes in the last 24 days from the\nRoadmap :\n\nwe now fully support GitHub and GitHub enterprise. BitBucket cloud and gitea is almost there too.\nHopefully BitBucketServer and Gitlab are not too far away either. For more detail see\nsupporting different git servers\n\nFor issue tracking we support GitHub, GitHub Enterprise and JIRA. For more detail see\nsupporting issue trackers\n\nGradle support is now available from jx create spring\nor by importing gradle apps\n\nGo, Node and Rust build packs are now available with more planned\n\nNew addons for anchore and kubeless\n\nAlso we’ve made it a little bit easier to keep your jx binary up to date continuously. Just type one of the following:\n\njx version will prompt you if there is a new version available\nand if prompted, it will upgrade itself\n\njx upgrade cli will upgrade the jx binary if its available or\njx upgrade platform for the platform\n\nFor more detail on the changes over the last 24 days with metrics please see the\nchangelog generated by Jenkins X\n\nWe’d love to hear your feedback what you think of\nJenkins X and the\nRoadmap - please\njoin the community.\n\nLinks\n\nJenkins X website\n\nDemos\n\nJenkins X JEP proposal","title":"Jenkins X making awesome progress after 24 days","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/19e71/jstrachan.jpg","srcSet":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/77b35/jstrachan.jpg 32w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/d4a57/jstrachan.jpg 64w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/19e71/jstrachan.jpg 128w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/68974/jstrachan.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/ef6ff/jstrachan.webp 32w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/8257c/jstrachan.webp 64w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/6766a/jstrachan.webp 128w,\n/gatsby-jenkins-io/static/70241374c0e6a5665fafbc121c330d3c/22bfc/jstrachan.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"jstrachan","html":"<div class=\"paragraph\">\n<p>James is a long time open source contributor, created the Groovy programming language and Apache Camel integration framework.\nFor the past few years he&#8217;s been working on CI/CD with Kubernetes.</p>\n</div>","id":"jstrachan","irc":null,"linkedin":null,"name":"James Strachan","slug":"/blog/authors/jstrachan","twitter":"jstrachan"}]}},{"node":{"date":"2018-04-11T00:00:00.000Z","id":"ed222945-0b4b-5227-9e90-64450f40170f","slug":"/blog/2018/04/11/security-updates/","strippedHtml":"We just released security updates to Jenkins, versions 2.116 and 2.107.2, that fix two security vulnerabilities.\n\nFor an overview of what was fixed, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security updates for Jenkins core","tags":["core","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and member of the <a href=\"/security/#team\">Jenkins security team</a>.\nHe was the inaugural Jenkins security officer from 2015 to 2021.\nHe sometimes contributes to developer documentation and project infrastructure in his spare time.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck","twitter":null}]}},{"node":{"date":"2018-04-10T00:00:00.000Z","id":"de012828-154d-5d83-8b81-e1199eaa8685","slug":"/blog/2018/04/10/opinionated-cd-jenkins-x/","strippedHtml":"I\nrecently wrote\nabout how all the cloud platforms are all in Kubernetes and so are developers.\nIt is an exciting time, but the problem for many is that this is\na huge blank sheet of paper for how to build and deploy applications.\nA white space, a void, a limitless canvas of possibilities.\nInsert metaphors here.\n\nThe problem, as you may guess, is that few people really like or are able to start with a blank canvas.\nI know I prefer to start with something working and iterate towards a solution,\nor be given some rails to stay on (again with the metaphors).\n\nThat’s where the Jenkins X project comes in.\nJenkins X is a Kubernetes-native continuous integration and continuous delivery platform\nfor developing cloud native applications that was recently introduced as a\nJenkins Enhancement Proposal,\nsponsored by James Strachan.\n\nThere is a lot to take in but at it’s heart,\nthis is an open source opinionated way to do continuous delivery with Kubernetes,\nnatively, without necessarily having to learn all the things I talked about in my last blog post.\nI shall attempt to explain what this is all about and why it matters to developers.\nAs someone said on the jenkins-dev mailing list\n“We have the two glued together with baling wire and twine” -\nJenkins X aims to simplify how to work with continuous delivery and Kubernetes.\n\nFirst and most importantly, let’s see the logo:\n\nYou can see the nautical theme leaking through (and Kubernetes).\nWhilst it is called Jenkins X, it is about quite a lot more than Jenkins.\n\nJenkins X makes decisions for you\n\nJenkins X presents itself to you initially as a handy sleek command line\n(a native binary you can install called jx - the debate is on as to how pronounce it).\nLet’s take a tour (sail?):\n\njx import my-app\n\nIf you have an existing project, this will detect what type of project it is, build a pipeline for you (and a bunch of Kubernetes things, like Helm Charts), add it to your project and set it up in GitHub, WebHooks and all, build the project (run the pipeline) and deploy a version to a “staging” environment.\n\nIf it looks ok, you can promote it to production:\n\njx promote --env production --version 1.0.1 my-app\n\nIf something went wrong in production, you can roll back an app to any version (the version numbers are made for you):\n\njx promote --env production --version 1.0.0 my-app\n> jx get apps # list versions\n\nAn environment is a well-established concept for web developers using\ncontinuous delivery: out of the box Jenkins X makes three of them for you\n(dev, staging and production), but you can make as many as you like.\nEnvironments have rules around how things are promoted into them\n(and they also have their own extensible pipelines,\nbut you can just use them as-is to start).\n\nYou can also create a Spring Boot microservice app:\n\njx create spring\n\nAnswer a few questions and it will set everything up for you.\n\nAny changes you make to your app automatically are built,\nand if the build looks good, they go through to the staging environment.\nWebHooks are setup for you (if you are using GitHub) to smooth this over.\n\nFor those looking at starting from pre-made apps, there are \"quickstarts\":\n\njx create quickstart\n\nThey are based on a growing set of starter apps, in a variety of languages and tech stacks.\n\nReview apps for your changes: Each pull request is built/tested,\nand a “review app” is made available in a temporary environment.\nThat means each proposed change, before it goes to the default branch (master),\nhas an environment made (temporary) that it can be tried out in.\nIn GitHub, this shows up as a comment in the pull request:\n\nProject type detection\n\nAs you can see, so far there is no editing or manual creation of pipelines,\nor scripting or setup, just importing or creating your app and go.\nThis is powered by\nDraft “packs”\n(a handy project that came out of Azure).\n What you end up with is a Jenkinsfile in your project repository.\n You may want to edit it one day, or you may be happy with it as is!\n Jenkins is famous for being un-opinionated in what you do,\n but Jenkins X has strong opinions (but you can extend and customise).\n\nimage::/images/jenkins-x/draft-logo.png[Draft Logo, width=300]\n\nDeploying or promoting to environments\n\nDeploying happens via pipelines behind the scenes -\nwhen a change is pushed, or a version promoted.\nYou don’t need to directly interact with Kubernetes if you don’t need to.\nA tool called Helm does the heavy lifting:\nHelm is used to package and perform installations and upgrade for your apps.\n\nThere is a little more magic going on here with environments, which you don’t see at first.\nEach environment, for a team, is represented by a Git repository behind the scenes.\nConfiguration as code is a well-established best practice these days,\nso why not use it to track deployments and initiate deployments.\nI also mentioned in my previous post how declarative Kubernetes is:\nit is perfect for keeping all config in a repository, of the desired system state.\n\nEach promotion is actually a pull request to a per-environment repository.\nThis repository is made and managed for you (and kept outside of the\nmain application code repository), you don’t have to look at it,\nbut you can extend things there should you need to.\nSpecific environment repositories may have different access rules,\nor be controlled by a different team (perhaps even deploy to a different cluster).\nSome have coined the term for this as “GitOps.”\nI first came across this concept on a\nWeaveWorks blog.\n\nI’ll try and explain this one with a diagram:\n\nThe pipeline is actually split in the middle.\nOn the left is the more familiar continuous integration pipeline.\nThis works on pull requests, pre-release version of things\nand is all about testing(automated and manual review).\nThe source of truth for this is the configuration in the\napplications repository: branches, pull requests and so on.\n\nThe right-hand side is the continuous delivery pipeline.\nThis kicks in when the application is ready to be updated with a new release.\nThis is the “GitOps” repo behind the scenes that controls the state of things in Kubernetes.\nA promotion on this side is a pull request, and then a merge,\nfrom the staging repository to the production repository.\n\nInstalling Jenkins X\n\nThe jx command line has a jx install command that installs it into a Kubernetes cluster.\n\nThe best experience initially is using Google’s excellent GKE service:\n\njx create cluster gke\n\nThis will ask a few questions, and go and set it all up for you in a\ncluster set aside for Jenkins X (recommended).\nJenkins X runs entirely as services on top of a Kubernetes cluster.\n\njx install\n\nIs designed to work with a Kubernetes cluster (if it already exists,\nrecommendation is to have a cluster put aside for Jenkins X if possible).\nAmazon EKS support is coming (mostly it is around testing),\nthat service is in beta/early access so it is still a work in progress,\nas is Microsoft Azures excellent AKS service.\n\nSo where is Jenkins?\n\nGood question, thanks for asking. Well, it is behind the scenes.\nAs you have seen, there was no direct interaction with Jenkins,\nbut it is there, running the pipelines for continuous integration and\ncontinuous delivery of the respective repositories, and orchestrating things with Kubernetes.\n\nIf you run jx get pipelines you can see URLs to the various pipelines\nthat have been setup for you are part of interacting with Jenkins X.\n\nBy the way,\nJames Strachan has written an extensive blog on jenkins.io\nthat really explores the Jenkins X project in-depth.\nOnce you finish reading this blog, take a stroll on over there and read James'.\nHe also provides several ways you can get involved in the project.\n\nWhat else can I do with the command line?\n\nLots, the jx command line has built in help:\n\njx open\n\nopen apps, services or pipelines in your browser\n\njx activity\n\nexplains how things got to where they are, a history\n\njx get environments\n\nlist environments\n\njx get apps\n\nshow the state of applications, what versions are in what environments.\n\nWhat’s next\n\nThere is a whole lot more to this, and lots more moving parts and services\nthat are set up for you that are very useful, but it is best to head over\nto jenkins-x.io and have a look.\n\nThis project is obviously in early stages (it is stll a Draft JEP after all) and there is lots happening.\nCheck out the Jenkins X community\nif you want to chat on slack, IRC, issues or email.\nAlso, read the\nJenkins Enhancement Proposal doc.","title":"Opinionated Kubernetes and Jenkins X","tags":["jenkins-x","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg","srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/77b35/michaelneale.jpg 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/d4a57/michaelneale.jpg 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/19e71/michaelneale.jpg 128w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/ef6ff/michaelneale.webp 32w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/8257c/michaelneale.webp 64w,\n/gatsby-jenkins-io/static/75c8520897a1db139d524965f5bb7ccc/6766a/michaelneale.webp 128w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"michaelneale","html":"<div class=\"paragraph\">\n<p>Michael is a CD enthusiast with a interest in User Experience.\nHe is a co-founder of CloudBees and a long time OSS developer, and can often be found\nlurking around the jenkins-dev mailing list or #jenkins on irc (same nick as twitter name).\nBefore CloudBees he worked at Red Hat.</p>\n</div>","id":"michaelneale","irc":null,"linkedin":null,"name":"Michael Neale","slug":"/blog/authors/michaelneale","twitter":"michaelneale"}]}}]}},"pageContext":{"limit":8,"skip":240,"numPages":101,"currentPage":31}},
    "staticQueryHashes": ["3649515864"]}