{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/49",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-07-19T00:00:00.000Z","id":"ce2c6f83-1ed8-521b-a608-5f3680ad5166","slug":"/blog/2016/07/19/blue-ocean-update/","strippedHtml":"The team have been hard at work moving the needle forward on the Blue\nOcean 1.0 features. Many of the features we have been working on have\ncome a long way in the past few months but here’s a few highlights:\n\nGoodbye page refreshes, Hello Real Time updates!\n\nBuilding upon\nTom 's great work on\nServer Sent Events (SSE) both\nCliff and\nTom worked\non making the all the screens in Blue Ocean update without manual\nrefreshes.\n\nSSE is a great technology\nchoice for new web apps as it only pushes out\nevents to the client when things have changed on the server. That means\nthere’s a lot less traffic going between your browser and the Jenkins\nserver when compared to the continuous AJAX polling method that has been\ntypical of Jenkins in the past.\n\nNew Test Reporting UI\n\nKeith has\nbeen working with Vivek to\ndrive out a new set of extension points that allow us to build a new\nrest reporting UI in Blue Ocean. Today this works for JUnit test reports\nbut can be easily extended to work with other kinds of reports.\n\nPipeline logs are split into steps and update live\n\nThorsten and\nJosh have\nbeen hard at work breaking down the log into steps and making the live\nlog tailing follow the pipeline execution - which we’ve lovingly\nnicknamed the “karaoke mode”\n\nPipelines can be triggered from the UI\n\nTom has\nbeen on allowing users to trigger jobs from Blue Ocean, which is one\nless reason to go back to the Classic UI :)\n\nBlue Ocean has been released to the experimental update center\n\nMany of you have asked us questions about how you can try Blue Ocean\ntoday and have resorted to building the plugin yourself or running our\nDocker image.\n\nWe wanted to make the process of trying Blue Ocean in its unfinished\nstate by publishing the plugin to the experimental update center - it’s\navailable today!\n\nSo what is the Experimental Update Center? It is a mechanism for the\nJenkins developer community to share early previews of new plugins with\nthe broader user community. Plugins in this update center are\nexperimental and we strongly advise not running them on production or\nJenkins systems that you rely on for your work.\n\nThat means any plugin in this update center could eat your Jenkins data,\ncause slowdowns, degrade security or have their behavior change at no\nnotice.\n\nYou can learn how to\nactivate\nthe experimental update center on this post.\n\nStay tuned for more updates!","title":"Blue Ocean July development update ","tags":["blueocean","ux","pipeline"],"authors":[]}},{"node":{"date":"2016-07-18T00:00:00.000Z","id":"523da562-6777-53bd-978f-45ab4cb9092c","slug":"/blog/2016/07/18/pipeline-notifications/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nRather than sitting and watching Jenkins for job status, I want Jenkins to send\nnotifications when events occur.  There are Jenkins plugins for\nSlack,\nHipChat,\nor even email\namong others.\n\nNote: Something is happening!\n\nI think we can all agree getting notified when events occur is preferable to\nhaving to constantly monitor them just in case.  I’m going to continue from\nwhere I left off in my\nprevious post with the\nhermann project.  I added a Jenkins\nPipeline with an HTML publisher for code coverage. This week, I’d like to make\nJenkins to notify me when builds start and when they succeed or fail.\n\nSetup and Configuration\n\nFirst, I select targets for my notifications. For this blog post, I’ll use sample\ntargets that I control.  I’ve created Slack and HipChat organizations called\n\"bitwiseman\", each with one member - me.  And for email I’m running a Ruby SMTP server called\nmailcatcher, that is perfect for local testing\nsuch as this.  Aside for these concessions, configuration would be much the\nsame in a non-demo situation.\n\nNext, I install and add server-wide configuration for the\nSlack,\nHipChat,\nand Email-ext\nplugins.  Slack and HipChat use API tokens - both products have integration\npoints on their side that generate tokens which I copy into my Jenkins\nconfiguration. Mailcatcher SMTP runs locally. I just point Jenkins\nat it.\n\nHere’s what the Jenkins configuration section for each of these looks like:\n\nOriginal Pipeline\n\nNow I can start adding notification steps. The same as\nlast week, I’ll use the\nJenkins Pipeline Snippet Generator\nto explore the step syntax for the notification plugins.\n\nHere’s the base pipeline before I start making changes:\n\nstage 'Build'\n\nnode {\n  // Checkout\n  checkout scm\n\n  // install required bundles\n  sh 'bundle install'\n\n  // build and run tests with coverage\n  sh 'bundle exec rake build spec'\n\n  // Archive the built artifacts\n  archive (includes: 'pkg/*.gem')\n\n  // publish html\n  // snippet generator doesn't include \"target:\"\n  // https://issues.jenkins.io/browse/JENKINS-29711.\n  publishHTML (target: [\n      allowMissing: false,\n      alwaysLinkToLastBuild: false,\n      keepAll: true,\n      reportDir: 'coverage',\n      reportFiles: 'index.html',\n      reportName: \"RCov Report\"\n    ])\n}\n\nThis pipeline expects to be run from a Jenkinsfile in SCM.\nTo copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with\ngit 'https://github.com/reiseburo/hermann.git'.\n\nJob Started Notification\n\nFor the first change, I decide to add a \"Job Started\" notification.  The\nsnippet generator and then reformatting makes this straightforward:\n\nnode {\n\n  notifyStarted()\n\n  /* ... existing build steps ... */\n}\n\ndef notifyStarted() {\n  // send to Slack\n  slackSend (color: '#FFFF00', message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n  // send to HipChat\n  hipchatSend (color: 'YELLOW', notify: true,\n      message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n    )\n\n  // send to email\n  emailext (\n      subject: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n      body: \"\"\" STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nSince Pipeline is a Groovy-based DSL, I can use\nstring interpolation\nand variables to add exactly the details I want in my notification messages. When\nI run this I get the following notifications:\n\nJob Successful Notification\n\nThe next logical choice is to get notifications when a job succeeds.  I’ll\ncopy and paste based on the notifyStarted method for now and do some refactoring\nlater.\n\nnode {\n\n  notifyStarted()\n\n  /* ... existing build steps ... */\n\n  notifySuccessful()\n}\n\ndef notifyStarted() { /* .. */ }\n\ndef notifySuccessful() {\n  slackSend (color: '#00FF00', message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n  hipchatSend (color: 'GREEN', notify: true,\n      message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n    )\n\n  emailext (\n      subject: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n      body: \"\"\" SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nAgain, I get notifications, as expected.  This build is fast enough,\nsome of them are even on the screen at the same time:\n\nJob Failed Notification\n\nNext I want to add failure notification.  Here’s where we really start to see the power\nand expressiveness of Jenkins pipeline.  A Pipeline is a Groovy script, so as we’d\nexpect in any Groovy script, we can handle errors using try-catch blocks.\n\nnode {\n  try {\n    notifyStarted()\n\n    /* ... existing build steps ... */\n\n    notifySuccessful()\n  } catch (e) {\n    currentBuild.result = \"FAILED\"\n    notifyFailed()\n    throw e\n  }\n}\n\ndef notifyStarted() { /* .. */ }\n\ndef notifySuccessful() { /* .. */ }\n\ndef notifyFailed() {\n  slackSend (color: '#FF0000', message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n  hipchatSend (color: 'RED', notify: true,\n      message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n    )\n\n  emailext (\n      subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n      body: \"\"\" FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nCode Cleanup\n\nLastly, now that I have it all working, I’ll do some refactoring. I’ll unify\nall the notifications in one method and move the final success/failure notification\ninto a finally block.\n\nstage 'Build'\n\nnode {\n  try {\n    notifyBuild('STARTED')\n\n    /* ... existing build steps ... */\n\n  } catch (e) {\n    // If there was an exception thrown, the build failed\n    currentBuild.result = \"FAILED\"\n    throw e\n  } finally {\n    // Success or failure, always send notifications\n    notifyBuild(currentBuild.result)\n  }\n}\n\ndef notifyBuild(String buildStatus = 'STARTED') {\n  // build status of null means successful\n  buildStatus = buildStatus ?: 'SUCCESS'\n\n  // Default values\n  def colorName = 'RED'\n  def colorCode = '#FF0000'\n  def subject = \"${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\"\n  def summary = \"${subject} (${env.BUILD_URL})\"\n  def details = \"\"\" STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\"\n\n  // Override default values based on build status\n  if (buildStatus == 'STARTED') {\n    color = 'YELLOW'\n    colorCode = '#FFFF00'\n  } else if (buildStatus == 'SUCCESS') {\n    color = 'GREEN'\n    colorCode = '#00FF00'\n  } else {\n    color = 'RED'\n    colorCode = '#FF0000'\n  }\n\n  // Send notifications\n  slackSend (color: colorCode, message: summary)\n\n  hipchatSend (color: color, notify: true, message: summary)\n\n  emailext (\n      subject: subject,\n      body: details,\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nYou have been notified!\n\nI now get notified twice per build on three different channels.  I’m not sure I\nneed to get notified this much for such a short build.  However, for a longer\nor complex CD pipeline, I might want exactly that.  If needed, I could even\nimprove this to handle other status strings and call it as needed throughout\nmy pipeline.\n\nLinks\n\nSlack Plugin\n\nHipChat Plugin\n\nEmail-ext Plugin\n\nJenkins Pipeline Snippet Generator","title":"Sending Notifications in Pipeline","tags":["tutorial","pipeline","plugins","notifications","slack","hipchat","emailext"],"authors":[]}},{"node":{"date":"2016-07-14T00:00:00.000Z","id":"a5b6f4b0-0b11-53a8-a751-ef9f1b23e787","slug":"/blog/2016/07/14/2-7-1-re-release/","strippedHtml":"We created new native packages for Jenkins 2.7.1 today. These replace the existing packages. Due to a release process issue, the packaging (RPM, etc.) was created the same way as Jenkins 1.x LTS, resulting in problems starting Jenkins on some platforms: While we dropped support for AJP in Jenkins 2.0, some 1.x packages had it enabled by default, resulting in an exception during startup.\n\nThese new packages for Jenkins 2.7.1, dated July 14, have the same scripts and parameters as Jenkins 2.x and should allow starting up Jenkins without problems. If you notice any further problems with the packaging, please report them in the packaging component.","title":"New packages for Jenkins 2.7.1","tags":["jenkins2","lts"],"authors":[]}},{"node":{"date":"2016-07-07T00:00:00.000Z","id":"d6aef4a7-7579-5619-b25e-5569e48f5464","slug":"/blog/2016/07/07/jenkins-2.7.1/","strippedHtml":"It’s been almost three months since we’ve released Jenkins 2.0, the first ever major version upgrade for this 10 year old project. The 2.x versions since then has been adopted by more than 20% of the users, but one segment of users who haven’t seen the benefits of Jenkins 2 is those who has been running LTS releases.\n\nBut that is no more! The new version of Jenkins LTS release we just released is 2.7.1, and now LTS users get to finally enjoy Jenkins 2.\n\nThis release also officially marks the end-of-life for Jenkins 1.x. There won’t be any future release of Jenkins 1.x beyond this point. If you are worried about the upgrade, don’t be! The core of Jenkins is still the same, and all the plugins & existing configuration will just work.","title":"Jenkins 2 hits LTS","tags":["lts","jenkins2"],"authors":[]}},{"node":{"date":"2016-07-01T00:00:00.000Z","id":"4848db1b-feac-54a0-8b3e-2a0f5e3fbfc6","slug":"/blog/2016/07/01/html-publisher-plugin/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nMost projects need more that just JUnit result reporting.  Rather than writing a\ncustom plugin for each type of report, we can use the\nHTML Publisher Plugin.\n\nLet’s Make This Quick\n\nI’ve found a Ruby project,\nhermann, I’d like to build using Jenkins Pipeline. I’d\nalso like to have the code coverage results published with each build job.  I could\nwrite a plugin to publish this data, but I’m in a bit of hurry and\nthe build already creates an HTML report file using SimpleCov\nwhen the unit tests run.\n\nSimple Build\n\nI’m going to use the\nHTML Publisher Plugin\nto add the HTML-formatted code coverage report to my builds.  Here’s a simple\npipeline for building the hermann\nproject.\n\nstage 'Build'\n\nnode {\n  // Checkout\n  checkout scm\n\n  // install required bundles\n  sh 'bundle install'\n\n  // build and run tests with coverage\n  sh 'bundle exec rake build spec'\n\n  // Archive the built artifacts\n  archive (includes: 'pkg/*.gem')\n}\n\nThis pipeline expects to be run from a Jenkinsfile in SCM.\nTo copy and paste it directly into a Jenkins Pipeline job, replace the checkout scm step with\ngit 'https://github.com/reiseburo/hermann.git'.\n\nSimple enough, it builds, runs tests, and archives the package.\n\nNow I just need to add the step to publish the code coverage report.\nI know that rake spec creates an index.html file in the coverage directory.\nI’ve already installed the\nHTML Publisher Plugin.\nHow do I add the HTML publishing step to the pipeline?  The plugin page doesn’t\nsay anything about it.\n\nSnippet Generator to the Rescue\n\nDocumentation is hard to maintain and easy to miss, even more so in a system\nlike Jenkins with hundreds of plugins the each potential have one or more\ngroovy fixtures to add to the Pipeline.  The Pipeline Syntax\"Snippet Generator\" helps users\nnavigate this jungle by providing a way to generate a code snippet for any step using\nprovided inputs.\n\nIt offers a dynamically generated list of steps, based on the installed plugins.\nFrom that list I select the publishHTML step:\n\nThen it shows me a UI similar to the one used in job configuration.  I fill in\nthe fields, click \"generate\", and it shows me snippet of groovy generated from\nthat input.\n\nHTML Published\n\nI can use that snippet directly or as a template for further customization.\nIn this case, I’ll just reformat and copy it in at the end of my\npipeline.  (I ran into a minor bug\nin the snippet generated for this plugin step. Typing\nerror string in my search bar immediately found the bug and a workaround.)\n\n/* ...unchanged... */\n\n  // Archive the built artifacts\n  archive (includes: 'pkg/*.gem')\n\n  // publish html\n  // snippet generator doesn't include \"target:\"\n  // https://issues.jenkins.io/browse/JENKINS-29711.\n  publishHTML (target: [\n      allowMissing: false,\n      alwaysLinkToLastBuild: false,\n      keepAll: true,\n      reportDir: 'coverage',\n      reportFiles: 'index.html',\n      reportName: \"RCov Report\"\n    ])\n\n}\n\nWhen I run this new pipeline I am rewarded with an RCov Report link on left side,\nwhich I can follow to show the HTML report.\n\nI even added the keepAll setting to let I can also go back an look at reports on old jobs as\nmore come in.  As I said to to begin with, this is not as slick as what I\ncould do with a custom plugin, but it is much easier and works with any static\nHTML.\n\nLinks\n\nHTML Publisher Plugin\n\nJenkins Pipeline Snippet Generator","title":"Publishing HTML Reports in Pipeline","tags":["tutorial","pipeline","plugins","ruby"],"authors":[]}},{"node":{"date":"2016-06-30T00:00:00.000Z","id":"6dc0bcbf-e180-50ae-86bf-0a881c810b38","slug":"/blog/2016/06/30/ewm-alpha-version/","strippedHtml":"Currently it’s quite difficult to share and reuse the same workspace between multiple jobs and across nodes.\nThere are some possible workarounds for achieving this, but each of them has its own drawback,\ne.g. stash/unstash pre-made artifacts, Copy Artifacts plugin or advanced job settings.\nA viable solution for this problem is the External Workspace Manager plugin, which facilitates workspace share and\nreuse across multiple Jenkins jobs and nodes.\nIt also eliminates the need to copy, archive or move files.\nYou can learn more about the design and goals of the External Workspace Manager project in\nthis introductory blog post.\n\nI’d like to announce that an alpha version of the External Manager Plugin has been released!\nIt’s now public available for testing.\nTo be able to install this plugin, you must follow the steps from the Experimental Plugins Update Center\nblog post.\n\nPlease be aware that it’s not recommended to use the Experimental Update Center in production installations of\nJenkins, since it may break it.\n\nThe plugin’s wiki page may be accessed\nhere.\nThe documentation that helps you get started with this plugin may be found on the\nREADME page.\nTo get an idea of what this plugin does, which are the features implemented so far and to see a working demo of it,\nyou can watch my mid-term presentation that is available here.\nThe slides for the presentation are shared on\nGoogle Slides.\n\nMy mentors, Martin and Oleg,\nand I have set up public meetings related to this plugin.\nYou are invited to join our discussions if you’d like to get more insight about the project.\nThe meetings are taking place twice a week on the Jenkins hangout,\nevery Monday at\n12 PM UTC\nand every Thursday at\n5 PM UTC.\n\nIf you have any issues in setting up or using the plugin, please feel free to ask me on the plugin’s Gitter\nchat.\nThe plugin is open-source, having the repository on\nGitHub, and you may contribute to it.\nAny feedback is welcome, and you may provide it either on the Gitter chat, or on\nJira by using the external-workspace-manager-plugin component.\n\nLinks\n\nProject repository\n\nPlugin wiki page\n\nMid-term presentation\n\nProject intro blog post\n\nGSoC page\n\nJenkins GSoC Page","title":"GSoC: External Workspace Manager Plugin alpha version","tags":["pipeline","plugins","external-workspace-manager","gsoc"],"authors":[]}},{"node":{"date":"2016-06-29T00:00:00.000Z","id":"72dc398a-0c3a-5b36-949e-7687e6ecbefc","slug":"/blog/2016/06/29/from-freestyle-to-pipeline/","strippedHtml":"This is a guest post by R. Tyler Croy, who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\nCloudBees, Inc.\n\nFor ages I have used the \"Build After\" feature in Jenkins to cobble together\nwhat one might refer to as a \"pipeline\" of sorts. The Jenkins project itself, a\nmajor consumer of Jenkins, has used these daisy-chained Freestyle jobs to drive\na myriad of delivery pipelines in our infrastructure.\n\nOne such \"pipeline\" helped drive the complex process of generating the pretty\nblue charts on\nstats.jenkins.io.\nThis statistics generation process primarily performs two major tasks, on rather\nlarge sets of data:\n\nGenerate aggregate monthly \"census data.\"\n\nProcess the census data and create trend charts\n\nThe chained jobs allowed us to resume the independent stages of the pipeline,\nand allowed us to run different stages on different hardware (different\ncapabilities) as needed. Below is a diagram of what this looked like:\n\nThe infra_generate_monthly_json would run periodically creating the\naggregated census data, which would then be picked up by infra_census_push\nwhose sole responsibility was to take census data and publish it to the\nnecessary hosts inside the project’s infrastructure.\n\nThe second, semi-independent, \"pipeline\" would also run periodically. The\ninfra_statistics job’s responsibility was to use the census data, pushed\nearlier by infra_census_push, to generate the myriad of pretty blue charts\nbefore triggering the\ninfra_checkout_stats job which would make sure stats.jenkins.io was\nproperly updated.\n\nSuffice it to say, this \"pipeline\" had grown organically over a period time when\nmore advanced tools weren’t quite available.\n\nWhen we migrated to newer infrastructure for\nci.jenkins.io earlier this year I took the\nopportunity to do some cleaning up. Instead of migrating jobs verbatim, I pruned\nstale jobs and refactored a number of others into proper\nPipelines, statistics generation being an obvious\ntarget!\n\nOur requirements for statistics generation, in their most basic form, are:\n\nEnable a sequence of dependent tasks to be executed as a logical group (a\npipeline)\n\nEnable executing those dependent tasks on various pieces of infrastructure\nwhich support different requirements\n\nActually generate those pretty blue charts\n\nIf you wish to skip ahead, you can jump straight to the\nJenkinsfile\nwhich implements our new Pipeline.\n\nThe first iteration of the Jenkinsfile simply defined the conceptual stages we\nwould need:\n\nnode {\n    stage 'Sync raw data and census files'\n\n    stage 'Process raw logs'\n\n    stage 'Generate census data'\n\n    stage 'Generate stats'\n\n    stage 'Publish census'\n\n    stage 'Publish stats'\n}\n\nHow exciting! Although not terrifically useful. When I began actually\nimplementing the first couple stages, I noticed that the Pipeline might sync\ndozens of gigabytes of data every time it ran on a new agent in the cluster.\nWhile this problem will soon be solved by the\nExternal\nWorkspace Manager plugin, which is currently being developed. Until it’s ready,\nI chose to mitigate the issue by pinning the execution to a consistent agent.\n\n/* `census` is a node label for a single machine, ideally, which will be\n * consistently used for processing usage statistics and generating census data\n */\nnode('census && docker') {\n    /* .. */\n}\n\nRestricting a workload which previously used multiple agents to a single one\nintroduced the next challenge. As an infrastructure administrator, technically\nspeaking, I could just install all the system dependencies that I want on this\none special Jenkins agent. But what kind of example would that be setting!\n\nThe statistics generation process requires:\n\nJDK8\n\nGroovy\n\nA running MongoDB instance\n\nFortunately, with Pipeline we have a couple of useful features at our disposal:\ntool auto-installers and the\nCloudBees\nDocker Pipeline plugin.\n\nTool Auto-Installers\n\nTool Auto-Installers are exposed in Pipeline through the tool step and on\nci.jenkins.io we already had JDK8 and Groovy\navailable. This meant that the Jenkinsfile would invoke tool and Pipeline\nwould automatically install the desired tool on the agent executing the current\nPipeline steps.\n\nThe tool step does not modify the PATH environment variable, so it’s usually\nused in conjunction with the withEnv step, for example:\n\nnode('census && docker') {\n    /* .. */\n\n    def javaHome = tool(name: 'jdk8')\n    def groovyHome = tool(name: 'groovy')\n\n    /* Set up environment variables for re-using our auto-installed tools */\n    def customEnv = [\n        \"PATH+JDK=${javaHome}/bin\",\n        \"PATH+GROOVY=${groovyHome}/bin\",\n        \"JAVA_HOME=${javaHome}\",\n    ]\n\n    /* use our auto-installed tools */\n    withEnv(customEnv) {\n        sh 'java --version'\n    }\n\n    /* .. */\n}\n\nCloudBees Docker Pipeline plugin\n\nSatisfying the MongoDB dependency would still be tricky. If I caved in and installed\nMongoDB on a single unicorn agent in the cluster, what could I say the next time\nsomebody asked for a special, one-off, piece of software installed on our\nJenkins build agents?\n\nAfter doing my usual complaining and whining, I discovered that the CloudBees\nDocker Pipeline plugin provides the ability to run containers inside of a\nJenkinsfile. To make things even better, there are\nofficial MongoDB docker images readily\navailable on DockerHub!\n\nThis feature requires that the machine has a running Docker daemon which is\naccessible to the user running the Jenkins agent. After that, running a\ncontainer in the background is easy, for example:\n\nnode('census && docker') {\n    /* .. */\n\n    /* Run MongoDB in the background, mapping its port 27017 to our host's port\n     * 27017 so our script can talk to it, then execute our Groovy script with\n     * tools from our `customEnv`\n     */\n    docker.image('mongo:2').withRun('-p 27017:27017') { container ->\n        withEnv(customEnv) {\n            sh \"groovy parseUsage.groovy --logs ${usagestats_dir} --output ${census_dir} --incremental\"\n        }\n    }\n\n    /* .. */\n}\n\nThe beauty, to me, of this example is that you can pass a\nclosure to withRun which will\nexecute while the container is running. When the closure is finished executin,\njust the sh step in this case, the container is destroyed.\n\nWith that system requirement satisfied, the rest of the stages of the Pipeline\nfell into place. We now have a single source of truth, the\nJenkinsfile,\nfor the sequence of dependent tasks which need to be executed, accounting for\nvariations in systems requirements, and it actually generates\nthose pretty\nblue charts!\n\nOf course, a nice added bonus is the beautiful visualization of our\nnew Pipeline!\n\nLinks\n\nPipeline documentation\n\nCloudBees Docker Pipeline plugin documentation\n\nLive statistics Pipeline","title":"Migrating from chained Freestyle jobs to Pipelines","tags":["pipeline","infra"],"authors":[]}},{"node":{"date":"2016-06-21T00:00:00.000Z","id":"719def0e-69a3-5e1c-b789-b2d19d5834dd","slug":"/blog/2016/06/21/gsoc-midterm-presentations-ann/","strippedHtml":"As you probably know, on this year Jenkins projects participates in\nGoogle Summer of Code 2016.\nYou can find more information about the accepted projects on the GSoC subproject page and in the\nJenkins Developer mailing list.\n\nOn this week GSoC students are going to present their projects as a part of mid-term evaluation,\nwhich covers one month of community bonding and one month of coding.\n\nWe would like to invite Jenkins developers to attend these meetings.\nThere are two additional months of coding ahead for successful students, so any feedback from Jenkins contributors and users will be appreciated.\n\nMeeting #1 - June 23, 7:00 PM UTC - 9:00 PM UTC\n\nSupport Core plugin improvements by Minudika Malshan\n\nIntro blogpost\n\nExternal Workspace Manager by Alex Somai\n\nIntro blogpost\n\nPlugin documentation publishing to jenkins.io by Cynthia Anyango\n\nIntro blogpost\n\nQ&A session\n\nMeeting link\n\nMeeting #2 - June 24, 8AM UTC - 9 AM UTC\n\nJenkins WebUI: Improving Job Creation/Configuration by Samat Davletshin\n\nIntro blogpost\n\nQ&A session\n\nMeeting link\n\nBoth meetings will be conducted and recorded via Hangouts on Air.\nThe recorded sessions will be made public after the meetup.\nThe agenda may change a bit.\n\nLinks\n\nMid-term presentations announcement on Jenkins Developer mailing list\n\nJenkins GSoC 2016 Wiki Page\n\nJenkins project page on the GSoC2016 website","title":"GSoC: Mid-term presentations by students on June 23 and 24","tags":["core","gsoc","plugin","general"],"authors":[]}}]}},"pageContext":{"limit":8,"skip":384,"numPages":100,"currentPage":49}},
    "staticQueryHashes": ["3649515864"]}