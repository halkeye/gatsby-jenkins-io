{
    "componentChunkName": "component---src-templates-blog-list-template-js",
    "path": "/blog/page/53",
    "result": {"data":{"allBlog":{"edges":[{"node":{"date":"2016-04-14T00:00:00.000Z","id":"44aa3a43-715d-549b-b0d2-cc5c5bd94725","slug":"/blog/2016/04/14/replay-with-pipeline/","strippedHtml":"This is a cross-post of\nan article authored by\nPipeline plugin maintainer Jesse Glick on the\nCloudBees blog.\n\nFor those of you not checking their Updates tab obsessively, Pipeline 1.14 [up\nto 2.1 now] was\nreleased\na couple of weeks ago and I wanted to highlight the major feature in this\nrelease: JENKINS-32727,\nor replay. Some folks writing \"Jenkinsfiles\" in the field had grumbled that it\nwas awkward to develop the script incrementally, especially compared to jobs\nusing inline scripts stored in the Jenkins job configuration: to try a change to\nthe script, you had to edit Jenkinsfile in SCM, commit it (perhaps to a\nbranch), and then go back to Jenkins to follow the output. Now this is a little\neasier. If you have a Pipeline build which did not proceed exactly as you\nexpected, for reasons having to do with Jenkins itself (say, inability to find &\npublish test results, as opposed to test failures you could reproduce locally),\ntry clicking the Replay link in the build’s sidebar. The quickest way to try\nthis for yourself is to run the\nstock CD demo in its\nlatest release:\n\n$ docker run --rm -p 2222:2222 -p 8080:8080 -p 8081:8081 -p 9418:9418 -ti jenkinsci/workflow-demo:1.14-3\n\nWhen you see the page Replay\n#1 , you are shown two\n(Groovy) editor boxes: one for the main\nJenkinsfile , one for a library script\nit loaded\n( servers.groovy , introduced to help demonstrate this feature). You\ncan make edits to either or both. For example, the original demo allocates a\ntemporary web application with a random name like\n9c89e9aa-6ca2-431c-a04a-6599e81827ac for the duration of the functional tests.\nPerhaps you wished to prefix the application name with tmp- to make it obvious\nto anyone encountering the Jetty index page that these\nURLs are transient. So in the second text area, find the line\n\ndef id = UUID.randomUUID().toString()\n\nand change it to read\n\ndef id = \"tmp-${UUID.randomUUID()}\"\n\nthen click Run. In\nthe new build’s log\nyou will now see\n\nReplayed #1\n\nand later something like\n\n… test -Durl=http://localhost:8081/tmp-812725bb-74c6-41dc-859e-7d9896b938c3/ …\n\nwith the improved URL format. Like the result? You will want to make it\npermanent. So jump to the [second build’s index\npage]( http://localhost:8080/job/cd/branch/master/2/) where you will see a note\nthat this build > Replayed #1 (diff) If you\nclick on diff you\nwill see:\n\n--- old/Script1\n+++ new/Script1\n@@ -8,7 +8,7 @@\n }\n\n def runWithServer(body) {\n-    def id = UUID.randomUUID().toString()\n+    def id = \"tmp-${UUID.randomUUID()}\"\n     deploy id\n     try {\n         body.call id\n\nso you can know exactly what you changed from the last-saved version. In fact if you replay #2 and change tmp to temp in the loaded script, in the diff view for #3 you will see the diff from the first build, the aggregate diff:\n\n--- old/Script1\n+++ new/Script1\n@@ -8,7 +8,7 @@\n }\n\n def runWithServer(body) {\n-    def id = UUID.randomUUID().toString()\n+    def id = \"temp-${UUID.randomUUID()}\"\n     deploy id\n     try {\n         body.call id\n\nAt this point you could touch up the patch to refer to servers.groovy\n( JENKINS-31838), git\napply it to a clone of your repository, and commit. But why go to the trouble\nof editing Groovy in the Jenkins web UI and then manually copying changes back\nto your IDE, when you could stay in your preferred development environment from\nthe start?\n\n$ git clone git://localhost/repo\nCloning into 'repo'...\nremote: Counting objects: 23, done.\nremote: Compressing objects: 100% (12/12), done.\nremote: Total 23 (delta 1), reused 0 (delta 0)\nReceiving objects: 100% (23/23), done.\nResolving deltas: 100% (1/1), done.\nChecking connectivity... done.\n$ cd repo\n$ $EDITOR servers.groovy\n# make the same edit as previously described\n$ git diff\ndiff --git a/servers.groovy b/servers.groovy\nindex 562d92e..63ea8d6 100644\n--- a/servers.groovy\n+++ b/servers.groovy\n@@ -8,7 +8,7 @@ def undeploy(id) {\n }\n\n def runWithServer(body) {\n-    def id = UUID.randomUUID().toString()\n+    def id = \"tmp-${UUID.randomUUID()}\"\n     deploy id\n     try {\n         body.call id\n$ ssh -p 2222 -o StrictHostKeyChecking=no localhost replay-pipeline cd/master -s Script1 webapp-naming\n\nUsing the replay-pipeline CLI command (in this example via\nSSH)\nyou can prepare, test, and commit changes to your Pipeline script code without\ncopying anything to or from a browser. That is all for now. Enjoy!","title":"Replay a Pipeline with script edits","tags":["jenkins2","pipeline"],"authors":[]}},{"node":{"date":"2016-04-11T00:00:00.000Z","id":"e9d4f87e-38f5-5fa5-8f99-7062f5a29099","slug":"/blog/2016/04/11/jenkins-plugins-security-update/","strippedHtml":"The Script Security Plugin and the Extra Columns Plugin were updated today to fix medium-severity security vulnerabilities. For detailed information about the security content of these updates, see the security advisory.\n\nSubscribe to the jenkinsci-advisories mailing list to receive important notifications related to Jenkins security.","title":"Security fixes in Script Security Plugin and Extra Columns Plugin","tags":["plugins","security"],"authors":[{"avatar":null,"blog":null,"github":"daniel-beck","html":"<div class=\"paragraph\">\n<p>Daniel is a Jenkins core maintainer and, as security officer, leads the <a href=\"/security/#team\">Jenkins security team</a>.\nHe sometimes contributes to developer documentation and project infrastructure.</p>\n</div>","id":"daniel-beck","irc":null,"linkedin":null,"name":"Daniel Beck","slug":"/blog/authors/daniel-beck/","twitter":null}]}},{"node":{"date":"2016-04-11T00:00:00.000Z","id":"25d1b7f0-6783-53a9-aec5-f7242e8493d2","slug":"/blog/2016/04/11/gsoc2016-mentors-call/","strippedHtml":"As you probably know, Jenkins project has been accepted to\nGoogle Summer of Code 2016.\n\nDuring last month we were working with students in order to discuss their project ideas and to review their application drafts.\nThanks again to all students and mentors for your hard work during about ten office hours and dozens of other calls/chats!\n\nCurrent status\n\nWe have successfully handled the student application period\n\nWe have received a bunch of good project proposals (mentors cannot disclose the number)\n\nWe have done the preliminary filtering of applications\n\nGSoC mentors and organization admins have prepared the project slot application draft\n\nCurrently we are looking for mentors.\nWe have a minimal required number for the current project slot application plan, but additional expertise would allow us to share the load and to provide more expertise to students.\n\nIf you want to be a mentor:\n\nCheck out mentor requirements here.\n\nCheck out the project ideas\nhere.\n\nStudent application period is finished, so it is too late to propose project ideas for this year\n\nYou can join the mentor team for one of the mentioned projects\n\nHot areas: UI improvements, Fingerprints, External Workspace Manager\n\nContact Google GSoC admins via jenkinsci-gsoc-org@googlegroups.com\n\nLinks\n\nGSoC2016 page on our Wiki\n\nJenkins page on the GSoC2016 website","title":"Google Summer of Code. Call for Mentors","tags":["general","jenkins2","gsoc"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png","srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/914ee/oleg_nenashev.png 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/1c9ce/oleg_nenashev.png 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/acb7c/oleg_nenashev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/ef6ff/oleg_nenashev.webp 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/8257c/oleg_nenashev.webp 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/6766a/oleg_nenashev.webp 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/22bfc/oleg_nenashev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/oleg_nenashev.png"},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/authors/oleg_nenashev/","twitter":"oleg_nenashev"}]}},{"node":{"date":"2016-04-11T00:00:00.000Z","id":"71b50dae-de34-5505-957d-a9c0f8d10044","slug":"/blog/2016/04/11/run-your-api-tests-continuously-with-jenkins-and-dhc/","strippedHtml":"This is a guest post by Guillaume Laforge.\nWell known for his contribution to the Apache Groovy project,\nGuillaume is also the \"Product Ninja and Advocate\" of Restlet,\na company focusing on Web APIs:\nwith DHC (an API testing client),\nRestlet Studio (an API designer),\nAPISpark (an API platform in the cloud),\nand the Restlet Framework\nopen source project for developing APIs.\n\nModern mobile apps, single-page web sites and applications, are more and more relying on Web APIs,\nas the nexus of the interaction between the frontend and the backend services.\nWeb APIs are also central to third-party integration, when you want to share your services with others,\nor when you need to consume existing APIs to build your own solution on top of their shoulders.\n\nWith APIs being a key element of your architecture and big picture,\nit’s obviously important to assess that this API is functioning the way it should, thanks to proper testing.\nYour framework of choice, regardless of the technology stack or programming language used,\nwill hopefully offer some facilities for testing your code,\nwhether in the form of unit tests, or ideally with integration tests.\n\nCoding Web API tests\n\nFrom a code perspective, as I said, most languages and frameworks provide approaches to testing APIs built with them.\nThere’s one I wanted to highlight in particular, which is one developed with a DSL approach (Domain-Specific Language),\nusing the Apache Groovy programming language, it’s\nAccuREST.\n\nTo get started, you can have a look at the introduction,\nand the usage guide.\nIf you use the contract DSL,\nyou’ll be able to write highly readable examples of requests you want to issue against your API,\nand the assertions that you expect to be true when getting the response from that call.\nHere’s a concrete example from the documentation:\n\nGroovyDsl.make {\n    request {\n        method 'POST'\n        urlPath('/users') {\n            queryParameters {\n                parameter 'limit': 100\n                parameter 'offset': containing(\"1\")\n                parameter 'filter': \"email\"\n            }\n        }\n        headers {\n            header 'Content-Type': 'application/json'\n        }\n        body '''{ \"login\" : \"john\", \"name\": \"John The Contract\" }'''\n    }\n    response {\n        status 200\n        headers {\n            header 'Location': '/users/john'\n        }\n    }\n}\n\nNotice that the response is expected to return a status code 200 OK, and a Location header pointing at /users/john.\nIndeed, a very readable way to express the requests and responses!\n\nTooling to test your APIs\n\nFrom a tooling perspective, there are some interesting tools that can be used to test Web APIs,\nlike Paw (on Macs),\nAdvanced REST client,\nPostman or\nInsomnia.\n\nBut in this article, I’ll offer a quick look at DHC,\na handy visual tool, that you can use both manually to craft your tests and assertions,\nand whose test scenarios you can export and integrate in your build and continuous integration pipeline,\nthanks to Maven and Jenkins.\n\nAt the end of this post, you should be able to see the following reporting in your Jenkins dashboard,\nwhen visualising the resulting API test execution:\n\nIntroducing DHC\n\nDHC is a Chrome extension, that you can\ninstall from the Chrome Web Store,\nin your Chrome browser. There’s also an online service available, with some limitations.\nFor the purpose of this article, we’ll use the Chrome extension.\n\nIn the main area, you can create your request, define the URL to call, specify the various request headers or params,\nchose the method you want to use, and then, you can click the send button to issue the request.\n\nIn the left pane, that’s where you’ll be able to see your request history, create and save your project in the cloud,\nor also set context variables.\n\nThe latter is important when testing your Web API, as you’ll be able to insert variables like for example\n{localhost} for testing locally on your machine or {staging} and {prod} to run your tests in different environments.\n\nIn the bottom pane, you have access to actual raw HTTP exchange, as well as the assertions pane.\n\nAgain, a very important pane to look at! With assertions, you’ll be able to ensure that your Web API works as expected.\nFor instance, you can check the status code of the call, check the payload contains a certain element,\nby using JSON Path or XPath to go through the JSON or XML payload respectively.\n\nBeyond assertions, what’s also interesting is that you can chain requests together.\nA call request can depend on the outcome of a previous request!\nFor example, in a new request, you could pass a query parameter whose value would be the value of some element\nof the JSON payload of a previously executed request.\nAnd by combining assertions, linked requests and context variables together, you can create full-blown test scenarios,\nthat you can then save in the cloud, but also export as a JSON file.\n\nTo export that test scenario, you can click on the little export icon in the bottom left hand corner,\nand you’ll be able to select exactly what you want to export:\n\nRunning your Web API tests with Maven\n\nNow things become even more interesting, as we’ll proceed to using Maven and Jenkins!\nAs the saying goes, there’s a Maven plugin for that! For running those Web API tests in your build!\nEven if your Web API is developed in another technology than Java, you can still create a small Maven build\njust for your Web API tests.\nAnd the icing on the cake, when you configure Jenkins to run this build, as the plugin outputs JUnit-friendly test reports,\nyou’ll be able to see the details of your successful and failed tests, just like you would see JUnit’s!\n\nLet’s sketch your Maven POM:\n\n4.0.0\n\ncom.example\nmy-first-api-test\n1.2.3\n\ncom.restlet.dhc\ndhc-maven-plugin\n1.1\n\ntest\n\ntest\n\ncompanies-scenario.json\n\nrestlet-maven\nRestlet public Maven repository Release Repository\nhttps://maven.restlet.com\n\nVisualizing Web API test executions in Jenkins\n\nOnce you’ve configured your Jenkins server to launch the test goal of this Maven project,\nyou’ll be able to see nice test reports for your Web API scenarios, like in the screenshot in introduction of this article!\n\nNext, you can easily run your Web API tests when developers commit changes to the API,\nor schedule regular builds with Jenkins to monitor an online Web API.\n\nFor more information, be sure to read the tutorial on\ntesting Web APIs with DHC.\nThere are also some more resources like a\nscreencast,\nas well as the\nuser guide, if you want to learn more.\nAnd above all, happy testing!","title":"Run Your API Tests Continuously with Jenkins and DHC","tags":["development","webapis","testing"],"authors":[{"avatar":null,"blog":"https://glaforge.appspot.com/","github":"glaforge","html":"","id":"glaforge","irc":null,"linkedin":null,"name":"Guillaume Laforge","slug":"/blog/authors/glaforge/","twitter":"glaforge"}]}},{"node":{"date":"2016-04-07T00:00:00.000Z","id":"e79f0919-bcdb-509d-81fc-767eb7210b3a","slug":"/blog/2016/04/07/2.0-release-candidate/","strippedHtml":"Those who fervently watch the\njenkinsci-dev@\nlist, like I do, may have caught Daniel\nBeck 's email today which quietly referenced a significant milestone on the\nroad to 2.0 which has been reached: the first 2.0 release\ncandidate is here!\n\nThe release candidate process, in short, is the final stabilization and testing\nperiod before the final release of Jenkins 2.0. If you have the\ncycles to help test, please download the release candidate and give\nus your feedback as soon as possible!\n\nThe release candidate process also means that changes targeting release after\n2.0 can start landing in the master branch, laying the groundwork 2.1 and\nbeyond.\n\nI pushed the merge to 'master'. So anything targeting 2.1+ can be now proposed\nin pull requests to that branch.\n\nAnything happening on '2.0' branch will be limited to critical fixes for the 2.0\nrelease specifically.\n\n— Daniel Beck\n\nCompared to the\n2.0 beta release, the first\nrelease candidate has a number of fixes for issues discovered in the alpha and beta\nprocess. Most notable perhaps is the stabilization of a system property which\nconfiguration management tools, like Puppet/Chef/Ansible/etc, can use to suppress\nthe user-friendly Getting Started wizard. Since users of those tools\nhave alternative means of ensuring security and correctness of their Jenkins\ninstallations, the out-of-the-box experience can be skipped.\n\nBased on our\nrough\ntimeline this gives us a couple weeks to test the release candidates and get\nready for a big exciting release of 2.0 at the end of April!","title":"Jenkins 2.0 Release Candidate available!","tags":["jenkins2"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/rtyler.jpeg"},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler/","twitter":"agentdero"}]}},{"node":{"date":"2016-04-07T00:00:00.000Z","id":"dc2d5625-7a35-5883-9c50-152fda1c584a","slug":"/blog/2016/04/07/jenkins-community-survey-results-blog/","strippedHtml":"This is a guest post by Brian\nDawson at CloudBees, where he works as a DevOps Evangelist responsible for\ndeveloping and sharing continuous delivery and DevOps best practices. He also\nserves as the CloudBees Product Marketing Manager for Jenkins.\n\nLast fall CloudBees asked attendees at the Jenkins User Conference – US West\n(JUC), and other in the Jenkins community to take a survey.  Almost 250 people\ndid – and thanks to their input, we have results which provided interesting\ninsights into how Jenkins is being used.\n\nBack in 2012, at the time of the last community survey, 83% of respondents felt\nthat Jenkins was mission-critical. By 2015, the percentage saying that\nJenkins was mission-critical was 92%. Additionally, echoing the\nimportance of Jenkins, 89% of respondents said their use of Jenkins had\nincreased over the last year, while 11% said it had stayed the same. 0%\nsaid that it had decreased.\n\nThe trend in the industry over the last couple of years has been to adopt\ncontinuous delivery (CD), thus pushing automation further down the pipeline –\nfrom development all the way into production.  Jenkins being an automation\nengine applicable to any phase of the software delivery lifecycle, is readily\nsupporting this trend. Jenkins' extensible architecture and unparalleled plugin\necosystem enables integration with and orchestration of practically any tool in\nany phase of software delivery.\n\nThe trend towards adoption of CD is clearly reflected amongst the community: 59%\nof respondents are using Jenkins for continuous integration (CI), but an\nadditional 30% have extended CI into CD and are manually deploying code to\nproduction.  Finally, 11% are practicing continuous deployment – they have\nextended CI to CD and are deploying code automatically into production.\n\nAnother trend tied to the adoption of CD and DevOps is the frequent deployment\nof incremental releases to production. 26% of those respondents using continuous\ndelivery practices are deploying code at least once per day.  Another 37% are\ndeploying code at least once per week.\n\nIn keeping with the move to CD, 30% of survey takers are already using the\nrelatively new Pipeline plugin to automate their\nsoftware delivery pipelines.  Of those not using the Pipeline plugin, 79% plan\nto adopt it in the next 12 months.\n\nSurvey respondents are also using Jenkins for many different activities.  97% of\nsurvey takers use it for \"build\" – no surprise, since that is where Jenkins got\nits start - but 58% now also use it for their deployment.\n\nWhen the 2012 community survey was conducted, container technology was not as\nwell understood as it is today,  and many didn’t know what a “Docker” was. A\nshort four years later, 96% of survey respondents who use Linux containers are\nusing Docker.  Container technology has seen impressive adoption and arguably is\nrevolutionizing the way application infrastructure is delivered.  When coupled\nwith Jenkins as an automation engine, containers help accelerate software\ndelivery by providing rapid access to lightweight environments.  The Jenkins\ncommunity has recognized and embraced the power of containers by\nproviding plugins for Docker and Kubernetes.\n\nThe Jenkins improvements which survey respondents desired the most were\nquality/timely bug fixes, a better UI and more documentation/examples.\nInterestingly, Jenkins 2.0 - which is just about to officially launch,\nprovides UI improvements and the new Jenkins.io website\nprovides improved, centralized documentation.\n\nFinally, the respondents favorite Star Wars character was R2-D2, followed by\nObi-Wan and Darth Vader. Yoda and Han Solo also got a fair amount of votes. The\nvotes for Jar-Jar Binks and Jabba the Hutt left us puzzled. Notably, BB-8 had a\nwrite-in vote despite the fact the new Star Wars movie hadn’t been released yet.\n\nAs to where the community is headed, our prediction is that by the next Jenkins Community Survey:\n\nMore Jenkins users will have transitioned from just continuous\nintegration to continuous delivery with some evening practicing continuous\ndeployment\n\nPipeline plugin adoption and improvements will continue, leading to\npipeline-as-code becoming an essential solution for automating the software\n(and infrastructure) delivery process\n\nThere will be a significant increase in use of the Docker plugin to support\nelastic Jenkins infrastructure and continuous delivery of containers using\nsoftware development best practices\n\nBB-8 will be the next favorite Star Wars character! <3</p>\n\nSee you at Jenkins World, September 13-15, in Santa Clara, California!\nRegister now for the largest Jenkins event on the planet in 2016 – and get the Early Bird discount. The Call for Papers is still open – so submit a talk and share your knowledge with the community about Jenkins.\n\n2015 Community Survey Results (PDF)\n\nState of Jenkins Infographic (PDF)","title":"Jenkins Community Survey Results","tags":["continuousdelivery","pipeline","docker"],"authors":[{"avatar":null,"blog":null,"github":"bvdawson","html":"<div class=\"paragraph\">\n<p>DevOps dude at CloudBees.\nJenkins Marketing Manager.\nTools geek.</p>\n</div>","id":"bvdawson","irc":null,"linkedin":null,"name":"Brian Dawson","slug":"/blog/authors/bvdawson/","twitter":"brianvdawson"}]}},{"node":{"date":"2016-04-07T00:00:00.000Z","id":"bb46e899-10f9-583c-862c-a664e9eb81b4","slug":"/blog/2016/04/07/pipeline-for-runs-on-hardware/","strippedHtml":"In addition to Jenkins development, during last 8 years I’ve been involved into continuous integration for hardware and embedded projects.\nAt JUC2015/London\nI have conducted a talk about common automation challenges in the area.\n\nIn this blog post I would like to concentrate on Pipeline (formerly known as Workflow), which is a new ecosystem in Jenkins that allows implementing jobs in a domain specific language.\nIt is in the suggested plugins list in the upcoming Jenkins 2.0 release.\n\nThe first time I tried Pipeline two and half years ago, it unfortunately did not work for my use-cases at all.\nI was very disappointed but tried it again a year later.\nThis time, the plugin had become much more stable and useful.\nIt had also attracted more contributors and started evolving more rapidly with the development of plugins extending the Pipeline ecosystem.\n\nCurrently, Pipeline a powerful tool available for Jenkins users to implement a variety of software delivery pipelines in code.\nI would like to highlight several Pipeline features which may be interesting to Jenkins users working specifically with embedded and hardware projects.\n\nIntroduction\n\nIn Embedded projects it’s frequently required to run tests on specific hardware peripherals: development boards, prototypes, etc.\nIt may be required for both software and hardware areas, and especially for products involving both worlds.\nCI and CD methodologies require continuous integration and system testing, and Jenkins comes to help here.\nJenkins is an automation framework, which can be adjusted to reliably work with hardware attached to its nodes.\n\nArea challenges\n\nGenerally, any peripheral hardware device can be attached to a Jenkins node.\nSince Jenkins nodes require Java only, almost every development machine can be attached.\nBelow you can find a common connection scheme:\n\nAfter the connection, Jenkins jobs could invoke common EDA tools via command-line interfaces.\nIt can be easily done by a Execute shell build steps in free-style projects.\nSuch testing scheme is commonly affected by the following issues:\n\nNodes with peripherals are being shared across several projects.\nJenkins must ensure the correctness of access (e.g. by throttling the access).\n\nIn a single Freestyle project builds utilize the node for a long period. If you synthesize the item before the run, much of the peripheral utilization file may be wasted.\n\nThe issue can be solved by one of concurrency management plugins:\nThrottle Concurrent Builds, Lockable Resources\nor\nExclusions.\n\nTest parallelization on multiple nodes requires using of multiple projects or\nMatrix configurations, so it causes job chaining again.\n\nThese build chains can be created via\nParameterized Trigger and\nCopy Artifacts, but it complicates job management and build history investigation.\n\nHardware infrastructure is usually flaky.\nIf it fails during the build due to any reason, it’s hard to diagnose the issue and re-run the project if the issue comes from hardware.\n\nBuild Failure Analyzer allows to identify the root cause of a build failure (e.g. by build log parsing).\n\nConditional Build Step and\nFlexible Publish plugins allow altering the build flow according to the analysis results.\n\nCombination of the plugins above is possible, but it makes job configurations extremely large.\n\nTests on hardware peripherals may take much time.\nIf an infrastructure fails, we may have to restart the run from scratch.\nSo the builds should be robust against infrastructure issues including network failures and Jenkins controller restarts.\n\nTests on hardware should be reproducible, so the environment and input parameters should be controlled well.\n\nJenkins supports\ncleaning workspaces, so it can get rid of temporary files generated by previous runs.\n\nJenkins provides support of agents connected via containers (e.g.\nDocker) or VMs, which allow creating clean environments for every new run.\nIt’s important for 3rd-party tools, which may modify files outside the workspace: user home directory, temporary files, etc.\n\nThese environments still need to be connected to hardware peripherals, which may be a serious obstacle for Jenkins admins\n\nThe classic automation approaches in Jenkins are based on Free-style and Multi-configuration project types.\nLinks to various articles on this topic are collected on the\nHW/Embedded Solution page Embedded on the Jenkins website.\nTests automation on hardware peripherals has been covered in several publications by Robert Martin, Steve Harris, JL Gray, Gordon McGregor, Martin d’Anjou, and Sarah Woodall.\nThere is also a top-level overview of classic approaches made by me at JUC2015/London (a bit outdated now).\n\nOn the other hand, there is no previous publications, which would address Pipeline usage for the Embedded area.\nIn this post I want to address this use-case.\n\nPipeline as Code for test runs on hardware\n\nPipeline as Code is an approach for describing complex automation flows in software lifecycles: build, delivery, deployment, etc.\nIt is being advertised in Continuous Delivery and DevOps methodologies.\n\nIn Jenkins there are two most popular plugins:\nPipeline and Job DSL.\nJobDSL Plugin internally generates common freestyle jobs according to the script, so it’s functionality is similar to the classic approaches.\nPipeline is fundamentally different, because it provides a new engine controlling flows independently from particular nodes and workspaces.\nSo it provides a higher job description level, which was not available in Jenkins before.\n\nBelow you can find an example of Pipeline scripts, which runs tests on FPGA board. The id of this board comes from build parameters ( fpgaId). In this script we also presume that all nodes have pre-installed tools (Xilinx ISE in this case).\n\n// Run on node having my_fpga label\nnode(\"linux && ml509\") {\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  sh \"make all\"\n}\n\nBut such scenario could be also implemented in a Free-style project.\nWhat would we get from Pipeline plugin?\n\nGetting added-value from Pipeline as code\n\nPipeline provides much added-value features for hardware-based tests.\nI would like to highlight the following advantages:\n\nRobustness against restarts of Jenkins controller.\n\nRobustness against network disconnects. sh() steps are based on the\nDurable Task plugin, so Jenkins can safely continue the execution flow once the node reconnects to the controller.\n\nIt’s possible to run tasks on multiple nodes without creating complex flows based on job triggers and copy artifact steps, etc. It can be achieved via combination of parallel() and node() steps.\n\nAbility to store the shared logic in standalone Pipeline libraries\n\netc.\n\nFirst two advantages allow to improve the robustness of Jenkins nodes against infrastructure failures.\nIt is critical for long-running tests on hardware.\n\nLast two advantages address the flexibility of Pipeline flows.\nThere are also plugins for freestyle projects, but they are not flexible enough.\n\nUtilizing Pipeline features\n\nThe sample Pipeline script above is very simple.\nWe would like to get some added value from Jenkins.\n\nGeneral improvements\n\nLet’s enhance the script by using several features being provided by pipeline in order to get visualization of stages, report publishing and build notifications.\n\nWe also want to minimize the time being spent on the node with the attached FPGA board.\nSo we will split the bitfile generation and further runs to two different nodes in this case: a general purpose linux node, and the node with the hardware attached.\n\nYou can find the resulting Pipeline script below:\n\n// Synthesize on any node\ndef imageId=\"\"\nnode(\"linux\") {\n  stage \"Prepare environment\"\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  // Construct the bitfile image ID from commit ID\n  sh 'git rev-parse HEAD > GIT_COMMIT'\n  imageId= \"myprj-${fpgaId}-\" + readFile('GIT_COMMIT').take(6)\n\n  stage \"Synthesize project\"\n  sh \"make FPGA_TYPE=$fpgaId synthesize_for_fpga\"\n  /* We archive the bitfile before running the test, so it won't be lost it if something happens with the FPGA run stage. */\n  archive \"target/image_${fpgaId}.bit\"\n  stash includes: \"target/image_${fpgaId}.bit\", name: 'bitfile'\n}\n\n/* Run on a node with 'my_fpga' label.\nIn this example it means that the Jenkins node contains the attacked FPGA of such type.*/\nnode (\"linux && $fpgaId\") {\n  stage \"Blast bitfile\"\n  git url:\"https://github.com/oleg-nenashev/pipeline_hw_samples\"\n  def artifact='target/image_'+fpgaId+'.bit'\n  echo \"Using ${artifact}\"\n  unstash 'bitfile'\n  sh \"make FPGA_TYPE=$fpgaId impact\"\n\n  /* We run automatic tests.\n  Then we report test results from the generated JUnit report. */\n  stage \"Auto Tests\"\n  sh \"make FPGA_TYPE=$fpgaId tests\"\n  sh \"perl scripts/convertToJunit.pl --from=target/test-results/* --to=target/report_${fpgaId}.xml --classPrefix=\\\"myprj-${fpgaId}.\\\"\"\n  junit \"target/report_${fpgaId}.xml\"\n\n  stage \"Finalization\"\n  sh \"make FPGA_TYPE=$fpgaId flush_fpga\"\n  hipchatSend(\"${imageId} testing has been completed\")\n}\n\nAs you may see, the pipeline script mostly consists of various calls of command-line tools via the sh() command.\nAll EDA tools provide great CLIs, so we do not need special plugins in order to invoke common operations from Jenkins.\n\nMakefile above is a sample stuff for demo purposes.\nIt implements a set of unrelated routines merged into a single file without dependency declarations.\nNever write such makefiles.\n\nIt is possible to continue expanding the pipeline in such way.\nPipeline Examples\ncontain examples for common cases: build parallelization, code sharing between pipelines, error handling, etc.\n\nLessons learned\n\nDuring last 2 years I’ve been using Pipeline for Hardware test automation several times.\nThe first attempts were not very successful, but the ecosystem has been evolving rapidly.\nI feel Pipeline has become a really powerful tool, but there are several missing features.\nI would like to mention the following ones:\n\nShared resource management across different pipelines.\n\nRuns of a single Pipeline job can be synchronized using the concurrency parameter of the stage() step\n\nIt can be done by the incoming Pipeline integration in the\nLockable Resources plugin\n( JENKINS-30269).\n\nAnother case is integration with\nThrottle Concurrent Builds plugin, which is an effective engine for limiting the license utilization in automation infrastructures\n( JENKINS-31801).\n\nBetter support of CLI tools.\n\nEDA tools frequently need a complex environment, which should be deployed on nodes somehow.\n\nIntegration with\nCustom Tools Plugin seems to be the best option, especially in the case of multiple tool versions\n( JENKINS-30680).\n\nPipeline package manager ( JENKINS-34186)\n\nSince there is almost no plugins for EDA tools in Jenkins, developers need to implement similar tasks at multiple jobs.\n\nA common approach is to keep the shared \"functions\" in libraries.\n\nPipeline Global Library and\nPipeline Remote Loader can be used, but they do not provide features like dependency management.\n\nPipeline debugger ( JENKINS-34185)\n\nHardware test runs are very slow, so it is difficult to troubleshoot and fix issues in the Pipeline code if you have to run every build from scratch.\n\nThere are several features in Pipeline, which simplify the development, but we still need an IDE-alike implementation for complex scripts.\n\nConclusions\n\nJenkins is a powerful automation framework, which can be used in many areas.\nEven though Jenkins has no dedicated plugins for test runs on hardware, it provides many general-purpose \"building blocks\", which allow implementing almost any flow.\nThat’s why Jenkins is so popular in the hardware and embedded areas.\n\nPipeline as code can greatly simplify the implementation of complex flows in Jenkins.\nIt continues to evolve and extend support of use-cases.\nif you’re developing embedded projects, consider Pipeline as a durable, extensible and versatile means of implementing your automation.\n\nWhat’s next?\n\nJenkins automation server dominates in the HW/Embedded area, but unfortunately there is not so much experience sharing for these use-cases.\nSo Jenkins community encourages everybody to share the experience in this area by writing docs and articles for Jenkins website and other resources.\n\nThis is just a a first blog post on this topic.\nI am planning to provide more examples of Pipeline usage for Embedded and Hardware tests in the future posts.\nThe next post will be about concurrency and shared resource management in Pipelines.\n\nI am also going to talk about running tests on hardware at the\nupcoming Automotive event in Stuttgart on April 26th.\nThis event is being held by\nCloudBees, but there will be several talks addressing Jenkins open-source as well.\n\nIf you want to share your experience about Jenkins usage in Hardware/Embedded areas, consider submitting a talk for the\nJenkins World conference or join/organize a\nJenkins Area Meetup in your city.\nThere is also a\nJenkins Online Meetup.\n\nLinks\n\nRelated articles and events:\n\nHW/Embedded Solution page\n\nJenkins-Based CI for Heterogeneous Hardware/Software Projects\n\nAccelerating Automotive Innovation with Continuous Integration & Delivery - meetup in Stuttgart\n\nPipeline:\n\nPipeline page\n\nJenkins 2.0 and Pipeline as code overview\n\nPipeline Tutorial\n\nPipeline Examples","title":"Automating test runs on hardware with Pipeline as Code","tags":["jenkins2","pipeline","embedded"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png","srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/914ee/oleg_nenashev.png 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/1c9ce/oleg_nenashev.png 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/acb7c/oleg_nenashev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/ef6ff/oleg_nenashev.webp 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/8257c/oleg_nenashev.webp 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/6766a/oleg_nenashev.webp 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/22bfc/oleg_nenashev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/oleg_nenashev.png"},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/authors/oleg_nenashev/","twitter":"oleg_nenashev"}]}},{"node":{"date":"2016-04-01T00:00:00.000Z","id":"b8091c97-4904-5c1c-adbb-76e6349003ab","slug":"/blog/2016/04/01/march-2016-jam-st-petersburg/","strippedHtml":"On March 10th we have conducted the second Jenkins meetup in Saint Petersburg,\nRussia.  The meetup topic was\"Jenkins and Continuous Delivery\".  We had 3\ntalks addressing various aspects of Jenkins usage in this area.\n\nTalks\n\nIntroduction slides [ru]\n\nJenkins 2.0 and Pipeline-as-Code\n\nSpeaker: Oleg Nenashev, CloudBees\n\nPresentation (en)\n\nPresentation (ru)\n\nContinuous Delivery for Documentation\n\nSpeaker: Stanislav Ovchar, Motorola Solutions\n\nPresentation (ru)\n\nContinuous Delivery with Jenkins at ZeroTurnaround\n\nSpeaker: Sergei Egorov, ZeroTurnaround\n\nPresentation (en)\n\nWe also had a long Jenkins afterparty. Starting from the next meetup we hope to\nmake this part more official.\n\nLinks\n\nSt. Petersburg Meetup page (follow the events here)\n\nEvent page on the Yandex.Events portal\n\nSt. Petersburg Meetup Twitter\n\nJenkins RU Twitter\n\nJenkins RU Gitter Chat\n\nAcknowledgments\n\nThe event has been organized with the help from\nYandex and\nCloudBees.\n\nMore Jenkins meetups\n\nIf you want to organize a Jenkins meetup in St. Petersburg or to be a speaker\nthere, please contact us via the\nMeetup\ndiscussions page\n\nRegarding other areas, check out where\nJenkins Area Meetups (JAMs) are\nlocated in the world.\n\nDon’t see a JAM in your area?  Why not start your own,\nfind out\nhow.","title":"March 2016 St. Petersburg Jenkins Meetup Report","tags":["jam","jenkins_ru","jenkins2"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png","srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/914ee/oleg_nenashev.png 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/1c9ce/oleg_nenashev.png 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/bf8e1/oleg_nenashev.png 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/acb7c/oleg_nenashev.png 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/ef6ff/oleg_nenashev.webp 32w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/8257c/oleg_nenashev.webp 64w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/6766a/oleg_nenashev.webp 128w,\n/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/22bfc/oleg_nenashev.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/611f92ce782a36a3a1454a29c79753db/oleg_nenashev.png"},"blog":"https://oleg-nenashev.github.io/","github":"oleg-nenashev","html":"<div class=\"paragraph\">\n<p>Jenkins core maintainer and board member.\nOleg started using Hudson for Hardware/Embedded projects in 2008 and became an active Jenkins contributor in 2012.\nNowadays he leads several Jenkins <a href=\"/sigs\">SIGs</a>, outreach programs (<a href=\"/projects/gsoc\">Google Summer of Code</a>, <a href=\"/events/hacktoberfest\">Hacktoberfest</a>) and <a href=\"/projects/jam/\">Jenkins meetups</a> in Switzerland and Russia.\nOleg works for <a href=\"https://www.cloudbees.com/\">CloudBees</a> and focuses on key projects in the community.</p>\n</div>","id":"oleg_nenashev","irc":"oleg_nenashev","linkedin":"onenashev","name":"Oleg Nenashev","slug":"/blog/authors/oleg_nenashev/","twitter":"oleg_nenashev"}]}}]}},"pageContext":{"limit":8,"skip":416,"numPages":100,"currentPage":53}},
    "staticQueryHashes": ["3649515864"]}