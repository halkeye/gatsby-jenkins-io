{
    "componentChunkName": "component---src-templates-post-js",
    "path": "/blog/2016/06/29/from-freestyle-to-pipeline/",
    "result": {"data":{"blog":{"html":"<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<i class=\"fa icon-note\" title=\"Note\"></i>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>This is a guest post by <a href=\"https://github.com/rtyler\">R. Tyler Croy</a>, who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\n<a href=\"https://cloudbees.com\">CloudBees, Inc.</a></p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>For ages I have used the \"Build After\" feature in Jenkins to cobble together\nwhat one might refer to as a \"pipeline\" of sorts. The Jenkins project itself, a\nmajor consumer of Jenkins, has used these daisy-chained Freestyle jobs to drive\na myriad of delivery pipelines in our infrastructure.</p>\n</div>\n<div class=\"paragraph\">\n<p>One such \"pipeline\" helped drive the complex process of generating the pretty\nblue charts on\n<a href=\"https://stats.jenkins.io/jenkins-stats/svg/svgs.html\">stats.jenkins.io</a>.\nThis statistics generation process primarily performs two major tasks, on rather\nlarge sets of data:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Generate aggregate monthly \"census data.\"</p>\n</li>\n<li>\n<p>Process the census data and create trend charts</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>The chained jobs allowed us to resume the independent stages of the pipeline,\nand allowed us to run different stages on different hardware (different\ncapabilities) as needed. Below is a diagram of what this looked like:</p>\n</div>\n<div class=\"imageblock center\">\n<div class=\"content\">\n<img src=\"/images/post-images/freestyle-to-pipeline-2016/freestyle-pipeline.png\" alt=\"freestyle pipeline\">\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The <code>infra_generate_monthly_json</code> would run periodically creating the\naggregated census data, which would then be picked up by <code>infra_census_push</code>\nwhose sole responsibility was to take census data and publish it to the\nnecessary hosts inside the project&#8217;s infrastructure.</p>\n</div>\n<div class=\"paragraph\">\n<p>The second, semi-independent, \"pipeline\" would also run periodically. The\n<code>infra_statistics</code> job&#8217;s responsibility was to use the census data, pushed\nearlier by <code>infra_census_push</code>, to generate the myriad of pretty blue charts\nbefore triggering the\n<code>infra_checkout_stats</code> job which would make sure <code>stats.jenkins.io</code> was\nproperly updated.</p>\n</div>\n<div class=\"paragraph\">\n<p>Suffice it to say, this \"pipeline\" had grown organically over a period time when\n<a href=\"/doc/pipeline\">more advanced tools</a> weren&#8217;t quite available.</p>\n</div>\n<hr>\n<div class=\"paragraph\">\n<p>When we migrated to newer infrastructure for\n<a href=\"https://ci.jenkins.io\">ci.jenkins.io</a> earlier this year I took the\nopportunity to do some cleaning up. Instead of migrating jobs verbatim, I pruned\nstale jobs and refactored a number of others into proper\n<a href=\"/solutions/pipeline\">Pipelines</a>, statistics generation being an obvious\ntarget!</p>\n</div>\n<div class=\"paragraph\">\n<p>Our requirements for statistics generation, in their most basic form, are:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Enable a sequence of dependent tasks to be executed as a logical group (a\npipeline)</p>\n</li>\n<li>\n<p>Enable executing those dependent tasks on various pieces of infrastructure\nwhich support different requirements</p>\n</li>\n<li>\n<p>Actually generate those pretty blue charts</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<i class=\"fa icon-note\" title=\"Note\"></i>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you wish to skip ahead, you can jump straight to the\n<a href=\"https://github.com/jenkins-infra/infra-statistics/blob/a6dcaa29fca9a4f61143954fb9e1300c2f995a89/Jenkinsfile\">Jenkinsfile</a>\nwhich implements our new Pipeline.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>The first iteration of the <code>Jenkinsfile</code> simply defined the conceptual stages we\nwould need:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-groovy\" data-lang=\"groovy\">node {\n    stage 'Sync raw data and census files'\n\n    stage 'Process raw logs'\n\n    stage 'Generate census data'\n\n    stage 'Generate stats'\n\n    stage 'Publish census'\n\n    stage 'Publish stats'\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>How exciting! Although not terrifically useful. When I began actually\nimplementing the first couple stages, I noticed that the Pipeline might sync\n<em>dozens</em> of gigabytes of data every time it ran on a new agent in the cluster.\nWhile this problem will soon be solved by the\n<a href=\"https://github.com/jenkinsci/external-workspace-manager-plugin\">External\nWorkspace Manager plugin</a>, which is currently being developed. Until it&#8217;s ready,\nI chose to mitigate the issue by pinning the execution to a consistent agent.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-groovy\" data-lang=\"groovy\">/* `census` is a node label for a single machine, ideally, which will be\n * consistently used for processing usage statistics and generating census data\n */\nnode('census &amp;&amp; docker') {\n    /* .. */\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Restricting a workload which previously used multiple agents to a single one\nintroduced the next challenge. As an infrastructure administrator, technically\nspeaking, I <em>could</em> just install all the system dependencies that I want on this\none special Jenkins agent. But what kind of example would that be setting!</p>\n</div>\n<div class=\"paragraph\">\n<p>The statistics generation process requires:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>JDK8</p>\n</li>\n<li>\n<p><a href=\"http://www.groovy-lang.org\">Groovy</a></p>\n</li>\n<li>\n<p>A running <a href=\"https://www.mongodb.org/\">MongoDB</a> instance</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Fortunately, with Pipeline we have a couple of useful features at our disposal:\ntool auto-installers and the\n<a href=\"https://go.cloudbees.com/docs/cloudbees-documentation/cje-user-guide/chapter-docker-workflow.html\">CloudBees\nDocker Pipeline plugin</a>.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"tool-auto-installers\"><a class=\"anchor\" href=\"#tool-auto-installers\"></a>Tool Auto-Installers</h3>\n<div class=\"paragraph\">\n<p>Tool Auto-Installers are exposed in Pipeline through the <code>tool</code> step and on\n<a href=\"https://ci.jenkins.io\">ci.jenkins.io</a> we already had JDK8 and Groovy\navailable. This meant that the <code>Jenkinsfile</code> would invoke <code>tool</code> and Pipeline\nwould automatically install the desired tool on the agent executing the current\nPipeline steps.</p>\n</div>\n<div class=\"paragraph\">\n<p>The <code>tool</code> step does not modify the <code>PATH</code> environment variable, so it&#8217;s usually\nused in conjunction with the <code>withEnv</code> step, for example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-groovy\" data-lang=\"groovy\">node('census &amp;&amp; docker') {\n    /* .. */\n\n    def javaHome = tool(name: 'jdk8')\n    def groovyHome = tool(name: 'groovy')\n\n    /* Set up environment variables for re-using our auto-installed tools */\n    def customEnv = [\n        \"PATH+JDK=${javaHome}/bin\",\n        \"PATH+GROOVY=${groovyHome}/bin\",\n        \"JAVA_HOME=${javaHome}\",\n    ]\n\n    /* use our auto-installed tools */\n    withEnv(customEnv) {\n        sh 'java --version'\n    }\n\n    /* .. */\n}</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"cloudbees-docker-pipeline-plugin\"><a class=\"anchor\" href=\"#cloudbees-docker-pipeline-plugin\"></a>CloudBees Docker Pipeline plugin</h3>\n<div class=\"paragraph\">\n<p>Satisfying the MongoDB dependency would still be tricky. If I caved in and installed\nMongoDB on a single unicorn agent in the cluster, what could I say the next time\nsomebody asked for a special, one-off, piece of software installed on our\nJenkins build agents?</p>\n</div>\n<div class=\"paragraph\">\n<p>After doing my usual complaining and whining, I discovered that the CloudBees\nDocker Pipeline plugin provides the ability to <strong>run containers</strong> inside of a\n<code>Jenkinsfile</code>. To make things even better, there are\n<a href=\"https://hub.docker.com/_/mongo/\">official MongoDB docker images</a> readily\navailable on DockerHub!</p>\n</div>\n<div class=\"paragraph\">\n<p>This feature requires that the machine has a running Docker daemon which is\naccessible to the user running the Jenkins agent. After that, running a\ncontainer in the background is easy, for example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight nowrap\"><code class=\"language-groovy\" data-lang=\"groovy\">node('census &amp;&amp; docker') {\n    /* .. */\n\n    /* Run MongoDB in the background, mapping its port 27017 to our host's port\n     * 27017 so our script can talk to it, then execute our Groovy script with\n     * tools from our `customEnv`\n     */\n    docker.image('mongo:2').withRun('-p 27017:27017') { container -&gt;\n        withEnv(customEnv) {\n            sh \"groovy parseUsage.groovy --logs ${usagestats_dir} --output ${census_dir} --incremental\"\n        }\n    }\n\n    /* .. */\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The beauty, to me, of this example is that you can pass a\n<a href=\"http://www.groovy-lang.org/Closures\">closure</a> to <code>withRun</code> which will\nexecute <em>while</em> the container is running. When the closure is finished executin,\njust the <code>sh</code> step in this case, the container is destroyed.</p>\n</div>\n<div class=\"paragraph\">\n<p>With that system requirement satisfied, the rest of the stages of the Pipeline\nfell into place. We now have a single source of truth, the\n<a href=\"https://github.com/jenkins-infra/infra-statistics/blob/master/Jenkinsfile\">Jenkinsfile</a>,\nfor the sequence of dependent tasks which need to be executed, accounting for\nvariations in systems requirements, and it actually generates\n<a href=\"https://stats.jenkins.io/jenkins-stats/svg/svgs.html\">those pretty\nblue charts</a>!</p>\n</div>\n<div class=\"paragraph\">\n<p>Of course, a nice added bonus is the beautiful visualization of our\n<a href=\"https://ci.jenkins.io/job/Infra/job/infra-statistics/\">new Pipeline</a>!</p>\n</div>\n<div class=\"imageblock center\">\n<div class=\"content\">\n<img src=\"/images/post-images/freestyle-to-pipeline-2016/stats-pipeline.png\" alt=\"The New and Improved Statistics Pipeline\">\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"links\"><a class=\"anchor\" href=\"#links\"></a>Links</h3>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"/doc/pipeline\">Pipeline documentation</a></p>\n</li>\n<li>\n<p><a href=\"https://go.cloudbees.com/docs/cloudbees-documentation/cje-user-guide/chapter-docker-workflow.html\">CloudBees Docker Pipeline plugin documentation</a></p>\n</li>\n<li>\n<p>Live <a href=\"https://ci.jenkins.io/job/Infra/job/infra-statistics/\">statistics Pipeline</a></p>\n</li>\n</ul>\n</div>\n</div>","id":"72dc398a-0c3a-5b36-949e-7687e6ecbefc","title":"Migrating from chained Freestyle jobs to Pipelines","date":"2016-06-29T00:00:00.000Z","slug":"/blog/2016/06/29/from-freestyle-to-pipeline/","authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg","srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/77b35/rtyler.jpg 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/d4a57/rtyler.jpg 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/19e71/rtyler.jpg 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/68974/rtyler.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/ef6ff/rtyler.webp 32w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/8257c/rtyler.webp 64w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/6766a/rtyler.webp 128w,\n/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/22bfc/rtyler.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}},"publicURL":"/gatsby-jenkins-io/static/c98b6de76465e89f9f5e5b331e9abfea/rtyler.jpeg"},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"/blog/authors/rtyler/","twitter":"agentdero"}]}},"pageContext":{"id":"72dc398a-0c3a-5b36-949e-7687e6ecbefc"}},
    "staticQueryHashes": ["1271460761","3649515864"]}