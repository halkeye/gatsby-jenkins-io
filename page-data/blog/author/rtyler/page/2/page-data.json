{
    "componentChunkName": "component---src-templates-author-blog-list-template-js",
    "path": "/blog/author/rtyler/page/2",
    "result": {"data":{"author":{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"},"allBlog":{"edges":[{"node":{"date":"2017-08-10T00:00:00.000Z","id":"7a11360a-42a4-5d64-8401-89a9e4f35904","slug":"/blog/2017/08/10/kubernetes-with-pipeline-acs/","strippedHtml":"This is a guest post by Pui Chee Chen,\nProduct Manager at Microsoft working on\nAzure\nDevOps open source integrations.\n\nRecently, we improved the Azure Credential plugin by\nadding a custom binding for Azure Credentials which allows you to use an\nAzure\nservice principal (the analog to a service or system account) via  the\nCredentials Binding plugin. This means it’s now trivial to run Azure CLI\ncommands from a Jenkins Pipeline. We also recently published the first version\nof the Azure App Service plugin which makes it very\neasy to deploy\nAzure Web\nApps directly from Jenkins Pipeline. While we’ll have\nmuch more to discuss in our Jenkins World presentation on\nAzure\nDevOps open source integrations, in this blog post I wanted to share some good\nsnippets of what is possible today with Jenkins Pipeline and Azure.\n\nFirst, a simple example using the Azure CLI to list resources in the\nsubscription:\n\n// Scripted //\nnode {\n    /* .. snip .. */\n    stage('Deploy') {\n        withCredentials([azureServicePrincipal('principal-credentials-id')]) {\n            sh 'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID'\n            sh 'az account set -s $AZURE_SUBSCRIPTION_ID'\n            sh 'az resource list'\n        }\n    }\n}\n// Declarative //\n\nazureServicePrincipal() cannot be used in Declarative Pipeline until\nJENKINS-46103 is\nresolved.\n\nOnce a Pipeline can interact with Azure, there are countless ways one could\nimplement continuous delivery with Jenkins and Azure. From a deploying a simple\nwebapp with the\nAzure\nApp Service plugin and the azureWebAppPublish step, or a more advanced\ncontainer-based delivery pipeline to deliver new containers to\nKubernetes\nvia Azure Container Service.\n\nWith the Docker Pipeline plugin and a little bit of\nextra scripting, a Jenkins Pipeline can also build and publish a Docker\ncontainer to an\nAzure\nContainer Registry :\n\n// Scripted //\nimport groovy.json.JsonSlurper\n\nnode {\n    def container\n    def acrSettings\n\n    withCredentials([azureServicePrincipal('principal-credentials-id')]) {\n        stage('Prepare Environment') {\n            sh 'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID'\n            sh 'az account set -s $AZURE_SUBSCRIPTION_ID'\n            acrSettings = new JsonSlurper().parseText(\n                                            sh(script: \"az acs show -o json -n my-acr\", returnStdout: true))\n        }\n\n        stage('Build') {\n            container = docker.build(\"${acrSettings.loginServer}/my-app:${env.BUILD_ID}\")\n        }\n\n        stage('Publish') {\n            /* https://issues.jenkins.io/browse/JENKINS-46108 */\n            sh \"docker login -u ${AZURE_CLIENT_ID} -p ${AZURE_CLIENT_SECRET} ${acrSettings.loginServer}\"\n            container.push()\n        }\n\n        stage('Deploy') {\n            echo 'Orchestrating a new deployment with kubectl is a simple exercise left to the reader ;)'\n        }\n    }\n}\n// Declarative //\n\nIf you have been following our\nAzure Blog, you may\nhave noticed we have shipped a lot of updates to provide better support for\nAzure on Jenkins, and vice versa, such as:\n\nHosted Jenkins. New\nSolution\nTemplate in Azure Marketplace lets you spin up a\nJenkins Controller on Azure in minutes. Not only is it easy and fast, the solution\ntemplate gives you option to scale up by selecting the VM disk type and size.\nAnd guess what? You can even select the Jenkins release type you want to use -\nLTS, weekly build or Azure verified - all under your control.\n\nContinuous integration experience. In the latest version of our\nAzure VM Agents plugin, we improved the user\nexperience and added the option to let you to select Managed Disk for disk\ntype (which is currently used extensively on\nci.jenknis.io. You no longer need to worry about\nexceeding the number of VMs on your subscription.\n\nContinuous deployment experience. Now, if\nAzure CLI is not your cup of tea, we released our first plugin to provide\ncontinuous deployment support to Azure App Service. The plugin supports all\nlanguages Azure App Service supports. We even have a walkthrough\nhere in the\nbrand new Jenkins Hub where you can find all Jenkins on Azure resources.\n\nPipeline readiness. Also, all Azure plugins are and will be pipeline ready.\nHave you been leveraging our\nAzure Storage plugin in your Pipeline?\n\nSo, what’s next? We have a big surprise in store at Jenkins World! :)\n\nWe are serious about supporting open source and the open source community.\nBe sure to catch our talk on\nAzure\nDevOps open source integrations.\nSee you at\nJenkins World 2017!\n\nJoin the Azure DevOps team at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"CI/CD with Jenkins Pipeline and Azure","tags":["plugins","kubernetes","pipeline"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2017-07-27T00:00:00.000Z","id":"92796c2d-9e8b-530e-82dd-441263269c06","slug":"/blog/2017/07/27/standardizing-builds-with-shared-libraries/","strippedHtml":"This is a guest post by Alvin Huang, DevOps Engineer at\nFireEye.\n\nAs a security company, FireEye relentlessly protects our customers from cyber attacks. To act\nquickly on intelligence and expertise learned, the feedback loop from the front lines to features\nand capabilities in software must be small. Jenkins helps us achieve this by allowing us to build,\ntest, and deploy to our hardware and software platforms faster, so we can stop the bad guys\nbefore they reach our customers.\n\nMore capabilities and functionalities in our product offerings means more applications and\nsystems, which means more software builds and jobs in Jenkins. Within the FaaS (FireEye as a\nService) organization, the tens of Jenkins jobs that were manageable manually in the web GUI\nquickly grew to hundreds of jobs that required more automation. Along the way, we outgrew\nour old legacy datacenter and were tasked with migrating 150+ Freestyle jobs on an old 1.x\nJenkins instance to a newer 2.x instance in the new datacenter in 60 days.\n\nCopying Freestyle job XML configuration files to the new server would leave\ntechnical debt.  Using Freestyle job templates would be better but for\ncomplicated jobs that require multiple templates, this would still create large\ndependency chains that would be hard to trace in the log output. Finally,\ndevelopers were not excited about having to replicate global changes, such as\nadd an email recipient when a new member joins the team, across tens of jobs\nmanually or using the\nConfiguration\nSlicer. We needed a way to migrate the jobs in a timely fashion while getting\nrid of as much technical debt as possible.\n\nJenkins Pipeline to the rescue! In 2.0, Jenkins added the capability to create pipelines as first-\nclass entities. At FireEye, we leveraged many of the features available in pipeline to aid in the\nmigration process including the ability to:\n\ncreate Pipeline as Code in a Jenkinsfile stored in SCM\n\ncreate Jenkins projects automatically when new branches or repos get added with a Jenkinsfile\n\ncontinue jobs after the Jenkins controller or build agent crashes\n\nand most importantly, build a Pipeline\nShared Library that keeps projects\nDRY and\nallows new applications to be on boarded into Jenkins within seconds\n\nHowever, Jenkins Pipeline came with a DSL that our users would have to learn to translate their\nFreestyle jobs to pipeline jobs. This would be a significant undertaking across multiple teams\njust to create Jenkins jobs. Instead, the DevOps team identified similarities across all the\nFreestyle jobs that we were migrating, learned the Jenkins DSL to become SMEs for the\norganization, and built a shared library of functions and wrappers that saved each Dev/QA\nengineer hours of time.\n\nBelow is an example function we created to promote builds in Artifactory:\n\nvars/promoteBuild.groovy\n\ndef call(source_repo, target_repo, build_name, build_number) {\n    stage('Promote to Production repo') {\n        milestone label: 'promote to production'\n        input 'Promote this build to Production?'\n\n        node {\n            Artifactory.server(getArtifactoryServerID()).promote([\n                'buildName'   : build_name,\n                'buildNumber' : build_number,\n                'targetRepo'  : target_repo,\n                'sourceRepo'  : source_repo,\n                'copy'        : true,\n            ])\n    }\n}\n\ndef call(source_repo, target_repo) {\n    buildInfo = getBuildInfo()\n\n    call(source_repo, target_repo, buildInfo.name, buildInfo.number)\n}\n\nRather than learning the Jenkins DSL and looking up how the Artifactory Plugin worked in\nPipeline, users could easily call this function and pass it parameters to do the promotion work\nfor them. In the Shared Library, we can also create build wrappers of opinionated workflows,\nthat encompasses multiple functions, based on a set of parameters defined in the Jenkinsfile.\nIn addition to migrating the jobs, we also had to migrate the build agents. No one knew the\nexact list of packages, versions, and build tools installed on each build server, so rebuilding\nthem would be extremely difficult. Rather than copying the VMs or trying to figure out what\npackages were on the build agents, we opted to use Docker to build containers with all\ndependencies needed for an application.\n\nI hope you will join me at my Jenkins World session:\nCodifying the Build and Release Process with a Jenkins\nPipeline Shared Library, as I deep dive into the inner workings of our Shared\nPipeline Library and explore how we integrated Docker into our CI/CD pipeline.\nCome see how we can turn a Jenkinsfile with just a set of parameters like this:\n\nJenkinsfile\n\nstandardBuild {\n    machine          = 'docker'\n    dev_branch       = 'develop'\n    release_branch   = 'master'\n    artifact_apttern = '*.rpm'\n    html_pattern     = [keepAll: true, reportDir: '.', reportFiles: 'output.html', reportName: 'OutputReport']\n    dev_repo         = 'pipeline-examples-dev'\n    prod_repo        = 'pipeline-examples-prod'\n    pr_script        = 'make prs'\n    dev_script       = 'make dev'\n    release_script   = 'make release'\n}\n\nand a Dockerfile like this:\n\nDockerfile\n\nFROM faas/el7-python:base\n\nRUN yum install -y python-virtualenv \\\n        rpm-build && \\\n        yum clean all\n\nInto a full Jenkins Pipeline like this:\n\nAs we look ahead at FireEye, I will explore how the Shared Library sets us up for easier future\nmigrations of other tools such as Puppet, JIRA, and Artifactory, and easier integration with new\ntools like Openshift. I will also cover our strategies for deployments and plans to move to\nDeclarative Pipeline.\n\nAlvin will be\npresenting\nmore on this topic at\nJenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Codifying the Build and Release Process with a Pipeline Shared Library","tags":["event","JenkinsWorld"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2017-03-16T00:00:00.000Z","id":"6d526060-b7a0-5b2a-be93-1daeaaa98ed6","slug":"/blog/2017/03/16/fosdem-event-report/","strippedHtml":"In early February numerous free and open source developers from around the\nworld traveled to Brussels, Belgium, for arguably the largest event of its\nkind:\nFOSDEM. Among the thousands of hackers in attendance\nwere a dozen or so Jenkins contributors. We have attended the event in the\npast, but this year we had a blizzard of activity spanning four days around the FOSDEM\nweekend.\n\nFigure 1. City Hall, photo by Kohsuke Kawaguchi\n\nOne of our \"accidental traditions\" has become a\nhappy hour\nthe Friday night before FOSDEM truly begins at Cafe Le Roy d’Espagne on Grand\nPlace right in the middle of Brussels. Conveniently located a few hundred meters away from the\nFOSDEM Beer Event\nat Delirium Cafe, each year we are inevitably joined by friends from other open\nsource projects who know they’re welcome to join us for a few drinks.\n\nFigure 2. Cafe Le Roy, photo by Kohsuke Kawaguchi\n\nAfter dinner and drinks, a few of us decided it would be a good idea (it\nwasn’t) to walk over to check out the FOSDEM Beer Event and maybe have just\none more beer. For the uninitiated, Belgian beers tend to be strong, as the FOSDEM organizers warn:\n\nUnlike some other beers, Belgian beer is not just coloured water. Some beers\ncontain significant quantities of alcohol and will give you a pounding\nhangover.\n\nUnfortunately, some of us seem to re-learn this lesson each year at FOSDEM!\n\nBright and early the following day, FOSDEM really kicked off with keynotes and\nthe project tables lining a number of corridors.\n\nFigure 3. A busy hall at FOSDEM, photo by Kohsuke Kawaguchi\n\nAt the Jenkins project’s table we typically spend two full days answering questions,\nshowing off the latest and greatest Jenkins features, and of course handing out\nJenkins stickers. The table is where many contributors, myself included, have\na rare opportunity to talk with dozens of enthusiastic Jenkins users from\nacross the broader open source community. This year we were very fortunate to have a\ntremendous number of contributors available at the table to answer hundreds of\nquestions throughout the two days of FOSDEM.\n\nI would like to thank everybody by name, but the entire weekend was such a blur\nthat I’m not sure I would be able to remember everybody who helped! We couldn’t have\nhad a successful event without their support, so many thanks to all the\ncontributors who helped!\n\nIn addition to the Jenkins project table, we had two contributors present in\nthe\nTesting and Automation\ndevroom, which I helped organize in between answering Jenkins questions.\n\nDeclarative Pipelines in Jenkins\n\nThe first presentation was a stellar introduction to\nDeclarative Pipelines\nin Jenkins, by long-time contributor and primary developer of Declarative\nPipeline support,\nAndrew Bayer.\n\nUsing Containers for Building and Testing\n\nLater in the day,\nCarlos Sanchez,\nanother long-time contributor, maintainer of the\nKubernetes plugin and a number of Jenkins- and Maven-related\nDocker containers, provided a great overview of the current state of using\ncontainers for building and testing in Jenkins.\n\nAfter a very busy two days at FOSDEM, a few contributors remained in Brussels\nfor a day-long\nPost-FOSDEM Contributor Hackathon\nsponsored by CloudBees, Inc. and\nBetacowork Brussels. Trying to cram lots of\nhacking into a single day is challenging, so the day was mostly filled with\ndiscussions, some light prototyping, and a bit of recovery from the hectic\nweekend at FOSDEM. :)\n\nFigure 4. Daniel Beck presenting on CLI prototyping, photo by Kohsuke Kawaguchi\n\nThanks\n\nOf course I would like to extend many thanks to all the contributors who\nparticipated in the various FOSDEM related events, but I would call special\nattention to the logistics and planning work done by contributors Alyssa Tong,\nDamien Duportal, and Olivier Vernin. Thanks to their work coordinating all the\nplans, reservations, and schedules, we had a flawless weekend\nof high-intensity Jenkins discussion, advocacy, and hacking.\n\nI hope to see everybody back in Brussels next year for FOSDEM 2018!","title":"FOSDEM 2017 Wrap-up","tags":["fosdem","event"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-12-31T00:00:00.000Z","id":"3267c8fe-f10e-530a-9caa-bae9eeb34fb0","slug":"/blog/2016/12/31/what-a-year/","strippedHtml":"I do not think it is an exaggeration to say: 2016 was the best year yet for the\nJenkins project. Since the first commit in 2006, the project has reached a\nnumber of significant milestones in its ten years but we have never experienced\nthe breadth of major milestones in such a short amount of time. From\nJenkins 2\nand\nBlue Ocean\nto the\nGoogle Summer of Code\nand\nJenkins World,\n\nI wanted to take a moment and celebrate the myriad of accomplishments which\ncouldn’t have happened without the help from everybody who participates in the\nJenkins project. The 1,300+ contributors to the\njenkinsci GitHub organization,\nthe 4,000+ members of the\ndevelopers mailing list,\nthe 8,000+ members of the\nusers mailing list,\nand countless others who have reported issues, submitted pull requests, and\npresented at meetups and conferences.\n\nJenkins 2\n\nThrough the course of 2016, the Jenkins project published 16\nLTS releases\nand 54\nWeekly releases.\nOf those 70 releases, the most notable may have been the\nJenkins 2.0 release\nwhich was published in April.\n\nJenkins 2 made Pipeline as Code front-and-center in the user experience,\nintroduced a new \"Getting Started\" experience, and included a number of other\nsmall UI improvements, all while maintaining backwards compatibility with\nexisting Jenkins environments.\n\nSince April, we have released a number of LTS\nreleases using Jenkins 2 as a baseline, meaning the Jenkins project no longer\nmaintains any 1.x release lines.\n\nThe\nPipeline\nefforts have continuted to gain steam since April, covered on this blog with a\nnumber of\nposts tagged \"pipeline\". Closing out 2016 with the\nannouncement of the beta for\nDeclarative Pipeline syntax\nwhich is expected in early 2017.\n\nBlue Ocean\n\nHot on the heels of Jenkins 2 announcement\"Blue Ocean, a new user experience for Jenkins\",\nwas\nopen sourced in May.\nBlue Ocean is a new project that rethinks the user experience of Jenkins.\nDesigned from the ground up for Jenkins Pipeline and compatible with Freestyle\njobs. The goal for the project is to reduce clutter and increase clarity for\nevery member of a team using Jenkins.\n\nThe Blue Ocean beta can be installed from the Update Center and can be run in\nproduction Jenkins environments alongside the existing UI. It adds the new user experience under\n/blue in the environment but does not disturb the existing UI.\n\nBlue Ocean is expected to reach \"1.0\" in the first half of 2017.\n\nAzure\n\nAlso in May of 2016, the Jenkins project announced an exciting\nPartnership with Microsoft\nto run our project infrastructure on\nAzure. While the migration of Jenkins project\ninfrastructure into Azure is still on-going, there have been some notable\nmilestones reached already:\n\nEnd-to-end TLS encrypted delivery for Debian/openSUSE/Red Hat repositories which are\nconfigured to use https://pkg.jenkins.io by the end-user.\n\nMajor capacity improvements to\nci.jenkins.io\nproviding on-demand Ubuntu and Windows build/test infrastructure.\n\nA full continuous delivery Pipeline for all Azure-based infrastructure using\nTerraform from Jenkins.\n\nThe migration to Azure is expected to complete in 2017.\n\nGoogle Summer of Code\n\nFor the first time in the history of the project, Jenkins was accepted into\nGoogle Summer of Code\n2016. Google Summer of Code (GSoC) is an annual, international, program\nwhich encourages college-aged students to participate with open source projects\nduring the summer break between classes. Students accepted into the program\nreceive a stipend, paid by Google, to work well-defined projects to improve or\nenhance the Jenkins project.\n\nIn exchange, numerous Jenkins community members volunteered as \"mentors\" for\nstudents to help integrate them into the open source community and succeed in\ncompleting their summer projects.\n\nA lot was learned during the summer which we look forward to applying to Google\nSummer of Code 2017\n\nJenkins World\n\nIn September, over one thousand people attended\nJenkins World,\nin Santa Clara, California.\n\nFollowing the event,\nLiam\nposted a series of blog posts which highlight some of the fantastic content\nshared by Jenkins users and contributors from around the world, such as:\n\nThe demos from the \"Experts\"\n\nSessions on Scaling Jenkins\n\nUsing Jenkins Pipeline\n\nThe Contributor Summit\n\nJenkins World was the first global event of its kind for Jenkins, it brought users\nand contributors together to exchange ideas on the current state of the\nproject, celebrate accomplishments of the past year, and look ahead at all the\nexiting enhancements coming down the pipe(line).\n\nIt was such a smashing success that\nJenkins World 2017\nis already scheduled for August 30-31st in San Francisco, California.\n\nJAM\n\nFinally, 2016 saw tremendous growth in the number of\nJenkins Area Meetups\n(JAMs) hosted around the world. JAMs are local meetups intended to bring\nJenkins users and contributors together for socializing and learning. JAMs are\norganized by local Jenkins community members who have a passion for sharing new\nJenkins concepts, patterns and tools.\n\nDriven by current Jenkins Events Officer,\nAlyssa Tong,\nand the dozens of passionate organizers, JAMs have become a great way to meet\nother Jenkins users near you.\n\nWhile we don’t yet have JAMs on each of the seven continents, you can always join the\nJenkins Online Meetup.\nThough we’re hoping more groups will be founded near you in 2017!\n\nI am personally grateful for the variety and volume of contributions made by\nthousands of people to the Jenkins project this year. I believe I can speak for\nproject founder,\nKohsuke Kawaguchi,\nin stating that the Jenkins community has grown beyond our anything we could\nhave imagined five years ago, let alone ten!\n\nThere are number of ways to\nparticipate\nin the Jenkins project, so if you didn’t have an opportunity to join in during\n2016, we hope to see you next year!","title":"Thank you for an amazing 2016","tags":["jam","jenkins2","pipeline","blueocean","azure","gsoc","new-year-blogpost"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-11-12T00:00:00.000Z","id":"8957e4ed-d485-505d-a0dd-5f3eaa1932fe","slug":"/blog/2016/11/12/addressing-remote-vulnerabilities-in-cli/","strippedHtml":"The Jenkins\nsecurity team\nhas been made aware of a new attack vector for a remote code execution\nvulnerability in the\nJenkins CLI,\naccording to\nthis\nadvisory\nby Daniel Beck:\n\nWe have received a report of a possible unauthenticated remote code execution\nvulnerability in Jenkins (all versions).\n\nWe strongly advise anyone running a Jenkins instance on a public network\ndisable the CLI for now.\n\nAs this uses the same attack vector as SECURITY-218, you can reuse the script\nand instructions published in this repository: https://github.com/jenkinsci-cert/SECURITY-218\n\nWe have since been able to confirm the vulnerability and strongly recommend\nthat everyone follow the instructions in the linked repository.\n\nAs Daniel mentions in the security advisory, the advised mitigation strategy is\nto disable the CLI subsystem via\nthis\nGroovy script.\nIf you are a Jenkins administrator, navigate to the 'Manage Jenkins' page and\nclick on the 'Script Console', which will allow you to run the Groovy script to\nimmediately disable the CLI.\n\nIn order to persist this change across restarts of your Jenkins controller, place\nthe\nGroovy script\nin $JENKINS_HOME/init.groovy.d/cli-shutdown.groovy so that Jenkins executes\nthe script on each boot.\n\nWe are expecting to have a fix implemented, tested and included in an updated\nweekly and LTS release this upcoming Wednesday, November 16th.\n\nFor users who are operating Jenkins on public, or otherwise hostile, networks,\nwe suggest hosting Jenkins behind reverse proxies such as Apache or Nginx.\nThese can help provide an additional layer of security, when used appropriately,\nto cordon off certain URLs such as /cli.\n\nAdditionally, we strongly recommend that all Jenkins administrators subscribe\nto the\njenkinsci-advisories@googlegroups.com\nmailing list to receive future advisories.\n\nThe Jenkins project has a responsible disclosure policy, which we strongly\nencourage anybody who believes they have discovered a potential vulnerability\nto follow. You can learn more about this policy and our processes on our\nsecurity page.","title":"Addressing recently disclosed vulnerabilities in the Jenkins CLI","tags":["security","lts"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-09-08T00:00:00.000Z","id":"51fd82b2-e6d8-562f-a3a7-329013385e5a","slug":"/blog/2016/09/08/continuous-delivery-of-infra/","strippedHtml":"This is a guest post by Jenkins World speaker\nR Tyler Croy, infrastructure maintainer for the\nJenkins project.\n\nI don’t think I have ever met a tools, infrastructure, or operations team that\ndid not have a ton of work to do. The Jenkins project’s\ninfrastructure\"team\" is no different; too much work, not enough time. In lieu of hiring more\npeople, which isn’t always an option, I have found heavy automation and\ncontinuous delivery pipelines to be two solutions within reach of the\nover-worked infrastructure team.\n\nAs a big believer in the concept of \"Infrastructure as Code\", I have been,\nslowly but surely, moving the project’s infrastructure from manual tasks to\ncode, whether implemented in our\nPuppet code-base,\nDocker containers,\nor even as\nmachine specifications\nwith\nPacker.\nThe more of our infrastructure that is code, the more we can apply continuous\ndelivery practices to consistently and reliably build, test and deliver our\ninfrastructure.\n\nThis approach integrates nicely with\nJenkins Pipeline,\nallowing us to also define our continuous delivery pipelines themselves as\ncode. For example, by sanity-checking our BIND zone files:\n\nJenkinsfile\n\nnode('docker') {\n    def dockerImage = 'rtyler/jenkins-infra-builder'\n\n    checkout scm\n    docker.image(dockerImage).inside {\n        sh \"/usr/sbin/named-checkzone jenkins-ci.org dist/profile/files/bind/jenkins-ci.org.zone\"\n        sh \"/usr/sbin/named-checkzone jenkins.io dist/profile/files/bind/jenkins.io.zone\"\n    }\n}\n\nOr delivering our Docker containers automatically to\nDocker Hub, with a Jenkinsfile such as:\n\nJenkinsfile\n\nnode('docker') {\n    checkout scm\n\n    /* Get our abbreviated SHA-1 to uniquely identify this build */\n    def shortCommit = sh(script: 'git rev-parse HEAD', returnStdout: true).take(6)\n\n    stage 'Build ircbot' {\n        withEnv([\"JAVA_HOME=${tool 'jdk8'}\", \"PATH+MVN=${tool 'mvn'}/bin\"]) }\n            sh 'make bot'\n        }\n    }\n\n    def whale\n    stage 'Build container' {\n        whale = docker.build(\"jenkinsciinfra/ircbot:build${shortCommit}\")\n    }\n\n    stage 'Deploy container' {\n        /* Push to Docker Hub */\n        whale.push()\n    }\n}\n\nIn\nmy talk at Jenkins World\n(September 14th, 3:00 - 3:45pm in Exhibit Hall A-1) I will discuss these\nJenkinsfiles along with some of the strategies, patterns and code used with the\nJenkins project’s\nopen source\ninfrastructure to get the most out of the team’s limited time.\n\nR Tyler will be\npresenting\nmore about continous delivery of infrastructure at\nJenkins World\nin September.  Register with the code JWFOSS for 20% off your full conference\npass.","title":"Continuous Delivery of Infrastructure with Jenkins","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-09-07T00:00:00.000Z","id":"a11e3798-132b-51c1-b4f2-5be067a487f4","slug":"/blog/2016/09/07/pipeline-at-jenkins-world/","strippedHtml":"This is a guest post by R. Tyler Croy, who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\nCloudBees, Inc.\n\nI have been heavily using Jenkins Pipeline for just about\nevery Jenkins-related project I have contributed to over the past year. Whether I am\nbuilding and publishing Docker\ncontainers, testing\ninfrastructure code or\npublishing this very web\nsite, I have been adding a Jenkinsfile to nearly every Git repository I\ntouch.\n\nImplementing Pipeline has been rewarding, but has not been without its own\nchallenges. That’s why I’m excited to see lots of different Jenkins Pipeline\nrelated content in the agenda at\nJenkins World.\n\nI don’t think it’s possible for a single person to attend all of the Pipeline\ntalks, or the Pipeline-related demos\nin the \"Open Source Hub\", but fortunately CloudBees\nwill be recording the sessions. If you have Pipeline-related questions unanswered by\nall these presentations, feel free to join us at the \"Open Source Hub\" in the\nexpo hall and Ask the\nExperts.\n\nOn the first day of Jenkins World (September 13th), Isaac Cohen is hosting a\nworkshop titled\nLet’s\nBuild a Jenkins Pipeline which may be interesting to you if you haven’t yet\nworked with Pipeline.\n\nPipelining\nDevOps with Jenkins and AWS\n\nSeptember 14th 2:00 PM - 2:45 PM, Exhibit Hall A-1\n\nAutomated workflow is a proven method for removing process variability. DevOps\npipelines are the next step in the evolution of CI/CD/DevOps. This talk covers\nJenkins pipelines, both with and without AWS integration, and explains how\nJenkins can be used to create, execute and manage pipelines.\n\n— Jimmy Ray of nextSource\n\nPerfecting\nYour Development Tools: Updates to the Helix Plugin for Jenkins\n\nSeptember 14th 5:00 PM - 6:00 PM, Exhibit Hall C\n\nConsidering a mono repo that can manage all your source code, binary and other\nassets? Join us at the Perforce Birds of a Feather Session for updates and\ndiscussions around the Helix Plugin for Jenkins (or ‘P4 plugin’).\n\nThis session will look at the latest DSL PipeLine support in the ‘P4 plugin’\nfor Jenkins and will include a live demo. We will show you how to map your\nBranches and Streams into a Jenkins Workspace, publish assets back into\nHelix, and more. You may even get a sneak preview at the latest ‘P4 plugin’\nfor Jenkins that allows you the freedom to query and run commands from\nwithin Jenkins directly against your Helix connection.\n\n— Paul Allen of Perforce\n\nContinuously\nDeploying Containers with Jenkins Pipeline to Docker Swarm Cluster\n\nSeptember 14th 3:00 PM - 3:45 PM, Exhibit Hall A-3\n\nMany of us have already experimented with Docker - for example, by running one\nof the pre-built images from Docker Hub. It is possible that your team might\nhave recognized the benefits that Docker provides in building microservices and\nthe advantages the technology could bring to development, testing, integration\nand, ultimately, production. However, you must create a comprehensive build\npipeline before deploying any containers into a live environment. Integrating\ncontainers into a CD pipeline is far from easy. Along with the benefits Docker\nbrings, there are challenges both technically and process-related. This\npresentation attempts to outline the steps you need to take for a\nfully-automated Jenkins pipeline that continuously builds, tests and deploys\nmicroservices into a Docker Swarm cluster.\n\n— Viktor Farcic\n\nNo,\nYou Shouldn’t Do That! Lessons from Using Pipeline\n\nSeptember 15th 10:30 AM - 11:15 AM, Exhibit Hall A-1\n\nPipeline is as powerful as a loaded gun, but with skill can be as delicate as a\nsurgeon’s knife. This talk will give an overview of health and safety so that\nyou can avoid shooting yourself in the head and walk the path to medical\nschool. It will cover not only what not to do, but also why, and share some\nsolutions so you are not left high and dry. Both James and Bobby have bullet\nwounds from “Champagning” pipeline to automate the test and release of several\nof the CloudBees products and can occasionally still be seen walking with a\nlimp from shooting for the moon and hitting their feet.\n\n— Bobby Sandell and James T. Nord of CloudBees\n\nDocker\nImage Lifecycle Implemented with Jenkins Pipeline\n\nSeptember 15th 11:30 AM - 12:15 PM, Exhibit Hall A-2\n\nWhile Docker has enabled an unprecedented velocity of software production, it\nis all too easy to spin out of control. A promotion-based model is required to\ncontrol and track the flow of Docker images as much as it is required for a\ntraditional software development lifecycle. We will demonstrate how to go from\ndevelopment to containerization to distribution utilizing binary management\npromotion in a framework implemented on Jenkins, using the Pipeline\nfunctionality.\n\n— Mark Galpin\n\nDirections for Pipeline\n\nSeptember 15th 11:30 AM - 12:15 PM, Exhibit Hall A-1\n\nThe Pipeline feature has matured and is now included in Jenkins 2.0. During the\ntime since its release, copious user feedback has been received about missing\nfeatures and pain points. Come hear about some things we know should be worked\non - or are already in progress - and bring your suggestions.\n\n— Jesse Glick of CloudBees\n\nHow\nto Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes\n\nSeptember 15th 2:30 PM - 3:15 PM, Great America J\n\nIn this talk, we’ll show how to use Jenkins Pipeline together with Docker and\nKubernetes to implement a complete end-to-end continuous delivery and\ncontinuous improvement system for microservices and monolithic applications\nusing open source software. We’ll demonstrate how to easily create new\nmicroservices projects or import existing projects, have them automatically\nbuilt, system and integration tested, staged and then deployed. Once deployed,\nwe will also see how to manage and update applications using continuous\ndelivery practices along with integrated ChatOps - all completely automated!\n\n— James Strachan of Red Hat\n\nIntroducing\na New Way to Define Jenkins Pipelines\n\nSeptember 15th 3:45 PM - 4:30 PM, Great America J\n\nPipeline is quickly establishing itself as the direction that Jenkins jobs are\ngoing, enabling the definition of a complete CD pipeline in a single job;\nPipeline as Code via the “Jenkinsfile”; job durability across controller restarts;\nand more. I’ll be talking here about the next evolution for Pipeline: a simple,\ndeclarative model to define your Pipelines with no need to write scripts. This\nconfiguration syntax for Pipeline allows you to automatically configure all\nstages of your pipeline, the complete build environment, post-build actions,\nnotifications and more. All while providing syntactic and semantic validation\nbefore the build actually gets going.\n\n— Andrew Bayer of CloudBees\n\nThe\nNeed For Speed: Building Pipelines To Be Faster\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall A-1\n\nResponse time is paramount for a CI/CD system. In this session, you will see\nhow a few best practices in constructing pipelines can yield faster turnaround\ntimes and reduced resource use. We’ll also run through plugins and tools to\nanalyze and visualize performance, including the Pipeline Stage View plugin. If\ntime permits, we may briefly discuss some of the computer science theory behind\ndifferent aspects of performance.\n\n— Sam Van Oort of CloudBees\n\nContinuously Delivering\nContinuous Delivery Pipelines\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall J\n\nOur 600-person IT organization has committed to implementing continuous\ndelivery practices enterprise-wide. This isn’t a single momentous event put in\nplace overnight. Rather, it’s a strategic journey towards a common goal, and\nthrough which each application will take its own unique path. A seminal\ncomponent of our CD journey is the Pipeline plugin and it has become our\nstandard for CD pipeline orchestration. We will discuss a few of the diverse\npaths taken by the application teams at our company and show how the use of the\nPipeline plugin has uniquely enabled continuous delivery for us in a way that\nno competing tool can.\n\n— Neil Hunt of Aquilent\n\nCD Pipelines as Code with\nGithub and Bitbucket\n\nSeptember 15th 4:45 PM - 5:30 PM, Exhibit Hall J\n\nPipeline Multibranch projects come as a natural evolution of pipeline as code:\ndefine your CD pipeline in your source code repository and Jenkins will create\nisolated branch and pull requests jobs for it. This talk is about the\nintegration of the Pipeline Multibranch plugin with Github and Bitbucket as\nbranch sources.\n\n— Antonio Muñiz of CloudBees\n\nRegister for Jenkins World in\nSeptember with the code JWFOSS for a 20% discount off your pass.","title":"Pipeline at Jenkins World 2016","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}},{"node":{"date":"2016-09-01T00:00:00.000Z","id":"029c2b9c-b402-58ba-b094-5060a9fa4c30","slug":"/blog/2016/09/01/jenkins-world-contributor-summit/","strippedHtml":"At previous Jenkins User Conferences we have hosted \"Contributor Summits\" to\ngather developers and power-users in one room to discuss specific areas of\nJenkins, such as Scalability, Pipeline, etc. As part of this year’s\nJenkins World we’re hosting\nanother Contributor\nSummit, to discuss: Blue Ocean ,\nPipeline and Storage Pluggability.\n\nContributors to these three areas of the Jenkins ecosystem will be in\nattendance to present details of their design, requirements, and tentative\nroadmaps. After the presentations, the afternoon will be \"unconference style\" which\nis much more fluid to allow discussions, feedback, and brain-storming around\nthe three focus areas.\n\nThe program for the\nJenkins World\nContributor Summit includes:\n\nUpdates from the various project\nofficers.\n\nA discussion of the Blue Ocean technology stack,\noverall architecture, and how to develop plugins that integrate with Blue\nOcean. Led by Keith Zantow.\n\nPresentation on the current status of Pipeline, lessons\nlearned, new changes and the future. Led by\nJesse Glick.\n\nOverview of \"Storage Pluggability\", a new scalability-oriented project to\nrevamp the underlying storage mechanisms in Jenkins. Led by\nKohsuke Kawaguchi.\n\nI cannot recommend participating in the Contributor Summit enough. I have found\nprevious Summits to be immensely useful for sharing my own thoughts, as well as\nfor hearing new perspectives from the others in attendance.\n\nOur space is limited however! I encourage you to join us, so please\nRSVP soon!\n\nRegister for Jenkins World in\nSeptember with the code JWFOSS for a 20% discount off your pass.","title":"Jenkins World Contributor Summit","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":{"childImageSharp":null},"blog":"http://unethicalblogger.com","github":"rtyler","html":"<div class=\"paragraph\">\n<p>R&#46; Tyler Croy has been part of the Jenkins project for the past seven years.\nWhile avoiding contributing any Java code, Tyler is involved in many of the\nother aspects of the project which keep it running, such as this website,\ninfrastructure, governance, etc.</p>\n</div>","id":"rtyler","irc":null,"linkedin":null,"name":"R. Tyler Croy","slug":"blog/author/rtyler","twitter":"agentdero"}]}}]}},"pageContext":{"author":"rtyler","limit":8,"skip":8,"numPages":21,"currentPage":2}},
    "staticQueryHashes": ["3649515864"]}