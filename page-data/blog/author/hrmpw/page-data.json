{
    "componentChunkName": "component---src-templates-author-blog-list-template-js",
    "path": "/blog/author/hrmpw",
    "result": {"data":{"author":{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"/blog/author/hrmpw","twitter":"hrmpw"},"allBlog":{"edges":[{"node":{"date":"2017-02-03T00:00:00.000Z","id":"eba78b86-bbf2-5022-a3c9-27efc09a20e1","slug":"/blog/2017/02/03/declarative-pipeline-ga/","strippedHtml":"This is a guest post by\nPatrick Wolf,\nDirector of Product Management at\nCloudBees\nand contributor to\nthe Jenkins project.\n\nI am very excited to announce the addition of\nDeclarative Pipeline syntax\n1.0 to\nJenkins Pipeline.\nWe think this new syntax will enable everyone involved in DevOps, regardless of expertise,\nto participate in the continuous delivery process. Whether creating, editing or reviewing\na pipeline, having a straightforward structure helps to understand and predict the\nflow of the pipeline and provides a common foundation across all pipelines.\n\nPipeline as Code\n\nPipeline as Code was one of the pillars of the Jenkins 2.0 release and an\nessential part of implementing continuous delivery (CD). Defining all of the\nstages of an application’s CD pipeline within a Jenkinsfile and checking it\ninto the repository with the application code provides all of the benefits\ninherent in source control management (SCM):\n\nRetain history of all changes to Pipeline\n\nRollback to a previous Pipeline version\n\nView diffs and merge changes to the Pipeline\n\nTest new Pipeline steps in branches\n\nRun the same Pipeline on a different Jenkins server\n\nGetting Started with Declarative Pipeline\n\nWe recommend people begin using it for all their Pipeline definitions in Jenkins.\nThe plugin has been available for use and testing starting with the 0.1 release that was debuted at\nJenkins World\nin September. Since then, it has already been installed in over 5,000 Jenkins\nenvironments.\n\nIf you haven’t tried Pipeline or have considered Pipeline in the past, I\nbelieve this new syntax is much more approachable with an easier adoption curve\nto quickly realize all of the benefits of Pipeline as Code. In addition, the\npre-defined structure of Declarative makes it possible to create and edit\nPipelines with a graphical user interface (GUI). The Blue Ocean team is\nactively working on a\nVisual Pipeline Editor\nwhich will be included in an upcoming release.\n\nIf you have already begun using Pipelines in Jenkins, I believe that this new\nalternative syntax can help expand that usage.\n\nThe original syntax for defining Pipelines in Jenkins is a Groovy DSL that\nallows most of the features of full\nimperative programming.\n\nThis syntax is still fully supported and is now\nreferred to as \"Scripted Pipeline Syntax\" to distinguish it from \"Declarative\nPipeline Syntax.\" Both use the same underlying execution engine in Jenkins and\nboth will generate the same results in\nPipeline Stage View\nor Blue Ocean visualizations. All existing\nPipeline steps,\nGlobal Variables, and\nShared Libraries\ncan be used in either. You can now create more cookie-cutter Pipelines and\nextend the power of Pipeline to all users regardless of Groovy expertise.\n\nDeclarative Pipeline Features\n\nSyntax Checking\n\nImmediate runtime syntax checking with explicit error messages.\n\nAPI endpoint for linting a Jenkinsfile.\n\nCLI command to lint a Jenkinsfile.\n\nDocker Pipeline integration\n\nRun all stages in a single container.\n\nRun each stage in a different container.\n\nEasy configuration\n\nQuickly define parameters for your Pipeline.\n\nQuickly define environment variables and credentials for your Pipeline.\n\nQuickly define options (such as timeout, retry, build discarding) for your Pipeline.\n\nRound trip editing with the Visual Pipeline Editor (watch for preview release shortly).\n\nConditional actions\n\nSend notifications or take actions depending upon success or failure.\n\nSkip stages based on branches, environment, or other Boolean expression.\nrelease shortly)\n\nWhere Can I Learn More?\n\nBe on the lookout for future blog posts detailing specific examples of\nscenarios or features in Declarative Pipeline. Andrew Bayer, one of the primary\ndevelopers behind Declarative Pipeline, will be presenting at\nFOSDEM\nin Brussels, Belgium this weekend. We have also scheduled an online\nJenkins Meetup (JAM)\nlater this month to demo the features of Declarative Pipeline and give a sneak\npeek at the upcoming Blue Ocean Pipeline Editor.\n\nIn the meantime, all the\nPipeline documentation\nhas been updated to incorporate a\nGuided Tour,\nand a\nSyntax Reference\nwith numerous examples to help you get on your way to using Pipeline.  Simply\nupgrade to the latest version, 2.5 or later of the Pipeline in Jenkins to\nenable all of these great features.","title":"Declarative Pipeline Syntax 1.0 is now available","tags":["pipeline","blueocean"],"authors":[{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"/blog/author/hrmpw","twitter":"hrmpw"}]}},{"node":{"date":"2016-12-19T00:00:00.000Z","id":"584ac2c5-5d3d-5e1c-bcbe-5ef1ef71e42e","slug":"/blog/2016/12/19/declarative-pipeline-beta/","strippedHtml":"Last week we released version 0.7.1 of the\nPipeline-Model-Defintion\nplugin and wanted to crown it as the official Beta version of the Declarative\nPipeline syntax. Although it has been available in the update center\nsince August,\nwe continue to solidify the syntax. We feel this release is getting\nvery close to the final version and should not change much before 1.0. However,\nit is still a Beta so further tweaks are possible.\n\nA release (0.8.0) is planned for early January 2017 which will finalize the\nsyntax with the following changes:\nJENKINS-40524,\nJENKINS-40370,\nJENKINS-40462,\nJENKINS-40337\n\nWhat is Declarative Pipeline?\n\nAll the way back at Jenkins World in September, Andrew Bayer presented a\nsneak peak\nof a new syntax for constructing Pipelines. We are calling this new syntax\nDeclarative Pipeline to differentiate it from the existing Scripted Pipeline\nsyntax that has always been a part of Pipeline.\n\nAfter listening to many Jenkins users over the last year we felt that, while\nPipeline Script provides tremendous power, flexibility, and extensibility, the\nlearning curve for Scripted Pipeline was steep for users new to either Jenkins\nor Pipeline. Beginning users wanting to take advantage of all the features\nprovided by Pipeline and Jenkinsfiles were required to learn Scripted Pipeline\nor remain limited to the functionality provided by Freestyle jobs.\n\nDeclarative Pipeline does not replace Scripted Pipeline but extends Pipeline it\nwith a pre-defined structure to let users focus entirely on the steps\nrequired at each stage without needing to worry about scripting every aspect\nof the pipeline. Granular flow-control is extremely powerful and Scripted\nPipeline syntax will always be part of Pipeline but it’s not for everyone.\n\nDeclarative Pipeline enables all users to connect simple, declarative blocks\nthat define agents (including Docker), post actions, environment\nsettings, credentials and all stages that make up the pipeline. Best of all,\nbecause this Declarative syntax is part of Pipeline, all build steps and build\nwrappers available in Plugins or loaded from Shared Libraries are also\navailable as steps in Declarative.\n\nExample\n\nBelow is an example of a pipeline in Declarative syntax. You can also switch the view to show the same pipeline in Scripted syntax.\n The Declarative syntax has a more straightforward structure that is easier to grok by users not versed in Groovy.\n\n// Declarative //\npipeline {\n  agent  label:'has-docker', dockerfile: true\n  environment {\n    GIT_COMMITTER_NAME = \"jenkins\"\n    GIT_COMMITTER_EMAIL = \"jenkins@jenkins.io\"\n  }\n  stages {\n    stage(\"Build\") {\n      steps {\n        sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n      }\n    }\n    stage(\"Archive\"){\n      steps {\n        archive \"*/target/**/*\"\n        junit '*/target/surefire-reports/*.xml'\n      }\n    }\n  }\n  post {\n    always {\n      deleteDir()\n    }\n    success {\n      mail to:\"me@example.com\", subject:\"SUCCESS: ${currentBuild.fullDisplayName}\", body: \"Yay, we passed.\"\n    }\n    failure {\n      mail to:\"me@example.com\", subject:\"FAILURE: ${currentBuild.fullDisplayName}\", body: \"Boo, we failed.\"\n    }\n  }\n}\n\n// Script //\nwithEnv([\"GIT_COMMITTER_NAME = jenkins\",\"GIT_COMMITTER_EMAIL = jenkins@jenkins.io\"]) {\n  node('has-docker') {\n    try {\n      checkout scm // checks out Dockerfile and source code\n      def myImage = docker.build 'my-environment:snapshot'\n      myImage.inside {\n        stage('Build') {\n          sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n        }\n        stage('Archive') {\n          archive \"*/target/**/*\"\n          junit '*/target/surefire-reports/*.xml'\n        }\n      }\n      if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {\n        mail to:\"me@example.com\", subject:\"SUCCESS: ${currentBuild.fullDisplayName}\", body: \"Yay, we passed.\"\n      }\n    }\n    catch (exc) {\n      mail to:\"me@example.com\", subject:\"FAILURE: ${currentBuild.fullDisplayName}\", body: \"Boo, we failed.\"\n    }\n    finally {\n      deleteDir()\n    }\n  }\n}\n\nHow can you help?\n\nInstall the lastest version of the\nPipeline-Model-Defintion plugin.\n\nRead the documentation:\nGetting Started and\nSyntax overview.\n(These documents will be incorporated into the Jenkins.io documentation.)\n\nConvert some of your existing Pipeline scripts into Declarative\n\nLog any issues or enhancements you have\nhere\nfor the syntax, the execution, or the documentation.\n\nAsk questions. You can send questions to the\nusers mailing list\nor visit the #jenkins channel on IRC.\n\nHow will this work with Blue Ocean?\n\nBlue Ocean is all about Pipelines in Jenkins. Running, displaying, and soon,\ncreating Pipelines.  Blue Ocean will be able to run and display Pipelines\nwritten in this new syntax just like any other Pipeline works today. However,\nbecause Declarative Pipeline includes a pre-defined structure, or model, it is\nnow possible to create and edit pipelines with a GUI editor.\n\nAlthough we plan to launch 1.0 of Declarative Pipeline before Blue Ocean 1.0 is\nofficially available, we expect to have a working Beta of the Editor available\nto play with. The combination of a simple syntax and an intuitive editor\nshould make creating Jenkins Pipelines a breeze.\n\nHappy Holidays\n\nI hope everyone has a great end of the year and a Happy New Year. With\nDeclarative Pipeline and\nBlue Ocean\nwe expect great things for Jenkins in 2017!","title":"Announcing the beta of Declarative Pipeline Syntax","tags":["pipeline","blueocean"],"authors":[{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"/blog/author/hrmpw","twitter":"hrmpw"}]}},{"node":{"date":"2016-10-16T00:00:00.000Z","id":"1b6c5cc3-a7d6-56f2-91fc-f717ed4f85fc","slug":"/blog/2016/10/16/stage-lock-milestone/","strippedHtml":"This is a guest post by Patrick Wolf,\nDirector of Product Management at CloudBees.\n\nRecently the Pipeline team began making several changes to improve the stage step and increase control of concurrent builds in Pipeline. Until now the stage step has been the catch-all for functionality related to the flow of builds through the Pipeline: grouping build steps into visualized stages, limiting concurrent builds, and discarding stale builds.\n\nIn order to improve upon each of these areas independently we decided to break this functionality into discrete steps rather than push more and more features into an already packed stage step.\n\nstage - the stage step remains but is now focused on grouping steps and providing boundaries for Pipeline segments.\n\nlock - the lock step throttles the number of concurrent builds in a defined section of the Pipeline.\n\nmilestone - the milestone step automatically discards builds that will finish out of order and become stale.\n\nSeparating these concerns into explicit, independent steps allows for much greater control of Pipelines and broadens the set of possible use cases.\n\nStage\n\nThe stage step is a primary building block in Pipeline, dividing the steps of a Pipeline into explicit units and helping to visualize the progress using the \"Stage View\" plugin or\"Blue Ocean\". Beginning with version 2.2 of \"Pipeline Stage Step\" plugin, the stage step now requires a block argument, wrapping all steps within the defined stage. This makes the boundaries of where each stage begins and ends obvious and predictable. In addition, the concurrency argument of stage has now been removed to make this step more concise; responsibility for concurrency control has been delegated to the lock step.\n\nstage('Build') {\n  doSomething()\n  sh \"echo $PATH\"\n}\n\nOmitting the block from stage and using the concurrency argument are now deprecated in Pipeline. Pipelines using this syntax will continue to function but will produce a warning in the console log:\n\nUsing the 'stage' step without a block argument is deprecated\n\nThis message is only a reminder to update your Pipeline scripts; none of your Pipelines will stop working. If we reach a point where the old syntax is to be removed we will make an announcement prior to the change. We do, however, recommend that you update your existing Pipelines to utilize the new syntax.\n\nnote: Stage View and Blue Ocean will both work with either the old stage syntax or the new.\n\nLock\n\nRather than attempt to limit the number of concurrent builds of a job using the stage, we now rely on the \"Lockable Resources\" plugin and the lock step to control this. The lock step limits concurrency to a single build and it provides much greater flexibility in designating where the concurrency is limited.\n\nlock can be used to constrain an entire stage or just a segment:\n\nstage('Build') {\n  doSomething()\n  lock('myResource') {\n    echo \"locked build\"\n  }\n}\n\nlock can be also used to wrap multiple stages into a single concurrency unit:\n\nlock('myResource') {\n  stage('Build') {\n    echo \"Building\"\n  }\n  stage('Test') {\n    echo \"Testing\"\n  }\n}\n\nMilestone\n\nThe milestone step is the last piece of the puzzle to replace functionality originally intended for stage and adds even more control for handling concurrent builds of a job. The lock step limits the number of builds running concurrently in a section of your Pipeline while the milestone step ensures that older builds of a job will not overwrite a newer build.\n\nConcurrent builds of the same job do not always run at the same rate. Depending on the network, the node used, compilation times, test times, etc. it is always possible for a newer build to complete faster than an older build. For example:\n\nBuild 1 is triggered\n\nBuild 2 is triggered\n\nBuild 2 builds faster than Build 1 and enters the Test stage sooner.\n\nRather than allowing Build 1 to continue and possibly overwrite the newer artifact produced in Build 2, you can use the milestone step to abort Build 1:\n\nstage('Build') {\n  milestone()\n  echo \"Building\"\n}\nstage('Test') {\n  milestone()\n  echo \"Testing\"\n}\n\nWhen using the input step or the lock step a backlog of concurrent builds can easily stack up, either waiting for user input or waiting for a resource to become free. The milestone step will automatically prune all older jobs that are waiting at these junctions.\n\nmilestone()\ninput message: \"Proceed?\"\nmilestone()\n\nBookending an input step like this allows you to select a specific build to proceed and automatically abort all antecedent builds.\n\nmilestone()\nlock(resource: 'myResource', inversePrecedence: true) {\n  echo \"locked step\"\n  milestone()\n}\n\nSimilarly a pair of milestone steps used with a lock will discard all old builds waiting for a shared resource. In this example, inversePrecedence: true instructs the lock to begin most recent waiting build first, ensuring that the most recent code takes precedence.\n\nPutting it all together\n\nEach of these steps can be used independently of the others to control one aspect of a Pipeline or they can be combined to provide powerful, fine-grained control of every aspect of multiple concurrent builds flowing through a Pipeline. Here is a very simple example utilizing all three:\n\nstage('Build') {\n  // The first milestone step starts tracking concurrent build order\n  milestone()\n  node {\n    echo \"Building\"\n  }\n}\n\n// This locked resource contains both Test stages as a single concurrency Unit.\n// Only 1 concurrent build is allowed to utilize the test resources at a time.\n// Newer builds are pulled off the queue first. When a build reaches the\n// milestone at the end of the lock, all jobs started prior to the current\n// build that are still waiting for the lock will be aborted\nlock(resource: 'myResource', inversePrecedence: true){\n  node('test') {\n    stage('Unit Tests') {\n      echo \"Unit Tests\"\n    }\n    stage('System Tests') {\n      echo \"System Tests\"\n    }\n  }\n  milestone()\n}\n\n// The Deploy stage does not limit concurrency but requires manual input\n// from a user. Several builds might reach this step waiting for input.\n// When a user promotes a specific build all preceding builds are aborted,\n// ensuring that the latest code is always deployed.\nstage('Deploy') {\n  input \"Deploy?\"\n  milestone()\n  node {\n    echo \"Deploying\"\n  }\n}\n\nFor a more complete and complex example utilizing all these steps in a Pipeline check out the Jenkinsfile provided with the Docker image for demonstrating Pipeline. This is a working demo that can be quickly set up and run.","title":"Controlling the Flow with Stage, Lock, and Milestone","tags":["pipeline","newfeatures"],"authors":[{"avatar":null,"blog":null,"github":"HRMPW","html":"","id":"hrmpw","irc":null,"linkedin":null,"name":"Patrick Wolf","slug":"/blog/author/hrmpw","twitter":"hrmpw"}]}}]}},"pageContext":{"author":"hrmpw","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}