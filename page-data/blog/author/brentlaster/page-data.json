{
    "componentChunkName": "component---src-templates-author-blog-list-template-js",
    "path": "/blog/author/brentlaster",
    "result": {"data":{"author":{"avatar":{"childImageSharp":null},"blog":null,"github":"brentlaster","html":"<div class=\"paragraph\">\n<p>Brent Laster is a Senior Manager in the Research and Development division at SAS in Cary, North Carolina. He manages several groups involved with release engineering processes, best practices, and tooling. He also serves as a resource for the use of open-source technologies and conducts internal training classes in technologies such as Git, Gerrit, Gradle, and Jenkins, both in the U.S. and abroad.</p>\n</div>\n<div class=\"paragraph\">\n<p>Brent Laster is the author of \"Professional Git\"\n(a comprehensive guide to Git for users ranging from beginners to advanced)\nand \"Jenkins 2 – Up and Running:  Evolve Your Pipeline for Next-Generation Automation\".</p>\n</div>","id":"brentlaster","irc":null,"linkedin":null,"name":"Brent Laster","slug":"blog/author/brentlaster","twitter":"brentclaster"},"allBlog":{"edges":[{"node":{"date":"2018-08-17T00:00:00.000Z","id":"003e40e9-a1b3-5859-a18a-60017d86c651","slug":"/blog/2018/08/17/speaker-blog-brent-laster/","strippedHtml":"More and more today, continuous delivery (CD) pipelines are making use of containers.\nIn many implementations, the primary workflow/orchestration tool for CD pipelines is Jenkins.\nAnd the primary container orchestration tool is Docker.\nTogether these two applications provide a powerful, yet simple to understand and use, model for leveraging containers in your CD pipeline.\n\nWhen creating a pipeline script in Jenkins, there are multiple ways to incorporate Docker into your CD pipeline.\nThey include:\n\nManually running a predefined Docker image as a separate Jenkins agent\n\nAutomatically provisioning a Docker image, when needed, as a part of a “cloud” configuration\n\nReferencing a “docker” global variable that can be invoked via the Jenkins DSL\n\nCalling the Docker executable directly via a shell call in the Jenkins DSL\n\nFor this article, we’ll focus on the third item in this list given that it provides the most flexibility and convenience for Docker use in the pipeline.\nMore details on the other three can be found in the upcoming “Continuous Delivery and Containerization” workshop at Jenkins World/DevOps World 2018.\n\nFirst, we’ll provide some background on a couple of terms for those who may not be familiar with Jenkins 2.\nIf you already are familiar with it, feel free to skip ahead to the Global Variables section.\n\nBackground\n\nWhen we talk about Jenkins here, we’re referring to “Jenkins 2” - a name we use to generally refer to the 2.0 and beyond versions of Jenkins.\nJenkins 2 offers a powerful evolution of Jenkins over prior versions.\nIn particular, it provides full integration for “pipeline-as-code” (PAC).\nPAC refers to being able to write your pipeline in a scripting language, much like source code for any program.\nThe code you write becomes the program that defines your pipeline.\nIt is also the code that gets executed when your pipeline is initiated.\nListing 1 shows a simple example pipeline.\nNotice that this is very different from the classic way of creating pipelines in Jenkins.\nHere you are writing code - rather than the more traditional approaches, such as filling in web forms to configure a Freestyle job.\n\n// Scripted Pipeline //\nnode('worker') {\n    stage('Source') { // Get code\n        // Get code from our git repository\n        git 'git@diyvb2:/home/git/repositories/workshop.git'\n    }\n    stage('Compile') { // Compile and do unit testing\n        // Run gradle to execute compile and unit testing\n        sh \"gradle clean compileJava test\"\n    }\n}\n// Declarative //\n\nListing 1: Example Jenkins 2 pipeline\n\nThe language that we write the Jenkins pipeline code in is a Domain-Specific Language (DSL).\nYou can think of it as the “programming language” for Jenkins pipelines.\nThere are two variants of it.\nThe style we saw in figure 1 is called “scripted syntax”.\nIt is a mixture of elements from the Groovy programming language and special Jenkins “steps”.\nThe Jenkins steps are provided by the plugins that are installed in the current system.\nA built-in tool called the Snippet Generator provides a wizard interface to allow users to pick the step and options they want.\nThen, the user can click on a button to have Jenkins automatically generate the correct DSL code in the large text box (figure 1).\nThe DSL code can be copied from there and pasted into the pipeline script.\n\nFigure 1. The Snippet Generator\n\nA second type of syntax is called “declarative syntax.”  We won’t go into detail on it here.\nBut it is a much more structured syntax that focuses on having users declare what they want in a pipeline, rather than writing the logic to make it happen.\n\nGlobal Variables\n\nIn addition to the steps that are provided by plugins, additional functionality for pipelines can be provided by global variables.\nThe simplest way to think of a global variable is as an object with methods that can be invoked on it.\nSeveral of these are built in to Jenkins, such as the Docker global variable.\nOthers can be created by users as part of the structure of a shared source code repository called a “shared pipeline library.”\n\nTo get a list of the global variables that are currently available to your Jenkins instance, you can go to the Snippet Generator screen.\nImmediately below the box for the generated pipeline script is a section titled Global Variables.\nThere, within the small print, is a link to get to the actual section (figure 2).\n\nFigure 2. Link to Global Variables Reference section.\n\nClicking on that link takes us to a list of currently available Global Variables.\nIf you have the Docker Pipeline Plugin installed, you will see one at the top for Docker. (Figure 3).\n\nFigure 3. Docker global variable specifics.\n\nBroadly, the docker global variable includes methods that can be applied to the Docker application, Docker images, and Docker containers.\n\nWe’ll focus first on a couple of the Docker image methods as shown in figure 4.\n\nFigure 4. Key methods for getting a Docker image.\n\nThere are multiple ways you can use these methods to create a new image.\nListing 2 shows a basic example of assigning and pulling an image using the image method.\n\nmyImage = docker.image(\"bclaster/jenkins-node:1.0\")\nmyImage.pull()\n\nListing 2: Assigning a image to a variable and pulling it down.\n\nThis can also be done in a single statement as shown in listing 3.\n\ndocker.image(\"bclaster/jenkins-node:1.0\").pull()\n\nListing 3: Shorthand version of previous call.\n\nYou can also download a Dockerfile and build an image based on it.(See listing 4.)\n\nnode() {\n    def myImg\n    stage (\"Build image\") {\n        // download the dockerfile to build from\n        git 'git@diyvb:repos/dockerResources.git'\n\n        // build our docker image\n        myImg = docker.build 'my-image:snapshot'\n    }\n}\n\nListing 4: Pipeline code to download a Dockerfile and build an image from it.\n\nFigure 5 shows the actual output from running that “Build image” stage.\nNote that the docker.build step was translated into an actual Docker build command.\n\nFigure 5. Actual Docker output from running the download and build\n\nThe Inside Command\n\nAnother powerful method available for the Docker global variable is the inside method.\nWhen executed, this method will do the following:\n\nGet an agent and a workspace to execute on\n\nIf the Docker image is not already present, pull it down\n\nStart the container with that image\n\nMount the workspace from Jenkins\n\nExecute the build steps\n\nMounting the workspace means that the Jenkins workspace will appear as a volume inside the container.\nAnd it will have the same file path.\nSo, things running in the container will have direct access to the same location.\nHowever, this can only be done if the container is running on the same underlying system - such that it can directly access the path.\n\nIn terms of executing the build steps, the inside method acts as a scoping method.\nThis means that the environment it sets up is in effect for any statement that happens within its scope (within the block under it bounded by {}).\nThe practical application here is that any pipeline “sh” steps (a call to the shell to execute something) are automatically run in the container.\nBehind the scenes, this is done by wrapping the calls with “docker exec”.\n\nWhen executed, the calls with the global variable are translated (by Jenkins) into actual Docker call invocations.\nListing 5 shows an example of using this in a script, along with the output from the first invocation of the “inside” method.\nYou can see in the output the docker commands that are generated from the inside method call.\n\nstage (\"Get Source\") {\n        // run a command to get the source code download\n        myImg.inside('-v /home/git/repos:/home/git/repos') {\n            sh \"rm -rf gradle-greetings\"\n            sh \"git clone --branch test /home/git/repos/gradle-greetings.git\"\n        }\n    }\n    stage (\"Run Build\") {\n        myImg.inside() {\n            sh \"cd gradle-greetings && gradle -g /tmp clean build -x test\"\n        }\n    }\n\nListing 5: Example inside method usage.\n\nFigure 6. Example inside method Docker command output.\n\nOnce completed, the inside step will stop the container,\nget rid of the storage, and create a record that this image was used for the build.\nThat record facilitates image traceability, updates, etc.\n\nAs you can see, the combination of using the Docker “global variable” and its “inside” method provide a simple and powerful way to spin up and work with containers in your pipeline.\nIn addition, since you are not having to make the direct Docker calls, you can invoke steps like sh within the scope of the inside method, and have them executed by Docker transparently.\n\nAs we mentioned, this is only one of several ways you can interact with Docker in your pipeline code.\nTo learn about the other methods and get hands-on practice, join me at DevOps World/Jenkins World in San Francisco or Nice for the workshop\n\" Creating a Deployment Pipeline with Jenkins 2\".\nHope to see you there!\n\nJoin the Jenkins project at\nJenkins World on September 16-19th,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Using the Docker Global Variable in Your Jenkins Pipeline","tags":["event","jenkinsworld","jenkinsworld2018","pipeline","docker"],"authors":[{"avatar":{"childImageSharp":null},"blog":null,"github":"brentlaster","html":"<div class=\"paragraph\">\n<p>Brent Laster is a Senior Manager in the Research and Development division at SAS in Cary, North Carolina. He manages several groups involved with release engineering processes, best practices, and tooling. He also serves as a resource for the use of open-source technologies and conducts internal training classes in technologies such as Git, Gerrit, Gradle, and Jenkins, both in the U.S. and abroad.</p>\n</div>\n<div class=\"paragraph\">\n<p>Brent Laster is the author of \"Professional Git\"\n(a comprehensive guide to Git for users ranging from beginners to advanced)\nand \"Jenkins 2 – Up and Running:  Evolve Your Pipeline for Next-Generation Automation\".</p>\n</div>","id":"brentlaster","irc":null,"linkedin":null,"name":"Brent Laster","slug":"blog/author/brentlaster","twitter":"brentclaster"}]}}]}},"pageContext":{"author":"brentlaster","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}