{
    "componentChunkName": "component---src-templates-author-blog-list-template-js",
    "path": "/blog/authors/abayer",
    "result": {"data":{"author":{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"},"allBlog":{"edges":[{"node":{"date":"2018-07-02T00:00:00.000Z","id":"44cd4bd6-4c8f-5fdd-8f54-c99da078882e","slug":"/blog/2018/07/02/whats-new-declarative-piepline-13x-sequential-stages/","strippedHtml":"We recently released version 1.3 of Declarative Pipelines, which includes a couple significant new features. We’re\ngoing to cover these features in separate blog posts. The next post will show the new ability to restart a completed\nPipeline run starting from a stage partway through the Pipeline, but first, let’s look at the new sequential stages\nfeature.\n\nSequential Stages\n\nIn Declarative 1.2, we added the ability to define stages to run in parallel\nas part of the Declarative syntax. Now in Declarative 1.3, we’ve added another way to specify stages nested within other\nstages, which we’re calling \"sequential stages\".\n\nRunning Multiple Stages in a Parallel Branch\n\nOne common use case is running build and tests on multiple platforms. You could already do that with parallel stages,\nbut now you can run multiple stages in each parallel branch giving you more visibility into the progress of your\nPipeline without having to check the logs to see exactly which step is currently running where, etc.\n\nYou can also\nuse stage directives, including post, when, agent, and all the others covered in the\nPipeline Syntax reference\nin your sequential stages, letting you control behavior for different parts of each parallel branch.\n\nIn the example below, we are running builds on both Windows and Linux, but only want to deploy if we’re on the master branch.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and deploy on Windows and Linux\") {\n            parallel {\n                stage(\"windows\") {\n                    agent {\n                        label \"windows\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                bat \"run-build.bat\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                            when {\n                                branch \"master\"\n                            }\n                            steps {\n                                bat \"run-deploy.bat\"\n                            }\n                        }\n                    }\n                }\n\n                stage(\"linux\") {\n                    agent {\n                        label \"linux\"\n                    }\n                    stages {\n                        stage(\"build\") {\n                            steps {\n                                sh \"./run-build.sh\"\n                            }\n                        }\n                        stage(\"deploy\") {\n                             when {\n                                 branch \"master\"\n                             }\n                             steps {\n                                sh \"./run-deploy.sh\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nRunning Multiple Stages with the Same agent, or environment, or options\n\nWhile the sequential stages feature was originally driven by users wanting to have multiple stages in parallel branches,\nwe’ve found that being able to group multiple stages together with the same agent, environment, when, etc has a lot\nof other uses. For example, if you are using multiple agents in your Pipeline, but would like to be sure that stages using\nthe same agent use the same workspace, you can use a parent stage with an agent directive on it, and then all the stages\ninside its stages directive will run on the same executor, in the same workspace. Another example is that until now, you\ncould only set a timeout for the entire Pipeline or an individual stage. But by using a parent stage with nested stages,\nyou can define a timeout in the parent’s options directive, and that timeout will be applied for the execution of the\nparent, including its nested stages. You may also want to conditionally control the execution of multiple stages. For example,\nyour deployment process may be spread across multiple stages, and you don’t want to run any of those stages unless you’re on\na certain branch or some other criteria is satisified. Now you can group all those related stages together in a parent\nstage, within its stages directive, and have a single when condition on that parent, rather than having to copy an\nidentical when condition to each of the relevant stages.\n\nOne of my favorite use cases is shown in the example below. In Declarative 1.2.6, we added the input directive for stages.\nThis will pause the execution of the Pipeline until a user confirms that the Pipeline should continue, using the Scripted\nPipeline input step. The input directive is evaluated before the stage enters its agent, if it has one specified, and\nbefore the stage’s when condition, if specified, is evaluated. But if you’re using a top-level agent for most of your\nstages, you’re still going to be using that agent’s executor while waiting for input, which can be a waste of resources.\nWith sequential stages, you can instead use agent none at the top-level of the Pipeline, and group the stages using a common\nagent and running before the stage with the input directive together under a parent stage with the required agent\nspecified. Then, when your Pipeline reaches the stage with input, it will no longer be using an agent’s executor.\n\npipeline {\n    agent none\n\n    stages {\n        stage(\"build and test the project\") {\n            agent {\n                docker \"our-build-tools-image\"\n            }\n            stages {\n               stage(\"build\") {\n                   steps {\n                       sh \"./build.sh\"\n                   }\n               }\n               stage(\"test\") {\n                   steps {\n                       sh \"./test.sh\"\n                   }\n               }\n            }\n            post {\n                success {\n                    stash name: \"artifacts\", includes: \"artifacts/**/*\"\n                }\n            }\n        }\n\n        stage(\"deploy the artifacts if a user confirms\") {\n            input {\n                message \"Should we deploy the project?\"\n            }\n            agent {\n                docker \"our-deploy-tools-image\"\n            }\n            steps {\n                sh \"./deploy.sh\"\n            }\n        }\n    }\n}\n\nThese are just a few example of the power of the new sequential stages feature in Declarative 1.3.\nThis new feature adds another set of significant use cases that can be handled smoothly using Declarative Pipeline.\nIn my next post, I’ll show the another highly requested feature - the new ability to restart a Pipeline run from any stage in that Pipeline.","title":"What's New in Declarative Pipeline 1.3: Sequential Stages","tags":["pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2018-04-09T00:00:00.000Z","id":"3494cf73-5468-5673-9163-ca20378f0110","slug":"/blog/2018/04/09/whats-in-declarative/","strippedHtml":"Last week we released the latest version of Declarative Pipelines, version\n1.2.8. With that out, we thought now would be a good time to introduce you to\nthe new features and options that have been added to Declarative since the\nbeginning of 2018. These are all available now in the Update Center, with\nversion 1.2.8.\n\nDeclarative Directive Generator\n\nThis is something we’re really happy about - if you go to the \"Pipeline Syntax\"\nlink from your Pipeline’s page in Jenkins, you’ll see a couple new links on the\nleft, including \"Declarative Directive Generator\". The Directive Generator is\nmuch like the Snippet Generator that’s been in Pipeline for a couple years now,\nbut where the Snippet Generator is just for filling out a form for a step and\ngenerating the Pipeline code that configuration maps to, the Directive\nGenerator is built to help you write your Declarative Pipeline directives, like\nagent, options, stage, and more!\n\nThis is the first release to include the Directive Generator, and it’s\ndefinitely going to see more polish going forward, but we think it should be\nquite helpful for you already. We’ll be putting up another blog post looking at\nthe Directive Generator in more detail in the near future.\n\nNew when conditions\n\nWe’ve added a number of new when conditions, providing you more control over\nwhether your stages get executed.\n\nequals - Compares two values - strings, variables, numbers, booleans - and\nreturns true if they’re equal. I’m honestly not sure how we missed adding\nthis earlier! You can do \"not equals\" comparisons using the not { equals …​\n} combination too.\n\nchangeRequest - In its simplest form, this will return true if this\nPipeline is building a change request, such as a GitHub pull request. You can\nalso do more detailed checks against the change request, allowing you to ask\n\"is this a change request against the master branch?\" and much more.\n\nbuildingTag - A simple condition that just checks if the Pipeline is\nrunning against a tag in SCM, rather than a branch or a specific commit\nreference.\n\ntag - A more detailed equivalent of buildingTag, allowing you to check\nagainst the tag name itself.\n\nIn addition, we’ve added a new option to when : beforeAgent. This allows you\nto specify that the when conditions should be evaluated before entering the\nagent for the stage, rather than the normal behavior of evaluating when\nconditions after entering the agent. When beforeAgent true is specified,\nyou will not have access to the agent’s workspace, but you can avoid\nunnecessary SCM checkouts and waiting for a valid `agent to be available. This\ncan speed up your Pipeline’s execution in some cases.\n\nNew post conditions\n\nThe changed condition has always been a bit confusing, and to be\nhonest, it wasn’t our best work. changed will fire any time the current run’s\nstatus is different than the previous run’s status - whether the current run is\nhealthier than the previous one, or the other way around. That’s…​not actually\nvery useful. So now we’ve added two new post conditions that should provide\nyou with a lot more value than changed has.\n\nfixed - This will check to see if the current run is successful, and if the\nprevious run was either failed or unstable.\n\nregression - This will check to see if the current run’s status is worse\nthan the previous run’s status. So if the previous run was successful, and\nthe current run is unstable, this will fire and its block of steps will\nexecute. It will also run if the previous run was unstable, and the current\nrun is a failure, etc.\n\nNew options\n\nThe options directive in Declarative can contain a number of different kinds\nof configuration: traditional Jenkins job properties, like buildDiscarder,\nwrapper steps to execute the entire Pipeline within, like timeout, and\nDeclarative-specific options that can switch from some default behaviors of\nDeclarative execution. We’ve added two new Declarative-specific options in the\nlast few releases.\n\ncheckoutToSubdirectory - Allows you to override the location that the\nautomatic SCM checkout will use. Using checkoutToSubdirectory(\"foo\"), your\nPipeline will checkout your repository to\"$WORKSPACE/foo\", rather than the\ndefault of\"$WORKSPACE\".\n\nnewContainerPerStage - If you’re using a top-level docker or dockerfile\nagent, and want to ensure that each of your stages run in a fresh container\nof the same image, you can use this option. Any stage without its own\nagent specified will run in a new container using the image you’ve\nspecified or built, on the same computer and with access to the same\nworkspace.\n\nStage options\n\nSometimes, you may only want to disable automatic checkout of your repository,\nusing the skipDefaultCheckout(true) option, for one specific stage in your\nPipeline. Or perhaps you want to have a timeout that covers an entire\nstage, including time spent waiting for a valid agent, post condition\nexecution, or the new input directive for stages (see further down for more\ndetails on that!). To make those things possible, we’ve added a new options\ndirection to stage. You can use a subset of the top-level options content\nin a stage’s `options - wrapper steps, and Declarative-specific options that\nare marked as legal in a stage.\n\nInput\n\nYou’ve always been able to run the input step inside a stage’s `steps\nblock, but we’ve found that approach can lose out on some of the value that the\ninput step provides.\n\nTo help with that, we’ve added a new input directive\nto stage, with the same parameters as the input step. When you use the\nstage input directive rather than using the step directly, any parameters\nyou’ve specified for the input will be made available in the stage’s\nenvironment, meaning you can reference parameters from the `input in when\nconditions, or in environment variables.\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Example') {\n            input {\n                message \"Should we continue?\"\n                ok \"Yes, we should.\"\n                submitter \"alice,bob\"\n                parameters {\n                    string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n                }\n            }\n            agent any\n            steps {\n                echo \"Hello, ${PERSON}, nice to meet you.\"\n            }\n        }\n    }\n}\n// Script //\n\nAlso, the input directive is evaluated before you enter any agent specified\non this stage, so if you are using a top-level agent none and each stage\nhas its own agent specified, you can avoid consuming an executor while\nwaiting for the input to be submitted.\n\nLastly, you can use timeout in the stage options, as\nmentioned above, to time-out the input if too much time has passed without a\nresponse.\n\nI hope you find these new features and options for Declarative Pipelines\nhelpful, and I look forward to the rest of 2018 as we continue to invest and\nimprove in Jenkins Pipeline!","title":"The new things arriving in Declarative Pipeline!","tags":["pipeline","declarative"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2017-09-25T00:00:00.000Z","id":"ec7b8ed5-f69c-5e84-9b65-735961d0c5cf","slug":"/blog/2017/09/25/declarative-1.2-released/","strippedHtml":"After a few months of work on its key features, I’m happy to announce the\n1.2 release of\nDeclarative Pipeline!\nOn behalf of the contributors developing Pipeline, I thought it would be\nhelpful to discuss three of the key changes.\n\nParallel Stages\n\nFirst, we’ve added syntax support for parallel stages. In earlier versions of\nDeclarative Pipeline, the only way to run chunks of Pipeline code in parallel\nwas to use the parallel step inside the steps block for a stage, like this:\n\n/* .. snip .. */\nstage('run-parallel-branches') {\n  steps {\n    parallel(\n      a: {\n        echo \"This is branch a\"\n      },\n      b: {\n        echo \"This is branch b\"\n      }\n    )\n  }\n}\n/* .. snip .. */\n\nWhile this works, it doesn’t integrate well with the rest of the Declarative\nPipeline syntax. For example, to run each parallel branch on a different agent,\nyou need to use a node step, and if you do that, the output of the parallel\nbranch won’t be available for post directives (at a stage or pipeline\nlevel). Basically the old parallel step required you to use Scripted Pipeline\nwithin a Declarative Pipeline.\n\nBut now with Declarative Pipeline 1.2, we’ve introduced a true Declarative\nsyntax for running stages in parallel:\n\nJenkinsfile\n\npipeline {\n    agent none\n    stages {\n        stage('Run Tests') {\n            parallel {\n                stage('Test On Windows') {\n                    agent {\n                        label \"windows\"\n                    }\n                    steps {\n                        bat \"run-tests.bat\"\n                    }\n                    post {\n                        always {\n                            junit \"**/TEST-*.xml\"\n                        }\n                    }\n                }\n                stage('Test On Linux') {\n                    agent {\n                        label \"linux\"\n                    }\n                    steps {\n                        sh \"run-tests.sh\"\n                    }\n                    post {\n                        always {\n                            junit \"**/TEST-*.xml\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nYou can now specify either steps or parallel for a stage, and within\nparallel, you can specify a list of stage directives to run in parallel,\nwith all the configuration you’re used to for a stage in Declarative\nPipeline. We think this will be really useful for cross-platform builds and\ntesting, as an example. Support for parallel stages will be in the\nsoon-to-be-released Blue Ocean Pipeline Editor 1.3 as well.\n\nYou can find more documentation on parallel stages in the\nUser Handbook.\n\nDefining Declarative Pipelines in Shared Libraries\n\nUntil the 1.2 release, Declarative Pipelines did not officially support\ndefining your pipeline blocks in a shared library. Some of you may have tried\nthat out and found that it could work in some cases, but since it was never an\nofficially supported feature, it was vulnerable to breaking due to necessary\nchanges for the supported use cases of Declarative. But with 1.2, we’ve added\nofficial support for defining pipeline blocks in src/.groovy files in your\nshared libraries. Within your src/.groovy file’s call method, you can\ncall pipeline { …​ }, or possibly different pipeline { …​ } blocks\ndepending on if conditions and the like. Note that only one pipeline { …​ }\nblock can actually be executed per run - you’ll get an error if a second one\ntries to execute!\n\nMajor Improvements to Parsing and Environment Variables\n\nHopefully, you’ll never actually care about this change, but we’re very happy\nabout it nonetheless. The original approach used for actually taking the\npipeline { …​ } block and executing its contents was designed almost two\nyears ago, and wasn’t very well suited to how you all are actually using\nDeclarative Pipelines. In our attempts to work around some of those limitations,\nwe made the parsing logic even more complicated and fragile, resulting in an\nimpressive\nnumber of bugs, mainly relating to inconsistencies and bad behavior with\nenvironment variables.\n\nIn Declarative 1.2, we’ve replaced the runtime parsing logic completely with a\nfar more robust system, which also happens to fix most of those bugs at the\nsame time! While not every issue has been resolved, you may find that you can\nuse environment variables in more places, escaping is more consistent,\nWindows paths are no longer handled incorrectly, and a lot more. Again, we’re\nhoping you’ve never had the misfortune to run into any of these bugs, but if\nyou have, well, they’re fixed now, and it’s going to be a lot easier for us to\nfix any future issues that may arise relating to environment variables, when\nexpressions, and more. Also, the parsing at the very beginning of your build\nmay be about 0.5 seconds faster. =)\n\nMore to Come!\n\nWhile we don’t have any concrete plans for what will be going into Declarative\nPipelines 1.3, rest assured that we’ve got some great new features in mind, as\nwell as our continuing dedication to fixing the bugs you encounter and report.\nSo please do keep opening tickets for\nissues and feature requests. Thanks!","title":"Parallel stages with Declarative Pipeline 1.2","tags":["pipeline","declarative"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2017-08-18T00:00:00.000Z","id":"e2e86b67-d732-51e3-9127-44de5e51de0e","slug":"/blog/2017/08/18/declarative-pipelines-at-jenkinsworld/","strippedHtml":"This is a guest post by Andrew Bayer, who is\none of the authors of the\nDeclarative Pipeline plugin,\nand is a software engineer on the Pipeline team at\nCloudBees, Inc.\n\nA year ago at Jenkins World 2016, we unveiled Declarative Pipeline, a\nstructured way to define your Pipeline. It’s been a great year for Declarative\nand Pipeline in general, with the release of Declarative Pipeline 1.0 in\nFebruary, multiple releases since then, the introduction of\ndocumentation on Pipeline at jenkins.io,\nwith a focus on Declarative, and more. Given everything that’s happened over\nthe last year, we thought it’d be good to let you all know what you can expect\nto see and hear about Declarative Pipeline at this year’s Jenkins World.\n\nFirst, on Thursday, August 31, I’ll be giving a talk on Declarative Pipeline\nwith Robert Sandell, one of my coworkers\nhere at CloudBees and another author of Declarative Pipeline. We’ll be\ncovering what’s happened with Declarative over the last year, new features\nadded since the 1.0 release, such as the libraries directive and more when\nconditions, what’s planned for the upcoming 1.2 release (which is planned for\nshortly after Jenkins World!), including parallel stage s, and what’s on the\nroadmap for the future. In addition, we’ll be demoing some of the features in\n1.2, and providing some pointers on best practices for writing your Declarative\nPipeline.\n\nAlso on Thursday, Stephen Donner from Mozilla\nwill be giving a demo showing Mozilla’s usage of Declarative Pipeline and\nshared libraries at the Community Booth - Mozilla has been doing great work\nwith Declarative, and I’m excited to see their usage in more detail and hear\nStephen talk about their experience!\n\nIn addition, Robert, Stephen, and myself will all be at Jenkins World both days\nof the main sessions, and Robert and myself will also be at the\nContributor Summit\non Tuesday. We’d love to hear your thoughts on Declarative and will be happy to\nanswer any questions that we can. Looking forward to seeing you all!\n\nAndrew Bayer and Robert Sandell will be talking about the latest on\nDeclarative Pipeline in Jenkins\nat Jenkins World in August,\nregister with the code JWFOSS for a 30% discount off your pass.","title":"Declarative Pipeline at Jenkins World","tags":["plugins","pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2017-01-12T00:00:00.000Z","id":"2ff4e12b-c7b0-5650-8366-ce14906b5f15","slug":"/blog/2017/01/12/declarative-pipeline-beta-2/","strippedHtml":"This week, we released the second beta of the new\nDeclarative Pipeline syntax,\navailable in the Update Center now as version 0.8.1 of Pipeline: Model Definition.\nYou can read more about Declarative Pipeline\nin the blog post introducing the first beta\nfrom December, but we wanted to update you all on the syntax changes in the\nsecond beta. These syntax changes are the last compatibility-breaking changes to\nthe syntax before the 1.0 release planned for February, so you can safely start\nusing the 0.8.1 syntax now without needing to change it when 1.0 is released.\n\nA full syntax reference is available on the wiki as well.\n\nSyntax Changes\n\nChanged \"agent\" configuration to block structure\n\nIn order to support more detailed and clear configuration of agents, as well as\nmaking agent syntax more consistent with the rest of the Declarative Pipeline\nsyntax, we’ve moved the agent configuration into blocks. The agent any and\nagent none configurations work the same as previously, but label, docker\nand dockerfile now look like the following:\n\nJust specifying a label is simple.\n\n// Declarative //\nagent {\n    label \"some-label\"\n}\n// Script //\n\nIf you’re just specifying a Docker image, you can use this simple syntax.\n\n// Declarative //\nagent {\n    docker \"ubuntu:16.04\"\n}\n// Script //\n\nWhen you are specifying a label or other arguments, docker looks like this:\n\n// Declarative //\nagent {\n    docker {\n        image \"ubuntu:16.04\"\n        label \"docker-label\"\n        args \"-v /tmp:/tmp -p 8000:8000\"\n    }\n}\n// Script //\n\nWhen you’re building an image from \"Dockerfile\" in your repository and\ndon’t care what node is used or have additional arguments, you can again\nuse a simple syntax.\n\n// Declarative //\nagent {\n    dockerfile true\n}\n// Script //\n\nWhen you’re building an image from a different file, or have a label or other\narguments, use the following syntax:\n\n// Declarative //\nagent {\n    dockerfile {\n        filename \"OtherDockerfile\"\n        label \"docker-label\"\n        args \"-v /tmp:/tmp -p 8000:8000\"\n    }\n}\n// Script //\n\nImproved \"when\" conditions\n\nWe introduced the when section a couple releases ago, but have made some\nchanges to its syntax here in 0.8.1. We wanted to add some simpler ways to\nspecify common conditions, and that required we re-work the syntax accordingly.\n\nBranch\n\nOne of the most common conditions is running a stage only if you’re on a\nspecific branch. You can also use wildcards like \"*/master\".\n\n// Declarative //\nwhen {\n    branch \"master\"\n}\n// Script //\n\nEnvironment\n\nAnother built-in condition is the environment condition, which checks to see\nif a given environment variable is set to a given value.\n\n// Declarative //\nwhen {\n    environment name: \"SOME_ENV_VAR\", value: \"SOME_VALUE\"\n}\n// Script //\n\nExpression\n\nLastly, there’s the expression condition, which resolves an arbitrary\nPipeline expression. If the return value of that expression isn’t false or\nnull, the stage will execute.\n\n// Declarative //\nwhen {\n    expression {\n        echo \"Should I run?\"\n        return \"foo\" == \"bar\"\n    }\n}\n// Script //\n\n\"options\" replaces \"properties\" and \"wrappers\"\n\nWe’ve renamed the properties section to options, due to needing to add new\nDeclarative-specific options and to cut down on confusion. The options section\nis now where you’ll put general Pipeline options like buildDiscarder,\nDeclarative-specific options like skipDefaultCheckout, and block-scoped steps\nthat should wrap the execution of the entire build, like timeout or\ntimestamps.\n\n// Declarative //\n\noptions {\n    buildDiscarder(logRotator(numToKeepStr:'1'))\n    skipDefaultCheckout()\n    timeout(time: 5, unit: 'MINUTES')\n}\n// Script //\n\nHeading towards 1.0!\n\nWhile we may still add more functionality to the Declarative Pipeline syntax,\nwe won’t be making any changes to existing syntax for the 1.0 release. This\nmeans that any pipelines you write against the 0.8.1 syntax will keep working\nfor the foreseeable future without any changes. So if you’re already using\nDeclarative Pipelines, make sure to update your `Jenkinsfile`s after upgrading\nto 0.8.1, and if you haven’t been using Declarative Pipelines yet, install the\nPipeline: Model Definition plugin and\ngive them a try!","title":"Declarative Pipeline Syntax Beta 2 release","tags":["plugins","pipeline"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2016-09-06T00:00:00.000Z","id":"8ad9f6bc-3bc6-5882-82e5-d2a281d96faa","slug":"/blog/2016/09/06/jenkins-world-speaker-blog-pipeline-model-definition/","strippedHtml":"This is a guest post by Jenkins World speaker Andrew Bayer, Jenkins\ndeveloper at CloudBees.\n\nOver the last couple years, Pipeline as code has very much become the future of\nJenkins - in fact, at this point, I’d say it’s pretty well established as the\npresent of Jenkins. But that doesn’t mean it’s done, let alone that it’s\nperfect. While many developers enjoy the power and control that they get from\nwriting Pipelines using scripting, not everyone feels the same way. A lot of\ndevelopers want to specify their build as configuration and get on with building\nsoftware.\n\nPipeline scripts haven’t been a good way to do that…​until now.\n\nWith new changes to Jenkins Pipeline, you are now able to define your Pipeline\nfrom configuration in your Jenkinsfile by installing the new\nPipeline Model Definition\nplugin. It’s available today for you to try via the update center.\nBe sure to check the documentation for examples on how to get started for a\nvariety of languages and platforms.\n\nHere’s a quick example based on the plugin’s own Jenkinsfile :\n\npipeline {\n    // Make sure that the tools we need are installed and on the path.\n    tools {\n        maven \"Maven 3.3.9\"\n        jdk \"Oracle JDK 8u40\"\n    }\n\n    // Run on any executor.\n    agent label:\"\"\n\n    // The order that sections are specified doesn't matter - this will still be run\n    // after the stages, even though it's specified before the stages.\n    postBuild {\n        // No matter what the build status is, run these steps. There are other conditions\n        // available as well, such as \"success\", \"failed\", \"unstable\", and \"changed\".\n        always {\n            archive \"target/**/*\"\n            junit 'target/surefire-reports/*.xml'\n        }\n    }\n\n    stages {\n        // While there's only one stage here, you can specify as many stages as you like!\n        stage(\"build\") {\n            sh 'mvn clean install -Dmaven.test.failure.ignore=true'\n        }\n    }\n\n}\n\nIt’s still early days for this feature, with a lot of further functionality\nplanned to make it easier and more intuitive to define your Pipelines. All of\nthat functionality lives on top of Pipeline scripting, so we’ll also keep\nimproving Pipeline steps and syntax outside of the model! And perhaps most\nexciting, the Pipeline model will be used by an in-the-works visual editor\nthat will be part of the Blue Ocean project - while the editor isn’t ready yet,\nthe Pipeline Model Definition plugin will be bundled with the Blue Ocean beta\nfor you to try out.\n\nI’ll be going into all of this and more at my talk on Thursday, September 15th, at\n3:45pm at Jenkins World, and showing off the same day at the lunchtime demo\ntheater. I can’t wait to see you all there and hear what you think of all this!\n\nAndrew will be\npresenting\nmore of this concept at\nJenkins World in September.\nRegister with the code JWFOSS for 20% off your full conference pass.","title":"Introducing a New Way to Define Jenkins Pipelines","tags":["event","jenkinsworld","jenkinsworld2016"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2016-02-19T00:00:00.000Z","id":"d66435ff-2d80-5ab9-ae88-1ad87bcbf426","slug":"/blog/2016/02/19/january-2016-sf-jam/","strippedHtml":"On January 20, the first San Francisco JAM\n(Jenkins Area Meetup)\nof the new year was held at Mesosphere ’s offices.\nWe had two speakers - myself, and Roger Ignazio, an infrastructure automation\nengineer at Mesosphere. Around forty people attended and enjoyed the food and\ndrinks Mesosphere provided for us.\n\nLinks to the talks are below:\n\nElastic\nJenkins with Mesos and DCOS, by Roger\nIgnazio\n\nWho is Jenkins?,\nby Andrew Bayer\n\nMore JAMs will be happening in the coming months - for example, the first\nLos Angeles JAM is\ntentatively planned for early March, 2016! You can always find out the latest\non JAMs around the world at the\nJenkins Area Meetup page.","title":"January 2016 San Francisco JAM Report","tags":["general","meetup"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}},{"node":{"date":"2015-12-16T00:00:00.000Z","id":"c4dd7873-a1dc-5a87-918b-4c7455812df3","slug":"/blog/2015/12/16/workflow-best-practices-and-examples-repo-on-github/","strippedHtml":"A lot of people are using the Workflow plugin, but as with any scripting environment, users often have to start from scratch and learn the same lessons and shortcuts that other users have already learned. While there are blog posts from developers and users in various places, and some samples in the Workflow plugin documentation, more examples and tips and tricks are always, always useful. To help with that, we’ve created the workflow-examples repository on GitHub, as a place to store community-developed Workflow scripts that can help new users get started, show how to accomplish some non-trivial goals, and find tips and trick for taking your Workflow pipeline to the next level.\n\nThe repository has four directories:\n\ndocs/ - documentation, guides, and more. Including a Best Practices document. We’d love to see more contributions to that doc, as well as any new ones that would be helpful to Workflow users!\n\nworkflow-examples/ - general Workflow examples, showing how to use a given plugin with Workflow, quirks of the Workflow DSL syntax, and more.\n\nglobal-library-examples/ - examples of how to write code for the Workflow global library.\n\njenkinsfile-examples/ - Sample Jenkinsfiles or other Workflow scripts from SCM .\n\nDuring Hacksgiving some initial content was added, but not everything is covered yet, which is why I’m posting this - more is needed. We’d love to see your tips, examples, gotchas and more. If you’ve got Workflow scripts you’d like to contribute, please read the README and send a pull request. Thanks!","title":"Workflow Best Practices and Examples repo on GitHub","tags":["general","jenkinsci","pipeline","workflow"],"authors":[{"avatar":null,"blog":null,"github":"abayer","html":"","id":"abayer","irc":null,"linkedin":null,"name":"Andrew Bayer","slug":"/blog/authors/abayer","twitter":"abayer"}]}}]}},"pageContext":{"author":"abayer","limit":8,"skip":0,"numPages":3,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}