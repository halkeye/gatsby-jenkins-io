{
    "componentChunkName": "component---src-templates-author-blog-list-template-js",
    "path": "/blog/authors/lnewman/page/2",
    "result": {"data":{"author":{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"},"allBlog":{"edges":[{"node":{"date":"2017-04-11T00:00:00.000Z","id":"9d6e30d7-7295-5fb0-b863-4e1db0a6fa14","slug":"/blog/2017/04/11/welcome-to-blue-ocean-pipeline-activity/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nBlue Ocean is a new user experience for Jenkins,\nand version 1.0 is now live!\nBlue Ocean makes Jenkins, and continuous delivery, approachable to all team members.\nIn my previous post,\nI showed how easy it is to create and edit Declarative Pipelines using the Blue Ocean Visual Pipeline Editor.\nIn this video, I’ll use the Blue Ocean Activity View to track the\nstate of branches and Pull Requests in one project.\nBlue Ocean makes it so much easier to find the logs I need to triage failures.\n\nPlease Enjoy!  In my\nnext video,\nI’ll switch from looking at a single project to monitoring multiple projects with\nthe Blue Ocean Dashboard.","title":"Getting Started with Blue Ocean's Activity View","tags":["blueocean","ux","pipeline","tutorial","screencast"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-04-06T00:00:00.000Z","id":"f6b5f809-47da-5d3d-b7ca-7f843a8917d9","slug":"/blog/2017/04/06/welcome-to-blue-ocean-editor/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nBlue Ocean is a new user experience for Jenkins,\nand version 1.0 is now live!\nBlue Ocean makes Jenkins, and continuous delivery, approachable to all team members.\nIn my previous post,\nI explained how to install Blue Ocean on your local Jenkins instance and switch to using Blue Ocean.\nAs promised, here’s a screencast that picks up where that post left off.\nStarting from a clean Jenkins install, the video below will guide you through\ncreating and running your first Pipeline in Blue Ocean with the Visual Pipeline Editor.\n\nPlease Enjoy! In my next video, I’ll go over the\nBlue Ocean Pipeline Activity View.","title":"Getting Started with Blue Ocean's Visual Pipeline Editor","tags":["blueocean","ux","pipeline","tutorial","screencast"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-04-05T00:00:00.000Z","id":"ef0f71cf-7b8f-528c-bdbf-cb7997704db5","slug":"/blog/2017/04/05/welcome-to-blue-ocean/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nWelcome to Blue Ocean 1.0!\n\nIn case you’ve been heads down on other projects\nfor the past 10 months,\nBlue Ocean is a new user experience for Jenkins,\nand version 1.0 was released today!\nBlue Ocean makes Jenkins, and continuous delivery, approachable to all team members.\nI’ve been working with it for the past several months, and I can tell you it is amazing.\nI wish all the interactions with Jenkins were as easy as this:\n\n10 minutes to Blue Ocean\n\nBlue Ocean is simple to install and will work on basically any Jenkins 2 instance (version 2.7 or later).\nEven better, it runs side-by-side with the existing Jenkins web UI -\nyou can switch back and forth between them whenever you like.\nThere’s really no risk.\nIf you have a Jenkins instance and a good network connection,\nin 10 minutes you could be using Blue Ocean.\n\nLogin to your Jenkins server\n\nClick Manage Jenkins in the sidebar then Manage Plugins\n\nChoose the Available tab and use the search bar to find Blue Ocean\n\nClick the checkbox in the Install column\n\nClick either Install without restart or Download now and install after\nrestart\n\nAfter you install Blue Ocean, you can start using it\nby clicking on Open Blue Ocean in the navigation bar of the\nJenkins web UI, or you can navigate directly to Blue Ocean by adding\n/blue to your Jenkins URL, for example https://ci.jenkins.io/blue .\n\nIf you have to go back to the \"classic\" Jenkins UI,\nthere’s an \"exit\" icon located at the top of every page in Blue Ocean.\n\nDive in!\n\nThat’s it! You now have a working Blue Ocean installation.\nTake a look around at your Pipelines and activity, or try creating a new Pipeline.\nI think you’ll be pleasantly surprised at how intuitive and helpful Blue Ocean can be.\nBlue Ocean is so cool, I never want to leave it.\nOver the next few days, I’ll be publishing a series of videos,\nshowing some common Jenkins use cases and how Blue Ocean makes them clearer and easier than ever before.\n\nStay Tuned!","title":"Getting Started with Blue Ocean","tags":["blueocean","ux","pipeline","tutorial"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-23T00:00:00.000Z","id":"4617d4e9-51f3-58b1-8cf1-558aa14ce01d","slug":"/blog/2017/02/23/declarative-saucelabs-xunit/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the fourth post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe integrated several notification services into a Declarative Pipeline.\nWe kept our Pipeline clean and easy to understand\nby using a shared library to make a custom step called sendNotifications\nthat we called at the start and end of our Pipeline.\n\nIn this blog post, we’ll start by translating the Scripted Pipeline in the sample project I worked with\nin\n\" Browser-testing with Sauce OnDemand and Pipeline\"\nand\n\" xUnit and Pipeline\"\nto Declarative.\nWe’ll make our Pipeline clearer by adding an environment directive\nto define some environment variables, and then moving some code to a shared library.\nFinally, we’ll look at using the when directive to add simple conditional behavior to our Pipeline.\n\nSetup\n\nThe setup for this post uses the same repository as the two posts above,\nmy fork\nof the\nJS-Nightwatch.js sample project.\nI’ve once again created a branch specifically for this blog post,\nthis time called\nblog/declarative/sauce .\n\nLike the two posts above, this Pipeline will use the\nxUnit and\nSauce OnDemand plugins.\nThe xUnit plugin only needs to be installed, the Sauce OnDemand needs additional configuration.\nFollow\nSauce Labs' configuration instructions\nto create an account with Sauce Labs and add your Sauce Labs credentials to Jenkins.\nThe Sauce OnDemand plugin will automatically install\nSauce Connect\nfor us when we call it from our Pipeline.\n\nBe sure to you have the latest version of the\nSauce OnDemand plugin (1.160 or newer).\nIt has several fixes required for this post.\n\nFor a shared library, I’ve still got the one from the\nprevious post.\nTo set up this \"Global Pipeline Library,\" navigate to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", add a new library.\nThen set the name to bitwiseman-shared, point it at my repository,\nand set the default branch for the library to master.\n\nReducing Complexity with Declarative\n\nIf you’ve been following along through this series,\nthis first step will be quite familiar by now.\nWe’ll start from the Pipeline we had at the end of the xUnit post\nand translate it to Declarative.\n\n// Declarative //\npipeline {\n    agent any\n    options {\n        // Nightwatch.js supports color ouput, so wrap add his option\n        ansiColor colorMapName: 'XTerm'\n    }\n    stages {\n        stage (\"Build\") {\n            steps {\n                // Install dependencies\n                sh 'npm install'\n            }\n        }\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e chrome,firefox,ie,edge --test tests/guineaPig.js || true\"\n                    }\n                }\n            }\n            post {\n                always {\n                    step([$class: 'XUnitBuilder',\n                        thresholds: [\n                            [$class: 'SkippedThreshold', failureThreshold: '0'],\n                            // Allow for a significant number of failures\n                            // Keeping this threshold so that overwhelming failures are guaranteed\n                            //     to still fail the build\n                            [$class: 'FailedThreshold', failureThreshold: '10']],\n                        tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n                    saucePublisher()\n                }\n            }\n        }\n    }\n// Scripted //\nnode {\n    stage \"Build\"\n    checkout scm\n\n    // Install dependencies\n    sh 'npm install'\n\n    stage \"Test\"\n    // Add sauce credentials\n    sauce('f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a') {\n        // Start sauce connect\n        sauceconnect() {\n\n            // List of browser configs we'll be testing against.\n            def platform_configs = [\n                'chrome',\n                'firefox',\n                'ie',\n                'edge'\n            ].join(',')\n\n            // Nightwatch.js supports color ouput, so wrap this step for ansi color\n            wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm']) {\n                // Run selenium tests using Nightwatch.js\n                // Ignore error codes. The junit publisher will cover setting build status.\n                sh \"./node_modules/.bin/nightwatch -e ${platform_configs} --test tests/guineaPig.js || true\"\n            }\n\n            step([$class: 'XUnitBuilder',\n                thresholds: [\n                    [$class: 'SkippedThreshold', failureThreshold: '0'],\n                    // Allow for a significant number of failures\n                    // Keeping this threshold so that overwhelming failures are guaranteed\n                    //     to still fail the build\n                    [$class: 'FailedThreshold', failureThreshold: '10']],\n                tools: [[$class: 'JUnitType', pattern: 'reports/**']]])\n\n            saucePublisher()\n        }\n    }\n}\n\nBlue Ocean doesn’t support displaying SauceLabs test reports yet\n(see JENKINS-42242).\nTo view the report above, I had to switch back to the stage view of this run.\n\nElevating Settings using environment\n\nEach time we’ve moved a project from Scripted Pipeline to Declarative,\nwe’ve found the cleaner format of Declarative Pipeline highlights the less\nclear parts of the existing Pipeline.\nIn this case, the first thing that jumps out at me is that the parameters of the\nSaucelabs and Nightwatch execution are hardcoded and buried down in the middle of our Pipeline.\nThis is a relatively short Pipeline, so it isn’t terribly hard to find them,\nbut as this pipeline grows and changes it would be better if those values were kept separate.\nIn Scripted, we’d have defined some variables,\nbut Declarative doesn’t allow us to define variables in the usual Groovy sense.\n\nThe environment directive let’s us set some environment variables\nand use them later in our pipeline.\nAs you’d expect, the environment directive is just a set of name-value pairs.\nEnvironment variables are accessible in Pipeline via env.variableName (or just variableName)\nand in shell scripts as standard environment variables, typically $variableName.\n\nLet’s move the list of browsers, the test filter, and the sauce credential string to environment variables.\n\nJenkinsfile\n\nenvironment {\n        saucelabsCredentialId = 'f0a6b8ad-ce30-4cba-bf9a-95afbc470a8a'\n        sauceTestFilter = 'tests/guineaPig.js'\n        platformConfigs = 'chrome,firefox,ie,edge'\n    }\n    stages {\n        /* ... unchanged ... */\n        stage (\"Test\") {\n            steps {\n                // Add sauce credentials\n                sauce(saucelabsCredentialId) {\n                    // Start sauce connect\n                    sauceconnect() {\n                        // Run selenium tests using Nightwatch.js\n                        // Ignore error codes. The junit publisher will cover setting build status.\n                        sh \"./node_modules/.bin/nightwatch -e ${env.platformConfigs} --test ${env.sauceTestFilter} || true\" (1)\n}\n                }\n            }\n            post { /* ... unchanged ... */ }\n        }\n    }\n}\n\n1\nThis double-quoted string causes Groovy to replace the variables with their\nliteral values before passing to sh.\nThis could also be written using singe-quotes:\nsh './node_modules/.bin/nightwatch -e $platformConfigs --test $sauceTestFilter || true'.\nWith a single quoted string, the string is passed as written to the shell,\nand then the shell does the variable substitution.\n\nMoving Complex Code to Shared Libraries\n\nNow that we have settings separated from the code, we can do some code clean up.\nUnlike the previous post, we don’t have any repeating code,\nbut we do have some distractions.\nThe nesting of sauce, sauceconnect, and sh nightwatch seems excessive,\nand that xUnit step is a bit ugly as well.\nLet’s move those into our shared library as custom steps with parameters.\nWe’ll change the Jenkinsfile in our main project,\nand add the custom steps to a branch named\nblog/declarative/sauce in our library repository.\n\nJenkinsfile\n\n@Library('bitwiseman-shared@blog/declarative/sauce') _\n\n/* ... unchanged ... */\n\nstage (\"Test\") {\n    steps {\n        sauceNightwatch saucelabsCredentialId,\n            platformConfigs,\n            sauceTestFilter\n    }\n    post {\n        always {\n            xUnitPublishResults 'reports/**',\n                /* failWhenSkippedExceeds */ 0,\n                /* failWhenFailedExceeds */ 10\n\n            saucePublisher()\n        }\n    }\n}\n\nvars/sauceNightwatch.groovy\n\ndef call(String sauceCredential, String platforms = null, String testFilter = null) {\n    platforms = platforms ? \"-e '\" + platforms + \"'\" : ''\n    testFilter = testFilter ? \"--test '\" + testFilter + \"'\" : ''\n\n    // Add sauce credentials\n    sauce(sauceCredential) {\n        // Start sauce connect\n        sauceconnect() {\n            // Run selenium tests using Nightwatch.js\n            // Ignore error codes. The junit publisher will cover setting build status.\n            sh \"./node_modules/.bin/nightwatch ${platforms} ${testFilter} || true\" (1)\n}\n    }\n}\n\n1\nIn this form, this could not be written using a literal single-quoted string.\nHere, platforms and testFilter are groovy variables, not environment variables.\n\nvars/xUnitPublishResults.groovy\n\ndef call(String pattern, Integer failWhenSkippedExceeds,\n        Integer failWhenFailedExceeds) {\n    step([$class: 'XUnitBuilder',\n        thresholds: [\n            [$class: 'SkippedThreshold', failureThreshold: failWhenSkippedExceeds.toString()],\n            // Allow for a significant number of failures\n            // Keeping this threshold so that overwhelming failures are guaranteed\n            //     to still fail the build\n            [$class: 'FailedThreshold', failureThreshold: failWhenFailedExceeds.toString()]],\n        tools: [[$class: 'JUnitType', pattern: pattern]]])\n}\n\nRunning Conditional Stages using when\n\nThis is a sample web testing project.\nWe probably wouldn’t deploy it like we would production code,\nbut we might still want to deploy somewhere,\nby publishing it to an artifact repository, for example.\nThis project is hosted on GitHub and uses feature branches and pull requests to make changes.\nI’d like to use the same Pipeline for feature branches, pull requests, and the master branch,\nbut I only want to deploy from master.\n\nIn Scripted, we’d wrap a stage in an if-then and check if the branch for\nthe current run is named \"master\".\nDeclarative doesn’t support that kind of general conditional behavior.\nInstead, it provides a\nwhen directive\nthat can be added to stage sections.\nThe when directive supports several types of conditions, including a branch condition,\nwhere the stage will run when the branch name matches the specified pattern.\nThat is exactly what we need here.\n\nJenkinsfile\n\nstages {\n    /* ... unchanged ... */\n    stage ('Deploy') {\n        when {\n            branch 'master'\n        }\n        steps {\n             echo 'Placeholder for deploy steps.'\n        }\n    }\n}\n\nWhen we run our Pipeline with this new stage, we get the following outputs:\n\nLog output for 'feature/test' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\nStage 'Deploy' skipped due to when conditional\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nLog output for 'master' branch\n\n...\nFinished Sauce Labs test publisher\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Deploy)\n[Pipeline] echo\nPlaceholder for deploy steps.\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n...\n\nConclusion\n\nI have to say, our latest Declarative Pipeline turned out extremely well.\nI think someone coming from Freestyle jobs, with little to no experience with Pipeline or Groovy,\nwould still be able to look at this Declarative Pipeline and make sense of what it is doing.\nWe’ve added new functionality to our Pipeline while making it easier to understand\nand maintain.\n\nI hope you’ve learned as much as I have during this blog series.\nI’m excited to see that even in the the short time since Declarative 1.0 was released,\nteams are already using it in make improvements similar to what those we’ve covered in this series.\nThanks for reading!\n\nLinks\n\nxUnit\n\nSauce OnDemand\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Browser testing and conditional logic in Declarative Pipeline","tags":["pipeline","plugins","xunit","nightwatch","saucelabs","selenium","declarative"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-15T00:00:00.000Z","id":"76a4ff94-6194-5d56-a94c-3287ec832681","slug":"/blog/2017/02/15/declarative-notifications/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the third post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious post,\nwe converted a Scripted Pipeline to a Declarative Pipeline, adding descriptive stages\nand post sections.  In one of those post blocks, we included a placeholder for\nsending notifications.\n\nIn this blog post, we’ll repeat what I did in\n\" Sending Notifications in Pipeline\nbut this time in Declarative Pipeline.\nFirst we’ll integrate calls to notification services Slack, HipChat, and Email into our Pipeline.\nThen we’ll refactor those calls into a single Step in a Shared Library, which\nwe’ll reuse as needed, keeping our Jenkinsfile concise and understandable.\n\nSetup\n\nThe setup for this post is almost the same as\nmy previous Declarative Pipeline post.\nI’ve used a new branch in\nmy fork of the\nHermann project :\nblog/declarative/notifications .\nI’d already set up a Multibranch Pipeline and pointed it at my repository,\nso the new branch will be picked up and built automatically.\n\nI still have my notification targets (where we’ll send notifications) that I created for the\n\" Sending Notifications in Pipeline\" blog post.\nTake a look at that post to review how I setup the\nSlack,\nHipChat,\nand Email-ext\nplugins to use those channels.\n\nAdding Notifications\n\nWe’ll start from the same Pipeline we had at the end of the previous post.\n\nThis Pipeline works quite well, except it doesn’t print anything at the start of\nthe run, and that final always directive only prints a message to the console log.\nLet’s start by getting the notifications working like we did in the original post.\nWe’ll just copy-and-paste the three notification steps (with different parameters)\nto get the notifications working for started, success, and failure.\n\npipeline {\n  /* ... unchanged ... */\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        slackSend (color: '#FFFF00', message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n        // send to HipChat\n        hipchatSend (color: 'YELLOW', notify: true,\n            message: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n          )\n\n        // send to email\n        emailext (\n            subject: \"STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n            body: \"\"\" STARTED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n            recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n          )\n      }\n    }\n    /* ... unchanged ... */\n  }\n  post {\n    success {\n      slackSend (color: '#00FF00', message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'GREEN', notify: true,\n          message: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" SUCCESSFUL: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n\n    failure {\n      slackSend (color: '#FF0000', message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\")\n\n      hipchatSend (color: 'RED', notify: true,\n          message: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]' (${env.BUILD_URL})\"\n        )\n\n      emailext (\n          subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n          body: \"\"\" FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\",\n          recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n        )\n    }\n  }\n}\n\nMoving Notifications to Shared Library\n\nThis new Pipeline works and our Declarative Pipeline sends notifications; however,\nit is extremely ugly. In the original post using Scripted Pipeline,\nI defined a single method that I called at both the start and end of the pipeline.\nI’d like to do that here as well, but Declarative doesn’t support creating methods\nthat are accessible to multiple stages.\nFor this, we’ll need to turn to\nShared Libraries.\n\nShared Libraries, as the name suggests,\nlet Jenkins Pipelines share code instead of copying it to each new project.\nShared Libraries are not specific to Declarative; they were released in their\ncurrent form several months ago and were useful in Scripted Pipeline.\nDue to Declarative Pipeline’s lack of support for defining methods,\nShared Libraries take on a vital role.  They are the only supported way within\nDeclarative Pipeline to define methods or classes that we want to use in more than one stage.\n\nThe lack of support for defining methods that are accessible in multiple stages,\nis a known issue, with at least two JIRA tickets:\nJENKINS-41335 and\nJENKINS-41396.\nFor this series, I chose to stick to using features that are fully supported\nin Declarative Pipeline at this time.\nThe internet has plenty of hacked together solutions that happen to work today,\nbut I wanted to highlight current best practices and dependable solutions.\n\nSetting up a Shared Library\n\nI’ve created a simple shared library repository for this series of posts, called\njenkins-pipeline-shared.\nThe shared library functionality has too many configuration options to cover in one post.\nI’ve chosen to configure this library as a \"Global Pipeline Library,\"\naccessible from any project on my Jenkins controller.\nTo setup a \"Global Pipeline Library,\" I navigated to \"Manage Jenkins\" → \"Configure System\"\nin the Jenkins web UI.\nOnce there, under \"Global Pipeline Libraries\", I added a new library.\nI then set the name to bitwiseman-shared, pointed it at my repository,\nand set the default branch for the library to master,\nbut I’ll override that in my Jenkinsfile.\n\nMoving the Code to the Library\n\nAdding a Step to a library involves creating a file with the name of our Step,\nadding our code to a call() method inside that file,\nand replacing the appropriate code in our Jenkinsfile with the new Step calls.\nLibraries can be set to load \"implicitly,\"\nmaking their default branch automatically available to all Pipelines,\nor they can be loaded manually using a @Library annotation.\nThe branch for implicitly loaded libraries can also be overridden using the @Library annotation.\n\nThe minimal set of dependencies for sendNotifications means we can\nbasically copy-and-paste the code from the original blog post.\nWe’ll check this change into a branch in the library named\nblog/declarative/notifications, the same as my branch in the hermann repository.\nThis will let us make changes on the master branch later without breaking this example.\nWe’ll then use the @Library directive to tell Jenkins to use that branch’s version\nof the library with this Pipeline.\n\nJenkinsfile\n\n// Declarative //\n#!groovy\n@Library('bitwiseman-shared@blog/declarative/notifications') _ (1)\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Start') {\n      steps {\n        // send build started notifications\n        sendNotifications 'STARTED'\n      }\n    }\n    stage ('Install') {\n      steps {\n        // install required bundles\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      sendNotifications currentBuild.result\n    }\n  }\n}\n// Scripted //\n\n1\nThe _ here is intentional.\nJava/Groovy Annotations\nsuch as @Library must be applied to an element.\nThat is often a using statement, but that isn’t needed here so by convention we use an \\_.\n\nvars/sendNotifications.groovy\n\n#!/usr/bin/env groovy\n\n/**\n * Send notifications based on build status string\n */\ndef call(String buildStatus = 'STARTED') {\n  // build status of null means successful\n  buildStatus = buildStatus ?: 'SUCCESS'\n\n  // Default values\n  def colorName = 'RED'\n  def colorCode = '#FF0000'\n  def subject = \"${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\"\n  def summary = \"${subject} (${env.BUILD_URL})\"\n  def details = \"\"\" ${buildStatus}: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]':\nCheck console output at \" ${env.JOB_NAME} [${env.BUILD_NUMBER}]\"\"\"\"\n\n  // Override default values based on build status\n  if (buildStatus == 'STARTED') {\n    color = 'YELLOW'\n    colorCode = '#FFFF00'\n  } else if (buildStatus == 'SUCCESS') {\n    color = 'GREEN'\n    colorCode = '#00FF00'\n  } else {\n    color = 'RED'\n    colorCode = '#FF0000'\n  }\n\n  // Send notifications\n  slackSend (color: colorCode, message: summary)\n\n  hipchatSend (color: color, notify: true, message: summary)\n\n  emailext (\n      to: 'bitwiseman@bitwiseman.com',\n      subject: subject,\n      body: details,\n      recipientProviders: [[$class: 'DevelopersRecipientProvider']]\n    )\n}\n\nConclusion\n\nIn this post we added notifications to our Declarative Pipeline.\nWe wanted to move our repetitive notification code into a method;\nhowever, Declarative Pipeline prevented us from defining a method in our Jenkinsfile.\nInstead, with the help of the Shared Library feature,\nwe were able to define a sendNotifications Step that we could call from our Jenkinsfile.\nThis maintained the clarity of our Pipeline and will let us easily reuse this Step in other projects.\nI was pleased to see how little the resulting Pipeline differed from where we started.\nThe changes were restricted to the start and end of the file with no reformatting elsewhere.\n\nIn the next post, we’ll cover more about shared libraries and how to\nrun Sauce OnDemand with xUnit Reporting in Declarative Pipeline.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nShared Library reference\n\nPipeline source for this post\n\nPipeline Shared Library source for this post","title":"Declarative Pipeline: Notifications and Shared Libraries","tags":["tutorial","pipeline","declarative","plugins","notifications","slack","hipchat","emailext"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-10T00:00:00.000Z","id":"06a04f0b-7823-5a11-8c3a-d385a336b68c","slug":"/blog/2017/02/10/declarative-html-publisher/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is the second post in a series showing some of the cool features of\nDeclarative Pipeline.\n\nIn the\nprevious blog post,\nwe created a simple Declarative Pipeline.\nIn this blog post, we’ll go back and look at the Scripted Pipeline for the\nPublishing HTML Reports in Pipeline blog post.\nWe’ll convert that Pipeline to Declarative syntax (including properties), go\ninto more detail on the post section, and then we’ll use the agent\ndirective to switch our Pipeline to run in Docker.\n\nSetup\n\nFor this post, I’m going to use the\nblog/add-declarative/html\nbranch of\nmy fork of the\nhermann project.\nI’ve set up a Multibranch Pipeline and pointed it at my repository\nthe same as did it previous post.\nAlso the same as before, I’ve set this Pipeline’s Git configuration to\nautomatically \"Clean after checkout\".\n\nThis time we already have a Pipeline checked in.\nI’ll run it a few times to get a baseline.\n\nConverting to Declarative\n\nLet’s start by converting the Scripted Pipeline straight to Declarative.\n\n// Declarative //\npipeline {\n  agent any // <1> (2)\noptions {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10')) (3)\n}\n  stages {\n    stage ('Build') { (4)\nsteps {\n        // install required gems\n        sh 'bundle install'\n\n        // build and run tests with coverage\n        sh 'bundle exec rake build spec'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\nproperties([[$class: 'BuildDiscarderProperty',\n                strategy: [$class: 'LogRotator', numToKeepStr: '10']]]) (3)\n\nnode { (1)\nstage ('Build') { (4)\n\n// Checkout\n    checkout scm (2)\n\n// install required gems\n    sh 'bundle install'\n\n    // build and run tests with coverage\n    sh 'bundle exec rake build spec'\n\n    // Archive the built artifacts\n    archive includes: 'pkg/*.gem'\n\n    // publish html\n    publishHTML [\n        allowMissing: false,\n        alwaysLinkToLastBuild: false,\n        keepAll: true,\n        reportDir: 'coverage',\n        reportFiles: 'index.html',\n        reportName: 'RCov Report'\n      ]\n\n  }\n}\n\n1\nSelect where to run this Pipeline, in this case \"any\" agent, regardless of label.\n\n2\nDeclarative automatically performs a checkout of source code on the agent,\nwhereas Scripted Pipeline users must explicitly call checkout scm.\n\n3\nSet the Pipeline option to preserve the ten most recent runs.\nThis overrides the default behavior from the Multibranch parent of this Pipeline.\n\n4\nRun the \"Build\" stage.\n\nNow that we have this Pipeline in Declarative form, let’s take a minute to do a\nlittle clean up.  We’ll split out the bundle actions a little more and move\nsteps into logically grouped stages.  Rather than having one monolithic \"Build\"\nstage, we’ll have details for each stage.  As long as we’re prettying things\nup, let’s switch to using Blue Ocean to view our\nbuilds, as well.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n\n        // Archive the built artifacts\n        archive includes: 'pkg/*.gem'\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n\n        // publish html\n        publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: true,\n            reportDir: 'coverage',\n            reportFiles: 'index.html',\n            reportName: 'RCov Report'\n          ]\n      }\n    }\n  }\n}\n// Scripted //\n\nUsing post sections\n\nThis looks pretty good, but if we think about it\nthe archive and publishHTML steps are really post-stage actions.\nThey should only occur when the rest of their stage succeeds.\nAs our Pipeline gets more complex we might need to add actions that always happen\neven if a stage or the Pipeline as a whole fail.\n\nIn Scripted Pipeline, we would use try-catch-finally,\nbut we cannot do that in Declarative.\nOne of the defining features of the Declarative Pipeline\nis that it does not allow script-based control structures\nsuch as for loops, if-then-else blocks, or try-catch-finally blocks.\nOf course, internally Step implementations can still contain whatever conditional logic they want,\nbut the Declarative Pipeline cannot.\n\nInstead of free-form conditional logic,\nDeclarative Pipeline provides a set of Pipeline-specific controls:\nwhen directives, which we’ll look at in\na later blog post in this series, control whether to execute the steps in a stage,\nand\npost sections\ncontrol which actions to take based on result of a single stage\nor a whole Pipeline. post supports a number of\nrun conditions,\nincluding always (execute no matter what) and changed\n(execute when the result differs from previous run).\nWe’ll use success to run archive and publishHTML when their respective stages complete.\nWe’ll also use an always block with a placeholder for sending notifications,\nwhich I’ll implement in the next blog post.\n\n// Declarative //\npipeline {\n  agent any\n  options {\n    // Only keep the 10 most recent builds\n    buildDiscarder(logRotator(numToKeepStr:'10'))\n  }\n  stages {\n    stage ('Install') {\n      steps {\n        // install required gems\n        sh 'bundle install'\n      }\n    }\n    stage ('Build') {\n      steps {\n        // build\n        sh 'bundle exec rake build'\n      }\n\n      post {\n        success {\n          // Archive the built artifacts\n          archive includes: 'pkg/*.gem'\n        }\n      }\n    }\n    stage ('Test') {\n      steps {\n        // run tests with coverage\n        sh 'bundle exec rake spec'\n      }\n\n      post {\n        success {\n          // publish html\n          publishHTML target: [\n              allowMissing: false,\n              alwaysLinkToLastBuild: false,\n              keepAll: true,\n              reportDir: 'coverage',\n              reportFiles: 'index.html',\n              reportName: 'RCov Report'\n            ]\n        }\n      }\n    }\n  }\n  post {\n    always {\n      echo \"Send notifications for result: ${currentBuild.result}\"\n    }\n  }\n}\n// Scripted //\n\nSwitching agent to run in Docker\n\nagent can actually accept\nseveral other parameters instead of any.\nWe could filter on label \"some-label\", for example,\nwhich would be the equivalent of node ('some-label') in Scripted Pipeline.\nHowever, agent also lets us just as easily switch to using a Docker container,\nwhich replaces a more complicated set of changes in Scripted Pipeline:\n\npipeline {\n  agent {\n    // Use docker container\n    docker {\n      image 'ruby:2.3'\n    }\n  }\n  /* ... unchanged ... */\n}\n\nIf I needed to, I could add a label filter under docker\nto select a node to host the Docker container.\nI already have Docker available on all my agents, so I don’t need label -\nthis works as is.\nAs you can see below, the Docker container spins up at the start of the run\nand the pipeline runs inside it.  Simple!\n\nConclusion\n\nAt first glance, the Declarative Pipeline’s removal of control structures seems\nlike it would be too constrictive.  However, it replaces those structures with\nfacilities like the post section, that give us reasonable control over the\nflow our our Pipeline while still improving readability and maintainability.\nIn the next blog post, we’ll add notifications to this pipeline\nand look at how to use Shared Libraries with Declarative\nPipeline to share code and keep Pipelines easy to understand.\n\nLinks\n\nDeclarative Pipeline plugin\n\nDeclarative Pipeline Syntax Reference\n\nPipeline source for this post","title":"Declarative Pipeline: Publishing HTML Reports","tags":["tutorial","pipeline","declarative","plugins","ruby"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-02-07T00:00:00.000Z","id":"df12ba62-13a1-5a1b-88f3-afc58f167e79","slug":"/blog/2017/02/07/declarative-maven-project/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nDeclare Your Pipelines!\nDeclarative Pipeline 1.0 is here!\nThis is first in a series of blog posts that will show some of the cool features of\nDeclarative Pipeline.\nFor several of these posts, I’ll be revisiting some of my\nprevious posts\non using various plugins with (Scripted) Pipeline,\nand seeing how those are implemented in Declarative Pipeline.\n\nTo start though, let’s get familiar with the basic structure of a Declarative Pipeline\nby creating a simple Pipeline for a Maven-based Java project - the\nJenkins JUnit plugin.\nWe’ll create a minimal Declarative Pipeline,\nadd the settings needed to install Maven and the JDK,\nand finally we’ll actually run Maven to build the plugin.\n\nSet up\n\nWith Declarative, it is still possible to run Pipelines edited directly in the\nJenkins web UI, but one of the key features of \"Pipeline as Code\" is\nchecking-in and being able to track changes.  For this post, I’m going to use\nthe\nblog/add-declarative-pipeline\nbranch of\nmy fork of the JUnit plugin.\nI’m going to set up a Multi-branch Pipeline and point it at my repository.\n\nI’ve also set this Pipeline’s Git configuration to automatically \"clean after\ncheckout\" and to only keep the ten most recent runs.\n\nWriting a Minimal Pipeline\n\nAs has been said before, Declarative Pipeline provides a more structured,\n\"opinionated\" way to create Pipelines. I’m going to start by creating a minimal\nDeclarative Pipeline and adding it to my branch.  Below is a minimal Pipeline\n(with annotations) that just prints a message:\n\n// Declarative //\npipeline { (1)\nagent any // <2> (3)\nstages { (4)\nstage('Build') { (5)\nsteps { (6)\necho 'This is a minimal pipeline.' (7)\n}\n        }\n    }\n}\n// Scripted //\nnode { (2)\ncheckout scm (3)\nstage ('Build') { (5)\necho 'This is a minimal pipeline.' (6)\n}\n}\n\n1\nAll Declarative Pipelines start with a pipeline section.\n\n2\nSelect where to run this Pipeline, in this case \"any\" agent, regardless of label.\n\n3\nDeclarative automatically performs a checkout of source code on the agent,\nwhereas Scripted Pipeline users must explicitly call checkout scm,\n\n4\nA Declarative Pipeline is defined as a series of stages.\n\n5\nRun the \"Build\" stage.\n\n6\nEach stage in a Declarative Pipeline runs a series of steps.\n\n7\nRun the echo step to print a message in the Console Output.\n\nIf you are familiar with Scripted Pipeline, you can toggle the above\nDeclarative code sample to show the Scripted equivalent.\n\nOnce I add the Pipeline above to my Jenkinsfile and run \"Branch Indexing\", my\nJenkins will pick it up and run run it.  We see that the Declarative Pipeline\nhas added stage called \"Declarative: Checkout SCM\":\n\nThis a \"dynamic stage\", one of several the kinds that Declarative Pipeline adds\nas needed for clearer reporting.  In this case, it is a stage in which the\nDeclarative Pipeline automatically checkouts out source code on the agent.\n\nAs you can see above, we didn’t have to tell it do any of this,\n\nConsole Output\n\n[Pipeline] node\nRunning on osx_mbp in /Users/bitwiseman/jenkins/agents/osx_mbp/workspace/blog_add-declarative-pipeline\n[Pipeline] {\n[Pipeline] stage\n[Pipeline] { (Declarative: Checkout SCM)\n[Pipeline] checkout\nCloning the remote Git repository\n{ ... truncated 20 lines ... }\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Build)\n[Pipeline] echo\nThis is a minimal pipeline\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] End of Pipeline\nFinished: SUCCESS\n\nDeclarative Pipeline syntax is a little more verbose than the equivalent Scripted Pipeline,\nbut the added detail gives a clearer, more consistent view of what the Pipeline is supposed to do.\nIt also gives us a structure into which we can add more configuration details about this Pipeline.\n\nAdding Tools to Pipeline\n\nThe next thing we’ll add in this Pipeline is a tools section to let us use\nMaven.  The tools section is one of several sections we can add under\npipeline, which affect the configuration of the rest of the Pipeline.  (We’ll\nlook at the others, including agent, in later posts.) Each tool entry will\nmake whatever settings changes, such as updating PATH or other environment\nvariables, to make the named tool available in the current pipeline.  It will\nalso automatically install the named tool if that tool is configured to do so\nunder \"Managing Jenkins\" → \"Global Tool Configuration\".\n\n// Declarative //\npipeline {\n    agent any\n    tools { (1)\nmaven 'Maven 3.3.9' (2)\njdk 'jdk8' (3)\n}\n    stages {\n        stage ('Initialize') {\n            steps {\n                sh '''\n                    echo \"PATH = ${PATH}\"\n                    echo \"M2_HOME = ${M2_HOME}\"\n                ''' (4)\n}\n        }\n\n        stage ('Build') {\n            steps {\n                echo 'This is a minimal pipeline.'\n            }\n        }\n    }\n}\n// Scripted Not Defined //\n\n1\ntools section for adding tool settings.\n\n2\nConfigure this Pipeline to use the Maven version matching \"Maven 3.3.9\"\n(configured in \"Managing Jenkins\" → \"Global Tool Configuration\").\n\n3\nConfigure this Pipeline to use the Maven version matching \"jdk8\"\n(configured in \"Managing Jenkins\" → \"Global Tool Configuration\").\n\n4\nThese will show the values of PATH and M2_HOME environment variables.\n\nWhen we run this updated Pipeline the same way we ran the first, we see that\nthe Declarative Pipeline has added another stage called \"Declarative: Tool\nInstall\": In the console output, we see that during this particular stage \"Maven 3.3.9\" gets installed,\nand the PATH and M2_HOME environment variables are set:\n\nConsole Output\n\n{ ... truncated lines ... }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Declarative: Tool Install)\n[Pipeline] tool\nUnpacking https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/3.3.9/apache-maven-3.3.9-bin.zip\nto /Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9\non osx_mbp\n[Pipeline] envVarsForTool\n[Pipeline] tool\n[Pipeline] envVarsForTool\n[Pipeline] }\n[Pipeline] // stage\n{ ... }\nPATH = /Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/bin:/Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9/bin:...\nM2_HOME = /Users/bitwiseman/jenkins/agents/osx_mbp/tools/hudson.tasks.Maven_MavenInstallation/Maven_3.3.9\n{ ... }\n\nRunning a Maven Build\n\nFinally, running a Maven build is trivial.  The tools section already added\nMaven and JDK8 to the PATH, all we need to do is call mvn install.  It\nwould be nice if I could split the build and the tests into separate stages,\nbut Maven is famous for not liking when people do that, so I’ll leave it alone\nfor now.\n\nInstead, let’s load up the results of the build using the JUnit plugin,\nhowever the version that was just built, sorry.\n\n// Declarative //\npipeline {\n    agent any\n    tools {\n        maven 'Maven 3.3.9'\n        jdk 'jdk8'\n    }\n    stages {\n        stage ('Initialize') {\n            steps {\n                sh '''\n                    echo \"PATH = ${PATH}\"\n                    echo \"M2_HOME = ${M2_HOME}\"\n                '''\n            }\n        }\n\n        stage ('Build') {\n            steps {\n                sh 'mvn -Dmaven.test.failure.ignore=true install' (1)\n}\n            post {\n                success {\n                    junit 'target/surefire-reports/**/*.xml' (2)\n}\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    checkout scm\n\n    String jdktool = tool name: \"jdk8\", type: 'hudson.model.JDK'\n    def mvnHome = tool name: 'mvn'\n\n    /* Set JAVA_HOME, and special PATH variables. */\n    List javaEnv = [\n        \"PATH+MVN=${jdktool}/bin:${mvnHome}/bin\",\n        \"M2_HOME=${mvnHome}\",\n        \"JAVA_HOME=${jdktool}\"\n    ]\n\n    withEnv(javaEnv) {\n    stage ('Initialize') {\n        sh '''\n            echo \"PATH = ${PATH}\"\n            echo \"M2_HOME = ${M2_HOME}\"\n        '''\n    }\n    stage ('Build') {\n        try {\n            sh 'mvn -Dmaven.test.failure.ignore=true install'\n        } catch (e) {\n            currentBuild.result = 'FAILURE'\n        }\n    }\n    stage ('Post') {\n        if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {\n            junit 'target/surefire-reports/**/*.xml' (2)\n}\n    }\n}\n\n1\nCall mvn, the version configured by the tools section will be first on the path.\n\n2\nIf the maven build succeeded, archive the JUnit test reports for display in the Jenkins web UI.\nWe’ll discuss the\npost section in detail in the next blog post.\n\nIf you are familiar with Scripted Pipeline, you can toggle the above\nDeclarative code sample to show the Scripted equivalent.\n\nBelow is the console output for this last revision:\n\nConsole Output\n\n{ ... truncated lines ... }\n+ mvn install\n[INFO] Scanning for projects...\n[WARNING] The POM for org.jenkins-ci.tools:maven-hpi-plugin:jar:1.119 is missing, no dependency information available\n[WARNING] Failed to build parent project for org.jenkins-ci.plugins:junit:hpi:1.20-SNAPSHOT\n[INFO]\n[INFO] ------------------------------------------------------------------------\n[INFO] Building JUnit Plugin 1.20-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO]\n[INFO] --- maven-hpi-plugin:1.119:validate (default-validate) @ junit ---\n[INFO]\n[INFO] --- maven-enforcer-plugin:1.3.1:display-info (display-info) @ junit ---\n[INFO] Maven Version: 3.3.9\n[INFO] JDK Version: 1.8.0_92 normalized as: 1.8.0-92\n[INFO] OS Info: Arch: x86_64 Family: mac Name: mac os x Version: 10.12.3\n[INFO]\n{ ... }\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 03:25 min\n[INFO] Finished at: 2017-02-06T22:43:41-08:00\n[INFO] Final Memory: 84M/1265M\n[INFO] ------------------------------------------------------------------------\n\nConclusion\n\nThe new Declarative syntax is a significant step forward for Jenkins Pipeline.\nIt trades some verbosity and constraints for much greater clarity and\nmaintainability.  In the coming weeks, I’ll be adding new blog posts\ndemonstrating various features of the Declarative syntax along with some recent\nJenkins Pipeline improvements.\n\nLinks\n\nDeclarative Pipeline\n\nDeclarative Pipeline Syntax Reference\n\nJenkins JUnit plugin","title":"Declarative Pipeline for Maven Projects","tags":["tutorial","pipeline","declarative","maven","java"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}},{"node":{"date":"2017-01-19T00:00:00.000Z","id":"437a3a39-d6ca-5875-b27d-0189cefc4150","slug":"/blog/2017/01/19/converting-conditional-to-pipeline/","strippedHtml":"This is a guest post by Liam Newman,\nTechnical Evangelist at CloudBees.\n\nIntroduction\n\nWith all the new developments in\nJenkins Pipeline (and\nDeclarative Pipeline on the horizon),\nit’s easy to forget what we did to create \"pipelines\" before\nPipeline.\nThere are number of plugins, some that have been around since the very beginning,\nthat enable users to create \"pipelines\" in Jenkins.\nFor example, basic job chaining worked well in many cases, and the\nParameterized Trigger plugin\nmade chaining more flexible.\nHowever, creating chained jobs with conditional behavior was\nstill one of the harder things to do in Jenkins.\n\nThe\nConditional BuildStep plugin\nis a powerful tool that has allowed Jenkins users to write Jenkins jobs with complex conditional logic.\nIn this post, we’ll take a look at how we might converting Freestyle jobs that\ninclude conditional build steps to Jenkins Pipeline.\nUnlike Freestyle jobs, implementing conditional operations in Jenkins Pipeline is trivial,\nbut matching the behavior of complex conditional build steps will require a bit more care.\n\nGraphical Programming\n\nThe Conditional BuildStep plugin lets users add conditional logic to Freestyle\njobs from within the Jenkins web UI.  It does this by:\n\nAdding two types of Conditional BuildStep (\"Single\" and \"Multiple\") -\nthese build steps contain one or more other build steps to be run when the configured\ncondition is met\n\nAdding a set of Condition operations -\nthese control whether the Conditional BuildStep execute the contained step(s)\n\nLeveraging the Token Macro facility -\nthese provide values to the Conditions for evaluation\n\nIn the example below, this project will run the shell script step when the value of the\nREQUESTED_ACTION token equals \"greeting\".\n\nHere’s the output when I run this project with REQUESTED_ACTION set to \"greeting\":\n\nRun condition [Strings match] enabling prebuild for step [Execute shell]\nStrings match run condition: string 1=[greeting], string 2=[greeting]\nRun condition [Strings match] enabling perform for step [Execute shell]\n[freestyle-conditional] $ /bin/sh -xe /var/folders/hp/f7yc_mwj2tq1hmbv_5n10v2c0000gn/T/hudson5963233933358491209.sh\n+ echo 'Hello, bitwiseman!'\nHello, bitwiseman!\nFinished: SUCCESS\n\nAnd when I pass the value \"silence\":\n\nRun condition [Strings match] enabling prebuild for step [Execute shell]\nStrings match run condition: string 1=[silence], string 2=[greeting]\nRun condition [Strings match] preventing perform for step [Execute shell]\nFinished: SUCCESS\n\nThis is a simple example but the conditional step can contain any regular build step.\nWhen combined with other plugins, it can control whether to send notifications,\ngather data from other sources, wait for user feedback, or call other projects.\n\nThe Conditional BuildStep plugin does a great job of leveraging strengths of\nthe Jenkins web UI, Freestyle jobs, and UI-based programming,\nbut it is also hampered by their limitations.\nThe Jenkins web UI can be clunky and confusing at times.\nLike the steps in any Freestyle job, these conditional steps are only\nstored and viewable in Jenkins.\nThey are not versioned with other product or build code and can’t be code reviewed.\nLike any number of UI-based programming tools, it has to make trade-offs between clarity\nand flexibility: more options or clearer presentation.\nThere’s only so much space on the screen.\n\nConverting to Pipeline\n\nJenkins Pipeline, on the other hand, enables users to implement their pipeline as code.\nPipeline code can be written directly in the Jenkins Web UI or in any text editor.\nIt is a full-featured programming language,\nwhich gives users access to much broader set of conditional statements\nwithout the restrictions of UI-based programming.\n\nSo, taking the example above, the Pipeline equivalent is:\n\n// Declarative //\npipeline {\n    agent any\n    parameters {\n        choice(\n            choices: ['greeting' , 'silence'],\n            description: '',\n            name: 'REQUESTED_ACTION')\n    }\n\n    stages {\n        stage ('Speak') {\n            when {\n                // Only say hello if a \"greeting\" is requested\n                expression { params.REQUESTED_ACTION == 'greeting' }\n            }\n            steps {\n                echo \"Hello, bitwiseman!\"\n            }\n        }\n    }\n}\n// Script //\nproperties ([\n    parameters ([\n        choice (\n            choices: ['greeting', 'silence'],\n            description: '',\n            name : 'REQUESTED_ACTION')\n    ])\n])\n\nnode {\n    stage ('Speak') {\n        // Only say hello if a \"greeting\" is requested\n        if (params.REQUESTED_ACTION == 'greeting') {\n            echo \"Hello, bitwiseman!\"\n        }\n    }\n}\n\nWhen I run this project with REQUESTED_ACTION set to \"greeting\", here’s the output:\n\n[Pipeline] node\nRunning on osx_mbp in /Users/bitwiseman/jenkins/agents/osx_mbp/workspace/pipeline-conditional\n[Pipeline] {\n[Pipeline] stage\n[Pipeline] { (Speak)\n[Pipeline] echo\nHello, bitwiseman!\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] End of Pipeline\nFinished: SUCCESS\n\nWhen I pass the value \"silence\", the only change is \"Hello, bitwiseman!\" is not printed.\n\nSome might argue that the Pipeline code is a bit harder to understand on first reading.\nOthers would say the UI is just as confusing if not more so.\nEither way, the Pipeline representation is considerably more compact than the Jenkins UI presentation.\nPipeline also lets us add helpful comments, which we can’t do in the Freestyle UI.\nAnd we can easily put this Pipeline in a Jenkinsfile to be code-reviewed, checked-in, and versioned\nalong with the rest of our code.\n\nConditions\n\nThe previous example showed the \"Strings match\" condition and its Pipeline equivalent.\nLet’s look at couple more interesting conditions and their Jenkins Pipeline equivalents.\n\nBoolean condition\n\nYou might think that a boolean condition would be the simplest condition, but it isn’t.\nSince it works with string values from tokens, the Conditional BuildStep plugin offers\na number of ways to indicate true or false.\nTruth is a case insensitive match of one of the following:\n1 (the number one), Y, YES, T, TRUE, ON or RUN.\n\nPipeline can duplicate these, but depending on the scenario we might consider\nwhether a simpler expression would suffice.\n\nPipeline\n\n// Declarative //\nwhen {\n    // case insensitive regular expression for truthy values\n    expression { return token ==~ /(?i)(Y|YES|T|TRUE|ON|RUN)/ }\n}\nsteps {\n    /* step */\n}\n\n// Script //\n// case insensitive regular expression for truthy values\nif (token ==~ /(?i)(Y|YES|T|TRUE|ON|RUN)/) {\n    /* step */\n}\n\nLogical \"OR\" of conditions\n\nThis condition wraps other conditions.\nIt takes their results as inputs and performs a logical \"or\" of the results.\nThe AND and NOT conditions do the same, performing their respective operations.\n\nPipeline\n\n// Declarative //\nwhen {\n    // A or B\n    expression { return A || B }\n}\nsteps {\n    /* step */\n}\n\n// Script //\n// A or B\nif (A || B) {\n    /* step */\n}\n\nTokens\n\nTokens can be considerably more work than conditions.\nThere are more of them and they cover a much broader range of behaviors.\nThe previous example showed one of the simpler cases, accessing a build parameter,\nwhere the token has a direct equivalent in Pipeline.\nHowever, many tokens don’t have direct equivalents,\nsome take a parameters (adding to their complexity),\nand some provide information that is simply not exposed in Pipeline yet.\nSo, determining how to migrate tokens needs to be done on case-by-case basis.\n\nLet’s look at a few examples.\n\n\"FILE\" token\n\nExpands to the contents of a file. The file path is relative to the build workspace root.\n\n${FILE,path=\"PATH\"}\n\nThis token maps directly to the readFile step.\nThe only difference is the file path for readFile is relative to the\ncurrent working directory on the agent, but that is the workspace root by default.\nNo problem.\n\nPipeline\n\n// Declarative //\nwhen {\n    expression { return readFile('pom.xml').contains('mycomponent') }\n}\nsteps {\n    /* step */\n}\n\n// Script //\nif (readFile('pom.xml').contains('mycomponent')) {\n    /* step */\n}\n\nGIT_BRANCH\n\nExpands to the name of the branch that was built.\n\nParameters (descriptions omitted): all, fullName.\n\nThis information may or may not be exposed in Pipeline.  If you’re using the\nPipeline Multibranch plugin\nenv.BRANCH_NAME will give similar basic information, but doesn’t offer the parameters.\nThere are also\nseveral\nissues\nfiled around GIT_* tokens in Pipeline.\nUntil they are addressed fully, we can follow the pattern shown in\npipeline-examples,\nexecuting a shell to get the information we need.\n\nPipeline\n\nGIT_BRANCH = sh(returnStdout: true, script: 'git rev-parse --abbrev-ref HEAD').trim()\n\nCHANGES_SINCE_LAST_SUCCESS\n\nDisplays the changes since the last successful build.\n\nParameters (descriptions omitted):\nreverse, format, changesFormat, showPaths, pathFormat,\nshowDependencies, dateFormat, regex, replace, default.\n\nNot only is the information provided by this token not exposed in Pipeline,\nthe token has ten optional parameters, including format strings and regular expression\nsearches. There are a number of ways we might get similar information in Pipeline.\nEach have their own particular limitations and ways they differ from the token output.\nThen we’ll need to consider how each of the parameters changes the output.\nIf nothing else, translating this token is clearly beyond the scope of this post.\n\nSlightly More Complex Example\n\nLet’s do one more example that shows some of these conditions and tokens.\nThis time we’ll perform different build steps depending on what branch we’re building.\nWe’ll take two build parameters: BRANCH_PATTERN and FORCE_FULL_BUILD.\nBased on BRANCH_PATTERN, we’ll checkout a repository.\nIf we’re building on the master branch or the user checked FORCE_FULL_BUILD,\nwe’ll call three other builds in parallel\n( full-build-linux, full-build-mac, and full-build-windows),\nwait for them to finish, and report the result.\nIf we’re not building on the master branch and the user did not check FORCE_FULL_BUILD,\nwe’ll print a message saying we skipped the full builds.\n\nFreestyle\n\nHere’s the configuration for Freestyle version.\n(It’s pretty long.  Feel free to skip down to the Pipeline version):\n\nThe Pipeline version of this job determines the GIT_BRANCH branch by\nrunning a shell script that returns the current local branch name.\nThis means that the Pipeline version must checkout to a local branch (not a detached head).\n\nFreestyle version of this job does not require a local branch, GIT_BRANCH is set automatically.\nHowever, to maintain functional parity, the Freestyle version of this job includes\n\"Checkout to Specific Local Branch\" as well.\n\nPipeline\n\nHere’s the equivalent Pipeline:\n\nFreestyle version of this job is not stored in source control.\n\nIn general, the Pipeline version of this job would be stored in source control,\nwould checkout scm, and would run that same repository.\nHowever, to maintain functional parity, the Pipeline version shown does a checkout\nfrom source control but is not stored in that repository.\n\nPipeline\n\n// Script //\nproperties ([\n    parameters ([\n        string (\n            defaultValue: '*',\n            description: '',\n            name : 'BRANCH_PATTERN'),\n        booleanParam (\n            defaultValue: false,\n            description: '',\n            name : 'FORCE_FULL_BUILD')\n    ])\n])\n\nnode {\n    stage ('Prepare') {\n        checkout([$class: 'GitSCM',\n            branches: [[name: \"origin/${BRANCH_PATTERN}\"]],\n            doGenerateSubmoduleConfigurations: false,\n            extensions: [[$class: 'LocalBranch']],\n            submoduleCfg: [],\n            userRemoteConfigs: [[\n                credentialsId: 'bitwiseman_github',\n                url: 'https://github.com/bitwiseman/hermann']]])\n    }\n\n    stage ('Build') {\n        GIT_BRANCH = 'origin/' + sh(returnStdout: true, script: 'git rev-parse --abbrev-ref HEAD').trim()\n        if (GIT_BRANCH == 'origin/master' || params.FORCE_FULL_BUILD) {\n\n            // Freestyle build trigger calls a list of jobs\n            // Pipeline build() step only calls one job\n            // To run all three jobs in parallel, we use \"parallel\" step\n            // https://jenkins.io/doc/pipeline/examples/#jobs-in-parallel\n            parallel (\n                linux: {\n                    build job: 'full-build-linux', parameters: [string(name: 'GIT_BRANCH_NAME', value: GIT_BRANCH)]\n                },\n                mac: {\n                    build job: 'full-build-mac', parameters: [string(name: 'GIT_BRANCH_NAME', value: GIT_BRANCH)]\n                },\n                windows: {\n                    build job: 'full-build-windows', parameters: [string(name: 'GIT_BRANCH_NAME', value: GIT_BRANCH)]\n                },\n                failFast: false)\n\n        } else {\n            echo 'Skipped full build.'\n        }\n    }\n}\n// Declarative //\npipeline {\n    agent any\n    parameters {\n        string (\n            defaultValue: '*',\n            description: '',\n            name : 'BRANCH_PATTERN')\n        booleanParam (\n            defaultValue: false,\n            description: '',\n            name : 'FORCE_FULL_BUILD')\n    }\n\n    stages {\n        stage ('Prepare') {\n            steps {\n                checkout([$class: 'GitSCM',\n                    branches: [[name: \"origin/${BRANCH_PATTERN}\"]],\n                    doGenerateSubmoduleConfigurations: false,\n                    extensions: [[$class: 'LocalBranch']],\n                    submoduleCfg: [],\n                    userRemoteConfigs: [[\n                        credentialsId: 'bitwiseman_github',\n                        url: 'https://github.com/bitwiseman/hermann']]])\n            }\n        }\n\n        stage ('Build') {\n            when {\n                expression {\n                    GIT_BRANCH = 'origin/' + sh(returnStdout: true, script: 'git rev-parse --abbrev-ref HEAD').trim()\n                    return GIT_BRANCH == 'origin/master' || params.FORCE_FULL_BUILD\n                }\n            }\n            steps {\n                // Freestyle build trigger calls a list of jobs\n                // Pipeline build() step only calls one job\n                // To run all three jobs in parallel, we use \"parallel\" step\n                // https://jenkins.io/doc/pipeline/examples/#jobs-in-parallel\n                parallel (\n                    linux: {\n                        build job: 'full-build-linux', parameters: [string(name: 'GIT_BRANCH_NAME', value: GIT_BRANCH)]\n                    },\n                    mac: {\n                        build job: 'full-build-mac', parameters: [string(name: 'GIT_BRANCH_NAME', value: GIT_BRANCH)]\n                    },\n                    windows: {\n                        build job: 'full-build-windows', parameters: [string(name: 'GIT_BRANCH_NAME', value: GIT_BRANCH)]\n                    },\n                    failFast: false)\n            }\n        }\n        stage ('Build Skipped') {\n            when {\n                expression {\n                    GIT_BRANCH = 'origin/' + sh(returnStdout: true, script: 'git rev-parse --abbrev-ref HEAD').trim()\n                    return !(GIT_BRANCH == 'origin/master' || params.FORCE_FULL_BUILD)\n                }\n            }\n            steps {\n                echo 'Skipped full build.'\n            }\n        }\n    }\n}\n\nConclusion\n\nAs I said before, the Conditional BuildStep plugin is great.\nIt provides a clear, easy to understand way to add conditional logic to any Freestyle job.\nBefore Pipeline, it was one of the few plugins to do this and it remains one of the most popular plugins.\nNow that we have Pipeline, we can implement conditional logic directly in code.\n\nThis is blog post discussed how to approach converting conditional build steps to Pipeline\nand showed a couple concrete examples.  Overall, I’m pleased with the results so far.\nI found scenarios which could not easily be migrated to Pipeline, but even those\nare only more difficult, rather than impossible.\n\nThe next thing to do is add a section to the\nJenkins Handbook documenting the Pipeline\nequivalent of all of the Conditions and the most commonly used Tokens.\nLook for it soon!\n\nLinks\n\nConditional BuildStep plugin","title":"Converting Conditional Build Steps to Jenkins Pipeline","tags":["pipeline","freestyle","plugins","conditional-build-step","tutorial"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#382818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg","srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/77b35/lnewman.jpg 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/d4a57/lnewman.jpg 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/19e71/lnewman.jpg 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/68974/lnewman.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/ef6ff/lnewman.webp 32w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/8257c/lnewman.webp 64w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/6766a/lnewman.webp 128w,\n/gatsby-jenkins-io/static/9717c5c33fe8f4903eec2f2b5a8d1532/22bfc/lnewman.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"bitwiseman","html":"<div class=\"paragraph\">\n<p>Liam started his software career as a tester, which might explain why he&#8217;s such a fan of CI/CD and Pipeline as Code.\nHe has spent the majority of his software engineering career implementing Continuous Integration systems at companies big and small.\nHe is a Jenkins project contributor and an expert in Jenkins Pipeline, both Scripted and Declarative.\nLiam currently works as a Jenkins Evangelist at <a href=\"https://cloudbees.com\">CloudBees</a>.\nWhen not at work, he enjoys testing gravity by doing Aikido.</p>\n</div>","id":"lnewman","irc":null,"linkedin":null,"name":"Liam Newman","slug":"/blog/authors/lnewman","twitter":"bitwiseman"}]}}]}},"pageContext":{"author":"lnewman","limit":8,"skip":8,"numPages":4,"currentPage":2}},
    "staticQueryHashes": ["3649515864"]}