{
    "componentChunkName": "component---src-templates-author-blog-list-template-js",
    "path": "/blog/authors/darinpope",
    "result": {"data":{"author":{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/19e71/darinpope.jpg","srcSet":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/77b35/darinpope.jpg 32w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/d4a57/darinpope.jpg 64w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/19e71/darinpope.jpg 128w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/68974/darinpope.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/ef6ff/darinpope.webp 32w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/8257c/darinpope.webp 64w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/6766a/darinpope.webp 128w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/22bfc/darinpope.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"darinpope","html":"<div class=\"paragraph\">\n<p>Darin is a developer advocate for <a href=\"https://www.cloudbees.com\">CloudBees</a>.\nHe is the co-host of the weekly <a href=\"https://www.devopsparadox.com/\">DevOps Paradox</a> podcast.\nHe also hosts regular livestream sessions on continuous integration and continuous delivery.\nRecordings of his live stream sessions are available on the <a href=\"https://www.youtube.com/c/CloudBeesTV/search?query=Darin%20Pope\">CloudBees TV YouTube channel</a>.</p>\n</div>","id":"darinpope","irc":null,"linkedin":"darinpope","name":"Darin Pope","slug":"/blog/authors/darinpope","twitter":"DarinPope"},"allBlog":{"edges":[{"node":{"date":"2021-12-08T00:00:00.000Z","id":"34b75ac0-1288-52a7-ad14-a7424b679e04","slug":"/blog/2021/12/08/containers-as-build-agents/","strippedHtml":"A continuous integration environment is a mixed bag of machines, platforms, build toolchains and operating systems.\nIdeally, you want as much flexibility as possible in managing these environments.\nYou want your build machines to be interchangeable and you don’t want to tie your builds to a particular machine.\nUsing containers as build agents is an effective way to get the flexibility you need to create applications faster and more effectively.\n\nMost modern software organizations recognize the benefits of deploying and managing applications as containers.\nAnd now more organizations are using containers to unify their build and test environments across machines, and to provide an efficient mechanism for deploying applications.\n\nIf you’re new to containers, think of it as the next step beyond virtualization.\nIt consists of a set of platform-as-a-service products that use OS-level virtualization to deliver software in packages called containers.\nA container image contains everything it needs to run independently of the server on which it lives: It contains a copy of the operating system, along with your application.\nThat could include a database, code, configuration files, dependencies, and so forth.\n\nContainerization is a great way to simplify migration of Jenkins instances to different machines, as well as simplify ongoing maintenance and upgrades.\nStarting with versions 2.5 and higher, Jenkins Pipeline has built-in support for interacting with Docker from within a Jenkinsfile.\n\nAlthough you can install and upgrade Jenkins using OS-installable packages, the container images of Jenkins take installation and upgrades to a new level, removing a lot of the complications with maintaining the Jenkins installation.\nThat’s one of the main reasons you should prefer the container images of Jenkins over OS-specific installation packages.\n\nUsing containers as build agents for greater Pipeline flexibility\n\nWhat about using containers in your build agents? You’ll recall that Jenkins agents are the \"workers\" that perform operations requested by the Jenkins controller.\n\nWhat is a Jenkins agent?\n\nMany of you have been writing Jenkins pipelines for awhile, but you’ve been constrained by the tooling that’s available on your agent.\nBut what if you no longer had to be constrained by specific versions of specific tools on specific agents? And that you had full control over the tooling that you’re using just by having Docker available on your agents?\n\nWell, that is exactly what’s possible by using containers as build agents for Jenkins.\nTo learn how to set up your agents with Docker, watch this step-by-step video.\n\nHow to Setup Docker Containers As Build Agents for Jenkins\n\nSo why would you want to use a container as your build agent? As a pipeline author, it gives you the ability to define the tools and the specific versions of those tools that you want to use in your pipeline so that those items are not being mandated or managed by others.\n\nSecondly, if in your environment, someone else has to install the tools for you on your agent, you can completely bypass all of that because you’re able to dynamically bring in the tools that you want or need at runtime.\n\nFinally, it gives you the chance to experiment with different tools without having to make a long-term commitment to those tools.\nBecause if you have a dependency on someone else installing tools for you, that might take a long time.\nBut by running it as a container, you can test it out, and if it works, great! Then you have the option to work with somebody else to get static versions of those tools installed on your agents, or you can just stay with your container-based build agents.\n\nThanks to our Sponsor\n\nDarin works for CloudBees.\nCloudBees helps Fortune 1000 enterprises manage and scale Jenkins.\nThanks to CloudBees for sponsoring the creation of this blog post.","title":"Use Containers as Build Agents","tags":["agents","containers","docker"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/19e71/darinpope.jpg","srcSet":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/77b35/darinpope.jpg 32w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/d4a57/darinpope.jpg 64w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/19e71/darinpope.jpg 128w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/68974/darinpope.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/ef6ff/darinpope.webp 32w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/8257c/darinpope.webp 64w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/6766a/darinpope.webp 128w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/22bfc/darinpope.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"darinpope","html":"<div class=\"paragraph\">\n<p>Darin is a developer advocate for <a href=\"https://www.cloudbees.com\">CloudBees</a>.\nHe is the co-host of the weekly <a href=\"https://www.devopsparadox.com/\">DevOps Paradox</a> podcast.\nHe also hosts regular livestream sessions on continuous integration and continuous delivery.\nRecordings of his live stream sessions are available on the <a href=\"https://www.youtube.com/c/CloudBeesTV/search?query=Darin%20Pope\">CloudBees TV YouTube channel</a>.</p>\n</div>","id":"darinpope","irc":null,"linkedin":"darinpope","name":"Darin Pope","slug":"/blog/authors/darinpope","twitter":"DarinPope"}]}},{"node":{"date":"2021-10-26T00:00:00.000Z","id":"f6c301ff-6215-52d6-bc98-2b3d767cc4e0","slug":"/blog/2021/10/26/just-enough-pipeline/","strippedHtml":"Jenkins Pipeline (or simply Pipeline with a capital P) is a suite of plugins that supports implementing and integrating continuous delivery pipelines into Jenkins.\nThis allows you to automate the process of getting software from version control through to your users and customers.\n\nPipeline code works beautifully for its intended role of automating build, test, deploy, and administration tasks.\nBut, as it is pressed into more complex roles and unexpected uses, some users have run into snags.\nUsing best practices – and avoiding common mistakes – can help you design a pipeline that is more robust, scalable, and high-performing.\n\nWe see a lot of users making basic mistakes that can sabotage their pipeline.\n(Yes, you can sabotage yourself when you’re creating a pipeline.)\nIn fact, it’s easy to spot someone who is going down this dangerous path – and it’s usually because they don’t understand some key technical concepts about Pipeline.\nThis invariably leads to scalability mistakes that you’ll pay dearly for down the line.\n\nDon’t make this mistake!\n\nPerhaps the biggest misstep people make is deciding that they need to write their entire pipeline in a programming language.\nAfter all, Pipeline is a domain specific language (DSL).\nHowever, that does not mean that it is a general-purpose programming language.\n\nIf you treat the DSL as a general-purpose programming language, you are making a serious architectural blunder by doing the wrong work in the wrong place.\nRemember that the core of Pipeline code runs on the controller.\nSo, you should be mindful that everything you express in the Pipeline domain specific language (DSL) will compete with every other Jenkins job running on the controller.\n\nFor example, it’s easy to include a lot of conditionals, flow control logic, and requests using scripted syntax in the pipeline job.\nExperience tells us this is not a good idea and can result in serious damage to pipeline performance.\nWe’ve actually seen organizations with poorly written Pipeline jobs bring a controller to its knees, while only running a few concurrent builds.\n\nWait a minute, you might ask, “Isn’t handling code what the controller is there for?”\nYes, the controller certainly is there to execute pipelines.\nBut, it’s much better to assign individual steps of the pipeline to command line calls that execute on an agent.\nSo, instead of running a lot of conditionals inside the pipeline DSL, it’s better to put those conditionals inside a shell script or batch file and call that script from the pipeline.\n\nHowever, this raises another question: “What if I don’t have any agents connected to my controller?”\nIf this is the case, then you’ve just made another bad mistake in scaling Jenkins pipelines.\nWhy? Because the first rule of building an effective pipeline is to make sure you use agents.\nIf you’re using a Jenkins controller and haven’t defined any agents, then your first step should be to define at least one agent and use that agent instead of executing on the controller.\n\nFor the sake of maintaining scalability in your pipeline, the general rule is to avoid processing any workload on your controller.\nIf you’re running Jenkins jobs on the controller, you are sacrificing controller performance.\nSo, try to avoid using Jenkins controller capacity for things that should be passed off to an agent.\nThen, as you grow and develop, all of your work should be running agents.\nThis is why we always recommend setting the number of executors on the master to zero.\n\nUse Just Enough Pipeline to Keep Your Pipeline Scalable\n\nAll of this serves to highlight our overarching theme of “using just enough pipeline.”\nSimply put, you want to use enough code to connect the pipeline steps and integrate tools – but no more than that.\nLimit the amount of complex logic embedded in the Pipeline itself (similarly to a shell script), and avoid treating it as a general-purpose programming language.\nThis makes the pipeline easier to maintain, protects against bugs, and reduces the load on controllers.\n\nAnother best practice for keeping your pipeline lean, fast, and scalable is to use declarative syntax instead of scripted syntax for your Pipeline.\nDeclarative naturally leads you away from the kinds of mistakes we’ve just described.\nIt is a simpler expression of code and an easier way to define your job.\nIt’s computed at the startup of the pipeline instead of executing continually during the pipeline.\n\nTherefore, when creating a pipeline, start with declarative, and keep it simple for as long as possible.\nAnytime a script block shows up inside of a declarative pipeline, you should extract that block and put it in a shared library step.\nThat keeps the declarative pipeline clean.\nBy combining declarative with a shared library, that will take care of the vast majority of use cases you’ll encounter.\n\nThat said, it’s not accurate to say that declarative plus a shared library will solve every problem.\nThere are cases where scripted is the right solution.\nHowever, declarative is a great starting point until you discover that you absolutely must use scripted.\n\nJust remember, at the end of the day, you’ll do well to follow the adage: “Use just enough pipeline and no more.”\n\nThanks to our Sponsor\n\nMark and Darin both work for CloudBees.\nCloudBees helps Fortune 1000 enterprises manage and scale Jenkins.\nThanks to CloudBees for sponsoring the creation of this blog post.\n\nMark and Darin joined Hope Lynch and Joost van der Griendt to share additional topics in a CloudBees on-demand recording,\"Optimizing Jenkins for the Enterprise\".\nRegister for the on-demand recording to receive more information on configuration as code, plugin management, and Pipelines.","title":"Use Just Enough Pipeline","tags":["pipeline"],"authors":[{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#786888","images":{"fallback":{"src":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/60e20/markewaite.jpg","srcSet":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/f4523/markewaite.jpg 32w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/6859a/markewaite.jpg 64w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/60e20/markewaite.jpg 128w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/57001/markewaite.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/1fd06/markewaite.webp 32w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/a7803/markewaite.webp 64w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/1a87d/markewaite.webp 128w,\n/gatsby-jenkins-io/static/b6d1673d3033c967ff61ee8d4c73aefc/27a57/markewaite.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":140}}},"blog":null,"github":"markewaite","html":"<div class=\"paragraph\">\n<p>Mark is the <a href=\"/project/team-leads/#documentation\">Jenkins Documentation Officer</a>, a long-time Jenkins user and contributor, and maintains the <a href=\"https://plugins.jenkins.io/git\">git plugin</a> and the <a href=\"https://plugins.jenkins.io/git-client\">git client plugin</a>.\nHe is active in <a href=\"/sigs/\">Jenkins special interest groups</a> including the <a href=\"/sigs/docs/\">Docs SIG</a>, <a href=\"/sigs/platform\">Platform SIG</a>, and <a href=\"/sigs/advocacy-and-outreach\">Advocacy SIG</a>.</p>\n</div>","id":"markewaite","irc":"markewaite","linkedin":"markwaite","name":"Mark Waite","slug":"/blog/authors/markewaite","twitter":"MarkEWaite"},{"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/19e71/darinpope.jpg","srcSet":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/77b35/darinpope.jpg 32w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/d4a57/darinpope.jpg 64w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/19e71/darinpope.jpg 128w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/68974/darinpope.jpg 256w","sizes":"(min-width: 128px) 128px, 100vw"},"sources":[{"srcSet":"/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/ef6ff/darinpope.webp 32w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/8257c/darinpope.webp 64w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/6766a/darinpope.webp 128w,\n/gatsby-jenkins-io/static/d2e4143b4f4937f53714ff368da3e6e0/22bfc/darinpope.webp 256w","type":"image/webp","sizes":"(min-width: 128px) 128px, 100vw"}]},"width":128,"height":128}}},"blog":null,"github":"darinpope","html":"<div class=\"paragraph\">\n<p>Darin is a developer advocate for <a href=\"https://www.cloudbees.com\">CloudBees</a>.\nHe is the co-host of the weekly <a href=\"https://www.devopsparadox.com/\">DevOps Paradox</a> podcast.\nHe also hosts regular livestream sessions on continuous integration and continuous delivery.\nRecordings of his live stream sessions are available on the <a href=\"https://www.youtube.com/c/CloudBeesTV/search?query=Darin%20Pope\">CloudBees TV YouTube channel</a>.</p>\n</div>","id":"darinpope","irc":null,"linkedin":"darinpope","name":"Darin Pope","slug":"/blog/authors/darinpope","twitter":"DarinPope"}]}}]}},"pageContext":{"author":"darinpope","limit":8,"skip":0,"numPages":1,"currentPage":1}},
    "staticQueryHashes": ["3649515864"]}